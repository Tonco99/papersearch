[{"id": "http://arxiv.org/abs/1910.02202v1", "updated": "2019-10-05T03:23:45Z", "published": "2019-10-05T03:23:45Z", "title": "Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language", "summary": "In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SIGIR 2019"}, "link": [{"@href": "http://arxiv.org/abs/1910.02202v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.02202v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.09926v1", "updated": "2020-10-19T23:51:33Z", "published": "2020-10-19T23:51:33Z", "title": "Explainable Automated Fact-Checking for Public Health Claims", "summary": "Fact-checking is the task of verifying the veracity of claims by assessing\ntheir assertions against credible evidence. The vast majority of fact-checking\nstudies focus exclusively on political claims. Very little research explores\nfact-checking for other topics, specifically subject matters for which\nexpertise is required. We present the first study of explainable fact-checking\nfor claims which require specific expertise. For our case study we choose the\nsetting of public health. To support this case study we construct a new dataset\nPUBHEALTH of 11.8K claims accompanied by journalist crafted, gold standard\nexplanations (i.e., judgments) to support the fact-check labels for claims. We\nexplore two tasks: veracity prediction and explanation generation. We also\ndefine and evaluate, with humans and computationally, three coherence\nproperties of explanation quality. Our results indicate that, by training on\nin-domain data, gains can be made in explainable, automated fact-checking for\nclaims which require specific expertise.", "author": [{"name": "Neema Kotonya"}, {"name": "Francesca Toni"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to EMNLP 2020. 15 pages, 7 figures, 9 tables. The dataset is\n  available at https://github.com/neemakot/Health-Fact-Checking"}, "link": [{"@href": "http://arxiv.org/abs/2010.09926v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.09926v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.03870v1", "updated": "2020-11-07T23:56:02Z", "published": "2020-11-07T23:56:02Z", "title": "Explainable Automated Fact-Checking: A Survey", "summary": "A number of exciting advances have been made in automated fact-checking\nthanks to increasingly larger datasets and more powerful systems, leading to\nimprovements in the complexity of claims which can be accurately fact-checked.\nHowever, despite these advances, there are still desirable functionalities\nmissing from the fact-checking pipeline. In this survey, we focus on the\nexplanation functionality -- that is fact-checking systems providing reasons\nfor their predictions. We summarize existing methods for explaining the\npredictions of fact-checking systems and we explore trends in this topic.\nFurther, we consider what makes for good explanations in this specific domain\nthrough a comparative analysis of existing fact-checking explanations against\nsome desirable properties. Finally, we propose further research directions for\ngenerating fact-checking explanations, and describe how these may lead to\nimprovements in the research area.", "author": [{"name": "Neema Kotonya"}, {"name": "Francesca Toni"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to COLING 2020. Further resources available at\n  https://github.com/neemakot/Fact-Checking-Survey"}, "link": [{"@href": "http://arxiv.org/abs/2011.03870v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.03870v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.06058v1", "updated": "2020-05-12T21:25:37Z", "published": "2020-05-12T21:25:37Z", "title": "That is a Known Lie: Detecting Previously Fact-Checked Claims", "summary": "The recent proliferation of \"fake news\" has triggered a number of responses,\nmost notably the emergence of several manual fact-checking initiatives. As a\nresult and over time, a large number of fact-checked claims have been\naccumulated, which increases the likelihood that a new claim in social media or\na new statement by a politician might have already been fact-checked by some\ntrusted fact-checking organization, as viral claims often come back after a\nwhile in social media, and politicians like to repeat their favorite\nstatements, true or false, over and over again. As manual fact-checking is very\ntime-consuming (and fully automatic fact-checking has credibility issues), it\nis important to try to save this effort and to avoid wasting time on claims\nthat have already been fact-checked. Interestingly, despite the importance of\nthe task, it has been largely ignored by the research community so far. Here,\nwe aim to bridge this gap. In particular, we formulate the task and we discuss\nhow it relates to, but also differs from, previous work. We further create a\nspecialized dataset, which we release to the research community. Finally, we\npresent learning-to-rank experiments that demonstrate sizable improvements over\nstate-of-the-art retrieval and textual similarity approaches.", "author": [{"name": "Shaden Shaar"}, {"name": "Giovanni Da San Martino"}, {"name": "Nikolay Babulkov"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL-2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.06058v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.06058v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.07423v1", "updated": "2021-04-15T12:39:37Z", "published": "2021-04-15T12:39:37Z", "title": "The Role of Context in Detecting Previously Fact-Checked Claims", "summary": "Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.", "author": [{"name": "Shaden Shaar"}, {"name": "Firoj Alam"}, {"name": "Giovanni Da San Martino"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates"}, "link": [{"@href": "http://arxiv.org/abs/2104.07423v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.07423v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.00715v1", "updated": "2017-10-31T18:52:28Z", "published": "2017-10-31T18:52:28Z", "title": "Related Fact Checks: a tool for combating fake news", "summary": "The emergence of \"Fake News\" and misinformation via online news and social\nmedia has spurred an interest in computational tools to combat this phenomenon.\nIn this paper we present a new \"Related Fact Checks\" service, which can help a\nreader critically evaluate an article and make a judgment on its veracity by\nbringing up fact checks that are relevant to the article. We describe the core\ntechnical problems that need to be solved in building a \"Related Fact Checks\"\nservice, and present results from an evaluation of an implementation.", "author": {"name": "Sreya Guha"}, "link": [{"@href": "http://arxiv.org/abs/1711.00715v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.00715v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.11896v1", "updated": "2021-08-26T16:34:51Z", "published": "2021-08-26T16:34:51Z", "title": "A Survey on Automated Fact-Checking", "summary": "Fact-checking has become increasingly important due to the speed with which\nboth information and misinformation can spread in the modern media ecosystem.\nTherefore, researchers have been exploring how fact-checking can be automated,\nusing techniques based on natural language processing, machine learning,\nknowledge representation, and databases to automatically predict the veracity\nof claims. In this paper, we survey automated fact-checking stemming from\nnatural language processing, and discuss its connections to related tasks and\ndisciplines. In this process, we present an overview of existing datasets and\nmodels, aiming to unify the various definitions given and identify common\nconcepts. Finally, we highlight challenges for future research.", "author": [{"name": "Zhijiang Guo"}, {"name": "Michael Schlichtkrull"}, {"name": "Andreas Vlachos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "27 pages, 15 pages of references"}, "link": [{"@href": "http://arxiv.org/abs/2108.11896v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.11896v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2103.07769v2", "updated": "2021-05-22T12:27:05Z", "published": "2021-03-13T18:29:14Z", "title": "Automated Fact-Checking for Assisting Human Fact-Checkers", "summary": "The reporting and the analysis of current events around the globe has\nexpanded from professional, editor-lead journalism all the way to citizen\njournalism. Nowadays, politicians and other key players enjoy direct access to\ntheir audiences through social media, bypassing the filters of official cables\nor traditional media. However, the multiple advantages of free speech and\ndirect communication are dimmed by the misuse of media to spread inaccurate or\nmisleading claims. These phenomena have led to the modern incarnation of the\nfact-checker -- a professional whose main aim is to examine claims using\navailable evidence and to assess their veracity. As in other text forensics\ntasks, the amount of information available makes the work of the fact-checker\nmore difficult. With this in mind, starting from the perspective of the\nprofessional fact-checker, we survey the available intelligent technologies\nthat can support the human expert in the different steps of her fact-checking\nendeavor. These include identifying claims worth fact-checking, detecting\nrelevant previously fact-checked claims, retrieving relevant evidence to\nfact-check a claim, and actually verifying a claim. In each case, we pay\nattention to the challenges in future work and the potential impact on\nreal-world fact-checking.", "author": [{"name": "Preslav Nakov"}, {"name": "David Corney"}, {"name": "Maram Hasanain"}, {"name": "Firoj Alam"}, {"name": "Tamer Elsayed"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Paolo Papotti"}, {"name": "Shaden Shaar"}, {"name": "Giovanni Da San Martino"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "fact-checking, fact-checkers, check-worthiness, detecting previously\n  fact-checked claims, evidence retrieval"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IJCAI-2021"}, "link": [{"@href": "http://arxiv.org/abs/2103.07769v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.07769v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1804.08012v1", "updated": "2018-04-21T19:18:22Z", "published": "2018-04-21T19:18:22Z", "title": "Integrating Stance Detection and Fact Checking in a Unified Corpus", "summary": "A reasonable approach for fact checking a claim involves retrieving\npotentially relevant documents from different sources (e.g., news websites,\nsocial media, etc.), determining the stance of each document with respect to\nthe claim, and finally making a prediction about the claim's factuality by\naggregating the strength of the stances, while taking the reliability of the\nsource into account. Moreover, a fact checking system should be able to explain\nits decision by providing relevant extracts (rationales) from the documents.\nYet, this setup is not directly supported by existing datasets, which treat\nfact checking, document retrieval, source credibility, stance detection and\nrationale extraction as independent tasks. In this paper, we support the\ninterdependencies between these tasks as annotations in the same corpus. We\nimplement this setup on an Arabic fact checking corpus, the first of its kind.", "author": [{"name": "Ramy Baly"}, {"name": "Mitra Mohtarami"}, {"name": "James Glass"}, {"name": "Lluis Marquez"}, {"name": "Alessandro Moschitti"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Stance Detection, Fact-Checking, Veracity, Arabic, NAACL-2018"}, "link": [{"@href": "http://arxiv.org/abs/1804.08012v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.08012v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1806.07516v2", "updated": "2019-10-09T22:04:46Z", "published": "2018-06-20T01:26:21Z", "title": "The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake\n  News", "summary": "A large body of research work and efforts have been focused on detecting fake\nnews and building online fact-check systems in order to debunk fake news as\nsoon as possible. Despite the existence of these systems, fake news is still\nwildly shared by online users. It indicates that these systems may not be fully\nutilized. After detecting fake news, what is the next step to stop people from\nsharing it? How can we improve the utilization of these fact-check systems? To\nfill this gap, in this paper, we (i) collect and analyze online users called\nguardians, who correct misinformation and fake news in online discussions by\nreferring fact-checking URLs; and (ii) propose a novel fact-checking URL\nrecommendation model to encourage the guardians to engage more in fact-checking\nactivities. We found that the guardians usually took less than one day to reply\nto claims in online conversations and took another day to spread verified\ninformation to hundreds of millions of followers. Our proposed recommendation\nmodel outperformed four state-of-the-art models by 11%~33%. Our source code and\ndataset are available at https://github.com/nguyenvo09/CombatingFakeNews.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SIGIR 2018"}, "link": [{"@href": "http://arxiv.org/abs/1806.07516v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.07516v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.11343v1", "updated": "2020-06-19T19:48:00Z", "published": "2020-06-19T19:48:00Z", "title": "FakeCovid -- A Multilingual Cross-domain Fact Check News Dataset for\n  COVID-19", "summary": "In this paper, we present a first multilingual cross-domain dataset of 5182\nfact-checked news articles for COVID-19, collected from 04/01/2020 to\n15/05/2020. We have collected the fact-checked articles from 92 different\nfact-checking websites after obtaining references from Poynter and Snopes. We\nhave manually annotated articles into 11 different categories of the\nfact-checked news according to their content. The dataset is in 40 languages\nfrom 105 countries. We have built a classifier to detect fake news and present\nresults for the automatic fake news detection and its class. Our model achieves\nan F1 score of 0.76 to detect the false class and other fact check articles.\nThe FakeCovid dataset is available at Github.", "author": [{"name": "Gautam Kishore Shahi"}, {"name": "Durgesh Nandini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.36190/2020.14"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.36190/2020.14", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2006.11343v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.11343v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CySoc 2020 International Workshop on Cyber Social Threats, ICWSM 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.03159v1", "updated": "2020-10-07T04:55:34Z", "published": "2020-10-07T04:55:34Z", "title": "Where Are the Facts? Searching for Fact-checked Information to Alleviate\n  the Spread of Fake News", "summary": "Although many fact-checking systems have been developed in academia and\nindustry, fake news is still proliferating on social media. These systems\nmostly focus on fact-checking but usually neglect online users who are the main\ndrivers of the spread of misinformation. How can we use fact-checked\ninformation to improve users' consciousness of fake news to which they are\nexposed? How can we stop users from spreading fake news? To tackle these\nquestions, we propose a novel framework to search for fact-checking articles,\nwhich address the content of an original tweet (that may contain\nmisinformation) posted by online users. The search can directly warn fake news\nposters and online users (e.g. the posters' followers) about misinformation,\ndiscourage them from spreading fake news, and scale up verified content on\nsocial media. Our framework uses both text and images to search for\nfact-checking articles, and achieves promising results on real-world datasets.\nOur code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Full paper, EMNLP 2020"}, "link": [{"@href": "http://arxiv.org/abs/2010.03159v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.03159v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1501.03471v1", "updated": "2015-01-14T20:18:21Z", "published": "2015-01-14T20:18:21Z", "title": "Computational fact checking from knowledge networks", "summary": "Traditional fact checking by expert journalists cannot keep up with the\nenormous volume of information that is now generated online. Computational fact\nchecking may significantly enhance our ability to evaluate the veracity of\ndubious information. Here we show that the complexities of human fact checking\ncan be approximated quite well by finding the shortest path between concept\nnodes under properly defined semantic proximity metrics on knowledge graphs.\nFramed as a network problem this approach is feasible with efficient\ncomputational techniques. We evaluate this approach by examining tens of\nthousands of claims related to history, entertainment, geography, and\nbiographical information using a public knowledge graph extracted from\nWikipedia. Statements independently known to be true consistently receive\nhigher support via our method than do false ones. These findings represent a\nsignificant step toward scalable computational fact-checking methods that may\none day mitigate the spread of harmful misinformation.", "author": [{"name": "Giovanni Luca Ciampaglia"}, {"name": "Prashant Shiralkar"}, {"name": "Luis M. Rocha"}, {"name": "Johan Bollen"}, {"name": "Filippo Menczer"}, {"name": "Alessandro Flammini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0128193"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0128193", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1501.03471v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1501.03471v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.11722v1", "updated": "2019-08-30T13:12:21Z", "published": "2019-08-30T13:12:21Z", "title": "Fact-Checking Meets Fauxtography: Verifying Claims About Images", "summary": "The recent explosion of false claims in social media and on the Web in\ngeneral has given rise to a lot of manual fact-checking initiatives.\nUnfortunately, the number of claims that need to be fact-checked is several\norders of magnitude larger than what humans can handle manually. Thus, there\nhas been a lot of research aiming at automating the process. Interestingly,\nprevious work has largely ignored the growing number of claims about images.\nThis is despite the fact that visual imagery is more influential than text and\nnaturally appears alongside fake news. Here we aim at bridging this gap. In\nparticular, we create a new dataset for this problem, and we explore a variety\nof features modeling the claim, the image, and the relationship between the\nclaim and the image. The evaluation results show sizable improvements over the\nbaseline. We release our dataset, hoping to enable further research on\nfact-checking claims about images.", "author": [{"name": "Dimitrina Zlatkova"}, {"name": "Preslav Nakov"}, {"name": "Ivan Koychev"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Claims about Images; Fauxtography; Fact-Checking; Veracity; Fake News"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EMNLP-2019"}, "link": [{"@href": "http://arxiv.org/abs/1908.11722v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.11722v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.02471v2", "updated": "2020-08-06T03:11:38Z", "published": "2020-06-03T18:28:57Z", "title": "Can WhatsApp Benefit from Debunked Fact-Checked Stories to Reduce\n  Misinformation?", "summary": "WhatsApp was alleged to be widely used to spread misinformation and\npropaganda during elections in Brazil and India. Due to the private encrypted\nnature of the messages on WhatsApp, it is hard to track the dissemination of\nmisinformation at scale. In this work, using public WhatsApp data, we observe\nthat misinformation has been largely shared on WhatsApp public groups even\nafter they were already fact-checked by popular fact-checking agencies. This\nrepresents a significant portion of misinformation spread in both Brazil and\nIndia in the groups analyzed. We posit that such misinformation content could\nbe prevented if WhatsApp had a means to flag already fact-checked content. To\nthis end, we propose an architecture that could be implemented by WhatsApp to\ncounter such misinformation. Our proposal respects the current end-to-end\nencryption architecture on WhatsApp, thus protecting users' privacy while\nproviding an approach to detect the misinformation that benefits from\nfact-checking efforts.", "author": [{"name": "Julio C. S. Reis"}, {"name": "Philipe de Freitas Melo"}, {"name": "Kiran Garimella"}, {"name": "Fabr\u00edcio Benevenuto"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a preprint version of an accepted manuscript on The Harvard\n  Kennedy School (HKS) Misinformation Review. Please, consider to cite it\n  instead of this one"}, "link": [{"@href": "http://arxiv.org/abs/2006.02471v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.02471v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.10685v1", "updated": "2020-10-21T00:39:04Z", "published": "2020-10-21T00:39:04Z", "title": "Fact-Checking at Scale with DimensionRank", "summary": "The most important problem that has emerged after twenty years of popular\ninternet usage is that of fact-checking at scale. This problem is experienced\nacutely in both of the major internet application platform types, web search\nand social media.\n  We offer a working definition of what a \"platform\" is. We critically\ndeconstruct what we call the \"PolitiFact\" model of fact checking, and show it\nto be inherently inferior for fact-checking at scale to a platform-b ased\nsolution.\n  Our central contribution is to show how to effectively platformize the\nproblem of fact-checking at scale. We show how a two-dimensional rating system,\nwith dimensions agreement and hotness allows us to create information-seeking\nqueries not possible with the on e-dimensional rating system predominating on\nexisting platforms. And, we show that, underlying our user-friendly\nuser-interface, lies a system that allows the creation of formal proofs in the\npropositional calculus.\n  Our algorithm is implemented in our open-source DimensionRank software\npackage available at \"https://thinkdifferentagain.art\".", "author": {"name": "Gregory Coppola"}, "link": [{"@href": "http://arxiv.org/abs/2010.10685v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.10685v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.05448v1", "updated": "2020-11-10T23:02:47Z", "published": "2020-11-10T23:02:47Z", "title": "Generating Fact Checking Briefs", "summary": "Fact checking at scale is difficult -- while the number of active fact\nchecking websites is growing, it remains too small for the needs of the\ncontemporary media ecosystem. However, despite good intentions, contributions\nfrom volunteers are often error-prone, and thus in practice restricted to claim\ndetection. We investigate how to increase the accuracy and efficiency of fact\nchecking by providing information about the claim before performing the check,\nin the form of natural language briefs. We investigate passage-based briefs,\ncontaining a relevant passage from Wikipedia, entity-centric ones consisting of\nWikipedia pages of mentioned entities, and Question-Answering Briefs, with\nquestions decomposing the claim, and their answers. To produce QABriefs, we\ndevelop QABriefer, a model that generates a set of questions conditioned on the\nclaim, searches the web for evidence, and generates answers. To train its\ncomponents, we introduce QABriefDataset which we collected via crowdsourcing.\nWe show that fact checking with briefs -- in particular QABriefs -- increases\nthe accuracy of crowdworkers by 10% while slightly decreasing the time taken.\nFor volunteer (unpaid) fact checkers, QABriefs slightly increase accuracy and\nreduce the time required by around 20%.", "author": [{"name": "Angela Fan"}, {"name": "Aleksandra Piktus"}, {"name": "Fabio Petroni"}, {"name": "Guillaume Wenzek"}, {"name": "Marzieh Saeidi"}, {"name": "Andreas Vlachos"}, {"name": "Antoine Bordes"}, {"name": "Sebastian Riedel"}], "link": [{"@href": "http://arxiv.org/abs/2011.05448v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.05448v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2103.09535v1", "updated": "2021-03-17T09:43:19Z", "published": "2021-03-17T09:43:19Z", "title": "Towards Few-Shot Fact-Checking via Perplexity", "summary": "Few-shot learning has drawn researchers' attention to overcome the problem of\ndata scarcity. Recently, large pre-trained language models have shown great\nperformance in few-shot learning for various downstream tasks, such as question\nanswering and machine translation. Nevertheless, little exploration has been\nmade to achieve few-shot learning for the fact-checking task. However,\nfact-checking is an important problem, especially when the amount of\ninformation online is growing exponentially every day. In this paper, we\npropose a new way of utilizing the powerful transfer learning ability of a\nlanguage model via a perplexity score. The most notable strength of our\nmethodology lies in its capability in few-shot learning. With only two training\nsamples, our methodology can already outperform the Major Class baseline by\nmore than absolute 10% on the F1-Macro metric across multiple datasets. Through\nexperiments, we empirically verify the plausibility of the rather surprising\nusage of the perplexity score in the context of fact-checking and highlight the\nstrength of our few-shot methodology by comparing it to strong\nfine-tuning-based baseline models. Moreover, we construct and publicly release\ntwo new fact-checking datasets related to COVID-19.", "author": [{"name": "Nayeon Lee"}, {"name": "Yejin Bang"}, {"name": "Andrea Madotto"}, {"name": "Madian Khabsa"}, {"name": "Pascale Fung"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accpeted to NAACL'21"}, "link": [{"@href": "http://arxiv.org/abs/2103.09535v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.09535v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.12303v2", "updated": "2021-08-04T18:59:47Z", "published": "2021-07-26T16:20:44Z", "title": "The False COVID-19 Narratives That Keep Being Debunked: A Spatiotemporal\n  Analysis", "summary": "The onset of the Coronavirus disease 2019 (COVID-19) pandemic instigated a\nglobal infodemic that has brought unprecedented challenges for society as a\nwhole. During this time, a number of manual fact-checking initiatives have\nemerged to alleviate the spread of dis/mis-information. This study is about\nCOVID-19 debunks published in multiple languages by different fact-checking\norganisations, sometimes as far as several months apart, despite the fact that\nthe claim has already been fact-checked before. The spatiotemporal analysis\nreveals that similar or nearly duplicate false COVID-19 narratives have been\nspreading in multifarious modalities on various social media platforms in\ndifferent countries. We also find that misinformation involving general medical\nadvice has spread across multiple countries and hence has the highest\nproportion of false COVID-19 narratives that keep being debunked. Furthermore,\nas manual fact-checking is an onerous task in itself, therefore debunking\nsimilar claims recurrently is leading to a waste of resources. To this end, we\npropound the idea of the inclusion of multilingual debunk search in the\nfact-checking pipeline.", "author": [{"name": "Iknoor Singh"}, {"name": "Kalina Bontcheva"}, {"name": "Carolina Scarton"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Under Review"}, "link": [{"@href": "http://arxiv.org/abs/2107.12303v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.12303v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1907.03718v1", "updated": "2019-07-08T16:50:12Z", "published": "2019-07-08T16:50:12Z", "title": "CobWeb: A Research Prototype for Exploring User Bias in Political\n  Fact-Checking", "summary": "The effect of user bias in fact-checking has not been explored extensively\nfrom a user-experience perspective. We estimate the user bias as a function of\nthe user's perceived reputation of the news sources (e.g., a user with liberal\nbeliefs may tend to trust liberal sources). We build an interface to\ncommunicate the role of estimated user bias in the context of a fact-checking\ntask. We also explore the utility of helping users visualize their detected\nlevel of bias. 80% of the users of our system find that the presence of an\nindicator for user bias is useful in judging the veracity of a political claim.", "author": [{"name": "Anubrata Das"}, {"name": "Kunjan Mehta"}, {"name": "Matthew Lease"}], "link": [{"@href": "http://arxiv.org/abs/1907.03718v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.03718v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.06634v1", "updated": "2020-03-14T14:02:27Z", "published": "2020-03-14T14:02:27Z", "title": "Text Similarity Using Word Embeddings to Classify Misinformation", "summary": "Fake news is a growing problem in the last years, especially during\nelections. It's hard work to identify what is true and what is false among all\nthe user generated content that circulates every day. Technology can help with\nthat work and optimize the fact-checking process. In this work, we address the\nchallenge of finding similar content in order to be able to suggest to a\nfact-checker articles that could have been verified before and thus avoid that\nthe same information is verified more than once. This is especially important\nin collaborative approaches to fact-checking where members of large teams will\nnot know what content others have already fact-checked.", "author": [{"name": "Caio Almeida"}, {"name": "D\u00e9bora Santos"}], "link": [{"@href": "http://arxiv.org/abs/2003.06634v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.06634v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.07175v2", "updated": "2021-05-01T23:18:18Z", "published": "2021-04-15T00:25:52Z", "title": "Community-Based Fact-Checking on Twitter's Birdwatch Platform", "summary": "Misinformation undermines the credibility of social media and poses\nsignificant threats to modern societies. As a countermeasure, Twitter has\nrecently introduced \"Birdwatch,\" a community-driven approach to address\nmisinformation on Twitter. On Birdwatch, users can identify tweets they believe\nare misleading, write notes that provide context to the tweet and rate the\nquality of other users' notes. In this work, we empirically analyze how users\ninteract with this new feature. For this purpose, we collect all Birdwatch\nnotes and ratings since the introduction of the feature in early 2021. We then\nmap each Birdwatch note to the fact-checked tweet using Twitter's historical\nAPI. In addition, we use text mining methods to extract content characteristics\nfrom the text explanations in the Birdwatch notes (e.g., sentiment). Our\nempirical analysis yields the following main findings: (i) users more\nfrequently file Birdwatch notes for misleading than not misleading tweets.\nThese misleading tweets are primarily reported because of factual errors, lack\nof important context, or because they contain unverified claims. (ii) Birdwatch\nnotes are more helpful to other users if they link to trustworthy sources and\nif they embed a more positive sentiment. (iii) The helpfulness of Birdwatch\nnotes depends on the social influence of the author of the fact-checked tweet.\nFor influential users with many followers, Birdwatch notes yield a lower level\nof consensus among users and community-created fact checks are more likely to\nbe seen as being incorrect. Altogether, our findings can help social media\nplatforms to formulate guidelines for users on how to write more helpful fact\nchecks. At the same time, our analysis suggests that community-based\nfact-checking faces challenges regarding biased views and polarization among\nthe user base.", "author": {"name": "Nicolas Pr\u00f6llochs"}, "link": [{"@href": "http://arxiv.org/abs/2104.07175v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.07175v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.13046v1", "updated": "2021-04-27T08:43:14Z", "published": "2021-04-27T08:43:14Z", "title": "A Knowledge Enhanced Learning and Semantic Composition Model for\n  Multi-Claim Fact Checking", "summary": "To inhibit the spread of rumorous information and its severe consequences,\ntraditional fact checking aims at retrieving relevant evidence to verify the\nveracity of a given claim. Fact checking methods typically use knowledge graphs\n(KGs) as external repositories and develop reasoning mechanism to retrieve\nevidence for verifying the triple claim. However, existing methods only focus\non verifying a single claim. As real-world rumorous information is more complex\nand a textual statement is often composed of multiple clauses (i.e. represented\nas multiple claims instead of a single one), multiclaim fact checking is not\nonly necessary but more important for practical applications. Although previous\nmethods for verifying a single triple can be applied repeatedly to verify\nmultiple triples one by one, they ignore the contextual information implied in\na multi-claim statement and could not learn the rich semantic information in\nthe statement as a whole. In this paper, we propose an end-to-end knowledge\nenhanced learning and verification method for multi-claim fact checking. Our\nmethod consists of two modules, KG-based learning enhancement and multi-claim\nsemantic composition. To fully utilize the contextual information, the KG-based\nlearning enhancement module learns the dynamic context-specific representations\nvia selectively aggregating relevant attributes of entities. To capture the\ncompositional semantics of multiple triples, the multi-claim semantic\ncomposition module constructs the graph structure to model claim-level\ninteractions, and integrates global and salient local semantics with multi-head\nattention. Experimental results on a real-world dataset and two benchmark\ndatasets show the effectiveness of our method for multi-claim fact checking\nover KG.", "author": [{"name": "Shuai Wang"}, {"name": "Penghui Wei"}, {"name": "Jiahao Zhao"}, {"name": "Wenji Mao"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "28 pages, 4 figures"}, "link": [{"@href": "http://arxiv.org/abs/2104.13046v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13046v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.10274v1", "updated": "2021-08-23T16:22:50Z", "published": "2021-08-23T16:22:50Z", "title": "Towards Explainable Fact Checking", "summary": "The past decade has seen a substantial rise in the amount of mis- and\ndisinformation online, from targeted disinformation campaigns to influence\npolitics, to the unintentional spreading of misinformation about public health.\nThis development has spurred research in the area of automatic fact checking,\nfrom approaches to detect check-worthy claims and determining the stance of\ntweets towards claims, to methods to determine the veracity of claims given\nevidence documents. These automatic methods are often content-based, using\nnatural language processing methods, which in turn utilise deep neural networks\nto learn higher-order features from text in order to make predictions. As deep\nneural networks are black-box models, their inner workings cannot be easily\nexplained. At the same time, it is desirable to explain how they arrive at\ncertain decisions, especially if they are to be used for decision making. While\nthis has been known for some time, the issues this raises have been exacerbated\nby models increasing in size, and by EU legislation requiring models to be used\nfor decision making to provide explanations, and, very recently, by legislation\nrequiring online platforms operating in the EU to provide transparent reporting\non their services. Despite this, current solutions for explainability are still\nlacking in the area of fact checking. This thesis presents my research on\nautomatic fact checking, including claim check-worthiness detection, stance\ndetection and veracity prediction. Its contributions go beyond fact checking,\nwith the thesis proposing more general machine learning solutions for natural\nlanguage processing in the area of learning with limited labelled data.\nFinally, the thesis presents some first solutions for explainable fact\nchecking.", "author": {"name": "Isabelle Augenstein"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Thesis presented to the University of Copenhagen Faculty of Science\n  in partial fulfillment of the requirements for the degree of Doctor\n  Scientiarum (Dr. Scient.)"}, "link": [{"@href": "http://arxiv.org/abs/2108.10274v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.10274v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1610.04170v2", "updated": "2018-01-17T17:44:51Z", "published": "2016-10-13T16:48:45Z", "title": "Network segregation in a model of misinformation and fact checking", "summary": "Misinformation under the form of rumor, hoaxes, and conspiracy theories\nspreads on social media at alarming rates. One hypothesis is that, since social\nmedia are shaped by homophily, belief in misinformation may be more likely to\nthrive on those social circles that are segregated from the rest of the\nnetwork. One possible antidote is fact checking which, in some cases, is known\nto stop rumors from spreading further. However, fact checking may also backfire\nand reinforce the belief in a hoax. Here we take into account the combination\nof network segregation, finite memory and attention, and fact-checking efforts.\nWe consider a compartmental model of two interacting epidemic processes over a\nnetwork that is segregated between gullible and skeptic users. Extensive\nsimulation and mean-field analysis show that a more segregated network\nfacilitates the spread of a hoax only at low forgetting rates, but has no\neffect when agents forget at faster rates. This finding may inform the\ndevelopment of mitigation techniques and overall inform on the risks of\nuncontrolled misinformation online.", "author": [{"name": "Marcella Tambuscio"}, {"name": "Diego F. M. Oliveira"}, {"name": "Giovanni Luca Ciampaglia"}, {"name": "Giancarlo Ruffo"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/s42001-018-0018-9"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/s42001-018-0018-9", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1610.04170v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1610.04170v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "J Comput Soc Sc (2018) 1: 261"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1806.07687v2", "updated": "2018-09-05T12:47:39Z", "published": "2018-06-20T12:13:53Z", "title": "Automated Fact Checking: Task formulations, methods and future\n  directions", "summary": "The recently increased focus on misinformation has stimulated research in\nfact checking, the task of assessing the truthfulness of a claim. Research in\nautomating this task has been conducted in a variety of disciplines including\nnatural language processing, machine learning, knowledge representation,\ndatabases, and journalism. While there has been substantial progress, relevant\npapers and articles have been published in research communities that are often\nunaware of each other and use inconsistent terminology, thus impeding\nunderstanding and further progress. In this paper we survey automated fact\nchecking research stemming from natural language processing and related\ndisciplines, unifying the task formulations and methodologies across papers and\nauthors. Furthermore, we highlight the use of evidence as an important\ndistinguishing factor among them cutting across task formulations and methods.\nWe conclude with proposing avenues for future NLP research on automated fact\nchecking.", "author": [{"name": "James Thorne"}, {"name": "Andreas Vlachos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at the 27th International Conference on Computational\n  Linguistics (COLING 2018)"}, "link": [{"@href": "http://arxiv.org/abs/1806.07687v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.07687v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1904.02037v1", "updated": "2019-04-03T14:46:44Z", "published": "2019-04-03T14:46:44Z", "title": "Automated Fact Checking in the News Room", "summary": "Fact checking is an essential task in journalism; its importance has been\nhighlighted due to recently increased concerns and efforts in combating\nmisinformation. In this paper, we present an automated fact-checking platform\nwhich given a claim, it retrieves relevant textual evidence from a document\ncollection, predicts whether each piece of evidence supports or refutes the\nclaim, and returns a final verdict. We describe the architecture of the system\nand the user interface, focusing on the choices made to improve its\nuser-friendliness and transparency. We conduct a user study of the\nfact-checking platform in a journalistic setting: we integrated it with a\ncollection of news articles and provide an evaluation of the platform using\nfeedback from journalists in their workflow. We found that the predictions of\nour platform were correct 58\\% of the time, and 59\\% of the returned evidence\nwas relevant.", "author": [{"name": "Sebasti\u00e3o Miranda"}, {"name": "David Nogueira"}, {"name": "Afonso Mendes"}, {"name": "Andreas Vlachos"}, {"name": "Andrew Secker"}, {"name": "Rebecca Garrett"}, {"name": "Jeff Mitchel"}, {"name": "Zita Marinho"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "WEBCONF 2019"}, "link": [{"@href": "http://arxiv.org/abs/1904.02037v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.02037v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.09198v1", "updated": "2019-06-21T15:35:03Z", "published": "2019-06-21T15:35:03Z", "title": "Explainable Fact Checking with Probabilistic Answer Set Programming", "summary": "One challenge in fact checking is the ability to improve the transparency of\nthe decision. We present a fact checking method that uses reference information\nin knowledge graphs (KGs) to assess claims and explain its decisions. KGs\ncontain a formal representation of knowledge with semantic descriptions of\nentities and their relationships. We exploit such rich semantics to produce\ninterpretable explanations for the fact checking output. As information in a KG\nis inevitably incomplete, we rely on logical rule discovery and on Web text\nmining to gather the evidence to assess a given claim. Uncertain rules and\nfacts are turned into logical programs and the checking task is modeled as an\ninference problem in a probabilistic extension of answer set programs.\nExperiments show that the probabilistic inference enables the efficient\nlabeling of claims with interpretable explanations, and the quality of the\nresults is higher than state of the art baselines.", "author": [{"name": "Naser Ahmadi"}, {"name": "Joohyung Lee"}, {"name": "Paolo Papotti"}, {"name": "Mohammed Saeed"}], "link": [{"@href": "http://arxiv.org/abs/1906.09198v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.09198v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LO", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.05380v1", "updated": "2019-09-11T21:25:40Z", "published": "2019-09-11T21:25:40Z", "title": "Selecting Data to Clean for Fact Checking: Minimizing Uncertainty vs.\n  Maximizing Surprise", "summary": "We study the optimization problem of selecting numerical quantities to clean\nin order to fact-check claims based on such data. Oftentimes, such claims are\ntechnically correct, but they can still mislead for two reasons. First, data\nmay contain uncertainty and errors. Second, data can be \"fished\" to advance\nparticular positions. In practice, fact-checkers cannot afford to clean all\ndata and must choose to clean what \"matters the most\" to checking a claim. We\nexplore alternative definitions of what \"matters the most\": one is to ascertain\nclaim qualities (by minimizing uncertainty in these measures), while an\nalternative is just to counter the claim (by maximizing the probability of\nfinding a counterargument). We show whether the two objectives align with each\nother, with important implications on when fact-checkers should exercise care\nin selective data cleaning, to avoid potential bias introduced by their desire\nto counter claims. We develop efficient algorithms for solving the various\nvariants of the optimization problem, showing significant improvements over\nnaive solutions. The problem is particularly challenging because the objectives\nin the fact-checking context are complex, non-linear functions over data. We\nobtain results that generalize to a large class of functions, with potential\napplications beyond fact-checking.", "author": [{"name": "Stavros Sintos"}, {"name": "Pankaj K. Agarwal"}, {"name": "Jun Yang"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.14778/3358701.3358708"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.14778/3358701.3358708", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1909.05380v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.05380v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1912.08084v1", "updated": "2019-12-14T10:29:13Z", "published": "2019-12-14T10:29:13Z", "title": "A Context-Aware Approach for Detecting Check-Worthy Claims in Political\n  Debates", "summary": "In the context of investigative journalism, we address the problem of\nautomatically identifying which claims in a given document are most worthy and\nshould be prioritized for fact-checking. Despite its importance, this is a\nrelatively understudied problem. Thus, we create a new dataset of political\ndebates, containing statements that have been fact-checked by nine reputable\nsources, and we train machine learning models to predict which claims should be\nprioritized for fact-checking, i.e., we model the problem as a ranking task.\nUnlike previous work, which has looked primarily at sentences in isolation, in\nthis paper we focus on a rich input representation modeling the context:\nrelationship between the target statement and the larger context of the debate,\ninteraction between the opponents, and reaction by the moderator and by the\npublic. Our experiments show state-of-the-art results, outperforming a strong\nrivaling system by a margin, while also confirming the importance of the\ncontextual information.", "author": [{"name": "Pepa Gencheva"}, {"name": "Ivan Koychev"}, {"name": "Llu\u00eds M\u00e0rquez"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Check-worthiness; Fact-Checking; Veracity; Neural Networks. arXiv\n  admin note: substantial text overlap with arXiv:1908.01328"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RANLP-2017"}, "link": [{"@href": "http://arxiv.org/abs/1912.08084v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.08084v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.02214v1", "updated": "2020-01-07T18:26:38Z", "published": "2020-01-07T18:26:38Z", "title": "Attributed Multi-Relational Attention Network for Fact-checking URL\n  Recommendation", "summary": "To combat fake news, researchers mostly focused on detecting fake news and\njournalists built and maintained fact-checking sites (e.g., Snopes.com and\nPolitifact.com). However, fake news dissemination has been greatly promoted via\nsocial media sites, and these fact-checking sites have not been fully utilized.\nTo overcome these problems and complement existing methods against fake news,\nin this paper we propose a deep-learning based fact-checking URL recommender\nsystem to mitigate impact of fake news in social media sites such as Twitter\nand Facebook. In particular, our proposed framework consists of a\nmulti-relational attentive module and a heterogeneous graph attention network\nto learn complex/semantic relationship between user-URL pairs, user-user pairs,\nand URL-URL pairs. Extensive experiments on a real-world dataset show that our\nproposed framework outperforms eight state-of-the-art recommendation models,\nachieving at least 3~5.3% improvement.", "author": [{"name": "Di You"}, {"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}, {"name": "Qiang Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CIKM2019"}, "link": [{"@href": "http://arxiv.org/abs/2001.02214v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.02214v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.04374v1", "updated": "2020-08-10T19:21:06Z", "published": "2020-08-10T19:21:06Z", "title": "Can We Spot the \"Fake News\" Before It Was Even Written?", "summary": "Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n\"fake news.\" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.", "author": {"name": "Preslav Nakov"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Fake News, Disinformation, Media Bias, Propaganda, Infodemic,\n  COVID-19"}, "link": [{"@href": "http://arxiv.org/abs/2008.04374v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.04374v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.01215v1", "updated": "2021-04-02T19:27:53Z", "published": "2021-04-02T19:27:53Z", "title": "The Coronavirus is a Bioweapon: Analysing Coronavirus Fact-Checked\n  Stories", "summary": "The 2020 coronavirus pandemic has heightened the need to flag\ncoronavirus-related misinformation, and fact-checking groups have taken to\nverifying misinformation on the Internet. We explore stories reported by\nfact-checking groups PolitiFact, Poynter and Snopes from January to June 2020,\ncharacterising them into six story clusters before then analyse time-series and\nstory validity trends and the level of agreement across sites. We further break\ndown the story clusters into more granular story types by proposing a unique\nautomated method with a BERT classifier, which can be used to classify diverse\nstory sources, in both fact-checked stories and tweets.", "author": [{"name": "Lynnette Hui Xian Ng"}, {"name": "Kathleen M. Carley"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SBP-Brims 2020 COVID Special Track"}, "link": [{"@href": "http://arxiv.org/abs/2104.01215v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.01215v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2109.00835v1", "updated": "2021-09-02T10:45:07Z", "published": "2021-09-02T10:45:07Z", "title": "WikiCheck: An end-to-end open source Automatic Fact-Checking API based\n  on Wikipedia", "summary": "With the growth of fake news and disinformation, the NLP community has been\nworking to assist humans in fact-checking. However, most academic research has\nfocused on model accuracy without paying attention to resource efficiency,\nwhich is crucial in real-life scenarios. In this work, we review the\nState-of-the-Art datasets and solutions for Automatic Fact-checking and test\ntheir applicability in production environments. We discover overfitting issues\nin those models, and we propose a data filtering method that improves the\nmodel's performance and generalization. Then, we design an unsupervised\nfine-tuning of the Masked Language models to improve its accuracy working with\nWikipedia. We also propose a novel query enhancing method to improve evidence\ndiscovery using the Wikipedia Search API. Finally, we present a new\nfact-checking system, the \\textit{WikiCheck} API that automatically performs a\nfacts validation process based on the Wikipedia knowledge base. It is\ncomparable to SOTA solutions in terms of accuracy and can be used on low-memory\nCPU instances.", "author": [{"name": "Mykola Trokhymovych"}, {"name": "Diego Saez-Trumper"}], "link": [{"@href": "http://arxiv.org/abs/2109.00835v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2109.00835v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1801.06122v1", "updated": "2018-01-18T16:54:01Z", "published": "2018-01-18T16:54:01Z", "title": "Anatomy of an online misinformation network", "summary": "Massive amounts of fake news and conspiratorial content have spread over\nsocial media before and after the 2016 US Presidential Elections despite\nintense fact-checking efforts. How do the spread of misinformation and\nfact-checking compete? What are the structural and dynamic characteristics of\nthe core of the misinformation diffusion network, and who are its main\npurveyors? How to reduce the overall amount of misinformation? To explore these\nquestions we built Hoaxy, an open platform that enables large-scale, systematic\nstudies of how misinformation and fact-checking spread and compete on Twitter.\nHoaxy filters public tweets that include links to unverified claims or\nfact-checking articles. We perform k-core decomposition on a diffusion network\nobtained from two million retweets produced by several hundred thousand\naccounts over the six months before the election. As we move from the periphery\nto the core of the network, fact-checking nearly disappears, while social bots\nproliferate. The number of users in the main core reaches equilibrium around\nthe time of the election, with limited churn and increasingly dense\nconnections. We conclude by quantifying how effectively the network can be\ndisrupted by penalizing the most central nodes. These findings provide a first\nlook at the anatomy of a massive online misinformation diffusion network.", "author": [{"name": "Chengcheng Shao"}, {"name": "Pik-Mai Hui"}, {"name": "Lei Wang"}, {"name": "Xinwen Jiang"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}, {"name": "Giovanni Luca Ciampaglia"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0196087"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0196087", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1801.06122v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1801.06122v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "28 pages, 11 figures, submitted to PLOS ONE"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PLoS ONE, 13(4): e0196087. 2018"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1603.01511v1", "updated": "2016-03-04T15:59:06Z", "published": "2016-03-04T15:59:06Z", "title": "Hoaxy: A Platform for Tracking Online Misinformation", "summary": "Massive amounts of misinformation have been observed to spread in\nuncontrolled fashion across social media. Examples include rumors, hoaxes, fake\nnews, and conspiracy theories. At the same time, several journalistic\norganizations devote significant efforts to high-quality fact checking of\nonline claims. The resulting information cascades contain instances of both\naccurate and inaccurate information, unfold over multiple time scales, and\noften reach audiences of considerable size. All these factors pose challenges\nfor the study of the social dynamics of online news sharing. Here we introduce\nHoaxy, a platform for the collection, detection, and analysis of online\nmisinformation and its related fact-checking efforts. We discuss the design of\nthe platform and present a preliminary analysis of a sample of public tweets\ncontaining both fake news and fact checking. We find that, in the aggregate,\nthe sharing of fact-checking content typically lags that of misinformation by\n10--20 hours. Moreover, fake news are dominated by very active users, while\nfact checking is a more grass-roots activity. With the increasing risks\nconnected to massive online misinformation, social news observatories have the\npotential to help researchers, journalists, and the general public understand\nthe dynamics of real and fake news sharing.", "author": [{"name": "Chengcheng Shao"}, {"name": "Giovanni Luca Ciampaglia"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/2872518.2890098"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/2872518.2890098", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1603.01511v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1603.01511v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 6 figures, submitted to Third Workshop on Social News On the\n  Web"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.01214v1", "updated": "2019-10-29T16:07:12Z", "published": "2019-10-29T16:07:12Z", "title": "A Richly Annotated Corpus for Different Tasks in Automated Fact-Checking", "summary": "Automated fact-checking based on machine learning is a promising approach to\nidentify false information distributed on the web. In order to achieve\nsatisfactory performance, machine learning methods require a large corpus with\nreliable annotations for the different tasks in the fact-checking process.\nHaving analyzed existing fact-checking corpora, we found that none of them\nmeets these criteria in full. They are either too small in size, do not provide\ndetailed annotations, or are limited to a single domain. Motivated by this gap,\nwe present a new substantially sized mixed-domain corpus with annotations of\ngood quality for the core fact-checking tasks: document retrieval, evidence\nextraction, stance detection, and claim validation. To aid future corpus\nconstruction, we describe our methodology for corpus creation and annotation,\nand demonstrate that it results in substantial inter-annotator agreement. As\nbaselines for future research, we perform experiments on our corpus with a\nnumber of model architectures that reach high performance in similar problem\nsettings. Finally, to support the development of future models, we provide a\ndetailed error analysis for each of the tasks. Our results show that the\nrealistic, multi-domain setting defined by our data poses new challenges for\nthe existing models, providing opportunities for considerable improvement by\nfuture systems.", "author": [{"name": "Andreas Hanselowski"}, {"name": "Christian Stab"}, {"name": "Claudia Schulz"}, {"name": "Zile Li"}, {"name": "Iryna Gurevych"}], "link": [{"@href": "http://arxiv.org/abs/1911.01214v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.01214v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.00853v1", "updated": "2021-06-01T23:28:05Z", "published": "2021-06-01T23:28:05Z", "title": "Claim Matching Beyond English to Scale Global Fact-Checking", "summary": "Manual fact-checking does not scale well to serve the needs of the internet.\nThis issue is further compounded in non-English contexts. In this paper, we\ndiscuss claim matching as a possible solution to scale fact-checking. We define\nclaim matching as the task of identifying pairs of textual messages containing\nclaims that can be served with one fact-check. We construct a novel dataset of\nWhatsApp tipline and public group messages alongside fact-checked claims that\nare first annotated for containing \"claim-like statements\" and then matched\nwith potentially similar items and annotated for claim matching. Our dataset\ncontains content in high-resource (English, Hindi) and lower-resource (Bengali,\nMalayalam, Tamil) languages. We train our own embedding model using knowledge\ndistillation and a high-quality \"teacher\" model in order to address the\nimbalance in embedding quality between the low- and high-resource languages in\nour dataset. We provide evaluations on the performance of our solution and\ncompare with baselines and existing state-of-the-art multilingual embedding\nmodels, namely LASER and LaBSE. We demonstrate that our performance exceeds\nLASER and LaBSE in all settings. We release our annotated datasets, codebooks,\nand trained embedding model to allow for further research.", "author": [{"name": "Ashkan Kazemi"}, {"name": "Kiran Garimella"}, {"name": "Devin Gaffney"}, {"name": "Scott A. Hale"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "to appear in ACL 2021 as a long paper"}, "link": [{"@href": "http://arxiv.org/abs/2106.00853v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.00853v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.05773v2", "updated": "2020-11-12T04:20:37Z", "published": "2020-11-11T13:48:44Z", "title": "The Role of the Crowd in Countering Misinformation: A Case Study of the\n  COVID-19 Infodemic", "summary": "Fact checking by professionals is viewed as a vital defense in the fight\nagainst misinformation.While fact checking is important and its impact has been\nsignificant, fact checks could have limited visibility and may not reach the\nintended audience, such as those deeply embedded in polarized communities.\nConcerned citizens (i.e., the crowd), who are users of the platforms where\nmisinformation appears, can play a crucial role in disseminating fact-checking\ninformation and in countering the spread of misinformation. To explore if this\nis the case, we conduct a data-driven study of misinformation on the Twitter\nplatform, focusing on tweets related to the COVID-19 pandemic, analyzing the\nspread of misinformation, professional fact checks, and the crowd response to\npopular misleading claims about COVID-19. In this work, we curate a dataset of\nfalse claims and statements that seek to challenge or refute them. We train a\nclassifier to create a novel dataset of 155,468 COVID-19-related tweets,\ncontaining 33,237 false claims and 33,413 refuting arguments.Our findings show\nthat professional fact-checking tweets have limited volume and reach. In\ncontrast, we observe that the surge in misinformation tweets results in a quick\nresponse and a corresponding increase in tweets that refute such\nmisinformation. More importantly, we find contrasting differences in the way\nthe crowd refutes tweets, some tweets appear to be opinions, while others\ncontain concrete evidence, such as a link to a reputed source. Our work\nprovides insights into how misinformation is organically countered in social\nplatforms by some of their users and the role they play in amplifying\nprofessional fact checks.These insights could lead to development of tools and\nmechanisms that can empower concerned citizens in combating misinformation. The\ncode and data can be found in\nhttp://claws.cc.gatech.edu/covid_counter_misinformation.html.", "author": [{"name": "Nicholas Micallef"}, {"name": "Bing He"}, {"name": "Srijan Kumar"}, {"name": "Mustaque Ahamad"}, {"name": "Nasir Memon"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PrePrint - IEEE BigData 2020. The code and data can be found in\n  http://claws.cc.gatech.edu/covid_counter_misinformation.html"}, "link": [{"@href": "http://arxiv.org/abs/2011.05773v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.05773v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.01515v1", "updated": "2019-05-29T09:31:26Z", "published": "2019-05-29T09:31:26Z", "title": "TMLab SRPOL at SemEval-2019 Task 8: Fact Checking in Community Question\n  Answering Forums", "summary": "The article describes our submission to SemEval 2019 Task 8 on Fact-Checking\nin Community Forums. The systems under discussion participated in Subtask A:\ndecide whether a question asks for factual information, opinion/advice or is\njust socializing. Our primary submission was ranked as the second one among all\nparticipants in the official evaluation phase. The article presents our primary\nsolution: Deeply Regularized Residual Neural Network (DRR NN) with Universal\nSentence Encoder embeddings. This is followed by a description of two\ncontrastive solutions based on ensemble methods.", "author": [{"name": "Piotr Niewinski"}, {"name": "Aleksander Wawer"}, {"name": "Maria Pszona"}, {"name": "Maria Janicka"}], "link": [{"@href": "http://arxiv.org/abs/1906.01515v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.01515v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.04164v1", "updated": "2019-06-07T18:49:38Z", "published": "2019-06-07T18:49:38Z", "title": "FAKTA: An Automatic End-to-End Fact Checking System", "summary": "We present FAKTA which is a unified framework that integrates various\ncomponents of a fact checking process: document retrieval from media sources\nwith various types of reliability, stance detection of documents with respect\nto given claims, evidence extraction, and linguistic analysis. FAKTA predicts\nthe factuality of given claims and provides evidence at the document and\nsentence level to explain its predictions", "author": [{"name": "Moin Nadeem"}, {"name": "Wei Fang"}, {"name": "Brian Xu"}, {"name": "Mitra Mohtarami"}, {"name": "James Glass"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to NAACL '19"}, "link": [{"@href": "http://arxiv.org/abs/1906.04164v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.04164v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.10926v1", "updated": "2020-01-29T16:14:47Z", "published": "2020-01-29T16:14:47Z", "title": "HoaxItaly: a collection of Italian disinformation and fact-checking\n  stories shared on Twitter in 2019", "summary": "We released over 1 million tweets shared during 2019 and containing links to\nthousands of news articles published on two classes of Italian outlets: (1)\ndisinformation websites, i.e. outlets which have been repeatedly flagged by\njournalists and fact-checkers for producing low-credibility content such as\nfalse news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)\nfact-checking websites which notably debunk and verify online news and claims.\nThe dataset, which includes also title and body for approximately 37k news\narticles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.", "author": [{"name": "Francesco Pierri"}, {"name": "Alessandro Artoni"}, {"name": "Stefano Ceri"}], "link": [{"@href": "http://arxiv.org/abs/2001.10926v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.10926v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.09263v1", "updated": "2020-12-16T21:00:24Z", "published": "2020-12-16T21:00:24Z", "title": "Checking Fact Worthiness using Sentence Embeddings", "summary": "Checking and confirming factual information in texts and speeches is vital to\ndetermine the veracity and correctness of the factual statements. This work was\npreviously done by journalists and other manual means but it is a\ntime-consuming task. With the advancements in Information Retrieval and NLP,\nresearch in the area of Fact-checking is getting attention for automating it.\nCLEF-2018 and 2019 organised tasks related to Fact-checking and invited\nparticipants. This project focuses on CLEF-2019 Task-1 Check-Worthiness and\nexperiments using the latest Sentence-BERT pre-trained embeddings, topic\nModeling and sentiment score are performed. Evaluation metrics such as MAP,\nMean Reciprocal Rank, Mean R-Precision and Mean Precision@N present the\nimprovement in the results using the techniques.", "author": {"name": "Sidharth Singla"}, "link": [{"@href": "http://arxiv.org/abs/2012.09263v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.09263v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.02335v1", "updated": "2021-02-03T23:37:09Z", "published": "2021-02-03T23:37:09Z", "title": "Self-Supervised Claim Identification for Automated Fact Checking", "summary": "We propose a novel, attention-based self-supervised approach to identify\n\"claim-worthy\" sentences in a fake news article, an important first step in\nautomated fact-checking. We leverage \"aboutness\" of headline and content using\nattention mechanism for this task. The identified claims can be used for\ndownstream task of claim verification for which we are releasing a benchmark\ndataset of manually selected compelling articles with veracity labels and\nassociated evidence. This work goes beyond stylistic analysis to identifying\ncontent that influences reader belief. Experiments with three datasets show the\nstrength of our model. Data and code available at\nhttps://github.com/architapathak/Self-Supervised-ClaimIdentification", "author": [{"name": "Archita Pathak"}, {"name": "Mohammad Abuzar Shaikh"}, {"name": "Rohini Srihari"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages, 4 figures, Accepted at ICON 2020"}, "link": [{"@href": "http://arxiv.org/abs/2102.02335v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.02335v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.12918v1", "updated": "2021-04-27T00:21:55Z", "published": "2021-04-27T00:21:55Z", "title": "Extractive and Abstractive Explanations for Fact-Checking and Evaluation\n  of News", "summary": "In this paper, we explore the construction of natural language explanations\nfor news claims, with the goal of assisting fact-checking and news evaluation\napplications. We experiment with two methods: (1) an extractive method based on\nBiased TextRank -- a resource-effective unsupervised graph-based algorithm for\ncontent extraction; and (2) an abstractive method based on the GPT-2 language\nmodel. We perform comparative evaluations on two misinformation datasets in the\npolitical and health news domains, and find that the extractive method shows\nthe most promise.", "author": [{"name": "Ashkan Kazemi"}, {"name": "Zehua Li"}, {"name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"name": "Rada Mihalcea"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to NLP for Internet Freedom Workshop at NAACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.12918v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.12918v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.00950v1", "updated": "2021-06-02T05:40:12Z", "published": "2021-06-02T05:40:12Z", "title": "A Multi-Level Attention Model for Evidence-Based Fact Checking", "summary": "Evidence-based fact checking aims to verify the truthfulness of a claim\nagainst evidence extracted from textual sources. Learning a representation that\neffectively captures relations between a claim and evidence can be challenging.\nRecent state-of-the-art approaches have developed increasingly sophisticated\nmodels based on graph structures. We present a simple model that can be trained\non sequence structures. Our model enables inter-sentence attentions at\ndifferent levels and can benefit from joint training. Results on a large-scale\ndataset for Fact Extraction and VERification (FEVER) show that our model\noutperforms the graph-based approaches and yields 1.09% and 1.42% improvements\nin label accuracy and FEVER score, respectively, over the best published model.", "author": [{"name": "Canasai Kruengkrai"}, {"name": "Junichi Yamagishi"}, {"name": "Xin Wang"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Findings of ACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2106.00950v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.00950v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1708.07239v1", "updated": "2017-08-24T01:07:21Z", "published": "2017-08-24T01:07:21Z", "title": "Finding Streams in Knowledge Graphs to Support Fact Checking", "summary": "The volume and velocity of information that gets generated online limits\ncurrent journalistic practices to fact-check claims at the same rate.\nComputational approaches for fact checking may be the key to help mitigate the\nrisks of massive misinformation spread. Such approaches can be designed to not\nonly be scalable and effective at assessing veracity of dubious claims, but\nalso to boost a human fact checker's productivity by surfacing relevant facts\nand patterns to aid their analysis. To this end, we present a novel,\nunsupervised network-flow based approach to determine the truthfulness of a\nstatement of fact expressed in the form of a (subject, predicate, object)\ntriple. We view a knowledge graph of background information about real-world\nentities as a flow network, and knowledge as a fluid, abstract commodity. We\nshow that computational fact checking of such a triple then amounts to finding\na \"knowledge stream\" that emanates from the subject node and flows toward the\nobject node through paths connecting them. Evaluation on a range of real-world\nand hand-crafted datasets of facts related to entertainment, business, sports,\ngeography and more reveals that this network-flow model can be very effective\nin discerning true statements from false ones, outperforming existing\nalgorithms on many test cases. Moreover, the model is expressive in its ability\nto automatically discover several useful path patterns and surface relevant\nfacts that may help a human fact checker corroborate or refute a claim.", "author": [{"name": "Prashant Shiralkar"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}, {"name": "Giovanni Luca Ciampaglia"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Extended version of the paper in proceedings of ICDM 2017"}, "link": [{"@href": "http://arxiv.org/abs/1708.07239v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1708.07239v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.01328v1", "updated": "2019-08-04T12:40:28Z", "published": "2019-08-04T12:40:28Z", "title": "Automatic Fact-Checking Using Context and Discourse Information", "summary": "We study the problem of automatic fact-checking, paying special attention to\nthe impact of contextual and discourse information. We address two related\ntasks: (i) detecting check-worthy claims, and (ii) fact-checking claims. We\ndevelop supervised systems based on neural networks, kernel-based support\nvector machines, and combinations thereof, which make use of rich input\nrepresentations in terms of discourse cues and contextual features. For the\ncheck-worthiness estimation task, we focus on political debates, and we model\nthe target claim in the context of the full intervention of a participant and\nthe previous and the following turns in the debate, taking into account\ncontextual meta information. For the fact-checking task, we focus on answer\nverification in a community forum, and we model the veracity of the answer with\nrespect to the entire question--answer thread in which it occurs as well as\nwith respect to other related posts from the entire forum. We develop annotated\ndatasets for both tasks and we run extensive experimental evaluation,\nconfirming that both types of information ---but especially contextual\nfeatures--- play an important role.", "author": [{"name": "Pepa Atanasova"}, {"name": "Preslav Nakov"}, {"name": "Llu\u00eds M\u00e0rquez"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Georgi Karadzhov"}, {"name": "Tsvetomila Mihaylova"}, {"name": "Mitra Mohtarami"}, {"name": "James Glass"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3297722"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3297722", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1908.01328v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.01328v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "JDIQ,Special Issue on Combating Digital Misinformation and\n  Disinformation"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "J. Data and Information Quality, Volume 11 Issue 3, July 2019,\n  Article No. 12"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.02431v1", "updated": "2020-09-05T01:44:11Z", "published": "2020-09-05T01:44:11Z", "title": "Accenture at CheckThat! 2020: If you say so: Post-hoc fact-checking of\n  claims using transformer-based models", "summary": "We introduce the strategies used by the Accenture Team for the CLEF2020\nCheckThat! Lab, Task 1, on English and Arabic. This shared task evaluated\nwhether a claim in social media text should be professionally fact checked. To\na journalist, a statement presented as fact, which would be of interest to a\nlarge audience, requires professional fact-checking before dissemination. We\nutilized BERT and RoBERTa models to identify claims in social media text a\nprofessional fact-checker should review, and rank these in priority order for\nthe fact-checker. For the English challenge, we fine-tuned a RoBERTa model and\nadded an extra mean pooling layer and a dropout layer to enhance\ngeneralizability to unseen text. For the Arabic task, we fine-tuned\nArabic-language BERT models and demonstrate the use of back-translation to\namplify the minority class and balance the dataset. The work presented here was\nscored 1st place in the English track, and 1st, 2nd, 3rd, and 4th place in the\nArabic track.", "author": [{"name": "Evan Williams"}, {"name": "Paul Rodrigues"}, {"name": "Valerie Novak"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To Appear As: Evan Williams, Paul Rodrigues, Valerie Novak. Accenture\n  at CheckThat! 2020: If you say so: Post-hoc fact-checking of claims using\n  transformer-based models. In: Cappellato et al. Working Notes of CLEF\n  2020-Conference and Labs of the Evaluation Forum. Thessaloniki, Greece. 22-25\n  September 2020"}, "link": [{"@href": "http://arxiv.org/abs/2009.02431v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.02431v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2009.02931v1", "updated": "2020-09-07T08:03:21Z", "published": "2020-09-07T08:03:21Z", "title": "Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models", "summary": "While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.", "author": [{"name": "Alex Nikolov"}, {"name": "Giovanni Da San Martino"}, {"name": "Ivan Koychev"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Check-worthiness; Fact-Checking; Veracity"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF-2020"}, "link": [{"@href": "http://arxiv.org/abs/2009.02931v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.02931v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.11004v1", "updated": "2020-12-20T19:35:25Z", "published": "2020-12-20T19:35:25Z", "title": "Fake news agenda in the era of COVID-19: Identifying trends through\n  fact-checking content", "summary": "The rise of social media has ignited an unprecedented circulation of false\ninformation in our society. It is even more evident in times of crises, such as\nthe COVID-19 pandemic. Fact-checking efforts have expanded greatly and have\nbeen touted as among the most promising solutions to fake news, especially in\ntimes like these. Several studies have reported the development of\nfact-checking organizations in Western societies, albeit little attention has\nbeen given to the Global South. Here, to fill this gap, we introduce a novel\nMarkov-inspired computational method for identifying topics in tweets. In\ncontrast to other topic modeling approaches, our method clusters topics and\ntheir current evolution in a predefined time window. Through these, we\ncollected data from Twitter accounts of two Brazilian fact-checking outlets and\npresented the topics debunked by these initiatives in fortnights throughout the\npandemic. By comparing these organizations, we could identify similarities and\ndifferences in what was shared by them. Our method resulted in an important\ntechnique to cluster topics in a wide range of scenarios, including an\ninfodemic -- a period overabundance of the same information. In particular, the\ndata clearly revealed a complex intertwining between politics and the health\ncrisis during this period. We conclude by proposing a generic model which, in\nour opinion, is suitable for topic modeling and an agenda for future research.", "author": [{"name": "Wilson Ceron"}, {"name": "Mathias-Felipe de-Lima-Santos"}, {"name": "Marcos G. Quiles"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.osnem.2020.100116"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.osnem.2020.100116", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2012.11004v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.11004v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Online Social Networks and Media, 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1510.05911v2", "updated": "2016-04-15T14:43:30Z", "published": "2015-10-20T14:31:31Z", "title": "Discriminative Predicate Path Mining for Fact Checking in Knowledge\n  Graphs", "summary": "Traditional fact checking by experts and analysts cannot keep pace with the\nvolume of newly created information. It is important and necessary, therefore,\nto enhance our ability to computationally determine whether some statement of\nfact is true or false. We view this problem as a link-prediction task in a\nknowledge graph, and present a discriminative path-based method for fact\nchecking in knowledge graphs that incorporates connectivity, type information,\nand predicate interactions. Given a statement S of the form (subject,\npredicate, object), for example, (Chicago, capitalOf, Illinois), our approach\nmines discriminative paths that alternatively define the generalized statement\n(U.S. city, predicate, U.S. state) and uses the mined rules to evaluate the\nveracity of statement S. We evaluate our approach by examining thousands of\nclaims related to history, geography, biology, and politics using a public,\nmillion node knowledge graph extracted from Wikipedia and PubMedDB. Not only\ndoes our approach significantly outperform related models, we also find that\nthe discriminative predicate path model is easily interpretable and provides\nsensible reasons for the final determination.", "author": [{"name": "Baoxu Shi"}, {"name": "Tim Weninger"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.knosys.2016.04.015"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.knosys.2016.04.015", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1510.05911v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1510.05911v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "17 pages, 4 Figures. To Appear in Knowledge Based Systems"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.4, H.2.8", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.01806v1", "updated": "2018-11-05T15:43:45Z", "published": "2018-11-05T15:43:45Z", "title": "Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of\n  User Engagement and Challenges", "summary": "Fake news and misinformation spread in developing countries as fast as they\ndo in developed countries with increasing penetration of the internet and\nsocial media. However, fighting misinformation is more difficult in developing\ncountries where resources and necessary technologies are scarce. This study\nprovides an understanding of the challenges various fact-checking initiatives\nface in three South Asian countries--Bangladesh, India, and Nepal. In-depth\ninterviews were conducted with senior editors of six fact-checking initiatives.\nChallenges identified include lack of resources, technologies, and political\npressure. An analysis of Facebook pages of these initiatives shows increasing\nuser engagement with their posts.", "author": [{"name": "Md Mahfuzul Haque"}, {"name": "Mohammad Yousuf"}, {"name": "Zahedur Arman"}, {"name": "Md Main Uddin Rony"}, {"name": "Ahmed Shatil Alam"}, {"name": "Kazi Mehedi Hasan"}, {"name": "Md Khadimul Islam"}, {"name": "Naeemul Hassan"}], "link": [{"@href": "http://arxiv.org/abs/1811.01806v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.01806v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1710.00341v1", "updated": "2017-10-01T12:54:50Z", "published": "2017-10-01T12:54:50Z", "title": "Fully Automated Fact Checking Using External Sources", "summary": "Given the constantly growing proliferation of false claims online in recent\nyears, there has been also a growing research interest in automatically\ndistinguishing false rumors from factually true claims. Here, we propose a\ngeneral-purpose framework for fully-automatic fact checking using external\nsources, tapping the potential of the entire Web as a knowledge source to\nconfirm or reject a claim. Our framework uses a deep neural network with LSTM\ntext encoding to combine semantic kernels with task-specific embeddings that\nencode a claim together with pieces of potentially-relevant text fragments from\nthe Web, taking the source reliability into account. The evaluation results\nshow good performance on two different tasks and datasets: (i) rumor detection\nand (ii) fact checking of the answers to a question in community question\nanswering forums.", "author": [{"name": "Georgi Karadzhov"}, {"name": "Preslav Nakov"}, {"name": "Lluis Marquez"}, {"name": "Alberto Barron-Cedeno"}, {"name": "Ivan Koychev"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RANLP-2017"}, "link": [{"@href": "http://arxiv.org/abs/1710.00341v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1710.00341v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1804.07587v1", "updated": "2018-04-20T13:00:58Z", "published": "2018-04-20T13:00:58Z", "title": "ClaimRank: Detecting Check-Worthy Claims in Arabic and English", "summary": "We present ClaimRank, an online system for detecting check-worthy claims.\nWhile originally trained on political debates, the system can work for any kind\nof text, e.g., interviews or regular news articles. Its aim is to facilitate\nmanual fact-checking efforts by prioritizing the claims that fact-checkers\nshould consider first. ClaimRank supports both Arabic and English, it is\ntrained on actual annotations from nine reputable fact-checking organizations\n(PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and\nWashington Post), and thus it can mimic the claim selection strategies for each\nand any of them, as well as for the union of them all.", "author": [{"name": "Israa Jaradat"}, {"name": "Pepa Gencheva"}, {"name": "Alberto Barron-Cedeno"}, {"name": "Lluis Marquez"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Check-worthiness; Fact-Checking; Veracity; Community-Question\n  Answering; Neural Networks; Arabic; English"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NAACL-2018"}, "link": [{"@href": "http://arxiv.org/abs/1804.07587v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.07587v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.01727v1", "updated": "2019-05-25T16:46:49Z", "published": "2019-05-25T16:46:49Z", "title": "SemEval-2019 Task 8: Fact Checking in Community Question Answering\n  Forums", "summary": "We present SemEval-2019 Task 8 on Fact Checking in Community Question\nAnswering Forums, which features two subtasks. Subtask A is about deciding\nwhether a question asks for factual information vs. an opinion/advice vs. just\nsocializing. Subtask B asks to predict whether an answer to a factual question\nis true, false or not a proper answer. We received 17 official submissions for\nsubtask A and 11 official submissions for Subtask B. For subtask A, all systems\nimproved over the majority class baseline. For Subtask B, all systems were\nbelow a majority class baseline, but several systems were very close to it. The\nleaderboard and the data from the competition can be found at\nhttp://competitions.codalab.org/competitions/20022", "author": [{"name": "Tsvetomila Mihaylova", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Instituto de Telecomunica\u00e7\u00f5es, Lisbon, Portugal"}}, {"name": "Georgi Karadjov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SiteGround Hosting EOOD, Bulgaria"}}, {"name": "Pepa Atanasova", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "University of Copenhagen, Denmark"}}, {"name": "Ramy Baly", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA"}}, {"name": "Mitra Mohtarami", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIT Computer Science and Artificial Intelligence Laboratory, Cambridge, MA"}}, {"name": "Preslav Nakov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Qatar Computing Research Institute, HBKU"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Fact checking, community question answering, community fora,\n  semeval-2019"}, "link": [{"@href": "http://arxiv.org/abs/1906.01727v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.01727v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.07912v1", "updated": "2019-08-19T19:52:50Z", "published": "2019-08-19T19:52:50Z", "title": "It Takes Nine to Smell a Rat: Neural Multi-Task Learning for\n  Check-Worthiness Prediction", "summary": "We propose a multi-task deep-learning approach for estimating the\ncheck-worthiness of claims in political debates. Given a political debate, such\nas the 2016 US Presidential and Vice-Presidential ones, the task is to predict\nwhich statements in the debate should be prioritized for fact-checking. While\ndifferent fact-checking organizations would naturally make different choices\nwhen analyzing the same debate, we show that it pays to learn from multiple\nsources simultaneously (PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago\nTribune, The Guardian, and Washington Post) in a multi-task learning setup,\neven when a particular source is chosen as a target to imitate. Our evaluation\nshows state-of-the-art results on a standard dataset for the task of\ncheck-worthiness prediction.", "author": [{"name": "Slavena Vasileva"}, {"name": "Pepa Atanasova"}, {"name": "Llu\u00eds M\u00e0rquez"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Check-worthiness; Fact-Checking; Veracity; Multi-task Learning;\n  Neural Networks. arXiv admin note: text overlap with arXiv:1908.01328"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RANLP-2019"}, "link": [{"@href": "http://arxiv.org/abs/1908.07912v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.07912v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.05773v1", "updated": "2020-04-13T05:23:25Z", "published": "2020-04-13T05:23:25Z", "title": "Generating Fact Checking Explanations", "summary": "Most existing work on automated fact checking is concerned with predicting\nthe veracity of claims based on metadata, social network spread, language used\nin claims, and, more recently, evidence supporting or denying claims. A crucial\npiece of the puzzle that is still missing is to understand how to automate the\nmost elaborate part of the process -- generating justifications for verdicts on\nclaims. This paper provides the first study of how these explanations can be\ngenerated automatically based on available claim context, and how this task can\nbe modelled jointly with veracity prediction. Our results indicate that\noptimising both objectives at the same time, rather than training them\nseparately, improves the performance of a fact checking system. The results of\na manual evaluation further suggest that the informativeness, coverage and\noverall quality of the generated explanations are also improved in the\nmulti-task model.", "author": [{"name": "Pepa Atanasova"}, {"name": "Jakob Grue Simonsen"}, {"name": "Christina Lioma"}, {"name": "Isabelle Augenstein"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Proceedings of the 2020 Annual Conference of the Association for\n  Computational Linguistics (ACL 2020)"}, "link": [{"@href": "http://arxiv.org/abs/2004.05773v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.05773v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.12864v1", "updated": "2020-04-27T15:18:49Z", "published": "2020-04-27T15:18:49Z", "title": "DeSePtion: Dual Sequence Prediction and Adversarial Examples for\n  Improved Fact-Checking", "summary": "The increased focus on misinformation has spurred development of data and\nsystems for detecting the veracity of a claim as well as retrieving\nauthoritative evidence. The Fact Extraction and VERification (FEVER) dataset\nprovides such a resource for evaluating end-to-end fact-checking, requiring\nretrieval of evidence from Wikipedia to validate a veracity prediction. We show\nthat current systems for FEVER are vulnerable to three categories of realistic\nchallenges for fact-checking -- multiple propositions, temporal reasoning, and\nambiguity and lexical variation -- and introduce a resource with these types of\nclaims. Then we present a system designed to be resilient to these \"attacks\"\nusing multiple pointer networks for document selection and jointly modeling a\nsequence of evidence sentences and veracity relation predictions. We find that\nin handling these attacks we obtain state-of-the-art results on FEVER, largely\ndue to improved evidence retrieval.", "author": [{"name": "Christopher Hidey"}, {"name": "Tuhin Chakrabarty"}, {"name": "Tariq Alhindi"}, {"name": "Siddharth Varia"}, {"name": "Kriste Krstovski"}, {"name": "Mona Diab"}, {"name": "Smaranda Muresan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL 2020"}, "link": [{"@href": "http://arxiv.org/abs/2004.12864v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.12864v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.02443v1", "updated": "2020-05-05T19:08:26Z", "published": "2020-05-05T19:08:26Z", "title": "A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian\n  and Indian Elections", "summary": "Recently, messaging applications, such as WhatsApp, have been reportedly\nabused by misinformation campaigns, especially in Brazil and India. A notable\nform of abuse in WhatsApp relies on several manipulated images and memes\ncontaining all kinds of fake stories. In this work, we performed an extensive\ndata collection from a large set of WhatsApp publicly accessible groups and\nfact-checking agency websites. This paper opens a novel dataset to the research\ncommunity containing fact-checked fake images shared through WhatsApp for two\ndistinct scenarios known for the spread of fake news on the platform: the 2018\nBrazilian elections and the 2019 Indian elections.", "author": [{"name": "Julio C. S. Reis"}, {"name": "Philipe de Freitas Melo"}, {"name": "Kiran Garimella"}, {"name": "Jussara M. Almeida"}, {"name": "Dean Eckles"}, {"name": "Fabr\u00edcio Benevenuto"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "7 pages. This is a preprint version of an accepted paper on ICWSM'20.\n  Please, consider to cite the conference version instead of this one"}, "link": [{"@href": "http://arxiv.org/abs/2005.02443v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.02443v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.13270v1", "updated": "2020-05-27T10:29:14Z", "published": "2020-05-27T10:29:14Z", "title": "BRENDA: Browser Extension for Fake News Detection", "summary": "Misinformation such as fake news has drawn a lot of attention in recent\nyears. It has serious consequences on society, politics and economy. This has\nlead to a rise of manually fact-checking websites such as Snopes and\nPolitifact. However, the scale of misinformation limits their ability for\nverification. In this demonstration, we propose BRENDA a browser extension\nwhich can be used to automate the entire process of credibility assessments of\nfalse claims. Behind the scenes BRENDA uses a tested deep neural network\narchitecture to automatically identify fact check worthy claims and classifies\nas well as presents the result along with evidence to the user. Since BRENDA is\na browser extension, it facilities fast automated fact checking for the end\nuser without having to leave the Webpage.", "author": [{"name": "Bjarte Botnevik"}, {"name": "Eirik Sakariassen"}, {"name": "Vinay Setty"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3397271.3401396"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3397271.3401396", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2005.13270v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.13270v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted as SIGIR demo"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Proceedings of the 43rd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR 2020), July 25 to\n  30, 2020, Virtual Event, China. ACM, New York, NY, USA, 4 pages"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.08854v1", "updated": "2020-08-20T09:30:05Z", "published": "2020-08-20T09:30:05Z", "title": "Checkworthiness in Automatic Claim Detection Models: Definitions and\n  Analysis of Datasets", "summary": "Public, professional and academic interest in automated fact-checking has\ndrastically increased over the past decade, with many aiming to automate one of\nthe first steps in a fact-check procedure: the selection of so-called\ncheckworthy claims. However, there is little agreement on the definition and\ncharacteristics of checkworthiness among fact-checkers, which is consequently\nreflected in the datasets used for training and testing checkworthy claim\ndetection models. After elaborate analysis of checkworthy claim selection\nprocedures in fact-check organisations and analysis of state-of-the-art claim\ndetection datasets, checkworthiness is defined as the concept of having a\nspatiotemporal and context-dependent worth and need to have the correctness of\nthe objectivity it conveys verified. This is irrespective of the claim's\nperceived veracity judgement by an individual based on prior knowledge and\nbeliefs. Concerning the characteristics of current datasets, it is argued that\nthe data is not only highly imbalanced and noisy, but also too limited in scope\nand language. Furthermore, we believe that the subjective concept of\ncheckworthiness might not be a suitable filter for claim detection.", "author": [{"name": "Liesbeth Allein"}, {"name": "Marie-Francine Moens"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-61841-4_1"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-61841-4_1", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.08854v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.08854v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2009.06401v3", "updated": "2021-06-01T14:06:14Z", "published": "2020-09-10T13:54:15Z", "title": "Multi-Hop Fact Checking of Political Claims", "summary": "Recent work has proposed multi-hop models and datasets for studying complex\nnatural language reasoning. One notable task requiring multi-hop reasoning is\nfact checking, where a set of connected evidence pieces leads to the final\nverdict of a claim. However, existing datasets either do not provide\nannotations for gold evidence pages, or the only dataset which does (FEVER)\nmostly consists of claims which can be fact-checked with simple reasoning and\nis constructed artificially. Here, we study more complex claim verification of\nnaturally occurring claims with multiple hops over interconnected evidence\nchunks. We: 1) construct a small annotated dataset, PolitiHop, of evidence\nsentences for claim verification; 2) compare it to existing multi-hop datasets;\nand 3) study how to transfer knowledge from more extensive in- and\nout-of-domain resources to PolitiHop. We find that the task is complex and\nachieve the best performance with an architecture that specifically models\nreasoning over evidence pieces in combination with in-domain transfer learning.", "author": [{"name": "Wojciech Ostrowski"}, {"name": "Arnav Arora"}, {"name": "Pepa Atanasova"}, {"name": "Isabelle Augenstein"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, to be published at Proceedings of IJCAI-2021"}, "link": [{"@href": "http://arxiv.org/abs/2009.06401v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.06401v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T07, 68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.06402v3", "updated": "2021-07-30T12:24:13Z", "published": "2020-09-10T13:39:49Z", "title": "Time-Aware Evidence Ranking for Fact-Checking", "summary": "Truth can vary over time. Fact-checking decisions on claim veracity should\ntherefore take into account temporal information of both the claim and\nsupporting or refuting evidence. In this work, we investigate the hypothesis\nthat the timestamp of a Web page is crucial to how it should be ranked for a\ngiven claim. We delineate four temporal ranking methods that constrain evidence\nranking differently and simulate hypothesis-specific evidence rankings given\nthe evidence timestamps as gold standard. Evidence ranking in three\nfact-checking models is ultimately optimized using a learning-to-rank loss\nfunction. Our study reveals that time-aware evidence ranking not only surpasses\nrelevance assumptions based purely on semantic similarity or position in a\nsearch results list, but also improves veracity predictions of time-sensitive\nclaims in particular.", "author": [{"name": "Liesbeth Allein"}, {"name": "Isabelle Augenstein"}, {"name": "Marie-Francine Moens"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages"}, "link": [{"@href": "http://arxiv.org/abs/2009.06402v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.06402v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.08205v1", "updated": "2020-09-17T10:50:42Z", "published": "2020-09-17T10:50:42Z", "title": "Generating Label Cohesive and Well-Formed Adversarial Claims", "summary": "Adversarial attacks reveal important vulnerabilities and flaws of trained\nmodels. One potent type of attack are universal adversarial triggers, which are\nindividual n-grams that, when appended to instances of a class under attack,\ncan trick a model into predicting a target class. However, for inference tasks\nsuch as fact checking, these triggers often inadvertently invert the meaning of\ninstances they are inserted in. In addition, such attacks produce semantically\nnonsensical inputs, as they simply concatenate triggers to existing samples.\nHere, we investigate how to generate adversarial attacks against fact checking\nsystems that preserve the ground truth meaning and are semantically valid. We\nextend the HotFlip attack algorithm used for universal trigger generation by\njointly minimising the target class loss of a fact checking model and the\nentailment class loss of an auxiliary natural language inference model. We then\ntrain a conditional language model to generate semantically valid statements,\nwhich include the found universal triggers. We find that the generated attacks\nmaintain the directionality and semantic validity of the claim better than\nprevious work.", "author": [{"name": "Pepa Atanasova"}, {"name": "Dustin Wright"}, {"name": "Isabelle Augenstein"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 1 figure, 4 tables"}, "link": [{"@href": "http://arxiv.org/abs/2009.08205v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.08205v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.13387v2", "updated": "2021-07-10T06:08:44Z", "published": "2020-10-26T07:33:28Z", "title": "Check Mate: Prioritizing User Generated Multi-Media Content for\n  Fact-Checking", "summary": "Volume of content and misinformation on social media is rapidly increasing.\nThere is a need for systems that can support fact checkers by prioritizing\ncontent that needs to be fact checked. Prior research on prioritizing content\nfor fact-checking has focused on news media articles, predominantly in English\nlanguage. Increasingly, misinformation is found in user-generated content. In\nthis paper we present a novel dataset that can be used to prioritize\ncheck-worthy posts from multi-media content in Hindi. It is unique in its 1)\nfocus on user generated content, 2) language and 3) accommodation of\nmulti-modality in social media posts. In addition, we also provide metadata for\neach post such as number of shares and likes of the post on ShareChat, a\npopular Indian social media platform, that allows for correlative analysis\naround virality and misinformation. The data is accessible on Zenodo\n(https://zenodo.org/record/4032629) under Creative Commons Attribution License\n(CC BY 4.0).", "author": [{"name": "Tarunima Prabhakar"}, {"name": "Anushree Gupta"}, {"name": "Kruttika Nadig"}, {"name": "Denny George"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 13 figures, 2 tables"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the International AAAI Conference on Web and Social\n  Media, Volume 15(1), 2021"}, "link": [{"@href": "http://arxiv.org/abs/2010.13387v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.13387v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.08028v1", "updated": "2020-11-16T15:27:38Z", "published": "2020-11-16T15:27:38Z", "title": "Fact Checking via Path Embedding and Aggregation", "summary": "Knowledge graphs (KGs) are a useful source of background knowledge to\n(dis)prove facts of the form (s, p, o). Finding paths between s and o is the\ncornerstone of several fact-checking approaches. While paths are useful to\n(visually) explain why a given fact is true or false, it is not completely\nclear how to identify paths that are most relevant to a fact, encode them and\nweigh their importance. The goal of this paper is to present the Fact Checking\nvia path Embedding and Aggregation (FEA) system. FEA starts by carefully\ncollecting the paths between s and o that are most semantically related to the\ndomain of p. However, instead of directly working with this subset of all\npaths, it learns vectorized path representations, aggregates them according to\ndifferent strategies, and use them to finally (dis)prove a fact. We conducted a\nlarge set of experiments on a variety of KGs and found that our hybrid solution\nbrings some benefits in terms of performance.", "author": {"name": "Giuseppe Pirr\u00f2"}, "link": [{"@href": "http://arxiv.org/abs/2011.08028v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.08028v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2105.00826v1", "updated": "2021-04-16T12:23:56Z", "published": "2021-04-16T12:23:56Z", "title": "WhatTheWikiFact: Fact-Checking Claims Against Wikipedia", "summary": "The rise of Internet has made it a major source of information.\nUnfortunately, not all information online is true, and thus a number of\nfact-checking initiatives have been launched, both manual and automatic. Here,\nwe present our contribution in this regard: WhatTheWikiFact, a system for\nautomatic claim verification using Wikipedia. The system predicts the veracity\nof an input claim, and it further shows the evidence it has retrieved as part\nof the verification process. It shows confidence scores and a list of relevant\nWikipedia articles, together with detailed information about each article,\nincluding the phrase used to retrieve it, the most relevant sentences it\ncontains, and their stances with respect to the input claim, with associated\nprobabilities.", "author": [{"name": "Anton Chernyavskiy"}, {"name": "Dmitry Ilvovsky"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "fact-checking, veracity, factuality, stance detection, evidence\n  retrieval, fake news, FEVER, Wikipedia"}, "link": [{"@href": "http://arxiv.org/abs/2105.00826v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.00826v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.04726v2", "updated": "2021-07-23T17:49:31Z", "published": "2021-06-08T23:08:47Z", "title": "Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study\n  of the 2019 Indian Election on WhatsApp", "summary": "There is currently no easy way to fact-check content on WhatsApp and other\nend-to-end encrypted platforms at scale. In this paper, we analyze the\nusefulness of a crowd-sourced \"tipline\" through which users can submit content\n(\"tips\") that they want fact-checked. We compare the tips sent to a WhatsApp\ntipline run during the 2019 Indian national elections with the messages\ncirculating in large, public groups on WhatsApp and other social media\nplatforms during the same period. We find that tiplines are a very useful lens\ninto WhatsApp conversations: a significant fraction of messages and images sent\nto the tipline match with the content being shared on public WhatsApp groups\nand other social media. Our analysis also shows that tiplines cover the most\npopular content well, and a majority of such content is often shared to the\ntipline before appearing in large, public WhatsApp groups. Overall, our\nfindings suggest tiplines can be an effective source for discovering content to\nfact-check.", "author": [{"name": "Ashkan Kazemi"}, {"name": "Kiran Garimella"}, {"name": "Gautam Kishore Shahi"}, {"name": "Devin Gaffney"}, {"name": "Scott A. Hale"}], "link": [{"@href": "http://arxiv.org/abs/2106.04726v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.04726v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.09248v1", "updated": "2021-06-17T05:09:54Z", "published": "2021-06-17T05:09:54Z", "title": "X-FACT: A New Benchmark Dataset for Multilingual Fact Checking", "summary": "In this work, we introduce X-FACT: the largest publicly available\nmultilingual dataset for factual verification of naturally existing real-world\nclaims. The dataset contains short statements in 25 languages and is labeled\nfor veracity by expert fact-checkers. The dataset includes a multilingual\nevaluation benchmark that measures both out-of-domain generalization, and\nzero-shot capabilities of the multilingual models. Using state-of-the-art\nmultilingual transformer-based models, we develop several automated\nfact-checking models that, along with textual claims, make use of additional\nmetadata and evidence from news stories retrieved using a search engine.\nEmpirically, our best model attains an F-score of around 40%, suggesting that\nour dataset is a challenging benchmark for evaluation of multilingual\nfact-checking models.", "author": [{"name": "Ashim Gupta"}, {"name": "Vivek Srikumar"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL 2021; For data and code, see https://github.com/utahnlp/x-fact/"}, "link": [{"@href": "http://arxiv.org/abs/2106.09248v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.09248v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.05016v1", "updated": "2021-07-11T10:42:58Z", "published": "2021-07-11T10:42:58Z", "title": "Combating fake news by empowering fact-checked news spread via\n  topology-based interventions", "summary": "Rapid information diffusion and large-scaled information cascades can enable\nthe undesired spread of false information. A small-scaled false information\noutbreak may potentially lead to an infodemic. We propose a novel information\ndiffusion and intervention technique to combat the spread of false news. As\nfalse information is often spreading faster in a social network, the proposed\ndiffusion methodology inhibits the spread of false news by proactively\ndiffusing the fact-checked information. Our methodology mainly relies on\ndefining the potential super-spreaders in a social network based on their\ncentrality metrics. We run an extensive set of experiments on different\nnetworks to investigate the impact of centrality metrics on the performance of\nthe proposed diffusion and intervention models. The obtained results\ndemonstrate that empowering the diffusion of fact-checked news combats the\nspread of false news further and deeper in social networks.", "author": [{"name": "Ke Wang"}, {"name": "Waheeb Yaqub"}, {"name": "Abdallah Lakhdari"}, {"name": "Basem Suleiman"}], "link": [{"@href": "http://arxiv.org/abs/2107.05016v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.05016v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.09918v1", "updated": "2017-11-27T19:00:08Z", "published": "2017-11-27T19:00:08Z", "title": "Leveraging the Crowd to Detect and Reduce the Spread of Fake News and\n  Misinformation", "summary": "Online social networking sites are experimenting with the following\ncrowd-powered procedure to reduce the spread of fake news and misinformation:\nwhenever a user is exposed to a story through her feed, she can flag the story\nas misinformation and, if the story receives enough flags, it is sent to a\ntrusted third party for fact checking. If this party identifies the story as\nmisinformation, it is marked as disputed. However, given the uncertain number\nof exposures, the high cost of fact checking, and the trade-off between flags\nand exposures, the above mentioned procedure requires careful reasoning and\nsmart algorithms which, to the best of our knowledge, do not exist to date.\n  In this paper, we first introduce a flexible representation of the above\nprocedure using the framework of marked temporal point processes. Then, we\ndevelop a scalable online algorithm, Curb, to select which stories to send for\nfact checking and when to do so to efficiently reduce the spread of\nmisinformation with provable guarantees. In doing so, we need to solve a novel\nstochastic optimal control problem for stochastic differential equations with\njumps, which is of independent interest. Experiments on two real-world datasets\ngathered from Twitter and Weibo show that our algorithm may be able to\neffectively reduce the spread of fake news and misinformation.", "author": [{"name": "Jooyeon Kim"}, {"name": "Behzad Tabibian"}, {"name": "Alice Oh"}, {"name": "Bernhard Schoelkopf"}, {"name": "Manuel Gomez-Rodriguez"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear at the 11th ACM International Conference on Web Search and\n  Data Mining (WSDM 2018)"}, "link": [{"@href": "http://arxiv.org/abs/1711.09918v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.09918v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1808.05542v1", "updated": "2018-08-08T12:51:21Z", "published": "2018-08-08T12:51:21Z", "title": "Overview of the CLEF-2018 CheckThat! Lab on Automatic Identification and\n  Verification of Political Claims. Task 1: Check-Worthiness", "summary": "We present an overview of the CLEF-2018 CheckThat! Lab on Automatic\nIdentification and Verification of Political Claims, with focus on Task 1:\nCheck-Worthiness. The task asks to predict which claims in a political debate\nshould be prioritized for fact-checking. In particular, given a debate or a\npolitical speech, the goal was to produce a ranked list of its sentences based\non their worthiness for fact checking. We offered the task in both English and\nArabic, based on debates from the 2016 US Presidential Campaign, as well as on\nsome speeches during and after the campaign. A total of 30 teams registered to\nparticipate in the Lab and seven teams actually submitted systems for Task~1.\nThe most successful approaches used by the participants relied on recurrent and\nmulti-layer neural networks, as well as on combinations of distributional\nrepresentations, on matchings claims' vocabulary against lexicons, and on\nmeasures of syntactic dependency. The best systems achieved mean average\nprecision of 0.18 and 0.15 on the English and on the Arabic test datasets,\nrespectively. This leaves large room for further improvement, and thus we\nrelease all datasets and the scoring scripts, which should enable further\nresearch in check-worthiness estimation.", "author": [{"name": "Pepa Atanasova"}, {"name": "Alberto Barron-Cedeno"}, {"name": "Tamer Elsayed"}, {"name": "Reem Suwaileh"}, {"name": "Wajdi Zaghouani"}, {"name": "Spas Kyuchukov"}, {"name": "Giovanni Da San Martino"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Computational journalism, Check-worthiness, Fact-checking, Veracity"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF-2018"}, "link": [{"@href": "http://arxiv.org/abs/1808.05542v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.05542v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1902.11116v1", "updated": "2019-02-28T14:50:59Z", "published": "2019-02-28T14:50:59Z", "title": "Citation Needed: A Taxonomy and Algorithmic Assessment of Wikipedia's\n  Verifiability", "summary": "Wikipedia is playing an increasingly central role on the web,and the policies\nits contributors follow when sourcing and fact-checking content affect million\nof readers. Among these core guiding principles, verifiability policies have a\nparticularly important role. Verifiability requires that information included\nin a Wikipedia article be corroborated against reliable secondary sources.\nBecause of the manual labor needed to curate and fact-check Wikipedia at scale,\nhowever, its contents do not always evenly comply with these policies.\nCitations (i.e. reference to external sources) may not conform to verifiability\nrequirements or may be missing altogether, potentially weakening the\nreliability of specific topic areas of the free encyclopedia. In this paper, we\naim to provide an empirical characterization of the reasons why and how\nWikipedia cites external sources to comply with its own verifiability\nguidelines. First, we construct a taxonomy of reasons why inline citations are\nrequired by collecting labeled data from editors of multiple Wikipedia language\neditions. We then collect a large-scale crowdsourced dataset of Wikipedia\nsentences annotated with categories derived from this taxonomy. Finally, we\ndesign and evaluate algorithmic models to determine if a statement requires a\ncitation, and to predict the citation reason based on our taxonomy. We evaluate\nthe robustness of such models across different classes of Wikipedia articles of\nvarying quality, as well as on an additional dataset of claims annotated for\nfact-checking purposes.", "author": [{"name": "Miriam Redi"}, {"name": "Besnik Fetahu"}, {"name": "Jonathan Morgan"}, {"name": "Dario Taraborelli"}], "link": [{"@href": "http://arxiv.org/abs/1902.11116v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.11116v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1903.08404v1", "updated": "2019-03-20T09:40:19Z", "published": "2019-03-20T09:40:19Z", "title": "Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking", "summary": "Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.", "author": [{"name": "Casper Hansen"}, {"name": "Christian Hansen"}, {"name": "Stephen Alstrup"}, {"name": "Jakob Grue Simonsen"}, {"name": "Christina Lioma"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Companion Proceedings of the 2019 World Wide Web Conference"}, "link": [{"@href": "http://arxiv.org/abs/1903.08404v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.08404v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.03745v3", "updated": "2020-04-25T06:48:06Z", "published": "2019-09-09T10:34:09Z", "title": "Reasoning Over Semantic-Level Graph for Fact Checking", "summary": "Fact checking is a challenging task because verifying the truthfulness of a\nclaim requires reasoning about multiple retrievable evidence. In this work, we\npresent a method suitable for reasoning about the semantic-level structure of\nevidence. Unlike most previous works, which typically represent evidence\nsentences with either string concatenation or fusing the features of isolated\nevidence sentences, our approach operates on rich semantic structures of\nevidence obtained by semantic role labeling. We propose two mechanisms to\nexploit the structure of evidence while leveraging the advances of pre-trained\nmodels like BERT, GPT or XLNet. Specifically, using XLNet as the backbone, we\nfirst utilize the graph structure to re-define the relative distances of words,\nwith the intuition that semantically related words should have short distances.\nThen, we adopt graph convolutional network and graph attention network to\npropagate and aggregate information from neighboring nodes on the graph. We\nevaluate our system on FEVER, a benchmark dataset for fact checking, and find\nthat rich structural information is helpful and both our graph-based mechanisms\nimprove the accuracy. Our model is the state-of-the-art system in terms of both\nofficial evaluation metrics, namely claim verification accuracy and FEVER\nscore.", "author": [{"name": "Wanjun Zhong"}, {"name": "Jingjing Xu"}, {"name": "Duyu Tang"}, {"name": "Zenan Xu"}, {"name": "Nan Duan"}, {"name": "Ming Zhou"}, {"name": "Jiahai Wang"}, {"name": "Jian Yin"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9pages"}, "link": [{"@href": "http://arxiv.org/abs/1909.03745v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.03745v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.08546v1", "updated": "2020-01-21T06:47:11Z", "published": "2020-01-21T06:47:11Z", "title": "CheckThat! at CLEF 2020: Enabling the Automatic Identification and\n  Verification of Claims in Social Media", "summary": "We describe the third edition of the CheckThat! Lab, which is part of the\n2020 Cross-Language Evaluation Forum (CLEF). CheckThat! proposes four\ncomplementary tasks and a related task from previous lab editions, offered in\nEnglish, Arabic, and Spanish. Task 1 asks to predict which tweets in a Twitter\nstream are worth fact-checking. Task 2 asks to determine whether a claim posted\nin a tweet can be verified using a set of previously fact-checked claims. Task\n3 asks to retrieve text snippets from a given set of Web pages that would be\nuseful for verifying a target tweet's claim. Task 4 asks to predict the\nveracity of a target tweet's claim using a set of Web pages and potentially\nuseful snippets in them. Finally, the lab offers a fifth task that asks to\npredict the check-worthiness of the claims made in English political debates\nand speeches. CheckThat! features a full evaluation framework. The evaluation\nis carried out using mean average precision or precision at rank k for ranking\ntasks, and F1 for classification tasks.", "author": [{"name": "Alberto Barron-Cedeno"}, {"name": "Tamer Elsayed"}, {"name": "Preslav Nakov"}, {"name": "Giovanni Da San Martino"}, {"name": "Maram Hasanain"}, {"name": "Reem Suwaileh"}, {"name": "Fatima Haouari"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Computational journalism, Check-worthiness, Fact-checking, Veracity,\n  CLEF-2020 CheckThat! Lab"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF-2018 ECIR-2020"}, "link": [{"@href": "http://arxiv.org/abs/2001.08546v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.08546v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.07997v1", "updated": "2020-07-15T21:19:32Z", "published": "2020-07-15T21:19:32Z", "title": "Overview of CheckThat! 2020: Automatic Identification and Verification\n  of Claims in Social Media", "summary": "We present an overview of the third edition of the CheckThat! Lab at CLEF\n2020. The lab featured five tasks in two different languages: English and\nArabic. The first four tasks compose the full pipeline of claim verification in\nsocial media: Task 1 on check-worthiness estimation, Task 2 on retrieving\npreviously fact-checked claims, Task 3 on evidence retrieval, and Task 4 on\nclaim verification. The lab is completed with Task 5 on check-worthiness\nestimation in political debates and speeches. A total of 67 teams registered to\nparticipate in the lab (up from 47 at CLEF 2019), and 23 of them actually\nsubmitted runs (compared to 14 at CLEF 2019). Most teams used deep neural\nnetworks based on BERT, LSTMs, or CNNs, and achieved sizable improvements over\nthe baselines on all tasks. Here we describe the tasks setup, the evaluation\nresults, and a summary of the approaches used by the participants, and we\ndiscuss some lessons learned. Last but not least, we release to the research\ncommunity all datasets from the lab as well as the evaluation scripts, which\nshould enable further research in the important tasks of check-worthiness\nestimation and automatic claim verification.", "author": [{"name": "Alberto Barron-Cedeno"}, {"name": "Tamer Elsayed"}, {"name": "Preslav Nakov"}, {"name": "Giovanni Da San Martino"}, {"name": "Maram Hasanain"}, {"name": "Reem Suwaileh"}, {"name": "Fatima Haouari"}, {"name": "Nikolay Babulkov"}, {"name": "Bayan Hamdan"}, {"name": "Alex Nikolov"}, {"name": "Shaden Shaar"}, {"name": "Zien Sheikh Ali"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Check-Worthiness Estimation, Fact-Checking, Veracity, Evidence-based\n  Verification, Detecting Previously Fact-Checked Claims, Social Media\n  Verification, Computational Journalism, COVID-19"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF-2020"}, "link": [{"@href": "http://arxiv.org/abs/2007.07997v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.07997v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.11276v1", "updated": "2021-02-23T16:47:41Z", "published": "2021-02-23T16:47:41Z", "title": "Factorization of Fact-Checks for Low Resource Indian Languages", "summary": "The advancement in technology and accessibility of internet to each\nindividual is revolutionizing the real time information. The liberty to express\nyour thoughts without passing through any credibility check is leading to\ndissemination of fake content in the ecosystem. It can have disastrous effects\non both individuals and society as a whole. The amplification of fake news is\nbecoming rampant in India too. Debunked information often gets republished with\na replacement description, claiming it to depict some different incidence. To\ncurb such fabricated stories, it is necessary to investigate such deduplicates\nand false claims made in public. The majority of studies on automatic\nfact-checking and fake news detection is restricted to English only. But for a\ncountry like India where only 10% of the literate population speak English,\nrole of regional languages in spreading falsity cannot be undermined. In this\npaper, we introduce FactDRIL: the first large scale multilingual Fact-checking\nDataset for Regional Indian Languages. We collect an exhaustive dataset across\n7 months covering 11 low-resource languages. Our propose dataset consists of\n9,058 samples belonging to English, 5,155 samples to Hindi and remaining 8,222\nsamples are distributed across various regional languages, i.e. Bangla,\nMarathi, Malayalam, Telugu, Tamil, Oriya, Assamese, Punjabi, Urdu, Sinhala and\nBurmese. We also present the detailed characterization of three M's\n(multi-lingual, multi-media, multi-domain) in the FactDRIL accompanied with the\ncomplete list of other varied attributes making it a unique dataset to study.\nLastly, we present some potential use cases of the dataset. We expect this\ndataset will be a valuable resource and serve as a starting point to fight\nproliferation of fake news in low resource languages.", "author": [{"name": "Shivangi Singhal"}, {"name": "Rajiv Ratn Shah"}, {"name": "Ponnurangam Kumaraguru"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/2102.11276v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.11276v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.12506v1", "updated": "2021-03-16T11:11:54Z", "published": "2021-03-16T11:11:54Z", "title": "A Survey on Predicting the Factuality and the Bias of News Media", "summary": "The present level of proliferation of fake, biased, and propagandistic\ncontent online has made it impossible to fact-check every single suspicious\nclaim or article, either manually or automatically. Thus, many researchers are\nshifting their attention to higher granularity, aiming to profile entire news\noutlets, which makes it possible to detect likely \"fake news\" the moment it is\npublished, by simply checking the reliability of its source. Source factuality\nis also an important element of systems for automatic fact-checking and \"fake\nnews\" detection, as they need to assess the reliability of the evidence they\nretrieve online. Political bias detection, which in the Western political\nlandscape is about predicting left-center-right bias, is an equally important\ntopic, which has experienced a similar shift towards profiling entire news\noutlets. Moreover, there is a clear connection between the two, as highly\nbiased media are less likely to be factual; yet, the two problems have been\naddressed separately. In this survey, we review the state of the art on media\nprofiling for factuality and bias, arguing for the need to model them jointly.\nWe further discuss interesting recent advances in using different information\nsources and modalities, which go beyond the text of the articles the target\nnews outlet has published. Finally, we discuss current challenges and outline\nfuture research directions.", "author": [{"name": "Preslav Nakov"}, {"name": "Husrev Taha Sencar"}, {"name": "Jisun An"}, {"name": "Haewoon Kwak"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "factuality of reporting, fact-checking, political ideology, media\n  bias, disinformation, propaganda, social media, news media"}, "link": [{"@href": "http://arxiv.org/abs/2103.12506v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.12506v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.02153v1", "updated": "2021-07-05T17:31:44Z", "published": "2021-07-05T17:31:44Z", "title": "FaVIQ: FAct Verification from Information-seeking Questions", "summary": "Despite significant interest in developing general purpose fact checking\nmodels, it is challenging to construct a large-scale fact verification dataset\nwith realistic claims that would occur in the real world. Existing claims are\neither authored by crowdworkers, thereby introducing subtle biases that are\ndifficult to control for, or manually verified by professional fact checkers,\ncausing them to be expensive and limited in scale. In this paper, we construct\na challenging, realistic, and large-scale fact verification dataset called\nFaVIQ, using information-seeking questions posed by real users who do not know\nhow to answer. The ambiguity in information-seeking questions enables\nautomatically constructing true and false claims that reflect confusions arisen\nfrom users (e.g., the year of the movie being filmed vs. being released). Our\nclaims are verified to be natural, contain little lexical bias, and require a\ncomplete understanding of the evidence for verification. Our experiments show\nthat the state-of-the-art models are far from solving our new task. Moreover,\ntraining on our data helps in professional fact-checking, outperforming models\ntrained on the most widely used dataset FEVER or in-domain data by up to 17%\nabsolute. Altogether, our data will serve as a challenging benchmark for\nnatural language understanding and support future progress in professional fact\nchecking.", "author": [{"name": "Jungsoo Park"}, {"name": "Sewon Min"}, {"name": "Jaewoo Kang"}, {"name": "Luke Zettlemoyer"}, {"name": "Hannaneh Hajishirzi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages, 3 figures; Data & Code available at https://faviq.github.io"}, "link": [{"@href": "http://arxiv.org/abs/2107.02153v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.02153v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1810.01765v1", "updated": "2018-10-02T03:27:04Z", "published": "2018-10-02T03:27:04Z", "title": "Predicting Factuality of Reporting and Bias of News Media Sources", "summary": "We present a study on predicting the factuality of reporting and bias of news\nmedia. While previous work has focused on studying the veracity of claims or\ndocuments, here we are interested in characterizing entire news media. These\nare under-studied but arguably important research problems, both in their own\nright and as a prior for fact-checking systems. We experiment with a large list\nof news websites and with a rich set of features derived from (i) a sample of\narticles from the target news medium, (ii) its Wikipedia page, (iii) its\nTwitter account, (iv) the structure of its URL, and (v) information about the\nWeb traffic it attracts. The experimental results show sizable performance\ngains over the baselines, and confirm the importance of each feature type.", "author": [{"name": "Ramy Baly", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIT Computer Science and Artificial Intelligence Laboratory"}}, {"name": "Georgi Karadzhov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Sofia University, Bulgaria"}}, {"name": "Dimitar Alexandrov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Sofia University, Bulgaria"}}, {"name": "James Glass", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIT Computer Science and Artificial Intelligence Laboratory"}}, {"name": "Preslav Nakov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Qatar Computing Research Institute, HBKU, Qatar"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Fact-checking, political ideology, news media, EMNLP-2018"}, "link": [{"@href": "http://arxiv.org/abs/1810.01765v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1810.01765v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.07154v1", "updated": "2019-10-16T03:34:34Z", "published": "2019-10-16T03:34:34Z", "title": "Unsupervised Question Answering for Fact-Checking", "summary": "Recent Deep Learning (DL) models have succeeded in achieving human-level\naccuracy on various natural language tasks such as question-answering, natural\nlanguage inference (NLI), and textual entailment. These tasks not only require\nthe contextual knowledge but also the reasoning abilities to be solved\nefficiently. In this paper, we propose an unsupervised question-answering based\napproach for a similar task, fact-checking. We transform the FEVER dataset into\na Cloze-task by masking named entities provided in the claims. To predict the\nanswer token, we utilize pre-trained Bidirectional Encoder Representations from\nTransformers (BERT). The classifier computes label based on the correctly\nanswered questions and a threshold. Currently, the classifier is able to\nclassify the claims as \"SUPPORTS\" and \"MANUAL_REVIEW\". This approach achieves a\nlabel accuracy of 80.2% on the development set and 80.25% on the test set of\nthe transformed dataset.", "author": {"name": "Mayank Jobanputra"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "FEVER - 19 (EMNLP)"}, "link": [{"@href": "http://arxiv.org/abs/1910.07154v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.07154v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1910.09516v3", "updated": "2020-05-06T13:25:07Z", "published": "2019-10-21T17:14:52Z", "title": "Reversible bootstrap percolation: Fake news and fact checking", "summary": "Bootstrap percolation has been used to describe opinion formation in society\nand other social and natural phenomena. The formal equation of the bootstrap\npercolation may have more than one solution, corresponding to several stable\nfixed points of the corresponding iteration process. We construct a reversible\nbootstrap percolation process, which converges to these extra solutions\ndisplaying a hysteresis typical of discontinuous phase transitions. This\nprocess provides a reasonable model for fake news spreading and the\neffectiveness of fact checking. We show that sometimes it is not sufficient to\ndiscard all the sources of fake news in order to reverse the belief of a\npopulation that formed under the influence of these sources.", "author": [{"name": "M. A. Di Muro"}, {"name": "S. V. Buldyrev"}, {"name": "L. A. Braunstein"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevE.101.042307"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevE.101.042307", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1910.09516v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.09516v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys. Rev. E 101, 042307 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1803.03178v1", "updated": "2018-03-08T16:06:54Z", "published": "2018-03-08T16:06:54Z", "title": "Fact Checking in Community Forums", "summary": "Community Question Answering (cQA) forums are very popular nowadays, as they\nrepresent effective means for communities around particular topics to share\ninformation. Unfortunately, this information is not always factual. Thus, here\nwe explore a new dimension in the context of cQA, which has been ignored so\nfar: checking the veracity of answers to particular questions in cQA forums. As\nthis is a new problem, we create a specialized dataset for it. We further\npropose a novel multi-faceted model, which captures information from the answer\ncontent (what is said and how), from the author profile (who says it), from the\nrest of the community forum (where it is said), and from external authoritative\nsources of information (external support). Evaluation results show a MAP value\nof 86.54, which is 21 points absolute above the baseline.", "author": [{"name": "Tsvetomila Mihaylova"}, {"name": "Preslav Nakov"}, {"name": "Lluis Marquez"}, {"name": "Alberto Barron-Cedeno"}, {"name": "Mitra Mohtarami"}, {"name": "Georgi Karadzhov"}, {"name": "James Glass"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AAAI-2018; Fact-Checking; Veracity; Community-Question Answering;\n  Neural Networks; Distributed Representations"}, "link": [{"@href": "http://arxiv.org/abs/1803.03178v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1803.03178v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1901.09657v1", "updated": "2019-01-05T11:56:13Z", "published": "2019-01-05T11:56:13Z", "title": "Fake News Detection via NLP is Vulnerable to Adversarial Attacks", "summary": "News plays a significant role in shaping people's beliefs and opinions. Fake\nnews has always been a problem, which wasn't exposed to the mass public until\nthe past election cycle for the 45th President of the United States. While\nquite a few detection methods have been proposed to combat fake news since\n2015, they focus mainly on linguistic aspects of an article without any fact\nchecking. In this paper, we argue that these models have the potential to\nmisclassify fact-tampering fake news as well as under-written real news.\nThrough experiments on Fakebox, a state-of-the-art fake news detector, we show\nthat fact tampering attacks can be effective. To address these weaknesses, we\nargue that fact checking should be adopted in conjunction with linguistic\ncharacteristics analysis, so as to truly separate fake news from real news. A\ncrowdsourced knowledge graph is proposed as a straw man solution to collecting\ntimely facts about news events.", "author": [{"name": "Zhixuan Zhou"}, {"name": "Huankang Guan"}, {"name": "Meghana Moorthy Bhat"}, {"name": "Justin Hsu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.5220/0007566307940800"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.5220/0007566307940800", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1901.09657v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.09657v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11th International Conference on Agents and Artificial Intelligence\n  (ICAART 2019)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1902.02401v1", "updated": "2019-02-06T21:17:57Z", "published": "2019-02-06T21:17:57Z", "title": "Adversarial Domain Adaptation for Stance Detection", "summary": "This paper studies the problem of stance detection which aims to predict the\nperspective (or stance) of a given document with respect to a given claim.\nStance detection is a major component of automated fact checking. As annotating\nstances in different domains is a tedious and costly task, automatic methods\nbased on machine learning are viable alternatives. In this paper, we focus on\nadversarial domain adaptation for stance detection where we assume there exists\nsufficient labeled data in the source domain and limited labeled data in the\ntarget domain. Extensive experiments on publicly available datasets show the\neffectiveness of our domain adaption model in transferring knowledge for\naccurate stance detection across domains.", "author": [{"name": "Brian Xu"}, {"name": "Mitra Mohtarami"}, {"name": "James Glass"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at NIPS-CL-2018, Stance Detection, Fact Checking,\n  Adversarial Domain Adaptation"}, "link": [{"@href": "http://arxiv.org/abs/1902.02401v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.02401v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.03242v2", "updated": "2019-10-21T15:51:53Z", "published": "2019-09-07T10:57:29Z", "title": "MultiFC: A Real-World Multi-Domain Dataset for Evidence-Based Fact\n  Checking of Claims", "summary": "We contribute the largest publicly available dataset of naturally occurring\nfactual claims for the purpose of automatic claim verification. It is collected\nfrom 26 fact checking websites in English, paired with textual sources and rich\nmetadata, and labelled for veracity by human expert journalists. We present an\nin-depth analysis of the dataset, highlighting characteristics and challenges.\nFurther, we present results for automatic veracity prediction, both with\nestablished baselines and with a novel method for joint ranking of evidence\npages and predicting veracity that outperforms all baselines. Significant\nperformance increases are achieved by encoding evidence, and by modelling\nmetadata. Our best-performing model achieves a Macro F1 of 49.2%, showing that\nthis is a challenging testbed for claim veracity prediction.", "author": [{"name": "Isabelle Augenstein"}, {"name": "Christina Lioma"}, {"name": "Dongsheng Wang"}, {"name": "Lucas Chaves Lima"}, {"name": "Casper Hansen"}, {"name": "Christian Hansen"}, {"name": "Jakob Grue Simonsen"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of EMNLP 2019, to appear"}, "link": [{"@href": "http://arxiv.org/abs/1909.03242v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.03242v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.02736v2", "updated": "2020-09-16T16:52:15Z", "published": "2020-03-05T16:06:07Z", "title": "Claim Check-Worthiness Detection as Positive Unlabelled Learning", "summary": "As the first step of automatic fact checking, claim check-worthiness\ndetection is a critical component of fact checking systems. There are multiple\nlines of research which study this problem: check-worthiness ranking from\npolitical speeches and debates, rumour detection on Twitter, and citation\nneeded detection from Wikipedia. To date, there has been no structured\ncomparison of these various tasks to understand their relatedness, and no\ninvestigation into whether or not a unified approach to all of them is\nachievable. In this work, we illuminate a central challenge in claim\ncheck-worthiness detection underlying all of these tasks, being that they hinge\nupon detecting both how factual a sentence is, as well as how likely a sentence\nis to be believed without verification. As such, annotators only mark those\ninstances they judge to be clear-cut check-worthy. Our best performing method\nis a unified approach which automatically corrects for this using a variant of\npositive unlabelled learning that finds instances which were incorrectly\nlabelled as not check-worthy. In applying this, we out-perform the state of the\nart in two of the three tasks studied for claim check-worthiness detection in\nEnglish.", "author": [{"name": "Dustin Wright"}, {"name": "Isabelle Augenstein"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages, 2 figures, 9 tables"}, "link": [{"@href": "http://arxiv.org/abs/2003.02736v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.02736v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.08570v1", "updated": "2020-10-16T18:10:47Z", "published": "2020-10-16T18:10:47Z", "title": "Generating Fact Checking Summaries for Web Claims", "summary": "We present SUMO, a neural attention-based approach that learns to establish\nthe correctness of textual claims based on evidence in the form of text\ndocuments (e.g., news articles or Web documents). SUMO further generates an\nextractive summary by presenting a diversified set of sentences from the\ndocuments that explain its decision on the correctness of the textual claim.\nPrior approaches to address the problem of fact checking and evidence\nextraction have relied on simple concatenation of claim and document word\nembeddings as an input to claim driven attention weight computation. This is\ndone so as to extract salient words and sentences from the documents that help\nestablish the correctness of the claim. However, this design of claim-driven\nattention does not capture the contextual information in documents properly. We\nimprove on the prior art by using improved claim and title guided hierarchical\nattention to model effective contextual cues. We show the efficacy of our\napproach on datasets concerning political, healthcare, and environmental\nissues.", "author": [{"name": "Rahul Mishra"}, {"name": "Dhruv Gupta"}, {"name": "Markus Leippold"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted paper; The 2020 Conference on Empirical Methods in Natural\n  Language Processing EMNLP - WNUT"}, "link": [{"@href": "http://arxiv.org/abs/2010.08570v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.08570v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.1.1; H.3.1; H.3.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.02680v1", "updated": "2021-02-04T15:18:44Z", "published": "2021-02-04T15:18:44Z", "title": "Hierarchical Multi-head Attentive Network for Evidence-aware Fake News\n  Detection", "summary": "The widespread of fake news and misinformation in various domains ranging\nfrom politics, economics to public health has posed an urgent need to\nautomatically fact-check information. A recent trend in fake news detection is\nto utilize evidence from external sources. However, existing evidence-aware\nfake news detection methods focused on either only word-level attention or\nevidence-level attention, which may result in suboptimal performance. In this\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\ntextual claims. Our model jointly combines multi-head word-level attention and\nmulti-head document-level attention, which aid explanation in both word-level\nand evidence-level. Experiments on two real-word datasets show that our model\noutperforms seven state-of-the-art baselines. Improvements over baselines are\nfrom 6\\% to 18\\%. Our source code and datasets are released at\n\\texttt{\\url{https://github.com/nguyenvo09/EACL2021}}.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EACL2021"}, "link": [{"@href": "http://arxiv.org/abs/2102.02680v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.02680v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.00242v1", "updated": "2021-02-27T15:27:22Z", "published": "2021-02-27T15:27:22Z", "title": "A Survey on Stance Detection for Mis- and Disinformation Identification", "summary": "Detecting attitudes expressed in texts, also known as stance detection, has\nbecome an important task for the detection of false information online, be it\nmisinformation (unintentionally false) or disinformation (intentionally false,\nspread deliberately with malicious intent). Stance detection has been framed in\ndifferent ways, including: (a) as a component of fact-checking, rumour\ndetection, and detecting previously fact-checked claims; or (b) as a task in\nits own right. While there have been prior efforts to contrast stance detection\nwith other related social media tasks such as argumentation mining and\nsentiment analysis, there is no survey examining the relationship between\nstance detection detection and mis- and disinformation detection from a\nholistic viewpoint, which is the focus of this survey. We review and analyse\nexisting work in this area, before discussing lessons learnt and future\nchallenges.", "author": [{"name": "Momchil Hardalov"}, {"name": "Arnav Arora"}, {"name": "Preslav Nakov"}, {"name": "Isabelle Augenstein"}], "link": [{"@href": "http://arxiv.org/abs/2103.00242v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.00242v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.13559v2", "updated": "2021-05-18T05:41:05Z", "published": "2021-04-28T03:38:24Z", "title": "AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance\n  Detection for Fact Checking", "summary": "With the continuing spread of misinformation and disinformation online, it is\nof increasing importance to develop combating mechanisms at scale in the form\nof automated systems that support multiple languages. One task of interest is\nclaim veracity prediction, which can be addressed using stance detection with\nrespect to relevant documents retrieved online. To this end, we present our new\nArabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from\na diverse set of sources comprising three fact-checking websites and one news\nwebsite. AraStance covers false and true claims from multiple domains (e.g.,\npolitics, sports, health) and several Arab countries, and it is well-balanced\nbetween related and unrelated documents with respect to the claims. We\nbenchmark AraStance, along with two other stance detection datasets, using a\nnumber of BERT-based models. Our best model achieves an accuracy of 85\\% and a\nmacro F1 score of 78\\%, which leaves room for improvement and reflects the\nchallenging nature of AraStance and the task of stance detection in general.", "author": [{"name": "Tariq Alhindi"}, {"name": "Amal Alabdulkarim"}, {"name": "Ali Alshehri"}, {"name": "Muhammad Abdul-Mageed"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the 2021 Workshop on NLP4IF: Censorship, Disinformation,\n  and Propaganda"}, "link": [{"@href": "http://arxiv.org/abs/2104.13559v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13559v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2105.07698v1", "updated": "2021-05-17T09:34:03Z", "published": "2021-05-17T09:34:03Z", "title": "Automatic Fake News Detection: Are Models Learning to Reason?", "summary": "Most fact checking models for automatic fake news detection are based on\nreasoning: given a claim with associated evidence, the models aim to estimate\nthe claim veracity based on the supporting or refuting content within the\nevidence. When these models perform well, it is generally assumed to be due to\nthe models having learned to reason over the evidence with regards to the\nclaim. In this paper, we investigate this assumption of reasoning, by exploring\nthe relationship and importance of both claim and evidence. Surprisingly, we\nfind on political fact checking datasets that most often the highest\neffectiveness is obtained by utilizing only the evidence, as the impact of\nincluding the claim is either negligible or harmful to the effectiveness. This\nhighlights an important problem in what constitutes evidence in existing\napproaches for automatic fake news detection.", "author": [{"name": "Casper Hansen"}, {"name": "Christian Hansen"}, {"name": "Lucas Chaves Lima"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at ACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2105.07698v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.07698v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.06051v2", "updated": "2021-07-14T10:51:41Z", "published": "2021-07-13T13:05:11Z", "title": "Rating Facts under Coarse-to-fine Regimes", "summary": "The rise of manipulating fake news as a political weapon has become a global\nconcern and highlighted the incapability of manually fact checking against\nrapidly produced fake news. Thus, statistical approaches are required if we are\nto address this problem efficiently. The shortage of publicly available\ndatasets is one major bottleneck of automated fact checking. To remedy this, we\ncollected 24K manually rated statements from PolitiFact. The class values\nexhibit a natural order with respect to truthfulness as shown in Table 1. Thus,\nour task represents a twist from standard classification, due to the various\ndegrees of similarity between classes. To investigate this, we defined\ncoarse-to-fine classification regimes, which presents new challenge for\nclassification. To address this, we propose BERT-based models. After training,\nclass similarity is sensible over the multi-class datasets, especially in the\nfine-grained one. Under all the regimes, BERT achieves state of the art, while\nthe additional layers provide insignificant improvement.", "author": {"name": "Guojun Wu"}, "link": [{"@href": "http://arxiv.org/abs/2107.06051v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.06051v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.14740v1", "updated": "2021-07-30T16:37:45Z", "published": "2021-07-30T16:37:45Z", "title": "Automatic Claim Review for Climate Science via Explanation Generation", "summary": "There is unison is the scientific community about human induced climate\nchange. Despite this, we see the web awash with claims around climate change\nscepticism, thus driving the need for fact checking them but at the same time\nproviding an explanation and justification for the fact check. Scientists and\nexperts have been trying to address it by providing manually written feedback\nfor these claims. In this paper, we try to aid them by automating generating\nexplanation for a predicted veracity label for a claim by deploying the\napproach used in open domain question answering of a fusion in decoder\naugmented with retrieved supporting passages from an external knowledge. We\nexperiment with different knowledge sources, retrievers, retriever depths and\ndemonstrate that even a small number of high quality manually written\nexplanations can help us in generating good explanations.", "author": [{"name": "Shraey Bhatia"}, {"name": "Jey Han Lau"}, {"name": "Timothy Baldwin"}], "link": [{"@href": "http://arxiv.org/abs/2107.14740v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.14740v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.11669v1", "updated": "2021-08-26T09:28:50Z", "published": "2021-08-26T09:28:50Z", "title": "Technological Approaches to Detecting Online Disinformation and\n  Manipulation", "summary": "The move of propaganda and disinformation to the online environment is\npossible thanks to the fact that within the last decade, digital information\nchannels radically increased in popularity as a news source. The main advantage\nof such media lies in the speed of information creation and dissemination.\nThis, on the other hand, inevitably adds pressure, accelerating editorial work,\nfact-checking, and the scrutiny of source credibility. In this chapter, an\noverview of computer-supported approaches to detecting disinformation and\nmanipulative techniques based on several criteria is presented. We concentrate\non the technical aspects of automatic methods which support fact-checking,\ntopic identification, text style analysis, or message filtering on social media\nchannels. Most of the techniques employ artificial intelligence and machine\nlearning with feature extraction combining available information resources. The\nfollowing text firstly specifies the tasks related to computer detection of\nmanipulation and disinformation spreading. The second section presents concrete\nmethods of solving the tasks of the analysis, and the third sections enlists\ncurrent verification and benchmarking datasets published and used in this area\nfor evaluation and comparison.", "author": [{"name": "Ale\u0161 Hor\u00e1k"}, {"name": "V\u00edt Baisa"}, {"name": "Ond\u0159ej Herman"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-58624-9"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-58624-9", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.11669v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.11669v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is an author preprint of the 5th chapter in the book of\n  \"Challenging Online Propaganda and Disinformation in the 21st Century\"\n  published by Palgrave Macmillan at\n  https://www.palgrave.com/gp/book/9783030586232"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1511.01850v1", "updated": "2015-11-05T18:47:13Z", "published": "2015-11-05T18:47:13Z", "title": "Non-integrability of restricted double pendula", "summary": "We consider two special types of double pendula, with the motion of masses\nrestricted to various surfaces. In order to get quick insight into the dynamics\nof the considered systems the Poincar\\'e cross sections as well as bifurcation\ndiagrams have been used. The numerical computations show that both models are\nchaotic which suggest that they are not integrable. We give an analytic proof\nof this fact checking the properties of the differential Galois group of the\nsystem's variational equations along a particular non-equilibrium solution.", "author": [{"name": "Tomasz Stachowiak"}, {"name": "Wojciech Szumi\u0144ski"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.physleta.2015.09.052"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.physleta.2015.09.052", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1511.01850v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1511.01850v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages, 8 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Physics Letters A 379 (2015) pp. 3017-3024"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "nlin.CD", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "nlin.CD", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.MP", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1608.04147v1", "updated": "2016-08-14T22:34:22Z", "published": "2016-08-14T22:34:22Z", "title": "Numerically Grounded Language Models for Semantic Error Correction", "summary": "Semantic error detection and correction is an important task for applications\nsuch as fact checking, speech-to-text or grammatical error correction. Current\napproaches generally focus on relatively shallow semantics and do not account\nfor numeric quantities. Our approach uses language models grounded in numbers\nwithin the text. Such groundings are easily achieved for recurrent neural\nlanguage model architectures, which can be further conditioned on incomplete\nbackground knowledge bases. Our evaluation on clinical reports shows that\nnumerical grounding improves perplexity by 33% and F1 for semantic error\ncorrection by 5 points when compared to ungrounded approaches. Conditioning on\na knowledge base yields further improvements.", "author": [{"name": "Georgios P. Spithourakis"}, {"name": "Isabelle Augenstein"}, {"name": "Sebastian Riedel"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "accepted to EMNLP 2016"}, "link": [{"@href": "http://arxiv.org/abs/1608.04147v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1608.04147v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1804.07581v1", "updated": "2018-04-20T12:48:10Z", "published": "2018-04-20T12:48:10Z", "title": "Automatic Stance Detection Using End-to-End Memory Networks", "summary": "We present a novel end-to-end memory network for stance detection, which\njointly (i) predicts whether a document agrees, disagrees, discusses or is\nunrelated with respect to a given target claim, and also (ii) extracts snippets\nof evidence for that prediction. The network operates at the paragraph level\nand integrates convolutional and recurrent neural networks, as well as a\nsimilarity matrix as part of the overall architecture. The experimental\nevaluation on the Fake News Challenge dataset shows state-of-the-art\nperformance.", "author": [{"name": "Mitra Mohtarami"}, {"name": "Ramy Baly"}, {"name": "James Glass"}, {"name": "Preslav Nakov"}, {"name": "Lluis Marquez"}, {"name": "Alessandro Moschitti"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NAACL-2018; Stance detection; Fact-Checking; Veracity; Memory\n  networks; Neural Networks; Distributed Representations"}, "link": [{"@href": "http://arxiv.org/abs/1804.07581v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.07581v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1812.10814v1", "updated": "2018-12-27T20:09:51Z", "published": "2018-12-27T20:09:51Z", "title": "Uni-DUE Student Team: Tackling fact checking through decomposable\n  attention neural network", "summary": "In this paper we present our system for the FEVER Challenge. The task of this\nchallenge is to verify claims by extracting information from Wikipedia. Our\nsystem has two parts. In the first part it performs a search for candidate\nsentences by treating the claims as query. In the second part it filters out\nnoise from these candidates and uses the remaining ones to decide whether they\nsupport or refute or entail not enough information to verify the claim. We show\nthat this system achieves a FEVER score of 0.3927 on the FEVER shared task\ndevelopment data set which is a 25.5% improvement over the baseline score.", "author": [{"name": "Jan Kowollik"}, {"name": "Ahmet Aker"}], "link": [{"@href": "http://arxiv.org/abs/1812.10814v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.10814v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.14425v1", "updated": "2020-04-29T18:39:15Z", "published": "2020-04-29T18:39:15Z", "title": "A Benchmark Dataset of Check-worthy Factual Claims", "summary": "In this paper we present the ClaimBuster dataset of 23,533 statements\nextracted from all U.S. general election presidential debates and annotated by\nhuman coders. The ClaimBuster dataset can be leveraged in building\ncomputational methods to identify claims that are worth fact-checking from the\nmyriad of sources of digital or traditional media. The ClaimBuster dataset is\npublicly available to the research community, and it can be found at\nhttp://doi.org/10.5281/zenodo.3609356.", "author": [{"name": "Fatma Arslan"}, {"name": "Naeemul Hassan"}, {"name": "Chengkai Li"}, {"name": "Mark Tremayne"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to ICWSM 2020"}, "link": [{"@href": "http://arxiv.org/abs/2004.14425v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.14425v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1911.10130v1", "updated": "2019-11-22T16:35:37Z", "published": "2019-11-22T16:35:37Z", "title": "A Data Set of Internet Claims and Comparison of their Sentiments with\n  Credibility", "summary": "In this modern era, communication has become faster and easier. This means\nfallacious information can spread as fast as reality. Considering the damage\nthat fake news kindles on the psychology of people and the fact that such news\nproliferates faster than truth, we need to study the phenomenon that helps\nspread fake news. An unbiased data set that depends on reality for rating news\nis necessary to construct predictive models for its classification. This paper\ndescribes the methodology to create such a data set. We collect our data from\nsnopes.com which is a fact-checking organization. Furthermore, we intend to\ncreate this data set not only for classification of the news but also to find\npatterns that reason the intent behind misinformation. We also formally define\nan Internet Claim, its credibility, and the sentiment behind such a claim. We\ntry to realize the relationship between the sentiment of a claim with its\ncredibility. This relationship pours light on the bigger picture behind the\npropagation of misinformation. We pave the way for further research based on\nthe methodology described in this paper to create the data set and usage of\npredictive modeling along with research-based on psychology/mentality of people\nto understand why fake news spreads much faster than reality.", "author": [{"name": "Amey Parundekar"}, {"name": "Susan Elias"}, {"name": "Ashwin Ashok"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 6 figures, A paper accepted at the Truth Discovery and Fact\n  Checking: Theory and Practice SIGKDD 2019 Workshop, August 5th, Anchorage,\n  Alaska"}, "link": [{"@href": "http://arxiv.org/abs/1911.10130v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.10130v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3.3, I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3.3; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.03436v1", "updated": "2020-01-09T15:19:45Z", "published": "2020-01-09T15:19:45Z", "title": "Debate Dynamics for Human-comprehensible Fact-checking on Knowledge\n  Graphs", "summary": "We propose a novel method for fact-checking on knowledge graphs based on\ndebate dynamics. The underlying idea is to frame the task of triple\nclassification as a debate game between two reinforcement learning agents which\nextract arguments -- paths in the knowledge graph -- with the goal to justify\nthe fact being true (thesis) or the fact being false (antithesis),\nrespectively. Based on these arguments, a binary classifier, referred to as the\njudge, decides whether the fact is true or false. The two agents can be\nconsidered as sparse feature extractors that present interpretable evidence for\neither the thesis or the antithesis. In contrast to black-box methods, the\narguments enable the user to gain an understanding for the decision of the\njudge. Moreover, our method allows for interactive reasoning on knowledge\ngraphs where the users can raise additional arguments or evaluate the debate\ntaking common sense reasoning and external information into account. Such\ninteractive systems can increase the acceptance of various AI applications\nbased on knowledge graphs and can further lead to higher efficiency,\nrobustness, and fairness.", "author": [{"name": "Marcel Hildebrandt"}, {"name": "Jorge Andres Quintero Serna"}, {"name": "Yunpu Ma"}, {"name": "Martin Ringsquandl"}, {"name": "Mitchell Joblin"}, {"name": "Volker Tresp"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AAAI 2019 Fall Symposium Series. arXiv admin note: substantial text\n  overlap with arXiv:2001.00461"}, "link": [{"@href": "http://arxiv.org/abs/2001.03436v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.03436v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.13659v1", "updated": "2020-04-28T17:04:19Z", "published": "2020-04-28T17:04:19Z", "title": "LogicalFactChecker: Leveraging Logical Operations for Fact Checking with\n  Graph Module Network", "summary": "Verifying the correctness of a textual statement requires not only semantic\nreasoning about the meaning of words, but also symbolic reasoning about logical\noperations like count, superlative, aggregation, etc. In this work, we propose\nLogicalFactChecker, a neural network approach capable of leveraging logical\noperations for fact checking. It achieves the state-of-the-art performance on\nTABFACT, a large-scale, benchmark dataset built for verifying a textual\nstatement with semi-structured tables. This is achieved by a graph module\nnetwork built upon the Transformer-based architecture. With a textual statement\nand a table as the input, LogicalFactChecker automatically derives a program\n(a.k.a. logical form) of the statement in a semantic parsing manner. A\nheterogeneous graph is then constructed to capture not only the structures of\nthe table and the program, but also the connections between inputs with\ndifferent modalities. Such a graph reveals the related contexts of each word in\nthe statement, the table and the program. The graph is used to obtain\ngraph-enhanced contextual representations of words in Transformer-based\narchitecture. After that, a program-driven module network is further introduced\nto exploit the hierarchical structure of the program, where semantic\ncompositionality is dynamically modeled along the program structure with a set\nof function-specific modules. Ablation experiments suggest that both the\nheterogeneous graph and the module network are important to obtain strong\nresults.", "author": [{"name": "Wanjun Zhong"}, {"name": "Duyu Tang"}, {"name": "Zhangyin Feng"}, {"name": "Nan Duan"}, {"name": "Ming Zhou"}, {"name": "Ming Gong"}, {"name": "Linjun Shou"}, {"name": "Daxin Jiang"}, {"name": "Jiahai Wang"}, {"name": "Jian Yin"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages; 7 figures; Accepted by ACL2020 as a long paper"}, "link": [{"@href": "http://arxiv.org/abs/2004.13659v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.13659v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.04518v1", "updated": "2020-05-09T22:00:08Z", "published": "2020-05-09T22:00:08Z", "title": "What Was Written vs. Who Read It: News Media Profiling Using Text\n  Analysis and Social Media Context", "summary": "Predicting the political bias and the factuality of reporting of entire news\noutlets are critical elements of media profiling, which is an understudied but\nan increasingly important research direction. The present level of\nproliferation of fake, biased, and propagandistic content online, has made it\nimpossible to fact-check every single suspicious claim, either manually or\nautomatically. Alternatively, we can profile entire news outlets and look for\nthose that are likely to publish fake or biased content. This approach makes it\npossible to detect likely \"fake news\" the moment they are published, by simply\nchecking the reliability of their source. From a practical perspective,\npolitical bias and factuality of reporting have a linguistic aspect but also a\nsocial context. Here, we study the impact of both, namely (i) what was written\n(i.e., what was published by the target medium, and how it describes itself on\nTwitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium\non Facebook, Twitter, and YouTube). We further study (iii) what was written\nabout the target medium on Wikipedia. The evaluation results show that what was\nwritten matters most, and that putting all information sources together yields\nhuge improvements over the current state-of-the-art.", "author": [{"name": "Ramy Baly"}, {"name": "Georgi Karadzhov"}, {"name": "Jisun An"}, {"name": "Haewoon Kwak"}, {"name": "Yoan Dinkov"}, {"name": "Ahmed Ali"}, {"name": "James Glass"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Factuality of reporting, fact-checking, political ideology, media\n  bias, disinformation, propaganda, social media, news media"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL-2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.04518v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.04518v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.05710v2", "updated": "2020-08-24T19:13:30Z", "published": "2020-05-12T12:07:35Z", "title": "An Exploratory Study of COVID-19 Misinformation on Twitter", "summary": "During the COVID-19 pandemic, social media has become a home ground for\nmisinformation. To tackle this infodemic, scientific oversight, as well as a\nbetter understanding by practitioners in crisis management, is needed. We have\nconducted an exploratory study into the propagation, authors and content of\nmisinformation on Twitter around the topic of COVID-19 in order to gain early\ninsights. We have collected all tweets mentioned in the verdicts of\nfact-checked claims related to COVID-19 by over 92 professional fact-checking\norganisations between January and mid-July 2020 and share this corpus with the\ncommunity. This resulted in 1 500 tweets relating to 1 274 false and 276\npartially false claims, respectively. Exploratory analysis of author accounts\nrevealed that the verified twitter handle(including Organisation/celebrity) are\nalso involved in either creating (new tweets) or spreading (retweet) the\nmisinformation. Additionally, we found that false claims propagate faster than\npartially false claims. Compare to a background corpus of COVID-19 tweets,\ntweets with misinformation are more often concerned with discrediting other\ninformation on social media. Authors use less tentative language and appear to\nbe more driven by concerns of potential harm to others. Our results enable us\nto suggest gaps in the current scientific coverage of the topic as well as\npropose actions for authorities and social media users to counter\nmisinformation.", "author": [{"name": "Gautam Kishore Shahi"}, {"name": "Anne Dirkson"}, {"name": "Tim A. Majchrzak"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "20 pages, nine figures, four tables. Submitted for peer review,\n  revision 1"}, "link": [{"@href": "http://arxiv.org/abs/2005.05710v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.05710v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.10534v2", "updated": "2020-09-20T23:51:37Z", "published": "2020-07-21T00:07:17Z", "title": "Check_square at CheckThat! 2020: Claim Detection in Social Media via\n  Fusion of Transformer and Syntactic Features", "summary": "In this digital age of news consumption, a news reader has the ability to\nreact, express and share opinions with others in a highly interactive and fast\nmanner. As a consequence, fake news has made its way into our daily life\nbecause of very limited capacity to verify news on the Internet by large\ncompanies as well as individuals. In this paper, we focus on solving two\nproblems which are part of the fact-checking ecosystem that can help to\nautomate fact-checking of claims in an ever increasing stream of content on\nsocial media. For the first problem, claim check-worthiness prediction, we\nexplore the fusion of syntactic features and deep transformer Bidirectional\nEncoder Representations from Transformers (BERT) embeddings, to classify\ncheck-worthiness of a tweet, i.e. whether it includes a claim or not. We\nconduct a detailed feature analysis and present our best performing models for\nEnglish and Arabic tweets. For the second problem, claim retrieval, we explore\nthe pre-trained embeddings from a Siamese network transformer model\n(sentence-transformers) specifically trained for semantic textual similarity,\nand perform KD-search to retrieve verified claims with respect to a query\ntweet.", "author": [{"name": "Gullal S. Cheema"}, {"name": "Sherzod Hakimov"}, {"name": "Ralph Ewerth"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF2020-CheckThat!"}, "link": [{"@href": "http://arxiv.org/abs/2007.10534v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.10534v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.15121v2", "updated": "2021-05-17T17:10:02Z", "published": "2020-07-29T21:40:01Z", "title": "Exploiting stance hierarchies for cost-sensitive stance detection of Web\n  documents", "summary": "Fact checking is an essential challenge when combating fake news. Identifying\ndocuments that agree or disagree with a particular statement (claim) is a core\ntask in this process. In this context, stance detection aims at identifying the\nposition (stance) of a document towards a claim. Most approaches address this\ntask through a 4-class classification model where the class distribution is\nhighly imbalanced. Therefore, they are particularly ineffective in detecting\nthe minority classes (for instance, 'disagree'), even though such instances are\ncrucial for tasks such as fact-checking by providing evidence for detecting\nfalse claims. In this paper, we exploit the hierarchical nature of stance\nclasses, which allows us to propose a modular pipeline of cascading binary\nclassifiers, enabling performance tuning on a per step and class basis. We\nimplement our approach through a combination of neural and traditional\nclassification models that highlight the misclassification costs of minority\nclasses. Evaluation results demonstrate state-of-the-art performance of our\napproach and its ability to significantly improve the classification\nperformance of the important 'disagree' class.", "author": [{"name": "Arjun Roy"}, {"name": "Pavlos Fafalios"}, {"name": "Asif Ekbal"}, {"name": "Xiaofei Zhu"}, {"name": "Stefan Dietze"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/s10844-021-00642-z"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/s10844-021-00642-z", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.15121v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.15121v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a pre-print version of the Journal paper published in J\n  Intell Inf Syst (2021) (Springer). https://rdcu.be/ckLiC"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.02252v4", "updated": "2021-05-27T15:20:59Z", "published": "2020-09-04T15:32:19Z", "title": "KILT: a Benchmark for Knowledge Intensive Language Tasks", "summary": "Challenging problems such as open-domain question answering, fact checking,\nslot filling and entity linking require access to large, external knowledge\nsources. While some models do well on individual tasks, developing general\nmodels is difficult as each task might require computationally expensive\nindexing of custom knowledge sources, in addition to dedicated infrastructure.\nTo catalyze research on models that condition on specific information in large\ntextual resources, we present a benchmark for knowledge-intensive language\ntasks (KILT). All tasks in KILT are grounded in the same snapshot of Wikipedia,\nreducing engineering turnaround through the re-use of components, as well as\naccelerating research into task-agnostic memory architectures. We test both\ntask-specific and general baselines, evaluating downstream performance in\naddition to the ability of the models to provide provenance. We find that a\nshared dense vector index coupled with a seq2seq model is a strong baseline,\noutperforming more tailor-made approaches for fact checking, open-domain\nquestion answering and dialogue, and yielding competitive results on entity\nlinking and slot filling, by generating disambiguated text. KILT data and code\nare available at https://github.com/facebookresearch/KILT.", "author": [{"name": "Fabio Petroni"}, {"name": "Aleksandra Piktus"}, {"name": "Angela Fan"}, {"name": "Patrick Lewis"}, {"name": "Majid Yazdani"}, {"name": "Nicola De Cao"}, {"name": "James Thorne"}, {"name": "Yacine Jernite"}, {"name": "Vladimir Karpukhin"}, {"name": "Jean Maillard"}, {"name": "Vassilis Plachouras"}, {"name": "Tim Rockt\u00e4schel"}, {"name": "Sebastian Riedel"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "accepted at NAACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2009.02252v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.02252v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.13253v1", "updated": "2020-11-26T11:50:45Z", "published": "2020-11-26T11:50:45Z", "title": "Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking", "summary": "The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.", "author": [{"name": "Rutvik Vijjali"}, {"name": "Prathyush Potluri"}, {"name": "Siddharth Kumar"}, {"name": "Sundeep Teki"}], "link": [{"@href": "http://arxiv.org/abs/2011.13253v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.13253v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.10864v1", "updated": "2021-04-22T05:09:25Z", "published": "2021-04-22T05:09:25Z", "title": "Misinformation, Believability, and Vaccine Acceptance Over 40 Countries:\n  Takeaways From the Initial Phase of The COVID-19 Infodemic", "summary": "The COVID-19 pandemic has been damaging to the lives of people all around the\nworld. Accompanied by the pandemic is an infodemic, an abundant and\nuncontrolled spreading of potentially harmful misinformation. The infodemic may\nseverely change the pandemic's course by interfering with public health\ninterventions such as wearing masks, social distancing, and vaccination. In\nparticular, the impact of the infodemic on vaccination is critical because it\nholds the key to reverting to pre-pandemic normalcy. This paper presents\nfindings from a global survey on the extent of worldwide exposure to the\nCOVID-19 infodemic, assesses different populations' susceptibility to false\nclaims, and analyzes its association with vaccine acceptance. Based on\nresponses gathered from over 18,400 individuals from 40 countries, we find a\nstrong association between perceived believability of misinformation and\nvaccination hesitancy. Additionally, our study shows that only half of the\nonline users exposed to rumors might have seen the fact-checked information.\nMoreover, depending on the country, between 6% and 37% of individuals\nconsidered these rumors believable. Our survey also shows that poorer regions\nare more susceptible to encountering and believing COVID-19 misinformation. We\ndiscuss implications of our findings on public campaigns that proactively\nspread accurate information to countries that are more susceptible to the\ninfodemic. We also highlight fact-checking platforms' role in better\nidentifying and prioritizing claims that are perceived to be believable and\nhave wide exposure. Our findings give insights into better handling of risk\ncommunication during the initial phase of a future pandemic.", "author": [{"name": "Karandeep Singh"}, {"name": "Gabriel Lima"}, {"name": "Meeyoung Cha"}, {"name": "Chiyoung Cha"}, {"name": "Juhi Kulshrestha"}, {"name": "Yong-Yeol Ahn"}, {"name": "Onur Varol"}], "link": [{"@href": "http://arxiv.org/abs/2104.10864v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.10864v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.09586v1", "updated": "2021-06-17T15:13:08Z", "published": "2021-06-17T15:13:08Z", "title": "Prevalence and Propagation of Fake News", "summary": "In recent years, scholars have raised concerns on the effects that unreliable\nnews, or \"fake news,\" has on our political sphere, and our democracy as a\nwhole. For example, the propagation of fake news on social media is widely\nbelieved to have influenced the outcome of national elections, including the\n2016 U.S. Presidential Election, and the 2020 COVID-19 pandemic. What drives\nthe propagation of fake news on an individual level, and which interventions\ncould effectively reduce the propagation rate? Our model disentangles bias from\ntruthfulness of an article and examines the relationship between these two\nparameters and a reader's own beliefs. Using the model, we create policy\nrecommendations for both social media platforms and individual social media\nusers to reduce the spread of untruthful or highly biased news. We recommend\nthat platforms sponsor unbiased truthful news, focus fact-checking efforts on\nmild to moderately biased news, recommend friend suggestions across the\npolitical spectrum, and provide users with reports about the political\nalignment of their feed. We recommend that individual social media users fact\ncheck news that strongly aligns with their political bias and read articles of\nopposing political bias.", "author": [{"name": "Banafsheh Behzad"}, {"name": "Bhavana Bheem"}, {"name": "Daniela Elizondo"}, {"name": "Deyana Marsh"}, {"name": "Susan Martonosi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "45 pages, 22 figures. Submitted for peer review on 7 May 2021"}, "link": [{"@href": "http://arxiv.org/abs/2106.09586v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.09586v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.OC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "90B50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "J.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1806.00749v1", "updated": "2018-06-03T08:09:58Z", "published": "2018-06-03T08:09:58Z", "title": "TI-CNN: Convolutional Neural Networks for Fake News Detection", "summary": "With the development of social networks, fake news for various commercial and\npolitical purposes has been appearing in large numbers and gotten widespread in\nthe online world. With deceptive words, people can get infected by the fake\nnews very easily and will share them without any fact-checking. For instance,\nduring the 2016 US president election, various kinds of fake news about the\ncandidates widely spread through both official news media and the online social\nnetworks. These fake news is usually released to either smear the opponents or\nsupport the candidate on their side. The erroneous information in the fake news\nis usually written to motivate the voters' irrational emotion and enthusiasm.\nSuch kinds of fake news sometimes can bring about devastating effects, and an\nimportant goal in improving the credibility of online social networks is to\nidentify the fake news timely. In this paper, we propose to study the fake news\ndetection problem. Automatic fake news identification is extremely hard, since\npure model based fact-checking for news is still an open problem, and few\nexisting models can be applied to solve the problem. With a thorough\ninvestigation of a fake news data, lots of useful explicit features are\nidentified from both the text words and images used in the fake news. Besides\nthe explicit features, there also exist some hidden patterns in the words and\nimages used in fake news, which can be captured with a set of latent features\nextracted via the multiple convolutional layers in our model. A model named as\nTI-CNN (Text and Image information based Convolutinal Neural Network) is\nproposed in this paper. By projecting the explicit and latent features into a\nunified feature space, TI-CNN is trained with both the text and image\ninformation simultaneously. Extensive experiments carried on the real-world\nfake news datasets have demonstrate the effectiveness of TI-CNN.", "author": [{"name": "Yang Yang"}, {"name": "Lei Zheng"}, {"name": "Jiawei Zhang"}, {"name": "Qingcai Cui"}, {"name": "Zhoujun Li"}, {"name": "Philip S. Yu"}], "link": [{"@href": "http://arxiv.org/abs/1806.00749v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.00749v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.12226v2", "updated": "2020-10-01T16:44:25Z", "published": "2020-07-23T19:43:27Z", "title": "Understanding the dynamics emerging from infodemics: A call to action\n  for interdisciplinary research", "summary": "Research on infodemics, i.e., the rapid spread of (mis)information related to\na hazardous event, such as the COVID-19 pandemic, requires the integration of a\nmultiplicity of scientific disciplines. The dynamics emerging from infodemics\nhave the potential to generate complex behavioral patterns. In order to react\nappropriately, it is of ultimate importance for the fields of Business and\nEconomics to understand the dynamics emerging from it. In the short run,\ndynamics might lead to an adaptation in household spending or to a shift in\nbuying behavior towards online providers. In the long run, changes in\ninvestments, consumer behavior, and markets are to be expected. We argue that\nthe dynamics emerge from complex interactions among multiple factors, such as\ninformation and misinformation accessible for individuals and the formation and\nrevision of beliefs. (Mis)information accessible to individuals is, amongst\nothers, affected by algorithms specifically designed to provide personalized\ninformation, while automated fact-checking algorithms can help reduce the\namount of circulating misinformation. The formation and revision of individual\n(and probably false) beliefs and individual fact-checking and interpretation of\ninformation are heavily affected by linguistic patterns inherent to information\nduring pandemics and infodemics and further factors, such as affect, intuition\nand motives. We argue that, in order to get a deep(er) understanding of the\ndynamics emerging from infodemics, the fields of Business and Economics should\nintegrate the perspectives of Computer Science and Information Systems,\n(Computational) Linguistics, and Cognitive Science into the wider context of\neconomic systems (e.g., organizations, markets or industries) and propose a way\nto do so.", "author": [{"name": "Stephan Leitner"}, {"name": "Bartosz Gula"}, {"name": "Dietmar Jannach"}, {"name": "Ulrike Krieg-Holz"}, {"name": "Friederike Wall"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "16 pages"}, "link": [{"@href": "http://arxiv.org/abs/2007.12226v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.12226v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.DS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68Q11, 68U35, 91E10, 68T50, 91F20, 91B44, 91B70", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.4; J.4; J.5", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.12841v3", "updated": "2020-08-27T04:01:13Z", "published": "2020-07-25T03:03:20Z", "title": "Combating Misinformation in Bangladesh: Roles and Responsibilities as\n  Perceived by Journalists, Fact-checkers, and Users", "summary": "There has been a growing interest within CSCW community in understanding the\ncharacteristics of misinformation propagated through computational media, and\nthe devising techniques to address the associated challenges. However, most\nwork in this area has been concentrated on the cases in the western world\nleaving a major portion of this problem unaddressed that is situated in the\nGlobal South. This paper aims to broaden the scope of this discourse by\nfocusing on this problem in the context of Bangladesh, a country in the Global\nSouth. The spread of misinformation on Facebook in Bangladesh, a country with a\npopulation over 163 million, has resulted in chaos, hate attacks, and killings.\nBy interviewing journalists, fact-checkers, in addition to surveying the\ngeneral public, we analyzed the current state of verifying misinformation in\nBangladesh. Our findings show that most people in the `news audience' want the\nnews media to verify the authenticity of online information that they see\nonline. However, the newspaper journalists say that fact-checking online\ninformation is not a part of their job, and it is also beyond their capacity\ngiven the amount of information being published online everyday. We further\nfind that the voluntary fact-checkers in Bangladesh are not equipped with\nsufficient infrastructural support to fill in this gap. We show how our\nfindings are connected to some of the core concerns of CSCW community around\nsocial media, collaboration, infrastructural politics, and information\ninequality. From our analysis, we also suggest several pathways to increase the\nimpact of fact-checking efforts through collaboration, technology design, and\ninfrastructure development.", "author": [{"name": "Md Mahfuzul Haque"}, {"name": "Mohammad Yousuf"}, {"name": "Ahmed Shatil Alam"}, {"name": "Pratyasha Saha"}, {"name": "Syed Ishtiaque Ahmed"}, {"name": "Naeemul Hassan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3415201"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3415201", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.12841v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.12841v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1702.05638v1", "updated": "2017-02-18T18:10:04Z", "published": "2017-02-18T18:10:04Z", "title": "A Stylometric Inquiry into Hyperpartisan and Fake News", "summary": "This paper reports on a writing style analysis of hyperpartisan (i.e.,\nextremely one-sided) news in connection to fake news. It presents a large\ncorpus of 1,627 articles that were manually fact-checked by professional\njournalists from BuzzFeed. The articles originated from 9 well-known political\npublishers, 3 each from the mainstream, the hyperpartisan left-wing, and the\nhyperpartisan right-wing. In sum, the corpus contains 299 fake news, 97% of\nwhich originated from hyperpartisan publishers.\n  We propose and demonstrate a new way of assessing style similarity between\ntext categories via Unmasking---a meta-learning approach originally devised for\nauthorship verification---, revealing that the style of left-wing and\nright-wing news have a lot more in common than any of the two have with the\nmainstream. Furthermore, we show that hyperpartisan news can be discriminated\nwell by its style from the mainstream (F1=0.78), as can be satire from both\n(F1=0.81). Unsurprisingly, style-based fake news detection does not live up to\nscratch (F1=0.46). Nevertheless, the former results are important to implement\npre-screening for fake news detectors.", "author": [{"name": "Martin Potthast"}, {"name": "Johannes Kiesel"}, {"name": "Kevin Reinartz"}, {"name": "Janek Bevendorff"}, {"name": "Benno Stein"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 3 figures, 6 tables, submitted to ACL 2017"}, "link": [{"@href": "http://arxiv.org/abs/1702.05638v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1702.05638v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1307.2052v1", "updated": "2013-07-08T12:01:17Z", "published": "2013-07-08T12:01:17Z", "title": "Fact-checking Ziegler's maximum entropy production principle beyond the\n  linear regime and towards steady states", "summary": "We challenge claims that the principle of maximum entropy production produces\nphysical phenomenological relations between conjugate currents and forces, even\nbeyond the linear regime, and that currents in networks arrange themselves to\nmaximize entropy production as the system approaches the steady state. In\nparticular: (1) we show that Ziegler's principle of thermodynamic orthogonality\nleads to stringent reciprocal relations for higher order response coefficients,\nand in the framework of stochastic thermodynamics, we exhibit a simple explicit\nmodel that does not satisfy them; (2) on a network, enforcing Kirchhoff's\ncurrent law, we show that maximization of the entropy production prescribes\nreciprocal relations between coarse-grained observables, but is not responsible\nfor the onset of the steady state, which is rather due to the minimum entropy\nproduction principle.", "author": {"name": "Matteo Polettini"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.3390/e15072570"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.3390/e15072570", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1307.2052v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1307.2052v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "21 pages"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Entropy 2013, 15(7), 2570-2584"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cond-mat.stat-mech", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cond-mat.stat-mech", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1810.03775v1", "updated": "2018-10-09T02:15:48Z", "published": "2018-10-09T02:15:48Z", "title": "Rumor propagation meets skepticism: a parallel with zombies", "summary": "We propose a model of rumor spreading in which susceptible, but skeptically\noriented individuals may oppose the rumor. Resistance may be implemented either\nby skeptical activists trying to convince spreaders to stop their activity,\nbecoming stiflers or, passively (non-reactive) as a consequence, for example,\nof fact-checking. Interestingly, these two mechanisms, when combined, are\nsimilar to the (assumed) spreading of a fictitious zombie outbreak, where\nsurvivors actively target infected people. We analyse the well-mixed\n(mean-field) description and obtain the conditions for rumors (zombies) to\nspread through the whole population. The results show that when the skepticism\nis strong enough, the model predicts the coexistence of two fixed points (such\nbistability may be related to polarized situations), with the fate of rumors\ndepending on the initial exposure to it.", "author": [{"name": "Marco Antonio Amaral"}, {"name": "Jeferson J. Arenzon"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1209/0295-5075/124/18007"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1209/0295-5075/124/18007", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1810.03775v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1810.03775v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Europhysics Letters, Volume 124, Number 1, 2018"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cond-mat.stat-mech", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.bio-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1810.11663v1", "updated": "2018-10-27T15:24:15Z", "published": "2018-10-27T15:24:15Z", "title": "Suspicious News Detection Using Micro Blog Text", "summary": "We present a new task, suspicious news detection using micro blog text. This\ntask aims to support human experts to detect suspicious news articles to be\nverified, which is costly but a crucial step before verifying the truthfulness\nof the articles. Specifically, in this task, given a set of posts on SNS\nreferring to a news article, the goal is to judge whether the article is to be\nverified or not. For this task, we create a publicly available dataset in\nJapanese and provide benchmark results by using several basic machine learning\ntechniques. Experimental results show that our models can reduce the cost of\nmanual fact-checking process.", "author": [{"name": "Tsubasa Tagami"}, {"name": "Hiroki Ouchi"}, {"name": "Hiroki Asano"}, {"name": "Kazuaki Hanawa"}, {"name": "Kaori Uchiyama"}, {"name": "Kaito Suzuki"}, {"name": "Kentaro Inui"}, {"name": "Atsushi Komiya"}, {"name": "Atsuo Fujimura"}, {"name": "Hitofumi Yanai"}, {"name": "Ryo Yamashita"}, {"name": "Akinori Machino"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages; PACLIC 2018"}, "link": [{"@href": "http://arxiv.org/abs/1810.11663v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1810.11663v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1910.01990v1", "updated": "2019-10-04T15:28:01Z", "published": "2019-10-04T15:28:01Z", "title": "Detecting Deception in Political Debates Using Acoustic and Textual\n  Features", "summary": "We present work on deception detection, where, given a spoken claim, we aim\nto predict its factuality. While previous work in the speech community has\nrelied on recordings from staged setups where people were asked to tell the\ntruth or to lie and their statements were recorded, here we use real-world\npolitical debates. Thanks to the efforts of fact-checking organizations, it is\npossible to obtain annotations for statements in the context of a political\ndiscourse as true, half-true, or false. Starting with such data from the\nCLEF-2018 CheckThat! Lab, which was limited to text, we performed alignment to\nthe corresponding videos, thus producing a multimodal dataset. We further\ndeveloped a multimodal deep-learning architecture for the task of deception\ndetection, which yielded sizable improvements over the state of the art for the\nCLEF-2018 Lab task 2. Our experiments show that the use of the acoustic signal\nconsistently helped to improve the performance compared to using textual and\nmetadata features only, based on several different evaluation measures. We\nrelease the new dataset to the research community, hoping to help advance the\noverall field of multimodal deception detection.", "author": [{"name": "Daniel Kopev"}, {"name": "Ahmed Ali"}, {"name": "Ivan Koychev"}, {"name": "Preslav Nakov"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ASRU-2019"}, "link": [{"@href": "http://arxiv.org/abs/1910.01990v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.01990v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.AS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.08948v1", "updated": "2019-10-20T11:05:05Z", "published": "2019-10-20T11:05:05Z", "title": "Predicting the Leading Political Ideology of YouTube Channels Using\n  Acoustic, Textual, and Metadata Information", "summary": "We address the problem of predicting the leading political ideology, i.e.,\nleft-center-right bias, for YouTube channels of news media. Previous work on\nthe problem has focused exclusively on text and on analysis of the language\nused, topics discussed, sentiment, and the like. In contrast, here we study\nvideos, which yields an interesting multimodal setup. Starting with gold\nannotations about the leading political ideology of major world news media from\nMedia Bias/Fact Check, we searched on YouTube to find their corresponding\nchannels, and we downloaded a recent sample of videos from each channel. We\ncrawled more than 1,000 YouTube hours along with the corresponding subtitles\nand metadata, thus producing a new multimodal dataset. We further developed a\nmultimodal deep-learning architecture for the task. Our analysis shows that the\nuse of acoustic signal helped to improve bias detection by more than 6%\nabsolute over using text and metadata only. We release the dataset to the\nresearch community, hoping to help advance the field of multi-modal political\nbias detection.", "author": [{"name": "Yoan Dinkov"}, {"name": "Ahmed Ali"}, {"name": "Ivan Koychev"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "media bias, political ideology, Youtube channels, propaganda,\n  disinformation, fake news"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "INTERSPEECH-2019"}, "link": [{"@href": "http://arxiv.org/abs/1910.08948v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.08948v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SD", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.AS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.12840v1", "updated": "2019-10-28T17:51:44Z", "published": "2019-10-28T17:51:44Z", "title": "Evaluating the Factual Consistency of Abstractive Text Summarization", "summary": "Currently used metrics for assessing summarization algorithms do not account\nfor whether summaries are factually consistent with source documents. We\npropose a weakly-supervised, model-based approach for verifying factual\nconsistency and identifying conflicts between source documents and a generated\nsummary. Training data is generated by applying a series of rule-based\ntransformations to the sentences of source documents. The factual consistency\nmodel is then trained jointly for three tasks: 1) identify whether sentences\nremain factually consistent after transformation, 2) extract a span in the\nsource documents to support the consistency prediction, 3) extract a span in\nthe summary sentence that is inconsistent if one exists. Transferring this\nmodel to summaries generated by several state-of-the art models reveals that\nthis highly scalable approach substantially outperforms previous models,\nincluding those trained with strong supervision using standard datasets for\nnatural language inference and fact checking. Additionally, human evaluation\nshows that the auxiliary span extraction tasks provide useful assistance in the\nprocess of verifying factual consistency.", "author": [{"name": "Wojciech Kry\u015bci\u0144ski"}, {"name": "Bryan McCann"}, {"name": "Caiming Xiong"}, {"name": "Richard Socher"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 7 tables, 1 algorithm"}, "link": [{"@href": "http://arxiv.org/abs/1910.12840v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.12840v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1611.05425v1", "updated": "2016-11-16T20:09:08Z", "published": "2016-11-16T20:09:08Z", "title": "ProjE: Embedding Projection for Knowledge Graph Completion", "summary": "With the large volume of new information created every day, determining the\nvalidity of information in a knowledge graph and filling in its missing parts\nare crucial tasks for many researchers and practitioners. To address this\nchallenge, a number of knowledge graph completion methods have been developed\nusing low-dimensional graph embeddings. Although researchers continue to\nimprove these models using an increasingly complex feature space, we show that\nsimple changes in the architecture of the underlying model can outperform\nstate-of-the-art models without the need for complex feature engineering. In\nthis work, we present a shared variable neural network model called ProjE that\nfills-in missing information in a knowledge graph by learning joint embeddings\nof the knowledge graph's entities and edges, and through subtle, but important,\nchanges to the standard loss function. In doing so, ProjE has a parameter size\nthat is smaller than 11 out of 15 existing methods while performing $37\\%$\nbetter than the current-best method on standard datasets. We also show, via a\nnew fact checking task, that ProjE is capable of accurately determining the\nveracity of many declarative statements.", "author": [{"name": "Baoxu Shi"}, {"name": "Tim Weninger"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "14 pages, Accepted to AAAI 2017"}, "link": [{"@href": "http://arxiv.org/abs/1611.05425v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1611.05425v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1705.00648v1", "updated": "2017-05-01T18:20:47Z", "published": "2017-05-01T18:20:47Z", "title": "\"Liar, Liar Pants on Fire\": A New Benchmark Dataset for Fake News\n  Detection", "summary": "Automatic fake news detection is a challenging problem in deception\ndetection, and it has tremendous real-world political and social impacts.\nHowever, statistical approaches to combating fake news has been dramatically\nlimited by the lack of labeled benchmark datasets. In this paper, we present\nliar: a new, publicly available dataset for fake news detection. We collected a\ndecade-long, 12.8K manually labeled short statements in various contexts from\nPolitiFact.com, which provides detailed analysis report and links to source\ndocuments for each case. This dataset can be used for fact-checking research as\nwell. Notably, this new dataset is an order of magnitude larger than previously\nlargest public fake news datasets of similar type. Empirically, we investigate\nautomatic fake news detection based on surface-level linguistic patterns. We\nhave designed a novel, hybrid convolutional neural network to integrate\nmeta-data with text. We show that this hybrid approach can improve a text-only\ndeep learning model.", "author": {"name": "William Yang Wang"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL 2017"}, "link": [{"@href": "http://arxiv.org/abs/1705.00648v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1705.00648v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1707.03264v2", "updated": "2018-05-21T10:31:40Z", "published": "2017-07-11T13:44:51Z", "title": "A simple but tough-to-beat baseline for the Fake News Challenge stance\n  detection task", "summary": "Identifying public misinformation is a complicated and challenging task. An\nimportant part of checking the veracity of a specific claim is to evaluate the\nstance different news sources take towards the assertion. Automatic stance\nevaluation, i.e. stance detection, would arguably facilitate the process of\nfact checking. In this paper, we present our stance detection system which\nclaimed third place in Stage 1 of the Fake News Challenge. Despite our\nstraightforward approach, our system performs at a competitive level with the\ncomplex ensembles of the top two winning teams. We therefore propose our system\nas the 'simple but tough-to-beat baseline' for the Fake News Challenge stance\ndetection task.", "author": [{"name": "Benjamin Riedel"}, {"name": "Isabelle Augenstein"}, {"name": "Georgios P. Spithourakis"}, {"name": "Sebastian Riedel"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 1 figure, 3 tables; additional reference and details added,\n  typos and wording corrected"}, "link": [{"@href": "http://arxiv.org/abs/1707.03264v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1707.03264v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1806.01507v1", "updated": "2018-06-05T06:01:06Z", "published": "2018-06-05T06:01:06Z", "title": "Using the AIDA Language to Formally Organize Scientific Claims", "summary": "Scientific communication still mainly relies on natural language written in\nscientific papers, which makes the described knowledge very difficult to access\nwith automatic means. We can therefore only make limited use of formal\nknowledge organization methods to support researchers and other interested\nparties with features such as automatic aggregations, fact checking,\nconsistency checking, question answering, and powerful semantic search.\nExisting approaches to solve this problem by improving the scientific\ncommunication methods have either very restricted coverage, require formal\nlogic skills on the side of the researchers, or depend on unreliable machine\nlearning for the formalization of knowledge. Here, I propose an approach to\nthis problem that is general, intuitive, and flexible. It is based on a unique\nkind of controlled natural language, called AIDA, consisting of English\nsentences that are atomic, independent, declarative, and absolute. Such\nsentences can then serve as nodes in a network of scientific claims linked to\npublications, researchers, and domain elements. I present here some small\nstudies on preliminary applications of this language. The results indicate that\nit is well accepted by users and provides a good basis for the creation of a\nknowledge graph of scientific findings.", "author": {"name": "Tobias Kuhn"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear in the Proceedings of the Sixth International Workshop on\n  Controlled Natural Language (CNL 2018)"}, "link": [{"@href": "http://arxiv.org/abs/1806.01507v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.01507v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1809.06416v1", "updated": "2018-09-17T19:51:18Z", "published": "2018-09-17T19:51:18Z", "title": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning", "summary": "Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.", "author": [{"name": "Kashyap Popat"}, {"name": "Subhabrata Mukherjee"}, {"name": "Andrew Yates"}, {"name": "Gerhard Weikum"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EMNLP 2018"}, "link": [{"@href": "http://arxiv.org/abs/1809.06416v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.06416v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1903.05543v1", "updated": "2019-03-13T15:29:22Z", "published": "2019-03-13T15:29:22Z", "title": "Adversarial attacks against Fact Extraction and VERification", "summary": "This paper describes a baseline for the second iteration of the Fact\nExtraction and VERification shared task (FEVER2.0) which explores the\nresilience of systems through adversarial evaluation. We present a collection\nof simple adversarial attacks against systems that participated in the first\nFEVER shared task. FEVER modeled the assessment of truthfulness of written\nclaims as a joint information retrieval and natural language inference task\nusing evidence from Wikipedia. A large number of participants made use of deep\nneural networks in their submissions to the shared task. The extent as to\nwhether such models understand language has been the subject of a number of\nrecent investigations and discussion in literature. In this paper, we present a\nsimple method of generating entailment-preserving and entailment-altering\nperturbations of instances by common patterns within the training data. We find\nthat a number of systems are greatly affected with absolute losses in\nclassification accuracy of up to $29\\%$ on the newly perturbed instances. Using\nthese newly generated instances, we construct a sample submission for the\nFEVER2.0 shared task. Addressing these types of attacks will aid in building\nmore robust fact-checking models, as well as suggest directions to expand the\ndatasets.", "author": [{"name": "James Thorne"}, {"name": "Andreas Vlachos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Work in progress"}, "link": [{"@href": "http://arxiv.org/abs/1903.05543v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.05543v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.00542v1", "updated": "2019-04-01T02:54:54Z", "published": "2019-04-01T02:54:54Z", "title": "Multi-Task Ordinal Regression for Jointly Predicting the Trustworthiness\n  and the Leading Political Ideology of News Media", "summary": "In the context of fake news, bias, and propaganda, we study two important but\nrelatively under-explored problems: (i) trustworthiness estimation (on a\n3-point scale) and (ii) political ideology detection (left/right bias on a\n7-point scale) of entire news outlets, as opposed to evaluating individual\narticles. In particular, we propose a multi-task ordinal regression framework\nthat models the two problems jointly. This is motivated by the observation that\nhyper-partisanship is often linked to low trustworthiness, e.g., appealing to\nemotions rather than sticking to the facts, while center media tend to be\ngenerally more impartial and trustworthy. We further use several auxiliary\ntasks, modeling centrality, hyperpartisanship, as well as left-vs.-right bias\non a coarse-grained scale. The evaluation results show sizable performance\ngains by the joint models over models that target the problems in isolation.", "author": [{"name": "Ramy Baly", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIT Computer Science and Artificial Intelligence Laboratory, MA, USA"}}, {"name": "Georgi Karadzhov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SiteGround Hosting EOOD, Bulgaria"}}, {"name": "Abdelrhman Saleh", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Harvard University, MA, USA"}}, {"name": "James Glass", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIT Computer Science and Artificial Intelligence Laboratory, MA, USA"}}, {"name": "Preslav Nakov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Qatar Computing Research Institute, HBKU, Qatar"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Fact-checking, political ideology, news media, NAACL-2019"}, "link": [{"@href": "http://arxiv.org/abs/1904.00542v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.00542v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.00957v1", "updated": "2019-05-02T20:50:22Z", "published": "2019-05-02T20:50:22Z", "title": "A Topic-Agnostic Approach for Identifying Fake News Pages", "summary": "Fake news and misinformation have been increasingly used to manipulate\npopular opinion and influence political processes. To better understand fake\nnews, how they are propagated, and how to counter their effect, it is necessary\nto first identify them. Recently, approaches have been proposed to\nautomatically classify articles as fake based on their content. An important\nchallenge for these approaches comes from the dynamic nature of news: as new\npolitical events are covered, topics and discourse constantly change and thus,\na classifier trained using content from articles published at a given time is\nlikely to become ineffective in the future. To address this challenge, we\npropose a topic-agnostic (TAG) classification strategy that uses linguistic and\nweb-markup features to identify fake news pages. We report experimental results\nusing multiple data sets which show that our approach attains high accuracy in\nthe identification of fake news, even as topics evolve over time.", "author": [{"name": "Sonia Castelo"}, {"name": "Thais Almeida"}, {"name": "Anas Elghafari"}, {"name": "A\u00e9cio Santos"}, {"name": "Kien Pham"}, {"name": "Eduardo Nakamura"}, {"name": "Juliana Freire"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3308560.3316739"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3308560.3316739", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1905.00957v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.00957v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication in the Companion Proceedings of the 2019\n  World Wide Web Conference (WWW'19 Companion). Presented in the 2019\n  International Workshop on Misinformation, Computational Fact-Checking and\n  Credible Web (MisinfoWorkshop2019). 6 pages"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1907.00435v2", "updated": "2019-09-13T18:04:08Z", "published": "2019-06-30T19:14:17Z", "title": "YouTube Chatter: Understanding Online Comments Discourse on\n  Misinformative and Political YouTube Videos", "summary": "We conduct a preliminary analysis of comments on political YouTube content\ncontaining misinformation in comparison to comments on trustworthy or\napolitical videos, labelling the bias and factual ratings of our channels\naccording to Media Bias Fact Check where applicable. One of our most\ninteresting discoveries is that especially-polarized or misinformative\npolitical channels (Left-Bias, Right-Bias, PragerU, Conspiracy-Pseudoscience,\nand Questionable Source) generate 7.5x more comments per view and 10.42x more\nreplies per view than apolitical or Pro-Science channels; in particular,\nConspiracy-Pseudoscience and Questionable Sources generate 8.3x more comments\nper view and 11.0x more replies per view than apolitical and Pro-Science\nchannels. We also compared average thread lengths, average comment lengths, and\nprofanity rates across channels, and present simple machine learning\nclassifiers for predicting the bias category of a video based on these\nstatistics.", "author": [{"name": "Aarash Heydari"}, {"name": "Janny Zhang"}, {"name": "Shaan Appel"}, {"name": "Xinyi Wu"}, {"name": "Gireeja Ranade"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "32 pages, 23 figures. Primary contributors: Aarash Heydari and Janny\n  Zhang. These authors contributed equally to the work"}, "link": [{"@href": "http://arxiv.org/abs/1907.00435v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.00435v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1907.01260v2", "updated": "2020-05-21T08:15:22Z", "published": "2019-07-02T09:39:43Z", "title": "Predicting the Topical Stance of Media and Popular Twitter Users", "summary": "Discovering the stances of media outlets and influential people on current,\ndebatable topics is important for social statisticians and policy makers. Many\nsupervised solutions exist for determining viewpoints, but manually annotating\ntraining data is costly. In this paper, we propose a cascaded method that uses\nunsupervised learning to ascertain the stance of Twitter users with respect to\na polarizing topic by leveraging their retweet behavior; then, it uses\nsupervised learning based on user labels to characterize both the general\npolitical leaning of online media and of popular Twitter users, as well as\ntheir stance with respect to the target polarizing topic. We evaluate the model\nby comparing its predictions to gold labels from the Media Bias/Fact Check\nwebsite, achieving 82.6% accuracy.", "author": [{"name": "Peter Stefanov"}, {"name": "Kareem Darwish"}, {"name": "Atanas Atanasov"}, {"name": "Preslav Nakov"}], "link": [{"@href": "http://arxiv.org/abs/1907.01260v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.01260v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "91D30", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.09785v1", "updated": "2019-08-26T16:37:03Z", "published": "2019-08-26T16:37:03Z", "title": "Detecting Toxicity in News Articles: Application to Bulgarian", "summary": "Online media aim for reaching ever bigger audience and for attracting ever\nlonger attention span. This competition creates an environment that rewards\nsensational, fake, and toxic news. To help limit their spread and impact, we\npropose and develop a news toxicity detector that can recognize various types\nof toxic content. While previous research primarily focused on English, here we\ntarget Bulgarian. We created a new dataset by crawling a website that for five\nyears has been collecting Bulgarian news articles that were manually\ncategorized into eight toxicity groups. Then we trained a multi-class\nclassifier with nine categories: eight toxic and one non-toxic. We experimented\nwith different representations based on ElMo, BERT, and XLM, as well as with a\nvariety of domain-specific features. Due to the small size of our dataset, we\ncreated a separate model for each feature type, and we ultimately combined\nthese models into a meta-classifier. The evaluation results show an accuracy of\n59.0% and a macro-F1 score of 39.7%, which represent sizable improvements over\nthe majority-class baseline (Acc=30.3%, macro-F1=5.2%).", "author": [{"name": "Yoan Dinkov"}, {"name": "Ivan Koychev"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Fact-checking, source reliability, political ideology, news media,\n  Bulgarian, RANLP-2019. arXiv admin note: text overlap with arXiv:1810.01765"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RANLP-2019"}, "link": [{"@href": "http://arxiv.org/abs/1908.09785v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.09785v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.13838v2", "updated": "2019-12-02T23:39:02Z", "published": "2019-09-30T17:02:57Z", "title": "Automatic Fact-guided Sentence Modification", "summary": "Online encyclopediae like Wikipedia contain large amounts of text that need\nfrequent corrections and updates. The new information may contradict existing\ncontent in encyclopediae. In this paper, we focus on rewriting such dynamically\nchanging articles. This is a challenging constrained generation task, as the\noutput must be consistent with the new information and fit into the rest of the\nexisting document. To this end, we propose a two-step solution: (1) We identify\nand remove the contradicting components in a target text for a given claim,\nusing a neutralizing stance model; (2) We expand the remaining text to be\nconsistent with the given claim, using a novel two-encoder sequence-to-sequence\nmodel with copy attention. Applied to a Wikipedia fact update dataset, our\nmethod successfully generates updated sentences for new claims, achieving the\nhighest SARI score. Furthermore, we demonstrate that generating synthetic data\nthrough such rewritten sentences can successfully augment the FEVER\nfact-checking training dataset, leading to a relative error reduction of 13%.", "author": [{"name": "Darsh J Shah"}, {"name": "Tal Schuster"}, {"name": "Regina Barzilay"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AAAI 2020"}, "link": [{"@href": "http://arxiv.org/abs/1909.13838v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.13838v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1911.02541v3", "updated": "2020-04-28T01:33:49Z", "published": "2019-11-06T18:25:00Z", "title": "Optimizing the Factual Correctness of a Summary: A Study of Summarizing\n  Radiology Reports", "summary": "Neural abstractive summarization models are able to generate summaries which\nhave high overlap with human references. However, existing models are not\noptimized for factual correctness, a critical metric in real-world\napplications. In this work, we develop a general framework where we evaluate\nthe factual correctness of a generated summary by fact-checking it\nautomatically against its reference using an information extraction module. We\nfurther propose a training strategy which optimizes a neural summarization\nmodel with a factual correctness reward via reinforcement learning. We apply\nthe proposed method to the summarization of radiology reports, where factual\ncorrectness is a key requirement. On two separate datasets collected from\nhospitals, we show via both automatic and human evaluation that the proposed\napproach substantially improves the factual correctness and overall quality of\noutputs over a competitive neural summarization system, producing radiology\nsummaries that approach the quality of human-authored ones.", "author": [{"name": "Yuhao Zhang"}, {"name": "Derek Merck"}, {"name": "Emily Bao Tsai"}, {"name": "Christopher D. Manning"}, {"name": "Curtis P. Langlotz"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL2020. 13 pages with appendices"}, "link": [{"@href": "http://arxiv.org/abs/1911.02541v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.02541v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1911.08125v1", "updated": "2019-11-19T07:06:22Z", "published": "2019-11-19T07:06:22Z", "title": "In Search of Credible News", "summary": "We study the problem of finding fake online news. This is an important\nproblem as news of questionable credibility have recently been proliferating in\nsocial media at an alarming scale. As this is an understudied problem,\nespecially for languages other than English, we first collect and release to\nthe research community three new balanced credible vs. fake news datasets\nderived from four online sources. We then propose a language-independent\napproach for automatically distinguishing credible from fake news, based on a\nrich feature set. In particular, we use linguistic (n-gram),\ncredibility-related (capitalization, punctuation, pronoun use, sentiment\npolarity), and semantic (embeddings and DBPedia data) features. Our experiments\non three different testsets show that our model can distinguish credible from\nfake news with very high accuracy.", "author": [{"name": "Momchil Hardalov"}, {"name": "Ivan Koychev"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Credibility, veracity, fact checking, humor detection"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AIMSA-2016"}, "link": [{"@href": "http://arxiv.org/abs/1911.08125v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.08125v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.06423v1", "updated": "2020-01-17T16:46:17Z", "published": "2020-01-17T16:46:17Z", "title": "InChorus: Designing Consistent Multimodal Interactions for Data\n  Visualization on Tablet Devices", "summary": "While tablet devices are a promising platform for data visualization,\nsupporting consistent interactions across different types of visualizations on\ntablets remains an open challenge. In this paper, we present multimodal\ninteractions that function consistently across different visualizations,\nsupporting common operations during visual data analysis. By considering\nstandard interface elements (e.g., axes, marks) and grounding our design in a\nset of core concepts including operations, parameters, targets, and\ninstruments, we systematically develop interactions applicable to different\nvisualization types. To exemplify how the proposed interactions collectively\nfacilitate data exploration, we employ them in a tablet-based system, InChorus\nthat supports pen, touch, and speech input. Based on a study with 12\nparticipants performing replication and fact-checking tasks with InChorus, we\ndiscuss how participants adapted to using multimodal input and highlight\nconsiderations for future multimodal visualization systems.", "author": [{"name": "Arjun Srinivasan"}, {"name": "Bongshin Lee"}, {"name": "Nathalie Henry Riche"}, {"name": "Steven M. Drucker"}, {"name": "Ken Hinckley"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear in ACM CHI 2020 Conference on Human Factors in Computing\n  Systems; 13 pages (10 content + 3 references); 4 Figures, 1 Table"}, "link": [{"@href": "http://arxiv.org/abs/2001.06423v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.06423v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2001.10560v1", "updated": "2020-01-28T19:12:37Z", "published": "2020-01-28T19:12:37Z", "title": "The KEEN Universe: An Ecosystem for Knowledge Graph Embeddings with a\n  Focus on Reproducibility and Transferability", "summary": "There is an emerging trend of embedding knowledge graphs (KGs) in continuous\nvector spaces in order to use those for machine learning tasks. Recently, many\nknowledge graph embedding (KGE) models have been proposed that learn low\ndimensional representations while trying to maintain the structural properties\nof the KGs such as the similarity of nodes depending on their edges to other\nnodes. KGEs can be used to address tasks within KGs such as the prediction of\nnovel links and the disambiguation of entities. They can also be used for\ndownstream tasks like question answering and fact-checking. Overall, these\ntasks are relevant for the semantic web community. Despite their popularity,\nthe reproducibility of KGE experiments and the transferability of proposed KGE\nmodels to research fields outside the machine learning community can be a major\nchallenge. Therefore, we present the KEEN Universe, an ecosystem for knowledge\ngraph embeddings that we have developed with a strong focus on reproducibility\nand transferability. The KEEN Universe currently consists of the Python\npackages PyKEEN (Python KnowlEdge EmbeddiNgs), BioKEEN (Biological KnowlEdge\nEmbeddiNgs), and the KEEN Model Zoo for sharing trained KGE models with the\ncommunity.", "author": [{"name": "Mehdi Ali"}, {"name": "Hajira Jabeen"}, {"name": "Charles Tapley Hoyt"}, {"name": "Jens Lehman"}], "link": [{"@href": "http://arxiv.org/abs/2001.10560v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.10560v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.11104v1", "updated": "2020-02-24T20:04:54Z", "published": "2020-02-24T20:04:54Z", "title": "An Information Diffusion Approach to Rumor Propagation and\n  Identification on Twitter", "summary": "With the increasing use of online social networks as a source of news and\ninformation, the propensity for a rumor to disseminate widely and quickly poses\na great concern, especially in disaster situations where users do not have\nenough time to fact-check posts before making the informed decision to react to\na post that appears to be credible. In this study, we explore the propagation\npattern of rumors on Twitter by exploring the dynamics of microscopic-level\nmisinformation spread, based on the latent message and user interaction\nattributes. We perform supervised learning for feature selection and\nprediction. Experimental results with real-world data sets give the models'\nprediction accuracy at about 90\\% for the diffusion of both True and False\ntopics. Our findings confirm that rumor cascades run deeper and that rumor\nmasked as news, and messages that incite fear, will diffuse faster than other\nmessages. We show that the models for True and False message propagation differ\nsignificantly, both in the prediction parameters and in the message features\nthat govern the diffusion. Finally, we show that the diffusion pattern is an\nimportant metric in identifying the credibility of a tweet.", "author": [{"name": "Abiola Osho"}, {"name": "Caden Waters"}, {"name": "George Amariucai"}], "link": [{"@href": "http://arxiv.org/abs/2002.11104v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.11104v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.06708v1", "updated": "2020-03-14T21:28:43Z", "published": "2020-03-14T21:28:43Z", "title": "Scrutinizer: A Mixed-Initiative Approach to Large-Scale, Data-Driven\n  Claim Verification", "summary": "Organizations such as the International Energy Agency (IEA) spend significant\namounts of time and money to manually fact check text documents summarizing\ndata. The goal of the Scrutinizer system is to reduce verification overheads by\nsupporting human fact checkers in translating text claims into SQL queries on\nan associated database.\n  Scrutinizer coordinates teams of human fact checkers. It reduces verification\ntime by proposing queries or query fragments to the users. Those proposals are\nbased on claim text classifiers, that gradually improve during the verification\nof a large document. In addition, Scrutinizer uses tentative execution of query\ncandidates to narrow down the set of alternatives. The verification process is\ncontrolled by a cost-based optimizer. It optimizes the interaction with users\nand prioritizes claim verifications. For the latter, it considers expected\nverification overheads as well as the expected claim utility as training\nsamples for the classifiers. We evaluate the Scrutinizer system using\nsimulations and a user study, based on actual claims and data and using\nprofessional fact checkers employed by IEA. Our experiments consistently\ndemonstrate significant savings in verification time, without reducing result\naccuracy.", "author": [{"name": "Georgios Karagiannis"}, {"name": "Mohammed Saeed"}, {"name": "Paolo Papotti"}, {"name": "Immanuel Trummer"}], "link": [{"@href": "http://arxiv.org/abs/2003.06708v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.06708v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2003.07684v5", "updated": "2020-09-28T22:53:39Z", "published": "2020-02-28T18:40:54Z", "title": "Identifying Disinformation Websites Using Infrastructure Features", "summary": "Platforms have struggled to keep pace with the spread of disinformation.\nCurrent responses like user reports, manual analysis, and third-party fact\nchecking are slow and difficult to scale, and as a result, disinformation can\nspread unchecked for some time after being created. Automation is essential for\nenabling platforms to respond rapidly to disinformation. In this work, we\nexplore a new direction for automated detection of disinformation websites:\ninfrastructure features. Our hypothesis is that while disinformation websites\nmay be perceptually similar to authentic news websites, there may also be\nsignificant non-perceptual differences in the domain registrations, TLS/SSL\ncertificates, and web hosting configurations. Infrastructure features are\nparticularly valuable for detecting disinformation websites because they are\navailable before content goes live and reaches readers, enabling early\ndetection. We demonstrate the feasibility of our approach on a large corpus of\nlabeled website snapshots. We also present results from a preliminary real-time\ndeployment, successfully discovering disinformation websites while highlighting\nunexplored challenges for automated disinformation detection.", "author": [{"name": "Austin Hounsel"}, {"name": "Jordan Holland"}, {"name": "Ben Kaiser"}, {"name": "Kevin Borgolte"}, {"name": "Nick Feamster"}, {"name": "Jonathan Mayer"}], "link": [{"@href": "http://arxiv.org/abs/2003.07684v5", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.07684v5", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.00777v1", "updated": "2020-04-02T02:22:45Z", "published": "2020-04-02T02:22:45Z", "title": "Skepticism and rumor spreading: the role of spatial correlations", "summary": "Critical thinking and skepticism are fundamental mechanisms that one may use\nto prevent the spreading of rumors, fake-news and misinformation. We consider a\nsimple model in which agents without previous contact with the rumor, being\nskeptically oriented, may convince spreaders to stop their activity or, once\nexposed to the rumor, decide not to propagate it as a consequence, for example,\nof fact-checking. We extend a previous, mean-field analysis of the combined\neffect of these two mechanisms, active and passive skepticism, to include\nspatial correlations. This can be done either analytically, through the pair\napproximation, or simulating an agent-based version on diverse networks. Our\nresults show that while in mean-field there is no coexistence between spreaders\nand susceptibles (although, depending on the parameters, there may be\nbistability depending on the initial conditions), when spatial correlations are\nincluded, because of the protective effect of the isolation provided by removed\nagents, coexistence is possible.", "author": [{"name": "Marco Antonio Amaral"}, {"name": "W. G. Dantas"}, {"name": "Jeferson J. Arenzon"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevE.101.062418"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevE.101.062418", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.00777v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.00777v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 6 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys. Rev. E 101, 062418 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cond-mat.stat-mech", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.09600v1", "updated": "2020-04-20T19:56:48Z", "published": "2020-04-20T19:56:48Z", "title": "Why do People Share Misinformation during the COVID-19 Pandemic?", "summary": "The World Health Organization have emphasised that misinformation - spreading\nrapidly through social media - poses a serious threat to the COVID-19 response.\nDrawing from theories of health perception and cognitive load, we develop and\ntest a research model hypothesizing why people share unverified COVID-19\ninformation through social media. Our findings suggest a person's trust in\nonline information and perceived information overload are strong predictors of\nunverified information sharing. Furthermore, these factors, along with a\nperson's perceived COVID-19 severity and vulnerability influence cyberchondria.\nFemales were significantly more likely to suffer from cyberchondria, however,\nmales were more likely to share news without fact checking their source. Our\nfindings suggest that to mitigate the spread of COVID-19 misinformation and\ncyberchondria, measures should be taken to enhance a healthy skepticism of\nhealth news while simultaneously guarding against information overload.", "author": [{"name": "Samuli Laato"}, {"name": "A. K. M. Najmul Islam"}, {"name": "Muhammad Nazrul Islam"}, {"name": "Eoin Whelan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1080/0960085X.2020.1770632"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1080/0960085X.2020.1770632", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.09600v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.09600v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "European Journal of Information Systems (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.13878v2", "updated": "2020-05-01T10:59:41Z", "published": "2020-04-28T22:31:18Z", "title": "Analyzing Political Parody in Social Media", "summary": "Parody is a figurative device used to imitate an entity for comedic or\ncritical purposes and represents a widespread phenomenon in social media\nthrough many popular parody accounts. In this paper, we present the first\ncomputational study of parody. We introduce a new publicly available data set\nof tweets from real politicians and their corresponding parody accounts. We run\na battery of supervised machine learning models for automatically detecting\nparody tweets with an emphasis on robustness by testing on tweets from accounts\nunseen in training, across different genders and across countries. Our results\nshow that political parody tweets can be predicted with an accuracy up to 90%.\nFinally, we identify the markers of parody through a linguistic analysis.\nBeyond research in linguistics and political communication, accurately and\nautomatically detecting parody is important to improving fact checking for\njournalists and analytics such as sentiment analysis through filtering out\nparodical utterances.", "author": [{"name": "Antonis Maronikolakis"}, {"name": "Danae Sanchez Villegas"}, {"name": "Daniel Preotiuc-Pietro"}, {"name": "Nikolaos Aletras"}], "link": [{"@href": "http://arxiv.org/abs/2004.13878v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.13878v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.10414v1", "updated": "2020-05-21T01:34:08Z", "published": "2020-05-21T01:34:08Z", "title": "Analysis of misinformation during the COVID-19 outbreak in China:\n  cultural, social and political entanglements", "summary": "COVID-19 resulted in an infodemic, which could erode public trust, impede\nvirus containment, and outlive the pandemic itself. The evolving and fragmented\nmedia landscape is a key driver of the spread of misinformation. Using\nmisinformation identified by the fact-checking platform by Tencent and posts on\nWeibo, our results showed that the evolution of misinformation follows an\nissue-attention cycle, pertaining to topics such as city lockdown, cures, and\npreventions, and school reopening. Sources of authority weigh in on these\ntopics, but their influence is complicated by peoples' pre-existing beliefs and\ncultural practices. Finally, social media has a complicated relationship with\nestablished or legacy media systems. Sometimes they reinforce each other, but\nin general, social media may have a topic cycle of its own making. Our findings\nshed light on the distinct characteristics of misinformation during the\nCOVID-19 and offer insights into combating misinformation in China and across\nthe world at large.", "author": [{"name": "Yan Leng"}, {"name": "Yujia Zhai"}, {"name": "Shaojing Sun"}, {"name": "Yifei Wu"}, {"name": "Jordan Selzer"}, {"name": "Sharon Strover"}, {"name": "Julia Fensel"}, {"name": "Alex Pentland"}, {"name": "Ying Ding"}], "link": [{"@href": "http://arxiv.org/abs/2005.10414v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.10414v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.02774v1", "updated": "2020-06-30T21:07:34Z", "published": "2020-06-30T21:07:34Z", "title": "The role of time scale in the spreading of asymmetrically interacting\n  diseases", "summary": "Diseases and other contagion phenomena in nature and society can interact\nasymmetrically, such that one can benefit from the other, which in turn impairs\nthe first, in analogy with predator-prey systems. Here, we consider two models\nfor interacting disease-like dynamics with asymmetric interactions and\ndifferent associated time scales. Using rate equations for homogeneously mixed\npopulations, we show that the stationary prevalences and phase diagrams of each\nmodel behave differently with respect to variations of the relative time\nscales. We also characterize in detail the regime where transient oscillations\nare observed, a pattern that is inherent to asymmetrical interactions but often\nignored in the literature. Our results contribute to a better understanding of\ndisease dynamics in particular, and interacting processes in general, and could\nprovide interesting insights for real-world applications, most notably, the\ninterplay between the dynamics of fact-checked and fake news.", "author": [{"name": "Paulo Cesar Ventura"}, {"name": "Yamir Moreno"}, {"name": "Francisco A. Rodrigues"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevResearch.3.013146"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevResearch.3.013146", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.02774v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.02774v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages and 8 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys. Rev. Research 3, 013146 (2021)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.08821v2", "updated": "2020-08-07T13:33:15Z", "published": "2020-07-17T08:36:26Z", "title": "Tackling scalability issues in mining path patterns from knowledge\n  graphs: a preliminary study", "summary": "Features mined from knowledge graphs are widely used within multiple\nknowledge discovery tasks such as classification or fact-checking. Here, we\nconsider a given set of vertices, called seed vertices, and focus on mining\ntheir associated neighboring vertices, paths, and, more generally, path\npatterns that involve classes of ontologies linked with knowledge graphs. Due\nto the combinatorial nature and the increasing size of real-world knowledge\ngraphs, the task of mining these patterns immediately entails scalability\nissues. In this paper, we address these issues by proposing a pattern mining\napproach that relies on a set of constraints (e.g., support or degree\nthresholds) and the monotonicity property. As our motivation comes from the\nmining of real-world knowledge graphs, we illustrate our approach with PGxLOD,\na biomedical knowledge graph.", "author": [{"name": "Pierre Monnin"}, {"name": "Emmanuel Bresso"}, {"name": "Miguel Couceiro"}, {"name": "Malika Sma\u00efl-Tabbone"}, {"name": "Amedeo Napoli"}, {"name": "Adrien Coulet"}], "link": [{"@href": "http://arxiv.org/abs/2007.08821v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.08821v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.14083v1", "updated": "2020-07-28T09:32:41Z", "published": "2020-07-28T09:32:41Z", "title": "Universal Fake News Collection System using Debunking Tweets", "summary": "Large numbers of people use Social Networking Services (SNS) for easy access\nto various news, but they have more opportunities to obtain and share ``fake\nnews'' carrying false information. Partially to combat fake news, several\nfact-checking sites such as Snopes and PolitiFact have been founded.\nNevertheless, these sites rely on time-consuming and labor-intensive tasks.\nMoreover, their available languages are not extensive. To address these\ndifficulties, we propose a new fake news collection system based on rule-based\n(unsupervised) frameworks that can be extended easily for various languages.\nThe system collects news with high probability of being fake by debunking\ntweets by users and presents event clusters gathering higher attention. Our\nsystem currently functions in two languages: English and Japanese. It shows\nevent clusters, 65\\% of which are actually fake. In future studies, it will be\napplied to other languages and will be published with a large fake news\ndataset.", "author": [{"name": "Taichi Murayama"}, {"name": "Shoko Wakamiya"}, {"name": "Eiji Aramaki"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5pages, 2 figures"}, "link": [{"@href": "http://arxiv.org/abs/2007.14083v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.14083v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2008.13160v1", "updated": "2020-08-30T13:03:53Z", "published": "2020-08-30T13:03:53Z", "title": "QMUL-SDS at CheckThat! 2020: Determining COVID-19 Tweet Check-Worthiness\n  Using an Enhanced CT-BERT with Numeric Expressions", "summary": "This paper describes the participation of the QMUL-SDS team for Task 1 of the\nCLEF 2020 CheckThat! shared task. The purpose of this task is to determine the\ncheck-worthiness of tweets about COVID-19 to identify and prioritise tweets\nthat need fact-checking. The overarching aim is to further support ongoing\nefforts to protect the public from fake news and help people find reliable\ninformation. We describe and analyse the results of our submissions. We show\nthat a CNN using COVID-Twitter-BERT (CT-BERT) enhanced with numeric expressions\ncan effectively boost performance from baseline results. We also show results\nof training data augmentation with rumours on other topics. Our best system\nranked fourth in the task with encouraging outcomes showing potential for\nimproved results in the future.", "author": [{"name": "Rabab Alkhalifa"}, {"name": "Theodore Yoong"}, {"name": "Elena Kochkina"}, {"name": "Arkaitz Zubiaga"}, {"name": "Maria Liakata"}], "link": [{"@href": "http://arxiv.org/abs/2008.13160v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.13160v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.08768v2", "updated": "2021-03-13T20:26:35Z", "published": "2020-10-17T11:21:40Z", "title": "ArCOV19-Rumors: Arabic COVID-19 Twitter Dataset for Misinformation\n  Detection", "summary": "In this paper we introduce ArCOV19-Rumors, an Arabic COVID-19 Twitter dataset\nfor misinformation detection composed of tweets containing claims from 27th\nJanuary till the end of April 2020. We collected 138 verified claims, mostly\nfrom popular fact-checking websites, and identified 9.4K relevant tweets to\nthose claims. Tweets were manually-annotated by veracity to support research on\nmisinformation detection, which is one of the major problems faced during a\npandemic. ArCOV19-Rumors supports two levels of misinformation detection over\nTwitter: verifying free-text claims (called claim-level verification) and\nverifying claims expressed in tweets (called tweet-level verification). Our\ndataset covers, in addition to health, claims related to other topical\ncategories that were influenced by COVID-19, namely, social, politics, sports,\nentertainment, and religious. Moreover, we present benchmarking results for\ntweet-level verification on the dataset. We experimented with SOTA models of\nversatile approaches that either exploit content, user profiles features,\ntemporal features and propagation structure of the conversational threads for\ntweet verification.", "author": [{"name": "Fatima Haouari"}, {"name": "Maram Hasanain"}, {"name": "Reem Suwaileh"}, {"name": "Tamer Elsayed"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This work was accepted at the Sixth Arabic Natural Language\n  Processing Workshop (EACL/WANLP 2021)"}, "link": [{"@href": "http://arxiv.org/abs/2010.08768v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.08768v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.12758v2", "updated": "2020-12-15T01:13:08Z", "published": "2020-11-25T14:22:36Z", "title": "Encounters with Visual Misinformation and Labels Across Platforms: An\n  Interview and Diary Study to Inform Ecosystem Approaches to Misinformation\n  Interventions", "summary": "Since 2016, the amount of academic research with the keyword \"misinformation\"\nhas more than doubled [2]. This research often focuses on article headlines\nshown in artificial testing environments, yet misinformation largely spreads\nthrough images and video posts shared in highly-personalized platform contexts.\nA foundation of qualitative research is necessary to begin filling this gap to\nensure platforms' visual misinformation interventions are aligned with users'\nneeds and understanding of information in their personal contexts, across\nplatforms. In two studies, we combined in-depth interviews (n=15) with diary\nand co-design methods (n=23) to investigate how a broad mix of Americans\nexposed to misinformation during COVID-19 understand their visual information\nenvironments, including encounters with interventions such as Facebook\nfact-checking labels. Analysis reveals a deep division in user attitudes about\nplatform labeling interventions for visual information which are perceived by\nmany as overly paternalistic, biased, and punitive. Alongside these findings,\nwe discuss our methods as a model for continued independent qualitative\nresearch on cross-platform user experiences of misinformation that inform\ninterventions.", "author": [{"name": "Emily Saltz"}, {"name": "Claire Leibowicz"}, {"name": "Claire Wardle"}], "link": [{"@href": "http://arxiv.org/abs/2011.12758v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.12758v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.15115v2", "updated": "2021-08-20T14:36:42Z", "published": "2020-12-30T11:22:31Z", "title": "Joint Verification and Reranking for Open Fact Checking Over Tables", "summary": "Structured information is an important knowledge source for automatic\nverification of factual claims. Nevertheless, the majority of existing research\ninto this task has focused on textual data, and the few recent inquiries into\nstructured data have been for the closed-domain setting where appropriate\nevidence for each claim is assumed to have already been retrieved. In this\npaper, we investigate verification over structured data in the open-domain\nsetting, introducing a joint reranking-and-verification model which fuses\nevidence documents in the verification component. Our open-domain model\nachieves performance comparable to the closed-domain state-of-the-art on the\nTabFact dataset, and demonstrates performance gains from the inclusion of\nmultiple tables as well as a significant improvement over a heuristic retrieval\nbaseline.", "author": [{"name": "Michael Schlichtkrull"}, {"name": "Vladimir Karpukhin"}, {"name": "Barlas O\u011fuz"}, {"name": "Mike Lewis"}, {"name": "Wen-tau Yih"}, {"name": "Sebastian Riedel"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.18653/v1/2021.acl-long.529"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.18653/v1/2021.acl-long.529", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2012.15115v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.15115v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.15788v2", "updated": "2021-06-11T16:23:26Z", "published": "2020-12-31T18:11:26Z", "title": "Evidence-based Factual Error Correction", "summary": "This paper introduces the task of factual error correction: performing edits\nto a claim so that the generated rewrite is better supported by evidence. This\nextends the well-studied task of fact verification by providing a mechanism to\ncorrect written texts that are refuted or only partially supported by evidence.\nWe demonstrate that it is feasible to train factual error correction systems\nfrom existing fact checking datasets which only contain labeled claims\naccompanied by evidence, but not the correction. We achieve this by employing a\ntwo-stage distant supervision approach that incorporates evidence into masked\nclaims when generating corrections. Our approach, based on the T5 transformer\nand using retrieved evidence, achieved better results than existing work which\nused a pointer copy network and gold evidence, producing accurate factual error\ncorrections for 5x more instances in human evaluation and a .125 increase in\nSARI score. The evaluation is conducted on a dataset of 65,000 instances based\non a recent fact verification shared task and we release it to enable further\nwork on the task.", "author": [{"name": "James Thorne"}, {"name": "Andreas Vlachos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at ACL2021"}, "link": [{"@href": "http://arxiv.org/abs/2012.15788v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.15788v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.00117v1", "updated": "2021-01-01T00:16:34Z", "published": "2021-01-01T00:16:34Z", "title": "Multi-task Retrieval for Knowledge-Intensive Tasks", "summary": "Retrieving relevant contexts from a large corpus is a crucial step for tasks\nsuch as open-domain question answering and fact checking. Although neural\nretrieval outperforms traditional methods like tf-idf and BM25, its performance\ndegrades considerably when applied to out-of-domain data.\n  Driven by the question of whether a neural retrieval model can be universal\nand perform robustly on a wide variety of problems, we propose a multi-task\ntrained model. Our approach not only outperforms previous methods in the\nfew-shot setting, but also rivals specialised neural retrievers, even when\nin-domain training data is abundant. With the help of our retriever, we improve\nexisting models for downstream tasks and closely match or improve the state of\nthe art on multiple benchmarks.", "author": [{"name": "Jean Maillard"}, {"name": "Vladimir Karpukhin"}, {"name": "Fabio Petroni"}, {"name": "Wen-tau Yih"}, {"name": "Barlas O\u011fuz"}, {"name": "Veselin Stoyanov"}, {"name": "Gargi Ghosh"}], "link": [{"@href": "http://arxiv.org/abs/2101.00117v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.00117v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.05626v1", "updated": "2021-01-09T22:52:21Z", "published": "2021-01-09T22:52:21Z", "title": "Eating Garlic Prevents COVID-19 Infection: Detecting Misinformation on\n  the Arabic Content of Twitter", "summary": "The rapid growth of social media content during the current pandemic provides\nuseful tools for disseminating information which has also become a root for\nmisinformation. Therefore, there is an urgent need for fact-checking and\neffective techniques for detecting misinformation in social media. In this\nwork, we study the misinformation in the Arabic content of Twitter. We\nconstruct a large Arabic dataset related to COVID-19 misinformation and\ngold-annotate the tweets into two categories: misinformation or not. Then, we\napply eight different traditional and deep machine learning models, with\ndifferent features including word embeddings and word frequency. The word\nembedding models (\\textsc{FastText} and word2vec) exploit more than two million\nArabic tweets related to COVID-19. Experiments show that optimizing the area\nunder the curve (AUC) improves the models' performance and the Extreme Gradient\nBoosting (XGBoost) presents the highest accuracy in detecting COVID-19\nmisinformation online.", "author": [{"name": "Sarah Alqurashi"}, {"name": "Btool Hamoui"}, {"name": "Abdulaziz Alashaikh"}, {"name": "Ahmad Alhindi"}, {"name": "Eisa Alanazi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "18 pages, 4 figures"}, "link": [{"@href": "http://arxiv.org/abs/2101.05626v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.05626v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.00509v1", "updated": "2021-01-31T18:23:05Z", "published": "2021-01-31T18:23:05Z", "title": "TruthBot: An Automated Conversational Tool for Intent Learning, Curated\n  Information Presenting, and Fake News Alerting", "summary": "We present TruthBot, an all-in-one multilingual conversational chatbot\ndesigned for seeking truth (trustworthy and verified information) on specific\ntopics. It helps users to obtain information specific to certain topics,\nfact-check information, and get recent news. The chatbot learns the intent of a\nquery by training a deep neural network from the data of the previous intents\nand responds appropriately when it classifies the intent in one of the classes\nabove. Each class is implemented as a separate module that uses either its own\ncurated knowledge-base or searches the web to obtain the correct information.\nThe topic of the chatbot is currently set to COVID-19. However, the bot can be\neasily customized to any topic-specific responses. Our experimental results\nshow that each module performs significantly better than its closest\ncompetitor, which is verified both quantitatively and through several\nuser-based surveys in multiple languages. TruthBot has been deployed in June\n2020 and is currently running.", "author": [{"name": "Ankur Gupta"}, {"name": "Yash Varun"}, {"name": "Prarthana Das"}, {"name": "Nithya Muttineni"}, {"name": "Parth Srivastava"}, {"name": "Hamim Zafar"}, {"name": "Tanmoy Chakraborty"}, {"name": "Swaprava Nath"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "17 pages, 11 images"}, "link": [{"@href": "http://arxiv.org/abs/2102.00509v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.00509v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.04567v1", "updated": "2021-02-08T22:55:37Z", "published": "2021-02-08T22:55:37Z", "title": "NELA-GT-2020: A Large Multi-Labelled News Dataset for The Study of\n  Misinformation in News Articles", "summary": "In this paper, we present an updated version of the NELA-GT-2019 dataset,\nentitled NELA-GT-2020. NELA-GT-2020 contains nearly 1.8M news articles from 519\nsources collected between January 1st, 2020 and December 31st, 2020. Just as\nwith NELA-GT-2018 and NELA-GT-2019, these sources come from a wide range of\nmainstream news sources and alternative news sources. Included in the dataset\nare source-level ground truth labels from Media Bias/Fact Check (MBFC) covering\nmultiple dimensions of veracity. Additionally, new in the 2020 dataset are the\nTweets embedded in the collected news articles, adding an extra layer of\ninformation to the data. The NELA-GT-2020 dataset can be found at\nhttps://doi.org/10.7910/DVN/CHMUYZ.", "author": [{"name": "Maur\u00edcio Gruppi"}, {"name": "Benjamin D. Horne"}, {"name": "Sibel Adal\u0131"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2003.08444"}, "link": [{"@href": "http://arxiv.org/abs/2102.04567v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.04567v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.04627v1", "updated": "2021-02-09T03:25:57Z", "published": "2021-02-09T03:25:57Z", "title": "SCARLET: Explainable Attention based Graph Neural Network for Fake News\n  spreader prediction", "summary": "False information and true information fact checking it, often co-exist in\nsocial networks, each competing to influence people in their spread paths. An\nefficient strategy here to contain false information is to proactively identify\nif nodes in the spread path are likely to endorse false information (i.e.\nfurther spread it) or refutation information (thereby help contain false\ninformation spreading). In this paper, we propose SCARLET (truSt and\nCredibility bAsed gRaph neuraL nEtwork model using aTtention) to predict likely\naction of nodes in the spread path. We aggregate trust and credibility features\nfrom a node's neighborhood using historical behavioral data and network\nstructure and explain how features of a spreader's neighborhood vary. Using\nreal world Twitter datasets, we show that the model is able to predict false\ninformation spreaders with an accuracy of over 87%.", "author": [{"name": "Bhavtosh Rath"}, {"name": "Xavier Morales"}, {"name": "Jaideep Srivastava"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the Pacific-Asia Conference on Knowledge Discovery and\n  Data Mining (PAKDD, 2021)"}, "link": [{"@href": "http://arxiv.org/abs/2102.04627v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.04627v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.11362v1", "updated": "2021-02-22T21:06:52Z", "published": "2021-02-22T21:06:52Z", "title": "An ontological analysis of misinformation in online social networks", "summary": "The internet, Online Social Networks (OSNs) and smart phones enable users to\ncreate tremendous amount of information. Users who search for general or\nspecific knowledge may not have these days problems of information scarce but\nmisinformation. Misinformation nowadays can refer to a continuous spectrum\nbetween what can be seen as \"facts\" or \"truth\", if humans agree on the\nexistence of such, to false information that everyone agree that it is false.\nIn this paper, we will look at this spectrum of information/misinformation and\ncompare between some of the major relevant concepts. While few fact-checking\nwebsites exist to evaluate news articles or some of the popular claims people\nexchange, nonetheless this can be seen as a little effort in the mission to tag\nonline information with their \"proper\" category or label.", "author": [{"name": "Izzat Alsmadi"}, {"name": "Iyad Alazzam"}, {"name": "Mohammad A. AlRamahi"}], "link": [{"@href": "http://arxiv.org/abs/2102.11362v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.11362v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2103.08541v1", "updated": "2021-03-15T17:05:13Z", "published": "2021-03-15T17:05:13Z", "title": "Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence", "summary": "Typical fact verification models use retrieved written evidence to verify\nclaims. Evidence sources, however, often change over time as more information\nis gathered and revised. In order to adapt, models must be sensitive to subtle\ndifferences in supporting evidence. We present VitaminC, a benchmark infused\nwith challenging cases that require fact verification models to discern and\nadjust to slight factual changes. We collect over 100,000 Wikipedia revisions\nthat modify an underlying fact, and leverage these revisions, together with\nadditional synthetically constructed ones, to create a total of over 400,000\nclaim-evidence pairs. Unlike previous resources, the examples in VitaminC are\ncontrastive, i.e., they contain evidence pairs that are nearly identical in\nlanguage and content, with the exception that one supports a given claim while\nthe other does not. We show that training using this design increases\nrobustness -- improving accuracy by 10% on adversarial fact verification and 6%\non adversarial natural language inference (NLI). Moreover, the structure of\nVitaminC leads us to define additional tasks for fact-checking resources:\ntagging relevant words in the evidence for verifying the claim, identifying\nfactual revisions, and providing automatic edits via factually consistent text\ngeneration.", "author": [{"name": "Tal Schuster"}, {"name": "Adam Fisch"}, {"name": "Regina Barzilay"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NAACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2103.08541v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.08541v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.05866v1", "updated": "2021-04-12T23:46:54Z", "published": "2021-04-12T23:46:54Z", "title": "On Representation Learning for Scientific News Articles Using\n  Heterogeneous Knowledge Graphs", "summary": "In the era of misinformation and information inflation, the credibility\nassessment of the produced news is of the essence. However, fact-checking can\nbe challenging considering the limited references presented in the news. This\nchallenge can be transcended by utilizing the knowledge graph that is related\nto the news articles. In this work, we present a methodology for creating\nscientific news article representations by modeling the directed graph between\nthe scientific news articles and the cited scientific publications. The network\nused for the experiments is comprised of the scientific news articles, their\ntopic, the cited research literature, and their corresponding authors. We\nimplement and present three different approaches: 1) a baseline Relational\nGraph Convolutional Network (R-GCN), 2) a Heterogeneous Graph Neural Network\n(HetGNN) and 3) a Heterogeneous Graph Transformer (HGT). We test these models\nin the downstream task of link prediction on the: a) news article - paper links\nand b) news article - article topic links. The results show promising\napplications of graph neural network approaches in the domains of knowledge\ntracing and scientific news credibility assessment.", "author": [{"name": "Angelika Romanou"}, {"name": "Panayiotis Smeros"}, {"name": "Karl Aberer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3442442.3451362"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3442442.3451362", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2104.05866v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.05866v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.08790v1", "updated": "2021-04-18T09:50:11Z", "published": "2021-04-18T09:50:11Z", "title": "Misinfo Belief Frames: A Case Study on Covid & Climate News", "summary": "Prior beliefs of readers impact the way in which they project meaning onto\nnews headlines. These beliefs can influence their perception of news\nreliability, as well as their reaction to news, and their likelihood of\nspreading the misinformation through social networks. However, most prior work\nfocuses on fact-checking veracity of news or stylometry rather than measuring\nimpact of misinformation. We propose Misinfo Belief Frames, a formalism for\nunderstanding how readers perceive the reliability of news and the impact of\nmisinformation. We also introduce the Misinfo Belief Frames (MBF) corpus, a\ndataset of 66k inferences over 23.5k headlines. Misinformation frames use\ncommonsense reasoning to uncover implications of real and fake news headlines\nfocused on global crises: the Covid-19 pandemic and climate change. Our results\nusing large-scale language modeling to predict misinformation frames show that\nmachine-generated inferences can influence readers' trust in news headlines\n(readers' trust in news headlines was affected in 29.3% of cases). This\ndemonstrates the potential effectiveness of using generated frames to counter\nmisinformation.", "author": [{"name": "Saadia Gabriel"}, {"name": "Skyler Hallinan"}, {"name": "Maarten Sap"}, {"name": "Pemi Nguyen"}, {"name": "Franziska Roesner"}, {"name": "Eunsol Choi"}, {"name": "Yejin Choi"}], "link": [{"@href": "http://arxiv.org/abs/2104.08790v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.08790v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.11639v2", "updated": "2021-05-01T18:22:39Z", "published": "2021-04-23T14:45:31Z", "title": "Claim Detection in Biomedical Twitter Posts", "summary": "Social media contains unfiltered and unique information, which is potentially\nof great value, but, in the case of misinformation, can also do great harm.\nWith regards to biomedical topics, false information can be particularly\ndangerous. Methods of automatic fact-checking and fake news detection address\nthis problem, but have not been applied to the biomedical domain in social\nmedia yet. We aim to fill this research gap and annotate a corpus of 1200\ntweets for implicit and explicit biomedical claims (the latter also with span\nannotations for the claim phrase). With this corpus, which we sample to be\nrelated to COVID-19, measles, cystic fibrosis, and depression, we develop\nbaseline models which detect tweets that contain a claim automatically. Our\nanalyses reveal that biomedical tweets are densely populated with claims (45 %\nin a corpus sampled to contain 1200 tweets focused on the domains mentioned\nabove). Baseline classification experiments with embedding-based classifiers\nand BERT-based transfer learning demonstrate that the detection is challenging,\nhowever, shows acceptable performance for the identification of explicit\nexpressions of claims. Implicit claim tweets are more challenging to detect.", "author": [{"name": "Amelie W\u00fchrl"}, {"name": "Roman Klinger"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at the BioNLP Workshop at NAACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.11639v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.11639v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.13748v1", "updated": "2021-04-28T13:28:27Z", "published": "2021-04-28T13:28:27Z", "title": "QuTI! Quantifying Text-Image Consistency in Multimodal Documents", "summary": "The World Wide Web and social media platforms have become popular sources for\nnews and information. Typically, multimodal information, e.g., image and text\nis used to convey information more effectively and to attract attention. While\nin most cases image content is decorative or depicts additional information, it\nhas also been leveraged to spread misinformation and rumors in recent years. In\nthis paper, we present a Web-based demo application that automatically\nquantifies the cross-modal relations of entities (persons, locations, and\nevents) in image and text. The applications are manifold. For example, the\nsystem can help users to explore multimodal articles more efficiently, or can\nassist human assessors and fact-checking efforts in the verification of the\ncredibility of news stories, tweets, or other multimodal documents.", "author": [{"name": "Matthias Springstein"}, {"name": "Eric M\u00fcller-Budack"}, {"name": "Ralph Ewerth"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication in: International ACM SIGIR Conference on\n  Research and Development in Information Retrieval 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.13748v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13748v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.13816v1", "updated": "2021-04-28T15:04:22Z", "published": "2021-04-28T15:04:22Z", "title": "The Evolution of Rumors on a Closed Platform during COVID-19", "summary": "In this work we looked into a dataset of 114 thousands of suspicious messages\ncollected from the most popular closed messaging platform in Taiwan between\nJanuary and July, 2020. We proposed an hybrid algorithm that could efficiently\ncluster a large number of text messages according their topics and narratives.\nThat is, we obtained groups of messages that are within a limited content\nalterations within each other. By employing the algorithm to the dataset, we\nwere able to look at the content alterations and the temporal dynamics of each\nparticular rumor over time. With qualitative case studies of three COVID-19\nrelated rumors, we have found that key authoritative figures were often\nmisquoted in false information. It was an effective measure to increase the\npopularity of one false information. In addition, fact-check was not effective\nin stopping misinformation from getting attention. In fact, the popularity of\none false information was often more influenced by major societal events and\neffective content alterations.", "author": [{"name": "Andrea W Wang", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Information Operations Research Group"}}, {"name": "Jo-Yu Lan", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Department of Information Engineering and Computer Science, Feng Chia University"}}, {"name": "Chihhao Yu", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Information Operations Research Group"}}, {"name": "Ming-Hung Wang", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Department of Information Engineering and Computer Science, Feng Chia University"}}], "link": [{"@href": "http://arxiv.org/abs/2104.13816v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13816v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.03143v1", "updated": "2021-05-07T09:52:44Z", "published": "2021-05-07T09:52:44Z", "title": "AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News and Hate Speech\n  Detection Dataset", "summary": "Along with the COVID-19 pandemic, an \"infodemic\" of false and misleading\ninformation has emerged and has complicated the COVID-19 response efforts.\nSocial networking sites such as Facebook and Twitter have contributed largely\nto the spread of rumors, conspiracy theories, hate, xenophobia, racism, and\nprejudice. To combat the spread of fake news, researchers around the world have\nand are still making considerable efforts to build and share COVID-19 related\nresearch articles, models, and datasets. This paper releases \"AraCOVID19-MFH\" a\nmanually annotated multi-label Arabic COVID-19 fake news and hate speech\ndetection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10\ndifferent labels. The labels have been designed to consider some aspects\nrelevant to the fact-checking task, such as the tweet's check worthiness,\npositivity/negativity, and factuality. To confirm our annotated dataset's\npractical utility, we used it to train and evaluate several classification\nmodels and reported the obtained results. Though the dataset is mainly designed\nfor fake news detection, it can also be used for hate speech detection,\nopinion/news classification, dialect identification, and many other tasks.", "author": [{"name": "Mohamed Seghir Hadj Ameur"}, {"name": "Hassina Aliane"}], "link": [{"@href": "http://arxiv.org/abs/2105.03143v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.03143v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.00142v1", "updated": "2021-05-31T23:20:58Z", "published": "2021-05-31T23:20:58Z", "title": "FBAdTracker: An Interactive Data Collection and Analysis Tool for\n  Facebook Advertisements", "summary": "The growing use of social media has led to drastic changes in our\ndecision-making. Especially, Facebook offers marketing API which promotes\nbusiness to target potential groups who are likely to consume their items.\nHowever, this service can be abused by malicious advertisers who attempt to\ndeceive people by disinformation such as propaganda and divisive opinion. To\ncounter this problem, we introduce a new application named FBAdTracker. The\npurpose of this application is to provide an integrated data collection and\nanalysis system for current research on fact-checking related to Facebook\nadvertisements. Our system is capable of monitoring up-to-date Facebook ads and\nanalyzing ads retrieved from Facebook Ads Library.", "author": [{"name": "Ujun Jeong"}, {"name": "Kaize Ding"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "3 pages, 1 figure, 2021 International Conference on Social Computing,\n  Behavioral-Cultural Modeling, & Prediction and Behavior Representation in\n  Modeling and Simulation, demo track"}, "link": [{"@href": "http://arxiv.org/abs/2106.00142v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.00142v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.01072v2", "updated": "2021-06-17T10:29:43Z", "published": "2021-06-02T11:00:17Z", "title": "Evidence-based Factual Error Correction", "summary": "This paper introduces the task of factual error correction: performing edits\nto a claim so that the generated rewrite is better supported by evidence. This\nextends the well-studied task of fact verification by providing a mechanism to\ncorrect written texts that are refuted or only partially supported by evidence.\nWe demonstrate that it is feasible to train factual error correction systems\nfrom existing fact checking datasets which only contain labeled claims\naccompanied by evidence, but not the correction. We achieve this by employing a\ntwo-stage distant supervision approach that incorporates evidence into masked\nclaims when generating corrections. Our approach, based on the T5 transformer\nand using retrieved evidence, achieved better results than existing work which\nused a pointer copy network and gold evidence, producing accurate factual error\ncorrections for 5x more instances in human evaluation and a .125 increase in\nSARI score. The evaluation is conducted on a dataset of 65,000 instances based\non a recent fact verification shared task and we release it to enable further\nwork on the task.", "author": [{"name": "James Thorne"}, {"name": "Andreas Vlachos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Uploaded as a new paper in error. Please see the replacement of arxiv\n  paper 2012.15788v2 for this version: arXiv:2012.15788"}, "link": [{"@href": "http://arxiv.org/abs/2106.01072v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.01072v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.06830v1", "updated": "2021-06-12T18:27:18Z", "published": "2021-06-12T18:27:18Z", "title": "Evaluating Entity Disambiguation and the Role of Popularity in\n  Retrieval-Based NLP", "summary": "Retrieval is a core component for open-domain NLP tasks. In open-domain\ntasks, multiple entities can share a name, making disambiguation an inherent\nyet under-explored problem. We propose an evaluation benchmark for assessing\nthe entity disambiguation capabilities of these retrievers, which we call\nAmbiguous Entity Retrieval (AmbER) sets. We define an AmbER set as a collection\nof entities that share a name along with queries about those entities. By\ncovering the set of entities for polysemous names, AmbER sets act as a\nchallenging test of entity disambiguation. We create AmbER sets for three\npopular open-domain tasks: fact checking, slot filling, and question answering,\nand evaluate a diverse set of retrievers. We find that the retrievers exhibit\npopularity bias, significantly under-performing on rarer entities that share a\nname, e.g., they are twice as likely to retrieve erroneous documents on queries\nfor the less popular entity under the same name. These experiments on AmbER\nsets show their utility as an evaluation tool and highlight the weaknesses of\npopular retrieval systems.", "author": [{"name": "Anthony Chen"}, {"name": "Pallavi Gudipati"}, {"name": "Shayne Longpre"}, {"name": "Xiao Ling"}, {"name": "Sameer Singh"}], "link": [{"@href": "http://arxiv.org/abs/2106.06830v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.06830v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.08684v1", "updated": "2021-06-16T10:44:29Z", "published": "2021-06-16T10:44:29Z", "title": "Infodemics on Youtube: Reliability of Content and Echo Chambers on\n  COVID-19", "summary": "Social media radically changed how information is consumed and reported.\nMoreover, social networks elicited a disintermediated access to an\nunprecedented amount of content. The world health organization (WHO) coined the\nterm infodemics to identify the information overabundance during an epidemic.\nIndeed, the spread of inaccurate and misleading information may alter behaviors\nand complicate crisis management and health responses. This paper addresses\ninformation diffusion during the COVID-19 pandemic period with a massive data\nanalysis on YouTube. First, we analyze more than 2M users' engagement in 13000\nvideos released by 68 different YouTube channels, with different political bias\nand fact-checking indexes. We then investigate the relationship between each\nuser's political preference and her/his consumption of questionable/reliable\ninformation. Our results, quantified using information theory measures, provide\nevidence for the existence of echo chambers across two dimensions represented\nby the political bias and by the trustworthiness of information channels.\nFinally, we observe that the echo chamber structure cannot be reproduced after\nproperly randomizing the users' interaction patterns.", "author": [{"name": "Niccol\u00f2 Di Marco"}, {"name": "Matteo Cinelli"}, {"name": "Walter Quattrociocchi"}], "link": [{"@href": "http://arxiv.org/abs/2106.08684v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.08684v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.15221v2", "updated": "2021-06-30T05:00:20Z", "published": "2021-06-29T10:05:47Z", "title": "Fact Check: Analyzing Financial Events from Multilingual News Sources", "summary": "The explosion in the sheer magnitude and complexity of financial news data in\nrecent years makes it increasingly challenging for investment analysts to\nextract valuable insights and perform analysis. We propose FactCheck in\nfinance, a web-based news aggregator with deep learning models, to provide\nanalysts with a holistic view of important financial events from multilingual\nnews sources and extract events using an unsupervised clustering method. A web\ninterface is provided to examine the credibility of news articles using a\ntransformer-based fact-checker. The performance of the fact checker is\nevaluated using a dataset related to merger and acquisition (M\\&A) events and\nis shown to outperform several strong baselines.", "author": [{"name": "Linyi Yang"}, {"name": "Tin Lok James Ng"}, {"name": "Barry Smyth"}, {"name": "Ruihai Dong"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Demo"}, "link": [{"@href": "http://arxiv.org/abs/2106.15221v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.15221v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.02012v1", "updated": "2021-07-01T11:07:47Z", "published": "2021-07-01T11:07:47Z", "title": "Tackling COVID-19 Infodemic using Deep Learning", "summary": "Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia.", "author": [{"name": "Prathmesh Pathwar"}, {"name": "Simran Gill"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages, 4 figures, Accepted in 4th International Conference on\n  Computational Intelligence and Data Engineering"}, "link": [{"@href": "http://arxiv.org/abs/2107.02012v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.02012v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.03731v1", "updated": "2021-08-08T20:52:45Z", "published": "2021-08-08T20:52:45Z", "title": "Leveraging Commonsense Knowledge on Classifying False News and\n  Determining Checkworthiness of Claims", "summary": "Widespread and rapid dissemination of false news has made fact-checking an\nindispensable requirement. Given its time-consuming and labor-intensive nature,\nthe task calls for an automated support to meet the demand. In this paper, we\npropose to leverage commonsense knowledge for the tasks of false news\nclassification and check-worthy claim detection. Arguing that commonsense\nknowledge is a factor in human believability, we fine-tune the BERT language\nmodel with a commonsense question answering task and the aforementioned tasks\nin a multi-task learning environment. For predicting fine-grained false news\ntypes, we compare the proposed fine-tuned model's performance with the false\nnews classification models on a public dataset as well as a newly collected\ndataset. We compare the model's performance with the single-task BERT model and\na state-of-the-art check-worthy claim detection tool to evaluate the\ncheck-worthy claim detection. Our experimental analysis demonstrates that\ncommonsense knowledge can improve performance in both tasks.", "author": [{"name": "Ipek Baris Schlicht"}, {"name": "Erhan Sezerer"}, {"name": "Selma Tekir"}, {"name": "Oul Han"}, {"name": "Zeyd Boukhers"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "20 pages, 8 figures"}, "link": [{"@href": "http://arxiv.org/abs/2108.03731v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.03731v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.05419v1", "updated": "2021-08-11T19:13:04Z", "published": "2021-08-11T19:13:04Z", "title": "NoFake at CheckThat! 2021: Fake News Detection Using BERT", "summary": "Much research has been done for debunking and analysing fake news. Many\nresearchers study fake news detection in the last year, but many are limited to\nsocial media data. Currently, multiples fact-checkers are publishing their\nresults in various formats. Also, multiple fact-checkers use different labels\nfor the fake news, making it difficult to make a generalisable classifier. With\nthe merge classes, the performance of the machine model can be enhanced. This\ndomain categorisation will help group the article, which will help save the\nmanual effort in assigning the claim verification. In this paper, we have\npresented BERT based classification model to predict the domain and\nclassification. We have also used additional data from fact-checked articles.\nWe have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B\nusing the additional training data.", "author": {"name": "Sushma Kumari"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF Task 3"}, "link": [{"@href": "http://arxiv.org/abs/2108.05419v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.05419v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.09025v2", "updated": "2018-03-02T16:57:43Z", "published": "2017-11-24T15:53:37Z", "title": "Fake News Detection in Social Networks via Crowd Signals", "summary": "Our work considers leveraging crowd signals for detecting fake news and is\nmotivated by tools recently introduced by Facebook that enable users to flag\nfake news. By aggregating users' flags, our goal is to select a small subset of\nnews every day, send them to an expert (e.g., via a third-party fact-checking\norganization), and stop the spread of news identified as fake by an expert. The\nmain objective of our work is to minimize the spread of misinformation by\nstopping the propagation of fake news in the network. It is especially\nchallenging to achieve this objective as it requires detecting fake news with\nhigh-confidence as quickly as possible. We show that in order to leverage\nusers' flags efficiently, it is crucial to learn about users' flagging\naccuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian\ninference for detecting fake news and jointly learns about users' flagging\naccuracy over time. Our algorithm employs posterior sampling to actively trade\noff exploitation (selecting news that maximize the objective value at a given\nepoch) and exploration (selecting news that maximize the value of information\ntowards learning about users' flagging accuracy). We demonstrate the\neffectiveness of our approach via extensive experiments and show the power of\nleveraging community signals for fake news detection.", "author": [{"name": "Sebastian Tschiatschek"}, {"name": "Adish Singla"}, {"name": "Manuel Gomez Rodriguez"}, {"name": "Arpit Merchant"}, {"name": "Andreas Krause"}], "link": [{"@href": "http://arxiv.org/abs/1711.09025v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.09025v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1801.06510v2", "updated": "2018-01-23T14:41:34Z", "published": "2018-01-19T17:54:22Z", "title": "Image Provenance Analysis at Scale", "summary": "Prior art has shown it is possible to estimate, through image processing and\ncomputer vision techniques, the types and parameters of transformations that\nhave been applied to the content of individual images to obtain new images.\nGiven a large corpus of images and a query image, an interesting further step\nis to retrieve the set of original images whose content is present in the query\nimage, as well as the detailed sequences of transformations that yield the\nquery image given the original images. This is a problem that recently has\nreceived the name of image provenance analysis. In these times of public media\nmanipulation ( e.g., fake news and meme sharing), obtaining the history of\nimage transformations is relevant for fact checking and authorship\nverification, among many other applications. This article presents an\nend-to-end processing pipeline for image provenance analysis, which works at\nreal-world scale. It employs a cutting-edge image filtering solution that is\ncustom-tailored for the problem at hand, as well as novel techniques for\nobtaining the provenance graph that expresses how the images, as nodes, are\nancestrally connected. A comprehensive set of experiments for each stage of the\npipeline is provided, comparing the proposed solution with state-of-the-art\nresults, employing previously published datasets. In addition, this work\nintroduces a new dataset of real-world provenance cases from the social media\nsite Reddit, along with baseline results.", "author": [{"name": "Daniel Moreira"}, {"name": "Aparna Bharati"}, {"name": "Joel Brogan"}, {"name": "Allan Pinto"}, {"name": "Michael Parowski"}, {"name": "Kevin W. Bowyer"}, {"name": "Patrick J. Flynn"}, {"name": "Anderson Rocha"}, {"name": "Walter J. Scheirer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/1801.06510v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1801.06510v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.01938v1", "updated": "2018-11-05T10:46:45Z", "published": "2018-11-05T10:46:45Z", "title": "A personal model of trumpery: Deception detection in a real-world\n  high-stakes setting", "summary": "Language use reveals information about who we are and how we feel1-3. One of\nthe pioneers in text analysis, Walter Weintraub, manually counted which types\nof words people used in medical interviews and showed that the frequency of\nfirst-person singular pronouns (i.e., I, me, my) was a reliable indicator of\ndepression, with depressed people using I more often than people who are not\ndepressed4. Several studies have demonstrated that language use also differs\nbetween truthful and deceptive statements5-7, but not all differences are\nconsistent across people and contexts, making prediction difficult8. Here we\nshow how well linguistic deception detection performs at the individual level\nby developing a model tailored to a single individual: the current US\npresident. Using tweets fact-checked by an independent third party (Washington\nPost), we found substantial linguistic differences between factually correct\nand incorrect tweets and developed a quantitative model based on these\ndifferences. Next, we predicted whether out-of-sample tweets were either\nfactually correct or incorrect and achieved a 73% overall accuracy. Our results\ndemonstrate the power of linguistic analysis in real-world deception research\nwhen applied at the individual level and provide evidence that factually\nincorrect tweets are not random mistakes of the sender.", "author": [{"name": "Sophie van der Zee"}, {"name": "Ronald Poppe"}, {"name": "Alice Havrileck"}, {"name": "Aurelien Baillon"}], "link": [{"@href": "http://arxiv.org/abs/1811.01938v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.01938v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.07039v1", "updated": "2018-11-16T21:37:59Z", "published": "2018-11-16T21:37:59Z", "title": "Combining Fact Extraction and Verification with Neural Semantic Matching\n  Networks", "summary": "The increasing concern with misinformation has stimulated research efforts on\nautomatic fact checking. The recently-released FEVER dataset introduced a\nbenchmark fact-verification task in which a system is asked to verify a claim\nusing evidential sentences from Wikipedia documents. In this paper, we present\na connected system consisting of three homogeneous neural semantic matching\nmodels that conduct document retrieval, sentence selection, and claim\nverification jointly for fact extraction and verification. For evidence\nretrieval (document retrieval and sentence selection), unlike traditional\nvector space IR models in which queries and sources are matched in some\npre-designed term vector space, we develop neural models to perform deep\nsemantic matching from raw textual input, assuming no intermediate term\nrepresentation and no access to structured external knowledge bases. We also\nshow that Pageview frequency can also help improve the performance of evidence\nretrieval results, that later can be matched by using our neural semantic\nmatching network. For claim verification, unlike previous approaches that\nsimply feed upstream retrieved evidence and the claim to a natural language\ninference (NLI) model, we further enhance the NLI model by providing it with\ninternal semantic relatedness scores (hence integrating it with the evidence\nretrieval modules) and ontological WordNet features. Experiments on the FEVER\ndataset indicate that (1) our neural semantic matching method outperforms\npopular TF-IDF and encoder models, by significant margins on all evidence\nretrieval metrics, (2) the additional relatedness score and WordNet features\nimprove the NLI model via better semantic awareness, and (3) by formalizing all\nthree subtasks as a similar semantic matching problem and improving on all\nthree stages, the complete model is able to achieve the state-of-the-art\nresults on the FEVER test set.", "author": [{"name": "Yixin Nie"}, {"name": "Haonan Chen"}, {"name": "Mohit Bansal"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AAAI 2019"}, "link": [{"@href": "http://arxiv.org/abs/1811.07039v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.07039v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1701.04221v1", "updated": "2017-01-16T09:59:45Z", "published": "2017-01-16T09:59:45Z", "title": "It's Always April Fools' Day! On the Difficulty of Social Network\n  Misinformation Classification via Propagation Features", "summary": "Given the huge impact that Online Social Networks (OSN) had in the way people\nget informed and form their opinion, they became an attractive playground for\nmalicious entities that want to spread misinformation, and leverage their\neffect. In fact, misinformation easily spreads on OSN and is a huge threat for\nmodern society, possibly influencing also the outcome of elections, or even\nputting people's life at risk (e.g., spreading \"anti-vaccines\" misinformation).\nTherefore, it is of paramount importance for our society to have some sort of\n\"validation\" on information spreading through OSN. The need for a wide-scale\nvalidation would greatly benefit from automatic tools.\n  In this paper, we show that it is difficult to carry out an automatic\nclassification of misinformation considering only structural properties of\ncontent propagation cascades. We focus on structural properties, because they\nwould be inherently difficult to be manipulated, with the the aim of\ncircumventing classification systems. To support our claim, we carry out an\nextensive evaluation on Facebook posts belonging to conspiracy theories (as\nrepresentative of misinformation), and scientific news (representative of\nfact-checked content). Our findings show that conspiracy content actually\nreverberates in a way which is hard to distinguish from the one scientific\ncontent does: for the classification mechanisms we investigated, classification\nF1-score never exceeds 0.65 during content propagation stages, and is still\nless than 0.7 even after propagation is complete.", "author": [{"name": "Mauro Conti"}, {"name": "Daniele Lain"}, {"name": "Riccardo Lazzeretti"}, {"name": "Giulio Lovisotto"}, {"name": "Walter Quattrociocchi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/1701.04221v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1701.04221v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1707.03778v1", "updated": "2017-07-12T15:55:20Z", "published": "2017-07-12T15:55:20Z", "title": "Catching Zika Fever: Application of Crowdsourcing and Machine Learning\n  for Tracking Health Misinformation on Twitter", "summary": "In February 2016, World Health Organization declared the Zika outbreak a\nPublic Health Emergency of International Concern. With developing evidence it\ncan cause birth defects, and the Summer Olympics coming up in the worst\naffected country, Brazil, the virus caught fire on social media. In this work,\nuse Zika as a case study in building a tool for tracking the misinformation\naround health concerns on Twitter. We collect more than 13 million tweets --\nspanning the initial reports in February 2016 and the Summer Olympics --\nregarding the Zika outbreak and track rumors outlined by the World Health\nOrganization and Snopes fact checking website. The tool pipeline, which\nincorporates health professionals, crowdsourcing, and machine learning, allows\nus to capture health-related rumors around the world, as well as clarification\ncampaigns by reputable health organizations. In the case of Zika, we discover\nan extremely bursty behavior of rumor-related topics, and show that, once the\nquestionable topic is detected, it is possible to identify rumor-bearing tweets\nusing automated techniques. Thus, we illustrate insights the proposed tools\nprovide into potentially harmful information on social media, allowing public\nhealth researchers and practitioners to respond with a targeted and timely\naction.", "author": [{"name": "Amira Ghenai"}, {"name": "Yelena Mejova"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 7 figures, short version to be published in the Fifth IEEE\n  International Conference on Healthcare Informatics (ICHI 2017)"}, "link": [{"@href": "http://arxiv.org/abs/1707.03778v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1707.03778v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68P20", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8; H.3.3; I.2.7; J.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1804.07686v2", "updated": "2018-08-30T18:27:55Z", "published": "2018-04-20T15:46:05Z", "title": "Verifying Text Summaries of Relational Data Sets", "summary": "We present a novel natural language query interface, the AggChecker, aimed at\ntext summaries of relational data sets. The tool focuses on natural language\nclaims that translate into an SQL query and a claimed query result. Similar in\nspirit to a spell checker, the AggChecker marks up text passages that seem to\nbe inconsistent with the actual data. At the heart of the system is a\nprobabilistic model that reasons about the input document in a holistic\nfashion. Based on claim keywords and the document structure, it maps each text\nclaim to a probability distribution over associated query translations. By\nefficiently executing tens to hundreds of thousands of candidate translations\nfor a typical input document, the system maps text claims to correctness\nprobabilities. This process becomes practical via a specialized processing\nbackend, avoiding redundant work via query merging and result caching.\nVerification is an interactive process in which users are shown tentative\nresults, enabling them to take corrective actions if necessary.\n  Our system was tested on a set of 53 public articles containing 392 claims.\nOur test cases include articles from major newspapers, summaries of survey\nresults, and Wikipedia articles. Our tool revealed erroneous claims in roughly\na third of test cases. A detailed user study shows that users using our tool\nare in average six times faster at checking text summaries, compared to generic\nSQL interfaces. In fully automated verification, our tool achieves\nsignificantly higher recall and precision than baselines from the areas of\nnatural language query interfaces and fact-checking.", "author": [{"name": "Saehan Jo"}, {"name": "Immanuel Trummer"}, {"name": "Weicheng Yu"}, {"name": "Daniel Liu"}, {"name": "Xuezhi Wang"}, {"name": "Cong Yu"}, {"name": "Niyati Mehta"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "18 pages, 13 figures, 11 tables"}, "link": [{"@href": "http://arxiv.org/abs/1804.07686v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.07686v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.00494v1", "updated": "2018-09-03T08:37:33Z", "published": "2018-09-03T08:37:33Z", "title": "Belittling the Source: Trustworthiness Indicators to Obfuscate Fake News\n  on the Web", "summary": "With the growth of the internet, the number of fake-news online has been\nproliferating every year. The consequences of such phenomena are manifold,\nranging from lousy decision-making process to bullying and violence episodes.\nTherefore, fact-checking algorithms became a valuable asset. To this aim, an\nimportant step to detect fake-news is to have access to a credibility score for\na given information source. However, most of the widely used Web indicators\nhave either been shut-down to the public (e.g., Google PageRank) or are not\nfree for use (Alexa Rank). Further existing databases are short-manually\ncurated lists of online sources, which do not scale. Finally, most of the\nresearch on the topic is theoretical-based or explore confidential data in a\nrestricted simulation environment. In this paper we explore current research,\nhighlight the challenges and propose solutions to tackle the problem of\nclassifying websites into a credibility scale. The proposed model automatically\nextracts source reputation cues and computes a credibility factor, providing\nvaluable insights which can help in belittling dubious and confirming trustful\nunknown websites. Experimental results outperform state of the art in the\n2-classes and 5-classes setting.", "author": [{"name": "Diego Esteves"}, {"name": "Aniketh Janardhan Reddy"}, {"name": "Piyush Chawla"}, {"name": "Jens Lehmann"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EMNLP 2018: Conference on Empirical Methods in Natural Language\n  Processing (The First Workshop on Fact Extraction and Verification)"}, "link": [{"@href": "http://arxiv.org/abs/1809.00494v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.00494v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1812.03354v2", "updated": "2020-06-26T21:49:38Z", "published": "2018-12-08T17:36:47Z", "title": "Learning through the Grapevine: The Impact of Noise and the Breadth and\n  Depth of Social Networks", "summary": "We examine how well people learn when information is noisily relayed from\nperson to person; and we study how communication platforms can improve learning\nwithout censoring or fact-checking messages. We analyze learning as a function\nof social network depth (how many times information is relayed) and breadth\n(the number of relay chains accessed). Noise builds up as depth increases, so\nlearning requires greater breadth. In the presence of mutations (deliberate or\nrandom) and transmission failures of messages, we characterize sharp thresholds\nfor breadths above which receivers learn fully and below which they learn\nnothing. When there is uncertainty about mutation rates, optimizing learning\nrequires either capping depth, or if that is not possible, limiting breadth by\ncapping the number of people to whom someone can forward a message. Limiting\nbreadth cuts the number of messages received but also decreases the fraction\noriginating further from the receiver, and so can increase the signal to noise\nratio. Finally, we extend our model to study learning from message survival:\ne.g., people are more likely to pass messages with one conclusion than another.\nWe find that as depth grows, all learning comes from either the total number of\nmessages received or from the content of received messages, but the learner\ndoes not need to pay attention to both.", "author": [{"name": "Matthew O. Jackson"}, {"name": "Suraj Malladi"}, {"name": "David McAdams"}], "link": [{"@href": "http://arxiv.org/abs/1812.03354v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.03354v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1903.07136v1", "updated": "2019-03-17T17:37:39Z", "published": "2019-03-17T17:37:39Z", "title": "Human-Misinformation interaction: Understanding the interdisciplinary\n  approach needed to computationally combat false information", "summary": "The prevalence of new technologies and social media has amplified the effects\nof misinformation on our societies. Thus, it is necessary to create\ncomputational tools to mitigate their effects effectively. This study aims to\nprovide a critical overview of computational approaches concerned with\ncombating misinformation. To this aim, I offer an overview of scholarly\ndefinitions of misinformation. I adopt a framework for studying misinformation\nthat suggests paying attention to the source, content, and consumers as the\nthree main elements involved in the process of misinformation and I provide an\noverview of literature from disciplines of psychology, media studies, and\ncognitive sciences that deal with each of these elements. Using the framework,\nI overview the existing computational methods that deal with 1) misinformation\ndetection and fact-checking using Content 2) Identifying untrustworthy Sources\nand social bots, and 3) Consumer-facing tools and methods aiming to make humans\nresilient to misinformation. I find that the vast majority of works in computer\nscience and information technology is concerned with the crucial tasks of\ndetection and verification of content and sources of misinformation. Moreover,\nI find that computational research focusing on Consumers of Misinformation in\nHuman-Computer Interaction (HCI) and related fields are very sparse and often\ndo not deal with the subtleties of this process. The majority of existing\ninterfaces and systems are less concerned with the usability of the tools\nrather than the robustness and accuracy of the detection methods. Using this\nsurvey, I call for an interdisciplinary approach towards human-misinformation\ninteraction that focuses on building methods and tools that robustly deal with\nsuch complex psychological/social phenomena.", "author": {"name": "Alireza Karduni"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "21 pages, 2 figures"}, "link": [{"@href": "http://arxiv.org/abs/1903.07136v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.07136v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.00623v1", "updated": "2020-01-02T21:01:02Z", "published": "2020-01-02T21:01:02Z", "title": "Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements", "summary": "In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.", "author": [{"name": "Kai Shu"}, {"name": "Suhang Wang"}, {"name": "Dongwon Lee"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted as an introductory chapter for the edited book on \"Fake\n  News, Disinformation, and Misinformation in Social Media- Emerging Research\n  Challenges and Opportunities\", Springer Press"}, "link": [{"@href": "http://arxiv.org/abs/2001.00623v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.00623v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.12309v4", "updated": "2020-10-22T03:03:29Z", "published": "2020-03-26T09:48:24Z", "title": "COVID-19 on Social Media: Analyzing Misinformation in Twitter\n  Conversations", "summary": "The ongoing Coronavirus (COVID-19) pandemic highlights the\ninter-connectedness of our present-day globalized world. With social distancing\npolicies in place, virtual communication has become an important source of\n(mis)information. As increasing number of people rely on social media platforms\nfor news, identifying misinformation and uncovering the nature of online\ndiscourse around COVID-19 has emerged as a critical task. To this end, we\ncollected streaming data related to COVID-19 using the Twitter API, starting\nMarch 1, 2020. We identified unreliable and misleading contents based on\nfact-checking sources, and examined the narratives promoted in misinformation\ntweets, along with the distribution of engagements with these tweets. In\naddition, we provide examples of the spreading patterns of prominent\nmisinformation tweets. The analysis is presented and updated on a publically\naccessible dashboard (https://usc-melady.github.io/COVID-19-Tweet-Analysis) to\ntrack the nature of online discourse and misinformation about COVID-19 on\nTwitter from March 1 - June 5, 2020. The dashboard provides a daily list of\nidentified misinformation tweets, along with topics, sentiments, and emerging\ntrends in the COVID-19 Twitter discourse. The dashboard is provided to improve\nvisibility into the nature and quality of information shared online, and\nprovide real-time access to insights and information extracted from the\ndataset.", "author": [{"name": "Karishma Sharma"}, {"name": "Sungyong Seo"}, {"name": "Chuizheng Meng"}, {"name": "Sirisha Rambhatla"}, {"name": "Yan Liu"}], "link": [{"@href": "http://arxiv.org/abs/2003.12309v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.12309v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.14974v6", "updated": "2020-10-03T04:31:06Z", "published": "2020-04-30T17:22:57Z", "title": "Fact or Fiction: Verifying Scientific Claims", "summary": "We introduce scientific claim verification, a new task to select abstracts\nfrom the research literature containing evidence that SUPPORTS or REFUTES a\ngiven scientific claim, and to identify rationales justifying each decision. To\nstudy this task, we construct SciFact, a dataset of 1.4K expert-written\nscientific claims paired with evidence-containing abstracts annotated with\nlabels and rationales. We develop baseline models for SciFact, and demonstrate\nthat simple domain adaptation techniques substantially improve performance\ncompared to models trained on Wikipedia or political news. We show that our\nsystem is able to verify claims related to COVID-19 by identifying evidence\nfrom the CORD-19 corpus. Our experiments indicate that SciFact will provide a\nchallenging testbed for the development of new systems designed to retrieve and\nreason over corpora containing specialized domain knowledge. Data and code for\nthis new task are publicly available at https://github.com/allenai/scifact. A\nleaderboard and COVID-19 fact-checking demo are available at\nhttps://scifact.apps.allenai.org.", "author": [{"name": "David Wadden"}, {"name": "Shanchuan Lin"}, {"name": "Kyle Lo"}, {"name": "Lucy Lu Wang"}, {"name": "Madeleine van Zuylen"}, {"name": "Arman Cohan"}, {"name": "Hannaneh Hajishirzi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EMNLP 2020. GitHub: https://github.com/allenai/scifact. Leaderboard\n  and demo: https://scifact.apps.allenai.org"}, "link": [{"@href": "http://arxiv.org/abs/2004.14974v6", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.14974v6", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.05854v1", "updated": "2020-05-12T15:20:55Z", "published": "2020-05-12T15:20:55Z", "title": "Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News", "summary": "Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 \"infodemic\", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n\"fake news\" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta", "author": [{"name": "Giovanni Da San Martino"}, {"name": "Shaden Shaar"}, {"name": "Yifan Zhang"}, {"name": "Seunghak Yu"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, disinformation, fake news, media bias, COVID-19"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL-2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.05854v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.05854v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.03354v2", "updated": "2021-03-11T12:55:12Z", "published": "2020-06-05T10:32:18Z", "title": "Classification Aware Neural Topic Model and its Application on a New\n  COVID-19 Disinformation Corpus", "summary": "The explosion of disinformation accompanying the COVID-19 pandemic has\noverloaded fact-checkers and media worldwide, and brought a new major challenge\nto government responses worldwide. Not only is disinformation creating\nconfusion about medical science amongst citizens, but it is also amplifying\ndistrust in policy makers and governments. To help tackle this, we developed\ncomputational methods to categorise COVID-19 disinformation. The COVID-19\ndisinformation categories could be used for a) focusing fact-checking efforts\non the most damaging kinds of COVID-19 disinformation; b) guiding policy makers\nwho are trying to deliver effective public health messages and counter\neffectively COVID-19 disinformation. This paper presents: 1) a corpus\ncontaining what is currently the largest available set of manually annotated\nCOVID-19 disinformation categories; 2) a classification-aware neural topic\nmodel (CANTM) designed for COVID-19 disinformation category classification and\ntopic discovery; 3) an extensive analysis of COVID-19 disinformation categories\nwith respect to time, volume, false type, media type and origin source.", "author": [{"name": "Xingyi Song"}, {"name": "Johann Petrak"}, {"name": "Ye Jiang"}, {"name": "Iknoor Singh"}, {"name": "Diana Maynard"}, {"name": "Kalina Bontcheva"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0247086"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0247086", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2006.03354v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.03354v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is arXiv version of \"Classification Aware Neural Topic Model for\n  COVID-19 Disinformation Categorisation\""}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PLOS ONE 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.03001v4", "updated": "2021-08-24T15:40:14Z", "published": "2020-10-06T20:05:43Z", "title": "A Review on Fact Extraction and Verification", "summary": "We study the fact checking problem, which aims to identify the veracity of a\ngiven claim. Specifically, we focus on the task of Fact Extraction and\nVERification (FEVER) and its accompanied dataset. The task consists of the\nsubtasks of retrieving the relevant documents (and sentences) from Wikipedia\nand validating whether the information in the documents supports or refutes a\ngiven claim. This task is essential and can be the building block of\napplications such as fake news detection and medical claim verification. In\nthis paper, we aim at a better understanding of the challenges of the task by\npresenting the literature in a structured and comprehensive way. We describe\nthe proposed methods by analyzing the technical perspectives of the different\napproaches and discussing the performance results on the FEVER dataset, which\nis the most well-studied and formally structured dataset on the fact extraction\nand verification task. We also conduct the largest experimental study to date\non identifying beneficial loss functions for the sentence retrieval component.\nOur analysis indicates that sampling negative sentences is important for\nimproving the performance and decreasing the computational complexity. Finally,\nwe describe open issues and future challenges, and we motivate future research\nin the task.", "author": [{"name": "Giannis Bekoulis"}, {"name": "Christina Papagiannopoulou"}, {"name": "Nikos Deligiannis"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "author preprint version"}, "link": [{"@href": "http://arxiv.org/abs/2010.03001v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.03001v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.02241v1", "updated": "2020-11-04T11:54:54Z", "published": "2020-11-04T11:54:54Z", "title": "The Forchheim Image Database for Camera Identification in the Wild", "summary": "Image provenance can represent crucial knowledge in criminal investigation\nand journalistic fact checking. In the last two decades, numerous algorithms\nhave been proposed for obtaining information on the source camera and\ndistribution history of an image. For a fair ranking of these techniques, it is\nimportant to rigorously assess their performance on practically relevant test\ncases. To this end, a number of datasets have been proposed. However, we argue\nthat there is a gap in existing databases: to our knowledge, there is currently\nno dataset that simultaneously satisfies two goals, namely a) to cleanly\nseparate scene content and forensic traces, and b) to support realistic\npost-processing like social media recompression. In this work, we propose the\nForchheim Image Database (FODB) to close this gap. It consists of more than\n23,000 images of 143 scenes by 27 smartphone cameras, and it allows to cleanly\nseparate image content from forensic artifacts. Each image is provided in 6\ndifferent qualities: the original camera-native version, and five copies from\nsocial networks. We demonstrate the usefulness of FODB in an evaluation of\nmethods for camera identification. We report three findings. First, the\nrecently proposed general-purpose EfficientNet remarkably outperforms several\ndedicated forensic CNNs both on clean and compressed images. Second,\nclassifiers obtain a performance boost even on unknown post-processing after\naugmentation by artificial degradations. Third, FODB's clean separation of\nscene content and forensic traces imposes important, rigorous boundary\nconditions for algorithm benchmarking.", "author": [{"name": "Benjamin Hadwiger"}, {"name": "Christian Riess"}], "link": [{"@href": "http://arxiv.org/abs/2011.02241v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.02241v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.00483v2", "updated": "2021-01-02T16:13:06Z", "published": "2020-12-01T13:42:37Z", "title": "ClimaText: A Dataset for Climate Change Topic Detection", "summary": "Climate change communication in the mass media and other textual sources may\naffect and shape public perception. Extracting climate change information from\nthese sources is an important task, e.g., for filtering content and\ne-discovery, sentiment analysis, automatic summarization, question-answering,\nand fact-checking. However, automating this process is a challenge, as climate\nchange is a complex, fast-moving, and often ambiguous topic with scarce\nresources for popular text-based AI tasks. In this paper, we introduce\n\\textsc{ClimaText}, a dataset for sentence-based climate change topic\ndetection, which we make publicly available. We explore different approaches to\nidentify the climate change topic in various text sources. We find that popular\nkeyword-based models are not adequate for such a complex and evolving task.\nContext-based algorithms like BERT \\cite{devlin2018bert} can detect, in\naddition to many trivial cases, a variety of complex and implicit topic\npatterns. Nevertheless, our analysis reveals a great potential for improvement\nin several directions, such as, e.g., capturing the discussion on indirect\neffects of climate change. Hence, we hope this work can serve as a good\nstarting point for further research on this topic.", "author": [{"name": "Francesco S. Varini"}, {"name": "Jordan Boyd-Graber"}, {"name": "Massimiliano Ciaramita"}, {"name": "Markus Leippold"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for the Tackling Climate Change with Machine Learning\n  Workshop at NeurIPS 2020"}, "link": [{"@href": "http://arxiv.org/abs/2012.00483v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.00483v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.11925v3", "updated": "2021-06-14T22:05:28Z", "published": "2021-02-23T20:22:45Z", "title": "Chasm in Hegemony: Explaining and Reproducing Disparities in Homophilous\n  Networks", "summary": "In networks with a minority and a majority community, it is well-studied that\nminorities are under-represented at the top of the social hierarchy. However,\nresearchers are less clear about the representation of minorities from the\nlower levels of the hierarchy, where other disadvantages or vulnerabilities may\nexist. We offer a more complete picture of social disparities at each social\nlevel with empirical evidence that the minority representation exhibits two\nopposite phases: at the higher rungs of the social ladder, the representation\nof the minority community decreases; but, lower in the ladder, which is more\npopulous, as you ascend, the representation of the minority community improves.\nWe refer to this opposing phenomenon between the upper-level and lower-level as\nthe \\emph{chasm effect}. Previous models of network growth with homophily fail\nto detect and explain the presence of this chasm effect. We analyze the\ninteractions among a few well-observed network-growing mechanisms with a simple\nmodel to reveal the sufficient and necessary conditions for both phases in the\nchasm effect to occur. By generalizing the simple model naturally, we present a\ncomplete bi-affiliation bipartite network-growth model that could successfully\ncapture disparities at all social levels and reproduce real social networks.\nFinally, we illustrate that addressing the chasm effect can create fairer\nsystems with two applications in advertisement and fact-checks, thereby\ndemonstrating the potential impact of the chasm effect on the future research\nof minority-majority disparities and fair algorithms.", "author": [{"name": "Yiguang Zhang"}, {"name": "Jessy Xinyi Han"}, {"name": "Ilica Mahajan"}, {"name": "Priyanjana Bengani"}, {"name": "Augustin Chaintreau"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3460083"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3460083", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2102.11925v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.11925v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the ACM on Measurement and Analysis of Computing\n  Systems 5.2 (2021): 1-38"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2103.00747v1", "updated": "2021-03-01T04:28:39Z", "published": "2021-03-01T04:28:39Z", "title": "Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models", "summary": "Misinformation of COVID-19 is prevalent on social media as the pandemic\nunfolds, and the associated risks are extremely high. Thus, it is critical to\ndetect and combat such misinformation. Recently, deep learning models using\nnatural language processing techniques, such as BERT (Bidirectional Encoder\nRepresentations from Transformers), have achieved great successes in detecting\nmisinformation. In this paper, we proposed an explainable natural language\nprocessing model based on DistilBERT and SHAP (Shapley Additive exPlanations)\nto combat misinformation about COVID-19 due to their efficiency and\neffectiveness. First, we collected a dataset of 984 claims about COVID-19 with\nfact checking. By augmenting the data using back-translation, we doubled the\nsample size of the dataset and the DistilBERT model was able to obtain good\nperformance (accuracy: 0.972; areas under the curve: 0.993) in detecting\nmisinformation about COVID-19. Our model was also tested on a larger dataset\nfor AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good\nperformance (accuracy: 0.938; areas under the curve: 0.985). The performance on\nboth datasets was better than traditional machine learning models. Second, in\norder to boost public trust in model prediction, we employed SHAP to improve\nmodel explainability, which was further evaluated using a between-subjects\nexperiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),\nand text+SHAP explanation+source and evidence (TSESE). The participants were\nsignificantly more likely to trust and share information related to COVID-19 in\nthe TSE and TSESE conditions than in the T condition. Our results provided good\nimplications in detecting misinformation about COVID-19 and improving public\ntrust.", "author": [{"name": "Jackie Ayoub"}, {"name": "X. Jessie Yang"}, {"name": "Feng Zhou"}], "link": [{"@href": "http://arxiv.org/abs/2103.00747v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.00747v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.08164v1", "updated": "2021-04-16T15:24:42Z", "published": "2021-04-16T15:24:42Z", "title": "Editing Factual Knowledge in Language Models", "summary": "The factual knowledge acquired during pretraining and stored in the\nparameters of Language Models (LM) can be useful in downstream tasks (e.g.,\nquestion answering or textual inference). However, some facts can be\nincorrectly induced or become obsolete over time. We present KnowledgeEditor, a\nmethod that can be used to edit this knowledge and, thus, fix 'bugs' or\nunexpected predictions without the need for expensive re-training or\nfine-tuning. Besides being computationally efficient, KnowledgeEditor does not\nrequire any modifications in LM pre-training (e.g., the use of meta-learning).\nIn our approach, we train a hyper-network with constrained optimization to\nmodify a fact without affecting the rest of the knowledge; the trained\nhyper-network is then used to predict the weight update at test time. We show\nKnowledgeEditor's efficacy with two popular architectures and\nknowledge-intensive tasks: i) a BERT model fine-tuned for fact-checking, and\nii) a sequence-to-sequence BART model for question answering. With our method,\nchanging a prediction on the specific wording of a query tends to result in a\nconsistent change in predictions also for its paraphrases. We show that this\ncan be further encouraged by exploiting (e.g., automatically-generated)\nparaphrases during training. Interestingly, our hyper-network can be regarded\nas a 'probe' revealing which components of a model need to be changed to\nmanipulate factual knowledge; our analysis shows that the updates tend to be\nconcentrated on a small subset of components. Code at\nhttps://github.com/nicola-decao/KnowledgeEditor", "author": [{"name": "Nicola De Cao"}, {"name": "Wilker Aziz"}, {"name": "Ivan Titov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages, 6 figures, 2 tables. Code at\n  https://github.com/nicola-decao/KnowledgeEditor"}, "link": [{"@href": "http://arxiv.org/abs/2104.08164v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.08164v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.10130v1", "updated": "2021-04-20T17:16:41Z", "published": "2021-04-20T17:16:41Z", "title": "Hidden Biases in Unreliable News Detection Datasets", "summary": "Automatic unreliable news detection is a research problem with great\npotential impact. Recently, several papers have shown promising results on\nlarge-scale news datasets with models that only use the article itself without\nresorting to any fact-checking mechanism or retrieving any supporting evidence.\nIn this work, we take a closer look at these datasets. While they all provide\nvaluable resources for future research, we observe a number of problems that\nmay lead to results that do not generalize in more realistic settings.\nSpecifically, we show that selection bias during data collection leads to\nundesired artifacts in the datasets. In addition, while most systems train and\npredict at the level of individual articles, overlapping article sources in the\ntraining and evaluation data can provide a strong confounding factor that\nmodels can exploit. In the presence of this confounding factor, the models can\nachieve good performance by directly memorizing the site-label mapping instead\nof modeling the real task of unreliable news detection. We observed a\nsignificant drop (>10%) in accuracy for all models tested in a clean split with\nno train/test source overlap. Using the observations and experimental results,\nwe provide practical suggestions on how to create more reliable datasets for\nthe unreliable news detection task. We suggest future dataset creation include\na simple model as a difficulty/bias probe and future model development use a\nclean non-overlapping site and date split.", "author": [{"name": "Xiang Zhou"}, {"name": "Heba Elfardy"}, {"name": "Christos Christodoulopoulos"}, {"name": "Thomas Butler"}, {"name": "Mohit Bansal"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EACL 2021 (11 pages, 3 figures, 8 tables)"}, "link": [{"@href": "http://arxiv.org/abs/2104.10130v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.10130v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.09114v1", "updated": "2021-05-19T13:18:02Z", "published": "2021-05-19T13:18:02Z", "title": "Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment", "summary": "The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations.", "author": [{"name": "Bimal Bhattarai"}, {"name": "Ole-Christoffer Granmo"}, {"name": "Lei Jiao"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 4 figures, 4 tables"}, "link": [{"@href": "http://arxiv.org/abs/2105.09114v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.09114v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2; I.5; I.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.08117v1", "updated": "2021-06-15T13:22:48Z", "published": "2021-06-15T13:22:48Z", "title": "Semantic Representation and Inference for NLP", "summary": "Semantic representation and inference is essential for Natural Language\nProcessing (NLP). The state of the art for semantic representation and\ninference is deep learning, and particularly Recurrent Neural Networks (RNNs),\nConvolutional Neural Networks (CNNs), and transformer Self-Attention models.\nThis thesis investigates the use of deep learning for novel semantic\nrepresentation and inference, and makes contributions in the following three\nareas: creating training data, improving semantic representations and extending\ninference learning. In terms of creating training data, we contribute the\nlargest publicly available dataset of real-life factual claims for the purpose\nof automatic claim verification (MultiFC), and we present a novel inference\nmodel composed of multi-scale CNNs with different kernel sizes that learn from\nexternal sources to infer fact checking labels. In terms of improving semantic\nrepresentations, we contribute a novel model that captures non-compositional\nsemantic indicators. By definition, the meaning of a non-compositional phrase\ncannot be inferred from the individual meanings of its composing words (e.g.,\nhot dog). Motivated by this, we operationalize the compositionality of a phrase\ncontextually by enriching the phrase representation with external word\nembeddings and knowledge graphs. Finally, in terms of inference learning, we\npropose a series of novel deep learning architectures that improve inference by\nusing syntactic dependencies, by ensembling role guided attention heads,\nincorporating gating layers, and concatenating multiple heads in novel and\neffective ways. This thesis consists of seven publications (five published and\ntwo under review).", "author": {"name": "Dongsheng Wang"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PhD thesis, the University of Copenhagen"}, "link": [{"@href": "http://arxiv.org/abs/2106.08117v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.08117v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.11177v1", "updated": "2021-06-21T15:17:31Z", "published": "2021-06-21T15:17:31Z", "title": "MetaDetector: Meta Event Knowledge Transfer for Fake News Detection", "summary": "The blooming of fake news on social networks has devastating impacts on\nsociety, economy, and public security. Although numerous studies are conducted\nfor the automatic detection of fake news, the majority tend to utilize deep\nneural networks to learn event-specific features for superior detection\nperformance on specific datasets. However, the trained models heavily rely on\nthe training datasets and are infeasible to apply to upcoming events due to the\ndiscrepancy between event distributions. Inspired by domain adaptation\ntheories, we propose an end-to-end adversarial adaptation network, dubbed as\nMetaDetector, to transfer meta knowledge (event-shared features) between\ndifferent events. Specifically, MetaDetector pushes the feature extractor and\nevent discriminator to eliminate event-specific features and preserve required\nevent-shared features by adversarial training. Furthermore, the pseudo-event\ndiscriminator is utilized to evaluate the importance of historical event posts\nto obtain partial shared features that are discriminative for detecting fake\nnews. Under the coordinated optimization among the four submodules,\nMetaDetector accurately transfers the meta-knowledge of historical events to\nthe upcoming event for fact checking. We conduct extensive experiments on two\nlarge-scale datasets collected from Weibo and Twitter. The experimental results\ndemonstrate that MetaDetector outperforms the state-of-the-art methods,\nespecially when the distribution shift between events is significant.\nFurthermore, we find that MetaDetector is able to learn the event-shared\nfeatures, and alleviate the negative transfer caused by the large distribution\nshift between events.", "author": [{"name": "Yasan Ding"}, {"name": "Bin Guo"}, {"name": "Yan Liu"}, {"name": "Yunji Liang"}, {"name": "Haocheng Shen"}, {"name": "Zhiwen Yu"}], "link": [{"@href": "http://arxiv.org/abs/2106.11177v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.11177v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.05684v1", "updated": "2021-07-12T18:46:47Z", "published": "2021-07-12T18:46:47Z", "title": "Accenture at CheckThat! 2021: Interesting claim identification and\n  ranking with contextually sensitive lexical training data augmentation", "summary": "This paper discusses the approach used by the Accenture Team for CLEF2021\nCheckThat! Lab, Task 1, to identify whether a claim made in social media would\nbe interesting to a wide audience and should be fact-checked. Twitter training\nand test data were provided in English, Arabic, Spanish, Turkish, and\nBulgarian. Claims were to be classified (check-worthy/not check-worthy) and\nranked in priority order for the fact-checker. Our method used deep neural\nnetwork transformer models with contextually sensitive lexical augmentation\napplied on the supplied training datasets to create additional training\nsamples. This augmentation approach improved the performance for all languages.\nOverall, our architecture and data augmentation pipeline produced the best\nsubmitted system for Arabic, and performance scales according to the quantity\nof provided training data for English, Spanish, Turkish, and Bulgarian. This\npaper investigates the deep neural network architectures for each language as\nwell as the provided data to examine why the approach worked so effectively for\nArabic, and discusses additional data augmentation measures that should could\nbe useful to this problem.", "author": [{"name": "Evan Williams"}, {"name": "Paul Rodrigues"}, {"name": "Sieu Tran"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To Appear As: Evan Williams, Paul Rodrigues, Sieu Tran. Accenture at\n  CheckThat! 2021: Interesting claim identification and ranking with\n  contextually sensitive lexical training data augmentation. In: Faggioli et\n  al. Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum.\n  Bucharest, Romania. 21-24 September 2021"}, "link": [{"@href": "http://arxiv.org/abs/2107.05684v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.05684v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.09768v1", "updated": "2021-07-20T20:58:23Z", "published": "2021-07-20T20:58:23Z", "title": "Checkovid: A COVID-19 misinformation detection system on Twitter using\n  network and content mining perspectives", "summary": "During the COVID-19 pandemic, social media platforms were ideal for\ncommunicating due to social isolation and quarantine. Also, it was the primary\nsource of misinformation dissemination on a large scale, referred to as the\ninfodemic. Therefore, automatic debunking misinformation is a crucial problem.\nTo tackle this problem, we present two COVID-19 related misinformation datasets\non Twitter and propose a misinformation detection system comprising\nnetwork-based and content-based processes based on machine learning algorithms\nand NLP techniques. In the network-based process, we focus on social\nproperties, network characteristics, and users. On the other hand, we classify\nmisinformation using the content of the tweets directly in the content-based\nprocess, which contains text classification models (paragraph-level and\nsentence-level) and similarity models. The evaluation results on the\nnetwork-based process show the best results for the artificial neural network\nmodel with an F1 score of 88.68%. In the content-based process, our novel\nsimilarity models, which obtained an F1 score of 90.26%, show an improvement in\nthe misinformation classification results compared to the network-based models.\nIn addition, in the text classification models, the best result was achieved\nusing the stacking ensemble-learning model by obtaining an F1 score of 95.18%.\nFurthermore, we test our content-based models on the Constraint@AAAI2021\ndataset, and by getting an F1 score of 94.38%, we improve the baseline results.\nFinally, we develop a fact-checking website called Checkovid that uses each\nprocess to detect misinformative and informative claims in the domain of\nCOVID-19 from different perspectives.", "author": [{"name": "Sajad Dadgar"}, {"name": "Mehdi Ghatee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "20 Pages, 18 Figures, 7 Tables, Submitted for Review Process in a\n  Journal"}, "link": [{"@href": "http://arxiv.org/abs/2107.09768v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.09768v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T05, 68T07", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2; I.5", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1902.06673v1", "updated": "2019-02-10T15:21:45Z", "published": "2019-02-10T15:21:45Z", "title": "Fake News Detection on Social Media using Geometric Deep Learning", "summary": "Social media are nowadays one of the main news sources for millions of people\naround the globe due to their low cost, easy access and rapid dissemination.\nThis however comes at the cost of dubious trustworthiness and significant risk\nof exposure to 'fake news', intentionally written to mislead the readers.\nAutomatically detecting fake news poses challenges that defy existing\ncontent-based analysis approaches. One of the main reasons is that often the\ninterpretation of the news requires the knowledge of political or social\ncontext or 'common sense', which current NLP algorithms are still missing.\nRecent studies have shown that fake and real news spread differently on social\nmedia, forming propagation patterns that could be harnessed for the automatic\nfake news detection. Propagation-based approaches have multiple advantages\ncompared to their content-based counterparts, among which is language\nindependence and better resilience to adversarial attacks. In this paper we\nshow a novel automatic fake news detection model based on geometric deep\nlearning. The underlying core algorithms are a generalization of classical CNNs\nto graphs, allowing the fusion of heterogeneous data such as content, user\nprofile and activity, social graph, and news propagation. Our model was trained\nand tested on news stories, verified by professional fact-checking\norganizations, that were spread on Twitter. Our experiments indicate that\nsocial network structure and propagation are important features allowing highly\naccurate (92.7% ROC AUC) fake news detection. Second, we observe that fake news\ncan be reliably detected at an early stage, after just a few hours of\npropagation. Third, we test the aging of our model on training and testing data\nseparated in time. Our results point to the promise of propagation-based\napproaches for fake news detection as an alternative or complementary strategy\nto content-based approaches.", "author": [{"name": "Federico Monti"}, {"name": "Fabrizio Frasca"}, {"name": "Davide Eynard"}, {"name": "Damon Mannion"}, {"name": "Michael M. Bronstein"}], "link": [{"@href": "http://arxiv.org/abs/1902.06673v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.06673v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.03538v1", "updated": "2019-06-08T23:18:07Z", "published": "2019-06-08T23:18:07Z", "title": "Seeing Things from a Different Angle: Discovering Diverse Perspectives\n  about Claims", "summary": "One key consequence of the information revolution is a significant increase\nand a contamination of our information supply. The practice of fact checking\nwon't suffice to eliminate the biases in text data we observe, as the degree of\nfactuality alone does not determine whether biases exist in the spectrum of\nopinions visible to us. To better understand controversial issues, one needs to\nview them from a diverse yet comprehensive set of perspectives. For example,\nthere are many ways to respond to a claim such as \"animals should have lawful\nrights\", and these responses form a spectrum of perspectives, each with a\nstance relative to this claim and, ideally, with evidence supporting it.\nInherently, this is a natural language understanding task, and we propose to\naddress it as such. Specifically, we propose the task of substantiated\nperspective discovery where, given a claim, a system is expected to discover a\ndiverse set of well-corroborated perspectives that take a stance with respect\nto the claim. Each perspective should be substantiated by evidence paragraphs\nwhich summarize pertinent results and facts. We construct PERSPECTRUM, a\ndataset of claims, perspectives and evidence, making use of online debate\nwebsites to create the initial data collection, and augmenting it using search\nengines in order to expand and diversify our dataset. We use crowd-sourcing to\nfilter out noise and ensure high-quality data. Our dataset contains 1k claims,\naccompanied with pools of 10k and 8k perspective sentences and evidence\nparagraphs, respectively. We provide a thorough analysis of the dataset to\nhighlight key underlying language understanding challenges, and show that human\nbaselines across multiple subtasks far outperform ma-chine baselines built upon\nstate-of-the-art NLP techniques. This poses a challenge and opportunity for the\nNLP community to address.", "author": [{"name": "Sihao Chen"}, {"name": "Daniel Khashabi"}, {"name": "Wenpeng Yin"}, {"name": "Chris Callison-Burch"}, {"name": "Dan Roth"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Proceedings of the 2019 Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics (NAACL 2019)"}, "link": [{"@href": "http://arxiv.org/abs/1906.03538v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.03538v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1909.12233v1", "updated": "2019-09-13T13:39:59Z", "published": "2019-09-13T13:39:59Z", "title": "Deep Ensemble Learning for News Stance Detection", "summary": "Stance detection in fake news is an important component in news veracity\nassessment because this process helps fact-checking by understanding stance to\na central claim from different information sources. The Fake News Challenge\nStage 1 (FNC-1) held in 2017 was setup for this purpose, which involves\nestimating the stance of a news article body relative to a given headline. This\nthesis starts from the error analysis for the three top-performing systems in\nFNC-1. Based on the analysis, a simple but tough-to-beat Multilayer Perceptron\nsystem is chosen as the baseline. Afterwards, three approaches are explored to\nimprove baseline.The first approach explores the possibility of improving the\nprediction accuracy by adding extra keywords features when training a model,\nwhere keywords are converted to an indicator vector and then concatenated to\nthe baseline features. A list of keywords is manually selected based on the\nerror analysis, which may best reflect some characteristics of fake news titles\nand bodies. To make this selection process automatically, three algorithms are\ncreated based on Mutual Information (MI) theory: keywords generator based on MI\nstance class, MI customised class, and Pointwise MI algorithm. The second\napproach is based on word embedding, where word2vec model is introduced and two\ndocument similarities calculation algorithms are implemented: wor2vec cosine\nsimilarity and WMD distance. The third approach is ensemble learning. Different\nmodels are configured together with two continuous outputs combining\nalgorithms. The 10-fold cross validation reveals that the ensemble of three\nneural network models trained from simple bag-of-words features gives the best\nperformance. It is therefore selected to compete in FNC-1. After\nhyperparameters fine tuning, the selected deep ensemble model beats the FNC-1\nwinner team by a remarkable 34.25 marks under FNC-1's evaluation metric.", "author": [{"name": "Wenjun Liao"}, {"name": "Chenghua Lin"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Poster presenataion of 5th IC2S2 in University of Amsterdam"}, "link": [{"@href": "http://arxiv.org/abs/1909.12233v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.12233v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.03550v1", "updated": "2020-05-07T15:21:56Z", "published": "2020-05-07T15:21:56Z", "title": "Credulous Users and Fake News: a Real Case Study on the Propagation in\n  Twitter", "summary": "Recent studies have confirmed a growing trend, especially among youngsters,\nof using Online Social Media as favourite information platform at the expense\nof traditional mass media. Indeed, they can easily reach a wide audience at a\nhigh speed; but exactly because of this they are the preferred medium for\ninfluencing public opinion via so-called fake news. Moreover, there is a\ngeneral agreement that the main vehicle of fakes news are malicious software\nrobots (bots) that automatically interact with human users. In previous work we\nhave considered the problem of tagging human users in Online Social Networks as\ncredulous users. Specifically, we have considered credulous those users with\nrelatively high number of bot friends when compared to total number of their\nsocial friends. We consider this group of users worth of attention because they\nmight have a higher exposure to malicious activities and they may contribute to\nthe spreading of fake information by sharing dubious content. In this work,\nstarting from a dataset of fake news, we investigate the behaviour and the\ndegree of involvement of credulous users in fake news diffusion. The study aims\nto: (i) fight fake news by considering the content diffused by credulous users;\n(ii) highlight the relationship between credulous users and fake news\nspreading; (iii) target fake news detection by focusing on the analysis of\nspecific accounts more exposed to malicious activities of bots. Our first\nresults demonstrate a strong involvement of credulous users in fake news\ndiffusion. This findings are calling for tools that, by performing data\nstreaming on credulous' users actions, enables us to perform targeted\nfact-checking.", "author": [{"name": "Alessandro Balestrucci"}, {"name": "Rocco De Nicola"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages and 8 tables. Accepted to appear in the Proceedings at IEEE\n  Conference on Evolving and Adaptive Intelligent Systems (EAIS2020)"}, "link": [{"@href": "http://arxiv.org/abs/2005.03550v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.03550v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.03316v2", "updated": "2020-08-14T07:49:20Z", "published": "2020-07-07T10:04:50Z", "title": "Graph Neural Networks with Continual Learning for Fake News Detection\n  from Social Media", "summary": "Although significant effort has been applied to fact-checking, the prevalence\nof fake news over social media, which has profound impact on justice, public\ntrust and our society, remains a serious problem. In this work, we focus on\npropagation-based fake news detection, as recent studies have demonstrated that\nfake news and real news spread differently online. Specifically, considering\nthe capability of graph neural networks (GNNs) in dealing with non-Euclidean\ndata, we use GNNs to differentiate between the propagation patterns of fake and\nreal news on social media. In particular, we concentrate on two questions: (1)\nWithout relying on any text information, e.g., tweet content, replies and user\ndescriptions, how accurately can GNNs identify fake news? Machine learning\nmodels are known to be vulnerable to adversarial attacks, and avoiding the\ndependence on text-based features can make the model less susceptible to the\nmanipulation of advanced fake news fabricators. (2) How to deal with new,\nunseen data? In other words, how does a GNN trained on a given dataset perform\non a new and potentially vastly different dataset? If it achieves\nunsatisfactory performance, how do we solve the problem without re-training the\nmodel on the entire data from scratch? We study the above questions on two\ndatasets with thousands of labelled news items, and our results show that: (1)\nGNNs can achieve comparable or superior performance without any text\ninformation to state-of-the-art methods. (2) GNNs trained on a given dataset\nmay perform poorly on new, unseen data, and direct incremental training cannot\nsolve the problem---this issue has not been addressed in the previous work that\napplies GNNs for fake news detection. In order to solve the problem, we propose\na method that achieves balanced performance on both existing and new datasets,\nby using techniques from continual learning to train GNNs incrementally.", "author": [{"name": "Yi Han"}, {"name": "Shanika Karunasekera"}, {"name": "Christopher Leckie"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 7 figures, 2 tables"}, "link": [{"@href": "http://arxiv.org/abs/2007.03316v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.03316v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.01913v2", "updated": "2021-02-23T12:00:09Z", "published": "2020-10-05T10:49:32Z", "title": "Flow of online misinformation during the peak of the COVID-19 pandemic\n  in Italy", "summary": "The COVID-19 pandemic has impacted on every human activity and, because of\nthe urgency of finding the proper responses to such an unprecedented emergency,\nit generated a diffused societal debate. The online version of this discussion\nwas not exempted by the presence of d/misinformation campaigns, but differently\nfrom what already witnessed in other debates, the COVID-19 -- intentional or\nnot -- flow of false information put at severe risk the public health, reducing\nthe effectiveness of governments' countermeasures. In the present manuscript,\nwe study the effective impact of misinformation in the Italian societal debate\non Twitter during the pandemic, focusing on the various discursive communities.\nIn order to extract the discursive communities, we focus on verified users,\ni.e. accounts whose identity is officially certified by Twitter. We thus infer\nthe various discursive communities based on how verified users are perceived by\nstandard ones: if two verified accounts are considered as similar by non\nunverified ones, we link them in the network of certified accounts. We first\nobserve that, beside being a mostly scientific subject, the COVID-19 discussion\nshow a clear division in what results to be different political groups. At this\npoint, by using a commonly available fact-checking software (NewsGuard), we\nassess the reputation of the pieces of news exchanged. We filter the network of\nretweets (i.e. users re-broadcasting the same elementary piece of information,\nor tweet) from random noise and check the presence of messages displaying an\nurl. The impact of misinformation posts reaches the 22.1% in the right and\ncenter-right wing community and its contribution is even stronger in absolute\nnumbers, due to the activity of this group: 96% of all non reputable urls\nshared by political groups come from this community.", "author": [{"name": "Guido Caldarelli"}, {"name": "Rocco de Nicola"}, {"name": "Marinella Petrocchi"}, {"name": "Manuel Pratelli"}, {"name": "Fabio Saracco"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "25 pages, 4 figures. The Abstract, the Introduction, the Results, the\n  Conclusions and the Methods were substantially rewritten. The plot of the\n  network have been changed, as well as tables"}, "link": [{"@href": "http://arxiv.org/abs/2010.01913v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.01913v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.08537v3", "updated": "2021-04-07T05:06:05Z", "published": "2021-02-17T02:35:13Z", "title": "Political Bias and Factualness in News Sharing across more than 100,000\n  Online Communities", "summary": "As civil discourse increasingly takes place online, misinformation and the\npolarization of news shared in online communities have become ever more\nrelevant concerns with real world harms across our society. Studying online\nnews sharing at scale is challenging due to the massive volume of content which\nis shared by millions of users across thousands of communities. Therefore,\nexisting research has largely focused on specific communities or specific\ninterventions, such as bans. However, understanding the prevalence and spread\nof misinformation and polarization more broadly, across thousands of online\ncommunities, is critical for the development of governance strategies,\ninterventions, and community design. Here, we conduct the largest study of news\nsharing on reddit to date, analyzing more than 550 million links spanning 4\nyears. We use non-partisan news source ratings from Media Bias/Fact Check to\nannotate links to news sources with their political bias and factualness. We\nfind that, compared to left-leaning communities, right-leaning communities have\n105% more variance in the political bias of their news sources, and more links\nto relatively-more biased sources, on average. We observe that reddit users'\nvoting and re-sharing behaviors generally decrease the visibility of extremely\nbiased and low factual content, which receives 20% fewer upvotes and 30% fewer\nexposures from crossposts than more neutral or more factual content. This\nsuggests that reddit is more resilient to low factual content than Twitter. We\nshow that extremely biased and low factual content is very concentrated, with\n99% of such content being shared in only 0.5% of communities, giving credence\nto the recent strategy of community-wide bans and quarantines.", "author": [{"name": "Galen Weld"}, {"name": "Maria Glenski"}, {"name": "Tim Althoff"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages, 7 figures. To appear at ICWSM 2021, camera ready version\n  included here"}, "link": [{"@href": "http://arxiv.org/abs/2102.08537v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.08537v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.01222v2", "updated": "2021-08-23T04:21:58Z", "published": "2021-08-03T00:44:55Z", "title": "The Many Dimensions of Truthfulness: Crowdsourcing Misinformation\n  Assessments on a Multidimensional Scale", "summary": "Recent work has demonstrated the viability of using crowdsourcing as a tool\nfor evaluating the truthfulness of public statements. Under certain conditions\nsuch as: (1) having a balanced set of workers with different backgrounds and\ncognitive abilities; (2) using an adequate set of mechanisms to control the\nquality of the collected data; and (3) using a coarse grained assessment scale,\nthe crowd can provide reliable identification of fake news. However, fake news\nare a subtle matter: statements can be just biased (\"cherrypicked\"), imprecise,\nwrong, etc. and the unidimensional truth scale used in existing work cannot\naccount for such differences. In this paper we propose a multidimensional\nnotion of truthfulness and we ask the crowd workers to assess seven different\ndimensions of truthfulness selected based on existing literature: Correctness,\nNeutrality, Comprehensibility, Precision, Completeness, Speaker's\nTrustworthiness, and Informativeness. We deploy a set of quality control\nmechanisms to ensure that the thousands of assessments collected on 180\npublicly available fact-checked statements distributed over two datasets are of\nadequate quality, including a custom search engine used by the crowd workers to\nfind web pages supporting their truthfulness assessments. A comprehensive\nanalysis of crowdsourced judgments shows that: (1) the crowdsourced assessments\nare reliable when compared to an expert-provided gold standard; (2) the\nproposed dimensions of truthfulness capture independent pieces of information;\n(3) the crowdsourcing task can be easily learned by the workers; and (4) the\nresulting assessments provide a useful basis for a more complete estimation of\nstatement truthfulness.", "author": [{"name": "Michael Soprano"}, {"name": "Kevin Roitero"}, {"name": "David La Barbera"}, {"name": "Davide Ceolin"}, {"name": "Damiano Spina"}, {"name": "Stefano Mizzaro"}, {"name": "Gianluca Demartini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.ipm.2021.102710"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.ipm.2021.102710", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.01222v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.01222v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "33 pages; Paper accepted at Information Processing & Management on\n  July 28, 2021; IP&M Special Issue on Dis/Misinformation Mining from Social\n  Media"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Information Processing & Management Information Processing &\n  Management, Volume 58, Issue 6, November 2021, 102710"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68P20", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1803.03453v4", "updated": "2019-11-21T23:58:46Z", "published": "2018-03-09T10:17:18Z", "title": "The Surprising Creativity of Digital Evolution: A Collection of\n  Anecdotes from the Evolutionary Computation and Artificial Life Research\n  Communities", "summary": "Biological evolution provides a creative fount of complex and subtle\nadaptations, often surprising the scientists who discover them. However,\nbecause evolution is an algorithmic process that transcends the substrate in\nwhich it occurs, evolution's creativity is not limited to nature. Indeed, many\nresearchers in the field of digital evolution have observed their evolving\nalgorithms and organisms subverting their intentions, exposing unrecognized\nbugs in their code, producing unexpected adaptations, or exhibiting outcomes\nuncannily convergent with ones in nature. Such stories routinely reveal\ncreativity by evolution in these digital worlds, but they rarely fit into the\nstandard scientific narrative. Instead they are often treated as mere obstacles\nto be overcome, rather than results that warrant study in their own right. The\nstories themselves are traded among researchers through oral tradition, but\nthat mode of information transmission is inefficient and prone to error and\noutright loss. Moreover, the fact that these stories tend to be shared only\namong practitioners means that many natural scientists do not realize how\ninteresting and lifelike digital organisms are and how natural their evolution\ncan be. To our knowledge, no collection of such anecdotes has been published\nbefore. This paper is the crowd-sourced product of researchers in the fields of\nartificial life and evolutionary computation who have provided first-hand\naccounts of such cases. It thus serves as a written, fact-checked collection of\nscientifically important and even entertaining stories. In doing so we also\npresent here substantial evidence that the existence and importance of\nevolutionary surprises extends beyond the natural world, and may indeed be a\nuniversal property of all complex evolving systems.", "author": [{"name": "Joel Lehman"}, {"name": "Jeff Clune"}, {"name": "Dusan Misevic"}, {"name": "Christoph Adami"}, {"name": "Lee Altenberg"}, {"name": "Julie Beaulieu"}, {"name": "Peter J. Bentley"}, {"name": "Samuel Bernard"}, {"name": "Guillaume Beslon"}, {"name": "David M. Bryson"}, {"name": "Patryk Chrabaszcz"}, {"name": "Nick Cheney"}, {"name": "Antoine Cully"}, {"name": "Stephane Doncieux"}, {"name": "Fred C. Dyer"}, {"name": "Kai Olav Ellefsen"}, {"name": "Robert Feldt"}, {"name": "Stephan Fischer"}, {"name": "Stephanie Forrest"}, {"name": "Antoine Fr\u00e9noy"}, {"name": "Christian Gagn\u00e9"}, {"name": "Leni Le Goff"}, {"name": "Laura M. Grabowski"}, {"name": "Babak Hodjat"}, {"name": "Frank Hutter"}, {"name": "Laurent Keller"}, {"name": "Carole Knibbe"}, {"name": "Peter Krcah"}, {"name": "Richard E. Lenski"}, {"name": "Hod Lipson"}, {"name": "Robert MacCurdy"}, {"name": "Carlos Maestre"}, {"name": "Risto Miikkulainen"}, {"name": "Sara Mitri"}, {"name": "David E. Moriarty"}, {"name": "Jean-Baptiste Mouret"}, {"name": "Anh Nguyen"}, {"name": "Charles Ofria"}, {"name": "Marc Parizeau"}, {"name": "David Parsons"}, {"name": "Robert T. Pennock"}, {"name": "William F. Punch"}, {"name": "Thomas S. Ray"}, {"name": "Marc Schoenauer"}, {"name": "Eric Shulte"}, {"name": "Karl Sims"}, {"name": "Kenneth O. Stanley"}, {"name": "Fran\u00e7ois Taddei"}, {"name": "Danesh Tarapore"}, {"name": "Simon Thibault"}, {"name": "Westley Weimer"}, {"name": "Richard Watson"}, {"name": "Jason Yosinski"}], "link": [{"@href": "http://arxiv.org/abs/1803.03453v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1803.03453v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}}]