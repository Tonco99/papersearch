[{"id": "http://arxiv.org/abs/2103.07769v2", "updated": "2021-05-22T12:27:05Z", "published": "2021-03-13T18:29:14Z", "title": "Automated Fact-Checking for Assisting Human Fact-Checkers", "summary": "The reporting and the analysis of current events around the globe has\nexpanded from professional, editor-lead journalism all the way to citizen\njournalism. Nowadays, politicians and other key players enjoy direct access to\ntheir audiences through social media, bypassing the filters of official cables\nor traditional media. However, the multiple advantages of free speech and\ndirect communication are dimmed by the misuse of media to spread inaccurate or\nmisleading claims. These phenomena have led to the modern incarnation of the\nfact-checker -- a professional whose main aim is to examine claims using\navailable evidence and to assess their veracity. As in other text forensics\ntasks, the amount of information available makes the work of the fact-checker\nmore difficult. With this in mind, starting from the perspective of the\nprofessional fact-checker, we survey the available intelligent technologies\nthat can support the human expert in the different steps of her fact-checking\nendeavor. These include identifying claims worth fact-checking, detecting\nrelevant previously fact-checked claims, retrieving relevant evidence to\nfact-check a claim, and actually verifying a claim. In each case, we pay\nattention to the challenges in future work and the potential impact on\nreal-world fact-checking.", "author": [{"name": "Preslav Nakov"}, {"name": "David Corney"}, {"name": "Maram Hasanain"}, {"name": "Firoj Alam"}, {"name": "Tamer Elsayed"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Paolo Papotti"}, {"name": "Shaden Shaar"}, {"name": "Giovanni Da San Martino"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "fact-checking, fact-checkers, check-worthiness, detecting previously\n  fact-checked claims, evidence retrieval"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IJCAI-2021"}, "link": [{"@href": "http://arxiv.org/abs/2103.07769v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.07769v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.06708v1", "updated": "2020-03-14T21:28:43Z", "published": "2020-03-14T21:28:43Z", "title": "Scrutinizer: A Mixed-Initiative Approach to Large-Scale, Data-Driven\n  Claim Verification", "summary": "Organizations such as the International Energy Agency (IEA) spend significant\namounts of time and money to manually fact check text documents summarizing\ndata. The goal of the Scrutinizer system is to reduce verification overheads by\nsupporting human fact checkers in translating text claims into SQL queries on\nan associated database.\n  Scrutinizer coordinates teams of human fact checkers. It reduces verification\ntime by proposing queries or query fragments to the users. Those proposals are\nbased on claim text classifiers, that gradually improve during the verification\nof a large document. In addition, Scrutinizer uses tentative execution of query\ncandidates to narrow down the set of alternatives. The verification process is\ncontrolled by a cost-based optimizer. It optimizes the interaction with users\nand prioritizes claim verifications. For the latter, it considers expected\nverification overheads as well as the expected claim utility as training\nsamples for the classifiers. We evaluate the Scrutinizer system using\nsimulations and a user study, based on actual claims and data and using\nprofessional fact checkers employed by IEA. Our experiments consistently\ndemonstrate significant savings in verification time, without reducing result\naccuracy.", "author": [{"name": "Georgios Karagiannis"}, {"name": "Mohammed Saeed"}, {"name": "Paolo Papotti"}, {"name": "Immanuel Trummer"}], "link": [{"@href": "http://arxiv.org/abs/2003.06708v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.06708v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2006.04102v2", "updated": "2020-07-24T07:15:37Z", "published": "2020-06-07T09:52:05Z", "title": "Language Models as Fact Checkers?", "summary": "Recent work has suggested that language models (LMs) store both common-sense\nand factual knowledge learned from pre-training data. In this paper, we\nleverage this implicit knowledge to create an effective end-to-end fact checker\nusing a solely a language model, without any external knowledge or explicit\nretrieval components. While previous work on extracting knowledge from LMs have\nfocused on the task of open-domain question answering, to the best of our\nknowledge, this is the first work to examine the use of language models as fact\ncheckers. In a closed-book setting, we show that our zero-shot LM approach\noutperforms a random baseline on the standard FEVER task, and that our\nfine-tuned LM compares favorably with standard baselines. Though we do not\nultimately outperform methods which use explicit knowledge bases, we believe\nour exploration shows that this method is viable and has much room for\nexploration.", "author": [{"name": "Nayeon Lee"}, {"name": "Belinda Z. Li"}, {"name": "Sinong Wang"}, {"name": "Wen-tau Yih"}, {"name": "Hao Ma"}, {"name": "Madian Khabsa"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted in FEVER Workshop (ACL2020)"}, "link": [{"@href": "http://arxiv.org/abs/2006.04102v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.04102v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.02202v1", "updated": "2019-10-05T03:23:45Z", "published": "2019-10-05T03:23:45Z", "title": "Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language", "summary": "In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SIGIR 2019"}, "link": [{"@href": "http://arxiv.org/abs/1910.02202v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.02202v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.05380v1", "updated": "2019-09-11T21:25:40Z", "published": "2019-09-11T21:25:40Z", "title": "Selecting Data to Clean for Fact Checking: Minimizing Uncertainty vs.\n  Maximizing Surprise", "summary": "We study the optimization problem of selecting numerical quantities to clean\nin order to fact-check claims based on such data. Oftentimes, such claims are\ntechnically correct, but they can still mislead for two reasons. First, data\nmay contain uncertainty and errors. Second, data can be \"fished\" to advance\nparticular positions. In practice, fact-checkers cannot afford to clean all\ndata and must choose to clean what \"matters the most\" to checking a claim. We\nexplore alternative definitions of what \"matters the most\": one is to ascertain\nclaim qualities (by minimizing uncertainty in these measures), while an\nalternative is just to counter the claim (by maximizing the probability of\nfinding a counterargument). We show whether the two objectives align with each\nother, with important implications on when fact-checkers should exercise care\nin selective data cleaning, to avoid potential bias introduced by their desire\nto counter claims. We develop efficient algorithms for solving the various\nvariants of the optimization problem, showing significant improvements over\nnaive solutions. The problem is particularly challenging because the objectives\nin the fact-checking context are complex, non-linear functions over data. We\nobtain results that generalize to a large class of functions, with potential\napplications beyond fact-checking.", "author": [{"name": "Stavros Sintos"}, {"name": "Pankaj K. Agarwal"}, {"name": "Jun Yang"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.14778/3358701.3358708"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.14778/3358701.3358708", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1909.05380v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.05380v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.15221v2", "updated": "2021-06-30T05:00:20Z", "published": "2021-06-29T10:05:47Z", "title": "Fact Check: Analyzing Financial Events from Multilingual News Sources", "summary": "The explosion in the sheer magnitude and complexity of financial news data in\nrecent years makes it increasingly challenging for investment analysts to\nextract valuable insights and perform analysis. We propose FactCheck in\nfinance, a web-based news aggregator with deep learning models, to provide\nanalysts with a holistic view of important financial events from multilingual\nnews sources and extract events using an unsupervised clustering method. A web\ninterface is provided to examine the credibility of news articles using a\ntransformer-based fact-checker. The performance of the fact checker is\nevaluated using a dataset related to merger and acquisition (M\\&A) events and\nis shown to outperform several strong baselines.", "author": [{"name": "Linyi Yang"}, {"name": "Tin Lok James Ng"}, {"name": "Barry Smyth"}, {"name": "Ruihai Dong"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Demo"}, "link": [{"@href": "http://arxiv.org/abs/2106.15221v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.15221v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.05419v1", "updated": "2021-08-11T19:13:04Z", "published": "2021-08-11T19:13:04Z", "title": "NoFake at CheckThat! 2021: Fake News Detection Using BERT", "summary": "Much research has been done for debunking and analysing fake news. Many\nresearchers study fake news detection in the last year, but many are limited to\nsocial media data. Currently, multiples fact-checkers are publishing their\nresults in various formats. Also, multiple fact-checkers use different labels\nfor the fake news, making it difficult to make a generalisable classifier. With\nthe merge classes, the performance of the machine model can be enhanced. This\ndomain categorisation will help group the article, which will help save the\nmanual effort in assigning the claim verification. In this paper, we have\npresented BERT based classification model to predict the domain and\nclassification. We have also used additional data from fact-checked articles.\nWe have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B\nusing the additional training data.", "author": {"name": "Sushma Kumari"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF Task 3"}, "link": [{"@href": "http://arxiv.org/abs/2108.05419v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.05419v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.12841v3", "updated": "2020-08-27T04:01:13Z", "published": "2020-07-25T03:03:20Z", "title": "Combating Misinformation in Bangladesh: Roles and Responsibilities as\n  Perceived by Journalists, Fact-checkers, and Users", "summary": "There has been a growing interest within CSCW community in understanding the\ncharacteristics of misinformation propagated through computational media, and\nthe devising techniques to address the associated challenges. However, most\nwork in this area has been concentrated on the cases in the western world\nleaving a major portion of this problem unaddressed that is situated in the\nGlobal South. This paper aims to broaden the scope of this discourse by\nfocusing on this problem in the context of Bangladesh, a country in the Global\nSouth. The spread of misinformation on Facebook in Bangladesh, a country with a\npopulation over 163 million, has resulted in chaos, hate attacks, and killings.\nBy interviewing journalists, fact-checkers, in addition to surveying the\ngeneral public, we analyzed the current state of verifying misinformation in\nBangladesh. Our findings show that most people in the `news audience' want the\nnews media to verify the authenticity of online information that they see\nonline. However, the newspaper journalists say that fact-checking online\ninformation is not a part of their job, and it is also beyond their capacity\ngiven the amount of information being published online everyday. We further\nfind that the voluntary fact-checkers in Bangladesh are not equipped with\nsufficient infrastructural support to fill in this gap. We show how our\nfindings are connected to some of the core concerns of CSCW community around\nsocial media, collaboration, infrastructural politics, and information\ninequality. From our analysis, we also suggest several pathways to increase the\nimpact of fact-checking efforts through collaboration, technology design, and\ninfrastructure development.", "author": [{"name": "Md Mahfuzul Haque"}, {"name": "Mohammad Yousuf"}, {"name": "Ahmed Shatil Alam"}, {"name": "Pratyasha Saha"}, {"name": "Syed Ishtiaque Ahmed"}, {"name": "Naeemul Hassan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3415201"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3415201", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.12841v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.12841v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.10926v1", "updated": "2020-01-29T16:14:47Z", "published": "2020-01-29T16:14:47Z", "title": "HoaxItaly: a collection of Italian disinformation and fact-checking\n  stories shared on Twitter in 2019", "summary": "We released over 1 million tweets shared during 2019 and containing links to\nthousands of news articles published on two classes of Italian outlets: (1)\ndisinformation websites, i.e. outlets which have been repeatedly flagged by\njournalists and fact-checkers for producing low-credibility content such as\nfalse news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)\nfact-checking websites which notably debunk and verify online news and claims.\nThe dataset, which includes also title and body for approximately 37k news\narticles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.", "author": [{"name": "Francesco Pierri"}, {"name": "Alessandro Artoni"}, {"name": "Stefano Ceri"}], "link": [{"@href": "http://arxiv.org/abs/2001.10926v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.10926v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.06634v1", "updated": "2020-03-14T14:02:27Z", "published": "2020-03-14T14:02:27Z", "title": "Text Similarity Using Word Embeddings to Classify Misinformation", "summary": "Fake news is a growing problem in the last years, especially during\nelections. It's hard work to identify what is true and what is false among all\nthe user generated content that circulates every day. Technology can help with\nthat work and optimize the fact-checking process. In this work, we address the\nchallenge of finding similar content in order to be able to suggest to a\nfact-checker articles that could have been verified before and thus avoid that\nthe same information is verified more than once. This is especially important\nin collaborative approaches to fact-checking where members of large teams will\nnot know what content others have already fact-checked.", "author": [{"name": "Caio Almeida"}, {"name": "D\u00e9bora Santos"}], "link": [{"@href": "http://arxiv.org/abs/2003.06634v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.06634v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.07174v1", "updated": "2020-05-14T17:42:25Z", "published": "2020-05-14T17:42:25Z", "title": "Estimating predictive uncertainty for rumour verification models", "summary": "The inability to correctly resolve rumours circulating online can have\nharmful real-world consequences. We present a method for incorporating model\nand data uncertainty estimates into natural language processing models for\nautomatic rumour verification. We show that these estimates can be used to\nfilter out model predictions likely to be erroneous, so that these difficult\ninstances can be prioritised by a human fact-checker. We propose two methods\nfor uncertainty-based instance rejection, supervised and unsupervised. We also\nshow how uncertainty estimates can be used to interpret model performance as a\nrumour unfolds.", "author": [{"name": "Elena Kochkina"}, {"name": "Maria Liakata"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the Annual Conference of the Association for\n  Computational Linguistics (ACL) 2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.07174v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.07174v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1708.07239v1", "updated": "2017-08-24T01:07:21Z", "published": "2017-08-24T01:07:21Z", "title": "Finding Streams in Knowledge Graphs to Support Fact Checking", "summary": "The volume and velocity of information that gets generated online limits\ncurrent journalistic practices to fact-check claims at the same rate.\nComputational approaches for fact checking may be the key to help mitigate the\nrisks of massive misinformation spread. Such approaches can be designed to not\nonly be scalable and effective at assessing veracity of dubious claims, but\nalso to boost a human fact checker's productivity by surfacing relevant facts\nand patterns to aid their analysis. To this end, we present a novel,\nunsupervised network-flow based approach to determine the truthfulness of a\nstatement of fact expressed in the form of a (subject, predicate, object)\ntriple. We view a knowledge graph of background information about real-world\nentities as a flow network, and knowledge as a fluid, abstract commodity. We\nshow that computational fact checking of such a triple then amounts to finding\na \"knowledge stream\" that emanates from the subject node and flows toward the\nobject node through paths connecting them. Evaluation on a range of real-world\nand hand-crafted datasets of facts related to entertainment, business, sports,\ngeography and more reveals that this network-flow model can be very effective\nin discerning true statements from false ones, outperforming existing\nalgorithms on many test cases. Moreover, the model is expressive in its ability\nto automatically discover several useful path patterns and surface relevant\nfacts that may help a human fact checker corroborate or refute a claim.", "author": [{"name": "Prashant Shiralkar"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}, {"name": "Giovanni Luca Ciampaglia"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Extended version of the paper in proceedings of ICDM 2017"}, "link": [{"@href": "http://arxiv.org/abs/1708.07239v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1708.07239v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.00033v2", "updated": "2020-06-09T13:33:12Z", "published": "2020-04-30T18:04:20Z", "title": "Fighting the COVID-19 Infodemic: Modeling the Perspective of\n  Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the\n  Society", "summary": "With the emergence of the COVID-19 pandemic, the political and the medical\naspects of disinformation merged as the problem got elevated to a whole new\nlevel to become the first global infodemic. Fighting this infodemic is ranked\nsecond in the list of the most important focus areas of the World Health\nOrganization, with dangers ranging from promoting fake cures, rumors, and\nconspiracy theories to spreading xenophobia and panic. Addressing the issue\nrequires solving a number of challenging problems such as identifying messages\ncontaining claims, determining their check-worthiness and factuality, and their\npotential to do harm as well as the nature of that harm, to mention just a few.\nThus, here we design, annotate, and release to the research community a new\ndataset for fine-grained disinformation analysis that (i)focuses on COVID-19,\n(ii) combines the perspectives and the interests of journalists, fact-checkers,\nsocial media platforms, policy makers, and society as a whole, and (iii) covers\nboth English and Arabic. Finally, we show strong evaluation results using\nstate-of-the-art Transformers, thus confirming the practical utility of the\nannotation schema and of the dataset.", "author": [{"name": "Firoj Alam"}, {"name": "Shaden Shaar"}, {"name": "Fahim Dalvi"}, {"name": "Hassan Sajjad"}, {"name": "Alex Nikolov"}, {"name": "Hamdy Mubarak"}, {"name": "Giovanni Da San Martino"}, {"name": "Ahmed Abdelali"}, {"name": "Nadir Durrani"}, {"name": "Kareem Darwish"}, {"name": "Preslav Nakov"}], "link": [{"@href": "http://arxiv.org/abs/2005.00033v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.00033v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.02431v1", "updated": "2020-09-05T01:44:11Z", "published": "2020-09-05T01:44:11Z", "title": "Accenture at CheckThat! 2020: If you say so: Post-hoc fact-checking of\n  claims using transformer-based models", "summary": "We introduce the strategies used by the Accenture Team for the CLEF2020\nCheckThat! Lab, Task 1, on English and Arabic. This shared task evaluated\nwhether a claim in social media text should be professionally fact checked. To\na journalist, a statement presented as fact, which would be of interest to a\nlarge audience, requires professional fact-checking before dissemination. We\nutilized BERT and RoBERTa models to identify claims in social media text a\nprofessional fact-checker should review, and rank these in priority order for\nthe fact-checker. For the English challenge, we fine-tuned a RoBERTa model and\nadded an extra mean pooling layer and a dropout layer to enhance\ngeneralizability to unseen text. For the Arabic task, we fine-tuned\nArabic-language BERT models and demonstrate the use of back-translation to\namplify the minority class and balance the dataset. The work presented here was\nscored 1st place in the English track, and 1st, 2nd, 3rd, and 4th place in the\nArabic track.", "author": [{"name": "Evan Williams"}, {"name": "Paul Rodrigues"}, {"name": "Valerie Novak"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To Appear As: Evan Williams, Paul Rodrigues, Valerie Novak. Accenture\n  at CheckThat! 2020: If you say so: Post-hoc fact-checking of claims using\n  transformer-based models. In: Cappellato et al. Working Notes of CLEF\n  2020-Conference and Labs of the Evaluation Forum. Thessaloniki, Greece. 22-25\n  September 2020"}, "link": [{"@href": "http://arxiv.org/abs/2009.02431v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.02431v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1804.07587v1", "updated": "2018-04-20T13:00:58Z", "published": "2018-04-20T13:00:58Z", "title": "ClaimRank: Detecting Check-Worthy Claims in Arabic and English", "summary": "We present ClaimRank, an online system for detecting check-worthy claims.\nWhile originally trained on political debates, the system can work for any kind\nof text, e.g., interviews or regular news articles. Its aim is to facilitate\nmanual fact-checking efforts by prioritizing the claims that fact-checkers\nshould consider first. ClaimRank supports both Arabic and English, it is\ntrained on actual annotations from nine reputable fact-checking organizations\n(PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and\nWashington Post), and thus it can mimic the claim selection strategies for each\nand any of them, as well as for the union of them all.", "author": [{"name": "Israa Jaradat"}, {"name": "Pepa Gencheva"}, {"name": "Alberto Barron-Cedeno"}, {"name": "Lluis Marquez"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Check-worthiness; Fact-Checking; Veracity; Community-Question\n  Answering; Neural Networks; Arabic; English"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NAACL-2018"}, "link": [{"@href": "http://arxiv.org/abs/1804.07587v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.07587v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1806.09541v1", "updated": "2018-06-06T10:47:20Z", "published": "2018-06-06T10:47:20Z", "title": "Technology, Propaganda, and the Limits of Human Intellect", "summary": "\"Fake news\" is a recent phenomenon, but misinformation and propaganda are\nnot. Our new communication technologies make it easy for us to be exposed to\nhigh volumes of true, false, irrelevant, and unprovable information. Future AI\nis expected to amplify the problem even more. At the same time, our brains are\nreaching their limits in handling information. How should we respond to\npropaganda? Technology can help, but relying on it alone will not suffice in\nthe long term. We also need ethical policies, laws, regulations, and trusted\nauthorities, including fact-checkers. However, we will not solve the problem\nwithout the active engagement of the educated citizen. Epistemological\neducation, recognition of self biases and protection of our channels of\ncommunication and trusted networks are all needed to overcome the problem and\ncontinue our progress as democratic societies.", "author": {"name": "Panagiotis Metaxas"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages"}, "link": [{"@href": "http://arxiv.org/abs/1806.09541v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.09541v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.GL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.08166v2", "updated": "2021-02-14T20:33:58Z", "published": "2020-04-17T10:55:07Z", "title": "Too Many Claims to Fact-Check: Prioritizing Political Claims Based on\n  Check-Worthiness", "summary": "The massive amount of misinformation spreading on the Internet on a daily\nbasis has enormous negative impacts on societies. Therefore, we need automated\nsystems helping fact-checkers in the combat against misinformation. In this\npaper, we propose a model prioritizing the claims based on their\ncheck-worthiness. We use BERT model with additional features including\ndomain-specific controversial topics, word embeddings, and others. In our\nexperiments, we show that our proposed model outperforms all state-of-the-art\nmodels in both test collections of CLEF Check That! Lab in 2018 and 2019. We\nalso conduct a qualitative analysis to shed light-detecting check-worthy\nclaims. We suggest requesting rationales behind judgments are needed to\nunderstand subjective nature of the task and problematic labels.", "author": [{"name": "Yavuz Selim Kartal"}, {"name": "Busra Guvenen"}, {"name": "Mucahid Kutlu"}], "link": [{"@href": "http://arxiv.org/abs/2004.08166v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.08166v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2008.08854v1", "updated": "2020-08-20T09:30:05Z", "published": "2020-08-20T09:30:05Z", "title": "Checkworthiness in Automatic Claim Detection Models: Definitions and\n  Analysis of Datasets", "summary": "Public, professional and academic interest in automated fact-checking has\ndrastically increased over the past decade, with many aiming to automate one of\nthe first steps in a fact-check procedure: the selection of so-called\ncheckworthy claims. However, there is little agreement on the definition and\ncharacteristics of checkworthiness among fact-checkers, which is consequently\nreflected in the datasets used for training and testing checkworthy claim\ndetection models. After elaborate analysis of checkworthy claim selection\nprocedures in fact-check organisations and analysis of state-of-the-art claim\ndetection datasets, checkworthiness is defined as the concept of having a\nspatiotemporal and context-dependent worth and need to have the correctness of\nthe objectivity it conveys verified. This is irrespective of the claim's\nperceived veracity judgement by an individual based on prior knowledge and\nbeliefs. Concerning the characteristics of current datasets, it is argued that\nthe data is not only highly imbalanced and noisy, but also too limited in scope\nand language. Furthermore, we believe that the subjective concept of\ncheckworthiness might not be a suitable filter for claim detection.", "author": [{"name": "Liesbeth Allein"}, {"name": "Marie-Francine Moens"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-61841-4_1"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-61841-4_1", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.08854v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.08854v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.13387v2", "updated": "2021-07-10T06:08:44Z", "published": "2020-10-26T07:33:28Z", "title": "Check Mate: Prioritizing User Generated Multi-Media Content for\n  Fact-Checking", "summary": "Volume of content and misinformation on social media is rapidly increasing.\nThere is a need for systems that can support fact checkers by prioritizing\ncontent that needs to be fact checked. Prior research on prioritizing content\nfor fact-checking has focused on news media articles, predominantly in English\nlanguage. Increasingly, misinformation is found in user-generated content. In\nthis paper we present a novel dataset that can be used to prioritize\ncheck-worthy posts from multi-media content in Hindi. It is unique in its 1)\nfocus on user generated content, 2) language and 3) accommodation of\nmulti-modality in social media posts. In addition, we also provide metadata for\neach post such as number of shares and likes of the post on ShareChat, a\npopular Indian social media platform, that allows for correlative analysis\naround virality and misinformation. The data is accessible on Zenodo\n(https://zenodo.org/record/4032629) under Creative Commons Attribution License\n(CC BY 4.0).", "author": [{"name": "Tarunima Prabhakar"}, {"name": "Anushree Gupta"}, {"name": "Kruttika Nadig"}, {"name": "Denny George"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 13 figures, 2 tables"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the International AAAI Conference on Web and Social\n  Media, Volume 15(1), 2021"}, "link": [{"@href": "http://arxiv.org/abs/2010.13387v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.13387v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.05448v1", "updated": "2020-11-10T23:02:47Z", "published": "2020-11-10T23:02:47Z", "title": "Generating Fact Checking Briefs", "summary": "Fact checking at scale is difficult -- while the number of active fact\nchecking websites is growing, it remains too small for the needs of the\ncontemporary media ecosystem. However, despite good intentions, contributions\nfrom volunteers are often error-prone, and thus in practice restricted to claim\ndetection. We investigate how to increase the accuracy and efficiency of fact\nchecking by providing information about the claim before performing the check,\nin the form of natural language briefs. We investigate passage-based briefs,\ncontaining a relevant passage from Wikipedia, entity-centric ones consisting of\nWikipedia pages of mentioned entities, and Question-Answering Briefs, with\nquestions decomposing the claim, and their answers. To produce QABriefs, we\ndevelop QABriefer, a model that generates a set of questions conditioned on the\nclaim, searches the web for evidence, and generates answers. To train its\ncomponents, we introduce QABriefDataset which we collected via crowdsourcing.\nWe show that fact checking with briefs -- in particular QABriefs -- increases\nthe accuracy of crowdworkers by 10% while slightly decreasing the time taken.\nFor volunteer (unpaid) fact checkers, QABriefs slightly increase accuracy and\nreduce the time required by around 20%.", "author": [{"name": "Angela Fan"}, {"name": "Aleksandra Piktus"}, {"name": "Fabio Petroni"}, {"name": "Guillaume Wenzek"}, {"name": "Marzieh Saeidi"}, {"name": "Andreas Vlachos"}, {"name": "Antoine Bordes"}, {"name": "Sebastian Riedel"}], "link": [{"@href": "http://arxiv.org/abs/2011.05448v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.05448v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2105.10319v1", "updated": "2021-05-21T12:49:42Z", "published": "2021-05-21T12:49:42Z", "title": "The Strategy Behind Anti-Vaxxers' Reply Behavior on Social Media", "summary": "Although the online campaigns of anti-vaccine advocates, or anti-vaxxers,\nseverely threaten efforts for herd immunity, their propaganda strategies remain\npoorly understood, as does their reply behavior, which constitutes the most\ndirect form of outreach on social media. Therefore, we empirically analyzed the\nstrategy of anti-vaxxers' reply behavior on Twitter in terms of interaction\nfrequency, content, and targets. Among the results, anti-vaxxers more\nfrequently conducted reply behavior to other clusters, especially to neutral\naccounts, and the content of their replies was significantly toxic and\nemotional. Furthermore, the most-targeted users were so-called \"decent\"\naccounts with large numbers of followers, including accounts related to health\ncare or representing scientists, policymakers, or media figures or outlets. We\ndiscussed and evaluated the effectiveness of these reply strategies, as well as\nthe possible countermeasures to them. Those findings should prove useful for\ndeveloping guidelines for pro-vaxxers and fact-checkers in online communities.", "author": [{"name": "Kunihiro Miyazaki"}, {"name": "Takayuki Uchiba"}, {"name": "Kenji Tanaka"}, {"name": "Kazutoshi Sasahara"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The manuscript is currently under review. 11 pages, 2 figures"}, "link": [{"@href": "http://arxiv.org/abs/2105.10319v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.10319v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.09248v1", "updated": "2021-06-17T05:09:54Z", "published": "2021-06-17T05:09:54Z", "title": "X-FACT: A New Benchmark Dataset for Multilingual Fact Checking", "summary": "In this work, we introduce X-FACT: the largest publicly available\nmultilingual dataset for factual verification of naturally existing real-world\nclaims. The dataset contains short statements in 25 languages and is labeled\nfor veracity by expert fact-checkers. The dataset includes a multilingual\nevaluation benchmark that measures both out-of-domain generalization, and\nzero-shot capabilities of the multilingual models. Using state-of-the-art\nmultilingual transformer-based models, we develop several automated\nfact-checking models that, along with textual claims, make use of additional\nmetadata and evidence from news stories retrieved using a search engine.\nEmpirically, our best model attains an F-score of around 40%, suggesting that\nour dataset is a challenging benchmark for evaluation of multilingual\nfact-checking models.", "author": [{"name": "Ashim Gupta"}, {"name": "Vivek Srikumar"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL 2021; For data and code, see https://github.com/utahnlp/x-fact/"}, "link": [{"@href": "http://arxiv.org/abs/2106.09248v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.09248v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1804.09088v1", "updated": "2018-04-24T15:13:51Z", "published": "2018-04-24T15:13:51Z", "title": "Semi-supervised Content-based Detection of Misinformation via Tensor\n  Embeddings", "summary": "Fake news may be intentionally created to promote economic, political and\nsocial interests, and can lead to negative impacts on humans beliefs and\ndecisions. Hence, detection of fake news is an emerging problem that has become\nextremely prevalent during the last few years. Most existing works on this\ntopic focus on manual feature extraction and supervised classification models\nleveraging a large number of labeled (fake or real) articles. In contrast, we\nfocus on content-based detection of fake news articles, while assuming that we\nhave a small amount of labels, made available by manual fact-checkers or\nautomated sources. We argue this is a more realistic setting in the presence of\nmassive amounts of content, most of which cannot be easily factchecked. To that\nend, we represent collections of news articles as multi-dimensional tensors,\nleverage tensor decomposition to derive concise article embeddings that capture\nspatial/contextual information about each news article, and use those\nembeddings to create an article-by-article graph on which we propagate limited\nlabels. Results on three real-world datasets show that our method performs on\npar or better than existing models that are fully supervised, in that we\nachieve better detection accuracy using fewer labels. In particular, our\nproposed method achieves 75.43% of accuracy using only 30% of labels of a\npublic dataset while an SVM-based classifier achieved 67.43%. Furthermore, our\nmethod achieves 70.92% of accuracy in a large dataset using only 2% of labels.", "author": [{"name": "Gisel Bastidas Guacho"}, {"name": "Sara Abdali"}, {"name": "Neil Shah"}, {"name": "Evangelos E. Papalexakis"}], "link": [{"@href": "http://arxiv.org/abs/1804.09088v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.09088v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1808.09922v1", "updated": "2018-08-29T16:50:16Z", "published": "2018-08-29T16:50:16Z", "title": "Limiting the Spread of Fake News on Social Media Platforms by Evaluating\n  Users' Trustworthiness", "summary": "Today's social media platforms enable to spread both authentic and fake news\nvery quickly. Some approaches have been proposed to automatically detect such\n\"fake\" news based on their content, but it is difficult to agree on universal\ncriteria of authenticity (which can be bypassed by adversaries once known).\nBesides, it is obviously impossible to have each news item checked by a human.\n  In this paper, we a mechanism to limit the spread of fake news which is not\nbased on content. It can be implemented as a plugin on a social media platform.\nThe principle is as follows: a team of fact-checkers reviews a small number of\nnews items (the most popular ones), which enables to have an estimation of each\nuser's inclination to share fake news items. Then, using a Bayesian approach,\nwe estimate the trustworthiness of future news items, and treat accordingly\nthose of them that pass a certain \"untrustworthiness\" threshold.\n  We then evaluate the effectiveness and overhead of this technique on a large\nTwitter graph. We show that having a few thousands users exposed to one given\nnews item enables to reach a very precise estimation of its reliability. We\nthus identify more than 99% of fake news items with no false positives. The\nperformance impact is very small: the induced overhead on the 90th percentile\nlatency is less than 3%, and less than 8% on the throughput of user operations.", "author": [{"name": "Oana Balmau"}, {"name": "Rachid Guerraoui"}, {"name": "Anne-Marie Kermarrec"}, {"name": "Alexandre Maurer"}, {"name": "Matej Pavlovic"}, {"name": "Willy Zwaenepoel"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 9 figures"}, "link": [{"@href": "http://arxiv.org/abs/1808.09922v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.09922v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1909.08837v1", "updated": "2019-09-19T07:36:54Z", "published": "2019-09-19T07:36:54Z", "title": "How to Write Summaries with Patterns? Learning towards Abstractive\n  Summarization through Prototype Editing", "summary": "Under special circumstances, summaries should conform to a particular style\nwith patterns, such as court judgments and abstracts in academic papers. To\nthis end, the prototype document-summary pairs can be utilized to generate\nbetter summaries. There are two main challenges in this task: (1) the model\nneeds to incorporate learned patterns from the prototype, but (2) should avoid\ncopying contents other than the patternized words---such as irrelevant\nfacts---into the generated summaries. To tackle these challenges, we design a\nmodel named Prototype Editing based Summary Generator (PESG). PESG first learns\nsummary patterns and prototype facts by analyzing the correlation between a\nprototype document and its summary. Prototype facts are then utilized to help\nextract facts from the input document. Next, an editing generator generates new\nsummary based on the summary pattern or extracted facts. Finally, to address\nthe second challenge, a fact checker is used to estimate mutual information\nbetween the input document and generated summary, providing an additional\nsignal for the generator. Extensive experiments conducted on a large-scale\nreal-world text summarization dataset show that PESG achieves the\nstate-of-the-art performance in terms of both automatic metrics and human\nevaluations.", "author": [{"name": "Shen Gao"}, {"name": "Xiuying Chen"}, {"name": "Piji Li"}, {"name": "Zhangming Chan"}, {"name": "Dongyan Zhao"}, {"name": "Rui Yan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EMNLP 2019. Dataset available at\n  https://github.com/gsh199449/proto-summ"}, "link": [{"@href": "http://arxiv.org/abs/1909.08837v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.08837v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2006.03354v2", "updated": "2021-03-11T12:55:12Z", "published": "2020-06-05T10:32:18Z", "title": "Classification Aware Neural Topic Model and its Application on a New\n  COVID-19 Disinformation Corpus", "summary": "The explosion of disinformation accompanying the COVID-19 pandemic has\noverloaded fact-checkers and media worldwide, and brought a new major challenge\nto government responses worldwide. Not only is disinformation creating\nconfusion about medical science amongst citizens, but it is also amplifying\ndistrust in policy makers and governments. To help tackle this, we developed\ncomputational methods to categorise COVID-19 disinformation. The COVID-19\ndisinformation categories could be used for a) focusing fact-checking efforts\non the most damaging kinds of COVID-19 disinformation; b) guiding policy makers\nwho are trying to deliver effective public health messages and counter\neffectively COVID-19 disinformation. This paper presents: 1) a corpus\ncontaining what is currently the largest available set of manually annotated\nCOVID-19 disinformation categories; 2) a classification-aware neural topic\nmodel (CANTM) designed for COVID-19 disinformation category classification and\ntopic discovery; 3) an extensive analysis of COVID-19 disinformation categories\nwith respect to time, volume, false type, media type and origin source.", "author": [{"name": "Xingyi Song"}, {"name": "Johann Petrak"}, {"name": "Ye Jiang"}, {"name": "Iknoor Singh"}, {"name": "Diana Maynard"}, {"name": "Kalina Bontcheva"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0247086"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0247086", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2006.03354v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.03354v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is arXiv version of \"Classification Aware Neural Topic Model for\n  COVID-19 Disinformation Categorisation\""}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PLOS ONE 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.07996v2", "updated": "2021-04-09T08:52:10Z", "published": "2020-07-15T21:18:30Z", "title": "Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms", "summary": "With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.", "author": [{"name": "Firoj Alam"}, {"name": "Fahim Dalvi"}, {"name": "Shaden Shaar"}, {"name": "Nadir Durrani"}, {"name": "Hamdy Mubarak"}, {"name": "Alex Nikolov"}, {"name": "Giovanni Da San Martino"}, {"name": "Ahmed Abdelali"}, {"name": "Hassan Sajjad"}, {"name": "Kareem Darwish"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "COVID-19, Infodemic, Disinformation, Misinformation, Fake News, Call\n  to Arms, Crowdsourcing Annotations"}, "link": [{"@href": "http://arxiv.org/abs/2007.07996v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.07996v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.06278v3", "updated": "2021-04-21T18:00:07Z", "published": "2021-01-15T19:00:42Z", "title": "COSMOS: Catching Out-of-Context Misinformation with Self-Supervised\n  Learning", "summary": "Despite the recent attention to DeepFakes, one of the most prevalent ways to\nmislead audiences on social media is the use of unaltered images in a new but\nfalse context. To address these challenges and support fact-checkers, we\npropose a new method that automatically detects out-of-context image and text\npairs. Our key insight is to leverage the grounding of image with text to\ndistinguish out-of-context scenarios that cannot be disambiguated with language\nalone. We propose a self-supervised training strategy where we only need a set\nof captioned images. At train time, our method learns to selectively align\nindividual objects in an image with textual claims, without explicit\nsupervision. At test time, we check if both captions correspond to the same\nobject(s) in the image but are semantically different, which allows us to make\nfairly accurate out-of-context predictions. Our method achieves 85%\nout-of-context detection accuracy. To facilitate benchmarking of this task, we\ncreate a large-scale dataset of 200K images with 450K textual captions from a\nvariety of news websites, blogs, and social media posts. The dataset and source\ncode is publicly available at\nhttps://shivangi-aneja.github.io/projects/cosmos/.", "author": [{"name": "Shivangi Aneja"}, {"name": "Chris Bregler"}, {"name": "Matthias Nie\u00dfner"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Video : https://youtu.be/riI3Cl2xy10"}, "link": [{"@href": "http://arxiv.org/abs/2101.06278v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.06278v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.11105v2", "updated": "2021-04-22T16:05:49Z", "published": "2021-02-22T15:26:36Z", "title": "REMOD: Relation Extraction for Modeling Online Discourse", "summary": "The enormous amount of discourse taking place online poses challenges to the\nfunctioning of a civil and informed public sphere. Efforts to standardize\nonline discourse data, such as ClaimReview, are making available a wealth of\nnew data about potentially inaccurate claims, reviewed by third-party\nfact-checkers. These data could help shed light on the nature of online\ndiscourse, the role of political elites in amplifying it, and its implications\nfor the integrity of the online information ecosystem. Unfortunately, the\nsemi-structured nature of much of this data presents significant challenges\nwhen it comes to modeling and reasoning about online discourse. A key challenge\nis relation extraction, which is the task of determining the semantic\nrelationships between named entities in a claim. Here we develop a novel\nsupervised learning method for relation extraction that combines graph\nembedding techniques with path traversal on semantic dependency graphs. Our\napproach is based on the intuitive observation that knowledge of the entities\nalong the path between the subject and object of a triple (e.g.\nWashington,_D.C.}, and United_States_of_America) provides useful information\nthat can be leveraged for extracting its semantic relation (i.e. capitalOf). As\nan example of a potential application of this technique for modeling online\ndiscourse, we show that our method can be integrated into a pipeline to reason\nabout potential misinformation claims.", "author": [{"name": "Matthew Sumpter"}, {"name": "Giovanni Luca Ciampaglia"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/2102.11105v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.11105v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.02153v1", "updated": "2021-07-05T17:31:44Z", "published": "2021-07-05T17:31:44Z", "title": "FaVIQ: FAct Verification from Information-seeking Questions", "summary": "Despite significant interest in developing general purpose fact checking\nmodels, it is challenging to construct a large-scale fact verification dataset\nwith realistic claims that would occur in the real world. Existing claims are\neither authored by crowdworkers, thereby introducing subtle biases that are\ndifficult to control for, or manually verified by professional fact checkers,\ncausing them to be expensive and limited in scale. In this paper, we construct\na challenging, realistic, and large-scale fact verification dataset called\nFaVIQ, using information-seeking questions posed by real users who do not know\nhow to answer. The ambiguity in information-seeking questions enables\nautomatically constructing true and false claims that reflect confusions arisen\nfrom users (e.g., the year of the movie being filmed vs. being released). Our\nclaims are verified to be natural, contain little lexical bias, and require a\ncomplete understanding of the evidence for verification. Our experiments show\nthat the state-of-the-art models are far from solving our new task. Moreover,\ntraining on our data helps in professional fact-checking, outperforming models\ntrained on the most widely used dataset FEVER or in-domain data by up to 17%\nabsolute. Altogether, our data will serve as a challenging benchmark for\nnatural language understanding and support future progress in professional fact\nchecking.", "author": [{"name": "Jungsoo Park"}, {"name": "Sewon Min"}, {"name": "Jaewoo Kang"}, {"name": "Luke Zettlemoyer"}, {"name": "Hannaneh Hajishirzi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages, 3 figures; Data & Code available at https://faviq.github.io"}, "link": [{"@href": "http://arxiv.org/abs/2107.02153v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.02153v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.05684v1", "updated": "2021-07-12T18:46:47Z", "published": "2021-07-12T18:46:47Z", "title": "Accenture at CheckThat! 2021: Interesting claim identification and\n  ranking with contextually sensitive lexical training data augmentation", "summary": "This paper discusses the approach used by the Accenture Team for CLEF2021\nCheckThat! Lab, Task 1, to identify whether a claim made in social media would\nbe interesting to a wide audience and should be fact-checked. Twitter training\nand test data were provided in English, Arabic, Spanish, Turkish, and\nBulgarian. Claims were to be classified (check-worthy/not check-worthy) and\nranked in priority order for the fact-checker. Our method used deep neural\nnetwork transformer models with contextually sensitive lexical augmentation\napplied on the supplied training datasets to create additional training\nsamples. This augmentation approach improved the performance for all languages.\nOverall, our architecture and data augmentation pipeline produced the best\nsubmitted system for Arabic, and performance scales according to the quantity\nof provided training data for English, Spanish, Turkish, and Bulgarian. This\npaper investigates the deep neural network architectures for each language as\nwell as the provided data to examine why the approach worked so effectively for\nArabic, and discusses additional data augmentation measures that should could\nbe useful to this problem.", "author": [{"name": "Evan Williams"}, {"name": "Paul Rodrigues"}, {"name": "Sieu Tran"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To Appear As: Evan Williams, Paul Rodrigues, Sieu Tran. Accenture at\n  CheckThat! 2021: Interesting claim identification and ranking with\n  contextually sensitive lexical training data augmentation. In: Faggioli et\n  al. Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum.\n  Bucharest, Romania. 21-24 September 2021"}, "link": [{"@href": "http://arxiv.org/abs/2107.05684v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.05684v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}]