[{"id": "http://arxiv.org/abs/2102.00976v1", "updated": "2021-02-01T16:59:31Z", "published": "2021-02-01T16:59:31Z", "title": "Can Predominant Credible Information Suppress Misinformation in Crises?\n  Empirical Studies of Tweets Related to Prevention Measures during COVID-19", "summary": "During COVID-19, misinformation on social media affects the adoption of\nappropriate prevention behaviors. It is urgent to suppress the misinformation\nto prevent negative public health consequences. Although an array of studies\nhas proposed misinformation suppression strategies, few have investigated the\nrole of predominant credible information during crises. None has examined its\neffect quantitatively using longitudinal social media data. Therefore, this\nresearch investigates the temporal correlations between credible information\nand misinformation, and whether predominant credible information can suppress\nmisinformation for two prevention measures (i.e. topics), i.e. wearing masks\nand social distancing using tweets collected from February 15 to June 30, 2020.\nWe trained Support Vector Machine classifiers to retrieve relevant tweets and\nclassify tweets containing credible information and misinformation for each\ntopic. Based on cross-correlation analyses of credible and misinformation time\nseries for both topics, we find that the previously predominant credible\ninformation can lead to the decrease of misinformation (i.e. suppression) with\na time lag. The research findings provide empirical evidence for suppressing\nmisinformation with credible information in complex online environments and\nsuggest practical strategies for future information management during crises\nand emergencies.", "author": [{"name": "Yan Wang"}, {"name": "Shangde Gao"}, {"name": "Wenyu Gao"}], "link": [{"@href": "http://arxiv.org/abs/2102.00976v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.00976v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.00124v2", "updated": "2021-04-03T17:34:31Z", "published": "2021-03-31T21:12:29Z", "title": "Misinformation detection in Luganda-English code-mixed social media text", "summary": "The increasing occurrence, forms, and negative effects of misinformation on\nsocial media platforms has necessitated more misinformation detection tools.\nCurrently, work is being done addressing COVID-19 misinformation however, there\nare no misinformation detection tools for any of the 40 distinct indigenous\nUgandan languages. This paper addresses this gap by presenting basic language\nresources and a misinformation detection data set based on code-mixed\nLuganda-English messages sourced from the Facebook and Twitter social media\nplatforms. Several machine learning methods are applied on the misinformation\ndetection data set to develop classification models for detecting whether a\ncode-mixed Luganda-English message contains misinformation or not. A 10-fold\ncross validation evaluation of the classification methods in an experimental\nmisinformation detection task shows that a Discriminative Multinomial Naive\nBayes (DMNB) method achieves the highest accuracy and F-measure of 78.19% and\n77.90% respectively. Also, Support Vector Machine and Bagging ensemble\nclassification models achieve comparable results. These results are promising\nsince the machine learning models are based on n-gram features from only the\nmisinformation detection dataset.", "author": [{"name": "Peter Nabende"}, {"name": "David Kabiito"}, {"name": "Claire Babirye"}, {"name": "Hewitt Tusiime"}, {"name": "Joyce Nakatumba-Nabende"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at African NLP workshop @EACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.00124v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.00124v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.11702v4", "updated": "2021-07-08T08:39:43Z", "published": "2021-06-22T12:17:53Z", "title": "Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study\n  of COVID-19 Infodemic", "summary": "The spreading COVID-19 misinformation over social media already draws the\nattention of many researchers. According to Google Scholar, about 26000\nCOVID-19 related misinformation studies have been published to date. Most of\nthese studies focusing on 1) detect and/or 2) analysing the characteristics of\nCOVID-19 related misinformation. However, the study of the social behaviours\nrelated to misinformation is often neglected. In this paper, we introduce a\nfine-grained annotated misinformation tweets dataset including social\nbehaviours annotation (e.g. comment or question to the misinformation). The\ndataset not only allows social behaviours analysis but also suitable for both\nevidence-based or non-evidence-based misinformation classification task. In\naddition, we introduce leave claim out validation in our experiments and\ndemonstrate the misinformation classification performance could be\nsignificantly different when applying to real-world unseen misinformation.", "author": [{"name": "Ye Jiang"}, {"name": "Xingyi Song"}, {"name": "Carolina Scarton"}, {"name": "Ahmet Aker"}, {"name": "Kalina Bontcheva"}], "link": [{"@href": "http://arxiv.org/abs/2106.11702v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.11702v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.02471v2", "updated": "2020-08-06T03:11:38Z", "published": "2020-06-03T18:28:57Z", "title": "Can WhatsApp Benefit from Debunked Fact-Checked Stories to Reduce\n  Misinformation?", "summary": "WhatsApp was alleged to be widely used to spread misinformation and\npropaganda during elections in Brazil and India. Due to the private encrypted\nnature of the messages on WhatsApp, it is hard to track the dissemination of\nmisinformation at scale. In this work, using public WhatsApp data, we observe\nthat misinformation has been largely shared on WhatsApp public groups even\nafter they were already fact-checked by popular fact-checking agencies. This\nrepresents a significant portion of misinformation spread in both Brazil and\nIndia in the groups analyzed. We posit that such misinformation content could\nbe prevented if WhatsApp had a means to flag already fact-checked content. To\nthis end, we propose an architecture that could be implemented by WhatsApp to\ncounter such misinformation. Our proposal respects the current end-to-end\nencryption architecture on WhatsApp, thus protecting users' privacy while\nproviding an approach to detect the misinformation that benefits from\nfact-checking efforts.", "author": [{"name": "Julio C. S. Reis"}, {"name": "Philipe de Freitas Melo"}, {"name": "Kiran Garimella"}, {"name": "Fabr\u00edcio Benevenuto"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a preprint version of an accepted manuscript on The Harvard\n  Kennedy School (HKS) Misinformation Review. Please, consider to cite it\n  instead of this one"}, "link": [{"@href": "http://arxiv.org/abs/2006.02471v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.02471v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.14806v1", "updated": "2020-07-29T12:46:45Z", "published": "2020-07-29T12:46:45Z", "title": "Towards Domain-Specific Characterization of Misinformation", "summary": "The rapid dissemination of health misinformation poses an increasing risk to\npublic health. To best understand the way of combating health misinformation,\nit is important to acknowledge how the fundamental characteristics of\nmisinformation differ from domain to domain. This paper presents a pathway\ntowards domain-specific characterization of misinformation so that we can\naddress the concealed behavior of health misinformation compared to others and\ntake proper initiative accordingly for combating it. With this aim, we have\nmentioned several possible approaches to identify discriminating features of\nmedical misinformation from other types of misinformation. Thereafter, we\nbriefly propose a research plan followed by possible challenges to meet up. The\nfindings of the proposed research idea will provide new directions to the\nmisinformation research community.", "author": [{"name": "Fariha Afsana"}, {"name": "Muhammad Ashad Kabir"}, {"name": "Naeemul Hassan"}, {"name": "Manoranjan Paul"}], "link": [{"@href": "http://arxiv.org/abs/2007.14806v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.14806v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1903.07136v1", "updated": "2019-03-17T17:37:39Z", "published": "2019-03-17T17:37:39Z", "title": "Human-Misinformation interaction: Understanding the interdisciplinary\n  approach needed to computationally combat false information", "summary": "The prevalence of new technologies and social media has amplified the effects\nof misinformation on our societies. Thus, it is necessary to create\ncomputational tools to mitigate their effects effectively. This study aims to\nprovide a critical overview of computational approaches concerned with\ncombating misinformation. To this aim, I offer an overview of scholarly\ndefinitions of misinformation. I adopt a framework for studying misinformation\nthat suggests paying attention to the source, content, and consumers as the\nthree main elements involved in the process of misinformation and I provide an\noverview of literature from disciplines of psychology, media studies, and\ncognitive sciences that deal with each of these elements. Using the framework,\nI overview the existing computational methods that deal with 1) misinformation\ndetection and fact-checking using Content 2) Identifying untrustworthy Sources\nand social bots, and 3) Consumer-facing tools and methods aiming to make humans\nresilient to misinformation. I find that the vast majority of works in computer\nscience and information technology is concerned with the crucial tasks of\ndetection and verification of content and sources of misinformation. Moreover,\nI find that computational research focusing on Consumers of Misinformation in\nHuman-Computer Interaction (HCI) and related fields are very sparse and often\ndo not deal with the subtleties of this process. The majority of existing\ninterfaces and systems are less concerned with the usability of the tools\nrather than the robustness and accuracy of the detection methods. Using this\nsurvey, I call for an interdisciplinary approach towards human-misinformation\ninteraction that focuses on building methods and tools that robustly deal with\nsuch complex psychological/social phenomena.", "author": {"name": "Alireza Karduni"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "21 pages, 2 figures"}, "link": [{"@href": "http://arxiv.org/abs/1903.07136v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.07136v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.12468v1", "updated": "2020-09-25T22:48:51Z", "published": "2020-09-25T22:48:51Z", "title": "Investigating Misinformation in Online Marketplaces: An Audit Study on\n  Amazon", "summary": "Search and recommendation systems are ubiquitous and irreplaceable tools in\nour daily lives. Despite their critical role in selecting and ranking the most\nrelevant information, they typically do not consider the veracity of\ninformation presented to the user. In this paper, we introduce an audit\nmethodology to investigate the extent of misinformation presented in search\nresults and recommendations on online marketplaces. We investigate the factors\nand personalization attributes that influence the amount of misinformation in\nsearches and recommendations. Recently, several media reports criticized Amazon\nfor hosting and recommending items that promote misinformation on topics such\nas vaccines. Motivated by those reports, we apply our algorithmic auditing\nmethodology on Amazon to verify those claims. Our audit study investigates (a)\nfactors that might influence the search algorithms of Amazon and (b)\npersonalization attributes that contribute to amplifying the amount of\nmisinformation recommended to users in their search results and\nrecommendations. Our audit study collected ~526k search results and ~182k\nhomepage recommendations, with ~8.5k unique items. Each item is annotated for\nits stance on vaccines' misinformation (pro, neutral, or anti). Our study\nreveals that (1) the selection and ranking by the default Featured search\nalgorithm of search results that have misinformation stances are positively\ncorrelated with the stance of search queries and customers' evaluation of items\n(ratings and reviews), (2) misinformation stances of search results are neither\naffected by users' activities nor by interacting (browsing, wish-listing,\nshopping) with items that have a misinformation stance, and (3) a filter bubble\nbuilt-in users' homepages have a misinformation stance positively correlated\nwith the misinformation stance of items that a user interacts with.", "author": [{"name": "Eslam Hussein"}, {"name": "Hoda Eldardiry"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 9 figures, submitted to ASONAM"}, "link": [{"@href": "http://arxiv.org/abs/2009.12468v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.12468v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.06455v2", "updated": "2020-10-15T03:23:26Z", "published": "2020-10-13T15:10:26Z", "title": "Characterizing and Comparing COVID-19 Misinformation Across Languages,\n  Countries and Platforms", "summary": "Misinformation/disinformation about COVID-19 has been rampant on social media\naround the world. In this study, we investigate COVID-19 misinformation/\ndisinformation on social media in multiple languages - Farsi (Persian),\nChinese, and English, about multiple countries - Iran, China, and the United\nStates (US), and on multiple platforms such as Twitter, Facebook, Instagram,\nWeibo, and WhatsApp. Misinformation, especially about a global pandemic, is a\nglobal problem yet it is common for studies of COVID-19 misinformation on\nsocial media to focus on a single language, like English, a single country,\nlike the US, or a single platform, like Twitter. We utilized opportunistic\nsampling to compile 200 specific items of viral and yet debunked misinformation\nacross these languages, countries and platforms emerged between January 1 and\nAugust 31. We then categorized this collection based both on the topics of the\nmisinformation and the underlying roots of that misinformation. Our\nmulti-cultural and multilingual team observed that the nature of COVID-19\nmisinformation on social media varied in substantial ways across different\nlanguages/countries depending on the cultures, beliefs/religions, popularity of\nsocial media, types of platforms, freedom of speech and the power of people\nversus governments. We observe that politics is at the root of most of the\ncollected misinformation across all three languages in this dataset. We further\nobserve the different impact of government restrictions on platforms and\nplatform restrictions on content in Iran, China, and the US and their impact on\na key question of our age: how do we control misinformation without silencing\nthe voices we need to hold governments accountable?", "author": [{"name": "Golshan Madraki"}, {"name": "Isabella Grasso"}, {"name": "Jacqueline Otala"}, {"name": "Yu Liu"}, {"name": "Jeanna Matthews"}], "link": [{"@href": "http://arxiv.org/abs/2010.06455v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.06455v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.12191v1", "updated": "2021-03-22T21:44:32Z", "published": "2021-03-22T21:44:32Z", "title": "Using an Epidemiological Model to Study the Spread of Misinformation\n  during the Black Lives Matter Movement", "summary": "The proliferation of social media platforms like Twitter has heightened the\nconsequences of the spread of misinformation. To understand and model the\nspread of misinformation, in this paper, we leveraged the SEIZ (Susceptible,\nExposed, Infected, Skeptics) epidemiological model to describe the underlying\nprocess that delineates the spread of misinformation on Twitter. Compared to\nthe other epidemiological models, this model produces broader results because\nit includes the additional Skeptics (Z) compartment, wherein a user may be\nexposed to an item of misinformation but not engage in any reaction to it, and\nthe additional Exposed (E) compartment, wherein the user may need some time\nbefore deciding to spread a misinformation item. We analyzed misinformation\nregarding the unrest in Washington, D.C. in the month of March 2020 which was\npropagated by the use of the #DCblackout hashtag by different users across the\nU.S. on Twitter. Our analysis shows that misinformation can be modeled using\nthe concept of epidemiology. To the best of our knowledge, this research is the\nfirst to attempt to apply the SEIZ epidemiological model to the spread of a\nspecific item of misinformation, which is a category distinct from that of\nrumor, and a hoax on online social media platforms. Applying a mathematical\nmodel can help to understand the trends and dynamics of the spread of\nmisinformation on Twitter and ultimately help to develop techniques to quickly\nidentify and control it.", "author": [{"name": "Maryam Maleki"}, {"name": "Esther Mead"}, {"name": "Mohammad Arani"}, {"name": "Nitin Agarwal"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This paper is accepted on the International Conference on Fake News,\n  Social Media Manipulation and Misinformation 2021 (ICFNSMMM 2021)"}, "link": [{"@href": "http://arxiv.org/abs/2103.12191v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.12191v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.08423v1", "updated": "2021-06-15T20:32:10Z", "published": "2021-06-15T20:32:10Z", "title": "COVID-19 Vaccines: Characterizing Misinformation Campaigns and Vaccine\n  Hesitancy on Twitter", "summary": "Vaccine hesitancy and misinformation on social media has increased concerns\nabout COVID-19 vaccine uptake required to achieve herd immunity and overcome\nthe pandemic. However anti-science and political misinformation and\nconspiracies have been rampant throughout the pandemic. For COVID-19 vaccines,\nwe investigate misinformation and conspiracy campaigns and their characteristic\nbehaviours. We identify whether coordinated efforts are used to promote\nmisinformation in vaccine related discussions, and find accounts coordinately\npromoting a `Great Reset' conspiracy group promoting vaccine related\nmisinformation and strong anti-vaccine and anti-social messages such as boycott\nvaccine passports, no lock-downs and masks. We characterize other\nmisinformation communities from the information diffusion structure, and study\nthe large anti-vaccine misinformation community and smaller anti-vaccine\ncommunities, including a far-right anti-vaccine conspiracy group. In comparison\nwith the mainstream and health news, left-leaning group, which are more\npro-vaccine, the right-leaning group is influenced more by the anti-vaccine and\nfar-right misinformation/conspiracy communities. The misinformation communities\nare more vocal either specific to the vaccine discussion or political\ndiscussion, and we find other differences in the characteristic behaviours of\ndifferent communities. Lastly, we investigate misinformation narratives and\ntactics of information distortion that can increase vaccine hesitancy, using\ntopic modeling and comparison with reported vaccine side-effects (VAERS)\nfinding rarer side-effects are more frequently discussed on social media.", "author": [{"name": "Karishma Sharma"}, {"name": "Yizhou Zhang"}, {"name": "Yan Liu"}], "link": [{"@href": "http://arxiv.org/abs/2106.08423v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.08423v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.08419v2", "updated": "2021-01-29T20:15:18Z", "published": "2021-01-21T03:16:29Z", "title": "Auditing E-Commerce Platforms for Algorithmically Curated Vaccine\n  Misinformation", "summary": "There is a growing concern that e-commerce platforms are amplifying\nvaccine-misinformation. To investigate, we conduct two-sets of algorithmic\naudits for vaccine misinformation on the search and recommendation algorithms\nof Amazon -- world's leading e-retailer. First, we systematically audit\nsearch-results belonging to vaccine-related search-queries without logging into\nthe platform -- unpersonalized audits. We find 10.47% of search-results promote\nmisinformative health products. We also observe ranking-bias, with Amazon\nranking misinformative search-results higher than debunking search-results.\nNext, we analyze the effects of personalization due to account-history, where\nhistory is built progressively by performing various real-world user-actions,\nsuch as clicking a product. We find evidence of filter-bubble effect in\nAmazon's recommendations; accounts performing actions on misinformative\nproducts are presented with more misinformation compared to accounts performing\nactions on neutral and debunking products. Interestingly, once user clicks on a\nmisinformative product, homepage recommendations become more contaminated\ncompared to when user shows an intention to buy that product.", "author": [{"name": "Prerna Juneja"}, {"name": "Tanushree Mitra"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3411764.3445250"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3411764.3445250", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2101.08419v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.08419v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CHI Conference on Human Factors in Computing Systems 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.14748v1", "updated": "2021-03-26T21:53:38Z", "published": "2021-03-26T21:53:38Z", "title": "Analysing the Effect of Recommendation Algorithms on the Amplification\n  of Misinformation", "summary": "Recommendation algorithms have been pointed out as one of the major culprits\nof misinformation spreading in the digital sphere. However, it is still unclear\nhow these algorithms really propagate misinformation, e.g., it has not been\nshown which particular recommendation approaches are more prone to suggest\nmisinforming items, or which internal parameters of the algorithms could be\ninfluencing more on their misinformation propagation capacity.\n  Motivated by this fact, in this paper we present an analysis of the effect of\nsome of the most popular recommendation algorithms on the spread of\nmisinformation in Twitter. A set of guidelines on how to adapt these algorithms\nis provided based on such analysis and a comprehensive review of the research\nliterature. A dataset is also generated and released to the scientific\ncommunity to stimulate discussions on the future design and development of\nrecommendation algorithms to counter misinformation. The dataset includes\neditorially labelled news items and claims regarding their misinformation\nnature.", "author": [{"name": "Miriam Fern\u00e1ndez"}, {"name": "Alejandro Bellog\u00edn"}, {"name": "Iv\u00e1n Cantador"}], "link": [{"@href": "http://arxiv.org/abs/2103.14748v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.14748v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.00941v1", "updated": "2021-07-02T10:02:36Z", "published": "2021-07-02T10:02:36Z", "title": "Misinformation Detection on YouTube Using Video Captions", "summary": "Millions of people use platforms such as YouTube, Facebook, Twitter, and\nother mass media. Due to the accessibility of these platforms, they are often\nused to establish a narrative, conduct propaganda, and disseminate\nmisinformation. This work proposes an approach that uses state-of-the-art NLP\ntechniques to extract features from video captions (subtitles). To evaluate our\napproach, we utilize a publicly accessible and labeled dataset for classifying\nvideos as misinformation or not. The motivation behind exploring video captions\nstems from our analysis of videos metadata. Attributes such as the number of\nviews, likes, dislikes, and comments are ineffective as videos are hard to\ndifferentiate using this information. Using caption dataset, the proposed\nmodels can classify videos among three classes (Misinformation, Debunking\nMisinformation, and Neutral) with 0.85 to 0.90 F1-score. To emphasize the\nrelevance of the misinformation class, we re-formulate our classification\nproblem as a two-class classification - Misinformation vs. others (Debunking\nMisinformation and Neutral). In our experiments, the proposed models can\nclassify videos with 0.92 to 0.95 F1-score and 0.78 to 0.90 AUC ROC.", "author": [{"name": "Raj Jagtap"}, {"name": "Abhinav Kumar"}, {"name": "Rahul Goel"}, {"name": "Shakshi Sharma"}, {"name": "Rajesh Sharma"}, {"name": "Clint P. George"}], "link": [{"@href": "http://arxiv.org/abs/2107.00941v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.00941v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.05243v1", "updated": "2021-04-12T07:25:49Z", "published": "2021-04-12T07:25:49Z", "title": "On Unifying Misinformation Detection", "summary": "In this paper, we introduce UnifiedM2, a general-purpose misinformation model\nthat jointly models multiple domains of misinformation with a single, unified\nsetup. The model is trained to handle four tasks: detecting news bias,\nclickbait, fake news, and verifying rumors. By grouping these tasks together,\nUnifiedM2learns a richer representation of misinformation, which leads to\nstate-of-the-art or comparable performance across all tasks. Furthermore, we\ndemonstrate that UnifiedM2's learned representation is helpful for few-shot\nlearning of unseen misinformation tasks/datasets and model's generalizability\nto unseen events.", "author": [{"name": "Nayeon Lee"}, {"name": "Belinda Z. Li"}, {"name": "Sinong Wang"}, {"name": "Pascale Fung"}, {"name": "Hao Ma"}, {"name": "Wen-tau Yih"}, {"name": "Madian Khabsa"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to NAACL2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.05243v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.05243v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.00397v1", "updated": "2019-09-01T13:32:08Z", "published": "2019-09-01T13:32:08Z", "title": "Misinformation spreading on correlated multiplex networks", "summary": "The numerous expanding online social networks offer fast channels for\nmisinformation spreading, which could have a serious impact on socioeconomic\nsystems. Researchers across multiple areas have paid attention to this issue\nwith a view of addressing it. However, no systematical theoretical study has\nbeen performed to date on observing misinformation spreading on correlated\nmultiplex networks. In this study, we propose a multiplex network-based\nmisinformation spreading model, considering the fact that each individual can\nobtain misinformation from multiple platforms. Subsequently, we develop a\nheterogeneous edge-base compartmental theory to comprehend the spreading\ndynamics of our proposed model. In addition, we establish an analytical method\nbased on stability analysis to obtain the misinformation outbreak threshold. On\nthe basis of these theories, we finally analyze the influence of different\ndynamical and structural parameters on the misinformation spreading dynamics.\nResults show that the misinformation outbreak size $R(\\infty)$ grows\ncontinuously with the effective transmission probability $\\beta$ once $\\beta$\nexceeds a certain value, that is, the outbreak threshold $\\beta_c$. A large\naverage degrees, strong degree heterogeneity, or positive inter-layer\ncorrelation will reduce $\\beta_c$, accelerating the outbreak of misinformation.\nBesides, increasing the degree heterogeneity or a more positive inter-layer\ncorrelation will both enlarge (reduce) $R(\\infty)$ for small (large) values of\n$\\beta$. Our systematic theoretical analysis results agree well with the\nnumerical simulation results. Our proposed model and accurate theoretical\nanalysis will serve as a useful framework to understand and predict the\nspreading dynamics of misinformation on multiplex networks, and thereby pave\nthe way to address this serious issue.", "author": [{"name": "Jiajun Xian"}, {"name": "Dan Yang"}, {"name": "Liming Pan"}, {"name": "Wei Wang"}, {"name": "Zhen Wang"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1063/1.5121394"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1063/1.5121394", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1909.00397v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.00397v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.00791v4", "updated": "2020-09-19T07:11:39Z", "published": "2020-08-03T11:44:22Z", "title": "Characterizing COVID-19 Misinformation Communities Using a Novel Twitter\n  Dataset", "summary": "From conspiracy theories to fake cures and fake treatments, COVID-19 has\nbecome a hot-bed for the spread of misinformation online. It is more important\nthan ever to identify methods to debunk and correct false information online.\nIn this paper, we present a methodology and analyses to characterize the two\ncompeting COVID-19 misinformation communities online: (i) misinformed users or\nusers who are actively posting misinformation, and (ii) informed users or users\nwho are actively spreading true information, or calling out misinformation. The\ngoals of this study are two-fold: (i) collecting a diverse set of annotated\nCOVID-19 Twitter dataset that can be used by the research community to conduct\nmeaningful analysis; and (ii) characterizing the two target communities in\nterms of their network structure, linguistic patterns, and their membership in\nother communities. Our analyses show that COVID-19 misinformed communities are\ndenser, and more organized than informed communities, with a possibility of a\nhigh volume of the misinformation being part of disinformation campaigns. Our\nanalyses also suggest that a large majority of misinformed users may be\nanti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19\ninformed users tend to use more narratives than misinformed users.", "author": [{"name": "Shahan Ali Memon"}, {"name": "Kathleen M. Carley"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, In Proceedings of The 5th International Workshop on Mining\n  Actionable Insights from Social Networks (MAISoN 2020), co-located with CIKM"}, "link": [{"@href": "http://arxiv.org/abs/2008.00791v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.00791v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.02164v2", "updated": "2020-12-23T15:13:31Z", "published": "2020-12-03T18:47:34Z", "title": "Predicting Misinformation and Engagement in COVID-19 Twitter Discourse\n  in the First Months of the Outbreak", "summary": "Disinformation entails the purposeful dissemination of falsehoods towards a\ngreater dubious agenda and the chaotic fracturing of a society. The general\npublic has grown aware of the misuse of social media towards these nefarious\nends, where even global public health crises have not been immune to\nmisinformation (deceptive content spread without intended malice). In this\npaper, we examine nearly 505K COVID-19-related tweets from the initial months\nof the pandemic to understand misinformation as a function of bot-behavior and\nengagement. Using a correlation-based feature selection method, we selected the\n11 most relevant feature subsets among over 170 features to distinguish\nmisinformation from facts, and to predict highly engaging misinformation tweets\nabout COVID-19. We achieved an average F-score of at least 72\\% with ten\npopular multi-class classifiers, reinforcing the relevance of the selected\nfeatures. We found that (i) real users tweet both facts and misinformation,\nwhile bots tweet proportionally more misinformation; (ii) misinformation tweets\nwere less engaging than facts; (iii) the textual content of a tweet was the\nmost important to distinguish fact from misinformation while (iv) user account\nmetadata and human-like activity were most important to predict high engagement\nin factual and misinformation tweets; and (v) sentiment features were not\nrelevant.", "author": [{"name": "Mirela Silva"}, {"name": "Fabr\u00edcio Ceschin"}, {"name": "Prakash Shrestha"}, {"name": "Christopher Brant"}, {"name": "Juliana Fernandes"}, {"name": "Catia S. Silva"}, {"name": "Andr\u00e9 Gr\u00e9gio"}, {"name": "Daniela Oliveira"}, {"name": "Luiz Giovanini"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "26 pages, 5 figures, 4 tables"}, "link": [{"@href": "http://arxiv.org/abs/2012.02164v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.02164v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.09665v1", "updated": "2021-01-24T07:21:50Z", "published": "2021-01-24T07:21:50Z", "title": "Corrective Information Does Not Necessarily Curb Social Disruption", "summary": "The spread of misinformation can cause social confusion. The authenticity of\ninformation on a social networking service (SNS) is unknown, and false\ninformation can be easily spread. Consequently, many studies have been\nconducted on methods to control the spread of misinformation on social\nnetworking sites. However, few studies have examined the impact of the spread\nof misinformation and its corrections on society. This study models the impact\nof the reduction of misinformation and the diffusion of corrective information\non social disruption, and it identifies the features of this impact. In this\nstudy, we analyzed misinformation regarding the shortage of toilet paper during\nthe 2020 COVID-19 epidemic, its corrections, and the excessive purchasing\ncaused by this information. First, we analyze the amount of misinformation and\ncorrective information spread on SNS, and we create a regression model to\nestimate the real-world impact of misinformation and its correction. This model\nis used to analyze the change in real-world impact corresponding to the change\nin the diffusion of misinformation and corrective information. Our analysis\nshows that the corrective information was spread to a much greater extent than\nthe misinformation. In addition, our model reveals that the corrective\ninformation was what caused the excessive purchasing behavior. As a result of\nour further analysis, we found that the amount of diffusion of corrective\ninformation required to minimize the impact on the real world depends on the\namount of the diffusion of misinformation.", "author": [{"name": "Ryusuke Iizuka"}, {"name": "Fujio Toriumi"}, {"name": "Mao Nishiguchi"}, {"name": "Masanori Takano"}, {"name": "Mitsuo Yoshida"}], "link": [{"@href": "http://arxiv.org/abs/2101.09665v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.09665v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.02314v2", "updated": "2021-08-30T03:29:48Z", "published": "2021-08-04T23:27:10Z", "title": "Automatic Detection of COVID-19 Vaccine Misinformation with Graph Link\n  Prediction", "summary": "Enormous hope in the efficacy of vaccines became recently a successful\nreality in the fight against the COVID-19 pandemic. However, vaccine hesitancy,\nfueled by exposure to social media misinformation about COVID-19 vaccines\nbecame a major hurdle. Therefore, it is essential to automatically detect where\nmisinformation about COVID-19 vaccines on social media is spread and what kind\nof misinformation is discussed, such that inoculation interventions can be\ndelivered at the right time and in the right place, in addition to\ninterventions designed to address vaccine hesitancy. This paper is addressing\nthe first step in tackling hesitancy against COVID-19 vaccines, namely the\nautomatic detection of known misinformation about the vaccines on Twitter, the\nsocial media platform that has the highest volume of conversations about\nCOVID-19 and its vaccines. We present CoVaxLies, a new dataset of tweets judged\nrelevant to several misinformation targets about COVID-19 vaccines on which a\nnovel method of detecting misinformation was developed. Our method organizes\nCoVaxLies in a Misinformation Knowledge Graph as it casts misinformation\ndetection as a graph link prediction problem. The misinformation detection\nmethod detailed in this paper takes advantage of the link scoring functions\nprovided by several knowledge embedding methods. The experimental results\ndemonstrate the superiority of this method when compared with\nclassification-based methods, widely used currently.", "author": [{"name": "Maxwell A. Weinzierl"}, {"name": "Sanda M. Harabagiu"}], "link": [{"@href": "http://arxiv.org/abs/2108.02314v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.02314v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1809.06486v2", "updated": "2018-09-20T20:49:08Z", "published": "2018-09-18T00:22:26Z", "title": "On Misinformation Containment in Online Social Networks", "summary": "The widespread online misinformation could cause public panic and serious\neconomic damages. The misinformation containment problem aims at limiting the\nspread of misinformation in online social networks by launching competing\ncampaigns. Motivated by realistic scenarios, we present the first analysis of\nthe misinformation containment problem for the case when an arbitrary number of\ncascades are allowed. This paper makes four contributions. First, we provide a\nformal model for multi-cascade diffusion and introduce an important concept\ncalled as cascade priority. Second, we show that the misinformation containment\nproblem cannot be approximated within a factor of\n$\\Omega(2^{\\log^{1-\\epsilon}n^4})$ in polynomial time unless $NP \\subseteq\nDTIME(n^{\\polylog{n}})$. Third, we introduce several types of cascade priority\nthat are frequently seen in real social networks. Finally, we design novel\nalgorithms for solving the misinformation containment problem. The\neffectiveness of the proposed algorithm is supported by encouraging\nexperimental results.", "author": [{"name": "Guangmo Tong"}, {"name": "Weili Wu"}, {"name": "Ding-Zhu Du"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NIPS 2018"}, "link": [{"@href": "http://arxiv.org/abs/1809.06486v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.06486v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2006.00885v3", "updated": "2020-11-03T20:37:11Z", "published": "2020-05-22T19:08:14Z", "title": "CoAID: COVID-19 Healthcare Misinformation Dataset", "summary": "As the COVID-19 virus quickly spreads around the world, unfortunately,\nmisinformation related to COVID-19 also gets created and spreads like wild\nfire. Such misinformation has caused confusion among people, disruptions in\nsociety, and even deadly consequences in health problems. To be able to\nunderstand, detect, and mitigate such COVID-19 misinformation, therefore, has\nnot only deep intellectual values but also huge societal impacts. To help\nresearchers combat COVID-19 health misinformation, therefore, we present CoAID\n(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare\nmisinformation, including fake news on websites and social platforms, along\nwith users' social engagement about such news. CoAID includes 4,251 news,\n296,000 related user engagements, 926 social platform posts about COVID-19, and\nground truth labels. The dataset is available at:\nhttps://github.com/cuilimeng/CoAID.", "author": [{"name": "Limeng Cui"}, {"name": "Dongwon Lee"}], "link": [{"@href": "http://arxiv.org/abs/2006.00885v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.00885v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.12758v2", "updated": "2020-12-15T01:13:08Z", "published": "2020-11-25T14:22:36Z", "title": "Encounters with Visual Misinformation and Labels Across Platforms: An\n  Interview and Diary Study to Inform Ecosystem Approaches to Misinformation\n  Interventions", "summary": "Since 2016, the amount of academic research with the keyword \"misinformation\"\nhas more than doubled [2]. This research often focuses on article headlines\nshown in artificial testing environments, yet misinformation largely spreads\nthrough images and video posts shared in highly-personalized platform contexts.\nA foundation of qualitative research is necessary to begin filling this gap to\nensure platforms' visual misinformation interventions are aligned with users'\nneeds and understanding of information in their personal contexts, across\nplatforms. In two studies, we combined in-depth interviews (n=15) with diary\nand co-design methods (n=23) to investigate how a broad mix of Americans\nexposed to misinformation during COVID-19 understand their visual information\nenvironments, including encounters with interventions such as Facebook\nfact-checking labels. Analysis reveals a deep division in user attitudes about\nplatform labeling interventions for visual information which are perceived by\nmany as overly paternalistic, biased, and punitive. Alongside these findings,\nwe discuss our methods as a model for continued independent qualitative\nresearch on cross-platform user experiences of misinformation that inform\ninterventions.", "author": [{"name": "Emily Saltz"}, {"name": "Claire Leibowicz"}, {"name": "Claire Wardle"}], "link": [{"@href": "http://arxiv.org/abs/2011.12758v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.12758v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.05626v1", "updated": "2021-01-09T22:52:21Z", "published": "2021-01-09T22:52:21Z", "title": "Eating Garlic Prevents COVID-19 Infection: Detecting Misinformation on\n  the Arabic Content of Twitter", "summary": "The rapid growth of social media content during the current pandemic provides\nuseful tools for disseminating information which has also become a root for\nmisinformation. Therefore, there is an urgent need for fact-checking and\neffective techniques for detecting misinformation in social media. In this\nwork, we study the misinformation in the Arabic content of Twitter. We\nconstruct a large Arabic dataset related to COVID-19 misinformation and\ngold-annotate the tweets into two categories: misinformation or not. Then, we\napply eight different traditional and deep machine learning models, with\ndifferent features including word embeddings and word frequency. The word\nembedding models (\\textsc{FastText} and word2vec) exploit more than two million\nArabic tweets related to COVID-19. Experiments show that optimizing the area\nunder the curve (AUC) improves the models' performance and the Extreme Gradient\nBoosting (XGBoost) presents the highest accuracy in detecting COVID-19\nmisinformation online.", "author": [{"name": "Sarah Alqurashi"}, {"name": "Btool Hamoui"}, {"name": "Abdulaziz Alashaikh"}, {"name": "Ahmad Alhindi"}, {"name": "Eisa Alanazi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "18 pages, 4 figures"}, "link": [{"@href": "http://arxiv.org/abs/2101.05626v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.05626v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1807.09739v2", "updated": "2019-03-17T18:37:34Z", "published": "2018-07-25T17:36:25Z", "title": "Vulnerable to Misinformation? Verifi!", "summary": "We present Verifi2, a visual analytic system to support the investigation of\nmisinformation on social media. On the one hand, social media platforms empower\nindividuals and organizations by democratizing the sharing of information. On\nthe other hand, even well-informed and experienced social media users are\nvulnerable to misinformation. To address the issue, various models and studies\nhave emerged from multiple disciplines to detect and understand the effects of\nmisinformation. However, there is still a lack of intuitive and accessible\ntools that help social media users distinguish misinformation from verified\nnews. In this paper, we present Verifi2, a visual analytic system that uses\nstate-of-the-art computational methods to highlight salient features from text,\nsocial network, and images. By exploring news on a source level through\nmultiple coordinated views in Verifi2, users can interact with the complex\ndimensions that characterize misinformation and contrast how real and\nsuspicious news outlets differ on these dimensions. To evaluate Verifi2, we\nconduct interviews with experts in digital media, journalism, education,\npsychology, and computing who study misinformation. Our interviews show\npromising potential for Verifi2 to serve as an educational tool on\nmisinformation. Furthermore, our interview results highlight the complexity of\nthe problem of combating misinformation and call for more work from the\nvisualization community.", "author": [{"name": "Alireza Karduni"}, {"name": "Isaac Cho"}, {"name": "Ryan Wesslen"}, {"name": "Sashank Santhanam"}, {"name": "Svitlana Volkova"}, {"name": "Dustin Arendt"}, {"name": "Samira Shaikh"}, {"name": "Wenwen Dou"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 7 figures"}, "link": [{"@href": "http://arxiv.org/abs/1807.09739v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1807.09739v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.06811v1", "updated": "2021-06-12T16:26:04Z", "published": "2021-06-12T16:26:04Z", "title": "Case Study on Detecting COVID-19 Health-Related Misinformation in Social\n  Media", "summary": "COVID-19 pandemic has generated what public health officials called an\ninfodemic of misinformation. As social distancing and stay-at-home orders came\ninto effect, many turned to social media for socializing. This increase in\nsocial media usage has made it a prime vehicle for the spreading of\nmisinformation. This paper presents a mechanism to detect COVID-19\nhealth-related misinformation in social media following an interdisciplinary\napproach. Leveraging social psychology as a foundation and existing\nmisinformation frameworks, we defined misinformation themes and associated\nkeywords incorporated into the misinformation detection mechanism using applied\nmachine learning techniques. Next, using the Twitter dataset, we explored the\nperformance of the proposed methodology using multiple state-of-the-art machine\nlearning classifiers. Our method shows promising results with at most 78%\naccuracy in classifying health-related misinformation versus true information\nusing uni-gram-based NLP feature generations from tweets and the Decision Tree\nclassifier. We also provide suggestions on alternatives for countering\nmisinformation and ethical consideration for the study.", "author": [{"name": "Mir Mehedi A. Pritom"}, {"name": "Rosana Montanez Rodriguez"}, {"name": "Asad Ali Khan"}, {"name": "Sebastian A. Nugroho"}, {"name": "Esra'a Alrashydah"}, {"name": "Beatrice N. Ruiz"}, {"name": "Anthony Rios"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages"}, "link": [{"@href": "http://arxiv.org/abs/2106.06811v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.06811v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.14907v1", "updated": "2020-04-30T16:06:02Z", "published": "2020-04-30T16:06:02Z", "title": "You are right. I am ALARMED -- But by Climate Change Counter Movement", "summary": "The world is facing the challenge of climate crisis. Despite the consensus in\nscientific community about anthropogenic global warming, the web is flooded\nwith articles spreading climate misinformation. These articles are carefully\nconstructed by climate change counter movement (cccm) organizations to\ninfluence the narrative around climate change. We revisit the literature on\nclimate misinformation in social sciences and repackage it to introduce in the\ncommunity of NLP. Despite considerable work in detection of fake news, there is\nno misinformation dataset available that is specific to the domain.of climate\nchange. We try to bridge this gap by scraping and releasing articles with known\nclimate change misinformation.", "author": [{"name": "Shraey Bhatia"}, {"name": "Jey Han Lau"}, {"name": "Timothy Baldwin"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages"}, "link": [{"@href": "http://arxiv.org/abs/2004.14907v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.14907v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2006.08830v2", "updated": "2021-01-27T20:23:36Z", "published": "2020-06-15T23:48:50Z", "title": "Examining the Global Spread of COVID-19 Misinformation", "summary": "The global COVID-19 pandemic has led to the online proliferation of health-,\npolitical-, and conspiratorial-based misinformation. Understanding the reach\nand belief in this misinformation is vital to managing this crisis, as well as\nfuture crises. The results from our global survey finds a troubling reach of\nand belief in COVID-related misinformation, as well as a correlation with those\nthat primarily consume news from social media, and, in the United States, a\nstrong correlation with political leaning.", "author": [{"name": "Sophie Nightingale"}, {"name": "Hany Farid"}], "link": [{"@href": "http://arxiv.org/abs/2006.08830v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.08830v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.10113v1", "updated": "2020-10-20T08:11:47Z", "published": "2020-10-20T08:11:47Z", "title": "Is this pofma? Analysing public opinion and misinformation in a COVID-19\n  Telegram group chat", "summary": "We analyse a Singapore-based COVID-19 Telegram group with more than 10,000\nparticipants. First, we study the group's opinion over time, focusing on four\ndimensions: participation, sentiment, topics, and psychological features. We\nfind that engagement peaked when the Ministry of Health raised the disease\nalert level, but this engagement was not sustained. Second, we search for\ngovernment-identified misinformation in the group. We find that\ngovernment-identified misinformation is rare, and that messages discussing\nthese pieces of misinformation express skepticism.", "author": [{"name": "Lynnette Hui Xian Ng"}, {"name": "Loke Jia Yuan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.36190/2020.12"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.36190/2020.12", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2010.10113v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.10113v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Workshop Proceedings of the 14th International AAAI Conference on\n  Web and Social Media 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.01076v1", "updated": "2020-12-21T15:49:19Z", "published": "2020-12-21T15:49:19Z", "title": "Understanding Health Misinformation Transmission: An Interpretable Deep\n  Learning Approach to Manage Infodemics", "summary": "Health misinformation on social media devastates physical and mental health,\ninvalidates health gains, and potentially costs lives. Understanding how health\nmisinformation is transmitted is an urgent goal for researchers, social media\nplatforms, health sectors, and policymakers to mitigate those ramifications.\nDeep learning methods have been deployed to predict the spread of\nmisinformation. While achieving the state-of-the-art predictive performance,\ndeep learning methods lack the interpretability due to their blackbox nature.\nTo remedy this gap, this study proposes a novel interpretable deep learning\napproach, Generative Adversarial Network based Piecewise Wide and Attention\nDeep Learning (GAN-PiWAD), to predict health misinformation transmission in\nsocial media. Improving upon state-of-the-art interpretable methods, GAN-PiWAD\ncaptures the interactions among multi-modal data, offers unbiased estimation of\nthe total effect of each feature, and models the dynamic total effect of each\nfeature when its value varies. We select features according to social exchange\ntheory and evaluate GAN-PiWAD on 4,445 misinformation videos. The proposed\napproach outperformed strong benchmarks. Interpretation of GAN-PiWAD indicates\nvideo description, negative video content, and channel credibility are key\nfeatures that drive viral transmission of misinformation. This study\ncontributes to IS with a novel interpretable deep learning method that is\ngeneralizable to understand other human decision factors. Our findings provide\ndirect implications for social media platforms and policymakers to design\nproactive interventions to identify misinformation, control transmissions, and\nmanage infodemics.", "author": [{"name": "Jiaheng Xie"}, {"name": "Yidong Chai"}, {"name": "Xiao Liu"}], "link": [{"@href": "http://arxiv.org/abs/2101.01076v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.01076v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.10635v2", "updated": "2021-05-01T11:33:34Z", "published": "2021-04-21T16:59:54Z", "title": "The impact of online misinformation on U.S. COVID-19 vaccinations", "summary": "Widespread uptake of COVID-19 vaccines is necessary to achieve herd immunity.\nHowever, surveys have found concerning numbers of U.S. adults hesitant or\nunwilling to be vaccinated. Online misinformation may play an important role in\nvaccine hesitancy, but we lack a clear picture of the extent to which it will\nimpact vaccination uptake. Here, we study how vaccination rates and vaccine\nhesitancy are associated with levels of online misinformation about vaccines\nshared by 1.6 million Twitter users geolocated at the U.S. state and county\nlevels. We find a negative relationship between misinformation and vaccination\nuptake rates. Online misinformation is also correlated with vaccine hesitancy\nrates taken from survey data. Associations between vaccine outcomes and\nmisinformation remain significant when accounting for political as well as\ndemographic and socioeconomic factors. While vaccine hesitancy is strongly\nassociated with Republican vote share, we observe that the effect of online\nmisinformation on hesitancy is strongest across Democratic rather than\nRepublican counties. These results suggest that addressing online\nmisinformation must be a key component of interventions aimed to maximize the\neffectiveness of vaccination campaigns.", "author": [{"name": "Francesco Pierri"}, {"name": "Brea Perry"}, {"name": "Matthew R. DeVerna"}, {"name": "Kai-Cheng Yang"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}, {"name": "John Bryden"}], "link": [{"@href": "http://arxiv.org/abs/2104.10635v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.10635v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.09768v1", "updated": "2021-07-20T20:58:23Z", "published": "2021-07-20T20:58:23Z", "title": "Checkovid: A COVID-19 misinformation detection system on Twitter using\n  network and content mining perspectives", "summary": "During the COVID-19 pandemic, social media platforms were ideal for\ncommunicating due to social isolation and quarantine. Also, it was the primary\nsource of misinformation dissemination on a large scale, referred to as the\ninfodemic. Therefore, automatic debunking misinformation is a crucial problem.\nTo tackle this problem, we present two COVID-19 related misinformation datasets\non Twitter and propose a misinformation detection system comprising\nnetwork-based and content-based processes based on machine learning algorithms\nand NLP techniques. In the network-based process, we focus on social\nproperties, network characteristics, and users. On the other hand, we classify\nmisinformation using the content of the tweets directly in the content-based\nprocess, which contains text classification models (paragraph-level and\nsentence-level) and similarity models. The evaluation results on the\nnetwork-based process show the best results for the artificial neural network\nmodel with an F1 score of 88.68%. In the content-based process, our novel\nsimilarity models, which obtained an F1 score of 90.26%, show an improvement in\nthe misinformation classification results compared to the network-based models.\nIn addition, in the text classification models, the best result was achieved\nusing the stacking ensemble-learning model by obtaining an F1 score of 95.18%.\nFurthermore, we test our content-based models on the Constraint@AAAI2021\ndataset, and by getting an F1 score of 94.38%, we improve the baseline results.\nFinally, we develop a fact-checking website called Checkovid that uses each\nprocess to detect misinformative and informative claims in the domain of\nCOVID-19 from different perspectives.", "author": [{"name": "Sajad Dadgar"}, {"name": "Mehdi Ghatee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "20 Pages, 18 Figures, 7 Tables, Submitted for Review Process in a\n  Journal"}, "link": [{"@href": "http://arxiv.org/abs/2107.09768v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.09768v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T05, 68T07", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2; I.5", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.10414v1", "updated": "2020-05-21T01:34:08Z", "published": "2020-05-21T01:34:08Z", "title": "Analysis of misinformation during the COVID-19 outbreak in China:\n  cultural, social and political entanglements", "summary": "COVID-19 resulted in an infodemic, which could erode public trust, impede\nvirus containment, and outlive the pandemic itself. The evolving and fragmented\nmedia landscape is a key driver of the spread of misinformation. Using\nmisinformation identified by the fact-checking platform by Tencent and posts on\nWeibo, our results showed that the evolution of misinformation follows an\nissue-attention cycle, pertaining to topics such as city lockdown, cures, and\npreventions, and school reopening. Sources of authority weigh in on these\ntopics, but their influence is complicated by peoples' pre-existing beliefs and\ncultural practices. Finally, social media has a complicated relationship with\nestablished or legacy media systems. Sometimes they reinforce each other, but\nin general, social media may have a topic cycle of its own making. Our findings\nshed light on the distinct characteristics of misinformation during the\nCOVID-19 and offer insights into combating misinformation in China and across\nthe world at large.", "author": [{"name": "Yan Leng"}, {"name": "Yujia Zhai"}, {"name": "Shaojing Sun"}, {"name": "Yifei Wu"}, {"name": "Jordan Selzer"}, {"name": "Sharon Strover"}, {"name": "Julia Fensel"}, {"name": "Alex Pentland"}, {"name": "Ying Ding"}], "link": [{"@href": "http://arxiv.org/abs/2005.10414v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.10414v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.04666v2", "updated": "2020-06-10T08:49:30Z", "published": "2020-06-08T15:13:44Z", "title": "Misinformation Has High Perplexity", "summary": "Debunking misinformation is an important and time-critical task as there\ncould be adverse consequences when misinformation is not quashed promptly.\nHowever, the usual supervised approach to debunking via misinformation\nclassification requires human-annotated data and is not suited to the fast\ntime-frame of newly emerging events such as the COVID-19 outbreak. In this\npaper, we postulate that misinformation itself has higher perplexity compared\nto truthful statements, and propose to leverage the perplexity to debunk false\nclaims in an unsupervised manner. First, we extract reliable evidence from\nscientific and news sources according to sentence similarity to the claims.\nSecond, we prime a language model with the extracted evidence and finally\nevaluate the correctness of given claims based on the perplexity scores at\ndebunking time. We construct two new COVID-19-related test sets, one is\nscientific, and another is political in content, and empirically verify that\nour system performs favorably compared to existing systems. We are releasing\nthese datasets publicly to encourage more research in debunking misinformation\non COVID-19 and other topics.", "author": [{"name": "Nayeon Lee"}, {"name": "Yejin Bang"}, {"name": "Andrea Madotto"}, {"name": "Pascale Fung"}], "link": [{"@href": "http://arxiv.org/abs/2006.04666v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.04666v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.12593v2", "updated": "2020-12-28T07:19:01Z", "published": "2020-12-23T10:50:30Z", "title": "Attention and misinformation sharing on social media", "summary": "The behaviour of sharing information on social media should be fulfilled only\nwhen a user is exhibiting attentive behaviour. So that the useful information\ncan be consumed constructively, and misinformation can be identified and\nignored. Attentive behaviour is related to users' cognitive abilities in their\nprocessing of set information. The work described in this paper examines the\nissue of attentive factors that affect users' behaviour when they share\nmisinformation on social media. The research aims to identify the significance\nof prevailing attention factors towards sharing misinformation on social media.\nWe used a closed-ended questionnaire which consisted of a psychometric scale to\nmeasure attention behaviour with participants (n = 112). The regression\nequation results are obtained as: y=(19,533-0,390+e) from a set of regression\nanalyses shows that attention factors have a significant negative correlation\neffect for users to share misinformation on social media. Along with the\nfindings of the analysis results, we propose that attentive factors are\nincorporated into a social media application's future design that could\nintervene in user attention and avoid potential harm caused by the spread of\nmisinformation.", "author": [{"name": "Zaid Amin"}, {"name": "Nazlena Mohamad Ali"}, {"name": "Alan F. Smeaton"}], "link": [{"@href": "http://arxiv.org/abs/2012.12593v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.12593v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.08790v1", "updated": "2021-04-18T09:50:11Z", "published": "2021-04-18T09:50:11Z", "title": "Misinfo Belief Frames: A Case Study on Covid & Climate News", "summary": "Prior beliefs of readers impact the way in which they project meaning onto\nnews headlines. These beliefs can influence their perception of news\nreliability, as well as their reaction to news, and their likelihood of\nspreading the misinformation through social networks. However, most prior work\nfocuses on fact-checking veracity of news or stylometry rather than measuring\nimpact of misinformation. We propose Misinfo Belief Frames, a formalism for\nunderstanding how readers perceive the reliability of news and the impact of\nmisinformation. We also introduce the Misinfo Belief Frames (MBF) corpus, a\ndataset of 66k inferences over 23.5k headlines. Misinformation frames use\ncommonsense reasoning to uncover implications of real and fake news headlines\nfocused on global crises: the Covid-19 pandemic and climate change. Our results\nusing large-scale language modeling to predict misinformation frames show that\nmachine-generated inferences can influence readers' trust in news headlines\n(readers' trust in news headlines was affected in 29.3% of cases). This\ndemonstrates the potential effectiveness of using generated frames to counter\nmisinformation.", "author": [{"name": "Saadia Gabriel"}, {"name": "Skyler Hallinan"}, {"name": "Maarten Sap"}, {"name": "Pemi Nguyen"}, {"name": "Franziska Roesner"}, {"name": "Eunsol Choi"}, {"name": "Yejin Choi"}], "link": [{"@href": "http://arxiv.org/abs/2104.08790v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.08790v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2105.03313v1", "updated": "2021-05-03T14:30:49Z", "published": "2021-05-03T14:30:49Z", "title": "Looking for COVID-19 misinformation in multilingual social media texts", "summary": "This paper presents the Multilingual COVID-19 Analysis Method (CMTA) for\ndetecting and observing the spread of misinformation about this disease within\ntexts. CMTA proposes a data science (DS) pipeline that applies machine learning\nmodels for processing, classifying (Dense-CNN) and analyzing (MBERT)\nmultilingual (micro)-texts. DS pipeline data preparation tasks extract features\nfrom multilingual textual data and categorize it into specific information\nclasses (i.e., 'false', 'partly false', 'misleading'). The CMTA pipeline has\nbeen experimented with multilingual micro-texts (tweets), showing\nmisinformation spread across different languages. To assess the performance of\nCMTA and put it in perspective, we performed a comparative analysis of CMTA\nwith eight monolingual models used for detecting misinformation. The comparison\nshows that CMTA has surpassed various monolingual models and suggests that it\ncan be used as a general method for detecting misinformation in multilingual\nmicro-texts. CMTA experimental results show misinformation trends about\nCOVID-19 in different languages during the first pandemic months.", "author": [{"name": "Raj Ratn Pranesh"}, {"name": "Mehrdad Farokhnejad"}, {"name": "Ambesh Shekhar"}, {"name": "Genoveva Vargas-Solar"}], "link": [{"@href": "http://arxiv.org/abs/2105.03313v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.03313v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DB", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.02607v1", "updated": "2021-06-03T16:34:54Z", "published": "2021-06-03T16:34:54Z", "title": "Defending Democracy: Using Deep Learning to Identify and Prevent\n  Misinformation", "summary": "The rise in online misinformation in recent years threatens democracies by\ndistorting authentic public discourse and causing confusion, fear, and even, in\nextreme cases, violence. There is a need to understand the spread of false\ncontent through online networks for developing interventions that disrupt\nmisinformation before it achieves virality. Using a Deep Bidirectional\nTransformer for Language Understanding (BERT) and propagation graphs, this\nstudy classifies and visualizes the spread of misinformation on a social media\nnetwork using publicly available Twitter data. The results confirm prior\nresearch around user clusters and the virality of false content while improving\nthe precision of deep learning models for misinformation detection. The study\nfurther demonstrates the suitability of BERT for providing a scalable model for\nfalse information detection, which can contribute to the development of more\ntimely and accurate interventions to slow the spread of misinformation in\nonline environments.", "author": [{"name": "Anusua Trivedi"}, {"name": "Alyssa Suhm"}, {"name": "Prathamesh Mahankal"}, {"name": "Subhiksha Mukuntharaj"}, {"name": "Meghana D. Parab"}, {"name": "Malvika Mohan"}, {"name": "Meredith Berger"}, {"name": "Arathi Sethumadhavan"}, {"name": "Ashish Jaiman"}, {"name": "Rahul Dodhia"}], "link": [{"@href": "http://arxiv.org/abs/2106.02607v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.02607v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.03805v1", "updated": "2021-08-09T04:46:41Z", "published": "2021-08-09T04:46:41Z", "title": "Learning to Detect Few-Shot-Few-Clue Misinformation", "summary": "The quality of digital information on the web has been disquieting due to the\nlack of careful manual review. Consequently, a large volume of false textual\ninformation has been disseminating for a long time since the prevalence of\nsocial media. The potential negative influence of misinformation on the public\nis a growing concern. Therefore, it is strongly motivated to detect online\nmisinformation as early as possible. Few-shot-few-clue learning applies in this\nmisinformation detection task when the number of annotated statements is quite\nfew (called few shots) and the corresponding evidence is also quite limited in\neach shot (called few clues). Within the few-shot-few-clue framework, we\npropose a Bayesian meta-learning algorithm to extract the shared patterns among\ndifferent topics (i.e.different tasks) of misinformation. Moreover, we derive a\nscalable method, i.e., amortized variational inference, to optimize the\nBayesian meta-learning algorithm. Empirical results on three benchmark datasets\ndemonstrate the superiority of our algorithm. This work focuses more on\noptimizing parameters than designing detection models, and will generate fresh\ninsights into data-efficient detection of online misinformation at early\nstages.", "author": [{"name": "Qiang Zhang"}, {"name": "Hongbin Huang"}, {"name": "Shangsong Liang"}, {"name": "Zaiqiao Meng"}, {"name": "Emine Yilmaz"}], "link": [{"@href": "http://arxiv.org/abs/2108.03805v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.03805v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1706.06314v1", "updated": "2017-06-20T08:36:56Z", "published": "2017-06-20T08:36:56Z", "title": "Mining Significant Microblogs for Misinformation Identification: An\n  Attention-based Approach", "summary": "With the rapid growth of social media, massive misinformation is also\nspreading widely on social media, such as microblog, and bring negative effects\nto human life. Nowadays, automatic misinformation identification has drawn\nattention from academic and industrial communities. For an event on social\nmedia usually consists of multiple microblogs, current methods are mainly based\non global statistical features. However, information on social media is full of\nnoisy and outliers, which should be alleviated. Moreover, most of microblogs\nabout an event have little contribution to the identification of\nmisinformation, where useful information can be easily overwhelmed by useless\ninformation. Thus, it is important to mine significant microblogs for a\nreliable misinformation identification method. In this paper, we propose an\nAttention-based approach for Identification of Misinformation (AIM). Based on\nthe attention mechanism, AIM can select microblogs with largest attention\nvalues for misinformation identification. The attention mechanism in AIM\ncontains two parts: content attention and dynamic attention. Content attention\nis calculated based textual features of each microblog. Dynamic attention is\nrelated to the time interval between the posting time of a microblog and the\nbeginning of the event. To evaluate AIM, we conduct a series of experiments on\nthe Weibo dataset and the Twitter dataset, and the experimental results show\nthat the proposed AIM model outperforms the state-of-the-art methods.", "author": [{"name": "Qiang Liu"}, {"name": "Feng Yu"}, {"name": "Shu Wu"}, {"name": "Liang Wang"}], "link": [{"@href": "http://arxiv.org/abs/1706.06314v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1706.06314v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.07729v2", "updated": "2021-04-15T13:56:54Z", "published": "2020-12-14T17:24:59Z", "title": "\"Thought I'd Share First\" and Other Conspiracy Theory Tweets from the\n  COVID-19 Infodemic: Exploratory Study", "summary": "Background: The COVID-19 outbreak has left many people isolated within their\nhomes; these people are turning to social media for news and social connection,\nwhich leaves them vulnerable to believing and sharing misinformation.\nHealth-related misinformation threatens adherence to public health messaging,\nand monitoring its spread on social media is critical to understanding the\nevolution of ideas that have potentially negative public health impacts.\nResults: Analysis using model-labeled data was beneficial for increasing the\nproportion of data matching misinformation indicators. Random forest classifier\nmetrics varied across the four conspiracy theories considered (F1 scores\nbetween 0.347 and 0.857); this performance increased as the given conspiracy\ntheory was more narrowly defined. We showed that misinformation tweets\ndemonstrate more negative sentiment when compared to nonmisinformation tweets\nand that theories evolve over time, incorporating details from unrelated\nconspiracy theories as well as real-world events. Conclusions: Although we\nfocus here on health-related misinformation, this combination of approaches is\nnot specific to public health and is valuable for characterizing misinformation\nin general, which is an important first step in creating targeted messaging to\ncounteract its spread. Initial messaging should aim to preempt generalized\nmisinformation before it becomes widespread, while later messaging will need to\ntarget evolving conspiracy theories and the new facets of each as they become\nincorporated.", "author": [{"name": "Dax Gerts"}, {"name": "Courtney D. Shelley"}, {"name": "Nidhi Parikh"}, {"name": "Travis Pitts"}, {"name": "Chrysm Watson Ross"}, {"name": "Geoffrey Fairchild"}, {"name": "Nidia Yadria Vaquera Chavez"}, {"name": "Ashlynn R. Daughton"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.2196/26527"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.2196/26527", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2012.07729v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.07729v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "JMIR Pub Hlth Surv 2021 7(4)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.09338v2", "updated": "2021-08-08T17:03:44Z", "published": "2021-06-17T09:19:45Z", "title": "Investigating Misinformation Dissemination on Social Media in Pakistan", "summary": "Fake news and misinformation are one of the most significant challenges\nbrought about by advances in communication technologies. We chose to research\nthe spread of fake news in Pakistan because of some unfortunate incidents that\ntook place during 2020. These included the downplaying of the severity of the\nCOVID-19 pandemic, and protests by right-wing political movements. We observed\nthat fake news and misinformation contributed significantly to these events and\nespecially affected low-literate and low-income populations. We conducted a\ncross-platform comparison of misinformation on WhatsApp, Twitter and YouTube\nwith a primary focus on messages shared in public WhatsApp groups, and analysed\nthe characteristics of misinformation, techniques used to make is believable,\nand how users respond to it. To the best of our knowledge, this is the first\nattempt to compare misinformation on all three platforms in Pakistan. Data\ncollected over a span of eight months helped us identify fake news and\nmisinformation related to politics, religion and health, among other\ncategories. Common elements which were used by fake news creators in Pakistan\nto make false content seem believable included: appeals to emotion, conspiracy\ntheories, political and religious polarization, incorrect facts and\nimpersonation of credible sources.", "author": [{"name": "Danyal Haroon"}, {"name": "Hammad Arif"}, {"name": "Ahmed Abdullah Tariq"}, {"name": "fareeda nawaz"}, {"name": "Dr. Ihsan Ayyub Qazi"}, {"name": "Dr. Maryam mustafa"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "i want to further work on it"}, "link": [{"@href": "http://arxiv.org/abs/2106.09338v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.09338v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.05773v2", "updated": "2020-11-12T04:20:37Z", "published": "2020-11-11T13:48:44Z", "title": "The Role of the Crowd in Countering Misinformation: A Case Study of the\n  COVID-19 Infodemic", "summary": "Fact checking by professionals is viewed as a vital defense in the fight\nagainst misinformation.While fact checking is important and its impact has been\nsignificant, fact checks could have limited visibility and may not reach the\nintended audience, such as those deeply embedded in polarized communities.\nConcerned citizens (i.e., the crowd), who are users of the platforms where\nmisinformation appears, can play a crucial role in disseminating fact-checking\ninformation and in countering the spread of misinformation. To explore if this\nis the case, we conduct a data-driven study of misinformation on the Twitter\nplatform, focusing on tweets related to the COVID-19 pandemic, analyzing the\nspread of misinformation, professional fact checks, and the crowd response to\npopular misleading claims about COVID-19. In this work, we curate a dataset of\nfalse claims and statements that seek to challenge or refute them. We train a\nclassifier to create a novel dataset of 155,468 COVID-19-related tweets,\ncontaining 33,237 false claims and 33,413 refuting arguments.Our findings show\nthat professional fact-checking tweets have limited volume and reach. In\ncontrast, we observe that the surge in misinformation tweets results in a quick\nresponse and a corresponding increase in tweets that refute such\nmisinformation. More importantly, we find contrasting differences in the way\nthe crowd refutes tweets, some tweets appear to be opinions, while others\ncontain concrete evidence, such as a link to a reputed source. Our work\nprovides insights into how misinformation is organically countered in social\nplatforms by some of their users and the role they play in amplifying\nprofessional fact checks.These insights could lead to development of tools and\nmechanisms that can empower concerned citizens in combating misinformation. The\ncode and data can be found in\nhttp://claws.cc.gatech.edu/covid_counter_misinformation.html.", "author": [{"name": "Nicholas Micallef"}, {"name": "Bing He"}, {"name": "Srijan Kumar"}, {"name": "Mustaque Ahamad"}, {"name": "Nasir Memon"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PrePrint - IEEE BigData 2020. The code and data can be found in\n  http://claws.cc.gatech.edu/covid_counter_misinformation.html"}, "link": [{"@href": "http://arxiv.org/abs/2011.05773v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.05773v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1901.01464v1", "updated": "2019-01-05T20:23:02Z", "published": "2019-01-05T20:23:02Z", "title": "The Value of Misinformation and Disinformation", "summary": "Information is a critical dimension in warfare. Inaccurate information such\nas misinformation or disinformation further complicates military operations. In\nthis paper, we examine the value of misinformation and disinformation to a\nmilitary leader who through investment in people, programs and technology is\nable to affect the accuracy of information communicated between other actors.\nWe model the problem as a partially observable stochastic game with three\nagents, a leader and two followers. We determine the value to the leader of\nmisinformation or disinformation being communicated between two (i) adversarial\nfollowers and (ii) allied followers. We demonstrate that only under certain\nconditions, the prevalent intuition that the leader would benefit from less\n(more) accurate communication between adversarial (allied) followers is valid.\nWe analyzed why the intuition may fail and show a holistic paradigm taking into\naccount both the reward structures and policies of agents is necessary in order\nto correctly determine the value of misinformation and disinformation. Our\nresearch identifies efficient targeted investments to affect the accuracy of\ninformation communicated between followers to the leader's advantage.", "author": [{"name": "Yanling Chang"}, {"name": "Matthew F. Keblis"}, {"name": "Ran Li"}, {"name": "Eleftherios Iakovou"}, {"name": "Chelsea C. White III"}], "link": [{"@href": "http://arxiv.org/abs/1901.01464v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.01464v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "math.OC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "math.OC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1909.01543v1", "updated": "2019-09-04T03:41:44Z", "published": "2019-09-04T03:41:44Z", "title": "Towards Automatic Detection of Misinformation in Online Medical Videos", "summary": "Recent years have witnessed a significant increase in the online sharing of\nmedical information, with videos representing a large fraction of such online\nsources. Previous studies have however shown that more than half of the\nhealth-related videos on platforms such as YouTube contain misleading\ninformation and biases. Hence, it is crucial to build computational tools that\ncan help evaluate the quality of these videos so that users can obtain accurate\ninformation to help inform their decisions. In this study, we focus on the\nautomatic detection of misinformation in YouTube videos. We select prostate\ncancer videos as our entry point to tackle this problem. The contribution of\nthis paper is twofold. First, we introduce a new dataset consisting of 250\nvideos related to prostate cancer manually annotated for misinformation.\nSecond, we explore the use of linguistic, acoustic, and user engagement\nfeatures for the development of classification models to identify\nmisinformation. Using a series of ablation experiments, we show that we can\nbuild automatic models with accuracies of up to 74%, corresponding to a 76.5%\nprecision and 73.2% recall for misinformative instances.", "author": [{"name": "Rui Hou"}, {"name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"name": "Stacy Loeb"}, {"name": "Rada Mihalcea"}], "link": [{"@href": "http://arxiv.org/abs/1909.01543v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.01543v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.13657v3", "updated": "2020-04-02T16:32:15Z", "published": "2020-03-30T17:44:42Z", "title": "Analysing the Extent of Misinformation in Cancer Related Tweets", "summary": "Twitter has become one of the most sought after places to discuss a wide\nvariety of topics, including medically relevant issues such as cancer. This\nhelps spread awareness regarding the various causes, cures and prevention\nmethods of cancer. However, no proper analysis has been performed, which\ndiscusses the validity of such claims. In this work, we aim to tackle the\nmisinformation spread in such platforms. We collect and present a dataset\nregarding tweets which talk specifically about cancer and propose an\nattention-based deep learning model for automated detection of misinformation\nalong with its spread. We then do a comparative analysis of the linguistic\nvariation in the text corresponding to misinformation and truth. This analysis\nhelps us gather relevant insights on various social aspects related to\nmisinformed tweets.", "author": [{"name": "Rakesh Bal"}, {"name": "Sayan Sinha"}, {"name": "Swastika Dutta"}, {"name": "Rishabh Joshi"}, {"name": "Sayan Ghosh"}, {"name": "Ritam Dutt"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the 14th International Conference on Web and Social\n  Media (ICWSM-20)"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ICWSM 2020, 14, 924-928"}, "link": [{"@href": "http://arxiv.org/abs/2003.13657v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.13657v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.04682v2", "updated": "2020-05-28T07:31:05Z", "published": "2020-05-10T14:55:50Z", "title": "Exposure to Social Engagement Metrics Increases Vulnerability to\n  Misinformation", "summary": "News feeds in virtually all social media platforms include engagement\nmetrics, such as the number of times each post is liked and shared. We find\nthat exposure to these social engagement signals increases the vulnerability of\nusers to misinformation. This finding has important implications for the design\nof social media interactions in the misinformation age. To reduce the spread of\nmisinformation, we call for technology platforms to rethink the display of\nsocial engagement metrics. Further research is needed to investigate whether\nand how engagement metrics can be presented without amplifying the spread of\nlow-credibility information.", "author": [{"name": "Mihai Avram"}, {"name": "Nicholas Micallef"}, {"name": "Sameer Patil"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.37016/mr-2020-033"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.37016/mr-2020-033", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2005.04682v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.04682v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 2 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "HKS Misinformation Review Vol. 1 (No. 5), 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2008.00784v1", "updated": "2020-08-03T11:25:47Z", "published": "2020-08-03T11:25:47Z", "title": "COVID-19 Misinformation and Disinformation on Social Networks -- The\n  Limits of Veritistic Countermeasures", "summary": "The COVID-19 pandemic has been the subject of a vast amount of\nmisinformation, particularly in digital information environments, and major\nsocial media platforms recently publicized some of the countermeasures they are\nadopting. This presents an opportunity to examine the nature of the\nmisinformation and disinformation being produced, and the theoretical and\ntechnological paradigm used to counter it. I argue that this approach is based\non a conception of misinformation as epistemic pollution that can only justify\na limited and potentially inadequate response , and that some of the measures\nundertaken in practice outrun this. In fact, social networks manage ecological\nand architectural conditions that influence discourse on their platforms in\nways that should motivate reconsideration of the justifications that ground\nepistemic interventions to combat misinformation, and the types of intervention\nthat they warrant. The editorial role of platforms should not be framed solely\nas the management of epistemic pollution, but instead as managing the epistemic\nenvironment in which narratives and social epistemic processes take place.\nThere is an element of inevitable epistemic paternalism involved in this, and\nexploration of the independent constraints on its justifiability can help\ndetermine proper limits of its exercise in practice.", "author": {"name": "Andrew Buzzell"}, "link": [{"@href": "http://arxiv.org/abs/2008.00784v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.00784v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.01462v2", "updated": "2021-01-21T13:55:23Z", "published": "2020-10-04T01:36:14Z", "title": "Right and left, partisanship predicts (asymmetric) vulnerability to\n  misinformation", "summary": "We analyze the relationship between partisanship, echo chambers, and\nvulnerability to online misinformation by studying news sharing behavior on\nTwitter. While our results confirm prior findings that online misinformation\nsharing is strongly correlated with right-leaning partisanship, we also uncover\na similar, though weaker trend among left-leaning users. Because of the\ncorrelation between a user's partisanship and their position within a partisan\necho chamber, these types of influence are confounded. To disentangle their\neffects, we perform a regression analysis and find that vulnerability to\nmisinformation is most strongly influenced by partisanship for both left- and\nright-leaning users.", "author": [{"name": "Dimitar Nikolov"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.37016/mr-2020-55"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.37016/mr-2020-55", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2010.01462v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.01462v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Harvard Kennedy School Misinformation Review, Volume 1, Issue 7,\n  2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.11055v1", "updated": "2020-12-21T00:02:04Z", "published": "2020-12-21T00:02:04Z", "title": "Social Media COVID-19 Misinformation Interventions Viewed Positively,\n  But Have Limited Impact", "summary": "Amidst COVID-19 misinformation spreading, social media platforms like\nFacebook and Twitter rolled out design interventions, including banners linking\nto authoritative resources and more specific \"false information\" labels. In\nlate March 2020, shortly after these interventions began to appear, we\nconducted an exploratory mixed-methods survey (N = 311) to learn: what are\nsocial media users' attitudes towards these interventions, and to what extent\ndo they self-report effectiveness? We found that most participants indicated a\npositive attitude towards interventions, particularly post-specific labels for\nmisinformation. Still, the majority of participants discovered or corrected\nmisinformation through other means, most commonly web searches, suggesting room\nfor platforms to do more to stem the spread of COVID-19 misinformation.", "author": [{"name": "Christine Geeng"}, {"name": "Tiona Francisco"}, {"name": "Jevin West"}, {"name": "Franziska Roesner"}], "link": [{"@href": "http://arxiv.org/abs/2012.11055v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.11055v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.02462v1", "updated": "2021-03-03T15:13:25Z", "published": "2021-03-03T15:13:25Z", "title": "University of Copenhagen Participation in TREC Health Misinformation\n  Track 2020", "summary": "In this paper, we describe our participation in the TREC Health\nMisinformation Track 2020. We submitted $11$ runs to the Total Recall Task and\n13 runs to the Ad Hoc task. Our approach consists of 3 steps: (1) we create an\ninitial run with BM25 and RM3; (2) we estimate credibility and misinformation\nscores for the documents in the initial run; (3) we merge the relevance,\ncredibility and misinformation scores to re-rank documents in the initial run.\nTo estimate credibility scores, we implement a classifier which exploits\nfeatures based on the content and the popularity of a document. To compute the\nmisinformation score, we apply a stance detection approach with a pretrained\nTransformer language model. Finally, we use different approaches to merge\nscores: weighted average, the distance among score vectors and rank fusion.", "author": [{"name": "Lucas Chaves Lima"}, {"name": "Dustin Brandon Wright"}, {"name": "Isabelle Augenstein"}, {"name": "Maria Maistro"}], "link": [{"@href": "http://arxiv.org/abs/2103.02462v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.02462v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.00779v1", "updated": "2021-04-01T21:50:19Z", "published": "2021-04-01T21:50:19Z", "title": "Misinformation Warning Labels: Twitter's Soft Moderation Effects on\n  COVID-19 Vaccine Belief Echoes", "summary": "Twitter, prompted by the rapid spread of alternative narratives, started\nactively warning users about the spread of COVID-19 misinformation. This form\nof soft moderation comes in two forms: as a warning cover before the Tweet is\ndisplayed to the user and as a warning tag below the Tweet. This study\ninvestigates how each of the soft moderation forms affects the perceived\naccuracy of COVID-19 vaccine misinformation on Twitter. The results suggest\nthat the warning covers work, but not the tags, in reducing the perception of\naccuracy of COVID-19 vaccine misinformation on Twitter. \"Belief echoes\" do\nexist among Twitter users, unfettered by any warning labels, in relationship to\nthe perceived safety and efficacy of the COVID-19 vaccine as well as the\nvaccination hesitancy for themselves and their children. The implications of\nthese results are discussed in the context of usable security affordances for\ncombating misinformation on social media.", "author": [{"name": "Filipo Sharevski"}, {"name": "Raniem Alsaadi"}, {"name": "Peter Jachim"}, {"name": "Emma Pieroni"}], "link": [{"@href": "http://arxiv.org/abs/2104.00779v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.00779v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.15715v2", "updated": "2021-08-12T23:43:28Z", "published": "2021-06-29T20:39:17Z", "title": "No Calm in The Storm: Investigating QAnon Website Relationships", "summary": "QAnon is a far-right conspiracy theory whose followers largely organize\nonline. In this work, we use web crawls seeded from two of the largest QAnon\nhotbeds on the Internet, Voat and 8kun, to build a hyperlink graph. We then use\nthis graph to identify, understand, and learn from the websites that spread\nQAnon content online. We curate the largest list of QAnon centered websites to\ndate, from which we document the types of QAnon sites, their hosting providers,\nas well as their popularity. We further analyze QAnon websites' connection to\nmainstream news and misinformation online, highlighting the outsized role\nmisinformation websites play in spreading the conspiracy. Finally, we leverage\nthe observed relationship between QAnon and misinformation sites to build a\nrandom forest classifier that distinguishes between misinformation and\nauthentic news sites, getting a performance of 0.98 AUC on a test set. Our\nresults demonstrate new and effective ways to study conspiracy and\nmisinformation on the Internet.", "author": [{"name": "Hans W. A. Hanley"}, {"name": "Deepak Kumar"}, {"name": "Zakir Durumeric"}], "link": [{"@href": "http://arxiv.org/abs/2106.15715v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.15715v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1303.7400v1", "updated": "2013-03-28T13:04:30Z", "published": "2013-03-28T13:04:30Z", "title": "Policy and Planning for Large Infrastructure Projects: Problems, Causes,\n  Cures", "summary": "This paper argues, first, that a major problem in the planning of large\ninfrastructure projects is the high level of misinformation about costs and\nbenefits that decision makers face in deciding whether to build, and the high\nrisks such misinformation generates. Second, it explores the causes of\nmisinformation and risk, mainly in the guise of optimism bias and strategic\nmisrepresentation. Finally, the paper presents a number of measures aimed at\nimproving planning and decision making for large infrastructure projects,\nincluding changed incentive structures and better planning methods. Thus the\npaper is organized as a simple triptych consisting in problems, causes, and\ncures.", "author": {"name": "Bent Flyvbjerg"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: substantial text overlap with arXiv:1303.6571,\n  arXiv:1303.6654, arXiv:1303.6571, arXiv:1302.3642"}, "link": [{"@href": "http://arxiv.org/abs/1303.7400v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1303.7400v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "q-fin.GN", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "q-fin.GN", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.09784v1", "updated": "2020-05-19T23:00:17Z", "published": "2020-05-19T23:00:17Z", "title": "Images and Misinformation in Political Groups: Evidence from WhatsApp in\n  India", "summary": "WhatsApp is a key medium for the spread of news and rumors, often shared as\nimages. We study a large collection of politically-oriented WhatsApp groups in\nIndia, focusing on the period leading up to the 2019 Indian national elections.\nBy labeling samples of random and popular images, we find that around 13% of\nshared images are known misinformation and most fall into three types of\nimages. Machine learning methods can be used to predict whether a viral image\nis misinformation, but are brittle to shifts in content over time.", "author": [{"name": "Kiran Garimella"}, {"name": "Dean Eckles"}], "link": [{"@href": "http://arxiv.org/abs/2005.09784v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.09784v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.07951v1", "updated": "2021-01-20T03:49:51Z", "published": "2021-01-20T03:49:51Z", "title": "This photograph has been altered: Testing the effectiveness of image\n  forensic labeling on news image credibility", "summary": "Despite the ubiquity and proliferation of images and videos in online news\nenvironments, much of the existing research on misinformation and its\ncorrection is solely focused on textual misinformation, and little is known\nabout how ordinary users evaluate fake or manipulated images and the most\neffective ways to label and correct such falsities. We designed a visual\nforensic label of image authenticity, Picture-O-Meter, and tested the label's\nefficacy in relation to its source and placement in an experiment with 2440\nparticipants. Our findings demonstrate that, despite human beings' general\ninability to detect manipulated images on their own, image forensic labels are\nan effective tool for counteracting visual misinformation.", "author": [{"name": "Cuihua Shen"}, {"name": "Mona Kasra"}, {"name": "James O'Brien"}], "link": [{"@href": "http://arxiv.org/abs/2101.07951v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.07951v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.08034v1", "updated": "2021-07-16T17:56:27Z", "published": "2021-07-16T17:56:27Z", "title": "Pilot Study Suggests Online Media Literacy Programming Reduces Belief in\n  False News in Indonesia", "summary": "Amidst the threat of digital misinformation, we offer a pilot study regarding\nthe efficacy of an online social media literacy campaign aimed at empowering\nindividuals in Indonesia with skills to help them identify misinformation. We\nfound that users who engaged with our online training materials and educational\nvideos were more likely to identify misinformation than those in our control\ngroup (total $N$=1000). Given the promising results of our preliminary study,\nwe plan to expand efforts in this area, and build upon lessons learned from\nthis pilot study.", "author": [{"name": "Pamela Bilo Thomas"}, {"name": "Clark Hogan-Taylor"}, {"name": "Michael Yankoski"}, {"name": "Tim Weninger"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages"}, "link": [{"@href": "http://arxiv.org/abs/2107.08034v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.08034v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.09918v1", "updated": "2017-11-27T19:00:08Z", "published": "2017-11-27T19:00:08Z", "title": "Leveraging the Crowd to Detect and Reduce the Spread of Fake News and\n  Misinformation", "summary": "Online social networking sites are experimenting with the following\ncrowd-powered procedure to reduce the spread of fake news and misinformation:\nwhenever a user is exposed to a story through her feed, she can flag the story\nas misinformation and, if the story receives enough flags, it is sent to a\ntrusted third party for fact checking. If this party identifies the story as\nmisinformation, it is marked as disputed. However, given the uncertain number\nof exposures, the high cost of fact checking, and the trade-off between flags\nand exposures, the above mentioned procedure requires careful reasoning and\nsmart algorithms which, to the best of our knowledge, do not exist to date.\n  In this paper, we first introduce a flexible representation of the above\nprocedure using the framework of marked temporal point processes. Then, we\ndevelop a scalable online algorithm, Curb, to select which stories to send for\nfact checking and when to do so to efficiently reduce the spread of\nmisinformation with provable guarantees. In doing so, we need to solve a novel\nstochastic optimal control problem for stochastic differential equations with\njumps, which is of independent interest. Experiments on two real-world datasets\ngathered from Twitter and Weibo show that our algorithm may be able to\neffectively reduce the spread of fake news and misinformation.", "author": [{"name": "Jooyeon Kim"}, {"name": "Behzad Tabibian"}, {"name": "Alice Oh"}, {"name": "Bernhard Schoelkopf"}, {"name": "Manuel Gomez-Rodriguez"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear at the 11th ACM International Conference on Web Search and\n  Data Mining (WSDM 2018)"}, "link": [{"@href": "http://arxiv.org/abs/1711.09918v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.09918v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1801.06122v1", "updated": "2018-01-18T16:54:01Z", "published": "2018-01-18T16:54:01Z", "title": "Anatomy of an online misinformation network", "summary": "Massive amounts of fake news and conspiratorial content have spread over\nsocial media before and after the 2016 US Presidential Elections despite\nintense fact-checking efforts. How do the spread of misinformation and\nfact-checking compete? What are the structural and dynamic characteristics of\nthe core of the misinformation diffusion network, and who are its main\npurveyors? How to reduce the overall amount of misinformation? To explore these\nquestions we built Hoaxy, an open platform that enables large-scale, systematic\nstudies of how misinformation and fact-checking spread and compete on Twitter.\nHoaxy filters public tweets that include links to unverified claims or\nfact-checking articles. We perform k-core decomposition on a diffusion network\nobtained from two million retweets produced by several hundred thousand\naccounts over the six months before the election. As we move from the periphery\nto the core of the network, fact-checking nearly disappears, while social bots\nproliferate. The number of users in the main core reaches equilibrium around\nthe time of the election, with limited churn and increasingly dense\nconnections. We conclude by quantifying how effectively the network can be\ndisrupted by penalizing the most central nodes. These findings provide a first\nlook at the anatomy of a massive online misinformation diffusion network.", "author": [{"name": "Chengcheng Shao"}, {"name": "Pik-Mai Hui"}, {"name": "Lei Wang"}, {"name": "Xinwen Jiang"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}, {"name": "Giovanni Luca Ciampaglia"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0196087"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0196087", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1801.06122v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1801.06122v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "28 pages, 11 figures, submitted to PLOS ONE"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PLoS ONE, 13(4): e0196087. 2018"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1701.04221v1", "updated": "2017-01-16T09:59:45Z", "published": "2017-01-16T09:59:45Z", "title": "It's Always April Fools' Day! On the Difficulty of Social Network\n  Misinformation Classification via Propagation Features", "summary": "Given the huge impact that Online Social Networks (OSN) had in the way people\nget informed and form their opinion, they became an attractive playground for\nmalicious entities that want to spread misinformation, and leverage their\neffect. In fact, misinformation easily spreads on OSN and is a huge threat for\nmodern society, possibly influencing also the outcome of elections, or even\nputting people's life at risk (e.g., spreading \"anti-vaccines\" misinformation).\nTherefore, it is of paramount importance for our society to have some sort of\n\"validation\" on information spreading through OSN. The need for a wide-scale\nvalidation would greatly benefit from automatic tools.\n  In this paper, we show that it is difficult to carry out an automatic\nclassification of misinformation considering only structural properties of\ncontent propagation cascades. We focus on structural properties, because they\nwould be inherently difficult to be manipulated, with the the aim of\ncircumventing classification systems. To support our claim, we carry out an\nextensive evaluation on Facebook posts belonging to conspiracy theories (as\nrepresentative of misinformation), and scientific news (representative of\nfact-checked content). Our findings show that conspiracy content actually\nreverberates in a way which is hard to distinguish from the one scientific\ncontent does: for the classification mechanisms we investigated, classification\nF1-score never exceeds 0.65 during content propagation stages, and is still\nless than 0.7 even after propagation is complete.", "author": [{"name": "Mauro Conti"}, {"name": "Daniele Lain"}, {"name": "Riccardo Lazzeretti"}, {"name": "Giulio Lovisotto"}, {"name": "Walter Quattrociocchi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/1701.04221v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1701.04221v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1901.05149v2", "updated": "2019-12-20T20:56:38Z", "published": "2019-01-16T06:24:37Z", "title": "Beyond Uniform Reverse Sampling: A Hybrid Sampling Technique for\n  Misinformation Prevention", "summary": "Online misinformation has been considered as one of the top global risks as\nit may cause serious consequences such as economic damages and public panic.\nThe misinformation prevention problem aims at generating a positive cascade\nwith appropriate seed nodes in order to compete against the misinformation. In\nthis paper, we study the misinformation prevention problem under the prominent\nindependent cascade model. Due to the #P-hardness in computing influence, the\ncore problem is to design effective sampling methods to estimate the function\nvalue. The main contribution of this paper is a novel sampling method.\nDifferent from the classic reverse sampling technique which treats all nodes\nequally and samples the node uniformly, the proposed method proceeds with a\nhybrid sampling process which is able to attach high weights to the users who\nare prone to be affected by the misinformation. Consequently, the new sampling\nmethod is more powerful in generating effective samples used for computing seed\nnodes for the positive cascade. Based on the new hybrid sample technique, we\ndesign an algorithm offering a $(1-1/e-\\epsilon)$-approximation. We\nexperimentally evaluate the proposed method on extensive datasets and show that\nit significantly outperforms the state-of-the-art solutions.", "author": [{"name": "Gunagmo Tong"}, {"name": "Ding-Zhu Du"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "New parameter estimation methods have been proposed to fix an error\n  in the previous version"}, "link": [{"@href": "http://arxiv.org/abs/1901.05149v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.05149v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DS", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.12309v4", "updated": "2020-10-22T03:03:29Z", "published": "2020-03-26T09:48:24Z", "title": "COVID-19 on Social Media: Analyzing Misinformation in Twitter\n  Conversations", "summary": "The ongoing Coronavirus (COVID-19) pandemic highlights the\ninter-connectedness of our present-day globalized world. With social distancing\npolicies in place, virtual communication has become an important source of\n(mis)information. As increasing number of people rely on social media platforms\nfor news, identifying misinformation and uncovering the nature of online\ndiscourse around COVID-19 has emerged as a critical task. To this end, we\ncollected streaming data related to COVID-19 using the Twitter API, starting\nMarch 1, 2020. We identified unreliable and misleading contents based on\nfact-checking sources, and examined the narratives promoted in misinformation\ntweets, along with the distribution of engagements with these tweets. In\naddition, we provide examples of the spreading patterns of prominent\nmisinformation tweets. The analysis is presented and updated on a publically\naccessible dashboard (https://usc-melady.github.io/COVID-19-Tweet-Analysis) to\ntrack the nature of online discourse and misinformation about COVID-19 on\nTwitter from March 1 - June 5, 2020. The dashboard provides a daily list of\nidentified misinformation tweets, along with topics, sentiments, and emerging\ntrends in the COVID-19 Twitter discourse. The dashboard is provided to improve\nvisibility into the nature and quality of information shared online, and\nprovide real-time access to insights and information extracted from the\ndataset.", "author": [{"name": "Karishma Sharma"}, {"name": "Sungyong Seo"}, {"name": "Chuizheng Meng"}, {"name": "Sirisha Rambhatla"}, {"name": "Yan Liu"}], "link": [{"@href": "http://arxiv.org/abs/2003.12309v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.12309v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.05710v2", "updated": "2020-08-24T19:13:30Z", "published": "2020-05-12T12:07:35Z", "title": "An Exploratory Study of COVID-19 Misinformation on Twitter", "summary": "During the COVID-19 pandemic, social media has become a home ground for\nmisinformation. To tackle this infodemic, scientific oversight, as well as a\nbetter understanding by practitioners in crisis management, is needed. We have\nconducted an exploratory study into the propagation, authors and content of\nmisinformation on Twitter around the topic of COVID-19 in order to gain early\ninsights. We have collected all tweets mentioned in the verdicts of\nfact-checked claims related to COVID-19 by over 92 professional fact-checking\norganisations between January and mid-July 2020 and share this corpus with the\ncommunity. This resulted in 1 500 tweets relating to 1 274 false and 276\npartially false claims, respectively. Exploratory analysis of author accounts\nrevealed that the verified twitter handle(including Organisation/celebrity) are\nalso involved in either creating (new tweets) or spreading (retweet) the\nmisinformation. Additionally, we found that false claims propagate faster than\npartially false claims. Compare to a background corpus of COVID-19 tweets,\ntweets with misinformation are more often concerned with discrediting other\ninformation on social media. Authors use less tentative language and appear to\nbe more driven by concerns of potential harm to others. Our results enable us\nto suggest gaps in the current scientific coverage of the topic as well as\npropose actions for authorities and social media users to counter\nmisinformation.", "author": [{"name": "Gautam Kishore Shahi"}, {"name": "Anne Dirkson"}, {"name": "Tim A. Majchrzak"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "20 pages, nine figures, four tables. Submitted for peer review,\n  revision 1"}, "link": [{"@href": "http://arxiv.org/abs/2005.05710v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.05710v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.00747v1", "updated": "2021-03-01T04:28:39Z", "published": "2021-03-01T04:28:39Z", "title": "Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models", "summary": "Misinformation of COVID-19 is prevalent on social media as the pandemic\nunfolds, and the associated risks are extremely high. Thus, it is critical to\ndetect and combat such misinformation. Recently, deep learning models using\nnatural language processing techniques, such as BERT (Bidirectional Encoder\nRepresentations from Transformers), have achieved great successes in detecting\nmisinformation. In this paper, we proposed an explainable natural language\nprocessing model based on DistilBERT and SHAP (Shapley Additive exPlanations)\nto combat misinformation about COVID-19 due to their efficiency and\neffectiveness. First, we collected a dataset of 984 claims about COVID-19 with\nfact checking. By augmenting the data using back-translation, we doubled the\nsample size of the dataset and the DistilBERT model was able to obtain good\nperformance (accuracy: 0.972; areas under the curve: 0.993) in detecting\nmisinformation about COVID-19. Our model was also tested on a larger dataset\nfor AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good\nperformance (accuracy: 0.938; areas under the curve: 0.985). The performance on\nboth datasets was better than traditional machine learning models. Second, in\norder to boost public trust in model prediction, we employed SHAP to improve\nmodel explainability, which was further evaluated using a between-subjects\nexperiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),\nand text+SHAP explanation+source and evidence (TSESE). The participants were\nsignificantly more likely to trust and share information related to COVID-19 in\nthe TSE and TSESE conditions than in the T condition. Our results provided good\nimplications in detecting misinformation about COVID-19 and improving public\ntrust.", "author": [{"name": "Jackie Ayoub"}, {"name": "X. Jessie Yang"}, {"name": "Feng Zhou"}], "link": [{"@href": "http://arxiv.org/abs/2103.00747v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.00747v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1610.04170v2", "updated": "2018-01-17T17:44:51Z", "published": "2016-10-13T16:48:45Z", "title": "Network segregation in a model of misinformation and fact checking", "summary": "Misinformation under the form of rumor, hoaxes, and conspiracy theories\nspreads on social media at alarming rates. One hypothesis is that, since social\nmedia are shaped by homophily, belief in misinformation may be more likely to\nthrive on those social circles that are segregated from the rest of the\nnetwork. One possible antidote is fact checking which, in some cases, is known\nto stop rumors from spreading further. However, fact checking may also backfire\nand reinforce the belief in a hoax. Here we take into account the combination\nof network segregation, finite memory and attention, and fact-checking efforts.\nWe consider a compartmental model of two interacting epidemic processes over a\nnetwork that is segregated between gullible and skeptic users. Extensive\nsimulation and mean-field analysis show that a more segregated network\nfacilitates the spread of a hoax only at low forgetting rates, but has no\neffect when agents forget at faster rates. This finding may inform the\ndevelopment of mitigation techniques and overall inform on the risks of\nuncontrolled misinformation online.", "author": [{"name": "Marcella Tambuscio"}, {"name": "Diego F. M. Oliveira"}, {"name": "Giovanni Luca Ciampaglia"}, {"name": "Giancarlo Ruffo"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/s42001-018-0018-9"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/s42001-018-0018-9", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1610.04170v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1610.04170v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "J Comput Soc Sc (2018) 1: 261"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1802.01400v1", "updated": "2018-02-05T14:17:21Z", "published": "2018-02-05T14:17:21Z", "title": "Polarization and Fake News: Early Warning of Potential Misinformation\n  Targets", "summary": "Users polarization and confirmation bias play a key role in misinformation\nspreading on online social media. Our aim is to use this information to\ndetermine in advance potential targets for hoaxes and fake news. In this paper,\nwe introduce a general framework for promptly identifying polarizing content on\nsocial media and, thus, \"predicting\" future fake news topics. We validate the\nperformances of the proposed methodology on a massive Italian Facebook dataset,\nshowing that we are able to identify topics that are susceptible to\nmisinformation with 77% accuracy. Moreover, such information may be embedded as\na new feature in an additional classifier able to recognize fake news with 91%\naccuracy. The novelty of our approach consists in taking into account a series\nof characteristics related to users behavior on online social media, making a\nfirst, important step towards the smoothing of polarization and the mitigation\nof misinformation phenomena.", "author": [{"name": "Michela Del Vicario"}, {"name": "Walter Quattrociocchi"}, {"name": "Antonio Scala"}, {"name": "Fabiana Zollo"}], "link": [{"@href": "http://arxiv.org/abs/1802.01400v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1802.01400v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1903.04887v2", "updated": "2019-12-05T20:29:36Z", "published": "2019-03-04T22:23:33Z", "title": "QuickStop: A Markov Optimal Stopping Approach for Quickest\n  Misinformation Detection", "summary": "This paper combines data-driven and model-driven methods for real-time\nmisinformation detection. Our algorithm, named QuickStop, is an optimal\nstopping algorithm based on a probabilistic information spreading model\nobtained from labeled data. The algorithm consists of an offline machine\nlearning algorithm for learning the probabilistic information spreading model\nand an online optimal stopping algorithm to detect misinformation. The online\ndetection algorithm has both low computational and memory complexities. Our\nnumerical evaluations with a real-world dataset show that QuickStop outperforms\nexisting misinformation detection algorithms in terms of both accuracy and\ndetection time (number of observations needed for detection). Our evaluations\nwith synthetic data further show that QuickStop is robust to (offline) learning\nerrors.", "author": [{"name": "Honghao Wei"}, {"name": "Xiaohan Kang"}, {"name": "Weina Wang"}, {"name": "Lei Ying"}], "link": [{"@href": "http://arxiv.org/abs/1903.04887v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.04887v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.10801v1", "updated": "2019-04-24T13:25:46Z", "published": "2019-04-24T13:25:46Z", "title": "Containing misinformation spreading in temporal social networks", "summary": "Many researchers from a variety of fields including computer science, network\nscience and mathematics have focused on how to contain the outbreaks of\nInternet misinformation that threaten social systems and undermine societal\nhealth. Most research on this topic treats the connections among individuals as\nstatic, but these connections change in time, and thus social networks are also\ntemporal networks. Currently there is no theoretical approach to the problem of\ncontaining misinformation outbreaks in temporal networks. We thus propose a\nmisinformation spreading model for temporal networks and describe it using a\nnew theoretical approach. We propose a heuristic-containing (HC) strategy based\non optimizing final outbreak size that outperforms simplified strategies such\nas those that are random-containing (RC) and targeted-containing (TC). We\nverify the effectiveness of our HC strategy on both artificial and real-world\nnetworks by performing extensive numerical simulations and theoretical\nanalyses. We find that the HC strategy greatly increases the outbreak threshold\nand decreases the final outbreak threshold.", "author": [{"name": "Wei Wang"}, {"name": "Yuanhui Ma"}, {"name": "Tao Wu"}, {"name": "Yang Dai"}, {"name": "Xingshu Chen"}, {"name": "Lidia A. Braunstein"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1063/1.5114853"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1063/1.5114853", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1904.10801v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.10801v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "22 pages, 9 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Chaos, (2019)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.09805v2", "updated": "2020-02-20T18:32:33Z", "published": "2019-08-26T17:23:22Z", "title": "The Limitations of Stylometry for Detecting Machine-Generated Fake News", "summary": "Recent developments in neural language models (LMs) have raised concerns\nabout their potential misuse for automatically spreading misinformation. In\nlight of these concerns, several studies have proposed to detect\nmachine-generated fake news by capturing their stylistic differences from\nhuman-written text. These approaches, broadly termed stylometry, have found\nsuccess in source attribution and misinformation detection in human-written\ntexts. However, in this work, we show that stylometry is limited against\nmachine-generated misinformation. While humans speak differently when trying to\ndeceive, LMs generate stylistically consistent text, regardless of underlying\nmotive. Thus, though stylometry can successfully prevent impersonation by\nidentifying text provenance, it fails to distinguish legitimate LM applications\nfrom those that introduce false information. We create two benchmarks\ndemonstrating the stylistic similarity between malicious and legitimate uses of\nLMs, employed in auto-completion and editing-assistance settings. Our findings\nhighlight the need for non-stylometry approaches in detecting machine-generated\nmisinformation, and open up the discussion on the desired evaluation\nbenchmarks.", "author": [{"name": "Tal Schuster"}, {"name": "Roei Schuster"}, {"name": "Darsh J Shah"}, {"name": "Regina Barzilay"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for Computational Linguistics journal (squib). Previously\n  posted with title \"Are We Safe Yet? The Limitations of Distributional\n  Features for Fake News Detection\""}, "link": [{"@href": "http://arxiv.org/abs/1908.09805v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.09805v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.01284v3", "updated": "2020-06-30T22:30:37Z", "published": "2020-06-01T21:48:22Z", "title": "Independent Component Analysis for Trustworthy Cyberspace during High\n  Impact Events: An Application to Covid-19", "summary": "Social media has become an important communication channel during high impact\nevents, such as the COVID-19 pandemic. As misinformation in social media can\nrapidly spread, creating social unrest, curtailing the spread of misinformation\nduring such events is a significant data challenge. While recent solutions that\nare based on machine learning have shown promise for the detection of\nmisinformation, most widely used methods include approaches that rely on either\nhandcrafted features that cannot be optimal for all scenarios, or those that\nare based on deep learning where the interpretation of the prediction results\nis not directly accessible. In this work, we propose a data-driven solution\nthat is based on the ICA model, such that knowledge discovery and detection of\nmisinformation are achieved jointly. To demonstrate the effectiveness of our\nmethod and compare its performance with deep learning methods, we developed a\nlabeled COVID-19 Twitter dataset based on socio-linguistic criteria.", "author": [{"name": "Zois Boukouvalas"}, {"name": "Christine Mallinson"}, {"name": "Evan Crothers"}, {"name": "Nathalie Japkowicz"}, {"name": "Aritran Piplai"}, {"name": "Sudip Mittal"}, {"name": "Anupam Joshi"}, {"name": "T\u00fclay Adal\u0131"}], "link": [{"@href": "http://arxiv.org/abs/2006.01284v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.01284v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.05271v1", "updated": "2020-08-12T12:42:57Z", "published": "2020-08-12T12:42:57Z", "title": "Social Media and Health Misinformation during the US COVID Crisis", "summary": "Health misinformation has been found to be prevalent on social media,\nparticularly in new public health crises in which there is limited scientific\ninformation. However, social media can also play a role in limiting and\nrefuting health misinformation. Using as a case study US President Donald\nTrump's controversial comments about the promise and power of UV light- and\ndisinfectant-based treatments, this data memo examines how these comments were\ndiscussed and responded to on Twitter. We find that these comments fell into\nestablished politically partisan narratives and dominated discussion of both\npolitics and COVID in the days following. Contestation of the comments was much\nmore prevalent than support. Supporters attacked media coverage in line with\nexisting Trump narratives. Contesters responded with humour and shared\nmainstream media coverage condemning the comments. These practices would have\nstrengthened the original misinformation through repetition and done little to\nconstruct a successful refutation for those who might have believed them. This\nresearch adds much-needed knowledge to our understanding of the information\nenvironment surrounding COVID and demonstrates that, despite calls for the\ndepoliticization of health information in this public health crisis, this is\nlargely being approached as a political issue along divisive, polarised,\npartisan lines.", "author": [{"name": "Gillian Bolsover"}, {"name": "Janet Tokitsu Tizon"}], "link": [{"@href": "http://arxiv.org/abs/2008.05271v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.05271v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.09218v2", "updated": "2021-05-27T22:07:08Z", "published": "2020-09-19T12:24:53Z", "title": "Misinformation and its stakeholders in Europe: a web-based analysis", "summary": "The rise of the internet and computational power in recent years allowed for\nthe exponential growth of misinformation phenomena. An issue that was a\nnon-issue a decade ago, became a challenge for societal cohesion. The emergence\nof this new threat has led many stakeholders, especially in Europe, to act in\norder to tackle this phenomenon. This paper provides in its first part a\nliterature review on misinformation in Europe, and in its second part a\nwebometrics analysis on the identified key stakeholders. In the results we\ndiscuss who those stakeholders are, what actions do they perform to limit\nmisinformation and whether those actions have an impact.", "author": [{"name": "Emmanouil Koulas"}, {"name": "Marios Anthopoulos"}, {"name": "Sotiria Grammenou"}, {"name": "Christos Kaimakamis"}, {"name": "Konstantinos Kousaris"}, {"name": "Fotini-Rafailia Panavou"}, {"name": "Orestis Piskioulis"}, {"name": "Syed Iftikhar H. Shah"}, {"name": "Vasilios Peristeras"}], "link": [{"@href": "http://arxiv.org/abs/2009.09218v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.09218v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.00544v1", "updated": "2020-10-01T16:58:12Z", "published": "2020-10-01T16:58:12Z", "title": "Designing Indicators to Combat Fake Media", "summary": "The growth of misinformation technology necessitates the need to identify\nfake videos. One approach to preventing the consumption of these fake videos is\nprovenance which allows the user to authenticate media content to its original\nsource. This research designs and investigates the use of provenance indicators\nto help users identify fake videos. We first interview users regarding their\nexperiences with different misinformation modes (text, image, video) to guide\nthe design of indicators within users' existing perspectives. Then, we conduct\na participatory design study to develop and design fake video indicators.\nFinally, we evaluate participant-designed indicators via both expert\nevaluations and quantitative surveys with a large group of end-users. Our\nresults provide concrete design guidelines for the emerging issue of fake\nvideos. Our findings also raise concerns regarding users' tendency to\novergeneralize from misinformation warning messages, suggesting the need for\nfurther research on warning design in the ongoing fight against misinformation.", "author": [{"name": "Imani N. Sherman"}, {"name": "Elissa M. Redmiles"}, {"name": "Jack W. Stokes"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "26 pages, 12 figures"}, "link": [{"@href": "http://arxiv.org/abs/2010.00544v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.00544v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.08743v1", "updated": "2020-10-17T08:34:57Z", "published": "2020-10-17T08:34:57Z", "title": "Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed\n  health decision making in the presence of COVID19 misinformation", "summary": "Given the wide spread of inaccurate medical advice related to the 2019\ncoronavirus pandemic (COVID-19), such as fake remedies, treatments and\nprevention suggestions, misinformation detection has emerged as an open problem\nof high importance and interest for the NLP community. To combat potential harm\nof COVID19-related misinformation, we release Covid-HeRA, a dataset for health\nrisk assessment of COVID-19-related social media posts. More specifically, we\nstudy the severity of each misinformation story, i.e., how harmful a message\nbelieved by the audience can be and what type of signals can be used to\ndiscover high malicious fake news and detect refuted claims. We present a\ndetailed analysis, evaluate several simple and advanced classification models,\nand conclude with our experimental analysis that presents open challenges and\nfuture directions.", "author": [{"name": "Arkin Dharawat"}, {"name": "Ismini Lourentzou"}, {"name": "Alex Morales"}, {"name": "ChengXiang Zhai"}], "link": [{"@href": "http://arxiv.org/abs/2010.08743v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.08743v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.08768v2", "updated": "2021-03-13T20:26:35Z", "published": "2020-10-17T11:21:40Z", "title": "ArCOV19-Rumors: Arabic COVID-19 Twitter Dataset for Misinformation\n  Detection", "summary": "In this paper we introduce ArCOV19-Rumors, an Arabic COVID-19 Twitter dataset\nfor misinformation detection composed of tweets containing claims from 27th\nJanuary till the end of April 2020. We collected 138 verified claims, mostly\nfrom popular fact-checking websites, and identified 9.4K relevant tweets to\nthose claims. Tweets were manually-annotated by veracity to support research on\nmisinformation detection, which is one of the major problems faced during a\npandemic. ArCOV19-Rumors supports two levels of misinformation detection over\nTwitter: verifying free-text claims (called claim-level verification) and\nverifying claims expressed in tweets (called tweet-level verification). Our\ndataset covers, in addition to health, claims related to other topical\ncategories that were influenced by COVID-19, namely, social, politics, sports,\nentertainment, and religious. Moreover, we present benchmarking results for\ntweet-level verification on the dataset. We experimented with SOTA models of\nversatile approaches that either exploit content, user profiles features,\ntemporal features and propagation structure of the conversational threads for\ntweet verification.", "author": [{"name": "Fatima Haouari"}, {"name": "Maram Hasanain"}, {"name": "Reem Suwaileh"}, {"name": "Tamer Elsayed"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This work was accepted at the Sixth Arabic Natural Language\n  Processing Workshop (EACL/WANLP 2021)"}, "link": [{"@href": "http://arxiv.org/abs/2010.08768v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.08768v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.11362v1", "updated": "2021-02-22T21:06:52Z", "published": "2021-02-22T21:06:52Z", "title": "An ontological analysis of misinformation in online social networks", "summary": "The internet, Online Social Networks (OSNs) and smart phones enable users to\ncreate tremendous amount of information. Users who search for general or\nspecific knowledge may not have these days problems of information scarce but\nmisinformation. Misinformation nowadays can refer to a continuous spectrum\nbetween what can be seen as \"facts\" or \"truth\", if humans agree on the\nexistence of such, to false information that everyone agree that it is false.\nIn this paper, we will look at this spectrum of information/misinformation and\ncompare between some of the major relevant concepts. While few fact-checking\nwebsites exist to evaluate news articles or some of the popular claims people\nexchange, nonetheless this can be seen as a little effort in the mission to tag\nonline information with their \"proper\" category or label.", "author": [{"name": "Izzat Alsmadi"}, {"name": "Iyad Alazzam"}, {"name": "Mohammad A. AlRamahi"}], "link": [{"@href": "http://arxiv.org/abs/2102.11362v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.11362v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.11694v1", "updated": "2021-04-20T23:19:43Z", "published": "2021-04-20T23:19:43Z", "title": "Mutual Hyperlinking Among Misinformation Peddlers", "summary": "The internet promised to democratize access to knowledge and make the world\nmore open and understanding. The reality of today's internet, however, is far\nfrom this ideal. Misinformation, lies, and conspiracies dominate many social\nmedia platforms. This toxic online world has had real-world implications\nranging from genocide to, election interference, and threats to global public\nhealth. A frustrated public and impatient government regulators are calling for\na more vigorous response to mis- and disinformation campaigns designed to sow\ncivil unrest and inspire violence against individuals, societies, and\ndemocracies. We describe a large-scale, domain-level analysis that reveals\nseemingly coordinated efforts between multiple domains to spread and amplify\nmisinformation. We also describe how the hyperlinks shared by certain Twitter\nusers can be used to surface problematic domains. These analyses can be used by\nsearch engines and social media recommendation algorithms to systematically\ndiscover and demote misinformation peddlers.", "author": [{"name": "Vibhor Sehgal"}, {"name": "Ankit Peshin"}, {"name": "Sadia Afroz"}, {"name": "Hany Farid"}], "link": [{"@href": "http://arxiv.org/abs/2104.11694v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.11694v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2105.07730v1", "updated": "2021-05-17T10:58:35Z", "published": "2021-05-17T10:58:35Z", "title": "The State of Infodemic on Twitter", "summary": "Following the wave of misinterpreted, manipulated and malicious information\ngrowing on the Internet, the misinformation surrounding COVID-19 has become a\nparamount issue. In the context of the current COVID-19 pandemic, social media\nposts and platforms are at risk of rumors and misinformation in the face of the\nserious uncertainty surrounding the virus itself. At the same time, the\nuncertainty and new nature of COVID-19 means that other unconfirmed information\nthat may appear \"rumored\" may be an important indicator of the behavior and\nimpact of this new virus. Twitter, in particular, has taken a center stage in\nthis storm where Covid-19 has been a much talked about subject. We have\npresented an exploratory analysis of the tweets and the users who are involved\nin spreading misinformation and then delved into machine learning models and\nnatural language processing techniques to identify if a tweet contains\nmisinformation.", "author": [{"name": "Drishti Jain", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Indraprastha Institute of Information Technology"}}, {"name": "Tavpritesh Sethi", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Indraprastha Institute of Information Technology"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages"}, "link": [{"@href": "http://arxiv.org/abs/2105.07730v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.07730v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.00163v1", "updated": "2021-06-01T01:12:44Z", "published": "2021-06-01T01:12:44Z", "title": "Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform", "summary": "This paper evaluates Parler, the controversial social media platform, from\ntwo seemingly orthogonal perspectives: UX design perspective and data science.\nUX design researchers explore how users react to the interface/content of their\nsocial media feeds; Data science researchers analyze the misinformation flow in\nthese feeds to detect alternative narratives and state-sponsored disinformation\ncampaigns. We took a critical look into the intersection of these approaches to\nunderstand how Parler's interface itself is conductive to the flow of\nmisinformation and the perception of \"free speech\" among its audience. Parler\ndrew widespread attention leading up to and after the 2020 U.S. elections as\nthe \"alternative\" place for free speech, as a reaction to other mainstream\nsocial media platform which actively engaged in labeling misinformation with\ncontent warnings. Because platforms like Parler are disruptive to the social\nmedia landscape, we believe the evaluation uniquely uncovers the platform's\nconductivity to the spread of misinformation.", "author": [{"name": "Emma Pieroni"}, {"name": "Peter Jachim"}, {"name": "Nathaniel Jachim"}, {"name": "Filipo Sharevski"}], "link": [{"@href": "http://arxiv.org/abs/2106.00163v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.00163v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1706.05924v2", "updated": "2017-07-17T17:17:37Z", "published": "2017-06-19T13:26:41Z", "title": "\"Everything I Disagree With is #FakeNews\": Correlating Political\n  Polarization and Spread of Misinformation", "summary": "An important challenge in the process of tracking and detecting the\ndissemination of misinformation is to understand the political gap between\npeople that engage with the so called \"fake news\". A possible factor\nresponsible for this gap is opinion polarization, which may prompt the general\npublic to classify content that they disagree or want to discredit as fake. In\nthis work, we study the relationship between political polarization and content\nreported by Twitter users as related to \"fake news\". We investigate how\npolarization may create distinct narratives on what misinformation actually is.\nWe perform our study based on two datasets collected from Twitter. The first\ndataset contains tweets about US politics in general, from which we compute the\ndegree of polarization of each user towards the Republican and Democratic\nParty. In the second dataset, we collect tweets and URLs that co-occurred with\n\"fake news\" related keywords and hashtags, such as #FakeNews and\n#AlternativeFact, as well as reactions towards such tweets and URLs. We then\nanalyze the relationship between polarization and what is perceived as\nmisinformation, and whether users are designating information that they\ndisagree as fake. Our results show an increase in the polarization of users and\nURLs associated with fake-news keywords and hashtags, when compared to\ninformation not labeled as \"fake news\". We discuss the impact of our findings\non the challenges of tracking \"fake news\" in the ongoing battle against\nmisinformation.", "author": [{"name": "Manoel Horta Ribeiro"}, {"name": "Pedro H. Calais"}, {"name": "Virg\u00edlio A. F. Almeida"}, {"name": "Wagner Meira Jr"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 10 figures, to be presented at DS+J Workshop @ KDD'17"}, "link": [{"@href": "http://arxiv.org/abs/1706.05924v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1706.05924v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1807.01162v2", "updated": "2020-01-13T04:35:08Z", "published": "2018-07-01T18:58:59Z", "title": "Reverse Prevention Sampling for Misinformation Mitigation in Social\n  Networks", "summary": "In this work, we consider misinformation propagating through a social network\nand study the problem of its prevention. In this problem, a \"bad\" campaign\nstarts propagating from a set of seed nodes in the network and we use the\nnotion of a limiting (or \"good\") campaign to counteract the effect of\nmisinformation. The goal is to identify a set of $k$ users that need to be\nconvinced to adopt the limiting campaign so as to minimize the number of people\nthat adopt the \"bad\" campaign at the end of both propagation processes.\n  This work presents \\emph{RPS} (Reverse Prevention Sampling), an algorithm\nthat provides a scalable solution to the misinformation mitigation problem. Our\ntheoretical analysis shows that \\emph{RPS} runs in $O((k + l)(n + m)(\\frac{1}{1\n- \\gamma}) \\log n / \\epsilon^2 )$ expected time and returns a $(1 - 1/e -\n\\epsilon)$-approximate solution with at least $1 - n^{-l}$ probability (where\n$\\gamma$ is a typically small network parameter and $l$ is a confidence\nparameter). The time complexity of \\emph{RPS} substantially improves upon the\npreviously best-known algorithms that run in time $\\Omega(m n k \\cdot\nPOLY(\\epsilon^{-1}))$. We experimentally evaluate \\emph{RPS} on large datasets\nand show that it outperforms the state-of-the-art solution by several orders of\nmagnitude in terms of running time. This demonstrates that misinformation\nmitigation can be made practical while still offering strong theoretical\nguarantees.", "author": [{"name": "Michael Simpson"}, {"name": "Venkatesh Srinivasan"}, {"name": "Alex Thomo"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: text overlap with arXiv:1404.0900, arXiv:1212.0884\n  by other authors"}, "link": [{"@href": "http://arxiv.org/abs/1807.01162v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1807.01162v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1603.01511v1", "updated": "2016-03-04T15:59:06Z", "published": "2016-03-04T15:59:06Z", "title": "Hoaxy: A Platform for Tracking Online Misinformation", "summary": "Massive amounts of misinformation have been observed to spread in\nuncontrolled fashion across social media. Examples include rumors, hoaxes, fake\nnews, and conspiracy theories. At the same time, several journalistic\norganizations devote significant efforts to high-quality fact checking of\nonline claims. The resulting information cascades contain instances of both\naccurate and inaccurate information, unfold over multiple time scales, and\noften reach audiences of considerable size. All these factors pose challenges\nfor the study of the social dynamics of online news sharing. Here we introduce\nHoaxy, a platform for the collection, detection, and analysis of online\nmisinformation and its related fact-checking efforts. We discuss the design of\nthe platform and present a preliminary analysis of a sample of public tweets\ncontaining both fake news and fact checking. We find that, in the aggregate,\nthe sharing of fact-checking content typically lags that of misinformation by\n10--20 hours. Moreover, fake news are dominated by very active users, while\nfact checking is a more grass-roots activity. With the increasing risks\nconnected to massive online misinformation, social news observatories have the\npotential to help researchers, journalists, and the general public understand\nthe dynamics of real and fake news sharing.", "author": [{"name": "Chengcheng Shao"}, {"name": "Giovanni Luca Ciampaglia"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/2872518.2890098"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/2872518.2890098", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1603.01511v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1603.01511v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 6 figures, submitted to Third Workshop on Social News On the\n  Web"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.08355v1", "updated": "2021-02-16T18:45:01Z", "published": "2021-02-16T18:45:01Z", "title": "Adversarial Targeted Forgetting in Regularization and Generative Based\n  Continual Learning Models", "summary": "Continual (or \"incremental\") learning approaches are employed when additional\nknowledge or tasks need to be learned from subsequent batches or from streaming\ndata. However these approaches are typically adversary agnostic, i.e., they do\nnot consider the possibility of a malicious attack. In our prior work, we\nexplored the vulnerabilities of Elastic Weight Consolidation (EWC) to the\nperceptible misinformation. We now explore the vulnerabilities of other\nregularization-based as well as generative replay-based continual learning\nalgorithms, and also extend the attack to imperceptible misinformation. We show\nthat an intelligent adversary can take advantage of a continual learning\nalgorithm's capabilities of retaining existing knowledge over time, and force\nit to learn and retain deliberately introduced misinformation. To demonstrate\nthis vulnerability, we inject backdoor attack samples into the training data.\nThese attack samples constitute the misinformation, allowing the attacker to\ncapture control of the model at test time. We evaluate the extent of this\nvulnerability on both rotated and split benchmark variants of the MNIST dataset\nunder two important domain and class incremental learning scenarios. We show\nthat the adversary can create a \"false memory\" about any task by inserting\ncarefully-designed backdoor samples to the test instances of that task thereby\ncontrolling the amount of forgetting of any task of its choosing. Perhaps most\nimportantly, we show this vulnerability to be very acute and damaging: the\nmodel memory can be easily compromised with the addition of backdoor samples\ninto as little as 1\\% of the training data, even when the misinformation is\nimperceptible to human eye.", "author": [{"name": "Muhammad Umer"}, {"name": "Robi Polikar"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: text overlap with arXiv:2002.07111"}, "link": [{"@href": "http://arxiv.org/abs/2102.08355v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.08355v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1903.07219v2", "updated": "2021-02-18T11:31:57Z", "published": "2019-03-18T01:15:48Z", "title": "Automatically applying a credibility appraisal tool to track\n  vaccination-related communications shared on social media", "summary": "Background:\n  Tools used to appraise the credibility of health information are\ntime-consuming to apply and require context-specific expertise, limiting their\nuse for quickly identifying and mitigating the spread of misinformation as it\nemerges. Our aim was to estimate the proportion of vaccination-related posts on\nTwitter are likely to be misinformation, and how unevenly exposure to\nmisinformation was distributed among Twitter users.\n  Methods:\n  Sampling from 144,878 vaccination-related web pages shared on Twitter between\nJanuary 2017 and March 2018, we used a seven-point checklist adapted from two\nvalidated tools to appraise the credibility of a small subset of 474. These\nwere used to train several classifiers (random forest, support vector machines,\nand a recurrent neural network with transfer learning), using the text from a\nweb page to predict whether the information satisfies each of the seven\ncriteria.\n  Results:\n  Applying the best performing classifier to the 144,878 web pages, we found\nthat 14.4% of relevant posts to text-based communications were linked to\nwebpages of low credibility and made up 9.2% of all potential\nvaccination-related exposures. However, the 100 most popular links to\nmisinformation were potentially seen by between 2 million and 80 million\nTwitter users, and for a substantial sub-population of Twitter users engaging\nwith vaccination-related information, links to misinformation appear to\ndominate the vaccination-related information to which they were exposed.\n  Conclusions:\n  We proposed a new method for automatically appraising the credibility of\nwebpages based on a combination of validated checklist tools. The results\nsuggest that an automatic credibility appraisal tool can be used to find\npopulations at higher risk of exposure to misinformation or applied proactively\nto add friction to the sharing of low credibility vaccination information.", "author": [{"name": "Zubair Shah"}, {"name": "Didi Surian"}, {"name": "Amalie Dyda"}, {"name": "Enrico Coiera"}, {"name": "Kenneth D. Mandl"}, {"name": "Adam G. Dunn"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.2196/14007"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.2196/14007", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1903.07219v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.07219v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 Pages, 5 Figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "https://www.jmir.org/2019/11/e14007"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2006.00765v2", "updated": "2021-04-06T14:09:31Z", "published": "2020-06-01T07:45:35Z", "title": "Conspiracy vs science: A large-scale analysis of online discussion\n  cascades", "summary": "With the emergence and rapid proliferation of social media platforms and\nsocial networking sites, recent years have witnessed a surge of misinformation\nspreading in our daily life. Drawing on a large-scale dataset which covers more\nthan 1.4M posts and 18M comments, we investigate the propagation of two\ndistinct narratives--(i) conspiracy information, whose claims are generally\nunsubstantiated and thus referred as misinformation to some extent, and (ii)\nscientific information, whose origins are generally readily identifiable and\nverifiable--in an online social media platform. We find that conspiracy\ncascades tend to propagate in a multigenerational branching process while\nscience cascades are more likely to grow in a breadth-first manner.\nSpecifically, conspiracy information triggers larger cascades, involves more\nusers and generations, persists longer, is more viral and bursty than science\ninformation. Content analysis reveals that conspiracy cascades contain more\nnegative words and emotional words which convey anger, fear, disgust, surprise\nand trust. We also find that conspiracy cascades are more concerned with\npolitical and controversial topics. After applying machine learning models, we\nachieve an AUC score of nearly 90% in discriminating conspiracy from science\nnarratives.\n  We find that conspiracy cascades are more likely to be controlled by a\nbroader set of users than science cascades, imposing new challenges on the\nmanagement of misinformation. Although political affinity is thought to affect\nthe consumption of misinformation, there is very little evidence that political\norientation of the information source plays a role during the propagation of\nconspiracy information. Our study provides complementing evidence to current\nmisinformation research and has practical policy implications to stem the\npropagation and mitigate the influence of misinformation online.", "author": [{"name": "Yafei Zhang"}, {"name": "Lin Wang"}, {"name": "Jonathan J. H. Zhu"}, {"name": "Xiaofan Wang"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/s11280-021-00862-x"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/s11280-021-00862-x", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2006.00765v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.00765v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "24 pages, 9 figures, 3 tables"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "World Wide Web 24, 585-606 (2021)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1212.1002v1", "updated": "2012-12-05T12:07:05Z", "published": "2012-12-05T12:07:05Z", "title": "Stochastic Models of Misinformation Distribution in Online Social\n  Networks", "summary": "This report contains results of an experimental study of the distribution of\nmisinformation in online social networks (OSNs). We consider the classification\nof the topologies of OSNs and analyze the parameters identified in order to\nrelate the topology of a real network with one of the classes. We propose an\nalgorithm for conducting a search for the percolation cluster in the social\ngraph.", "author": [{"name": "Konstantin Abramov"}, {"name": "Yuri Monakhov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "4 pages, 1 figure, 1 table"}, "link": [{"@href": "http://arxiv.org/abs/1212.1002v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1212.1002v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.1.2; J.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1704.02406v2", "updated": "2017-06-27T01:56:01Z", "published": "2017-04-08T00:12:10Z", "title": "Impact of misinformation in temporal network epidemiology", "summary": "We investigate the impact of misinformation about the contact structure on\nthe ability to predict disease outbreaks. We base our study on 31 empirical\ntemporal networks and tune the frequencies in errors in the node identities or\ntimestamps of contacts. We find that for both these spreading scenarios, the\nmaximal misprediction of both the outbreak size and time to extinction follows\nan stretched exponential convergence as a function of the error frequency. We\nfurthermore determine the temporal-network structural factors influencing the\nparameters of this convergence.", "author": [{"name": "Petter Holme"}, {"name": "Luis E C Rocha"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1017/nws.2018.28"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1017/nws.2018.28", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1704.02406v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1704.02406v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Net Sci 7 (2019) 52-69"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1809.05901v1", "updated": "2018-09-16T15:49:14Z", "published": "2018-09-16T15:49:14Z", "title": "Trends in the Diffusion of Misinformation on Social Media", "summary": "We measure trends in the diffusion of misinformation on Facebook and Twitter\nbetween January 2015 and July 2018. We focus on stories from 570 sites that\nhave been identified as producers of false stories. Interactions with these\nsites on both Facebook and Twitter rose steadily through the end of 2016.\nInteractions then fell sharply on Facebook while they continued to rise on\nTwitter, with the ratio of Facebook engagements to Twitter shares falling by\napproximately 60 percent. We see no similar pattern for other news, business,\nor culture sites, where interactions have been relatively stable over time and\nhave followed similar trends on the two platforms both before and after the\nelection.", "author": [{"name": "Hunt Allcott"}, {"name": "Matthew Gentzkow"}, {"name": "Chuan Yu"}], "link": [{"@href": "http://arxiv.org/abs/1809.05901v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.05901v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.13352v1", "updated": "2020-10-26T05:37:18Z", "published": "2020-10-26T05:37:18Z", "title": "The Age-related Differences in Web Information Search Process", "summary": "Older adults' need for quality health information has never been more\ncritical as during the COVID-19 pandemic. Yet, they are susceptible to the\nwide-spread misinformation disseminated through search engines and social\nmedia. To build a search-related behavioral profile of older adults, this\narticle surveys the empirical research on age-related differences in query\nformulation, search strategies, information evaluation, and susceptibility to\nmisinformation effects. It also decomposes the mechanisms (i.e., cognitive\nchanges, development goal shift) and moderators (i.e., search task and\ninterface design) of such differences. To inform the design of information\nsystems to improve older adults' information search experience, we discuss\nopportunities for future research.", "author": [{"name": "Zhaopeng Xing", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Jenny"}}, {"name": "Xiaojun", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Jenny"}}, {"name": "Yuan"}, {"name": "Lisa Vizer"}], "link": [{"@href": "http://arxiv.org/abs/2010.13352v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.13352v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.14500v2", "updated": "2021-01-25T02:29:18Z", "published": "2020-12-28T21:51:31Z", "title": "A Paragraph-level Multi-task Learning Model for Scientific\n  Fact-Verification", "summary": "Even for domain experts, it is a non-trivial task to verify a scientific\nclaim by providing supporting or refuting evidence rationales. The situation\nworsens as misinformation is proliferated on social media or news websites,\nmanually or programmatically, at every moment. As a result, an automatic\nfact-verification tool becomes crucial for combating the spread of\nmisinformation. In this work, we propose a novel, paragraph-level, multi-task\nlearning model for the SciFact task by directly computing a sequence of\ncontextualized sentence embeddings from a BERT model and jointly training the\nmodel on rationale selection and stance prediction.", "author": [{"name": "Xiangci Li"}, {"name": "Gully Burns"}, {"name": "Nanyun Peng"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages; The AAAI-21 Workshop on Scientific Document Understanding"}, "link": [{"@href": "http://arxiv.org/abs/2012.14500v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.14500v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.04311v1", "updated": "2021-04-09T11:33:02Z", "published": "2021-04-09T11:33:02Z", "title": "Helping People Deal With Disinformation -- A Socio-Technical Perspective", "summary": "At the latest since the advent of the Internet, disinformation and conspiracy\ntheories have become ubiquitous. Recent examples like QAnon and Pizzagate prove\nthat false information can lead to real violence. In this motivation statement\nfor the Workshop on Human Aspects of Misinformation at CHI 2021, I explain my\nresearch agenda focused on 1. why people believe in disinformation, 2. how\npeople can be best supported in recognizing disinformation, and 3. what the\npotentials and risks of different tools designed to fight disinformation are.", "author": {"name": "Hendrik Heuer"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This paper will be presented at the Workshop on Human Aspects of\n  Misinformation at CHI 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.04311v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.04311v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.14625v1", "updated": "2021-07-30T13:46:36Z", "published": "2021-07-30T13:46:36Z", "title": "Single-Leader-Multiple-Followers Stackelberg Security Game with\n  Hypergame Framework", "summary": "In this paper, we employ a hypergame framework to analyze the\nsingle-leader-multiple-followers (SLMF) Stackelberg security game with two\ntypical misinformed situations: misperception and deception. We provide a\nstability criterion with the help of hyper Nash equilibrium (HNE) to analyze\nboth strategic stability and cognitive stability of equilibria in SLMF games\nwith misinformation. To this end, we find mild stable conditions such that the\nequilibria with misperception and deception can derive HNE. Moreover, we\nanalyze the robustness of the equilibria to reveal whether the players have the\nability to keep their profits.", "author": [{"name": "Zhaoyang Cheng"}, {"name": "Guanpu Chen"}, {"name": "Yiguang Hong"}], "link": [{"@href": "http://arxiv.org/abs/2107.14625v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.14625v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/0906.5007v1", "updated": "2009-06-26T20:57:55Z", "published": "2009-06-26T20:57:55Z", "title": "Spread of Misinformation in Social Networks", "summary": "We provide a model to investigate the tension between information aggregation\nand spread of misinformation in large societies (conceptualized as networks of\nagents communicating with each other). Each individual holds a belief\nrepresented by a scalar. Individuals meet pairwise and exchange information,\nwhich is modeled as both individuals adopting the average of their pre-meeting\nbeliefs. When all individuals engage in this type of information exchange, the\nsociety will be able to effectively aggregate the initial information held by\nall individuals. There is also the possibility of misinformation, however,\nbecause some of the individuals are \"forceful,\" meaning that they influence the\nbeliefs of (some) of the other individuals they meet, but do not change their\nown opinion. The paper characterizes how the presence of forceful agents\ninterferes with information aggregation. Under the assumption that even\nforceful agents obtain some information (however infrequent) from some others\n(and additional weak regularity conditions), we first show that beliefs in this\nclass of societies converge to a consensus among all individuals. This\nconsensus value is a random variable, however, and we characterize its\nbehavior. Our main results quantify the extent of misinformation in the society\nby either providing bounds or exact results (in some special cases) on how far\nthe consensus value can be from the benchmark without forceful agents (where\nthere is efficient information aggregation). The worst outcomes obtain when\nthere are several forceful agents and forceful agents themselves update their\nbeliefs only on the basis of information they obtain from individuals most\nlikely to have received their own information previously.", "author": [{"name": "Daron Acemoglu"}, {"name": "Asuman Ozdaglar"}, {"name": "Ali ParandehGheibi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted to Games and Economic Behavior"}, "link": [{"@href": "http://arxiv.org/abs/0906.5007v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/0906.5007v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.PR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1703.06988v1", "updated": "2017-03-20T22:19:22Z", "published": "2017-03-20T22:19:22Z", "title": "The Fake News Spreading Plague: Was it Preventable?", "summary": "In 2010, a paper entitled \"From Obscurity to Prominence in Minutes: Political\nSpeech and Real-time search\" won the Best Paper Prize of the Web Science 2010\nConference. Among its findings were the discovery and documentation of what was\ntermed a \"Twitter-bomb\", an organized effort to spread misinformation about the\ndemocratic candidate Martha Coakley through anonymous Twitter accounts. In this\npaper, after summarizing the details of that event, we outline the recipe of\nhow social networks are used to spread misinformation. One of the most\nimportant steps in such a recipe is the \"infiltration\" of a community of users\nwho are already engaged in conversations about a topic, to use them as organic\nspreaders of misinformation in their extended subnetworks. Then, we take this\nmisinformation spreading recipe and indicate how it was successfully used to\nspread fake news during the 2016 U.S. Presidential Election. The main\ndifferences between the scenarios are the use of Facebook instead of Twitter,\nand the respective motivations (in 2010: political influence; in 2016:\nfinancial benefit through online advertising). After situating these events in\nthe broader context of exploiting the Web, we seize this opportunity to address\nlimitations of the reach of research findings and to start a conversation about\nhow communities of researchers can increase their impact on real-world societal\nissues.", "author": [{"name": "Eni Mustafaraj"}, {"name": "Panagiotis Takis Metaxas"}], "link": [{"@href": "http://arxiv.org/abs/1703.06988v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1703.06988v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1508.02079v1", "updated": "2015-08-09T20:14:09Z", "published": "2015-08-09T20:14:09Z", "title": "Facts and Fabrications about Ebola: A Twitter Based Study", "summary": "Microblogging websites like Twitter have been shown to be immensely useful\nfor spreading information on a global scale within seconds. The detrimental\neffect, however, of such platforms is that misinformation and rumors are also\nas likely to spread on the network as credible, verified information. From a\npublic health standpoint, the spread of misinformation creates unnecessary\npanic for the public. We recently witnessed several such scenarios during the\noutbreak of Ebola in 2014 [14, 1]. In order to effectively counter the medical\nmisinformation in a timely manner, our goal here is to study the nature of such\nmisinformation and rumors in the United States during fall 2014 when a handful\nof Ebola cases were confirmed in North America. It is a well known convention\non Twitter to use hashtags to give context to a Twitter message (a tweet). In\nthis study, we collected approximately 47M tweets from the Twitter streaming\nAPI related to Ebola. Based on hashtags, we propose a method to classify the\ntweets into two sets: credible and speculative. We analyze these two sets and\nstudy how they differ in terms of a number of features extracted from the\nTwitter API. In conclusion, we infer several interesting differences between\nthe two sets. We outline further potential directions to using this material\nfor monitoring and separating speculative tweets from credible ones, to enable\nimproved public health information.", "author": [{"name": "Janani Kalyanam"}, {"name": "Sumithra Velupillai"}, {"name": "Son Doan"}, {"name": "Mike Conway"}, {"name": "Gert Lanckriet"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Appears in SIGKDD BigCHat Workshop 2015"}, "link": [{"@href": "http://arxiv.org/abs/1508.02079v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1508.02079v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.10365v4", "updated": "2020-08-04T20:26:08Z", "published": "2019-06-25T07:47:00Z", "title": "Emotion Cognizance Improves Health Fake News Identification", "summary": "Identifying misinformation is increasingly being recognized as an important\ncomputational task with high potential social impact. Misinformation and fake\ncontents are injected into almost every domain of news including politics,\nhealth, science, business, etc., among which, the fakeness in health domain\npose serious adverse effects to scare or harm the society. Misinformation\ncontains scientific claims or content from social media exaggerated with strong\nemotion content to attract eyeballs. In this paper, we consider the utility of\nthe affective character of news articles for fake news identification in the\nhealth domain and present evidence that emotion cognizant representations are\nsignificantly more suited for the task. We outline a technique to leverage\nemotion intensity lexicons to develop emotionized text representations, and\nevaluate the utility of such a representation for identifying fake news\nrelating to health in various supervised and unsupervised scenarios. The\nconsistent and significant empirical gains that we observe over a range of\ntechnique types and parameter settings establish the utility of the emotional\ninformation in news articles, an often overlooked aspect, for the task of\nmisinformation identification in the health domain.", "author": [{"name": "Anoop K"}, {"name": "Deepak P"}, {"name": "Lajish V L"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Proceedings of 24th International Database Engineering &\n  Applications Symposium (IDEAS 2020), Incheon, Korea"}, "link": [{"@href": "http://arxiv.org/abs/1906.10365v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.10365v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1909.08740v2", "updated": "2019-09-23T14:51:16Z", "published": "2019-09-18T23:53:24Z", "title": "Can WhatsApp Counter Misinformation by Limiting Message Forwarding?", "summary": "WhatsApp is the most popular messaging app in the world. The closed nature of\nthe app, in addition to the ease of transferring multimedia and sharing\ninformation to large-scale groups make WhatsApp unique among other platforms,\nwhere an anonymous encrypted messages can become viral, reaching multiple users\nin a short period of time. The personal feeling and immediacy of messages\ndirectly delivered to the user's phone on WhatsApp was extensively abused to\nspread unfounded rumors and create misinformation campaigns during recent\nelections in Brazil and India. WhatsApp has been deploying measures to mitigate\nthis problem, such as reducing the limit for forwarding a message to at most\nfive users at once. Despite the welcomed effort to counter the problem, there\nis no evidence so far on the real effectiveness of such restrictions. In this\nwork, we propose a methodology to evaluate the effectiveness of such measures\non the spreading of misinformation circulating on WhatsApp. We use an\nepidemiological model and real data gathered from WhatsApp in Brazil, India and\nIndonesia to assess the impact of limiting virality features in this kind of\nnetwork. Our results suggest that the current efforts deployed by WhatsApp can\noffer significant delays on the information spread, but they are ineffective in\nblocking the propagation of misinformation campaigns through public groups when\nthe content has a high viral nature.", "author": [{"name": "Philipe de Freitas Melo"}, {"name": "Carolina Coimbra Vieira"}, {"name": "Kiran Garimella"}, {"name": "Pedro O. S. Vaz de Melo"}, {"name": "Fabr\u00edcio Benevenuto"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages"}, "link": [{"@href": "http://arxiv.org/abs/1909.08740v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.08740v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.05825v1", "updated": "2019-11-13T21:49:17Z", "published": "2019-11-13T21:49:17Z", "title": "Trustworthy Misinformation Mitigation with Soft Information Nudging", "summary": "Research in combating misinformation reports many negative results: facts may\nnot change minds, especially if they come from sources that are not trusted.\nIndividuals can disregard and justify lies told by trusted sources. This\nproblem is made even worse by social recommendation algorithms which help\namplify conspiracy theories and information confirming one's own biases due to\ncompanies' efforts to optimize for clicks and watch time over individuals' own\nvalues and public good. As a result, more nuanced voices and facts are drowned\nout by a continuous erosion of trust in better information sources. Most\nmisinformation mitigation techniques assume that discrediting, filtering, or\ndemoting low veracity information will help news consumers make better\ninformation decisions. However, these negative results indicate that some news\nconsumers, particularly extreme or conspiracy news consumers will not be\nhelped.\n  We argue that, given this background, technology solutions to combating\nmisinformation should not simply seek facts or discredit bad news sources, but\ninstead use more subtle nudges towards better information consumption. Repeated\nexposure to such nudges can help promote trust in better information sources\nand also improve societal outcomes in the long run. In this article, we will\ntalk about technological solutions that can help us in developing such an\napproach, and introduce one such model called Trust Nudging.", "author": [{"name": "Benjamin D. Horne"}, {"name": "Maur\u00edcio Gruppi"}, {"name": "Sibel Adal\u0131"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at IEEE TPS 2019"}, "link": [{"@href": "http://arxiv.org/abs/1911.05825v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.05825v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.04310v2", "updated": "2021-06-03T22:30:14Z", "published": "2020-05-08T22:41:39Z", "title": "Semi-Supervised Multi-aspect Detection of Misinformation using\n  Hierarchical Joint Decomposition", "summary": "Distinguishing between misinformation and real information is one of the most\nchallenging problems in today's interconnected world. The vast majority of the\nstate-of-the-art in detecting misinformation is fully supervised, requiring a\nlarge number of high-quality human annotations. However, the availability of\nsuch annotations cannot be taken for granted, since it is very costly,\ntime-consuming, and challenging to do so in a way that keeps up with the\nproliferation of misinformation. In this work, we are interested in exploring\nscenarios where the number of annotations is limited. In such scenarios, we\ninvestigate how tapping on a diverse number of resources that characterize a\nnews article, henceforth referred to as \"aspects\" can compensate for the lack\nof labels. In particular, our contributions in this paper are twofold: 1) We\npropose the use of three different aspects: article content, context of social\nsharing behaviors, and host website/domain features, and 2) We introduce a\nprincipled tensor based embedding framework that combines all those aspects\neffectively. We propose HiJoD a 2-level decomposition pipeline which not only\noutperforms state-of-the-art methods with F1-scores of 74% and 81% on Twitter\nand Politifact datasets respectively but also is an order of magnitude faster\nthan similar ensemble approaches.", "author": [{"name": "Sara Abdali"}, {"name": "Neil Shah"}, {"name": "Evangelos E. Papalexakis"}], "link": [{"@href": "http://arxiv.org/abs/2005.04310v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.04310v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.08705v1", "updated": "2020-05-15T17:02:19Z", "published": "2020-05-15T17:02:19Z", "title": "Threat from being Social: Vulnerability Analysis of Social Network\n  Coupled Smart Grid", "summary": "Social Networks (SNs) have been gradually applied by utility companies as an\naddition to smart grid and are proved to be helpful in smoothing load curves\nand reducing energy usage. However, SNs also bring in new threats to smart\ngrid: misinformation in SNs may cause smart grid users to alter their demand,\nresulting in transmission line overloading and in turn leading to catastrophic\nimpact to the grid. In this paper, we discuss the interdependency in the social\nnetwork coupled smart grid and focus on its vulnerability. That is, how much\ncan the smart grid be damaged when misinformation related to it diffuses in\nSNs? To analytically study the problem, we propose the Misinformation Attack\nProblem in Social-Smart Grid (MAPSS) that identifies the top critical nodes in\nthe SN, such that the smart grid can be greatly damaged when misinformation\npropagates from those nodes. This problem is challenging as we have to\nincorporate the complexity of the two networks concurrently. Nevertheless, we\npropose a technique that can explicitly take into account information diffusion\nin SN, power flow balance and cascading failure in smart grid integratedly when\nevaluating node criticality, based on which we propose various strategies in\nselecting the most critical nodes. Also, we introduce controlled load shedding\nas a protection strategy to reduce the impact of cascading failure. The\neffectiveness of our algorithms are demonstrated by experiments on IEEE bus\ntest cases as well as the Pegase data set.", "author": [{"name": "Tianyi Pan"}, {"name": "Subhankar Mishra"}, {"name": "Lan N. Nguyen"}, {"name": "Gunhee Lee"}, {"name": "Jungmin Kang"}, {"name": "Jungtaek Seo"}, {"name": "My T. Thai"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/ACCESS.2017.2738565"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/ACCESS.2017.2738565", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2005.08705v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.08705v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "16 pages"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IEEE Access 5 (2017): 16774-16783"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "eess.SY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "eess.SY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.12742v1", "updated": "2020-08-28T16:55:43Z", "published": "2020-08-28T16:55:43Z", "title": "Linked Credibility Reviews for Explainable Misinformation Detection", "summary": "In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task.", "author": [{"name": "Ronald Denaux"}, {"name": "Jose Manuel Gomez-Perez"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the 19th International Semantic Web Conference (ISWC\n  2020) https://iswc2020.semanticweb.org"}, "link": [{"@href": "http://arxiv.org/abs/2008.12742v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.12742v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.07849v2", "updated": "2021-06-03T22:32:32Z", "published": "2021-02-15T21:05:11Z", "title": "Identifying Misinformation from Website Screenshots", "summary": "Can the look and the feel of a website give information about the\ntrustworthiness of an article? In this paper, we propose to use a promising,\nyet neglected aspect in detecting the misinformativeness: the overall look of\nthe domain webpage. To capture this overall look, we take screenshots of news\narticles served by either misinformative or trustworthy web domains and\nleverage a tensor decomposition based semi-supervised classification technique.\nThe proposed approach i.e., VizFake is insensitive to a number of image\ntransformations such as converting the image to grayscale, vectorizing the\nimage and losing some parts of the screenshots. VizFake leverages a very small\namount of known labels, mirroring realistic and practical scenarios, where\nlabels (especially for known misinformative articles), are scarce and quickly\nbecome dated. The F1 score of VizFake on a dataset of 50k screenshots of news\narticles spanning more than 500 domains is roughly 85% using only 5% of ground\ntruth labels. Furthermore, tensor representations of VizFake, obtained in an\nunsupervised manner, allow for exploratory analysis of the data that provides\nvaluable insights into the problem. Finally, we compare VizFake with deep\ntransfer learning, since it is a very popular black-box approach for image\nclassification and also well-known text text-based methods. VizFake achieves\ncompetitive accuracy with deep transfer learning models while being two orders\nof magnitude faster and not requiring laborious hyper-parameter tuning.", "author": [{"name": "Sara Abdali"}, {"name": "Rutuja Gurav"}, {"name": "Siddharth Menon"}, {"name": "Daniel Fonseca"}, {"name": "Negin Entezari"}, {"name": "Neil Shah"}, {"name": "Evangelos E. Papalexakis"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The International AAAI Conference on Web and Social Media (ICWSM)\n  2021"}, "link": [{"@href": "http://arxiv.org/abs/2102.07849v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.07849v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.10864v1", "updated": "2021-04-22T05:09:25Z", "published": "2021-04-22T05:09:25Z", "title": "Misinformation, Believability, and Vaccine Acceptance Over 40 Countries:\n  Takeaways From the Initial Phase of The COVID-19 Infodemic", "summary": "The COVID-19 pandemic has been damaging to the lives of people all around the\nworld. Accompanied by the pandemic is an infodemic, an abundant and\nuncontrolled spreading of potentially harmful misinformation. The infodemic may\nseverely change the pandemic's course by interfering with public health\ninterventions such as wearing masks, social distancing, and vaccination. In\nparticular, the impact of the infodemic on vaccination is critical because it\nholds the key to reverting to pre-pandemic normalcy. This paper presents\nfindings from a global survey on the extent of worldwide exposure to the\nCOVID-19 infodemic, assesses different populations' susceptibility to false\nclaims, and analyzes its association with vaccine acceptance. Based on\nresponses gathered from over 18,400 individuals from 40 countries, we find a\nstrong association between perceived believability of misinformation and\nvaccination hesitancy. Additionally, our study shows that only half of the\nonline users exposed to rumors might have seen the fact-checked information.\nMoreover, depending on the country, between 6% and 37% of individuals\nconsidered these rumors believable. Our survey also shows that poorer regions\nare more susceptible to encountering and believing COVID-19 misinformation. We\ndiscuss implications of our findings on public campaigns that proactively\nspread accurate information to countries that are more susceptible to the\ninfodemic. We also highlight fact-checking platforms' role in better\nidentifying and prioritizing claims that are perceived to be believable and\nhave wide exposure. Our findings give insights into better handling of risk\ncommunication during the initial phase of a future pandemic.", "author": [{"name": "Karandeep Singh"}, {"name": "Gabriel Lima"}, {"name": "Meeyoung Cha"}, {"name": "Chiyoung Cha"}, {"name": "Juhi Kulshrestha"}, {"name": "Yong-Yeol Ahn"}, {"name": "Onur Varol"}], "link": [{"@href": "http://arxiv.org/abs/2104.10864v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.10864v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.09819v1", "updated": "2021-05-20T15:10:48Z", "published": "2021-05-20T15:10:48Z", "title": "Characterizing Abhorrent, Misinformative, and Mistargeted Content on\n  YouTube", "summary": "YouTube has revolutionized the way people discover and consume video.\nAlthough YouTube facilitates easy access to hundreds of well-produced and\ntrustworthy videos, abhorrent, misinformative, and mistargeted content is also\ncommon. The platform is plagued by various types of problematic content: 1)\ndisturbing videos targeting young children; 2) hateful and misogynistic\ncontent; and 3) pseudoscientific misinformation. While YouTube's recommendation\nalgorithm plays a vital role in increasing user engagement and YouTube's\nmonetization, its role in unwittingly promoting problematic content is not\nentirely understood. In this thesis, we shed some light on the degree of\nproblematic content on YouTube and the role of the recommendation algorithm in\nthe dissemination of such content. Following a data-driven quantitative\napproach, we analyze thousands of videos on YouTube, to shed light on: 1) the\nrisks of YouTube media consumption by young children; 2) the role of the\nrecommendation algorithm in the dissemination of misogynistic content, by\nfocusing on the Involuntary Celibates (Incels) community; and 3) user exposure\nto pseudoscientific content on various parts of the platform and how this\nexposure changes based on the user's watch history. Our analysis reveals that\nyoung children are likely to encounter disturbing content when they randomly\nbrowse the platform. By analyzing the Incel community on YouTube, we find that\nIncel activity is increasing over time and that platforms may play an active\nrole in steering users towards extreme content. Finally, when studying\npseudoscientific misinformation, we find that YouTube suggests more\npseudoscientific content regarding traditional pseudoscientific topics (e.g.,\nflat earth) than for emerging ones (like COVID-19) and that these\nrecommendations are more common on the search results page than on a user's\nhomepage or the video recommendations section.", "author": {"name": "Kostantinos Papadamou"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PhD Thesis. Overlaps with arXiv:1901.07046, arXiv:2001.08293,\n  arXiv:2010.11638"}, "link": [{"@href": "http://arxiv.org/abs/2105.09819v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.09819v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.11227v1", "updated": "2021-06-21T16:13:44Z", "published": "2021-06-21T16:13:44Z", "title": "FauxWard: A Graph Neural Network Approach to Fauxtography Detection\n  Using Social Media Comments", "summary": "Online social media has been a popular source for people to consume and share\nnews content. More recently, the spread of misinformation online has caused\nwidespread concerns. In this work, we focus on a critical task of detecting\nfauxtography on social media where the image and associated text together\nconvey misleading information. Many efforts have been made to mitigate\nmisinformation online, but we found that the fauxtography problem has not been\nfully addressed by existing work. Solutions focusing on detecting fake images\nor misinformed texts alone on social media often fail to identify the\nmisinformation delivered together by the image and the associated text of a\nfauxtography post. In this paper, we develop FauxWard, a novel graph\nconvolutional neural network framework that explicitly explores the complex\ninformation extracted from a user comment network of a social media post to\neffectively identify fauxtography. FauxWard is content-free in the sense that\nit does not analyze the visual or textual contents of the post itself, which\nmakes it robust against sophisticated fauxtography uploaders who intentionally\ncraft image-centric posts by editing either the text or image content. We\nevaluate FauxWard on two real-world datasets collected from mainstream social\nmedia platforms (i.e., Reddit and Twitter). The results show that FauxWard is\nboth effective and efficient in identifying fauxtography posts on social media.", "author": [{"name": "Lanyu Shang"}, {"name": "Yang Zhang"}, {"name": "Daniel Zhang"}, {"name": "Dong Wang"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/s13278-020-00689-w"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/s13278-020-00689-w", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2106.11227v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.11227v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Soc. Netw. Anal. Min. 10, 76 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.13687v1", "updated": "2021-08-31T08:55:47Z", "published": "2021-08-31T08:55:47Z", "title": "The coercive logic of fake news", "summary": "The spread of misinformation and \"fake news\" continues to be a major focus of\npublic concern. A great deal of recent research has examined who falls for\nmisinformation and why, and what can be done to make people more discerning\nconsumers of news. Comparatively little work, however, has considered the\nchoices of those who produce misinformation, and how these choices interact\nwith the psychology of news consumers. Here we use game-theoretic models to\nstudy the strategic interaction between news publishers and news readers. We\nshow that publishers who seek to spread misinformation can generate high\nengagement with falsehoods by using strategies that mix true and false stories\nover time, in such a way that they serve more false stories to more loyal\nreaders. These coercive strategies cause false stories to receive higher reader\nengagement than true stories - even when readers strictly prefer truth over\nfalsehood. In contrast, publishers who seek to promote engagement with accurate\ninformation will use strategies that generate more engagement with true stories\nthan with false stories. We confirm these predictions empirically by examining\n1,000 headlines from 20 mainstream and 20 fake news sites, comparing Facebook\nengagement data with 20,000 perceived accuracy ratings collected in a survey\nexperiment. We then use our model to analyze possible ways to disincentivize\nfake news, finding that reducing the capacity of news sources to microtarget\nreaders, and increasing readers' level of attention, reduces the efficacy of\ncoercion. Finally, we show that if a publisher incorrectly assumes that readers\nprefer falsehoods, their resulting publication strategy can manufacture greater\nengagement with false news - leading to a self-reinforcing cycle of false news\npromotion.", "author": [{"name": "Alexander J. Stewart"}, {"name": "Antonio A. Arechar"}, {"name": "David G. Rand"}, {"name": "Joshua B. Plotkin"}], "link": [{"@href": "http://arxiv.org/abs/2108.13687v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.13687v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "econ.TH", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "econ.TH", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1609.09435v1", "updated": "2016-09-29T17:31:44Z", "published": "2016-09-29T17:31:44Z", "title": "On the statistical properties of viral misinformation in online social\n  media", "summary": "The massive diffusion of online social media allows for the rapid and\nuncontrolled spreading of conspiracy theories, hoaxes, unsubstantiated claims,\nand false news. Such an impressive amount of misinformation can influence\npolicy preferences and encourage behaviors strongly divergent from recommended\npractices. In this paper, we study the statistical properties of viral\nmisinformation in online social media. By means of methods belonging to Extreme\nValue Theory, we show that the number of extremely viral posts over time\nfollows a homogeneous Poisson process, and that the interarrival times between\nsuch posts are independent and identically distributed, following an\nexponential distribution. Moreover, we characterize the uncertainty around the\nrate parameter of the Poisson process through Bayesian methods. Finally, we are\nable to derive the predictive posterior probability distribution of the number\nof posts exceeding a certain threshold of shares over a finite interval of\ntime.", "author": {"name": "Alessandro Bessi"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.physa.2016.11.012"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.physa.2016.11.012", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1609.09435v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1609.09435v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1212.0336v1", "updated": "2012-12-03T09:48:02Z", "published": "2012-12-03T09:48:02Z", "title": "Analytical model of misinformation of a social network node", "summary": "This paper presents the research of the influence of cognitive, behavioral,\nrepresentational factors on the susceptibility of the participants in social\nnetworks to misinformation, as well as on the activity of the nodes in this\nregard. The importance of this research consists of method of blocking the\npropaganda. This is very important because when people involuntarily acquire\ninformation some of them experience an undesired change in their social\nattitude. Such phenomena typically lead towards the information warfare. A\nmodel was developed during this research for calculating the level of\nmisinformation of the social network participant (network node) based on the\nmodel of iterative learning process.", "author": [{"name": "Yuri Monakhov"}, {"name": "Maria Medvednikova"}, {"name": "Konstantin Abramov"}, {"name": "Natalia Kostina"}, {"name": "Roman Malyshev"}, {"name": "Makarov Oleg"}, {"name": "Irina Semenova"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "3 pages, 1 figure"}, "link": [{"@href": "http://arxiv.org/abs/1212.0336v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1212.0336v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.1.2; J.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1706.09494v2", "updated": "2017-07-08T13:28:55Z", "published": "2017-06-28T21:54:16Z", "title": "Misinformation spreading on Facebook", "summary": "Social media are pervaded by unsubstantiated or untruthful rumors, that\ncontribute to the alarming phenomenon of misinformation. The widespread\npresence of a heterogeneous mass of information sources may affect the\nmechanisms behind the formation of public opinion. Such a scenario is a florid\nenvironment for digital wildfires when combined with functional illiteracy,\ninformation overload, and confirmation bias. In this essay, we focus on a\ncollection of works aiming at providing quantitative evidence about the\ncognitive determinants behind misinformation and rumor spreading. We account\nfor users' behavior with respect to two distinct narratives: a) conspiracy and\nb) scientific information sources. In particular, we analyze Facebook data on a\ntime span of five years in both the Italian and the US context, and measure\nusers' response to i) information consistent with one's narrative, ii) troll\ncontents, and iii) dissenting information e.g., debunking attempts. Our\nfindings suggest that users tend to a) join polarized communities sharing a\ncommon narrative (echo chambers), b) acquire information confirming their\nbeliefs (confirmation bias) even if containing false claims, and c) ignore\ndissenting information.", "author": [{"name": "Fabiana Zollo"}, {"name": "Walter Quattrociocchi"}], "link": [{"@href": "http://arxiv.org/abs/1706.09494v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1706.09494v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1705.01213v1", "updated": "2017-05-03T01:03:23Z", "published": "2017-05-03T01:03:23Z", "title": "Informative and misinformative interactions in a school of fish", "summary": "It is generally accepted that, when moving in groups, animals process\ninformation to coordinate their motion. Recent studies have begun to apply\nrigorous methods based on Information Theory to quantify such distributed\ncomputation. Following this perspective, we use transfer entropy to quantify\ndynamic information flows locally in space and time across a school of fish\nduring directional changes around a circular tank, i.e. U-turns. This analysis\nreveals peaks in information flows during collective U-turns and identifies two\ndifferent flows: an informative flow (positive transfer entropy) based on fish\nthat have already turned about fish that are turning, and a misinformative flow\n(negative transfer entropy) based on fish that have not turned yet about fish\nthat are turning. We also reveal that the information flows are related to\nrelative position and alignment between fish, and identify spatial patterns of\ninformation and misinformation cascades. This study offers several\nmethodological contributions and we expect further application of these\nmethodologies to reveal intricacies of self-organisation in other animal groups\nand active matter in general.", "author": [{"name": "Emanuele Crosato"}, {"name": "Li Jiang"}, {"name": "Valentin Lecheval"}, {"name": "Joseph T. Lizier"}, {"name": "X. Rosalind Wang"}, {"name": "Pierre Tichit"}, {"name": "Guy Theraulaz"}, {"name": "Mikhail Prokopenko"}], "link": [{"@href": "http://arxiv.org/abs/1705.01213v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1705.01213v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "q-bio.QM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "q-bio.QM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "nlin.AO", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.00557v1", "updated": "2018-09-03T11:27:28Z", "published": "2018-09-03T11:27:28Z", "title": "Fake Cures: User-centric Modeling of Health Misinformation in Social\n  Media", "summary": "Social media's unfettered access has made it an important venue for health\ndiscussion and a resource for patients and their loved ones. However, the\nquality of the information available, as well as the motivations of its\nposters, has been questioned. This work examines the individuals on social\nmedia that are posting questionable health-related information, and in\nparticular promoting cancer treatments which have been shown to be ineffective\n(making it a kind of misinformation, willful or not). Using a multi-stage user\nselection process, we study 4,212 Twitter users who have posted about one of\n139 such \"treatments\", and compare them to a baseline of users generally\ninterested in cancer. Considering features capturing user attributes, writing\nstyle, and sentiment, we build a classifier which is able to identify users\nprone to propagate such misinformation at an accuracy of over 90%, providing a\npotential tool for public health officials to identify such individuals for\npreventive intervention.", "author": [{"name": "Amira Ghenai"}, {"name": "Yelena Mejova"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACM Conference on Computer Supported Cooperative Work and Social\n  Computing (CSCW) 2018"}, "link": [{"@href": "http://arxiv.org/abs/1809.00557v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.00557v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.05521v2", "updated": "2018-11-21T00:22:24Z", "published": "2018-09-14T17:46:58Z", "title": "Defending Elections Against Malicious Spread of Misinformation", "summary": "The integrity of democratic elections depends on voters' access to accurate\ninformation. However, modern media environments, which are dominated by social\nmedia, provide malicious actors with unprecedented ability to manipulate\nelections via misinformation, such as fake news. We study a zero-sum game\nbetween an attacker, who attempts to subvert an election by propagating a fake\nnew story or other misinformation over a set of advertising channels, and a\ndefender who attempts to limit the attacker's impact. Computing an equilibrium\nin this game is challenging as even the pure strategy sets of players are\nexponential. Nevertheless, we give provable polynomial-time approximation\nalgorithms for computing the defender's minimax optimal strategy across a range\nof settings, encompassing different population structures as well as models of\nthe information available to each player. Experimental results confirm that our\nalgorithms provide near-optimal defender strategies and showcase variations in\nthe difficulty of defending elections depending on the resources and knowledge\navailable to the defender.", "author": [{"name": "Bryan Wilder"}, {"name": "Yevgeniy Vorobeychik"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Full version of paper accepted to AAAI 2019"}, "link": [{"@href": "http://arxiv.org/abs/1809.05521v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.05521v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1907.00435v2", "updated": "2019-09-13T18:04:08Z", "published": "2019-06-30T19:14:17Z", "title": "YouTube Chatter: Understanding Online Comments Discourse on\n  Misinformative and Political YouTube Videos", "summary": "We conduct a preliminary analysis of comments on political YouTube content\ncontaining misinformation in comparison to comments on trustworthy or\napolitical videos, labelling the bias and factual ratings of our channels\naccording to Media Bias Fact Check where applicable. One of our most\ninteresting discoveries is that especially-polarized or misinformative\npolitical channels (Left-Bias, Right-Bias, PragerU, Conspiracy-Pseudoscience,\nand Questionable Source) generate 7.5x more comments per view and 10.42x more\nreplies per view than apolitical or Pro-Science channels; in particular,\nConspiracy-Pseudoscience and Questionable Sources generate 8.3x more comments\nper view and 11.0x more replies per view than apolitical and Pro-Science\nchannels. We also compared average thread lengths, average comment lengths, and\nprofanity rates across channels, and present simple machine learning\nclassifiers for predicting the bias category of a video based on these\nstatistics.", "author": [{"name": "Aarash Heydari"}, {"name": "Janny Zhang"}, {"name": "Shaan Appel"}, {"name": "Xinyi Wu"}, {"name": "Gireeja Ranade"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "32 pages, 23 figures. Primary contributors: Aarash Heydari and Janny\n  Zhang. These authors contributed equally to the work"}, "link": [{"@href": "http://arxiv.org/abs/1907.00435v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.00435v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1909.03654v1", "updated": "2019-09-09T06:45:07Z", "published": "2019-09-09T06:45:07Z", "title": "The Future of Misinformation Detection: New Perspectives and Trends", "summary": "The massive spread of misinformation in social networks has become a global\nrisk, implicitly influencing public opinion and threatening social/political\ndevelopment. Misinformation detection (MID) has thus become a surging research\ntopic in recent years. As a promising and rapid developing research field, we\nfind that many efforts have been paid to new research problems and approaches\nof MID. Therefore, it is necessary to give a comprehensive review of the new\nresearch trends of MID. We first give a brief review of the literature history\nof MID, based on which we present several new research challenges and\ntechniques of it, including early detection, detection by multimodal data\nfusion, and explanatory detection. We further investigate the extraction and\nusage of various crowd intelligence in MID, which paves a promising way to\ntackle MID challenges. Finally, we give our own views on the open issues and\nfuture research directions of MID, such as model adaptivity/generality to new\nevents, embracing of novel machine learning models, explanatory detection\nmodels, and so on.", "author": [{"name": "Bin Guo"}, {"name": "Yasan Ding"}, {"name": "Lina Yao"}, {"name": "Yunji Liang"}, {"name": "Zhiwen Yu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted to ACM Computing Surveys"}, "link": [{"@href": "http://arxiv.org/abs/1909.03654v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.03654v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.11920v1", "updated": "2019-11-27T02:33:24Z", "published": "2019-11-27T02:33:24Z", "title": "Warning Signs in Communicating the Machine Learning Detection Results of\n  Misinformation with Individuals", "summary": "With the prevalence of misinformation online, researchers have focused on\ndeveloping various machine learning algorithms to detect fake news. However,\nusers' perception of machine learning outcomes and related behaviors have been\nwidely ignored. Hence, this paper proposed to bridge this gap by studying how\nto pass the detection results of machine learning to the users, and aid their\ndecisions in handling misinformation. An online experiment was conducted, to\nevaluate the effect of the proposed machine learning warning sign against a\ncontrol condition. We examined participants' detection and sharing of news. The\ndata showed that warning sign's effects on participants' trust toward the fake\nnews were not significant. However, we found that people's uncertainty about\nthe authenticity of the news dropped with the presence of the machine learning\nwarning sign. We also found that social media experience had effects on users'\ntrust toward the fake news, and age and social media experience had effects on\nusers' sharing decision. Therefore, the results indicate that there are many\nfactors worth studying that affect people's trust in the news. Moreover, the\nwarning sign in communicating machine learning detection results is different\nfrom ordinary warnings and needs more detailed research and design. These\nfindings hold important implications for the design of machine learning\nwarnings.", "author": {"name": "Limeng Cui"}, "link": [{"@href": "http://arxiv.org/abs/1911.11920v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.11920v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.5.2", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.04494v2", "updated": "2020-02-16T14:23:28Z", "published": "2020-02-11T15:49:32Z", "title": "The Rumour Mill: Making the Spread of Misinformation Explicit and\n  Tangible", "summary": "Misinformation spread presents a technological and social threat to society.\nWith the advance of AI-based language models, automatically generated texts\nhave become difficult to identify and easy to create at scale. We present \"The\nRumour Mill\", a playful art piece, designed as a commentary on the spread of\nrumours and automatically-generated misinformation. The mill is a tabletop\ninteractive machine, which invites a user to experience the process of creating\nbelievable text by interacting with different tangible controls on the mill.\nThe user manipulates visible parameters to adjust the genre and type of an\nautomatically generated text rumour. The Rumour Mill is a physical\ndemonstration of the state of current technology and its ability to generate\nand manipulate natural language text, and of the act of starting and spreading\nrumours.", "author": [{"name": "Nanna Inie"}, {"name": "Jeanette Falk Olesen"}, {"name": "Leon Derczynski"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3334480.3383159"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3334480.3383159", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2002.04494v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.04494v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to CHI 2020 Interactivity"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.09600v1", "updated": "2020-04-20T19:56:48Z", "published": "2020-04-20T19:56:48Z", "title": "Why do People Share Misinformation during the COVID-19 Pandemic?", "summary": "The World Health Organization have emphasised that misinformation - spreading\nrapidly through social media - poses a serious threat to the COVID-19 response.\nDrawing from theories of health perception and cognitive load, we develop and\ntest a research model hypothesizing why people share unverified COVID-19\ninformation through social media. Our findings suggest a person's trust in\nonline information and perceived information overload are strong predictors of\nunverified information sharing. Furthermore, these factors, along with a\nperson's perceived COVID-19 severity and vulnerability influence cyberchondria.\nFemales were significantly more likely to suffer from cyberchondria, however,\nmales were more likely to share news without fact checking their source. Our\nfindings suggest that to mitigate the spread of COVID-19 misinformation and\ncyberchondria, measures should be taken to enhance a healthy skepticism of\nhealth news while simultaneously guarding against information overload.", "author": [{"name": "Samuli Laato"}, {"name": "A. K. M. Najmul Islam"}, {"name": "Muhammad Nazrul Islam"}, {"name": "Eoin Whelan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1080/0960085X.2020.1770632"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1080/0960085X.2020.1770632", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.09600v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.09600v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "European Journal of Information Systems (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.03159v1", "updated": "2020-10-07T04:55:34Z", "published": "2020-10-07T04:55:34Z", "title": "Where Are the Facts? Searching for Fact-checked Information to Alleviate\n  the Spread of Fake News", "summary": "Although many fact-checking systems have been developed in academia and\nindustry, fake news is still proliferating on social media. These systems\nmostly focus on fact-checking but usually neglect online users who are the main\ndrivers of the spread of misinformation. How can we use fact-checked\ninformation to improve users' consciousness of fake news to which they are\nexposed? How can we stop users from spreading fake news? To tackle these\nquestions, we propose a novel framework to search for fact-checking articles,\nwhich address the content of an original tweet (that may contain\nmisinformation) posted by online users. The search can directly warn fake news\nposters and online users (e.g. the posters' followers) about misinformation,\ndiscourage them from spreading fake news, and scale up verified content on\nsocial media. Our framework uses both text and images to search for\nfact-checking articles, and achieves promising results on real-world datasets.\nOur code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Full paper, EMNLP 2020"}, "link": [{"@href": "http://arxiv.org/abs/2010.03159v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.03159v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.06019v2", "updated": "2020-10-14T15:50:22Z", "published": "2020-10-12T20:43:41Z", "title": "Probabilistic Social Learning Improves the Public's Detection of\n  Misinformation", "summary": "The digital spread of misinformation is one of the leading threats to\ndemocracy, public health, and the global economy. Popular strategies for\nmitigating misinformation include crowdsourcing, machine learning, and media\nliteracy programs that require social media users to classify news in binary\nterms as either true or false. However, research on peer influence suggests\nthat framing decisions in binary terms can amplify judgment errors and limit\nsocial learning, whereas framing decisions in probabilistic terms can reliably\nimprove judgments. In this preregistered experiment, we compare online peer\nnetworks that collaboratively evaluate the veracity of news by communicating\neither binary or probabilistic judgments. Exchanging probabilistic estimates of\nnews veracity substantially improved individual and group judgments, with the\neffect of eliminating polarization in news evaluation. By contrast, exchanging\nbinary classifications reduced social learning and entrenched polarization. The\nbenefits of probabilistic social learning are robust to participants'\neducation, gender, race, income, religion, and partisanship.", "author": [{"name": "Douglas Guilbeault"}, {"name": "Samuel Woolley"}, {"name": "Joshua Becker"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0247487"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0247487", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2010.06019v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.06019v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 4 figures"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.09029v2", "updated": "2021-06-13T02:17:47Z", "published": "2020-10-18T16:52:27Z", "title": "CHECKED: Chinese COVID-19 Fake News Dataset", "summary": "COVID-19 has impacted all lives. To maintain social distancing and avoiding\nexposure, works and lives have gradually moved online. Under this trend, social\nmedia usage to obtain COVID-19 news has increased. Also, misinformation on\nCOVID-19 is frequently spread on social media. In this work, we develop\nCHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides\na total 2,104 verified microblogs related to COVID-19 from December 2019 to\nAugust 2020, identified by using a specific list of keywords. Correspondingly,\nCHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes\nthat reveal how these verified microblogs are spread and reacted on Weibo. The\ndataset contains a rich set of multimedia information for each microblog\nincluding ground-truth label, textual, visual, temporal, and network\ninformation. Extensive experiments have been conducted to analyze CHECKED data\nand to provide benchmark results for well-established methods when predicting\nfake news using CHECKED. We hope that CHECKED can facilitate studies that\ntarget misinformation on coronavirus. The dataset is available at\nhttps://github.com/cyang03/CHECKED.", "author": [{"name": "Chen Yang"}, {"name": "Xinyi Zhou"}, {"name": "Reza Zafarani"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to Social Network Analysis and Mining (SNAM)"}, "link": [{"@href": "http://arxiv.org/abs/2010.09029v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.09029v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.13387v2", "updated": "2021-07-10T06:08:44Z", "published": "2020-10-26T07:33:28Z", "title": "Check Mate: Prioritizing User Generated Multi-Media Content for\n  Fact-Checking", "summary": "Volume of content and misinformation on social media is rapidly increasing.\nThere is a need for systems that can support fact checkers by prioritizing\ncontent that needs to be fact checked. Prior research on prioritizing content\nfor fact-checking has focused on news media articles, predominantly in English\nlanguage. Increasingly, misinformation is found in user-generated content. In\nthis paper we present a novel dataset that can be used to prioritize\ncheck-worthy posts from multi-media content in Hindi. It is unique in its 1)\nfocus on user generated content, 2) language and 3) accommodation of\nmulti-modality in social media posts. In addition, we also provide metadata for\neach post such as number of shares and likes of the post on ShareChat, a\npopular Indian social media platform, that allows for correlative analysis\naround virality and misinformation. The data is accessible on Zenodo\n(https://zenodo.org/record/4032629) under Creative Commons Attribution License\n(CC BY 4.0).", "author": [{"name": "Tarunima Prabhakar"}, {"name": "Anushree Gupta"}, {"name": "Kruttika Nadig"}, {"name": "Denny George"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 13 figures, 2 tables"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the International AAAI Conference on Web and Social\n  Media, Volume 15(1), 2021"}, "link": [{"@href": "http://arxiv.org/abs/2010.13387v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.13387v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.14146v2", "updated": "2021-02-15T02:26:25Z", "published": "2020-11-28T15:30:14Z", "title": "Towards Combating Pandemic-related Misinformation in Social Media", "summary": "Conventional preventive measures during pandemic include social distancing\nand lockdown. Such measures in the time of social media brought about a new set\nof challenges - vulnerability to the toxic impact of online misinformation is\nhigh. A case in point is the prevailing COVID-19; as the virus propagates, so\ndoes the associated misinformation and fake news about it leading to infodemic.\nSince the outbreak, there has been a surge of studies investigating various\naspects of the pandemic. Of interest to this chapter include studies centring\non datasets from online social media platforms where the bulk of the public\ndiscourse happen. Consequently, the main goal is to support the fight against\nnegative infodemic by (1) contributing a diverse set of curated relevant\ndatasets (2) recommending relevant areas to study using the datasets (3)\ndiscussion on how relevant datasets, strategies and state-of-the-art IT tools\ncan be leveraged in managing the pandemic.", "author": {"name": "Isa Inuwa-Dutse"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages, 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/2011.14146v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.14146v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.09536v1", "updated": "2020-12-17T12:17:55Z", "published": "2020-12-17T12:17:55Z", "title": "Conspiracy Machines -- The Role of Social Bots during the COVID-19\n  Infodemic", "summary": "The omnipresent COVID-19 pandemic gave rise to a parallel spreading of\nmisinformation, also referred to as an Infodemic. Consequently, social media\nhave become targets for the application of social bots, that is, algorithms\nthat mimic human behaviour. Their ability to exert influence on social media\ncan be exploited by amplifying misinformation, rumours, or conspiracy theories\nwhich might be harmful to society and the mastery of the pandemic. By applying\nsocial bot detection and content analysis techniques, this study aims to\ndetermine the extent to which social bots interfere with COVID- 19 discussions\non Twitter. A total of 78 presumptive bots were detected within a sample of\n542,345 users. The analysis revealed that bot-like users who disseminate\nmisinformation, at the same time, intersperse news from renowned sources. The\nfindings of this research provide implications for improved bot detection and\nmanaging potential threats through social bots during ongoing and future\ncrises.", "author": [{"name": "Julian Marx"}, {"name": "Felix Br\u00fcnker"}, {"name": "Milad Mirbabaie"}, {"name": "Eric Hochstrate"}], "link": [{"@href": "http://arxiv.org/abs/2012.09536v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.09536v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.04217v1", "updated": "2021-01-20T05:30:14Z", "published": "2021-01-20T05:30:14Z", "title": "The Fault in the Stars: Understanding the Underground Market of Amazon\n  Reviews", "summary": "In recent times, the Internet has been plagued by a tremendous amount of\nmisinformation. Online markets such as Amazon are also not free from\nmisinformation. In this work, we study the misinformation propagated to\nconsumers through the form of Amazon reviews. There exists a vast underground\nmarket where reviews by real Amazon users are purchased and sold. While such a\npractice violates Amazon's terms of service, we observe that there exists a\ncomplex network consisting of thousands of sellers and agents, who provide a\nrebate to consumers for leaving positive reviews to over $5000$ products. Based\non interviews with members involved in the reviews market, we understand the\nworking of this market, and the tactics used to avoid detection by Amazon. We\nalso present a set of recommendations of features that Amazon and similar\nonline markets can take into consideration to detect such reviews.", "author": {"name": "Rajvardhan Oak"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a work in progress!"}, "link": [{"@href": "http://arxiv.org/abs/2102.04217v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.04217v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "K.4.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.04077v1", "updated": "2021-04-01T22:37:34Z", "published": "2021-04-01T22:37:34Z", "title": "Two Truths and a Lie: Exploring Soft Moderation of COVID-19\n  Misinformation with Amazon Alexa", "summary": "In this paper, we analyzed the perceived accuracy of COVID-19 vaccine Tweets\nwhen they were spoken back by a third-party Amazon Alexa skill. We mimicked the\nsoft moderation that Twitter applies to COVID-19 misinformation content in both\nforms of warning covers and warning tags to investigate whether the third-party\nskill could affect how and when users heed these warnings. The results from a\n304-participant study suggest that the spoken back warning covers may not work\nas intended, even when converted from text to speech. We controlled for\nCOVID-19 vaccination hesitancy and political leanings and found that the\nvaccination hesitant Alexa users ignored any type of warning as long as the\nTweets align with their personal beliefs. The politically independent users\ntrusted Alexa less then their politically-laden counterparts and that helped\nthem accurately perceiving truthful COVID-19 information. We discuss soft\nmoderation adaptations for voice assistants to achieve the intended effect of\ncurbing COVID-19 misinformation.", "author": [{"name": "Donald Gover"}, {"name": "Filipo Sharevski"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: text overlap with arXiv:2104.00779"}, "link": [{"@href": "http://arxiv.org/abs/2104.04077v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.04077v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.07435v1", "updated": "2021-06-14T13:56:26Z", "published": "2021-06-14T13:56:26Z", "title": "Both Rates of Fake News and Fact-based News on Twitter Negatively\n  Correlate with the State-level COVID-19 Vaccine Uptake", "summary": "There is evidence of misinformation in the online discourses and discussions\nabout the COVID-19 vaccines. Using a sample of 1.6 million geotagged English\ntweets and the data from the CDC COVID Data Tracker, we conduct a quantitative\nstudy to understand the influence of both misinformation and fact-based news on\nTwitter on the COVID-19 vaccine uptake in the U.S. from April 19 when U.S.\nadults were vaccine eligible to May 7, 2021, after controlling state-level\nfactors such as demographics, education, and the pandemic severity. We identify\nthe tweets related to either misinformation or fact-based news by analyzing the\nURLs. By analyzing the content of the most frequent tweets of these two groups,\nwe find that their structures are similar, making it difficult for Twitter\nusers to distinguish one from another by reading the text alone. The users who\nspread both fake news and fact-based news tend to show a negative attitude\ntowards the vaccines. We further conduct the Fama-MacBeth regression with the\nNewey-West adjustment to examine the effect of fake-news-related and\nfact-related tweets on the vaccination rate, and find marginally negative\ncorrelations.", "author": [{"name": "Hanjia Lyu"}, {"name": "Zihe Zheng"}, {"name": "Jiebo Luo"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages"}, "link": [{"@href": "http://arxiv.org/abs/2106.07435v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.07435v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.02775v1", "updated": "2021-07-06T17:37:56Z", "published": "2021-07-06T17:37:56Z", "title": "Countering Misinformation on Social Media Through Educational\n  Interventions: Evidence from a Randomized Experiment in Pakistan", "summary": "Fake news is a growing problem in developing countries with potentially\nfar-reaching consequences. We conduct a randomized experiment in urban Pakistan\nto evaluate the effectiveness of two educational interventions to counter\nmisinformation among low-digital literacy populations. We do not find a\nsignificant effect of video-based general educational messages about\nmisinformation. However, when such messages are augmented with personalized\nfeedback based on individuals' past engagement with fake news, we find an\nimprovement of 0.14 standard deviations in identifying fake news. We also find\nnegative but insignificant effects on identifying true news, driven by female\nrespondents. Our results suggest that educational interventions can enable\ninformation discernment but their effectiveness critically depends on how well\ntheir features and delivery are customized for the population of interest.", "author": [{"name": "Ayesha Ali"}, {"name": "Ihsan Ayyub Qazi"}], "link": [{"@href": "http://arxiv.org/abs/2107.02775v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.02775v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.07074v3", "updated": "2020-10-30T15:49:04Z", "published": "2020-03-16T08:51:40Z", "title": "A Machine Learning Application for Raising WASH Awareness in the Times\n  of COVID-19 Pandemic", "summary": "Background: The COVID-19 pandemic has uncovered the potential of digital\nmisinformation in shaping the health of nations. The deluge of unverified\ninformation that spreads faster than the epidemic itself is an unprecedented\nphenomenon that has put millions of lives in danger. Mitigating this Infodemic\nrequires strong health messaging systems that are engaging, vernacular,\nscalable, effective and continuously learn the new patterns of misinformation.\n  Objective: We created WashKaro, a multi-pronged intervention for mitigating\nmisinformation through conversational AI, machine translation and natural\nlanguage processing. WashKaro provides the right information matched against\nWHO guidelines through AI, and delivers it in the right format in local\nlanguages.\n  Methods: We theorize (i) an NLP based AI engine that could continuously\nincorporate user feedback to improve relevance of information, (ii) bite sized\naudio in the local language to improve penetrance in a country with skewed\ngender literacy ratios, and (iii) conversational but interactive AI engagement\nwith users towards an increased health awareness in the community. Results: A\ntotal of 5026 people who downloaded the app during the study window, among\nthose 1545 were active users. Our study shows that 3.4 times more females\nengaged with the App in Hindi as compared to males, the relevance of\nAI-filtered news content doubled within 45 days of continuous machine learning,\nand the prudence of integrated AI chatbot Satya increased thus proving the\nusefulness of an mHealth platform to mitigate health misinformation.\n  Conclusion: We conclude that a multi-pronged machine learning application\ndelivering vernacular bite-sized audios and conversational AI is an effective\napproach to mitigate health misinformation.", "author": [{"name": "Rohan Pandey"}, {"name": "Vaibhav Gautam"}, {"name": "Ridam Pal"}, {"name": "Harsh Bandhey"}, {"name": "Lovedeep Singh Dhingra"}, {"name": "Himanshu Sharma"}, {"name": "Chirag Jain"}, {"name": "Kanav Bhagat"}, {"name": "Arushi"}, {"name": "Lajjaben Patel"}, {"name": "Mudit Agarwal"}, {"name": "Samprati Agrawal"}, {"name": "Rishabh Jalan"}, {"name": "Akshat Wadhwa"}, {"name": "Ayush Garg"}, {"name": "Vihaan Misra"}, {"name": "Yashwin Agrawal"}, {"name": "Bhavika Rana"}, {"name": "Ponnurangam Kumaraguru"}, {"name": "Tavpritesh Sethi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "14 pages, 7 figures"}, "link": [{"@href": "http://arxiv.org/abs/2003.07074v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.07074v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1802.06887v1", "updated": "2018-01-23T17:50:37Z", "published": "2018-01-23T17:50:37Z", "title": "A Multiclass Mean-Field Game for Thwarting Misinformation Spread in the\n  Internet of Battlefield Things (IoBT)", "summary": "In this paper, the problem of misinformation propagation is studied for an\nInternet of Battlefield Things (IoBT) system in which an attacker seeks to\ninject false information in the IoBT nodes in order to compromise the IoBT\noperations. In the considered model, each IoBT node seeks to counter the\nmisinformation attack by finding the optimal probability of accepting a given\ninformation that minimizes its cost at each time instant. The cost is expressed\nin terms of the quality of information received as well as the infection cost.\nThe problem is formulated as a mean-field game with multiclass agents which is\nsuitable to model a massive heterogeneous IoBT system. For this game, the\nmean-field equilibrium is characterized, and an algorithm based on the forward\nbackward sweep method is proposed to find the mean-field equilibrium. Then, the\nfinite IoBT case is considered, and the conditions of convergence of the Nash\nequilibria in the finite case to the mean-field equilibrium are presented.\nNumerical results show that the proposed scheme can achieve a 1.2-fold increase\nin the quality of information (QoI) compared to a baseline scheme in which the\nIoBT nodes are always transmitting. The results also show that the proposed\nscheme can reduce the proportion of infected nodes by 99% compared to the\nbaseline.", "author": [{"name": "Nof Abuzainab"}, {"name": "Walid Saad"}], "link": [{"@href": "http://arxiv.org/abs/1802.06887v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1802.06887v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1411.2893v1", "updated": "2014-11-11T17:34:13Z", "published": "2014-11-11T17:34:13Z", "title": "Viral Misinformation: The Role of Homophily and Polarization", "summary": "The spreading of unsubstantiated rumors on online social networks (OSN)\neither unintentionally or intentionally (e.g., for political reasons or even\ntrolling) can have serious consequences such as in the recent case of rumors\nabout Ebola causing disruption to health-care workers. Here we show that\nindicators aimed at quantifying information consumption patterns might provide\nimportant insights about the virality of false claims. In particular, we\naddress the driving forces behind the popularity of contents by analyzing a\nsample of 1.2M Facebook Italian users consuming different (and opposite) types\nof information (science and conspiracy news). We show that users' engagement\nacross different contents correlates with the number of friends having similar\nconsumption patterns (homophily), indicating the area in the social network\nwhere certain types of contents are more likely to spread. Then, we test\ndiffusion patterns on an external sample of $4,709$ intentional satirical false\nclaims showing that neither the presence of hubs (structural properties) nor\nthe most active users (influencers) are prevalent in viral phenomena. Instead,\nwe found out that in an environment where misinformation is pervasive, users'\naggregation around shared beliefs may make the usual exposure to conspiracy\nstories (polarization) a determinant for the virality of false information.", "author": [{"name": "Aris Anagnostopoulos"}, {"name": "Alessandro Bessi"}, {"name": "Guido Caldarelli"}, {"name": "Michela Del Vicario"}, {"name": "Fabio Petroni"}, {"name": "Antonio Scala"}, {"name": "Fabiana Zollo"}, {"name": "Walter Quattrociocchi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Misinformation, Virality, Attention Patterns"}, "link": [{"@href": "http://arxiv.org/abs/1411.2893v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1411.2893v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1707.07592v4", "updated": "2018-05-24T23:18:12Z", "published": "2017-07-24T14:53:36Z", "title": "The spread of low-credibility content by social bots", "summary": "The massive spread of digital misinformation has been identified as a major\nglobal risk and has been alleged to influence elections and threaten\ndemocracies. Communication, cognitive, social, and computer scientists are\nengaged in efforts to study the complex causes for the viral diffusion of\nmisinformation online and to develop solutions, while search and social media\nplatforms are beginning to deploy countermeasures. With few exceptions, these\nefforts have been mainly informed by anecdotal evidence rather than systematic\ndata. Here we analyze 14 million messages spreading 400 thousand articles on\nTwitter during and following the 2016 U.S. presidential campaign and election.\nWe find evidence that social bots played a disproportionate role in amplifying\nlow-credibility content. Accounts that actively spread articles from\nlow-credibility sources are significantly more likely to be bots. Automated\naccounts are particularly active in amplifying content in the very early\nspreading moments, before an article goes viral. Bots also target users with\nmany followers through replies and mentions. Humans are vulnerable to this\nmanipulation, retweeting bots who post links to low-credibility content.\nSuccessful low-credibility sources are heavily supported by social bots. These\nresults suggest that curbing social bots may be an effective strategy for\nmitigating the spread of online misinformation.", "author": [{"name": "Chengcheng Shao"}, {"name": "Giovanni Luca Ciampaglia"}, {"name": "Onur Varol"}, {"name": "Kaicheng Yang"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1038/s41467-018-06930-7"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1038/s41467-018-06930-7", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1707.07592v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1707.07592v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "41 pages, 20 figures, 3 tables"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Nature Communications, 9: 4787, 2018"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.00742v2", "updated": "2020-11-19T00:01:44Z", "published": "2020-04-01T23:44:58Z", "title": "#ArsonEmergency and Australia's \"Black Summer\": Polarisation and\n  misinformation on social media", "summary": "During the summer of 2019-20, while Australia suffered unprecedented\nbushfires across the country, false narratives regarding arson and limited\nbackburning spread quickly on Twitter, particularly using the hashtag\n#ArsonEmergency. Misinformation and bot- and troll-like behaviour were detected\nand reported by social media researchers and the news soon reached mainstream\nmedia. This paper examines the communication and behaviour of two polarised\nonline communities before and after news of the misinformation became public\nknowledge. Specifically, the Supporter community actively engaged with others\nto spread the hashtag, using a variety of news sources pushing the arson\nnarrative, while the Opposer community engaged less, retweeted more, and\nfocused its use of URLs to link to mainstream sources, debunking the narratives\nand exposing the anomalous behaviour. This influenced the content of the\nbroader discussion. Bot analysis revealed the active accounts were\npredominantly human, but behavioural and content analysis suggests Supporters\nengaged in trolling, though both communities used aggressive language.", "author": [{"name": "Derek Weber"}, {"name": "Mehwish Nasim"}, {"name": "Lucia Falzon"}, {"name": "Lewis Mitchell"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-61841-4_11"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-61841-4_11", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.00742v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.00742v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "16 pages, 8 images, presented at the 2nd Multidisciplinary\n  International Symposium on Disinformation in Open Online Media (MISDOOM\n  2020), Leiden, The Netherlands. Published in: van Duijn M., Preuss M.,\n  Spaiser V., Takes F., Verberne S. (eds) Disinformation in Open Online Media.\n  MISDOOM 2020. Lecture Notes in Computer Science, vol 12259. Springer, Cham.\n  https://doi.org/10.1007/978-3-030-61841-4_11"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2007.05848v1", "updated": "2020-07-11T20:37:14Z", "published": "2020-07-11T20:37:14Z", "title": "Fighting Disaster Misinformation in Latin America: The #19S Mexican\n  Earthquake Case Study", "summary": "Social media platforms have been extensively used during natural disasters.\nHowever, most prior work has lacked focus on studying their usage during\ndisasters in the Global South, where Internet access and social media\nutilization differs from developing countries. In this paper, we study how\nsocial media was used in the aftermath of the 7.1-magnitude earthquake that hit\nMexico on September 19 of 2017 (known as the #19S earthquake). We conduct an\nanalysis of how participants utilized social media platforms in the #19S\naftermath. Our research extends investigations of crisis informatics by: 1)\nexamining how participants used different social media platforms in the\naftermath of a natural disaster in a Global South country; 2) uncovering how\nindividuals developed their own processes to verify news reports using an\non-the-ground citizen approach; 3) revealing how people developed their own\nmechanisms to deal with outdated information. For this, we surveyed 356 people.\nAdditionally, we analyze one month of activity from: Facebook (12,606 posts),\nTwitter (2,909,109 tweets), Slack (28,782 messages), and GitHub (2,602\ncommits). This work offers a multi-platform view on user behavior to coordinate\nrelief efforts, reduce the spread of misinformation and deal with obsolete\ninformation which seems to have been essential to help in the coordination and\nefficiency of relief efforts. Finally, based on our findings, we make\nrecommendations for technology design to improve the effectiveness of social\nmedia use during crisis response efforts and mitigate the spread of\nmisinformation across social media platforms.", "author": [{"name": "Claudia Flores-Saviaga"}, {"name": "Saiph Savage"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/s00779-020-01411-5"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/s00779-020-01411-5", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.05848v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.05848v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Springer - Personal and Ubiquitous Computing 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.09682v3", "updated": "2021-03-26T18:35:43Z", "published": "2020-07-19T14:52:34Z", "title": "Twitter and Facebook posts about COVID-19 are less likely to spread\n  false and low-credibility content compared to other health topics", "summary": "On February 2, 2020, the World Health Organization declared a COVID-19 social\nmedia \"infodemic\", with special attention to misinformation -- frequently\nunderstood as false claims. To understand the infodemic's scope and scale, we\nanalyzed over 500 million posts from Twitter and Facebook about COVID-19 and\nother health topics, between March 8 and May 1, 2020. Following prior work, we\nassumed URL source credibility is a proxy for false content, but we also tested\nthis assumption. Contrary to expectations, we found that messages about\nCOVID-19 were more likely to contain links to more credible sources.\nAdditionally, messages linking to government sources, and to news with\nintermediate credibility, were shared more often, on average, than links to\nnon-credible sources. These results suggest that more ambiguous forms of\nmisinformation about COVID-19 may be more likely to be disseminated through\ncredible sources when compared to other health topics. Furthermore, the\nassumption that credibility is an adequate proxy for false content may\noverestimate the prevalence of false content online: less than 25% of posts\nlinking to the least credible sources contained false content. Our results\nemphasize the importance of distinguishing between explicit falsehoods and more\nambiguous forms of misinformation due to the search for meaning in an\nenvironment of scientific uncertainty.", "author": [{"name": "David A. Broniatowski"}, {"name": "Daniel Kerchner"}, {"name": "Fouzia Farooq"}, {"name": "Xiaolei Huang"}, {"name": "Amelia M. Jamison"}, {"name": "Mark Dredze"}, {"name": "Sandra Crouse Quinn"}], "link": [{"@href": "http://arxiv.org/abs/2007.09682v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.09682v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.09703v1", "updated": "2020-07-19T16:14:58Z", "published": "2020-07-19T16:14:58Z", "title": "A curated collection of COVID-19 online datasets", "summary": "One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data.", "author": [{"name": "Isa Inuwa-Dutse"}, {"name": "Ioannis Korkontzelos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 7 figures"}, "link": [{"@href": "http://arxiv.org/abs/2007.09703v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.09703v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.07647v2", "updated": "2021-07-06T09:16:25Z", "published": "2020-10-15T10:31:28Z", "title": "Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised\n  Learning Approach", "summary": "Online Social Media (OSM) platforms such as Twitter, Facebook are extensively\nexploited by the users of these platforms for spreading the (mis)information to\na large audience effortlessly at a rapid pace. It has been observed that the\nmisinformation can cause panic, fear, and financial loss to society. Thus, it\nis important to detect and control the misinformation in such platforms before\nit spreads to the masses. In this work, we focus on rumors, which is one type\nof misinformation (other types are fake news, hoaxes, etc). One way to control\nthe spread of the rumors is by identifying users who are possibly the rumor\nspreaders, that is, users who are often involved in spreading the rumors. Due\nto the lack of availability of rumor spreaders labeled dataset (which is an\nexpensive task), we use publicly available PHEME dataset, which contains rumor\nand non-rumor tweets information, and then apply a weak supervised learning\napproach to transform the PHEME dataset into rumor spreaders dataset. We\nutilize three types of features, that is, user, text, and ego-network features,\nbefore applying various supervised learning approaches. In particular, to\nexploit the inherent network property in this dataset (user-user reply graph),\nwe explore Graph Convolutional Network (GCN), a type of Graph Neural Network\n(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and\nLSTM. Extensive experiments performed on the rumor spreaders dataset, where we\nachieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the\neffectiveness of our methodology for identifying possible rumor spreaders using\nthe GCN technique.", "author": [{"name": "Shakshi Sharma"}, {"name": "Rajesh Sharma"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at The International Joint Conference on Neural Networks\n  2021 (IJCNN2021). Please cite the IJCNN version"}, "link": [{"@href": "http://arxiv.org/abs/2010.07647v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.07647v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.05416v1", "updated": "2020-11-09T04:15:44Z", "published": "2020-11-09T04:15:44Z", "title": "Challenges and Opportunities in Rapid Epidemic Information Propagation\n  with Live Knowledge Aggregation from Social Media", "summary": "A rapidly evolving situation such as the COVID-19 pandemic is a significant\nchallenge for AI/ML models because of its unpredictability. %The most reliable\nindicator of the pandemic spreading has been the number of test positive cases.\nHowever, the tests are both incomplete (due to untested asymptomatic cases) and\nlate (due the lag from the initial contact event, worsening symptoms, and test\nresults). Social media can complement physical test data due to faster and\nhigher coverage, but they present a different challenge: significant amounts of\nnoise, misinformation and disinformation. We believe that social media can\nbecome good indicators of pandemic, provided two conditions are met. The first\n(True Novelty) is the capture of new, previously unknown, information from\nunpredictably evolving situations. The second (Fact vs. Fiction) is the\ndistinction of verifiable facts from misinformation and disinformation. Social\nmedia information that satisfy those two conditions are called live knowledge.\nWe apply evidence-based knowledge acquisition (EBKA) approach to collect,\nfilter, and update live knowledge through the integration of social media\nsources with authoritative sources. Although limited in quantity, the reliable\ntraining data from authoritative sources enable the filtering of misinformation\nas well as capturing truly new information. We describe the EDNA/LITMUS tools\nthat implement EBKA, integrating social media such as Twitter and Facebook with\nauthoritative sources such as WHO and CDC, creating and updating live knowledge\non the COVID-19 pandemic.", "author": [{"name": "Calton Pu"}, {"name": "Abhijit Suprem"}, {"name": "Rodrigo Alves Lima"}], "link": [{"@href": "http://arxiv.org/abs/2011.05416v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.05416v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.02382v1", "updated": "2021-02-04T02:47:31Z", "published": "2021-02-04T02:47:31Z", "title": "Mainstreaming of conspiracy theories and misinformation", "summary": "Parents - particularly moms - increasingly consult social media for support\nwhen taking decisions about their young children, and likely also when advising\nother family members such as elderly relatives. Minimizing malignant online\ninfluences is therefore crucial to securing their assent for policies ranging\nfrom vaccinations, masks and social distancing against the pandemic, to\nhousehold best practices against climate change, to acceptance of future 5G\ntowers nearby. Here we show how a strengthening of bonds across online\ncommunities during the pandemic, has led to non-Covid-19 conspiracy theories\n(e.g. fluoride, chemtrails, 5G) attaining heightened access to mainstream\nparent communities. Alternative health communities act as the critical conduits\nbetween conspiracy theorists and parents, and make the narratives more\npalatable to the latter. We demonstrate experimentally that these\ninter-community bonds can perpetually generate new misinformation, irrespective\nof any changes in factual information. Our findings show explicitly why\nFacebook's current policies have failed to stop the mainstreaming of\nnon-Covid-19 and Covid-19 conspiracy theories and misinformation, and why\ntargeting the largest communities will not work. A simple yet exactly solvable\nand empirically grounded mathematical model, shows how modest tailoring of\nmainstream communities' couplings could prevent them from tipping against\nestablishment guidance. Our conclusions should also apply to other social media\nplatforms and topics.", "author": [{"name": "N. F. Johnson"}, {"name": "N. Velasquez"}, {"name": "N. Johnson Restrepo"}, {"name": "R. Leahy"}, {"name": "R. Sear"}, {"name": "N. Gabriel"}, {"name": "H. Larson"}, {"name": "Y. Lupu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Working paper. Comments welcome to neiljohnson@gwu.edu"}, "link": [{"@href": "http://arxiv.org/abs/2102.02382v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.02382v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "nlin.AO", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.05134v2", "updated": "2021-05-14T21:05:27Z", "published": "2021-05-11T15:43:41Z", "title": "COVID-19 Vaccine Hesitancy on Social Media: Building a Public Twitter\n  Dataset of Anti-vaccine Content, Vaccine Misinformation and Conspiracies", "summary": "False claims about COVID-19 vaccines can undermine public trust in ongoing\nvaccination campaigns, thus posing a threat to global public health.\nMisinformation originating from various sources has been spreading online since\nthe beginning of the COVID-19 pandemic. In this paper, we present a dataset of\nTwitter posts that exhibit a strong anti-vaccine stance. The dataset consists\nof two parts: a) a streaming keyword-centered data collection with more than\n1.8 million tweets, and b) a historical account-level collection with more than\n135 million tweets. The former leverages the Twitter streaming API to follow a\nset of specific vaccine-related keywords starting from mid-October 2020. The\nlatter consists of all historical tweets of 70K accounts that were engaged in\nthe active spreading of anti-vaccine narratives. We present descriptive\nanalyses showing the volume of activity over time, geographical distributions,\ntopics, news sources, and inferred account political leaning. This dataset can\nbe used in studying anti-vaccine misinformation on social media and enable a\nbetter understanding of vaccine hesitancy. In compliance with Twitter's Terms\nof Service, our anonymized dataset is publicly available at:\nhttps://github.com/gmuric/avax-tweets-dataset", "author": [{"name": "Goran Muric"}, {"name": "Yusong Wu"}, {"name": "Emilio Ferrara"}], "link": [{"@href": "http://arxiv.org/abs/2105.05134v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.05134v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.01627v1", "updated": "2021-06-03T06:56:09Z", "published": "2021-06-03T06:56:09Z", "title": "Piercing the Veil: Designs to Support Information Literacy on Social\n  Platforms", "summary": "In this position paper we approach problems concerning critical digital and\ninformation literacy with ideas to provide more digestible explanations of\nabstract concepts through interface design. In particular, we focus on social\nmedia platforms where we see the possibility of counteracting the spread of\nmisinformation by providing users with more proficiency through our approaches.\nWe argue that the omnipresent trend to abstract away and hide information from\nusers via UI/UX design opposes their ability to self-learn. This leads us to\npropose a different framework in which we unify elegant and simple interfaces\nwith nudges that promote a look behind the curtain. Such designs serve to\nfoster a deeper understanding of employed technologies and aim to increase the\ncritical assessment of content encountered on social platforms. Furthermore, we\nconsider users with an intermediary skill level to be largely ignored in\ncurrent approaches, as they are given no tools to broaden their knowledge\nwithout consultation of expert material. The resulting stagnation is\nexemplified by the tactics of misinformation campaigns, which exploit the\nensuing lack of information literacy and critical thinking. We propose an\napproach to design that sufficiently emancipates users in both aspects by\npromoting a look behind the abstraction of UI/UX so that an autonomous learning\nprocess is given the chance to occur. Furthermore, we name ideas for future\nresearch within this area that take our considerations into account.", "author": {"name": "Jan Wolff"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Originally submitted to and presented at CHI'21 Workshop on\n  Technologies to Support Critical Thinking in an Age of Misinformation"}, "link": [{"@href": "http://arxiv.org/abs/2106.01627v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.01627v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.05815v1", "updated": "2021-06-10T15:30:42Z", "published": "2021-06-10T15:30:42Z", "title": "Italian Twitter semantic network during the Covid-19 epidemic", "summary": "The Covid-19 pandemic has had a deep impact on the lives of the entire world\npopulation, inducing a participated societal debate. As in other contexts, the\ndebate has been the subject of several d/misinformation campaigns; in a quite\nunprecedented fashion, however, the presence of false information has seriously\nput at risk the public health. In this sense, detecting the presence of\nmalicious narratives and identifying the kinds of users that are more prone to\nspread them represent the first step to limit the persistence of the former\nones. In the present paper we analyse the semantic network observed on Twitter\nduring the first Italian lockdown (induced by the hashtags contained in\napproximately 1.5 millions tweets published between the 23rd of March 2020 and\nthe 23rd of April 2020) and study the extent to which various discursive\ncommunities are exposed to d/misinformation arguments. As observed in other\nstudies, the recovered discursive communities largely overlap with traditional\npolitical parties, even if the debated topics concern different facets of the\nmanagement of the pandemic. Although the themes directly related to\nd/misinformation are a minority of those discussed within our semantic\nnetworks, their popularity is unevenly distributed among the various discursive\ncommunities.", "author": [{"name": "Mattia Mattei"}, {"name": "Guido Caldarelli"}, {"name": "Tiziano Squartini"}, {"name": "Fabio Saracco"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "29 pages, 11 figures"}, "link": [{"@href": "http://arxiv.org/abs/2106.05815v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.05815v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.data-an", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1901.11408v1", "updated": "2019-01-29T22:02:24Z", "published": "2019-01-29T22:02:24Z", "title": "Building Knowledge Graphs About Political Agents in the Age of\n  Misinformation", "summary": "This paper presents the construction of a Knowledge Graph about relations\nbetween agents in a political system. It discusses the main modeling\nchallenges, with emphasis on the issue of trust and provenance. Implementation\ndecisions are also presented", "author": [{"name": "Daniel Schwabe"}, {"name": "Carlos Laufer"}, {"name": "Antonio Busson"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: substantial text overlap with arXiv:1804.06015"}, "link": [{"@href": "http://arxiv.org/abs/1901.11408v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.11408v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "D.2.11; H.2.1; I.2.4; K.4.1; K.4.2", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.12841v3", "updated": "2020-08-27T04:01:13Z", "published": "2020-07-25T03:03:20Z", "title": "Combating Misinformation in Bangladesh: Roles and Responsibilities as\n  Perceived by Journalists, Fact-checkers, and Users", "summary": "There has been a growing interest within CSCW community in understanding the\ncharacteristics of misinformation propagated through computational media, and\nthe devising techniques to address the associated challenges. However, most\nwork in this area has been concentrated on the cases in the western world\nleaving a major portion of this problem unaddressed that is situated in the\nGlobal South. This paper aims to broaden the scope of this discourse by\nfocusing on this problem in the context of Bangladesh, a country in the Global\nSouth. The spread of misinformation on Facebook in Bangladesh, a country with a\npopulation over 163 million, has resulted in chaos, hate attacks, and killings.\nBy interviewing journalists, fact-checkers, in addition to surveying the\ngeneral public, we analyzed the current state of verifying misinformation in\nBangladesh. Our findings show that most people in the `news audience' want the\nnews media to verify the authenticity of online information that they see\nonline. However, the newspaper journalists say that fact-checking online\ninformation is not a part of their job, and it is also beyond their capacity\ngiven the amount of information being published online everyday. We further\nfind that the voluntary fact-checkers in Bangladesh are not equipped with\nsufficient infrastructural support to fill in this gap. We show how our\nfindings are connected to some of the core concerns of CSCW community around\nsocial media, collaboration, infrastructural politics, and information\ninequality. From our analysis, we also suggest several pathways to increase the\nimpact of fact-checking efforts through collaboration, technology design, and\ninfrastructure development.", "author": [{"name": "Md Mahfuzul Haque"}, {"name": "Mohammad Yousuf"}, {"name": "Ahmed Shatil Alam"}, {"name": "Pratyasha Saha"}, {"name": "Syed Ishtiaque Ahmed"}, {"name": "Naeemul Hassan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3415201"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3415201", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.12841v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.12841v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.01913v2", "updated": "2021-02-23T12:00:09Z", "published": "2020-10-05T10:49:32Z", "title": "Flow of online misinformation during the peak of the COVID-19 pandemic\n  in Italy", "summary": "The COVID-19 pandemic has impacted on every human activity and, because of\nthe urgency of finding the proper responses to such an unprecedented emergency,\nit generated a diffused societal debate. The online version of this discussion\nwas not exempted by the presence of d/misinformation campaigns, but differently\nfrom what already witnessed in other debates, the COVID-19 -- intentional or\nnot -- flow of false information put at severe risk the public health, reducing\nthe effectiveness of governments' countermeasures. In the present manuscript,\nwe study the effective impact of misinformation in the Italian societal debate\non Twitter during the pandemic, focusing on the various discursive communities.\nIn order to extract the discursive communities, we focus on verified users,\ni.e. accounts whose identity is officially certified by Twitter. We thus infer\nthe various discursive communities based on how verified users are perceived by\nstandard ones: if two verified accounts are considered as similar by non\nunverified ones, we link them in the network of certified accounts. We first\nobserve that, beside being a mostly scientific subject, the COVID-19 discussion\nshow a clear division in what results to be different political groups. At this\npoint, by using a commonly available fact-checking software (NewsGuard), we\nassess the reputation of the pieces of news exchanged. We filter the network of\nretweets (i.e. users re-broadcasting the same elementary piece of information,\nor tweet) from random noise and check the presence of messages displaying an\nurl. The impact of misinformation posts reaches the 22.1% in the right and\ncenter-right wing community and its contribution is even stronger in absolute\nnumbers, due to the activity of this group: 96% of all non reputable urls\nshared by political groups come from this community.", "author": [{"name": "Guido Caldarelli"}, {"name": "Rocco de Nicola"}, {"name": "Marinella Petrocchi"}, {"name": "Manuel Pratelli"}, {"name": "Fabio Saracco"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "25 pages, 4 figures. The Abstract, the Introduction, the Results, the\n  Conclusions and the Methods were substantially rewritten. The plot of the\n  network have been changed, as well as tables"}, "link": [{"@href": "http://arxiv.org/abs/2010.01913v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.01913v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.05745v1", "updated": "2021-04-12T18:13:40Z", "published": "2021-04-12T18:13:40Z", "title": "Fighting the COVID-19 Infodemic with a Holistic BERT Ensemble", "summary": "This paper describes the TOKOFOU system, an ensemble model for misinformation\ndetection tasks based on six different transformer-based pre-trained encoders,\nimplemented in the context of the COVID-19 Infodemic Shared Task for English.\nWe fine tune each model on each of the task's questions and aggregate their\nprediction scores using a majority voting approach. TOKOFOU obtains an overall\nF1 score of 89.7%, ranking first.", "author": [{"name": "Giorgos Tziafas"}, {"name": "Konstantinos Kogkalidis"}, {"name": "Tommaso Caselli"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "4 pages, NLP4IF 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.05745v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.05745v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1802.03573v1", "updated": "2018-02-10T12:22:59Z", "published": "2018-02-10T12:22:59Z", "title": "Social Media, News and Political Information during the US Election: Was\n  Polarizing Content Concentrated in Swing States?", "summary": "US voters shared large volumes of polarizing political news and information\nin the form of links to content from Russian, WikiLeaks and junk news sources.\nWas this low quality political information distributed evenly around the\ncountry, or concentrated in swing states and particular parts of the country?\nIn this data memo we apply a tested dictionary of sources about political news\nand information being shared over Twitter over a ten day period around the 2016\nPresidential Election. Using self-reported location information, we place a\nthird of users by state and create a simple index for the distribution of\npolarizing content around the country. We find that (1) nationally, Twitter\nusers got more misinformation, polarizing and conspiratorial content than\nprofessionally produced news. (2) Users in some states, however, shared more\npolarizing political news and information than users in other states. (3)\nAverage levels of misinformation were higher in swing states than in\nuncontested states, even when weighted for the relative size of the user\npopulation in each state. We conclude with some observations about the impact\nof strategically disseminated polarizing information on public life.", "author": [{"name": "Philip N. Howard"}, {"name": "Bence Kollanyi"}, {"name": "Samantha Bradshaw"}, {"name": "Lisa-Maria Neudert"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Data Memo"}, "link": [{"@href": "http://arxiv.org/abs/1802.03573v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1802.03573v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1801.09223v2", "updated": "2018-04-10T05:22:23Z", "published": "2018-01-28T13:08:43Z", "title": "Probability Mass Exclusions and the Directed Components of Pointwise\n  Mutual Information", "summary": "This paper examines how an event from one random variable provides pointwise\nmutual information about an event from another variable via probability mass\nexclusions. We start by introducing probability mass diagrams, which provide a\nvisual representation of how a prior distribution is transformed to a posterior\ndistribution through exclusions. With the aid of these diagrams, we identify\ntwo distinct types of probability mass exclusions---namely informative and\nmisinformative exclusions. Then, motivated by Fano's derivation of the\npointwise mutual information, we propose four postulates which aim to decompose\nthe pointwise mutual information into two separate informational components: a\nnon-negative term associated with the informative exclusion and a non-positive\nterm associated with the misinformative exclusions. This yields a novel\nderivation of a familiar decomposition of the pointwise mutual information into\nentropic components. We conclude by discussing the relevance of considering\ninformation in terms of probability mass exclusions to the ongoing effort to\ndecompose multivariate information.", "author": [{"name": "Conor Finn"}, {"name": "Joseph T Lizier"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.3390/e20110826"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.3390/e20110826", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1801.09223v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1801.09223v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 7 figures"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "94A15, 94A17", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.01806v1", "updated": "2018-11-05T15:43:45Z", "published": "2018-11-05T15:43:45Z", "title": "Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of\n  User Engagement and Challenges", "summary": "Fake news and misinformation spread in developing countries as fast as they\ndo in developed countries with increasing penetration of the internet and\nsocial media. However, fighting misinformation is more difficult in developing\ncountries where resources and necessary technologies are scarce. This study\nprovides an understanding of the challenges various fact-checking initiatives\nface in three South Asian countries--Bangladesh, India, and Nepal. In-depth\ninterviews were conducted with senior editors of six fact-checking initiatives.\nChallenges identified include lack of resources, technologies, and political\npressure. An analysis of Facebook pages of these initiatives shows increasing\nuser engagement with their posts.", "author": [{"name": "Md Mahfuzul Haque"}, {"name": "Mohammad Yousuf"}, {"name": "Zahedur Arman"}, {"name": "Md Main Uddin Rony"}, {"name": "Ahmed Shatil Alam"}, {"name": "Kazi Mehedi Hasan"}, {"name": "Md Khadimul Islam"}, {"name": "Naeemul Hassan"}], "link": [{"@href": "http://arxiv.org/abs/1811.01806v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.01806v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1910.02202v1", "updated": "2019-10-05T03:23:45Z", "published": "2019-10-05T03:23:45Z", "title": "Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language", "summary": "In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SIGIR 2019"}, "link": [{"@href": "http://arxiv.org/abs/1910.02202v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.02202v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1701.07490v1", "updated": "2017-01-17T18:52:22Z", "published": "2017-01-17T18:52:22Z", "title": "What Are People Tweeting about Zika? An Exploratory Study Concerning\n  Symptoms, Treatment, Transmission, and Prevention", "summary": "The purpose of this study was to do a dataset distribution analysis, a\nclassification performance analysis, and a topical analysis concerning what\npeople are tweeting about four disease characteristics: symptoms, transmission,\nprevention, and treatment. A combination of natural language processing and\nmachine learning techniques were used to determine what people are tweeting\nabout Zika. Specifically, a two-stage classifier system was built to find\nrelevant tweets on Zika, and then categorize these into the four disease\ncategories. Tweets in each disease category were then examined using latent\ndirichlet allocation (LDA) to determine the five main tweet topics for each\ndisease characteristic. Results 1,234,605 tweets were collected. Tweets by\nmales and females were similar (28% and 23% respectively). The classifier\nperformed well on the training and test data for relevancy (F=0.87 and 0.99\nrespectively) and disease characteristics (F=0.79 and 0.90 respectively). Five\ntopics for each category were found and discussed with a focus on the symptoms\ncategory. Through this process, we demonstrate how misinformation can be\ndiscovered so that public health officials can respond to the tweets with\nmisinformation.", "author": [{"name": "Michele Miller"}, {"name": "Dr. Tanvi Banerjee"}, {"name": "RoopTeja Muppalla"}, {"name": "Dr. William Romine"}, {"name": "Dr. Amit Sheth"}], "link": [{"@href": "http://arxiv.org/abs/1701.07490v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1701.07490v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.OT", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1805.05999v2", "updated": "2018-05-17T09:33:35Z", "published": "2018-05-15T19:09:41Z", "title": "Agent Based Rumor Spreading in a scale-free network", "summary": "In the last years, the study of rumor spreading on social networks produced a\nlot of interest among the scientific community, expecially due to the role of\nsocial networks in the last political events. The goal of this work is to\nreproduce real-like diffusions of information and misinformation in a\nscale-free network using a multi-agent-based model. The data concerning the\nvirtual spreading are easily obtainable, in particular the diffusion of\ninformation during the announcement for the discovery of the Higgs Boson on\nTwitter was recorded and investigated in detail. We made some assumptions on\nthe micro behavior of our agents and registered the effects in a statistical\nanalysis replying the real data diffusion. Then, we studied an hypotetical\nresponse to a misinformation diffusion adding debunking agents and trying to\nmodel a critic response from the agents using real data from a hoax regarding\nthe Occupy Wall Street movement. After tuning our model to reproduce these\nresults, we measured some network properties and proved the emergence of\nsubstantially separated structures like echochambers, independently from the\nnetwork size scale, i.e. with one hundred, one thousand and ten thousand\nagents.", "author": [{"name": "Mattia Mazzoli"}, {"name": "Tullio Re"}, {"name": "Roberto Bertilone"}, {"name": "Marco Maggiora"}, {"name": "Jacopo Pellegrino"}], "link": [{"@href": "http://arxiv.org/abs/1805.05999v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1805.05999v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T42", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.00957v1", "updated": "2019-05-02T20:50:22Z", "published": "2019-05-02T20:50:22Z", "title": "A Topic-Agnostic Approach for Identifying Fake News Pages", "summary": "Fake news and misinformation have been increasingly used to manipulate\npopular opinion and influence political processes. To better understand fake\nnews, how they are propagated, and how to counter their effect, it is necessary\nto first identify them. Recently, approaches have been proposed to\nautomatically classify articles as fake based on their content. An important\nchallenge for these approaches comes from the dynamic nature of news: as new\npolitical events are covered, topics and discourse constantly change and thus,\na classifier trained using content from articles published at a given time is\nlikely to become ineffective in the future. To address this challenge, we\npropose a topic-agnostic (TAG) classification strategy that uses linguistic and\nweb-markup features to identify fake news pages. We report experimental results\nusing multiple data sets which show that our approach attains high accuracy in\nthe identification of fake news, even as topics evolve over time.", "author": [{"name": "Sonia Castelo"}, {"name": "Thais Almeida"}, {"name": "Anas Elghafari"}, {"name": "A\u00e9cio Santos"}, {"name": "Kien Pham"}, {"name": "Eduardo Nakamura"}, {"name": "Juliana Freire"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3308560.3316739"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3308560.3316739", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1905.00957v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.00957v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication in the Companion Proceedings of the 2019\n  World Wide Web Conference (WWW'19 Companion). Presented in the 2019\n  International Workshop on Misinformation, Computational Fact-Checking and\n  Credible Web (MisinfoWorkshop2019). 6 pages"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.04260v1", "updated": "2019-05-10T17:00:40Z", "published": "2019-05-10T17:00:40Z", "title": "Check-It: A Plugin for Detecting and Reducing the Spread of Fake News\n  and Misinformation on the Web", "summary": "Over the past few years, we have been witnessing the rise of misinformation\non the Web. People fall victims of fake news during their daily lives and\nassist their further propagation knowingly and inadvertently. There have been\nmany initiatives that are trying to mitigate the damage caused by fake news,\nfocusing on signals from either domain flag-lists, online social networks or\nartificial intelligence. In this work, we present Check-It, a system that\ncombines, in an intelligent way, a variety of signals into a pipeline for fake\nnews identification. Check-It is developed as a web browser plugin with the\nobjective of efficient and timely fake news detection, respecting the user's\nprivacy. Experimental results show that Check-It is able to outperform the\nstate-of-the-art methods. On a dataset, consisting of 9 millions of articles\nlabeled as fake and real, Check-It obtains classification accuracies that\nexceed 99%.", "author": [{"name": "Demetris Paschalides"}, {"name": "Alexandros Kornilakis"}, {"name": "Chrysovalantis Christodoulou"}, {"name": "Rafael Andreou"}, {"name": "George Pallis"}, {"name": "Marios D. Dikaiakos"}, {"name": "Evangelos Markatos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 6 figures,"}, "link": [{"@href": "http://arxiv.org/abs/1905.04260v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.04260v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.07100v1", "updated": "2019-11-16T21:13:33Z", "published": "2019-11-16T21:13:33Z", "title": "Defending Against Model Stealing Attacks with Adaptive Misinformation", "summary": "Deep Neural Networks (DNNs) are susceptible to model stealing attacks, which\nallows a data-limited adversary with no knowledge of the training dataset to\nclone the functionality of a target model, just by using black-box query\naccess. Such attacks are typically carried out by querying the target model\nusing inputs that are synthetically generated or sampled from a surrogate\ndataset to construct a labeled dataset. The adversary can use this labeled\ndataset to train a clone model, which achieves a classification accuracy\ncomparable to that of the target model. We propose \"Adaptive Misinformation\" to\ndefend against such model stealing attacks. We identify that all existing model\nstealing attacks invariably query the target model with Out-Of-Distribution\n(OOD) inputs. By selectively sending incorrect predictions for OOD queries, our\ndefense substantially degrades the accuracy of the attacker's clone model (by\nup to 40%), while minimally impacting the accuracy (<0.5%) for benign users.\nCompared to existing defenses, our defense has a significantly better security\nvs accuracy trade-off and incurs minimal computational overhead.", "author": [{"name": "Sanjay Kariyappa"}, {"name": "Moinuddin K Qureshi"}], "link": [{"@href": "http://arxiv.org/abs/1911.07100v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.07100v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1912.08926v1", "updated": "2019-11-25T03:55:55Z", "published": "2019-11-25T03:55:55Z", "title": "Rumor Detection and Classification for Twitter Data", "summary": "With the pervasiveness of online media data as a source of information\nverifying the validity of this information is becoming even more important yet\nquite challenging. Rumors spread a large quantity of misinformation on\nmicroblogs. In this study we address two common issues within the context of\nmicroblog social media. First we detect rumors as a type of misinformation\npropagation and next we go beyond detection to perform the task of rumor\nclassification. WE explore the problem using a standard data set. We devise\nnovel features and study their impact on the task. We experiment with various\nlevels of preprocessing as a precursor of the classification as well as\ngrouping of features. We achieve and f-measure of over 0.82 in RDC task in\nmixed rumors data set and 84 percent in a single rumor data set using a\ntwo-step classification approach.", "author": [{"name": "Sardar Hamidian"}, {"name": "Mona T Diab"}], "link": [{"@href": "http://arxiv.org/abs/1912.08926v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.08926v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.08444v2", "updated": "2020-03-26T21:29:51Z", "published": "2020-03-18T19:18:21Z", "title": "NELA-GT-2019: A Large Multi-Labelled News Dataset for The Study of\n  Misinformation in News Articles", "summary": "In this paper, we present an updated version of the NELA-GT-2018 dataset\n(N{\\o}rregaard, Horne, and Adal{\\i} 2019), entitled NELA-GT-2019. NELA-GT-2019\ncontains 1.12M news articles from 260 sources collected between January 1st\n2019 and December 31st 2019. Just as with NELA-GT-2018, these sources come from\na wide range of mainstream news sources and alternative news sources. Included\nwith the dataset are source-level ground truth labels from 7 different\nassessment sites covering multiple dimensions of veracity. The NELA-GT-2019\ndataset can be found at: https://doi.org/10.7910/DVN/O7FWPO", "author": [{"name": "Maur\u00edcio Gruppi"}, {"name": "Benjamin D. Horne"}, {"name": "Sibel Adal\u0131"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Updated dataset for paper NELA-GT-2018: A Large Multi-Labelled News\n  Dataset for The Study of Misinformation in News Articles, originally\n  published at ICWSM in 2019"}, "link": [{"@href": "http://arxiv.org/abs/2003.08444v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.08444v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.08166v2", "updated": "2021-02-14T20:33:58Z", "published": "2020-04-17T10:55:07Z", "title": "Too Many Claims to Fact-Check: Prioritizing Political Claims Based on\n  Check-Worthiness", "summary": "The massive amount of misinformation spreading on the Internet on a daily\nbasis has enormous negative impacts on societies. Therefore, we need automated\nsystems helping fact-checkers in the combat against misinformation. In this\npaper, we propose a model prioritizing the claims based on their\ncheck-worthiness. We use BERT model with additional features including\ndomain-specific controversial topics, word embeddings, and others. In our\nexperiments, we show that our proposed model outperforms all state-of-the-art\nmodels in both test collections of CLEF Check That! Lab in 2018 and 2019. We\nalso conduct a qualitative analysis to shed light-detecting check-worthy\nclaims. We suggest requesting rationales behind judgments are needed to\nunderstand subjective nature of the task and problematic labels.", "author": [{"name": "Yavuz Selim Kartal"}, {"name": "Busra Guvenen"}, {"name": "Mucahid Kutlu"}], "link": [{"@href": "http://arxiv.org/abs/2004.08166v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.08166v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.06915v3", "updated": "2020-06-25T01:54:21Z", "published": "2020-05-14T12:37:48Z", "title": "Can The Crowd Identify Misinformation Objectively? The Effects of\n  Judgment Scale and Assessor's Background", "summary": "Truthfulness judgments are a fundamental step in the process of fighting\nmisinformation, as they are crucial to train and evaluate classifiers that\nautomatically distinguish true and false statements. Usually such judgments are\nmade by experts, like journalists for political statements or medical doctors\nfor medical statements. In this paper, we follow a different approach and rely\non (non-expert) crowd workers. This of course leads to the following research\nquestion: Can crowdsourcing be reliably used to assess the truthfulness of\ninformation and to create large-scale labeled collections for information\ncredibility systems? To address this issue, we present the results of an\nextensive study based on crowdsourcing: we collect thousands of truthfulness\nassessments over two datasets, and we compare expert judgments with crowd\njudgments, expressed on scales with various granularity levels. We also measure\nthe political bias and the cognitive background of the workers, and quantify\ntheir effect on the reliability of the data provided by the crowd.", "author": [{"name": "Kevin Roitero"}, {"name": "Michael Soprano"}, {"name": "Shaoyang Fan"}, {"name": "Damiano Spina"}, {"name": "Stefano Mizzaro"}, {"name": "Gianluca Demartini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3397271.3401112"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3397271.3401112", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2005.06915v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.06915v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Preprint of the full paper accepted at SIGIR 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68P20", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.13270v1", "updated": "2020-05-27T10:29:14Z", "published": "2020-05-27T10:29:14Z", "title": "BRENDA: Browser Extension for Fake News Detection", "summary": "Misinformation such as fake news has drawn a lot of attention in recent\nyears. It has serious consequences on society, politics and economy. This has\nlead to a rise of manually fact-checking websites such as Snopes and\nPolitifact. However, the scale of misinformation limits their ability for\nverification. In this demonstration, we propose BRENDA a browser extension\nwhich can be used to automate the entire process of credibility assessments of\nfalse claims. Behind the scenes BRENDA uses a tested deep neural network\narchitecture to automatically identify fact check worthy claims and classifies\nas well as presents the result along with evidence to the user. Since BRENDA is\na browser extension, it facilities fast automated fact checking for the end\nuser without having to leave the Webpage.", "author": [{"name": "Bjarte Botnevik"}, {"name": "Eirik Sakariassen"}, {"name": "Vinay Setty"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3397271.3401396"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3397271.3401396", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2005.13270v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.13270v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted as SIGIR demo"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Proceedings of the 43rd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR 2020), July 25 to\n  30, 2020, Virtual Event, China. ACM, New York, NY, USA, 4 pages"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.02620v2", "updated": "2020-09-11T11:34:22Z", "published": "2020-07-06T10:20:12Z", "title": "Reducing Misinformation in Query Autocompletions", "summary": "Query autocompletions help users of search engines to speed up their searches\nby recommending completions of partially typed queries in a drop down box.\nThese recommended query autocompletions are usually based on large logs of\nqueries that were previously entered by the search engine's users. Therefore,\nmisinformation entered -- either accidentally or purposely to manipulate the\nsearch engine -- might end up in the search engine's recommendations,\npotentially harming organizations, individuals, and groups of people. This\npaper proposes an alternative approach for generating query autocompletions by\nextracting anchor texts from a large web crawl, without the need to use query\nlogs. Our evaluation shows that even though query log autocompletions perform\nbetter for shorter queries, anchor text autocompletions outperform query log\nautocompletions for queries of 2 words or more.", "author": {"name": "Djoerd Hiemstra"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at the 2nd International Symposium on Open Search\n  Technology, 12-14 October 2020, CERN, Geneva, Switzerland"}, "link": [{"@href": "http://arxiv.org/abs/2007.02620v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.02620v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.08078v2", "updated": "2021-03-06T15:11:31Z", "published": "2020-07-16T02:13:55Z", "title": "Political audience diversity and news reliability in algorithmic ranking", "summary": "Newsfeed algorithms frequently amplify misinformation and other low-quality\ncontent. How can social media platforms more effectively promote reliable\ninformation? Existing approaches are difficult to scale and vulnerable to\nmanipulation. In this paper, we propose using the political diversity of a\nwebsite's audience as a quality signal. Using news source reliability ratings\nfrom domain experts and web browsing data from a diverse sample of 6,890 U.S.\ncitizens, we first show that websites with more extreme and less politically\ndiverse audiences have lower journalistic standards. We then incorporate\naudience diversity into a standard collaborative filtering framework and show\nthat our improved algorithm increases the trustworthiness of websites suggested\nto users -- especially those who most frequently consume misinformation --\nwhile keeping recommendations relevant. These findings suggest that partisan\naudience diversity is a valuable signal of higher journalistic standards that\nshould be incorporated into algorithmic ranking decisions.", "author": [{"name": "Saumya Bhadani"}, {"name": "Shun Yamaya"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}, {"name": "Giovanni Luca Ciampaglia"}, {"name": "Brendan Nyhan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "47 pages, 23 figures, 5 tables (including supplementary materials)"}, "link": [{"@href": "http://arxiv.org/abs/2007.08078v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.08078v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.08413v1", "updated": "2020-09-17T16:42:08Z", "published": "2020-09-17T16:42:08Z", "title": "Not sure? Handling hesitancy of COVID-19 vaccines", "summary": "From the moment the first COVID-19 vaccines are rolled out, there will need\nto be a large fraction of the global population ready in line. It is therefore\ncrucial to start managing the growing global hesitancy to any such COVID-19\nvaccine. The current approach of trying to convince the \"no\"s cannot work\nquickly enough, nor can the current policy of trying to find, remove and/or\nrebut all the individual pieces of COVID and vaccine misinformation. Instead,\nwe show how this can be done in a simpler way by moving away from chasing\nmisinformation content and focusing instead on managing the \"yes--no--not-sure\"\nhesitancy ecosystem.", "author": [{"name": "N. F. Johnson"}, {"name": "N. Velasquez"}, {"name": "R. Leahy"}, {"name": "N. Johnson Restrepo"}, {"name": "O. Jha"}, {"name": "Y. Lupu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Working paper. Comments welcome to neiljohnson@gwu.edu"}, "link": [{"@href": "http://arxiv.org/abs/2009.08413v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.08413v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "nlin.AO", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.med-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.12905v1", "updated": "2020-09-27T17:38:54Z", "published": "2020-09-27T17:38:54Z", "title": "COVID-19's (mis)information ecosystem on Twitter: How partisanship\n  boosts the spread of conspiracy narratives on German speaking Twitter", "summary": "In late 2019, the gravest pandemic in a century began spreading across the\nworld. A state of uncertainty related to what has become known as SARS-CoV-2\nhas since fueled conspiracy narratives on social media about the origin,\ntransmission and medical treatment of and vaccination against the resulting\ndisease, COVID-19. Using social media intelligence to monitor and understand\nthe proliferation of conspiracy narratives is one way to analyze the\ndistribution of misinformation on the pandemic. We analyzed more than 9.5M\nGerman language tweets about COVID-19. The results show that only about 0.6% of\nall those tweets deal with conspiracy theory narratives. We also found that the\npolitical orientation of users correlates with the volume of content users\ncontribute to the dissemination of conspiracy narratives, implying that\npartisan communicators have a higher motivation to take part in conspiratorial\ndiscussions on Twitter. Finally, we showed that contrary to other studies,\nautomated accounts do not significantly influence the spread of misinformation\nin the German speaking Twitter sphere. They only represent about 1.31% of all\nconspiracy-related activities in our database.", "author": [{"name": "Morteza Shahrezaye"}, {"name": "Miriam Meckel"}, {"name": "L\u00e9a Steinacker"}, {"name": "Viktor Suter"}], "link": [{"@href": "http://arxiv.org/abs/2009.12905v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.12905v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2009.14337v1", "updated": "2020-09-29T22:58:33Z", "published": "2020-09-29T22:58:33Z", "title": "StratLearner: Learning a Strategy for Misinformation Prevention in\n  Social Networks", "summary": "Given a combinatorial optimization problem taking an input, can we learn a\nstrategy to solve it from the examples of input-solution pairs without knowing\nits objective function? In this paper, we consider such a setting and study the\nmisinformation prevention problem. Given the examples of attacker-protector\npairs, our goal is to learn a strategy to compute protectors against future\nattackers, without the need of knowing the underlying diffusion model. To this\nend, we design a structured prediction framework, where the main idea is to\nparameterize the scoring function using random features constructed through\ndistance functions on randomly sampled subgraphs, which leads to a kernelized\nscoring function with weights learnable via the large margin method. Evidenced\nby experiments, our method can produce near-optimal protectors without using\nany information of the diffusion model, and it outperforms other possible\ngraph-based and learning-based methods by an evident margin.", "author": {"name": "Guangmo Tong"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NeurIPS'20"}, "link": [{"@href": "http://arxiv.org/abs/2009.14337v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.14337v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.16357v1", "updated": "2020-10-30T16:26:35Z", "published": "2020-10-30T16:26:35Z", "title": "A Cross-lingual Natural Language Processing Framework for Infodemic\n  Management", "summary": "The COVID-19 pandemic has put immense pressure on health systems which are\nfurther strained due to the misinformation surrounding it. Under such a\nsituation, providing the right information at the right time is crucial. There\nis a growing demand for the management of information spread using Artificial\nIntelligence. Hence, we have exploited the potential of Natural Language\nProcessing for identifying relevant information that needs to be disseminated\namongst the masses. In this work, we present a novel Cross-lingual Natural\nLanguage Processing framework to provide relevant information by matching daily\nnews with trusted guidelines from the World Health Organization. The proposed\npipeline deploys various techniques of NLP such as summarizers, word\nembeddings, and similarity metrics to provide users with news articles along\nwith a corresponding healthcare guideline. A total of 36 models were evaluated\nand a combination of LexRank based summarizer on Word2Vec embedding with Word\nMover distance metric outperformed all other models. This novel open-source\napproach can be used as a template for proactive dissemination of relevant\nhealthcare information in the midst of misinformation spread associated with\nepidemics.", "author": [{"name": "Ridam Pal"}, {"name": "Rohan Pandey"}, {"name": "Vaibhav Gautam"}, {"name": "Kanav Bhagat"}, {"name": "Tavpritesh Sethi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 Pages, 2 Figures, 3 Tables"}, "link": [{"@href": "http://arxiv.org/abs/2010.16357v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.16357v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.03529v1", "updated": "2021-01-10T11:52:17Z", "published": "2021-01-10T11:52:17Z", "title": "TIB's Visual Analytics Group at MediaEval '20: Detecting Fake News on\n  Corona Virus and 5G Conspiracy", "summary": "Fake news on social media has become a hot topic of research as it negatively\nimpacts the discourse of real news in the public. Specifically, the ongoing\nCOVID-19 pandemic has seen a rise of inaccurate and misleading information due\nto the surrounding controversies and unknown details at the beginning of the\npandemic. The FakeNews task at MediaEval 2020 tackles this problem by creating\na challenge to automatically detect tweets containing misinformation based on\ntext and structure from Twitter follower network. In this paper, we present a\nsimple approach that uses BERT embeddings and a shallow neural network for\nclassifying tweets using only text, and discuss our findings and limitations of\nthe approach in text-based misinformation detection.", "author": [{"name": "Gullal S. Cheema"}, {"name": "Sherzod Hakimov"}, {"name": "Ralph Ewerth"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MediaEval 2020 Fake News Task"}, "link": [{"@href": "http://arxiv.org/abs/2101.03529v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.03529v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.04031v1", "updated": "2021-02-08T07:08:36Z", "published": "2021-02-08T07:08:36Z", "title": "Rihanna versus Bollywood: Twitter Influencers and the Indian Farmers'\n  Protest", "summary": "A tweet from popular entertainer and businesswoman, Rihanna, bringing\nattention to farmers' protests around Delhi set off heightened activity on\nIndian social media. An immediate consequence was the weighing in by Indian\npoliticians, entertainers, media and other influencers on the issue. In this\npaper, we use data from Twitter and an archive of debunked misinformation\nstories to understand some of the patterns around influencer engagement with a\npolitical issue. We found that more followed influencers were less likely to\ncome out in support of the tweet. We also find that the later engagement of\nmajor influencers on the side of the government's position shows suggestion's\nof collusion. Irrespective of their position on the issue, influencers who\nengaged saw a significant rise in their following after their tweets. While a\nnumber of tweets thanked Rihanna for raising awareness on the issue, she was\nsystematically trolled on the grounds of her gender, race, nationality and\nreligion. Finally, we observed how misinformation existing prior to the tweet\nset up the grounds for alternative narratives that emerged.", "author": [{"name": "Dibyendu Mishra"}, {"name": "Syeda Zainab Akbar"}, {"name": "Arshia Arya"}, {"name": "Saloni Dash"}, {"name": "Rynaa Grover"}, {"name": "Joyojeet Pal"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages, 12 figures"}, "link": [{"@href": "http://arxiv.org/abs/2102.04031v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.04031v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.06109v1", "updated": "2021-02-11T16:44:09Z", "published": "2021-02-11T16:44:09Z", "title": "The Deepfake Detection Dilemma: A Multistakeholder Exploration of\n  Adversarial Dynamics in Synthetic Media", "summary": "Synthetic media detection technologies label media as either synthetic or\nnon-synthetic and are increasingly used by journalists, web platforms, and the\ngeneral public to identify misinformation and other forms of problematic\ncontent. As both well-resourced organizations and the non-technical general\npublic generate more sophisticated synthetic media, the capacity for purveyors\nof problematic content to adapt induces a \\newterm{detection dilemma}: as\ndetection practices become more accessible, they become more easily\ncircumvented. This paper describes how a multistakeholder cohort from academia,\ntechnology platforms, media entities, and civil society organizations active in\nsynthetic media detection and its socio-technical implications evaluates the\ndetection dilemma. Specifically, we offer an assessment of detection contexts\nand adversary capacities sourced from the broader, global AI and media\nintegrity community concerned with mitigating the spread of harmful synthetic\nmedia. A collection of personas illustrates the intersection between\nunsophisticated and highly-resourced sponsors of misinformation in the context\nof their technical capacities. This work concludes that there is no \"best\"\napproach to navigating the detector dilemma, but derives a set of implications\nfrom multistakeholder input to better inform detection process decisions and\npolicies, in practice.", "author": [{"name": "Claire Leibowicz"}, {"name": "Sean McGregor"}, {"name": "Aviv Ovadya"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 8 Figures"}, "link": [{"@href": "http://arxiv.org/abs/2102.06109v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.06109v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.07857v1", "updated": "2021-02-15T21:41:12Z", "published": "2021-02-15T21:41:12Z", "title": "KNH: Multi-View Modeling with K-Nearest Hyperplanes Graph for\n  Misinformation Detection", "summary": "Graphs are one of the most efficacious structures for representing datapoints\nand their relations, and they have been largely exploited for different\napplications. Previously, the higher-order relations between the nodes have\nbeen modeled by a generalization of graphs known as hypergraphs. In\nhypergraphs, the edges are defined by a set of nodes i.e., hyperedges to\ndemonstrate the higher order relationships between the data. However, there is\nno explicit higher-order generalization for nodes themselves. In this work, we\nintroduce a novel generalization of graphs i.e., K-Nearest Hyperplanes graph\n(KNH) where the nodes are defined by higher order Euclidean subspaces for\nmulti-view modeling of the nodes. In fact, in KNH, nodes are hyperplanes or\nmore precisely m-flats instead of datapoints. We experimentally evaluate the\nKNH graph on two multi-aspect datasets for misinformation detection. The\nexperimental results suggest that multi-view modeling of articles using KNH\ngraph outperforms the classic KNN graph in terms of classification performance.", "author": [{"name": "Sara Abdali"}, {"name": "Neil Shah"}, {"name": "Evangelos E. Papalexakis"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Second International TrueFact Workshop 2020: Making a Credible Web\n  for Tomorrow"}, "link": [{"@href": "http://arxiv.org/abs/2102.07857v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.07857v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.01215v1", "updated": "2021-04-02T19:27:53Z", "published": "2021-04-02T19:27:53Z", "title": "The Coronavirus is a Bioweapon: Analysing Coronavirus Fact-Checked\n  Stories", "summary": "The 2020 coronavirus pandemic has heightened the need to flag\ncoronavirus-related misinformation, and fact-checking groups have taken to\nverifying misinformation on the Internet. We explore stories reported by\nfact-checking groups PolitiFact, Poynter and Snopes from January to June 2020,\ncharacterising them into six story clusters before then analyse time-series and\nstory validity trends and the level of agreement across sites. We further break\ndown the story clusters into more granular story types by proposing a unique\nautomated method with a BERT classifier, which can be used to classify diverse\nstory sources, in both fact-checked stories and tweets.", "author": [{"name": "Lynnette Hui Xian Ng"}, {"name": "Kathleen M. Carley"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SBP-Brims 2020 COVID Special Track"}, "link": [{"@href": "http://arxiv.org/abs/2104.01215v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.01215v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.06952v1", "updated": "2021-04-14T16:25:22Z", "published": "2021-04-14T16:25:22Z", "title": "The Surprising Performance of Simple Baselines for Misinformation\n  Detection", "summary": "As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.", "author": [{"name": "Kellin Pelrine"}, {"name": "Jacob Danovitch"}, {"name": "Reihaneh Rabbany"}], "link": [{"@href": "http://arxiv.org/abs/2104.06952v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.06952v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.13352v2", "updated": "2021-06-13T12:27:10Z", "published": "2021-04-24T08:54:02Z", "title": "Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021", "summary": "On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.", "author": [{"name": "Ajay Agarwal"}, {"name": "Basant Agarwal"}], "link": [{"@href": "http://arxiv.org/abs/2104.13352v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13352v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.03794v1", "updated": "2021-06-07T16:59:46Z", "published": "2021-06-07T16:59:46Z", "title": "COVID-Fact: Fact Extraction and Verification of Real-World Claims on\n  COVID-19 Pandemic", "summary": "We introduce a FEVER-like dataset COVID-Fact of $4,086$ claims concerning the\nCOVID-19 pandemic. The dataset contains claims, evidence for the claims, and\ncontradictory claims refuted by the evidence. Unlike previous approaches, we\nautomatically detect true claims and their source articles and then generate\ncounter-claims using automatic methods rather than employing human annotators.\nAlong with our constructed resource, we formally present the task of\nidentifying relevant evidence for the claims and verifying whether the evidence\nrefutes or supports a given claim. In addition to scientific claims, our data\ncontains simplified general claims from media sources, making it better suited\nfor detecting general misinformation regarding COVID-19. Our experiments\nindicate that COVID-Fact will provide a challenging testbed for the development\nof new systems and our approach will reduce the costs of building\ndomain-specific datasets for detecting misinformation.", "author": [{"name": "Arkadiy Saakyan"}, {"name": "Tuhin Chakrabarty"}, {"name": "Smaranda Muresan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL 2021 Camera Ready"}, "link": [{"@href": "http://arxiv.org/abs/2106.03794v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.03794v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.06249v1", "updated": "2021-08-13T14:00:12Z", "published": "2021-08-13T14:00:12Z", "title": "MIND - Mainstream and Independent News Documents Corpus", "summary": "This paper presents and characterizes MIND, a new Portuguese corpus comprised\nof different types of articles collected from online mainstream and alternative\nmedia sources, over a 10-month period. The articles in the corpus are organized\ninto five collections: facts, opinions, entertainment, satires, and conspiracy\ntheories. Throughout this paper, we explain how the data collection process was\nconducted, and present a set of linguistic metrics that allow us to perform a\npreliminary characterization of the texts included in the corpus. Also, we\ndeliver an analysis of the most frequent topics in the corpus, and discuss the\nmain differences and similarities among the collections considered. Finally, we\nenumerate some tasks and applications that could benefit from this corpus, in\nparticular the ones (in)directly related to misinformation detection. Overall,\nour contribution of a corpus and initial analysis are designed to support\nfuture exploratory news studies, and provide a better insight into\nmisinformation.", "author": [{"name": "Danielle Caled"}, {"name": "Paula Carvalho"}, {"name": "M\u00e1rio J. Silva"}], "link": [{"@href": "http://arxiv.org/abs/2108.06249v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.06249v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1901.07920v3", "updated": "2019-04-17T14:32:32Z", "published": "2019-01-23T14:42:47Z", "title": "The Junk News Aggregator: Examining junk news posted on Facebook,\n  starting with the 2018 US Midterm Elections", "summary": "In recent years, the phenomenon of online misinformation and junk news\ncirculating on social media has come to constitute an important and widespread\nproblem affecting public life online across the globe, particularly around\nimportant political events such as elections. At the same time, there have been\ncalls for more transparency around misinformation on social media platforms, as\nmany of the most popular social media platforms function as \"walled gardens,\"\nwhere it is impossible for researchers and the public to readily examine the\nscale and nature of misinformation activity as it unfolds on the platforms. In\norder to help address this, we present the Junk News Aggregator, a publicly\navailable interactive web tool, which allows anyone to examine, in near\nreal-time, all of the public content posted to Facebook by important junk news\nsources in the US. It allows the public to gain access to and examine the\nlatest articles posted on Facebook (the most popular social media platform in\nthe US and one where content is not readily accessible at scale from the open\nWeb), as well as organise them by time, news publisher, and keywords of\ninterest, and sort them based on all eight engagement metrics available on\nFacebook. Therefore, the Aggregator allows the public to gain insights on the\nvolume, content, key themes, and types and volumes of engagement received by\ncontent posted by junk news publishers, in near real-time, hence opening up and\noffering transparency in these activities as they unfold, at scale across the\ntop most popular junk news publishers. In this way, the Aggregator can help\nincrease transparency around the nature, volume, and engagement with junk news\non social media, and serve as a media literacy tool for the public.", "author": [{"name": "Dimitra Liotsiou"}, {"name": "Bence Kollanyi"}, {"name": "Philip N. Howard"}], "link": [{"@href": "http://arxiv.org/abs/1901.07920v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.07920v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.05513v2", "updated": "2020-05-13T16:47:44Z", "published": "2020-05-12T01:51:07Z", "title": "Psychometric Analysis and Coupling of Emotions Between State Bulletins\n  and Twitter in India during COVID-19 Infodemic", "summary": "COVID-19 infodemic has been spreading faster than the pandemic itself. The\nmisinformation riding upon the infodemic wave poses a major threat to people's\nhealth and governance systems. Since social media is the largest source of\ninformation, managing the infodemic not only requires mitigating of\nmisinformation but also an early understanding of psychological patterns\nresulting from it. During the COVID-19 crisis, Twitter alone has seen a sharp\n45% increase in the usage of its curated events page, and a 30% increase in its\ndirect messaging usage, since March 6th 2020. In this study, we analyze the\npsychometric impact and coupling of the COVID-19 infodemic with the official\nbulletins related to COVID-19 at the national and state level in India. We look\nat these two sources with a psycho-linguistic lens of emotions and quantified\nthe extent and coupling between the two. We modified path, a deep skip-gram\nbased open-sourced lexicon builder for effective capture of health-related\nemotions. We were then able to capture the time-evolution of health-related\nemotions in social media and official bulletins. An analysis of lead-lag\nrelationships between the time series of extracted emotions from official\nbulletins and social media using Granger's causality showed that state\nbulletins were leading the social media for some emotions such as Medical\nEmergency. Further insights that are potentially relevant for the policymaker\nand the communicators actively engaged in mitigating misinformation are also\ndiscussed. Our paper also introduces CoronaIndiaDataset2, the first social\nmedia based COVID-19 dataset at national and state levels from India with over\n5.6 million national and 2.6 million state-level tweets. Finally, we present\nour findings as COVibes, an interactive web application capturing psychometric\ninsights captured upon the CoronaIndiaDataset, both at a national and state\nlevel.", "author": [{"name": "Baani Leen Kaur Jolly"}, {"name": "Palash Aggrawal"}, {"name": "Amogh Gulati"}, {"name": "Amarjit Singh Sethi"}, {"name": "Ponnurangam Kumaraguru"}, {"name": "Tavpritesh Sethi"}], "link": [{"@href": "http://arxiv.org/abs/2005.05513v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.05513v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.05701v1", "updated": "2020-08-13T05:53:24Z", "published": "2020-08-13T05:53:24Z", "title": "The COVID-19 Infodemic: Can the Crowd Judge Recent Misinformation\n  Objectively?", "summary": "Misinformation is an ever increasing problem that is difficult to solve for\nthe research community and has a negative impact on the society at large. Very\nrecently, the problem has been addressed with a crowdsourcing-based approach to\nscale up labeling efforts: to assess the truthfulness of a statement, instead\nof relying on a few experts, a crowd of (non-expert) judges is exploited. We\nfollow the same approach to study whether crowdsourcing is an effective and\nreliable method to assess statements truthfulness during a pandemic. We\nspecifically target statements related to the COVID-19 health emergency, that\nis still ongoing at the time of the study and has arguably caused an increase\nof the amount of misinformation that is spreading online (a phenomenon for\nwhich the term \"infodemic\" has been used). By doing so, we are able to address\n(mis)information that is both related to a sensitive and personal issue like\nhealth and very recent as compared to when the judgment is done: two issues\nthat have not been analyzed in related work. In our experiment, crowd workers\nare asked to assess the truthfulness of statements, as well as to provide\nevidence for the assessments as a URL and a text justification. Besides showing\nthat the crowd is able to accurately judge the truthfulness of the statements,\nwe also report results on many different aspects, including: agreement among\nworkers, the effect of different aggregation functions, of scales\ntransformations, and of workers background / bias. We also analyze workers\nbehavior, in terms of queries submitted, URLs found / selected, text\njustifications, and other behavioral data like clicks and mouse actions\ncollected by means of an ad hoc logger.", "author": [{"name": "Kevin Roitero"}, {"name": "Michael Soprano"}, {"name": "Beatrice Portelli"}, {"name": "Damiano Spina"}, {"name": "Vincenzo Della Mea"}, {"name": "Giuseppe Serra"}, {"name": "Stefano Mizzaro"}, {"name": "Gianluca Demartini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3340531.3412048"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3340531.3412048", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.05701v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.05701v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages; Preprint of the full paper accepted at CIKM 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68P20", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.11824v5", "updated": "2021-05-23T04:56:44Z", "published": "2021-01-28T05:45:01Z", "title": "Exploring Lightweight Interventions at Posting Time to Reduce the\n  Sharing of Misinformation on Social Media", "summary": "When users on social media share content without considering its veracity,\nthey may unwittingly be spreading misinformation. In this work, we investigate\nthe design of lightweight interventions that nudge users to assess the accuracy\nof information as they share it. Such assessment may deter users from posting\nmisinformation in the first place, and their assessments may also provide\nuseful guidance to friends aiming to assess those posts themselves. In support\nof lightweight assessment, we first develop a taxonomy of the reasons why\npeople believe a news claim is or is not true; this taxonomy yields a checklist\nthat can be used at posting time. We conduct evaluations to demonstrate that\nthe checklist is an accurate and comprehensive encapsulation of people's\nfree-response rationales. In a second experiment, we study the effects of three\nbehavioral nudges -- 1) checkboxes indicating whether headings are accurate, 2)\ntagging reasons (from our taxonomy) that a post is accurate via a checklist and\n3) providing free-text rationales for why a headline is or is not accurate --\non people's intention of sharing the headline on social media. From an\nexperiment with 1668 participants, we find that both providing accuracy\nassessment and rationale reduce the sharing of false content. They also reduce\nthe sharing of true content, but to a lesser degree that yields an overall\ndecrease in the fraction of shared content that is false. Our findings have\nimplications for designing social media and news sharing platforms that draw\nfrom richer signals of content credibility contributed by users. In addition,\nour validated taxonomy can be used by platforms and researchers as a way to\ngather rationales in an easier fashion than free-response.", "author": [{"name": "Farnaz Jahanbakhsh"}, {"name": "Amy X. Zhang"}, {"name": "Adam J. Berinsky"}, {"name": "Gordon Pennycook"}, {"name": "David G. Rand"}, {"name": "David R. Karger"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3449092"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3449092", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2101.11824v5", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.11824v5", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In CSCW'21"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proc. ACM Hum.-Comput. Interact., Vol. 5, No. CSCW1, Article 18.\n  Publication date: April 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.5.3; J.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.02828v1", "updated": "2021-07-06T18:20:38Z", "published": "2021-07-06T18:20:38Z", "title": "Cognitive Contagion: How to model (and potentially counter) the spread\n  of fake news", "summary": "Understanding the spread of false or dangerous beliefs - so-called\nmis/disinformation - through a population has never seemed so urgent to many.\nNetwork science researchers have often taken a page from epidemiologists, and\nmodeled the spread of false beliefs as similar to how a disease spreads through\na social network. However, absent from those disease-inspired models is an\ninternal model of an individual's set of current beliefs, where cognitive\nscience has increasingly documented how the interaction between mental models\nand incoming messages seems to be crucially important for their adoption or\nrejection. We introduce a cognitive contagion model that combines a network\nscience approach with an internal cognitive model of the individual agents,\naffecting what they believe, and what they pass on. We show that the model,\neven with a very discrete and simplistic belief function to capture cognitive\ndissonance, both adds expressive power over existing disease-based contagion\nmodels, and qualitatively demonstrates the appropriate belief update phenomena\nat the individual level. Moreover, we situate our cognitive contagion model in\na larger public opinion diffusion model, which attempts to capture the role of\ninstitutions or media sources in belief diffusion - something that is often\nleft out. We conduct an analysis of the POD model with our simple cognitive\ndissonance-sensitive update function across various graph topologies and\ninstitutional messaging patterns. We demonstrate that population-level\naggregate outcomes of the model qualitatively match what has been reported in\nCOVID misinformation public opinion polls. The overall model sets up a\npreliminary framework with which social science misinformation researchers and\ncomputational opinion diffusion modelers can join forces to understand, and\nhopefully learn how to best counter, the spread of misinformation and\n\"alternative facts.\"", "author": [{"name": "Nicholas Rabb"}, {"name": "Lenore Cowen"}, {"name": "Jan P. de Ruiter"}, {"name": "Matthias Scheutz"}], "link": [{"@href": "http://arxiv.org/abs/2107.02828v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.02828v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/physics/0603218v1", "updated": "2006-03-26T08:07:32Z", "published": "2006-03-26T08:07:32Z", "title": "Self-Assembly of Information in Networks", "summary": "We model self-assembly of information in networks to investigate necessary\nconditions for building a global perception of a system by local communication.\nOur approach is to let agents chat in a model system to self-organize distant\ncommunication-pathways. We demonstrate that simple local rules allow agents to\nbuild a perception of the system, that is robust to dynamical changes and\nmistakes. We find that messages are most effectively forwarded in the presence\nof hubs, while transmission in hub-free networks is more robust against\nmisinformation and failures.", "author": [{"name": "M. Rosvall"}, {"name": "K. Sneppen"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1209/epl/i2006-10064-2"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1209/epl/i2006-10064-2", "@rel": "related"}, {"@href": "http://arxiv.org/abs/physics/0603218v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/physics/0603218v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "4 pages and 4 figures, Java simulation available at\n  http://cmol.nbi.dk/models/infoflow/infoflow.html"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Europhys. Lett., 74, 1109-1115 (2006)."}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cond-mat.dis-nn", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.00715v1", "updated": "2017-10-31T18:52:28Z", "published": "2017-10-31T18:52:28Z", "title": "Related Fact Checks: a tool for combating fake news", "summary": "The emergence of \"Fake News\" and misinformation via online news and social\nmedia has spurred an interest in computational tools to combat this phenomenon.\nIn this paper we present a new \"Related Fact Checks\" service, which can help a\nreader critically evaluate an article and make a judgment on its veracity by\nbringing up fact checks that are relevant to the article. We describe the core\ntechnical problems that need to be solved in building a \"Related Fact Checks\"\nservice, and present results from an evaluation of an implementation.", "author": {"name": "Sreya Guha"}, "link": [{"@href": "http://arxiv.org/abs/1711.00715v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.00715v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1804.03508v1", "updated": "2018-03-31T09:48:20Z", "published": "2018-03-31T09:48:20Z", "title": "Seeing Through Misinformation: A Framework for Identifying Fake Online\n  News", "summary": "The fake news epidemic makes it imperative to develop a diagnostic framework\nthat is both parsimonious and valid to guide present and future efforts in fake\nnews detection. This paper represents one of the very first attempts to fill a\nvoid in the research on this topic. The LeSiE (Lexical Structure, Simplicity,\nEmotion) framework we created and validated allows lay people to identify\npotential fake news without the use of calculators or complex statistics by\nlooking out for three simple cues.", "author": [{"name": "Murphy Choy"}, {"name": "Mark Chong"}], "link": [{"@href": "http://arxiv.org/abs/1804.03508v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.03508v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1804.06196v1", "updated": "2018-04-17T12:25:39Z", "published": "2018-04-17T12:25:39Z", "title": "Demystifying Deception Technology:A Survey", "summary": "Deception boosts security for systems and components by denial, deceit,\nmisinformation, camouflage and obfuscation. In this work an extensive overview\nof the deception technology environment is presented. Taxonomies, theoretical\nbackgrounds, psychological aspects as well as concepts, implementations, legal\naspects and ethics are discussed and compared.", "author": [{"name": "Daniel Fraunholz"}, {"name": "Simon Duque Anton"}, {"name": "Christoph Lipps"}, {"name": "Daniel Reti"}, {"name": "Daniel Krohmer"}, {"name": "Frederic Pohl"}, {"name": "Matthias Tammen"}, {"name": "Hans Dieter Schotten"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "25 pages, 169 references"}, "link": [{"@href": "http://arxiv.org/abs/1804.06196v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.06196v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1903.01780v1", "updated": "2019-03-05T12:10:11Z", "published": "2019-03-05T12:10:11Z", "title": "Trust and Trustworthiness in Social Recommender Systems", "summary": "The prevalence of misinformation on online social media has tangible\nempirical connections to increasing political polarization and partisan\nantipathy in the United States. Ranking algorithms for social recommendation\noften encode broad assumptions about network structure (like homophily) and\ngroup cognition (like, social action is largely imitative). Assumptions like\nthese can be na\\\"ive and exclusionary in the era of fake news and ideological\nuniformity towards the political poles. We examine these assumptions with aid\nfrom the user-centric framework of trustworthiness in social recommendation.\nThe constituent dimensions of trustworthiness (diversity, transparency,\nexplainability, disruption) highlight new opportunities for discouraging\ndogmatization and building decision-aware, transparent news recommender\nsystems.", "author": [{"name": "Taha Hassan"}, {"name": "D. Scott McCrickard"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "WWW '19 FATES"}, "link": [{"@href": "http://arxiv.org/abs/1903.01780v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.01780v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.01546v1", "updated": "2019-04-02T17:01:25Z", "published": "2019-04-02T17:01:25Z", "title": "NELA-GT-2018: A Large Multi-Labelled News Dataset for The Study of\n  Misinformation in News Articles", "summary": "In this paper, we present a dataset of 713k articles collected between\n02/2018-11/2018. These articles are collected directly from 194 news and media\noutlets including mainstream, hyper-partisan, and conspiracy sources. We\nincorporate ground truth ratings of the sources from 8 different assessment\nsites covering multiple dimensions of veracity, including reliability, bias,\ntransparency, adherence to journalistic standards, and consumer trust. The\nNELA-GT-2018 dataset can be found at https://doi.org/10.7910/DVN/ULHLCB.", "author": [{"name": "Jeppe Norregaard"}, {"name": "Benjamin D. Horne"}, {"name": "Sibel Adali"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at ICWSM 2019"}, "link": [{"@href": "http://arxiv.org/abs/1904.01546v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.01546v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1909.05838v1", "updated": "2019-09-12T17:44:15Z", "published": "2019-09-12T17:44:15Z", "title": "Multilingual Multimodal Digital Deception Detection and Disinformation\n  Spread across Social Platforms", "summary": "Our main contribution in this work is novel results of multilingual models\nthat go beyond typical applications of rumor or misinformation detection in\nEnglish social news content to identify fine-grained classes of digital\ndeception across multiple languages (e.g. Russian, Spanish, etc.). In addition,\nwe present models for multimodal deception detection from images and text and\ndiscuss the limitations of image only and text only models. Finally, we\nelaborate on the ongoing work on measuring deceptive content (in particular\ndisinformation) spread across social platforms.", "author": [{"name": "Maria Glenski"}, {"name": "Ellyn Ayton"}, {"name": "Josh Mendoza"}, {"name": "Svitlana Volkova"}], "link": [{"@href": "http://arxiv.org/abs/1909.05838v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.05838v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2003.06634v1", "updated": "2020-03-14T14:02:27Z", "published": "2020-03-14T14:02:27Z", "title": "Text Similarity Using Word Embeddings to Classify Misinformation", "summary": "Fake news is a growing problem in the last years, especially during\nelections. It's hard work to identify what is true and what is false among all\nthe user generated content that circulates every day. Technology can help with\nthat work and optimize the fact-checking process. In this work, we address the\nchallenge of finding similar content in order to be able to suggest to a\nfact-checker articles that could have been verified before and thus avoid that\nthe same information is verified more than once. This is especially important\nin collaborative approaches to fact-checking where members of large teams will\nnot know what content others have already fact-checked.", "author": [{"name": "Caio Almeida"}, {"name": "D\u00e9bora Santos"}], "link": [{"@href": "http://arxiv.org/abs/2003.06634v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.06634v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2007.03611v1", "updated": "2020-07-06T03:18:54Z", "published": "2020-07-06T03:18:54Z", "title": "P-Values in a Post-Truth World", "summary": "The role of statisticians in society is to provide tools, techniques, and\nguidance with regards to how much to trust data. This role is increasingly more\nimportant with more data and more misinformation than ever before. The American\nStatistical Association recently released two statements on p-values, and\nprovided four guiding principles. We evaluate their claims using these\nprinciples and find that they failed to adhere to them. In this age of\ndistrust, we have an opportunity to be role models of trustworthiness, and\nresponsibility to take it.", "author": {"name": "Joshua T. Vogelstein"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages"}, "link": [{"@href": "http://arxiv.org/abs/2007.03611v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.03611v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.OT", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.07989v1", "updated": "2020-12-14T22:40:49Z", "published": "2020-12-14T22:40:49Z", "title": "The Emerging Threats of Deepfake Attacks and Countermeasures", "summary": "Deepfake technology (DT) has taken a new level of sophistication.\nCybercriminals now can manipulate sounds, images, and videos to defraud and\nmisinform individuals and businesses. This represents a growing threat to\ninternational institutions and individuals which needs to be addressed. This\npaper provides an overview of deepfakes, their benefits to society, and how DT\nworks. Highlights the threats that are presented by deepfakes to businesses,\npolitics, and judicial systems worldwide. Additionally, the paper will explore\npotential solutions to deepfakes and conclude with future research direction.", "author": {"name": "Shadrack Awah Buo"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.13140/RG.2.2.23089.81762"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.13140/RG.2.2.23089.81762", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2012.07989v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.07989v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.07198v1", "updated": "2021-02-14T17:09:08Z", "published": "2021-02-14T17:09:08Z", "title": "How Misuse of Statistics Can Spread Misinformation: A Study of\n  Misrepresentation of COVID-19 Data", "summary": "This paper investigates various ways in which a pandemic such as the novel\ncoronavirus, could be predicted using different mathematical models. It also\nstudies the various ways in which these models could be depicted using various\nvisualization techniques. This paper aims to present various statistical\ntechniques suggested by the Centres for Disease Control and Prevention in order\nto represent the epidemiological data. The main focus of this paper is to\nanalyse how epidemiological data or contagious diseases are theorized using any\navailable information and later may be presented wrongly by not following the\nguidelines, leading to inaccurate representation and interpretations of the\ncurrent scenario of the pandemic; with a special reference to the Indian\nSubcontinent.", "author": [{"name": "Shailesh Bharati"}, {"name": "Rahul Batra"}], "link": [{"@href": "http://arxiv.org/abs/2102.07198v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.07198v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.12918v1", "updated": "2021-04-27T00:21:55Z", "published": "2021-04-27T00:21:55Z", "title": "Extractive and Abstractive Explanations for Fact-Checking and Evaluation\n  of News", "summary": "In this paper, we explore the construction of natural language explanations\nfor news claims, with the goal of assisting fact-checking and news evaluation\napplications. We experiment with two methods: (1) an extractive method based on\nBiased TextRank -- a resource-effective unsupervised graph-based algorithm for\ncontent extraction; and (2) an abstractive method based on the GPT-2 language\nmodel. We perform comparative evaluations on two misinformation datasets in the\npolitical and health news domains, and find that the extractive method shows\nthe most promise.", "author": [{"name": "Ashkan Kazemi"}, {"name": "Zehua Li"}, {"name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"name": "Rada Mihalcea"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to NLP for Internet Freedom Workshop at NAACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.12918v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.12918v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.13754v1", "updated": "2021-04-28T13:35:28Z", "published": "2021-04-28T13:35:28Z", "title": "Can the Wikipedia moderation model rescue the social marketplace of\n  ideas?", "summary": "Facebook announced a community review program in December 2019 and Twitter\nlaunched a community-based platform to address misinformation, called\nBirdwatch, in January 2021. We provide an overview of the potential affordances\nof such community based approaches to content moderation based on past\nresearch. While our analysis generally supports a community-based approach to\ncontent moderation, it also warns against potential pitfalls, particularly when\nthe implementation of the new infrastructures does not promote diversity. We\ncall for more multidisciplinary research utilizing methods from complex systems\nstudies, behavioural sociology, and computational social science to advance the\nresearch on crowd-based content moderation.", "author": [{"name": "Taha Yasseri"}, {"name": "Filippo Menczer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Under Review"}, "link": [{"@href": "http://arxiv.org/abs/2104.13754v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13754v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.data-an", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.11896v1", "updated": "2021-08-26T16:34:51Z", "published": "2021-08-26T16:34:51Z", "title": "A Survey on Automated Fact-Checking", "summary": "Fact-checking has become increasingly important due to the speed with which\nboth information and misinformation can spread in the modern media ecosystem.\nTherefore, researchers have been exploring how fact-checking can be automated,\nusing techniques based on natural language processing, machine learning,\nknowledge representation, and databases to automatically predict the veracity\nof claims. In this paper, we survey automated fact-checking stemming from\nnatural language processing, and discuss its connections to related tasks and\ndisciplines. In this process, we present an overview of existing datasets and\nmodels, aiming to unify the various definitions given and identify common\nconcepts. Finally, we highlight challenges for future research.", "author": [{"name": "Zhijiang Guo"}, {"name": "Michael Schlichtkrull"}, {"name": "Andreas Vlachos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "27 pages, 15 pages of references"}, "link": [{"@href": "http://arxiv.org/abs/2108.11896v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.11896v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1910.00531v2", "updated": "2019-10-03T19:43:53Z", "published": "2019-10-01T16:32:59Z", "title": "On the Influence of Twitter Trolls during the 2016 US Presidential\n  Election", "summary": "It is a widely accepted fact that state-sponsored Twitter accounts operated\nduring the 2016 US presidential election spreading millions of tweets with\nmisinformation and inflammatory political content. Whether these social media\ncampaigns of the so-called \"troll\" accounts were able to manipulate public\nopinion is still in question. Here we aim to quantify the influence of troll\naccounts and the impact they had on Twitter by analyzing 152.5 million tweets\nfrom 9.9 million users, including 822 troll accounts. The data collected during\nthe US election campaign, contain original troll tweets before they were\ndeleted by Twitter. From these data, we constructed a very large interaction\ngraph; a directed graph of 9.3 million nodes and 169.9 million edges. Recently,\nTwitter released datasets on the misinformation campaigns of 8,275\nstate-sponsored accounts linked to Russia, Iran and Venezuela as part of the\ninvestigation on the foreign interference in the 2016 US election. These data\nserve as ground-truth identifier of troll users in our dataset. Using graph\nanalysis techniques we qualify the diffusion cascades of web and media context\nthat have been shared by the troll accounts. We present strong evidence that\nauthentic users were the source of the viral cascades. Although the trolls were\nparticipating in the viral cascades, they did not have a leading role in them\nand only four troll accounts were truly influential.", "author": [{"name": "Nikos Salamanos"}, {"name": "Michael J. Jensen"}, {"name": "Xinlei He"}, {"name": "Yang Chen"}, {"name": "Michael Sirivianos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "With this version, we are correcting an error in the Acknowledgments\n  regarding the research funding that supports this work. The correct one is\n  the European Union's Horizon 2020 Research and Innovation program under the\n  Cybersecurity CONCORDIA project (Grant Agreement No. 830927)"}, "link": [{"@href": "http://arxiv.org/abs/1910.00531v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.00531v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1910.02223v1", "updated": "2019-10-05T06:48:23Z", "published": "2019-10-05T06:48:23Z", "title": "A Machine Learning Analysis of the Features in Deceptive and Credible\n  News", "summary": "Fake news is a type of pervasive propaganda that spreads misinformation\nonline, taking advantage of social media's extensive reach to manipulate public\nperception. Over the past three years, fake news has become a focal discussion\npoint in the media due to its impact on the 2016 U.S. presidential election.\nFake news can have severe real-world implications: in 2016, a man walked into a\npizzeria carrying a rifle because he read that Hillary Clinton was harboring\nchildren as sex slaves. This project presents a high accuracy (87%) machine\nlearning classifier that determines the validity of news based on the word\ndistributions and specific linguistic and stylistic differences in the first\nfew sentences of an article. This can help readers identify the validity of an\narticle by looking for specific features in the opening lines aiding them in\nmaking informed decisions. Using a dataset of 2,107 articles from 30 different\nwebsites, this project establishes an understanding of the variations between\nfake and credible news by examining the model, dataset, and features. This\nclassifier appears to use the differences in word distribution, levels of tone\nauthenticity, and frequency of adverbs, adjectives, and nouns. The\ndifferentiation in the features of these articles can be used to improve future\nclassifiers. This classifier can also be further applied directly to browsers\nas a Google Chrome extension or as a filter for social media outlets or news\nwebsites to reduce the spread of misinformation.", "author": {"name": "Qi Jia Sun"}, "link": [{"@href": "http://arxiv.org/abs/1910.02223v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.02223v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "J.5.5", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1707.03778v1", "updated": "2017-07-12T15:55:20Z", "published": "2017-07-12T15:55:20Z", "title": "Catching Zika Fever: Application of Crowdsourcing and Machine Learning\n  for Tracking Health Misinformation on Twitter", "summary": "In February 2016, World Health Organization declared the Zika outbreak a\nPublic Health Emergency of International Concern. With developing evidence it\ncan cause birth defects, and the Summer Olympics coming up in the worst\naffected country, Brazil, the virus caught fire on social media. In this work,\nuse Zika as a case study in building a tool for tracking the misinformation\naround health concerns on Twitter. We collect more than 13 million tweets --\nspanning the initial reports in February 2016 and the Summer Olympics --\nregarding the Zika outbreak and track rumors outlined by the World Health\nOrganization and Snopes fact checking website. The tool pipeline, which\nincorporates health professionals, crowdsourcing, and machine learning, allows\nus to capture health-related rumors around the world, as well as clarification\ncampaigns by reputable health organizations. In the case of Zika, we discover\nan extremely bursty behavior of rumor-related topics, and show that, once the\nquestionable topic is detected, it is possible to identify rumor-bearing tweets\nusing automated techniques. Thus, we illustrate insights the proposed tools\nprovide into potentially harmful information on social media, allowing public\nhealth researchers and practitioners to respond with a targeted and timely\naction.", "author": [{"name": "Amira Ghenai"}, {"name": "Yelena Mejova"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 7 figures, short version to be published in the Fifth IEEE\n  International Conference on Healthcare Informatics (ICHI 2017)"}, "link": [{"@href": "http://arxiv.org/abs/1707.03778v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1707.03778v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68P20", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8; H.3.3; I.2.7; J.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1808.05927v1", "updated": "2018-08-17T16:47:52Z", "published": "2018-08-17T16:47:52Z", "title": "Characterizing the public perception of WhatsApp through the lens of\n  media", "summary": "WhatsApp is, as of 2018, a significant component of the global information\nand communication infrastructure, especially in developing countries. However,\nprobably due to its strong end-to-end encryption, WhatsApp became an attractive\nplace for the dissemination of misinformation, extremism and other forms of\nundesirable behavior. In this paper, we investigate the public perception of\nWhatsApp through the lens of media. We analyze two large datasets of news and\nshow the kind of content that is being associated with WhatsApp in different\nregions of the world and over time. Our analyses include the examination of\nnamed entities, general vocabulary, and topics addressed in news articles that\nmention WhatsApp, as well as the polarity of these texts. Among other results,\nwe demonstrate that the vocabulary and topics around the term \"whatsapp\" in the\nmedia have been changing over the years and in 2018 concentrate on matters\nrelated to misinformation, politics and criminal scams. More generally, our\nfindings are useful to understand the impact that tools like WhatsApp play in\nthe contemporary society and how they are seen by the communities themselves.", "author": [{"name": "Josemar Alves Caetano"}, {"name": "Gabriel Magno"}, {"name": "Evandro Cunha"}, {"name": "Wagner Meira Jr."}, {"name": "Humberto T. Marques-Neto"}, {"name": "Virgilio Almeida"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted as a full paper at the 2nd International Workshop on Rumours\n  and Deception in Social Media (RDSM 2018), co-located with CIKM 2018 in\n  Turin. Please cite the RDSM version"}, "link": [{"@href": "http://arxiv.org/abs/1808.05927v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.05927v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1812.03533v1", "updated": "2018-12-09T17:53:08Z", "published": "2018-12-09T17:53:08Z", "title": "Propagation from Deceptive News Sources: Who Shares, How Much, How\n  Evenly, and How Quickly?", "summary": "As people rely on social media as their primary sources of news, the spread\nof misinformation has become a significant concern. In this large-scale study\nof news in social media we analyze eleven million posts and investigate\npropagation behavior of users that directly interact with news accounts\nidentified as spreading trusted versus malicious content. Unlike previous work,\nwhich looks at specific rumors, topics, or events, we consider all content\npropagated by various news sources. Moreover, we analyze and contrast\npopulation versus sub-population behaviour (by demographics) when spreading\nmisinformation, and distinguish between two types of propagation, i.e., direct\nretweets and mentions. Our evaluation examines how evenly, how many, how\nquickly, and which users propagate content from various types of news sources\non Twitter.\n  Our analysis has identified several key differences in propagation behavior\nfrom trusted versus suspicious news sources. These include high inequity in the\ndiffusion rate based on the source of disinformation, with a small group of\nhighly active users responsible for the majority of disinformation spread\noverall and within each demographic. Analysis by demographics showed that users\nwith lower annual income and education share more from disinformation sources\ncompared to their counterparts. News content is shared significantly more\nquickly from trusted, conspiracy, and disinformation sources compared to\nclickbait and propaganda. Older users propagate news from trusted sources more\nquickly than younger users, but they share from suspicious sources after longer\ndelays. Finally, users who interact with clickbait and conspiracy sources are\nlikely to share from propaganda accounts, but not the other way around.", "author": [{"name": "Maria Glenski"}, {"name": "Tim Weninger"}, {"name": "Svitlana Volkova"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/TCSS.2018.2881071"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/TCSS.2018.2881071", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1812.03533v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.03533v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages, 6 figures, 7 tables, published in IEEE TCSS December 2018"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IEEE Transactions on Computational Social Systems ( Volume: 5 ,\n  Issue: 4 , Dec. 2018 )"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1812.10508v1", "updated": "2018-12-26T19:31:32Z", "published": "2018-12-26T19:31:32Z", "title": "A blockchain based Secure and Trusted framework for Information\n  Propagation on Online Social Networks", "summary": "The online social networks facilitate naturally for the users to share\ninformation. On these platforms, each user shares information based on his or\nher interests. The particular information being shared by a user may be\nlegitimate or fake. Sometimes a misinformation, propagated by users and group\ncan create chaos or in some cases, might leads to cases of riots. Nowadays the\nthird party like ALT news and Cobrapost check the information authenticity, but\nit takes too much time to validate the news. Therefore, a robust and new system\nis required to check the information authenticity within the network, to stop\nthe propagation of misinformation. In this paper, we propose a blockchain based\nframework for sharing the information securely at the peer level. In the\nblockchain model, a chain is created by combining blocks of information. Each\nnode of network propagates the information based on its credibility to its peer\nnodes. The credibility of a node will vary according to the respective\ninformation. Trust is calculated between sender and receiver in two ways:(i)\nLocal trust used for sharing information at the peer level and (ii) global\ntrust is used for a credibility check of each user in the network. We evaluate\nour framework using real dataset derived from Facebook. Our approach achieves\nan accuracy of 83% which shows the effectiveness of our proposed framework.", "author": [{"name": "Md Arquam"}, {"name": "Anurag Singh"}, {"name": "Rajesh Sharma"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/s13278-021-00754-y"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/s13278-021-00754-y", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1812.10508v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.10508v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Social Network Analysis and Mining volume 11, Article number: 49\n  (2021)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1905.05305v1", "updated": "2019-05-13T22:27:59Z", "published": "2019-05-13T22:27:59Z", "title": "Consequential Ranking Algorithms and Long-term Welfare", "summary": "Ranking models are typically designed to provide rankings that optimize some\nmeasure of immediate utility to the users. As a result, they have been unable\nto anticipate an increasing number of undesirable long-term consequences of\ntheir proposed rankings, from fueling the spread of misinformation and\nincreasing polarization to degrading social discourse. Can we design ranking\nmodels that understand the consequences of their proposed rankings and, more\nimportantly, are able to avoid the undesirable ones? In this paper, we first\nintroduce a joint representation of rankings and user dynamics using Markov\ndecision processes. Then, we show that this representation greatly simplifies\nthe construction of consequential ranking models that trade off the immediate\nutility and the long-term welfare. In particular, we can obtain optimal\nconsequential rankings just by applying weighted sampling on the rankings\nprovided by models that maximize measures of immediate utility. However, in\npractice, such a strategy may be inefficient and impractical, specially in high\ndimensional scenarios. To overcome this, we introduce an efficient\ngradient-based algorithm to learn parameterized consequential ranking models\nthat effectively approximate optimal ones. We showcase our methodology using\nsynthetic and real data gathered from Reddit and show that ranking models\nderived using our methodology provide ranks that may mitigate the spread of\nmisinformation and improve the civility of online discussions.", "author": [{"name": "Behzad Tabibian"}, {"name": "Vicen\u00e7 G\u00f3mez"}, {"name": "Abir De"}, {"name": "Bernhard Sch\u00f6lkopf"}, {"name": "Manuel Gomez Rodriguez"}], "link": [{"@href": "http://arxiv.org/abs/1905.05305v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.05305v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.10130v1", "updated": "2019-11-22T16:35:37Z", "published": "2019-11-22T16:35:37Z", "title": "A Data Set of Internet Claims and Comparison of their Sentiments with\n  Credibility", "summary": "In this modern era, communication has become faster and easier. This means\nfallacious information can spread as fast as reality. Considering the damage\nthat fake news kindles on the psychology of people and the fact that such news\nproliferates faster than truth, we need to study the phenomenon that helps\nspread fake news. An unbiased data set that depends on reality for rating news\nis necessary to construct predictive models for its classification. This paper\ndescribes the methodology to create such a data set. We collect our data from\nsnopes.com which is a fact-checking organization. Furthermore, we intend to\ncreate this data set not only for classification of the news but also to find\npatterns that reason the intent behind misinformation. We also formally define\nan Internet Claim, its credibility, and the sentiment behind such a claim. We\ntry to realize the relationship between the sentiment of a claim with its\ncredibility. This relationship pours light on the bigger picture behind the\npropagation of misinformation. We pave the way for further research based on\nthe methodology described in this paper to create the data set and usage of\npredictive modeling along with research-based on psychology/mentality of people\nto understand why fake news spreads much faster than reality.", "author": [{"name": "Amey Parundekar"}, {"name": "Susan Elias"}, {"name": "Ashwin Ashok"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 6 figures, A paper accepted at the Truth Discovery and Fact\n  Checking: Theory and Practice SIGKDD 2019 Workshop, August 5th, Anchorage,\n  Alaska"}, "link": [{"@href": "http://arxiv.org/abs/1911.10130v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.10130v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3.3, I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3.3; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.04624v1", "updated": "2020-01-14T04:50:47Z", "published": "2020-01-14T04:50:47Z", "title": "A Feature-Driven Approach for Identifying Pathogenic Social Media\n  Accounts", "summary": "Over the past few years, we have observed different media outlets' attempts\nto shift public opinion by framing information to support a narrative that\nfacilitate their goals. Malicious users referred to as \"pathogenic social\nmedia\" (PSM) accounts are more likely to amplify this phenomena by spreading\nmisinformation to viral proportions. Understanding the spread of misinformation\nfrom account-level perspective is thus a pressing problem. In this work, we aim\nto present a feature-driven approach to detect PSM accounts in social media.\nInspired by the literature, we set out to assess PSMs from three broad\nperspectives: (1) user-related information (e.g., user activity, profile\ncharacteristics), (2) source-related information (i.e., information linked via\nURLs shared by users) and (3) content-related information (e.g., tweets\ncharacteristics). For the user-related information, we investigate malicious\nsignals using causality analysis (i.e., if user is frequently a cause of viral\ncascades) and profile characteristics (e.g., number of followers, etc.). For\nthe source-related information, we explore various malicious properties linked\nto URLs (e.g., URL address, content of the associated website, etc.). Finally,\nfor the content-related information, we examine attributes (e.g., number of\nhashtags, suspicious hashtags, etc.) from tweets posted by users. Experiments\non real-world Twitter data from different countries demonstrate the\neffectiveness of the proposed approach in identifying PSM users.", "author": [{"name": "Hamidreza Alvari"}, {"name": "Ghazaleh Beigi"}, {"name": "Soumajyoti Sarkar"}, {"name": "Scott W. Ruston"}, {"name": "Steven R. Corman"}, {"name": "Hasan Davulcu"}, {"name": "Paulo Shakarian"}], "link": [{"@href": "http://arxiv.org/abs/2001.04624v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.04624v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2001.09473v1", "updated": "2020-01-26T15:42:43Z", "published": "2020-01-26T15:42:43Z", "title": "Information Credibility in the Social Web: Contexts, Approaches, and\n  Open Issues", "summary": "In the Social Web scenario, large amounts of User-Generated Content (UGC) are\ndiffused through social media often without almost any form of traditional\ntrusted intermediaries. Therefore, the risk of running into misinformation is\nnot negligible. For this reason, assessing and mining the credibility of online\ninformation constitutes nowadays a fundamental research issue. Credibility,\nalso referred as believability, is a quality perceived by individuals, who are\nnot always able to discern, with their own cognitive capacities, genuine\ninformation from fake one. Hence, in the last years, several approaches have\nbeen proposed to automatically assess credibility in social media. Many of them\nare based on data-driven models, i.e., they employ machine learning techniques\nto identify misinformation, but recently also model-driven approaches are\nemerging, as well as graph-based approaches focusing on credibility\npropagation, and knowledge-based ones exploiting Semantic Web technologies.\nThree of the main contexts in which the assessment of information credibility\nhas been investigated concern: (i) the detection of opinion spam in review\nsites, (ii) the detection of fake news in microblogging, and (iii) the\ncredibility assessment of online health-related information. In this article,\nthe main issues connected to the evaluation of information credibility in the\nSocial Web, which are shared by the above-mentioned contexts, are discussed. A\nconcise survey of the approaches and methodologies that have been proposed in\nrecent years to address these issues is also presented.", "author": [{"name": "Gabriella Pasi"}, {"name": "Marco Viviani"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Article accepted and presented at ITASEC 2020: Italian Conference on\n  Cybersecurity. February 4-7, 2020, Ancona, Italy. https://itasec.it/"}, "link": [{"@href": "http://arxiv.org/abs/2001.09473v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.09473v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.07111v1", "updated": "2020-02-17T18:13:09Z", "published": "2020-02-17T18:13:09Z", "title": "Targeted Forgetting and False Memory Formation in Continual Learners\n  through Adversarial Backdoor Attacks", "summary": "Artificial neural networks are well-known to be susceptible to catastrophic\nforgetting when continually learning from sequences of tasks. Various continual\n(or \"incremental\") learning approaches have been proposed to avoid catastrophic\nforgetting, but they are typically adversary agnostic, i.e., they do not\nconsider the possibility of a malicious attack. In this effort, we explore the\nvulnerability of Elastic Weight Consolidation (EWC), a popular continual\nlearning algorithm for avoiding catastrophic forgetting. We show that an\nintelligent adversary can bypass the EWC's defenses, and instead cause gradual\nand deliberate forgetting by introducing small amounts of misinformation to the\nmodel during training. We demonstrate such an adversary's ability to assume\ncontrol of the model via injection of \"backdoor\" attack samples on both\npermuted and split benchmark variants of the MNIST dataset. Importantly, once\nthe model has learned the adversarial misinformation, the adversary can then\ncontrol the amount of forgetting of any task. Equivalently, the malicious actor\ncan create a \"false memory\" about any task by inserting carefully-designed\nbackdoor samples to any fraction of the test instances of that task. Perhaps\nmost damaging, we show this vulnerability to be very acute; neural network\nmemory can be easily compromised with the addition of backdoor samples into as\nlittle as 1% of the training data of even a single task.", "author": [{"name": "Muhammad Umer"}, {"name": "Glenn Dawson"}, {"name": "Robi Polikar"}], "link": [{"@href": "http://arxiv.org/abs/2002.07111v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.07111v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.05096v1", "updated": "2020-03-11T03:16:04Z", "published": "2020-03-11T03:16:04Z", "title": "Exploring the Role of Visual Content in Fake News Detection", "summary": "The increasing popularity of social media promotes the proliferation of fake\nnews, which has caused significant negative societal effects. Therefore, fake\nnews detection on social media has recently become an emerging research area of\ngreat concern. With the development of multimedia technology, fake news\nattempts to utilize multimedia content with images or videos to attract and\nmislead consumers for rapid dissemination, which makes visual content an\nimportant part of fake news. Despite the importance of visual content, our\nunderstanding of the role of visual content in fake news detection is still\nlimited. This chapter presents a comprehensive review of the visual content in\nfake news, including the basic concepts, effective visual features,\nrepresentative detection methods and challenging issues of multimedia fake news\ndetection. This chapter can help readers to understand the role of visual\ncontent in fake news detection, and effectively utilize visual content to\nassist in detecting multimedia fake news.", "author": [{"name": "Juan Cao"}, {"name": "Peng Qi"}, {"name": "Qiang Sheng"}, {"name": "Tianyun Yang"}, {"name": "Junbo Guo"}, {"name": "Jintao Li"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-42699-6"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-42699-6", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.05096v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.05096v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a preprint of a chapter published in Disinformation,\n  Misinformation, and Fake News in Social Media: Emerging Research Challenges\n  and Opportunities, edited by Kai, S., Suhang, W., Dongwon, L., Huan, L, 2020,\n  Springer reproduced with permission of Springer Nature Switzerland AG. The\n  final authenticated version is available online at:\n  https://www.springer.com/gp/book/9783030426989. arXiv admin note: text\n  overlap with arXiv:2001.00623, arXiv:1808.06686, arXiv:1903.00788 by other\n  authors"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Disinformation, Misinformation, and Fake News in Social Media.\n  2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.08377v2", "updated": "2020-04-09T13:24:29Z", "published": "2020-03-18T17:54:46Z", "title": "Network disruption: maximizing disagreement and polarization in social\n  networks", "summary": "Recent years have seen a marked increase in the spread of misinformation, a\nphenomenon which has been accelerated and amplified by social media such as\nFacebook and Twitter. While some actors spread misinformation to push a\nspecific agenda, it has also been widely documented that others aim to simply\ndisrupt the network by increasing disagreement and polarization across the\nnetwork and thereby destabilizing society. Popular social networks are also\nvulnerable to large-scale attacks. Motivated by this reality, we introduce a\nsimple model of network disruption where an adversary can take over a limited\nnumber of user profiles in a social network with the aim of maximizing\ndisagreement and/or polarization in the network.\n  We investigate this model both theoretically and empirically. We show that\nthe adversary will always change the opinion of a taken-over profile to an\nextreme in order to maximize disruption. We also prove that an adversary can\nincrease disagreement / polarization at most linearly in the number of user\nprofiles it takes over. Furthermore, we present a detailed empirical study of\nseveral natural algorithms for the adversary on both synthetic networks and\nreal world (Reddit and Twitter) data sets. These show that even simple,\nunsophisticated heuristics, such as targeting centrists, can disrupt a network\neffectively, causing a large increase in disagreement / polarization. Studying\nthe problem of network disruption through the lens of an adversary thus\nhighlights the seriousness of the problem.", "author": [{"name": "Mayee F. Chen"}, {"name": "Miklos Z. Racz"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "20 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/2003.08377v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.08377v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.11459v1", "updated": "2020-03-23T23:43:02Z", "published": "2020-03-23T23:43:02Z", "title": "BaitWatcher: A lightweight web interface for the detection of\n  incongruent news headlines", "summary": "In digital environments where substantial amounts of information are shared\nonline, news headlines play essential roles in the selection and diffusion of\nnews articles. Some news articles attract audience attention by showing\nexaggerated or misleading headlines. This study addresses the \\textit{headline\nincongruity} problem, in which a news headline makes claims that are either\nunrelated or opposite to the contents of the corresponding article. We present\n\\textit{BaitWatcher}, which is a lightweight web interface that guides readers\nin estimating the likelihood of incongruence in news articles before clicking\non the headlines. BaitWatcher utilizes a hierarchical recurrent encoder that\nefficiently learns complex textual representations of a news headline and its\nassociated body text. For training the model, we construct a million scale\ndataset of news articles, which we also release for broader research use. Based\non the results of a focus group interview, we discuss the importance of\ndeveloping an interpretable AI agent for the design of a better interface for\nmitigating the effects of online misinformation.", "author": [{"name": "Kunwoo Park"}, {"name": "Taegyun Kim"}, {"name": "Seunghyun Yoon"}, {"name": "Meeyoung Cha"}, {"name": "Kyomin Jung"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-42699-6"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-42699-6", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.11459v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.11459v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "24 pages (single column), 7 figures. This research article is\n  published as a book chapter of \\textit{Fake News, Disinformation, and\n  Misinformation in Social Media-Emerging Research Challenges and\n  Opportunities}. Springer, 2020. arXiv admin note: text overlap with\n  arXiv:1811.07066"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68U15", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.04334v3", "updated": "2020-10-04T13:28:50Z", "published": "2020-06-08T03:05:28Z", "title": "Characterizing Sociolinguistic Variation in the Competing Vaccination\n  Communities", "summary": "Public health practitioners and policy makers grapple with the challenge of\ndevising effective message-based interventions for debunking public health\nmisinformation in cyber communities. \"Framing\" and \"personalization\" of the\nmessage is one of the key features for devising a persuasive messaging\nstrategy. For an effective health communication, it is imperative to focus on\n\"preference-based framing\" where the preferences of the target sub-community\nare taken into consideration. To achieve that, it is important to understand\nand hence characterize the target sub-communities in terms of their social\ninteractions. In the context of health-related misinformation, vaccination\nremains to be the most prevalent topic of discord. Hence, in this paper, we\nconduct a sociolinguistic analysis of the two competing vaccination communities\non Twitter: \"pro-vaxxers\" or individuals who believe in the effectiveness of\nvaccinations, and \"anti-vaxxers\" or individuals who are opposed to\nvaccinations. Our data analysis show significant linguistic variation between\nthe two communities in terms of their usage of linguistic intensifiers,\npronouns, and uncertainty words. Our network-level analysis show significant\ndifferences between the two communities in terms of their network density,\necho-chamberness, and the EI index. We hypothesize that these sociolinguistic\ndifferences can be used as proxies to characterize and understand these\ncommunities to devise better message interventions.", "author": [{"name": "Shahan Ali Memon"}, {"name": "Aman Tyagi"}, {"name": "David R. Mortensen"}, {"name": "Kathleen M. Carley"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 4 tables, 1 figure, 1 algorithm, accepted to SBP-BRiMS 2020\n  -- International Conference on Social Computing, Behavioral-Cultural Modeling\n  & Prediction and Behavior Representation in Modeling and Simulation"}, "link": [{"@href": "http://arxiv.org/abs/2006.04334v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.04334v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.07996v2", "updated": "2021-04-09T08:52:10Z", "published": "2020-07-15T21:18:30Z", "title": "Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms", "summary": "With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.", "author": [{"name": "Firoj Alam"}, {"name": "Fahim Dalvi"}, {"name": "Shaden Shaar"}, {"name": "Nadir Durrani"}, {"name": "Hamdy Mubarak"}, {"name": "Alex Nikolov"}, {"name": "Giovanni Da San Martino"}, {"name": "Ahmed Abdelali"}, {"name": "Hassan Sajjad"}, {"name": "Kareem Darwish"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "COVID-19, Infodemic, Disinformation, Misinformation, Fake News, Call\n  to Arms, Crowdsourcing Annotations"}, "link": [{"@href": "http://arxiv.org/abs/2007.07996v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.07996v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.06854v1", "updated": "2020-08-16T08:06:52Z", "published": "2020-08-16T08:06:52Z", "title": "SGG: Spinbot, Grammarly and GloVe based Fake News Detection", "summary": "Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.", "author": [{"name": "Akansha Gautam"}, {"name": "Koteswar Rao Jerripothula"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 7 figures, Accepted by IEEE International Conference on\n  Multimedia Big Data (BigMM), 2020"}, "link": [{"@href": "http://arxiv.org/abs/2008.06854v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.06854v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.09533v1", "updated": "2020-08-21T15:19:18Z", "published": "2020-08-21T15:19:18Z", "title": "Investigating Differences in Crowdsourced News Credibility Assessment:\n  Raters, Tasks, and Expert Criteria", "summary": "Misinformation about critical issues such as climate change and vaccine\nsafety is oftentimes amplified on online social and search platforms. The\ncrowdsourcing of content credibility assessment by laypeople has been proposed\nas one strategy to combat misinformation by attempting to replicate the\nassessments of experts at scale. In this work, we investigate news credibility\nassessments by crowds versus experts to understand when and how ratings between\nthem differ. We gather a dataset of over 4,000 credibility assessments taken\nfrom 2 crowd groups---journalism students and Upwork workers---as well as 2\nexpert groups---journalists and scientists---on a varied set of 50 news\narticles related to climate science, a topic with widespread disconnect between\npublic opinion and expert consensus. Examining the ratings, we find differences\nin performance due to the makeup of the crowd, such as rater demographics and\npolitical leaning, as well as the scope of the tasks that the crowd is assigned\nto rate, such as the genre of the article and partisanship of the publication.\nFinally, we find differences between expert assessments due to differing expert\ncriteria that journalism versus science experts use---differences that may\ncontribute to crowd discrepancies, but that also suggest a way to reduce the\ngap by designing crowd tasks tailored to specific expert criteria. From these\nfindings, we outline future research directions to better design crowd\nprocesses that are tailored to specific crowds and types of content.", "author": [{"name": "Md Momen Bhuiyan"}, {"name": "Amy X. Zhang"}, {"name": "Connie Moon Sehat"}, {"name": "Tanushree Mitra"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3415164"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3415164", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.09533v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.09533v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2009.02931v1", "updated": "2020-09-07T08:03:21Z", "published": "2020-09-07T08:03:21Z", "title": "Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models", "summary": "While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.", "author": [{"name": "Alex Nikolov"}, {"name": "Giovanni Da San Martino"}, {"name": "Ivan Koychev"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Check-worthiness; Fact-Checking; Veracity"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF-2020"}, "link": [{"@href": "http://arxiv.org/abs/2009.02931v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.02931v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.11638v4", "updated": "2021-05-18T13:48:56Z", "published": "2020-10-22T12:20:01Z", "title": "\"It is just a flu\": Assessing the Effect of Watch History on YouTube's\n  Pseudoscientific Video Recommendations", "summary": "The role played by YouTube's recommendation algorithm in unwittingly\npromoting misinformation and conspiracy theories is not entirely understood.\nYet, this can have dire real-world consequences, especially when\npseudoscientific content is promoted to users at critical times, such as the\nCOVID-19 pandemic. In this paper, we set out to characterize and detect\npseudoscientific misinformation on YouTube. We collect 6.6K videos related to\nCOVID-19, the Flat Earth theory, as well as the anti-vaccination and anti-mask\nmovements. Using crowdsourcing, we annotate them as pseudoscience, legitimate\nscience, or irrelevant and train a deep learning classifier to detect\npseudoscientific videos with an accuracy of 0.79.\n  We quantify user exposure to this content on various parts of the platform\nand how this exposure changes based on the user's watch history. We find that\nYouTube suggests more pseudoscientific content regarding traditional\npseudoscientific topics (e.g., flat earth, anti-vaccination) than for emerging\nones (like COVID-19). At the same time, these recommendations are more common\non the search results page than on a user's homepage or in the recommendation\nsection when actively watching videos. Finally, we shed light on how a user's\nwatch history substantially affects the type of recommended videos.", "author": [{"name": "Kostantinos Papadamou"}, {"name": "Savvas Zannettou"}, {"name": "Jeremy Blackburn"}, {"name": "Emiliano De Cristofaro"}, {"name": "Gianluca Stringhini"}, {"name": "Michael Sirivianos"}], "link": [{"@href": "http://arxiv.org/abs/2010.11638v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.11638v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.09353v2", "updated": "2021-04-03T00:22:38Z", "published": "2020-12-17T02:00:43Z", "title": "The COVID-19 Infodemic: Twitter versus Facebook", "summary": "The global spread of the novel coronavirus is affected by the spread of\nrelated misinformation -- the so-called COVID-19 Infodemic -- that makes\npopulations more vulnerable to the disease through resistance to mitigation\nefforts. Here we analyze the prevalence and diffusion of links to\nlow-credibility content about the pandemic across two major social media\nplatforms, Twitter and Facebook. We characterize cross-platform similarities\nand differences in popular sources, diffusion patterns, influencers,\ncoordination, and automation. Comparing the two platforms, we find divergence\namong the prevalence of popular low-credibility sources and suspicious videos.\nA minority of accounts and pages exert a strong influence on each platform.\nThese misinformation \"superspreaders\" are often associated with the\nlow-credibility sources and tend to be verified by the platforms. On both\nplatforms, there is evidence of coordinated sharing of Infodemic content. The\novert nature of this manipulation points to the need for societal-level\nsolutions in addition to mitigation strategies within the platforms. However,\nwe highlight limits imposed by inconsistent data-access policies on our\ncapability to study harmful manipulations of information ecosystems.", "author": [{"name": "Kai-Cheng Yang"}, {"name": "Francesco Pierri"}, {"name": "Pik-Mai Hui"}, {"name": "David Axelrod"}, {"name": "Christopher Torres-Lugo"}, {"name": "John Bryden"}, {"name": "Filippo Menczer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "25 pages, 10 figures"}, "link": [{"@href": "http://arxiv.org/abs/2012.09353v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.09353v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.13968v1", "updated": "2020-12-27T16:03:32Z", "published": "2020-12-27T16:03:32Z", "title": "Detecting Medical Misinformation on Social Media Using Multimodal Deep\n  Learning", "summary": "In 2019, outbreaks of vaccine-preventable diseases reached the highest number\nin the US since 1992. Medical misinformation, such as antivaccine content\npropagating through social media, is associated with increases in vaccine delay\nand refusal. Our overall goal is to develop an automatic detector for\nantivaccine messages to counteract the negative impact that antivaccine\nmessages have on the public health. Very few extant detection systems have\nconsidered multimodality of social media posts (images, texts, and hashtags),\nand instead focus on textual components, despite the rapid growth of\nphoto-sharing applications (e.g., Instagram). As a result, existing systems are\nnot sufficient for detecting antivaccine messages with heavy visual components\n(e.g., images) posted on these newer platforms. To solve this problem, we\npropose a deep learning network that leverages both visual and textual\ninformation. A new semantic- and task-level attention mechanism was created to\nhelp our model to focus on the essential contents of a post that signal\nantivaccine messages. The proposed model, which consists of three branches, can\ngenerate comprehensive fused features for predictions. Moreover, an ensemble\nmethod is proposed to further improve the final prediction accuracy. To\nevaluate the proposed model's performance, a real-world social media dataset\nthat consists of more than 30,000 samples was collected from Instagram between\nJanuary 2016 and October 2019. Our 30 experiment results demonstrate that the\nfinal network achieves above 97% testing accuracy and outperforms other\nrelevant models, demonstrating that it can detect a large amount of antivaccine\nmessages posted daily. The implementation code is available at\nhttps://github.com/wzhings/antivaccine_detection.", "author": [{"name": "Zuhui Wang"}, {"name": "Zhaozheng Yin"}, {"name": "Young Anna Argyris"}], "link": [{"@href": "http://arxiv.org/abs/2012.13968v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.13968v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.08924v3", "updated": "2021-04-13T08:38:02Z", "published": "2021-02-17T18:30:43Z", "title": "Cross-SEAN: A Cross-Stitch Semi-Supervised Neural Attention Model for\n  COVID-19 Fake News Detection", "summary": "As the COVID-19 pandemic sweeps across the world, it has been accompanied by\na tsunami of fake news and misinformation on social media. At the time when\nreliable information is vital for public health and safety, COVID-19 related\nfake news has been spreading even faster than the facts. During times such as\nthe COVID-19 pandemic, fake news can not only cause intellectual confusion but\ncan also place lives of people at risk. This calls for an immediate need to\ncontain the spread of such misinformation on social media. We introduce CTF,\nthe first COVID-19 Twitter fake news dataset with labeled genuine and fake\ntweets. Additionally, we propose Cross-SEAN, a cross-stitch based\nsemi-supervised end-to-end neural attention model, which leverages the large\namount of unlabelled data. Cross-SEAN partially generalises to emerging fake\nnews as it learns from relevant external knowledge. We compare Cross-SEAN with\nseven state-of-the-art fake news detection methods. We observe that it achieves\n$0.95$ F1 Score on CTF, outperforming the best baseline by $9\\%$. We also\ndevelop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time\ndetection of fake tweets.", "author": [{"name": "William Scott Paka"}, {"name": "Rachit Bansal"}, {"name": "Abhay Kaushik"}, {"name": "Shubhashis Sengupta"}, {"name": "Tanmoy Chakraborty"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The Journal of Applied Soft Computing"}, "link": [{"@href": "http://arxiv.org/abs/2102.08924v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.08924v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.12541v1", "updated": "2021-03-13T18:04:17Z", "published": "2021-03-13T18:04:17Z", "title": "A Survey on Multimodal Disinformation Detection", "summary": "Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.", "author": [{"name": "Firoj Alam"}, {"name": "Stefano Cresci"}, {"name": "Tanmoy Chakraborty"}, {"name": "Fabrizio Silvestri"}, {"name": "Dimiter Dimitrov"}, {"name": "Giovanni Da San Martino"}, {"name": "Shaden Shaar"}, {"name": "Hamed Firooz"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, multimodality, text, images, videos, network structure,\n  temporality"}, "link": [{"@href": "http://arxiv.org/abs/2103.12541v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.12541v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.07175v2", "updated": "2021-05-01T23:18:18Z", "published": "2021-04-15T00:25:52Z", "title": "Community-Based Fact-Checking on Twitter's Birdwatch Platform", "summary": "Misinformation undermines the credibility of social media and poses\nsignificant threats to modern societies. As a countermeasure, Twitter has\nrecently introduced \"Birdwatch,\" a community-driven approach to address\nmisinformation on Twitter. On Birdwatch, users can identify tweets they believe\nare misleading, write notes that provide context to the tweet and rate the\nquality of other users' notes. In this work, we empirically analyze how users\ninteract with this new feature. For this purpose, we collect all Birdwatch\nnotes and ratings since the introduction of the feature in early 2021. We then\nmap each Birdwatch note to the fact-checked tweet using Twitter's historical\nAPI. In addition, we use text mining methods to extract content characteristics\nfrom the text explanations in the Birdwatch notes (e.g., sentiment). Our\nempirical analysis yields the following main findings: (i) users more\nfrequently file Birdwatch notes for misleading than not misleading tweets.\nThese misleading tweets are primarily reported because of factual errors, lack\nof important context, or because they contain unverified claims. (ii) Birdwatch\nnotes are more helpful to other users if they link to trustworthy sources and\nif they embed a more positive sentiment. (iii) The helpfulness of Birdwatch\nnotes depends on the social influence of the author of the fact-checked tweet.\nFor influential users with many followers, Birdwatch notes yield a lower level\nof consensus among users and community-created fact checks are more likely to\nbe seen as being incorrect. Altogether, our findings can help social media\nplatforms to formulate guidelines for users on how to write more helpful fact\nchecks. At the same time, our analysis suggests that community-based\nfact-checking faces challenges regarding biased views and polarization among\nthe user base.", "author": {"name": "Nicolas Pr\u00f6llochs"}, "link": [{"@href": "http://arxiv.org/abs/2104.07175v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.07175v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.07523v2", "updated": "2021-05-22T10:59:53Z", "published": "2021-05-16T21:47:30Z", "title": "Follow the Money: Analyzing @slpng_giants_pt's Strategy to Combat\n  Misinformation", "summary": "In 2020, the activist movement @sleeping_giants_pt (SGB) made a splash in\nBrazil. Similar to its international counterparts, the movement carried\n\"campaigns\" against media outlets spreading misinformation. In those, SGB\ntargeted companies whose ads were shown in these outlets, publicly asking them\nto remove the ads. In this work, we present a careful characterization of SGB's\nactivism model, analyzing the three campaigns carried by the movement up to\nSeptember 2020. We study how successful its complaints were and what factors\nare associated with their success, how attention towards the targeted media\noutlets progressed, and how online interactions with the companies were\nimpacted after they were targeted. Leveraging an annotated corpus of SGB's\ntweets as well as other data from Twitter and Google Search, we show that SGB's\n\"campaigns\" were largely successful: over 86\\% of companies (n=161) responded\npositively to SGB's requests, and, for those that responded, we find user\npressure to be negatively correlated with the time companies take to answer\n($r$=-0.67; $p$<0.001). Finally, we find that, although changes in the\ninteractions with companies were transient, the impact in targeted media\noutlets endured: all three outlets experienced a significant decrease in\nengagement on Twitter and search volume on Google following the start of SGB's\ncampaigns. Overall, our work suggests that internet-based activism can leverage\nthe transient attention it captures towards concrete goals to have a\nlong-lasting impact.", "author": [{"name": "B\u00e1rbara Gomes Ribeiro"}, {"name": "Manoel Horta Ribeiro"}, {"name": "Virg\u00edlio Almeida"}, {"name": "Wagner Meira Jr"}], "link": [{"@href": "http://arxiv.org/abs/2105.07523v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.07523v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2105.10272v1", "updated": "2021-05-21T10:46:43Z", "published": "2021-05-21T10:46:43Z", "title": "Stance Detection with BERT Embeddings for Credibility Analysis of\n  Information on Social Media", "summary": "The evolution of electronic media is a mixed blessing. Due to the easy\naccess, low cost, and faster reach of the information, people search out and\ndevour news from online social networks. In contrast, the increasing acceptance\nof social media reporting leads to the spread of fake news. This is a minacious\nproblem that causes disputes and endangers societal stability and harmony. Fake\nnews spread has gained attention from researchers due to its vicious nature.\nproliferation of misinformation in all media, from the internet to cable news,\npaid advertising and local news outlets, has made it essential for people to\nidentify the misinformation and sort through the facts. Researchers are trying\nto analyze the credibility of information and curtail false information on such\nplatforms. Credibility is the believability of the piece of information at\nhand. Analyzing the credibility of fake news is challenging due to the intent\nof its creation and the polychromatic nature of the news. In this work, we\npropose a model for detecting fake news. Our method investigates the content of\nthe news at the early stage i.e. when the news is published but is yet to be\ndisseminated through social media. Our work interprets the content with\nautomatic feature extraction and the relevance of the text pieces. In summary,\nwe introduce stance as one of the features along with the content of the\narticle and employ the pre-trained contextualized word embeddings BERT to\nobtain the state-of-art results for fake news detection. The experiment\nconducted on the real-world dataset indicates that our model outperforms the\nprevious work and enables fake news detection with an accuracy of 95.32%.", "author": [{"name": "Hema Karande"}, {"name": "Rahee Walambe"}, {"name": "Victor Benjamin"}, {"name": "Ketan Kotecha"}, {"name": "T. S. Raghu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.7717/peerj-cs.467"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.7717/peerj-cs.467", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2105.10272v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.10272v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.13385v1", "updated": "2021-06-25T01:49:45Z", "published": "2021-06-25T01:49:45Z", "title": "Trends, Politics, Sentiments, and Misinformation: Understanding People's\n  Reactions to COVID-19 During its Early Stages", "summary": "The sudden outbreak of COVID-19 resulted in large volumes of data shared on\ndifferent social media platforms. Analyzing and visualizing these data is\ndoubtlessly essential to having a deep understanding of the pandemic's impacts\non people's lives and their reactions to them. In this work, we conduct a\nlarge-scale spatiotemporal data analytic study to understand peoples' reactions\nto the COVID-19 pandemic during its early stages. In particular, we analyze a\nJSON-based dataset that is collected from news/messages/boards/blogs in English\nabout COVID-19 over a period of 4 months, for a total of 5.2M posts. The data\nare collected from December 2019 to March 2020 from several social media\nplatforms such as Facebook, LinkedIn, Pinterest, StumbleUpon and VK. Our study\naims mainly to understand which implications of COVID-19 have interested social\nmedia users the most and how did they vary over time, the spatiotemporal\ndistribution of misinformation, and the public opinion toward public figures\nduring the pandemic. Our results can be used by many parties (e.g.,\ngovernments, psychologists, etc.) to make more informative decisions, taking\ninto account the actual interests and opinions of the people.", "author": [{"name": "Omar Abdel Wahab"}, {"name": "Ali Mustafa"}, {"name": "Andr\u00e9 Bertrand Abisseck Bamatakina"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/2106.13385v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.13385v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.IT", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.08039v3", "updated": "2021-05-10T11:02:30Z", "published": "2020-05-16T16:52:12Z", "title": "Improved x-space Algorithm for Min-Max Bilevel Integer Programming with\n  an Application to Misinformation Spread in Social Networks", "summary": "In this work we propose an improvement of the $x$-space algorithm developed\nfor solving a class of min--max bilevel optimization problems (Tang Y., Richard\nJ.P.P., Smith J.C. (2016), A class of algorithms for mixed-integer bilevel\nmin--max optimization. Journal of Global Optimization, 66(2), 225--262). In\nthis setting, the leader of the upper level problem aims at restricting the\nfollower's decisions by minimizing an objective function, which the follower\nintends to maximize in the lower level problem by making decisions still\navailable to her. The $x$-space algorithm solves upper and lower bound problems\nconsecutively until convergence, and requires the dualization of an\napproximation of the follower's problem in formulating the lower bound problem.\nWe first reformulate the lower bound problem using the properties of an optimal\nsolution to the original formulation, which makes the dualization step\nunnecessary. The reformulation makes possible the integration of a greedy\ncovering heuristic into the solution scheme, which results in a considerable\nincrease in the efficiency. The new algorithm referred to as the improved\n$x$-space algorithm is implemented and applied to a recent min--max bilevel\noptimization problem that arises in the context of reducing the misinformation\nspread in social networks. It is also assessed on the benchmark instances of\ntwo other bilevel problems: zero-one knapsack problem with interdiction and\nmaximum clique problem with interdiction. Numerical results indicate that the\nperformance of the new algorithm is superior to that of the original algorithm,\nand also compares favorably with a recent algorithm developed for mixed-integer\nbilevel linear programs.", "author": [{"name": "K\u00fcbra Tan\u0131nm\u0131\u015f"}, {"name": "Necati Aras"}, {"name": "\u0130. Kuban Alt\u0131nel"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.ejor.2021.05.008"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.ejor.2021.05.008", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2005.08039v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.08039v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "31 pages, 7 tables, 4 figures. To be published in EJOR"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "math.OC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "math.OC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2007.12226v2", "updated": "2020-10-01T16:44:25Z", "published": "2020-07-23T19:43:27Z", "title": "Understanding the dynamics emerging from infodemics: A call to action\n  for interdisciplinary research", "summary": "Research on infodemics, i.e., the rapid spread of (mis)information related to\na hazardous event, such as the COVID-19 pandemic, requires the integration of a\nmultiplicity of scientific disciplines. The dynamics emerging from infodemics\nhave the potential to generate complex behavioral patterns. In order to react\nappropriately, it is of ultimate importance for the fields of Business and\nEconomics to understand the dynamics emerging from it. In the short run,\ndynamics might lead to an adaptation in household spending or to a shift in\nbuying behavior towards online providers. In the long run, changes in\ninvestments, consumer behavior, and markets are to be expected. We argue that\nthe dynamics emerge from complex interactions among multiple factors, such as\ninformation and misinformation accessible for individuals and the formation and\nrevision of beliefs. (Mis)information accessible to individuals is, amongst\nothers, affected by algorithms specifically designed to provide personalized\ninformation, while automated fact-checking algorithms can help reduce the\namount of circulating misinformation. The formation and revision of individual\n(and probably false) beliefs and individual fact-checking and interpretation of\ninformation are heavily affected by linguistic patterns inherent to information\nduring pandemics and infodemics and further factors, such as affect, intuition\nand motives. We argue that, in order to get a deep(er) understanding of the\ndynamics emerging from infodemics, the fields of Business and Economics should\nintegrate the perspectives of Computer Science and Information Systems,\n(Computational) Linguistics, and Cognitive Science into the wider context of\neconomic systems (e.g., organizations, markets or industries) and propose a way\nto do so.", "author": [{"name": "Stephan Leitner"}, {"name": "Bartosz Gula"}, {"name": "Dietmar Jannach"}, {"name": "Ulrike Krieg-Holz"}, {"name": "Friederike Wall"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "16 pages"}, "link": [{"@href": "http://arxiv.org/abs/2007.12226v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.12226v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.DS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68Q11, 68U35, 91E10, 68T50, 91F20, 91B44, 91B70", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.4; J.4; J.5", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.05940v1", "updated": "2020-08-13T14:48:03Z", "published": "2020-08-13T14:48:03Z", "title": "Impossible by Conventional Means: Ten Years on from the DARPA Red\n  Balloon Challenge", "summary": "Ten years ago, DARPA launched the 'Network Challenge', more commonly known as\nthe 'DARPA Red Balloon Challenge'. Ten red weather balloons were fixed at\nunknown locations in the US. An open challenge was launched to locate all ten,\nthe first to do so would be declared the winner receiving a cash prize. A team\nfrom MIT Media Lab was able to locate them all within 9 hours using social\nmedia and a novel reward scheme that rewarded viral recruitment. This\nachievement was rightly seen as proof of the remarkable ability of social\nmedia, then relatively nascent, to solve real world problems such as\nlarge-scale spatial search. Upon reflection, however, the challenge was also\nremarkable as it succeeded despite many efforts to provide false information on\nthe location of the balloons. At the time the false reports were filtered based\non manual inspection of visual proof and comparing the IP addresses of those\nreporting with the purported coordinates of the balloons. In the ten years\nsince, misinformation on social media has grown in prevalence and\nsophistication to be one of the defining social issues of our time. Seen\ndifferently we can cast the misinformation observed in the Red Balloon\nChallenge, and unexpected adverse effects in other social mobilisation\nchallenges subsequently, not as bugs but as essential features. We further\ninvestigate the role of the increasing levels of political polarisation in\nmodulating social mobilisation. We confirm that polarisation not only impedes\nthe overall success of mobilisation, but also leads to a low reachability to\noppositely polarised states, significantly hampering recruitment. We find that\ndiversifying geographic pathways of social influence are key to circumvent\nbarriers of political mobilisation and can boost the success of new open\nchallenges.", "author": [{"name": "Alex Rutherford"}, {"name": "Manuel Cebrian"}, {"name": "Inho Hong"}, {"name": "Iyad Rahwan"}], "link": [{"@href": "http://arxiv.org/abs/2008.05940v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.05940v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.06906v1", "updated": "2020-10-14T09:37:51Z", "published": "2020-10-14T09:37:51Z", "title": "No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet\n  Detection", "summary": "The sudden widespread menace created by the present global pandemic COVID-19\nhas had an unprecedented effect on our lives. Man-kind is going through\nhumongous fear and dependence on social media like never before. Fear\ninevitably leads to panic, speculations, and the spread of misinformation. Many\ngovernments have taken measures to curb the spread of such misinformation for\npublic well being. Besides global measures, to have effective outreach, systems\nfor demographically local languages have an important role to play in this\neffort. Towards this, we propose an approach to detect fake news about COVID-19\nearly on from social media, such as tweets, for multiple Indic-Languages\nbesides English. In addition, we also create an annotated dataset of Hindi and\nBengali tweet for fake news detection. We propose a BERT based model augmented\nwith additional relevant features extracted from Twitter to identify fake\ntweets. To expand our approach to multiple Indic languages, we resort to mBERT\nbased model which is fine-tuned over created dataset in Hindi and Bengali. We\nalso propose a zero-shot learning approach to alleviate the data scarcity issue\nfor such low resource languages. Through rigorous experiments, we show that our\napproach reaches around 89% F-Score in fake tweet detection which supercedes\nthe state-of-the-art (SOTA) results. Moreover, we establish the first benchmark\nfor two Indic-Languages, Hindi and Bengali. Using our annotated data, our model\nachieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our\nzero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali\nTweets without any annotated data, which clearly indicates the efficacy of our\napproach.", "author": [{"name": "Debanjana Kar"}, {"name": "Mohit Bhardwaj"}, {"name": "Suranjana Samanta"}, {"name": "Amar Prakash Azad"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 4 figures"}, "link": [{"@href": "http://arxiv.org/abs/2010.06906v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.06906v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.08537v3", "updated": "2021-04-07T05:06:05Z", "published": "2021-02-17T02:35:13Z", "title": "Political Bias and Factualness in News Sharing across more than 100,000\n  Online Communities", "summary": "As civil discourse increasingly takes place online, misinformation and the\npolarization of news shared in online communities have become ever more\nrelevant concerns with real world harms across our society. Studying online\nnews sharing at scale is challenging due to the massive volume of content which\nis shared by millions of users across thousands of communities. Therefore,\nexisting research has largely focused on specific communities or specific\ninterventions, such as bans. However, understanding the prevalence and spread\nof misinformation and polarization more broadly, across thousands of online\ncommunities, is critical for the development of governance strategies,\ninterventions, and community design. Here, we conduct the largest study of news\nsharing on reddit to date, analyzing more than 550 million links spanning 4\nyears. We use non-partisan news source ratings from Media Bias/Fact Check to\nannotate links to news sources with their political bias and factualness. We\nfind that, compared to left-leaning communities, right-leaning communities have\n105% more variance in the political bias of their news sources, and more links\nto relatively-more biased sources, on average. We observe that reddit users'\nvoting and re-sharing behaviors generally decrease the visibility of extremely\nbiased and low factual content, which receives 20% fewer upvotes and 30% fewer\nexposures from crossposts than more neutral or more factual content. This\nsuggests that reddit is more resilient to low factual content than Twitter. We\nshow that extremely biased and low factual content is very concentrated, with\n99% of such content being shared in only 0.5% of communities, giving credence\nto the recent strategy of community-wide bans and quarantines.", "author": [{"name": "Galen Weld"}, {"name": "Maria Glenski"}, {"name": "Tim Althoff"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages, 7 figures. To appear at ICWSM 2021, camera ready version\n  included here"}, "link": [{"@href": "http://arxiv.org/abs/2102.08537v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.08537v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.11755v1", "updated": "2021-07-25T08:37:09Z", "published": "2021-07-25T08:37:09Z", "title": "Can the Crowd Judge Truthfulness? A Longitudinal Study on Recent\n  Misinformation about COVID-19", "summary": "Recently, the misinformation problem has been addressed with a\ncrowdsourcing-based approach: to assess the truthfulness of a statement,\ninstead of relying on a few experts, a crowd of non-expert is exploited. We\nstudy whether crowdsourcing is an effective and reliable method to assess\ntruthfulness during a pandemic, targeting statements related to COVID-19, thus\naddressing (mis)information that is both related to a sensitive and personal\nissue and very recent as compared to when the judgment is done. In our\nexperiments, crowd workers are asked to assess the truthfulness of statements,\nand to provide evidence for the assessments. Besides showing that the crowd is\nable to accurately judge the truthfulness of the statements, we report results\non workers behavior, agreement among workers, effect of aggregation functions,\nof scales transformations, and of workers background and bias. We perform a\nlongitudinal study by re-launching the task multiple times with both novice and\nexperienced workers, deriving important insights on how the behavior and\nquality change over time. Our results show that: workers are able to detect and\nobjectively categorize online (mis)information related to COVID-19; both\ncrowdsourced and expert judgments can be transformed and aggregated to improve\nquality; worker background and other signals (e.g., source of information,\nbehavior) impact the quality of the data. The longitudinal study demonstrates\nthat the time-span has a major effect on the quality of the judgments, for both\nnovice and experienced workers. Finally, we provide an extensive failure\nanalysis of the statements misjudged by the crowd-workers.", "author": [{"name": "Kevin Roitero"}, {"name": "Michael Soprano"}, {"name": "Beatrice Portelli"}, {"name": "Massimiliano De Luise"}, {"name": "Damiano Spina"}, {"name": "Vincenzo Della Mea"}, {"name": "Giuseppe Serra"}, {"name": "Stefano Mizzaro"}, {"name": "Gianluca Demartini"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "31 pages; Preprint of an article accepted in Personal and Ubiquitous\n  Computing (Special Issue on Intelligent Systems for Tackling Online Harms).\n  arXiv admin note: substantial text overlap with arXiv:2008.05701"}, "link": [{"@href": "http://arxiv.org/abs/2107.11755v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.11755v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68P20", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.01222v2", "updated": "2021-08-23T04:21:58Z", "published": "2021-08-03T00:44:55Z", "title": "The Many Dimensions of Truthfulness: Crowdsourcing Misinformation\n  Assessments on a Multidimensional Scale", "summary": "Recent work has demonstrated the viability of using crowdsourcing as a tool\nfor evaluating the truthfulness of public statements. Under certain conditions\nsuch as: (1) having a balanced set of workers with different backgrounds and\ncognitive abilities; (2) using an adequate set of mechanisms to control the\nquality of the collected data; and (3) using a coarse grained assessment scale,\nthe crowd can provide reliable identification of fake news. However, fake news\nare a subtle matter: statements can be just biased (\"cherrypicked\"), imprecise,\nwrong, etc. and the unidimensional truth scale used in existing work cannot\naccount for such differences. In this paper we propose a multidimensional\nnotion of truthfulness and we ask the crowd workers to assess seven different\ndimensions of truthfulness selected based on existing literature: Correctness,\nNeutrality, Comprehensibility, Precision, Completeness, Speaker's\nTrustworthiness, and Informativeness. We deploy a set of quality control\nmechanisms to ensure that the thousands of assessments collected on 180\npublicly available fact-checked statements distributed over two datasets are of\nadequate quality, including a custom search engine used by the crowd workers to\nfind web pages supporting their truthfulness assessments. A comprehensive\nanalysis of crowdsourced judgments shows that: (1) the crowdsourced assessments\nare reliable when compared to an expert-provided gold standard; (2) the\nproposed dimensions of truthfulness capture independent pieces of information;\n(3) the crowdsourcing task can be easily learned by the workers; and (4) the\nresulting assessments provide a useful basis for a more complete estimation of\nstatement truthfulness.", "author": [{"name": "Michael Soprano"}, {"name": "Kevin Roitero"}, {"name": "David La Barbera"}, {"name": "Davide Ceolin"}, {"name": "Damiano Spina"}, {"name": "Stefano Mizzaro"}, {"name": "Gianluca Demartini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.ipm.2021.102710"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.ipm.2021.102710", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.01222v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.01222v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "33 pages; Paper accepted at Information Processing & Management on\n  July 28, 2021; IP&M Special Issue on Dis/Misinformation Mining from Social\n  Media"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Information Processing & Management Information Processing &\n  Management, Volume 58, Issue 6, November 2021, 102710"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68P20", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/astro-ph/0702542v3", "updated": "2009-01-24T18:59:33Z", "published": "2007-02-20T21:06:10Z", "title": "Tainted Evidence: Cosmological Model Selection vs. Fitting", "summary": "Interpretation of cosmological data to determine the number and values of\nparameters describing the universe must not rely solely on statistics but\ninvolve physical insight. When statistical techniques such as \"model selection\"\nor \"integrated survey optimization\" blindly apply Occam's Razor, this can lead\nto painful results. We emphasize that the sensitivity to prior probabilities\nand to the number of models compared can lead to \"prior selection\" rather than\nrobust model selection. A concrete example demonstrates that Information\nCriteria can in fact misinform over a large region of parameter space.", "author": [{"name": "Eric V. Linder"}, {"name": "Ramon Miquel"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1142/S0218271808013881"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1142/S0218271808013881", "@rel": "related"}, {"@href": "http://arxiv.org/abs/astro-ph/0702542v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/astro-ph/0702542v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages, 1 figure; v2 minor rephrasings, clarifications; v3 minor\n  changes to match published article under title \"Cosmological Model Selection:\n  Statistics and Physics\""}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Int.J.Mod.Phys.D17:2315,2008"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "astro-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "astro-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/0803.4357v1", "updated": "2008-03-31T00:24:19Z", "published": "2008-03-31T00:24:19Z", "title": "Paradoxical popups: Why are they hard to catch?", "summary": "Even professional baseball players occasionally find it difficult to\ngracefully approach seemingly routine pop-ups. This paper describes a set of\ntowering pop-ups with trajectories that exhibit cusps and loops near the apex.\nFor a normal fly ball, the horizontal velocity is continuously decreasing due\nto drag caused by air resistance. But for pop-ups, the Magnus force (the force\ndue to the ball spinning in a moving airflow) is larger than the drag force. In\nthese cases the horizontal velocity decreases in the beginning, like a normal\nfly ball, but after the apex, the Magnus force accelerates the horizontal\nmotion. We refer to this class of pop-ups as paradoxical because they appear to\nmisinform the typically robust optical control strategies used by fielders and\nlead to systematic vacillation in running paths, especially when a trajectory\nterminates near the fielder. In short, some of the dancing around when\ninfielders pursue pop-ups can be well explained as a combination of bizarre\ntrajectories and misguidance by the normally reliable optical control strategy,\nrather than apparent fielder error. Former major league infielders confirm that\nour model agrees with their experiences.", "author": [{"name": "Michael K. McBeath"}, {"name": "Alan M. Nathan"}, {"name": "A. Terry Bahill"}, {"name": "David G. Baldwin"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1119/1.2937899"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1119/1.2937899", "@rel": "related"}, {"@href": "http://arxiv.org/abs/0803.4357v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/0803.4357v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "28 pages, 10 figures, sumitted to American Journal of Physics"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.pop-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "physics.pop-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/0903.2448v3", "updated": "2009-03-23T18:42:39Z", "published": "2009-03-13T18:30:55Z", "title": "Positive Logic with Adjoint Modalities: Proof Theory, Semantics and\n  Reasoning about Information", "summary": "We consider a simple modal logic whose non-modal part has conjunction and\ndisjunction as connectives and whose modalities come in adjoint pairs, but are\nnot in general closure operators. Despite absence of negation and implication,\nand of axioms corresponding to the characteristic axioms of (e.g.) T, S4 and\nS5, such logics are useful, as shown in previous work by Baltag, Coecke and the\nfirst author, for encoding and reasoning about information and misinformation\nin multi-agent systems. For such a logic we present an algebraic semantics,\nusing lattices with agent-indexed families of adjoint pairs of operators, and a\ncut-free sequent calculus. The calculus exploits operators on sequents, in the\nstyle of \"nested\" or \"tree-sequent\" calculi; cut-admissibility is shown by\nconstructive syntactic methods. The applicability of the logic is illustrated\nby reasoning about the muddy children puzzle, for which the calculus is\naugmented with extra rules to express the facts of the muddy children scenario.", "author": [{"name": "Mehrnoosh Sadrzadeh"}, {"name": "Roy Dyckhoff"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This paper is the full version of the article that is to appear in\n  the ENTCS proceedings of the 25th conference on the Mathematical Foundations\n  of Programming Semantics (MFPS), April 2009, University of Oxford"}, "link": [{"@href": "http://arxiv.org/abs/0903.2448v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/0903.2448v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LO", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LO", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1011.3768v1", "updated": "2010-11-16T17:46:23Z", "published": "2010-11-16T17:46:23Z", "title": "Detecting and Tracking the Spread of Astroturf Memes in Microblog\n  Streams", "summary": "Online social media are complementing and in some cases replacing\nperson-to-person social interaction and redefining the diffusion of\ninformation. In particular, microblogs have become crucial grounds on which\npublic relations, marketing, and political battles are fought. We introduce an\nextensible framework that will enable the real-time analysis of meme diffusion\nin social media by mining, visualizing, mapping, classifying, and modeling\nmassive streams of public microblogging events. We describe a Web service that\nleverages this framework to track political memes in Twitter and help detect\nastroturfing, smear campaigns, and other misinformation in the context of U.S.\npolitical elections. We present some cases of abusive behaviors uncovered by\nour service. Finally, we discuss promising preliminary results on the detection\nof suspicious memes via supervised learning based on features extracted from\nthe topology of the diffusion networks, sentiment analysis, and crowdsourced\nannotations.", "author": [{"name": "Jacob Ratkiewicz"}, {"name": "Michael Conover"}, {"name": "Mark Meiss"}, {"name": "Bruno Gon\u00e7alves"}, {"name": "Snehal Patil"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/1963192.1963301"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/1963192.1963301", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1011.3768v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1011.3768v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the 20th international conference companion on\n  World wide web, 249-252 (2011)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1310.1942v1", "updated": "2013-10-07T20:19:36Z", "published": "2013-10-07T20:19:36Z", "title": "Containing Viral Spread on Sparse Random Graphs: Bounds, Algorithms, and\n  Experiments", "summary": "Viral spread on large graphs has many real-life applications such as malware\npropagation in computer networks and rumor (or misinformation) spread in\nTwitter-like online social networks. Although viral spread on large graphs has\nbeen intensively analyzed on classical models such as\nSusceptible-Infectious-Recovered, there still exits a deficit of effective\nmethods in practice to contain epidemic spread once it passes a critical\nthreshold. Against this backdrop, we explore methods of containing viral spread\nin large networks with the focus on sparse random networks. The viral\ncontainment strategy is to partition a large network into small components and\nthen to ensure the sanity of all messages delivered across different\ncomponents. With such a defense mechanism in place, an epidemic spread starting\nfrom any node is limited to only those nodes belonging to the same component as\nthe initial infection node. We establish both lower and upper bounds on the\ncosts of inspecting inter-component messages. We further propose\nheuristic-based approaches to partition large input graphs into small\ncomponents. Finally, we study the performance of our proposed algorithms under\ndifferent network topologies and different edge weight models.", "author": [{"name": "Milan Bradonji\u0107"}, {"name": "Michael Molloy"}, {"name": "Guanhua Yan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "28 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/1310.1942v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1310.1942v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "math.PR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "math.PR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.CO", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1408.5378v1", "updated": "2014-08-19T18:00:36Z", "published": "2014-08-19T18:00:36Z", "title": "Social Learning in a Human Society: An Experimental Study", "summary": "This paper presents an experimental study to investigate the learning and\ndecision making behavior of individuals in a human society. Social learning is\nused as the mathematical basis for modelling interaction of individuals that\naim to perform a perceptual task interactively. A psychology experiment was\nconducted on a group of undergraduate students at the University of British\nColumbia to examine whether the decision (action) of one individual affects the\ndecision of the subsequent individuals. The major experimental observation that\nstands out here is that the participants of the experiment (agents) were\naffected by decisions of their partners in a relatively large fraction (60%) of\ntrials. We fit a social learning model that mimics the interactions between\nparticipants of the psychology experiment. Misinformation propagation (also\nknown as data incest) within the society under study is further investigated in\nthis paper.", "author": [{"name": "Maziyar Hamdi"}, {"name": "Grayden Solman"}, {"name": "Alan Kingstone"}, {"name": "Vikram Krishnamurthy"}], "link": [{"@href": "http://arxiv.org/abs/1408.5378v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1408.5378v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1711.07412v2", "updated": "2017-12-01T20:06:56Z", "published": "2017-11-20T17:01:20Z", "title": "Distributed Rumor Blocking with Multiple Positive Cascades", "summary": "Misinformation and rumor can spread rapidly and widely through online social\nnetworks and therefore rumor controlling has become a critical issue. It is\noften assumed that there is a single authority whose goal is to minimize the\nspread of rumor by generating a positive cascade. In this paper, we study a\nmore realistic scenario when there are multiple positive cascades generated by\ndifferent agents. For the multiple-cascade diffusion, we propose the P2P\nindependent cascade (PIC) model for private social communications. The main\npart of this paper is an analysis of the rumor blocking effect (i.e. the number\nof the users activated by rumor) when the agents non-cooperatively generate the\npositive cascades. We show that the rumor blocking effect provided by the Nash\nequilibrium will not be arbitrarily worse even if the positive cascades are\ngenerated non-cooperatively. In addition, we give a discussion on how the\ncascade priority and activation order affect the rumor blocking problem. We\nexperimentally examine the Nash equilibrium of the proposed games by\nsimulations done on real social network structures.", "author": [{"name": "Guangmo Amo Tong"}, {"name": "Weili Wu"}, {"name": "Ding-Zhu Du"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "under review"}, "link": [{"@href": "http://arxiv.org/abs/1711.07412v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.07412v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.08615v1", "updated": "2017-11-23T08:36:17Z", "published": "2017-11-23T08:36:17Z", "title": "Controlling Elections through Social Influence", "summary": "Election control considers the problem of an adversary who attempts to tamper\nwith a voting process, in order to either ensure that their favored candidate\nwins (constructive control) or another candidate loses (destructive control).\nAs online social networks have become significant sources of information for\npotential voters, a new tool in an attacker's arsenal is to effect control by\nharnessing social influence, for example, by spreading fake news and other\nforms of misinformation through online social media.\n  We consider the computational problem of election control via social\ninfluence, studying the conditions under which finding good adversarial\nstrategies is computationally feasible. We consider two objectives for the\nadversary in both the constructive and destructive control settings:\nprobability and margin of victory (POV and MOV, respectively). We present\nseveral strong negative results, showing, for example, that the problem of\nmaximizing POV is inapproximable for any constant factor. On the other hand, we\npresent approximation algorithms which provide somewhat weaker approximation\nguarantees, such as bicriteria approximations for the POV objective and\nconstant-factor approximations for MOV. Finally, we present mixed integer\nprogramming formulations for these problems. Experimental results show that our\napproximation algorithms often find near-optimal control strategies, indicating\nthat election control through social influence is a salient threat to election\nintegrity.", "author": [{"name": "Bryan Wilder"}, {"name": "Yevgeniy Vorobeychik"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "19 pages, 2 figures"}, "link": [{"@href": "http://arxiv.org/abs/1711.08615v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.08615v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1112.3620v2", "updated": "2011-12-19T18:28:16Z", "published": "2011-12-15T19:35:01Z", "title": "Probably a discovery: Bad mathematics means rough scientific\n  communication", "summary": "According to the media, in spring of this year the experiment CDF at Fermilab\nhas made most likely (\"this result has a 99.7 percent chance of being correct\",\nDiscovery News) a great discovery (\"the most significant in physics in half a\ncentury\", NYT). However, since the very beginning, practically all particle\nphysics experts did not believe that was the case. This is the last of a quite\nlong series of fake claims based on trivial mistakes in the probabilistic\nreasoning. The main purpose of this note is to invite everybody, but especially\njournalists and general public, most times innocent victims of misinformation\nof this kind, to mistrust claims not explicitly reported in terms of how much\nwe should believe something, under well stated conditions and assumptions. (A\nlast minute appendix has been added, with comments on the recent news\nconcerning the Higgs at LHC.)", "author": {"name": "G. D'Agostini"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "21 pages, 2 figures, note based on lectures at the University of\n  Perugia, 15-16 April 2011 and at MAPSES School in Lecce, 23-25 November 2011"}, "link": [{"@href": "http://arxiv.org/abs/1112.3620v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1112.3620v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.data-an", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.data-an", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "hep-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.HO", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.pop-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1409.2651v1", "updated": "2014-09-09T09:43:44Z", "published": "2014-09-09T09:43:44Z", "title": "Social determinants of content selection in the age of (mis)information", "summary": "Despite the enthusiastic rhetoric about the so called \\emph{collective\nintelligence}, conspiracy theories -- e.g. global warming induced by chemtrails\nor the link between vaccines and autism -- find on the Web a natural medium for\ntheir dissemination. Users preferentially consume information according to\ntheir system of beliefs and the strife within users of opposite narratives may\nresult in heated debates. In this work we provide a genuine example of\ninformation consumption from a sample of 1.2 million of Facebook Italian users.\nWe show by means of a thorough quantitative analysis that information\nsupporting different worldviews -- i.e. scientific and conspiracist news -- are\nconsumed in a comparable way by their respective users. Moreover, we measure\nthe effect of the exposure to 4709 evidently false information (satirical\nversion of conspiracy theses) and to 4502 debunking memes (information aiming\nat contrasting unsubstantiated rumors) of the most polarized users of\nconspiracy claims. We find that either contrasting or teasing consumers of\nconspiracy narratives increases their probability to interact again with\nunsubstantiated rumors.", "author": [{"name": "Alessandro Bessi"}, {"name": "Guido Caldarelli"}, {"name": "Michela Del Vicario"}, {"name": "Antonio Scala"}, {"name": "Walter Quattrociocchi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "misinformation, collective narratives, crowd dynamics, information\n  spreading"}, "link": [{"@href": "http://arxiv.org/abs/1409.2651v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1409.2651v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.data-an", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1501.00994v1", "updated": "2015-01-05T21:00:51Z", "published": "2015-01-05T21:00:51Z", "title": "Online Reputation and Polling Systems: Data Incest, Social Learning and\n  Revealed Preferences", "summary": "This paper considers online reputation and polling systems where individuals\nmake recommendations based on their private observations and recommendations of\nfriends. Such interaction of individuals and their social influence is modelled\nas social learning on a directed acyclic graph. Data incest (misinformation\npropagation) occurs due to unintentional re-use of identical actions in the\nfor- mation of public belief in social learning; the information gathered by\neach agent is mistakenly considered to be independent. This results in\noverconfidence and bias in estimates of the state. Necessary and sufficient\nconditions are given on the structure of information exchange graph to mitigate\ndata incest. Incest removal algorithms are presented. Experimental results on\nhuman subjects are presented to illustrate the effect of social influence and\ndata incest on decision making. These experimental results indicate that social\nlearning protocols require careful design to handle and mitigate data incest.\nThe incest removal algorithms are illustrated in an expectation polling system\nwhere participants in a poll respond with a summary of their friends' beliefs.\nFinally, the principle of revealed preferences arising in micro-economics\ntheory is used to parse Twitter datasets to determine if social sensors are\nutility maximizers and then determine their utility functions.", "author": [{"name": "Vikram Krishnamurthy"}, {"name": "William Hoiles"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: substantial text overlap with arXiv:1412.4171"}, "link": [{"@href": "http://arxiv.org/abs/1501.00994v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1501.00994v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1501.03471v1", "updated": "2015-01-14T20:18:21Z", "published": "2015-01-14T20:18:21Z", "title": "Computational fact checking from knowledge networks", "summary": "Traditional fact checking by expert journalists cannot keep up with the\nenormous volume of information that is now generated online. Computational fact\nchecking may significantly enhance our ability to evaluate the veracity of\ndubious information. Here we show that the complexities of human fact checking\ncan be approximated quite well by finding the shortest path between concept\nnodes under properly defined semantic proximity metrics on knowledge graphs.\nFramed as a network problem this approach is feasible with efficient\ncomputational techniques. We evaluate this approach by examining tens of\nthousands of claims related to history, entertainment, geography, and\nbiographical information using a public knowledge graph extracted from\nWikipedia. Statements independently known to be true consistently receive\nhigher support via our method than do false ones. These findings represent a\nsignificant step toward scalable computational fact-checking methods that may\none day mitigate the spread of harmful misinformation.", "author": [{"name": "Giovanni Luca Ciampaglia"}, {"name": "Prashant Shiralkar"}, {"name": "Luis M. Rocha"}, {"name": "Johan Bollen"}, {"name": "Filippo Menczer"}, {"name": "Alessandro Flammini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0128193"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0128193", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1501.03471v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1501.03471v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1507.07109v1", "updated": "2015-07-25T15:13:34Z", "published": "2015-07-25T15:13:34Z", "title": "Political Bots and the Manipulation of Public Opinion in Venezuela", "summary": "Social and political bots have a small but strategic role in Venezuelan\npolitical conversations. These automated scripts generate content through\nsocial media platforms and then interact with people. In this preliminary study\non the use of political bots in Venezuela, we analyze the tweeting, following\nand retweeting patterns for the accounts of prominent Venezuelan politicians\nand prominent Venezuelan bots. We find that bots generate a very small\nproportion of all the traffic about political life in Venezuela. Bots are used\nto retweet content from Venezuelan politicians but the effect is subtle in that\nless than 10 percent of all retweets come from bot-related platforms.\nNonetheless, we find that the most active bots are those used by Venezuela's\nradical opposition. Bots are pretending to be political leaders, government\nagencies and political parties more than citizens. Finally, bots are promoting\ninnocuous political events more than attacking opponents or spreading\nmisinformation.", "author": [{"name": "Michelle Forelle"}, {"name": "Phil Howard"}, {"name": "Andr\u00e9s Monroy-Hern\u00e1ndez"}, {"name": "Saiph Savage"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 3 figures"}, "link": [{"@href": "http://arxiv.org/abs/1507.07109v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1507.07109v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.5.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1509.00189v2", "updated": "2015-12-21T15:03:12Z", "published": "2015-09-01T09:24:21Z", "title": "Echo chambers in the age of misinformation", "summary": "The wide availability of user-provided content in online social media\nfacilitates the aggregation of people around common interests, worldviews, and\nnarratives. Despite the enthusiastic rhetoric on the part of some that this\nprocess generates \"collective intelligence\", the WWW also allows the rapid\ndissemination of unsubstantiated conspiracy theories that often elicite rapid,\nlarge, but naive social responses such as the recent case of Jade Helm 15 --\nwhere a simple military exercise turned out to be perceived as the beginning of\nthe civil war in the US. We study how Facebook users consume information\nrelated to two different kinds of narrative: scientific and conspiracy news. We\nfind that although consumers of scientific and conspiracy stories present\nsimilar consumption patterns with respect to content, the sizes of the\nspreading cascades differ. Homogeneity appears to be the primary driver for the\ndiffusion of contents, but each echo chamber has its own cascade dynamics. To\nmimic these dynamics, we introduce a data-driven percolation model on signed\nnetworks.", "author": [{"name": "Michela Del Vicario"}, {"name": "Alessandro Bessi"}, {"name": "Fabiana Zollo"}, {"name": "Fabio Petroni"}, {"name": "Antonio Scala"}, {"name": "Guido Caldarelli"}, {"name": "H. Eugene Stanley"}, {"name": "Walter Quattrociocchi"}], "link": [{"@href": "http://arxiv.org/abs/1509.00189v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1509.00189v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1602.00975v1", "updated": "2016-02-02T15:29:42Z", "published": "2016-02-02T15:29:42Z", "title": "BotOrNot: A System to Evaluate Social Bots", "summary": "While most online social media accounts are controlled by humans, these\nplatforms also host automated agents called social bots or sybil accounts.\nRecent literature reported on cases of social bots imitating humans to\nmanipulate discussions, alter the popularity of users, pollute content and\nspread misinformation, and even perform terrorist propaganda and recruitment\nactions. Here we present BotOrNot, a publicly-available service that leverages\nmore than one thousand features to evaluate the extent to which a Twitter\naccount exhibits similarity to the known characteristics of social bots. Since\nits release in May 2014, BotOrNot has served over one million requests via our\nwebsite and APIs.", "author": [{"name": "Clayton A. Davis"}, {"name": "Onur Varol"}, {"name": "Emilio Ferrara"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/2872518.2889302"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/2872518.2889302", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1602.00975v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1602.00975v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "2 pages, 2 figures, WWW Developers Day"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the 25th International Conference Companion on\n  World Wide Web (pp. 273-274). 2016"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1307.2176v1", "updated": "2013-07-08T17:19:02Z", "published": "2013-07-08T17:19:02Z", "title": "Cost overruns in Large-Scale Transportation Infrastructure Projects:\n  Explanations and Their Theoretical Embeddedness", "summary": "Managing large-scale transportation infrastructure projects is difficult due\nto frequent misinformation about the costs which results in large cost overruns\nthat often threaten the overall project viability. This paper investigates the\nexplanations for cost overruns that are given in the literature. Overall, four\ncategories of explanations can be distinguished: technical, economic,\npsychological, and political. Political explanations have been seen to be the\nmost dominant explanations for cost overruns. Agency theory is considered the\nmost interesting for political explanations and an eclectic theory is also\nconsidered possible. Nonpolitical explanations are diverse in character,\ntherefore a range of different theories (including rational choice theory and\nprospect theory), depending on the kind of explanation is considered more\nappropriate than one all-embracing theory.", "author": [{"name": "Chantal C. Cantarelli"}, {"name": "Bent Flybjerg"}, {"name": "Eric J. E. Molin"}, {"name": "Bert van Wee"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "European Journal of Transport and Infrastructure Research, vol.\n  10, no. 1, March 2010, 5-18"}, "link": [{"@href": "http://arxiv.org/abs/1307.2176v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1307.2176v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "q-fin.GN", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "q-fin.GN", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1401.0693v2", "updated": "2014-01-20T12:58:12Z", "published": "2014-01-03T18:10:14Z", "title": "Non-existence of greedy bases in direct sums of mixed $\\ell_{p}$ spaces", "summary": "The fact that finite direct sums of two or more mutually different spaces\nfrom the family $\\{\\ell_{p} : 1\\le p<\\infty\\}\\cup c_{0}$ fail to have greedy\nbases is stated in [Dilworth et al., Greedy bases for Besov spaces, Constr.\nApprox. 34 (2011), no. 2, 281-296]. However, the concise proof that the authors\ngive of this fundamental result in greedy approximation relies on a fallacious\nargument, namely the alleged uniqueness of unconditional basis up to\npermutation of the spaces involved. The main goal of this note is to settle the\nproblem by providing a correct proof. For that we first show that all greedy\nbases in an $\\ell_{p}$ space have fundamental functions of the same order. As a\nby-product of our work we obtain that every almost greedy basis of a Banach\nspace with unconditional basis and nontrivial type contains a greedy subbasis.", "author": [{"name": "Fernando Albiac"}, {"name": "Jos\u00e9 L. Ansorena"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The manuscript needs to be revised in accordance with some feedback\n  we received from Dilworth et al. The submitted version contained an\n  inaccurate account of a statement in [Dilworth et al., Greedy Basis for Besov\n  Spaces, Constr. Approx. 34 (2011), 281-296]. We apologize for the\n  misinformation"}, "link": [{"@href": "http://arxiv.org/abs/1401.0693v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1401.0693v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "math.FA", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "math.FA", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "46A35, 46A45, 46B15, 46B25, 46B45, 46E30, 46T99", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1706.03019v1", "updated": "2017-06-09T16:21:46Z", "published": "2017-06-09T16:21:46Z", "title": "Understanding Information Spreading in Social Media during Hurricane\n  Sandy: User Activity and Network Properties", "summary": "Many people use social media to seek information during disasters while\nlacking access to traditional information sources. In this study, we analyze\nTwitter data to understand information spreading activities of social media\nusers during hurricane Sandy. We create multiple subgraphs of Twitter users\nbased on activity levels and analyze network properties of the subgraphs. We\nobserve that user information sharing activity follows a power-law distribution\nsuggesting the existence of few highly active nodes in disseminating\ninformation and many other nodes being less active. We also observe close\nenough connected components and isolates at all levels of activity, and\nnetworks become less transitive, but more assortative for larger subgraphs. We\nalso analyze the association between user activities and characteristics that\nmay influence user behavior to spread information during a crisis. Users become\nmore active in spreading information if they are centrally placed in the\nnetwork, less eccentric, and have higher degrees. Our analysis provides\ninsights on how to exploit user characteristics and network properties to\nspread information or limit the spreading of misinformation during a crisis\nevent.", "author": [{"name": "Arif Mohaimin Sadri"}, {"name": "Samiul Hasan"}, {"name": "Satish V. Ukkusuri"}, {"name": "Manuel Cebrian"}], "link": [{"@href": "http://arxiv.org/abs/1706.03019v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1706.03019v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1802.03572v1", "updated": "2018-02-10T12:16:12Z", "published": "2018-02-10T12:16:12Z", "title": "Junk News on Military Affairs and National Security: Social Media\n  Disinformation Campaigns Against US Military Personnel and Veterans", "summary": "Social media provides political news and information for both active duty\nmilitary personnel and veterans. We analyze the subgroups of Twitter and\nFacebook users who spend time consuming junk news from websites that target US\nmilitary personnel and veterans with conspiracy theories, misinformation, and\nother forms of junk news about military affairs and national security issues.\n(1) Over Twitter we find that there are significant and persistent interactions\nbetween current and former military personnel and a broad network of extremist,\nRussia-focused, and international conspiracy subgroups. (2) Over Facebook, we\nfind significant and persistent interactions between public pages for military\nand veterans and subgroups dedicated to political conspiracy, and both sides of\nthe political spectrum. (3) Over Facebook, the users who are most interested in\nconspiracy theories and the political right seem to be distributing the most\njunk news, whereas users who are either in the military or are veterans are\namong the most sophisticated news consumers, and share very little junk news\nthrough the network.", "author": [{"name": "John D. Gallacher"}, {"name": "Vlad Barash"}, {"name": "Philip N. Howard"}, {"name": "John Kelly"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Data Memo"}, "link": [{"@href": "http://arxiv.org/abs/1802.03572v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1802.03572v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1810.06973v2", "updated": "2018-10-17T09:09:06Z", "published": "2018-10-16T13:18:22Z", "title": "Opinion Dynamics via Search Engines (and other Algorithmic Gatekeepers)", "summary": "Ranking algorithms are the information gatekeepers of the Internet era. We\ndevelop a stylized model to study the effects of ranking algorithms on opinion\ndynamics. We consider a search engine that uses an algorithm based on\npopularity and on personalization. We find that popularity-based rankings\ngenerate an advantage of the fewer effect: fewer websites reporting a given\nsignal attract relatively more traffic overall. This highlights a novel,\nranking-driven channel that explains the diffusion of misinformation, as\nwebsites reporting incorrect information may attract an amplified amount of\ntraffic precisely because they are few. Furthermore, when individuals provide\nsufficiently positive feedback to the ranking algorithm, popularity-based\nrankings tend to aggregate information while personalization acts in the\nopposite direction.", "author": [{"name": "Fabrizio Germano"}, {"name": "Francesco Sobbrio"}], "link": [{"@href": "http://arxiv.org/abs/1810.06973v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1810.06973v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1403.3344v1", "updated": "2014-03-13T17:57:05Z", "published": "2014-03-13T17:57:05Z", "title": "Collective attention in the age of (mis)information", "summary": "In this work we study, on a sample of 2.3 million individuals, how Facebook\nusers consumed different information at the edge of political discussion and\nnews during the last Italian electoral competition. Pages are categorized,\naccording to their topics and the communities of interests they pertain to, in\na) alternative information sources (diffusing topics that are neglected by\nscience and main stream media); b) online political activism; and c) main\nstream media. We show that attention patterns are similar despite the different\nqualitative nature of the information, meaning that unsubstantiated claims\n(mainly conspiracy theories) reverberate for as long as other information.\nFinally, we categorize users according to their interaction patterns among the\ndifferent topics and measure how a sample of this social ecosystem (1279 users)\nresponded to the injection of 2788 false information posts. Our analysis\nreveals that users which are prominently interacting with alternative\ninformation sources (i.e. more exposed to unsubstantiated claims) are more\nprone to interact with false claims.", "author": [{"name": "Delia Mocanu"}, {"name": "Luca Rossi"}, {"name": "Qian Zhang"}, {"name": "M\u00e0rton Karsai"}, {"name": "Walter Quattrociocchi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "misinformation, attention patterns, false information, social\n  response"}, "link": [{"@href": "http://arxiv.org/abs/1403.3344v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1403.3344v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1807.05327v1", "updated": "2018-07-14T03:33:36Z", "published": "2018-07-14T03:33:36Z", "title": "How Humans versus Bots React to Deceptive and Trusted News Sources: A\n  Case Study of Active Users", "summary": "Society's reliance on social media as a primary source of news has spawned a\nrenewed focus on the spread of misinformation. In this work, we identify the\ndifferences in how social media accounts identified as bots react to news\nsources of varying credibility, regardless of the veracity of the content those\nsources have shared. We analyze bot and human responses annotated using a\nfine-grained model that labels responses as being an answer, appreciation,\nagreement, disagreement, an elaboration, humor, or a negative reaction. We\npresent key findings of our analysis into the prevalence of bots, the variety\nand speed of bot and human reactions, and the disparity in authorship of\nreaction tweets between these two sub-populations. We observe that bots are\nresponsible for 9-15% of the reactions to sources of any given type but\ncomprise only 7-10% of accounts responsible for reaction-tweets; trusted news\nsources have the highest proportion of humans who reacted; bots respond with\nsignificantly shorter delays than humans when posting answer-reactions in\nresponse to sources identified as propaganda. Finally, we report significantly\ndifferent inequality levels in reaction rates for accounts identified as bots\nvs not.", "author": [{"name": "Maria Glenski"}, {"name": "Tim Weninger"}, {"name": "Svitlana Volkova"}], "link": [{"@href": "http://arxiv.org/abs/1807.05327v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1807.05327v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1807.06926v1", "updated": "2018-07-18T13:41:57Z", "published": "2018-07-18T13:41:57Z", "title": "Fake news as we feel it: perception and conceptualization of the term\n  \"fake news\" in the media", "summary": "In this article, we quantitatively analyze how the term \"fake news\" is being\nshaped in news media in recent years. We study the perception and the\nconceptualization of this term in the traditional media using eight years of\ndata collected from news outlets based in 20 countries. Our results not only\ncorroborate previous indications of a high increase in the usage of the\nexpression \"fake news\", but also show contextual changes around this expression\nafter the United States presidential election of 2016. Among other results, we\nfound changes in the related vocabulary, in the mentioned entities, in the\nsurrounding topics and in the contextual polarity around the term \"fake news\",\nsuggesting that this expression underwent a change in perception and\nconceptualization after 2016. These outcomes expand the understandings on the\nusage of the term \"fake news\", helping to comprehend and more accurately\ncharacterize this relevant social phenomenon linked to misinformation and\nmanipulation.", "author": [{"name": "Evandro Cunha"}, {"name": "Gabriel Magno"}, {"name": "Josemar Caetano"}, {"name": "Douglas Teixeira"}, {"name": "Virgilio Almeida"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted as a full paper at the 10th International Conference on\n  Social Informatics (SocInfo 2018). Please cite the SocInfo version"}, "link": [{"@href": "http://arxiv.org/abs/1807.06926v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1807.06926v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.04670v1", "updated": "2018-11-12T11:40:09Z", "published": "2018-11-12T11:40:09Z", "title": "A Deep Ensemble Framework for Fake News Detection and Classification", "summary": "Fake news, rumor, incorrect information, and misinformation detection are\nnowadays crucial issues as these might have serious consequences for our social\nfabrics. The rate of such information is increasing rapidly due to the\navailability of enormous web information sources including social media feeds,\nnews blogs, online newspapers etc.\n  In this paper, we develop various deep learning models for detecting fake\nnews and classifying them into the pre-defined fine-grained categories.\n  At first, we develop models based on Convolutional Neural Network (CNN) and\nBi-directional Long Short Term Memory (Bi-LSTM) networks. The representations\nobtained from these two models are fed into a Multi-layer Perceptron Model\n(MLP) for the final classification. Our experiments on a benchmark dataset show\npromising results with an overall accuracy of 44.87\\%, which outperforms the\ncurrent state of the art.", "author": [{"name": "Arjun Roy"}, {"name": "Kingshuk Basak"}, {"name": "Asif Ekbal"}, {"name": "Pushpak Bhattacharyya"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 1 figure, accepted as a short paper in Web Intelligence 2018\n  (https://webintelligence2018.com/accepted-papers.html), title changed from\n  {\"Going Deep to Detect Liars\" Detecting Fake News using Deep Learning} to {A\n  Deep Ensemble Framework for Fake News Detection and Classification} as per\n  reviewers suggestion"}, "link": [{"@href": "http://arxiv.org/abs/1811.04670v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.04670v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1811.07031v1", "updated": "2018-11-16T20:57:37Z", "published": "2018-11-16T20:57:37Z", "title": "Improving Rotated Text Detection with Rotation Region Proposal Networks", "summary": "A significant number of images shared on social media platforms such as\nFacebook and Instagram contain text in various forms. It's increasingly\nbecoming commonplace for bad actors to share misinformation, hate speech or\nother kinds of harmful content as text overlaid on images on such platforms. A\nscene-text understanding system should hence be able to handle text in various\norientations that the adversary might use. Moreover, such a system can be\nincorporated into screen readers used to aid the visually impaired. In this\nwork, we extend the scene-text extraction system at Facebook, Rosetta, to\nefficiently handle text in various orientations. Specifically, we incorporate\nthe Rotation Region Proposal Networks (RRPN) in our text extraction pipeline\nand offer practical suggestions for building and deploying a model for\ndetecting and recognizing text in arbitrary orientations efficiently.\nExperimental results show a significant improvement on detecting rotated text.", "author": [{"name": "Jing Huang"}, {"name": "Viswanath Sivakumar"}, {"name": "Mher Mnatsakanyan"}, {"name": "Guan Pang"}], "link": [{"@href": "http://arxiv.org/abs/1811.07031v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.07031v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1811.09729v3", "updated": "2019-09-11T18:29:06Z", "published": "2018-11-24T00:06:10Z", "title": "Generate, Segment and Refine: Towards Generic Manipulation Segmentation", "summary": "Detecting manipulated images has become a significant emerging challenge. The\nadvent of image sharing platforms and the easy availability of advanced photo\nediting software have resulted in a large quantities of manipulated images\nbeing shared on the internet. While the intent behind such manipulations varies\nwidely, concerns on the spread of fake news and misinformation is growing.\nCurrent state of the art methods for detecting these manipulated images suffers\nfrom the lack of training data due to the laborious labeling process. We\naddress this problem in this paper, for which we introduce a manipulated image\ngeneration process that creates true positives using currently available\ndatasets. Drawing from traditional work on image blending, we propose a novel\ngenerator for creating such examples. In addition, we also propose to further\ncreate examples that force the algorithm to focus on boundary artifacts during\ntraining. Strong experimental results validate our proposal.", "author": [{"name": "Peng Zhou"}, {"name": "Bor-Chun Chen"}, {"name": "Xintong Han"}, {"name": "Mahyar Najibi"}, {"name": "Abhinav Shrivastava"}, {"name": "Ser Nam Lim"}, {"name": "Larry S. Davis"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AAAI-2020"}, "link": [{"@href": "http://arxiv.org/abs/1811.09729v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.09729v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1811.12349v2", "updated": "2018-12-04T16:15:25Z", "published": "2018-11-29T17:54:49Z", "title": "Combating Fake News with Interpretable News Feed Algorithms", "summary": "Nowadays, artificial intelligence algorithms are used for targeted and\npersonalized content distribution in the large scale as part of the intense\ncompetition for attention in the digital media environment. Unfortunately,\ntargeted information dissemination may result in intellectual isolation and\ndiscrimination. Further, as demonstrated in recent political events in the US\nand EU, malicious bots and social media users can create and propagate targeted\n`fake news' content in different forms for political gains. From the other\ndirection, fake news detection algorithms attempt to combat such problems by\nidentifying misinformation and fraudulent user profiles. This paper reviews\ncommon news feed algorithms as well as methods for fake news detection, and we\ndiscuss how news feed algorithms could be misused to promote falsified content,\naffect news diversity, or impact credibility. We review how news feed\nalgorithms and recommender engines can enable confirmation bias to isolate\nusers to certain news sources and affecting the perception of reality. As a\npotential solution for increasing user awareness of how content is selected or\nsorted, we argue for the use of interpretable and explainable news feed\nalgorithms. We discuss how improved user awareness and system transparency\ncould mitigate unwanted outcomes of echo chambers and bubble filters in social\nmedia.", "author": [{"name": "Sina Mohseni"}, {"name": "Eric Ragan"}], "link": [{"@href": "http://arxiv.org/abs/1811.12349v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.12349v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.01458v1", "updated": "2019-09-19T21:48:03Z", "published": "2019-09-19T21:48:03Z", "title": "Attention Based Neural Architecture for Rumor Detection with Author\n  Context Awareness", "summary": "The prevalence of social media has made information sharing possible across\nthe globe. The downside, unfortunately, is the wide spread of misinformation.\nMethods applied in most previous rumor classifiers give an equal weight, or\nattention, to words in the microblog, and do not take the context beyond\nmicroblog contents into account; therefore, the accuracy becomes plateaued. In\nthis research, we propose an ensemble neural architecture to detect rumor on\nTwitter. The architecture incorporates word attention and context from the\nauthor to enhance the classification performance. In particular, the word-level\nattention mechanism enables the architecture to put more emphasis on important\nwords when constructing the text representation. To derive further context,\nmicroblog posts composed by individual authors are exploited since they can\nreflect style and characteristics in spreading information, which are\nsignificant cues to help classify whether the shared content is rumor or\nlegitimate news. The experiment on the real-world Twitter dataset collected\nfrom two well-known rumor tracking websites demonstrates promising results.", "author": [{"name": "Sansiri Tarnpradab"}, {"name": "Kien A. Hua"}], "link": [{"@href": "http://arxiv.org/abs/1910.01458v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.01458v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.02103v1", "updated": "2019-10-04T18:45:09Z", "published": "2019-10-04T18:45:09Z", "title": "Health Wars and Beyond: The Rapidly Expanding and Efficient Network\n  Insurgency Interlinking Local and Global Online Crowds of Distrust", "summary": "We present preliminary results on the online war surrounding distrust of\nexpertise in medical science -- specifically, the issue of vaccinations. While\ndistrust and misinformation in politics can damage democratic elections, in the\nmedical context it may also endanger lives through missed vaccinations and DIY\ncancer cures. We find that this online health war has evolved into a highly\nefficient network insurgency with direct inter-crowd links across countries,\ncontinents and cultures. The online anti-vax crowds (referred to as Red) now\nappear better positioned to groom new recruits (Green) than those supporting\nestablished expertise (Blue). We also present preliminary results from a\nmathematically-grounded, crowd-based analysis of the war's evolution, which\noffers an explanation for how Red seems to be turning the tide on Blue.", "author": [{"name": "N. F. Johnson"}, {"name": "N. Velasquez"}, {"name": "N. Johnson Restrepo"}, {"name": "R. Leahy"}, {"name": "N. Gabriel"}, {"name": "S. Wuchty"}, {"name": "D. Broniatowski"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Working paper. Comments welcome"}, "link": [{"@href": "http://arxiv.org/abs/1910.02103v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.02103v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.med-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.pop-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1303.7404v1", "updated": "2013-03-28T10:29:04Z", "published": "2013-03-28T10:29:04Z", "title": "Megaprojects and Risk: An Anatomy of Ambition", "summary": "Back cover text: Megaprojects and Risk provides the first detailed\nexamination of the phenomenon of megaprojects. It is a fascinating account of\nhow the promoters of multibillion-dollar megaprojects systematically and\nself-servingly misinform parliaments, the public and the media in order to get\nprojects approved and built. It shows, in unusual depth, how the formula for\napproval is an unhealthy cocktail of underestimated costs, overestimated\nrevenues, undervalued environmental impacts and overvalued economic development\neffects. This results in projects that are extremely risky, but where the risk\nis concealed from MPs, taxpayers and investors. The authors not only explore\nthe problems but also suggest practical solutions drawing on theory and hard,\nscientific evidence from the several hundred projects in twenty nations that\nillustrate the book. Accessibly written, it will be essential reading in its\nfield for students, scholars, planners, economists, auditors, politicians,\njournalists and interested citizens.", "author": [{"name": "Bent Flyvbjerg"}, {"name": "Nils Bruzelius"}, {"name": "Werner Rothengatter"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Cambridge University Press, 2003"}, "link": [{"@href": "http://arxiv.org/abs/1303.7404v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1303.7404v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "q-fin.GN", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "q-fin.GN", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1502.07162v3", "updated": "2015-10-28T20:36:49Z", "published": "2015-02-25T13:29:17Z", "title": "Measuring Online Social Bubbles", "summary": "Social media have quickly become a prevalent channel to access information,\nspread ideas, and influence opinions. However, it has been suggested that\nsocial and algorithmic filtering may cause exposure to less diverse points of\nview, and even foster polarization and misinformation. Here we explore and\nvalidate this hypothesis quantitatively for the first time, at the collective\nand individual levels, by mining three massive datasets of web traffic, search\nlogs, and Twitter posts. Our analysis shows that collectively, people access\ninformation from a significantly narrower spectrum of sources through social\nmedia and email, compared to search. The significance of this finding for\nindividual exposure is revealed by investigating the relationship between the\ndiversity of information sources experienced by users at the collective and\nindividual level. There is a strong correlation between collective and\nindividual diversity, supporting the notion that when we use social media we\nfind ourselves inside \"social bubbles\". Our results could lead to a deeper\nunderstanding of how technology biases our exposure to new information.", "author": [{"name": "Dimitar Nikolov"}, {"name": "Diego F. M. Oliveira"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "link": [{"@href": "http://arxiv.org/abs/1502.07162v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1502.07162v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1606.04721v1", "updated": "2016-06-15T11:08:24Z", "published": "2016-06-15T11:08:24Z", "title": "Personality Traits and Echo Chambers on Facebook", "summary": "In online social networks, users tend to select information that adhere to\ntheir system of beliefs and to form polarized groups of like minded people.\nPolarization as well as its effects on online social interactions have been\nextensively investigated. Still, the relation between group formation and\npersonality traits remains unclear. A better understanding of the cognitive and\npsychological determinants of online social dynamics might help to design more\nefficient communication strategies and to challenge the digital misinformation\nthreat. In this work, we focus on users commenting posts published by US\nFacebook pages supporting scientific and conspiracy-like narratives, and we\nclassify the personality traits of those users according to their online\nbehavior. We show that different and conflicting communities are populated by\nusers showing similar psychological profiles, and that the dominant personality\nmodel is the same in both scientific and conspiracy echo chambers. Moreover, we\nobserve that the permanence within echo chambers slightly shapes users'\npsychological profiles. Our results suggest that the presence of specific\npersonality traits in individuals lead to their considerable involvement in\nsupporting narratives inside virtual echo chambers.", "author": {"name": "Alessandro Bessi"}, "link": [{"@href": "http://arxiv.org/abs/1606.04721v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1606.04721v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1704.04579v1", "updated": "2017-04-15T04:47:25Z", "published": "2017-04-15T04:47:25Z", "title": "Evaluating Quality of Chatbots and Intelligent Conversational Agents", "summary": "Chatbots are one class of intelligent, conversational software agents\nactivated by natural language input (which can be in the form of text, voice,\nor both). They provide conversational output in response, and if commanded, can\nsometimes also execute tasks. Although chatbot technologies have existed since\nthe 1960s and have influenced user interface development in games since the\nearly 1980s, chatbots are now easier to train and implement. This is due to\nplentiful open source code, widely available development platforms, and\nimplementation options via Software as a Service (SaaS). In addition to\nenhancing customer experiences and supporting learning, chatbots can also be\nused to engineer social harm - that is, to spread rumors and misinformation, or\nattack people for posting their thoughts and opinions online. This paper\npresents a literature review of quality issues and attributes as they relate to\nthe contemporary issue of chatbot development and implementation. Finally,\nquality assessment approaches are reviewed, and a quality assessment method\nbased on these attributes and the Analytic Hierarchy Process (AHP) is proposed\nand examined.", "author": [{"name": "Nicole M. Radziwill"}, {"name": "Morgan C. Benton"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Software Quality Professional, June 2017"}, "link": [{"@href": "http://arxiv.org/abs/1704.04579v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1704.04579v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1705.02522v1", "updated": "2017-05-06T19:38:33Z", "published": "2017-05-06T19:38:33Z", "title": "People on Drugs: Credibility of User Statements in Health Communities", "summary": "Online health communities are a valuable source of information for patients\nand physicians. However, such user-generated resources are often plagued by\ninaccuracies and misinformation. In this work we propose a method for\nautomatically establishing the credibility of user-generated medical statements\nand the trustworthiness of their authors by exploiting linguistic cues and\ndistant supervision from expert sources. To this end we introduce a\nprobabilistic graphical model that jointly learns user trustworthiness,\nstatement credibility, and language objectivity. We apply this methodology to\nthe task of extracting rare or unknown side-effects of medical drugs --- this\nbeing one of the problems where large scale non-expert data has the potential\nto complement expert medical knowledge. We show that our method can reliably\nextract side-effects and filter out false statements, while identifying\ntrustworthy users that are likely to contribute valuable medical information.", "author": [{"name": "Subhabrata Mukherjee"}, {"name": "Gerhard Weikum"}, {"name": "Cristian Danescu-Niculescu-Mizil"}], "link": [{"@href": "http://arxiv.org/abs/1705.02522v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1705.02522v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1705.11187v1", "updated": "2017-05-31T17:33:31Z", "published": "2017-05-31T17:33:31Z", "title": "U-Phylogeny: Undirected Provenance Graph Construction in the Wild", "summary": "Deriving relationships between images and tracing back their history of\nmodifications are at the core of Multimedia Phylogeny solutions, which aim to\ncombat misinformation through doctored visual media. Nonetheless, most recent\nimage phylogeny solutions cannot properly address cases of forged composite\nimages with multiple donors, an area known as multiple parenting phylogeny\n(MPP). This paper presents a preliminary undirected graph construction solution\nfor MPP, without any strict assumptions. The algorithm is underpinned by robust\nimage representative keypoints and different geometric consistency checks among\nmatching regions in both images to provide regions of interest for direct\ncomparison. The paper introduces a novel technique to geometrically filter the\nmost promising matches as well as to aid in the shared region localization\ntask. The strength of the approach is corroborated by experiments with\nreal-world cases, with and without image distractors (unrelated cases).", "author": [{"name": "Aparna Bharati"}, {"name": "Daniel Moreira"}, {"name": "Allan Pinto"}, {"name": "Joel Brogan"}, {"name": "Kevin Bowyer"}, {"name": "Patrick Flynn"}, {"name": "Walter Scheirer"}, {"name": "Anderson Rocha"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages, Accepted in International Conference on Image Processing,\n  2017"}, "link": [{"@href": "http://arxiv.org/abs/1705.11187v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1705.11187v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1707.03264v2", "updated": "2018-05-21T10:31:40Z", "published": "2017-07-11T13:44:51Z", "title": "A simple but tough-to-beat baseline for the Fake News Challenge stance\n  detection task", "summary": "Identifying public misinformation is a complicated and challenging task. An\nimportant part of checking the veracity of a specific claim is to evaluate the\nstance different news sources take towards the assertion. Automatic stance\nevaluation, i.e. stance detection, would arguably facilitate the process of\nfact checking. In this paper, we present our stance detection system which\nclaimed third place in Stage 1 of the Fake News Challenge. Despite our\nstraightforward approach, our system performs at a competitive level with the\ncomplex ensembles of the top two winning teams. We therefore propose our system\nas the 'simple but tough-to-beat baseline' for the Fake News Challenge stance\ndetection task.", "author": [{"name": "Benjamin Riedel"}, {"name": "Isabelle Augenstein"}, {"name": "Georgios P. Spithourakis"}, {"name": "Sebastian Riedel"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 1 figure, 3 tables; additional reference and details added,\n  typos and wording corrected"}, "link": [{"@href": "http://arxiv.org/abs/1707.03264v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1707.03264v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1707.09939v1", "updated": "2017-07-31T16:20:31Z", "published": "2017-07-31T16:20:31Z", "title": "An Analysis of the Twitter Discussion on the 2016 Austrian Presidential\n  Elections", "summary": "In this paper, we provide a systematic analysis of the Twitter discussion on\nthe 2016 Austrian presidential elections. In particular, we extracted and\nanalyzed a data-set consisting of 343645 Twitter messages related to the 2016\nAustrian presidential elections. Our analysis combines methods from network\nscience, sentiment analysis, as well as bot detection. Among other things, we\nfound that: a) the winner of the election (Alexander Van der Bellen) was\nconsiderably more popular and influential on Twitter than his opponent, b) the\nTwitter followers of Van der Bellen substantially participated in the spread of\nmisinformation about him, c) there was a clear polarization in terms of the\nsentiments spread by Twitter followers of the two presidential candidates, d)\nthe in-degree and out-degree distributions of the underlying communication\nnetwork are heavy-tailed, and e) compared to other recent events, such as the\n2016 Brexit referendum or the 2016 US presidential elections, only a very small\nnumber of bots participated in the Twitter discussion on the 2016 Austrian\npresidential election.", "author": [{"name": "Ema Ku\u0161en"}, {"name": "Mark Strembeck"}], "link": [{"@href": "http://arxiv.org/abs/1707.09939v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1707.09939v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "G.2.2; I.2.7; J.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1708.02763v2", "updated": "2018-01-04T07:51:52Z", "published": "2017-08-09T08:54:54Z", "title": "Has the Online Discussion Been Manipulated? Quantifying Online\n  Discussion Authenticity within Online Social Media", "summary": "Online social media (OSM) has a enormous influence in today's world. Some\nindividuals view OSM as fertile ground for abuse and use it to disseminate\nmisinformation and political propaganda, slander competitors, and spread spam.\nThe crowdturfing industry employs large numbers of bots and human workers to\nmanipulate OSM and misrepresent public opinion. The detection of online\ndiscussion topics manipulated by OSM \\emph{abusers} is an emerging issue\nattracting significant attention. In this paper, we propose an approach for\nquantifying the authenticity of online discussions based on the similarity of\nOSM accounts participating in the discussion to known abusers and legitimate\naccounts. Our method uses several similarity functions for the analysis and\nclassification of OSM accounts. The proposed methods are demonstrated using\nTwitter data collected for this study and previously published \\emph{Arabic\nhoneypot dataset}. The former includes manually labeled accounts and abusers\nwho participated in crowdturfing platforms. Evaluation of the topic's\nauthenticity, derived from account similarity functions, shows that the\nsuggested approach is effective for discriminating between topics that were\nstrongly promoted by abusers and topics that attracted authentic public\ninterest.", "author": [{"name": "Aviad Elyashar"}, {"name": "Jorge Bendahan"}, {"name": "Rami Puzis"}], "link": [{"@href": "http://arxiv.org/abs/1708.02763v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1708.02763v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1712.06919v1", "updated": "2017-12-19T13:39:37Z", "published": "2017-12-19T13:39:37Z", "title": "A Production Oriented Approach for Vandalism Detection in Wikidata - The\n  Buffaloberry Vandalism Detector at WSDM Cup 2017", "summary": "Wikidata is a free and open knowledge base from the Wikimedia Foundation,\nthat not only acts as a central storage of structured data for other projects\nof the organization, but also for a growing array of information systems,\nincluding search engines. Like Wikipedia, Wikidata's content can be created and\nedited by anyone; which is the main source of its strength, but also allows for\nmalicious users to vandalize it, risking the spreading of misinformation\nthrough all the systems that rely on it as a source of structured facts. Our\ntask at the WSDM Cup 2017 was to come up with a fast and reliable prediction\nsystem that narrows down suspicious edits for human revision. Elaborating on\nprevious works by Heindorf et al. we were able to outperform all other\ncontestants, while incorporating new interesting features, unifying the\nprogramming language used to only Python and refactoring the feature extractor\ninto a simpler and more compact code base.", "author": [{"name": "Rafael Crescenzi", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Austral University"}}, {"name": "Marcelo Fernandez", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Austral University"}}, {"name": "Federico A. Garcia Calabria", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Austral University"}}, {"name": "Pablo Albani", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Austral University"}}, {"name": "Diego Tauziet", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Austral University"}}, {"name": "Adriana Baravalle", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Austral University"}}, {"name": "Andr\u00e9s Sebasti\u00e1n D'Ambrosio", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Austral University"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Vandalism Detector at WSDM Cup 2017, see arXiv:1712.05956"}, "link": [{"@href": "http://arxiv.org/abs/1712.06919v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1712.06919v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1804.02233v2", "updated": "2018-04-16T11:53:56Z", "published": "2018-04-06T12:36:28Z", "title": "Forex trading and Twitter: Spam, bots, and reputation manipulation", "summary": "Currency trading (Forex) is the largest world market in terms of volume. We\nanalyze trading and tweeting about the EUR-USD currency pair over a period of\nthree years. First, a large number of tweets were manually labeled, and a\nTwitter stance classification model is constructed. The model then classifies\nall the tweets by the trading stance signal: buy, hold, or sell (EUR vs. USD).\nThe Twitter stance is compared to the actual currency rates by applying the\nevent study methodology, well-known in financial economics. It turns out that\nthere are large differences in Twitter stance distribution and potential\ntrading returns between the four groups of Twitter users: trading robots,\nspammers, trading companies, and individual traders. Additionally, we observe\nattempts of reputation manipulation by post festum removal of tweets with poor\npredictions, and deleting/reposting of identical tweets to increase the\nvisibility without tainting one's Twitter timeline.", "author": [{"name": "Igor Mozeti\u010d"}, {"name": "Peter Gabrov\u0161ek"}, {"name": "Petra Kralj Novak"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIS2: Misinformation and Misbehavior Mining on the Web, Workshop at\n  WSDM-18, Marina Del Rey, CA, USA, Feb. 9, 2018"}, "link": [{"@href": "http://arxiv.org/abs/1804.02233v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.02233v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.TH", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1805.04698v1", "updated": "2018-05-12T11:05:11Z", "published": "2018-05-12T11:05:11Z", "title": "Bitcoin Risk Modeling with Blockchain Graphs", "summary": "A key challenge for Bitcoin cryptocurrency holders, such as startups using\nICOs to raise funding, is managing their FX risk. Specifically, a misinformed\ndecision to convert Bitcoin to fiat currency could, by itself, cost USD\nmillions.\n  In contrast to financial exchanges, Blockchain based crypto-currencies expose\nthe entire transaction history to the public. By processing all transactions,\nwe model the network with a high fidelity graph so that it is possible to\ncharacterize how the flow of information in the network evolves over time. We\ndemonstrate how this data representation permits a new form of microstructure\nmodeling - with the emphasis on the topological network structures to study the\nrole of users, entities and their interactions in formation and dynamics of\ncrypto-currency investment risk. In particular, we identify certain sub-graphs\n('chainlets') that exhibit predictive influence on Bitcoin price and\nvolatility, and characterize the types of chainlets that signify extreme\nlosses.", "author": [{"name": "Cuneyt Akcora"}, {"name": "Matthew Dixon"}, {"name": "Yulia Gel"}, {"name": "Murat Kantarcioglu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "JEL Classification: C58, C63, G18"}, "link": [{"@href": "http://arxiv.org/abs/1805.04698v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1805.04698v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "q-fin.RM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "q-fin.RM", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1805.11303v1", "updated": "2018-05-29T08:34:53Z", "published": "2018-05-29T08:34:53Z", "title": "Trust-based dynamic linear threshold models for non-competitive and\n  competitive influence propagation", "summary": "What are the key-features that enable an information diffusion model to\nexplain the inherent dynamic, and often competitive, nature of real-world\npropagation phenomena? In this paper we aim to answer this question by\nproposing a novel class of diffusion models, inspired by the classic Linear\nThreshold model, and built around the following aspects: trust/distrust in the\nuser relationships, which is leveraged to model different effects of social\ninfluence on the decisions taken by an individual; changes in adopting one or\nalternative information items; hesitation towards adopting an information item\nover time; latency in the propagation; time horizon for the unfolding of the\ndiffusion process; and multiple cascades of information that might occur\ncompetitively. To the best of our knowledge, the above aspects have never been\nunified into the same LT-based diffusion model. We also define different\nstrategies for the selection of the initial influencers to simulate\nnon-competitive and competitive diffusion scenarios, particularly related to\nthe problem of limitation of misinformation spread. Results on publicly\navailable networks have shown the meaningfulness and uniqueness of our models.", "author": [{"name": "Antonio Cali\u00f2"}, {"name": "Andrea Tagarelli"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted (May 5, 2018) at the IEEE TrustCom/BigDataSE 2018 Conference"}, "link": [{"@href": "http://arxiv.org/abs/1805.11303v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1805.11303v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1806.01997v1", "updated": "2018-06-06T03:47:39Z", "published": "2018-06-06T03:47:39Z", "title": "TrollSpot: Detecting misbehavior in commenting platforms", "summary": "Commenting platforms, such as Disqus, have emerged as a major online\ncommunication platform with millions of users and posts. Their popularity has\nalso attracted parasitic and malicious behav- iors, such as trolling and\nspamming. There has been relatively little research on modeling and\nsafeguarding these platforms. As our key contribution, we develop a systematic\napproach to detect malicious users on commenting platforms focusing on having:\n(a) interpretable, and (b) fine-grained classification of malice. Our work has\ntwo key novelties: (a) we propose two classifications methods, with one\nfollowing a two stage approach, which first maps observ- able features to\nbehaviors and then maps these behaviors to user roles, and (b) we use a\ncomprehensive set of 73 features that span four dimensions of information. We\nuse 7 million comments during a 9 month period, and we show that our\nclassification methods can distinguish between benign, and malicious roles\n(spammers, trollers, and fanatics) with a 0.904 AUC. Our work is a solid step\nto- wards ensuring that commenting platforms are a safe and pleasant medium for\nthe exchange of ideas.", "author": [{"name": "Tai Ching Li"}, {"name": "Joobin Gharibshah"}, {"name": "Evangelos E. Papalexakis"}, {"name": "Michalis Faloutsos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted in WSDM workshop on Misinformation and Misbehavior Mining on\n  the Web, 2018"}, "link": [{"@href": "http://arxiv.org/abs/1806.01997v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.01997v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1806.02720v1", "updated": "2018-06-07T15:09:57Z", "published": "2018-06-07T15:09:57Z", "title": "Anchored in a Data Storm: How Anchoring Bias Can Affect User Strategy,\n  Confidence, and Decisions in Visual Analytics", "summary": "Cognitive biases have been shown to lead to faulty decision-making. Recent\nresearch has demonstrated that the effect of cognitive biases, anchoring bias\nin particular, transfers to information visualization and visual analytics.\nHowever, it is still unclear how users of visual interfaces can be anchored and\nthe impact of anchoring on user performance and decision-making process. To\ninvestigate, we performed two rounds of between-subjects, in-laboratory\nexperiments with 94 participants to analyze the effect of visual anchors and\nstrategy cues in decision-making with a visual analytic system that employs\ncoordinated multiple view design. The decision-making task is identifying\nmisinformation from Twitter news accounts. Participants were randomly assigned\none of three treatment groups (including control) in which participant training\nprocesses were modified. Our findings reveal that strategy cues and visual\nanchors (scenario videos) can significantly affect user activity, speed,\nconfidence, and, under certain circumstances, accuracy. We discuss the\nimplications of our experiment results on training users how to use a newly\ndeveloped visual interface. We call for more careful consideration into how\nvisualization designers and researchers train users to avoid unintentionally\nanchoring users and thus affecting the end result.", "author": [{"name": "Ryan Wesslen"}, {"name": "Sashank Santhanam"}, {"name": "Alireza Karduni"}, {"name": "Isaac Cho"}, {"name": "Samira Shaikh"}, {"name": "Wenwen Dou"}], "link": [{"@href": "http://arxiv.org/abs/1806.02720v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.02720v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1806.07516v2", "updated": "2019-10-09T22:04:46Z", "published": "2018-06-20T01:26:21Z", "title": "The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake\n  News", "summary": "A large body of research work and efforts have been focused on detecting fake\nnews and building online fact-check systems in order to debunk fake news as\nsoon as possible. Despite the existence of these systems, fake news is still\nwildly shared by online users. It indicates that these systems may not be fully\nutilized. After detecting fake news, what is the next step to stop people from\nsharing it? How can we improve the utilization of these fact-check systems? To\nfill this gap, in this paper, we (i) collect and analyze online users called\nguardians, who correct misinformation and fake news in online discussions by\nreferring fact-checking URLs; and (ii) propose a novel fact-checking URL\nrecommendation model to encourage the guardians to engage more in fact-checking\nactivities. We found that the guardians usually took less than one day to reply\nto claims in online conversations and took another day to spread verified\ninformation to hundreds of millions of followers. Our proposed recommendation\nmodel outperformed four state-of-the-art models by 11%~33%. Our source code and\ndataset are available at https://github.com/nguyenvo09/CombatingFakeNews.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SIGIR 2018"}, "link": [{"@href": "http://arxiv.org/abs/1806.07516v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.07516v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1806.07687v2", "updated": "2018-09-05T12:47:39Z", "published": "2018-06-20T12:13:53Z", "title": "Automated Fact Checking: Task formulations, methods and future\n  directions", "summary": "The recently increased focus on misinformation has stimulated research in\nfact checking, the task of assessing the truthfulness of a claim. Research in\nautomating this task has been conducted in a variety of disciplines including\nnatural language processing, machine learning, knowledge representation,\ndatabases, and journalism. While there has been substantial progress, relevant\npapers and articles have been published in research communities that are often\nunaware of each other and use inconsistent terminology, thus impeding\nunderstanding and further progress. In this paper we survey automated fact\nchecking research stemming from natural language processing and related\ndisciplines, unifying the task formulations and methodologies across papers and\nauthors. Furthermore, we highlight the use of evidence as an important\ndistinguishing factor among them cutting across task formulations and methods.\nWe conclude with proposing avenues for future NLP research on automated fact\nchecking.", "author": [{"name": "James Thorne"}, {"name": "Andreas Vlachos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at the 27th International Conference on Computational\n  Linguistics (COLING 2018)"}, "link": [{"@href": "http://arxiv.org/abs/1806.07687v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.07687v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1806.09541v1", "updated": "2018-06-06T10:47:20Z", "published": "2018-06-06T10:47:20Z", "title": "Technology, Propaganda, and the Limits of Human Intellect", "summary": "\"Fake news\" is a recent phenomenon, but misinformation and propaganda are\nnot. Our new communication technologies make it easy for us to be exposed to\nhigh volumes of true, false, irrelevant, and unprovable information. Future AI\nis expected to amplify the problem even more. At the same time, our brains are\nreaching their limits in handling information. How should we respond to\npropaganda? Technology can help, but relying on it alone will not suffice in\nthe long term. We also need ethical policies, laws, regulations, and trusted\nauthorities, including fact-checkers. However, we will not solve the problem\nwithout the active engagement of the educated citizen. Epistemological\neducation, recognition of self biases and protection of our channels of\ncommunication and trusted networks are all needed to overcome the problem and\ncontinue our progress as democratic societies.", "author": {"name": "Panagiotis Metaxas"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages"}, "link": [{"@href": "http://arxiv.org/abs/1806.09541v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.09541v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.GL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1808.06809v1", "updated": "2018-08-21T09:08:56Z", "published": "2018-08-21T09:08:56Z", "title": "Are You Tampering With My Data?", "summary": "We propose a novel approach towards adversarial attacks on neural networks\n(NN), focusing on tampering the data used for training instead of generating\nattacks on trained models. Our network-agnostic method creates a backdoor\nduring training which can be exploited at test time to force a neural network\nto exhibit abnormal behaviour. We demonstrate on two widely used datasets\n(CIFAR-10 and SVHN) that a universal modification of just one pixel per image\nfor all the images of a class in the training set is enough to corrupt the\ntraining procedure of several state-of-the-art deep neural networks causing the\nnetworks to misclassify any images to which the modification is applied. Our\naim is to bring to the attention of the machine learning community, the\npossibility that even learning-based methods that are personally trained on\npublic datasets can be subject to attacks by a skillful adversary.", "author": [{"name": "Michele Alberti"}, {"name": "Vinaychandran Pondenkandath"}, {"name": "Marcel W\u00fcrsch"}, {"name": "Manuel Bouillon"}, {"name": "Mathias Seuret"}, {"name": "Rolf Ingold"}, {"name": "Marcus Liwicki"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "18 pages"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "European Conference on Computer Vision (ECCV 2018), Workshop on\n  Objectionable Content and Misinformation"}, "link": [{"@href": "http://arxiv.org/abs/1808.06809v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.06809v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1808.08524v2", "updated": "2020-01-21T17:41:41Z", "published": "2018-08-26T09:46:47Z", "title": "When facts fail: Bias, polarisation and truth in social networks", "summary": "Online social networks provide users with unprecedented opportunities to\nengage with diverse opinions. At the same time, they enable confirmation bias\non large scales by empowering individuals to self-select narratives they want\nto be exposed to. A precise understanding of such tradeoffs is still largely\nmissing. We introduce a social learning model where most participants in a\nnetwork update their beliefs unbiasedly based on new information, while a\nminority of participants reject information that is incongruent with their\npreexisting beliefs. This simple mechanism generates permanent opinion\npolarization and cascade dynamics, and accounts for the aforementioned tradeoff\nbetween confirmation bias and social connectivity through analytic results. We\ninvestigate the model's predictions empirically using US county-level data on\nthe impact of Internet access on the formation of beliefs about global warming.\nWe conclude by discussing policy implications of our model, highlighting the\ndownsides of debunking and suggesting alternative strategies to contrast\nmisinformation.", "author": [{"name": "Orowa Sikder"}, {"name": "Robert E. Smith"}, {"name": "Pierpaolo Vivo"}, {"name": "Giacomo Livan"}], "link": [{"@href": "http://arxiv.org/abs/1808.08524v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.08524v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.06416v1", "updated": "2018-09-17T19:51:18Z", "published": "2018-09-17T19:51:18Z", "title": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning", "summary": "Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.", "author": [{"name": "Kashyap Popat"}, {"name": "Subhabrata Mukherjee"}, {"name": "Andrew Yates"}, {"name": "Gerhard Weikum"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EMNLP 2018"}, "link": [{"@href": "http://arxiv.org/abs/1809.06416v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.06416v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1812.09383v2", "updated": "2019-01-03T14:35:55Z", "published": "2018-12-21T21:46:34Z", "title": "Technology-Enabled Disinformation: Summary, Lessons, and Recommendations", "summary": "Technology is increasingly used -- unintentionally (misinformation) or\nintentionally (disinformation) -- to spread false information at scale, with\npotentially broad-reaching societal effects. For example, technology enables\nincreasingly realistic false images and videos, and hyper-personal targeting\nmeans different people may see different versions of reality. This report is\nthe culmination of a PhD-level special topics course\n(https://courses.cs.washington.edu/courses/cse599b/18au/) in Computer Science &\nEngineering at the University of Washington's Paul G. Allen School in the fall\nof 2018. The goals of this course were to study (1) how technologies and\ntoday's technical platforms enable and support the creation and spread of such\nmis- and disinformation, as well as (2) how technical approaches could be used\nto mitigate these issues. In this report, we summarize the space of\ntechnology-enabled mis- and disinformation based on our investigations, and\nthen surface our lessons and recommendations for technologists, researchers,\nplatform designers, policymakers, and users.", "author": [{"name": "John Akers"}, {"name": "Gagan Bansal"}, {"name": "Gabriel Cadamuro"}, {"name": "Christine Chen"}, {"name": "Quanze Chen"}, {"name": "Lucy Lin"}, {"name": "Phoebe Mulcaire"}, {"name": "Rajalakshmi Nandakumar"}, {"name": "Matthew Rockett"}, {"name": "Lucy Simko"}, {"name": "John Toman"}, {"name": "Tongshuang Wu"}, {"name": "Eric Zeng"}, {"name": "Bill Zorn"}, {"name": "Franziska Roesner"}], "link": [{"@href": "http://arxiv.org/abs/1812.09383v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.09383v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1812.11535v1", "updated": "2018-12-30T13:53:44Z", "published": "2018-12-30T13:53:44Z", "title": "Group based Centrality for Immunization of Complex Networks", "summary": "Network immunization is an extensively recognized issue in several domains\nlike virtual network security, public health and social media, to deal with the\nproblem of node inoculation so as to minimize the transmission through the\nlinks existed in these networks. We aim to identify top ranked nodes to\nimmunize networks, leading to control the outbreak of epidemics or\nmisinformation. We consider group based centrality and define a heuristic\nobjective criteria to establish the target of key nodes finding in network\nwhich if immunized result in essential network vulnerability. We propose a\ngroup based game theoretic payoff division approach, by employing Shapley value\nto assign the surplus acquired by participating nodes in different groups\nthrough the positional power and functional influence over other nodes. We tag\nthese key nodes as Shapley Value based Information Delimiters (SVID).\nExperiments on empirical data sets and model networks establish the efficacy of\nour proposed approach and acknowledge performance of node inoculation to\ndelimit contagion outbreak.", "author": [{"name": "Chandni Saxena"}, {"name": "M. N. Doja"}, {"name": "Tanvir Ahmad"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.physa.2018.05.107"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.physa.2018.05.107", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1812.11535v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.11535v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Physica A: Statistical Mechanics and its Applications Volume 508,\n  15 October 2018, Pages 35-47"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1901.06437v1", "updated": "2019-01-18T22:57:09Z", "published": "2019-01-18T22:57:09Z", "title": "Combating Fake News: A Survey on Identification and Mitigation\n  Techniques", "summary": "The proliferation of fake news on social media has opened up new directions\nof research for timely identification and containment of fake news, and\nmitigation of its widespread impact on public opinion. While much of the\nearlier research was focused on identification of fake news based on its\ncontents or by exploiting users' engagements with the news on social media,\nthere has been a rising interest in proactive intervention strategies to\ncounter the spread of misinformation and its impact on society. In this survey,\nwe describe the modern-day problem of fake news and, in particular, highlight\nthe technical challenges associated with it. We discuss existing methods and\ntechniques applicable to both identification and mitigation, with a focus on\nthe significant advances in each method and their advantages and limitations.\nIn addition, research has often been limited by the quality of existing\ndatasets and their specific application contexts. To alleviate this problem, we\ncomprehensively compile and summarize characteristic features of available\ndatasets. Furthermore, we outline new directions of research to facilitate\nfuture development of effective and interdisciplinary solutions.", "author": [{"name": "Karishma Sharma"}, {"name": "Feng Qian"}, {"name": "He Jiang"}, {"name": "Natali Ruchansky"}, {"name": "Ming Zhang"}, {"name": "Yan Liu"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACM Transactions on Intelligent Systems and Technology, 2019"}, "link": [{"@href": "http://arxiv.org/abs/1901.06437v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.06437v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1902.02580v2", "updated": "2019-06-14T09:51:50Z", "published": "2019-02-07T12:00:35Z", "title": "The few-get-richer: a surprising consequence of popularity-based\n  rankings", "summary": "Ranking algorithms play a crucial role in online platforms ranging from\nsearch engines to recommender systems. In this paper, we identify a surprising\nconsequence of popularity-based rankings: the fewer the items reporting a given\nsignal, the higher the share of the overall traffic they collectively attract.\nThis few-get-richer effect emerges in settings where there are few distinct\nclasses of items (e.g., left-leaning news sources versus right-leaning news\nsources), and items are ranked based on their popularity. We demonstrate\nanalytically that the few-get-richer effect emerges when people tend to click\non top-ranked items and have heterogeneous preferences for the classes of\nitems. Using simulations, we analyze how the strength of the effect changes\nwith assumptions about the setting and human behavior. We also test our\npredictions experimentally in an online experiment with human participants. Our\nfindings have important implications to understand the spread of\nmisinformation.", "author": [{"name": "Fabrizio Germano"}, {"name": "Vicen\u00e7 G\u00f3mez"}, {"name": "Ga\u00ebl Le Mens"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "7 pages, 3 figures, 1 table, Proceedings of The Web Conference (WWW\n  2019)"}, "link": [{"@href": "http://arxiv.org/abs/1902.02580v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.02580v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.1; H.3.3; G.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1903.00788v3", "updated": "2019-04-09T21:17:49Z", "published": "2019-03-02T23:14:58Z", "title": "AIRD: Adversarial Learning Framework for Image Repurposing Detection", "summary": "Image repurposing is a commonly used method for spreading misinformation on\nsocial media and online forums, which involves publishing untampered images\nwith modified metadata to create rumors and further propaganda. While manual\nverification is possible, given vast amounts of verified knowledge available on\nthe internet, the increasing prevalence and ease of this form of semantic\nmanipulation call for the development of robust automatic ways of assessing the\nsemantic integrity of multimedia data. In this paper, we present a novel method\nfor image repurposing detection that is based on the real-world adversarial\ninterplay between a bad actor who repurposes images with counterfeit metadata\nand a watchdog who verifies the semantic consistency between images and their\naccompanying metadata, where both players have access to a reference dataset of\nverified content, which they can use to achieve their goals. The proposed\nmethod exhibits state-of-the-art performance on location-identity,\nsubject-identity and painting-artist verification, showing its efficacy across\na diverse set of scenarios.", "author": [{"name": "Ayush Jaiswal"}, {"name": "Yue Wu"}, {"name": "Wael AbdAlmageed"}, {"name": "Iacopo Masi"}, {"name": "Premkumar Natarajan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Camera-ready version for the IEEE Conference on Computer Vision and\n  Pattern Recognition (CVPR), 2019"}, "link": [{"@href": "http://arxiv.org/abs/1903.00788v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.00788v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1903.11452v3", "updated": "2020-08-20T20:19:03Z", "published": "2019-03-27T14:28:17Z", "title": "Lexical convergence and collective identities on Facebook", "summary": "Recent studies, targeting Facebook, showed the tendency of users to interact\nwith information adhering to their preferred narrative and to ignore dissenting\ninformation. Primarily driven by confirmation bias, users tend to join\npolarized clusters where they cooperate to reinforce a like-minded system of\nbeliefs, thus facilitating fake news and misinformation cascades. To gain a\ndeeper understanding of these phenomena, in this work we analyze the lexicons\nused by the communities of users emerging on Facebook around verified and\nunverified contents. We show how the lexical approach provides important\ninsights about the kind of information processed by the two communities of\nusers and about their overall sentiment. Furthermore, by focusing on comment\nthreads, we observe a strong positive correlation between the lexical\nconvergence of co-commenters and their number of interactions, which in turns\nsuggests that such a trend could be a proxy for the emergence of collective\nidentities and polarization in opinion dynamics.", "author": [{"name": "Emanuele Brugnoli"}, {"name": "Matteo Cinelli"}, {"name": "Fabiana Zollo"}, {"name": "Walter Quattrociocchi"}, {"name": "Antonio Scala"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 9 figures"}, "link": [{"@href": "http://arxiv.org/abs/1903.11452v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.11452v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "91F20", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.02037v1", "updated": "2019-04-03T14:46:44Z", "published": "2019-04-03T14:46:44Z", "title": "Automated Fact Checking in the News Room", "summary": "Fact checking is an essential task in journalism; its importance has been\nhighlighted due to recently increased concerns and efforts in combating\nmisinformation. In this paper, we present an automated fact-checking platform\nwhich given a claim, it retrieves relevant textual evidence from a document\ncollection, predicts whether each piece of evidence supports or refutes the\nclaim, and returns a final verdict. We describe the architecture of the system\nand the user interface, focusing on the choices made to improve its\nuser-friendliness and transparency. We conduct a user study of the\nfact-checking platform in a journalistic setting: we integrated it with a\ncollection of news articles and provide an evaluation of the platform using\nfeedback from journalists in their workflow. We found that the predictions of\nour platform were correct 58\\% of the time, and 59\\% of the returned evidence\nwas relevant.", "author": [{"name": "Sebasti\u00e3o Miranda"}, {"name": "David Nogueira"}, {"name": "Afonso Mendes"}, {"name": "Andreas Vlachos"}, {"name": "Andrew Secker"}, {"name": "Rebecca Garrett"}, {"name": "Jeff Mitchel"}, {"name": "Zita Marinho"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "WEBCONF 2019"}, "link": [{"@href": "http://arxiv.org/abs/1904.02037v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.02037v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.05386v2", "updated": "2019-10-20T19:30:09Z", "published": "2019-04-10T18:42:45Z", "title": "Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality", "summary": "The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media.", "author": [{"name": "Paula Fraga-Lamas"}, {"name": "Tiago M. Fern\u00e1ndez-Caram\u00e9s"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Updated version"}, "link": [{"@href": "http://arxiv.org/abs/1904.05386v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.05386v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.00582v3", "updated": "2019-05-16T06:56:55Z", "published": "2019-05-02T06:06:25Z", "title": "Recurrent Convolutional Strategies for Face Manipulation Detection in\n  Videos", "summary": "The spread of misinformation through synthetically generated yet realistic\nimages and videos has become a significant problem, calling for robust\nmanipulation detection methods. Despite the predominant effort of detecting\nface manipulation in still images, less attention has been paid to the\nidentification of tampered faces in videos by taking advantage of the temporal\ninformation present in the stream. Recurrent convolutional models are a class\nof deep learning models which have proven effective at exploiting the temporal\ninformation from image streams across domains. We thereby distill the best\nstrategy for combining variations in these models along with domain specific\nface preprocessing techniques through extensive experimentation to obtain\nstate-of-the-art performance on publicly available video-based facial\nmanipulation benchmarks. Specifically, we attempt to detect Deepfake, Face2Face\nand FaceSwap tampered faces in video streams. Evaluation is performed on the\nrecently introduced FaceForensics++ dataset, improving the previous\nstate-of-the-art by up to 4.55% in accuracy.", "author": [{"name": "Ekraam Sabir"}, {"name": "Jiaxin Cheng"}, {"name": "Ayush Jaiswal"}, {"name": "Wael AbdAlmageed"}, {"name": "Iacopo Masi"}, {"name": "Prem Natarajan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear at Workshop on Applications of Computer Vision and Pattern\n  Recognition to Media Forensics at CVPR 2019"}, "link": [{"@href": "http://arxiv.org/abs/1905.00582v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.00582v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1906.12325v2", "updated": "2020-02-27T16:05:21Z", "published": "2019-06-28T17:27:35Z", "title": "Modeling echo chambers and polarization dynamics in social networks", "summary": "Echo chambers and opinion polarization recently quantified in several\nsociopolitical contexts and across different social media, raise concerns on\ntheir potential impact on the spread of misinformation and on openness of\ndebates. Despite increasing efforts, the dynamics leading to the emergence of\nthese phenomena stay unclear. We propose a model that introduces the dynamics\nof radicalization, as a reinforcing mechanism driving the evolution to extreme\nopinions from moderate initial conditions. Inspired by empirical findings on\nsocial interaction dynamics, we consider agents characterized by heterogeneous\nactivities and homophily. We show that the transition between a global\nconsensus and emerging radicalized states is mostly governed by social\ninfluence and by the controversialness of the topic discussed. Compared with\nempirical data of polarized debates on Twitter, the model qualitatively\nreproduces the observed relation between users' engagement and opinions, as\nwell as opinion segregation in the interaction network. Our findings shed light\non the mechanisms that may lie at the core of the emergence of echo chambers\nand polarization in social media.", "author": [{"name": "Fabian Baumann"}, {"name": "Philipp Lorenz-Spreen"}, {"name": "Igor M. Sokolov"}, {"name": "Michele Starnini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevLett.124.048301"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevLett.124.048301", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1906.12325v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.12325v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys. Rev. Lett. 124, 048301 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1907.03588v1", "updated": "2019-07-05T17:16:14Z", "published": "2019-07-05T17:16:14Z", "title": "A New Approach to Distributed Hypothesis Testing and Non-Bayesian\n  Learning: Improved Learning Rate and Byzantine-Resilience", "summary": "We study a setting where a group of agents, each receiving partially\ninformative private signals, seek to collaboratively learn the true underlying\nstate of the world (from a finite set of hypotheses) that generates their joint\nobservation profiles. To solve this problem, we propose a distributed learning\nrule that differs fundamentally from existing approaches, in that it does not\nemploy any form of \"belief-averaging\". Instead, agents update their beliefs\nbased on a min-rule. Under standard assumptions on the observation model and\nthe network structure, we establish that each agent learns the truth\nasymptotically almost surely. As our main contribution, we prove that with\nprobability 1, each false hypothesis is ruled out by every agent exponentially\nfast at a network-independent rate that is strictly larger than existing rates.\nWe then develop a computationally-efficient variant of our learning rule that\nis provably resilient to agents who do not behave as expected (as represented\nby a Byzantine adversary model) and deliberately try to spread misinformation.", "author": [{"name": "Aritra Mitra"}, {"name": "John A. Richards"}, {"name": "Shreyas Sundaram"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: text overlap with arXiv:1903.05817"}, "link": [{"@href": "http://arxiv.org/abs/1907.03588v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.03588v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "eess.SY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "eess.SY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.IT", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1907.06130v2", "updated": "2020-04-12T01:01:00Z", "published": "2019-07-13T21:12:08Z", "title": "Manipulating the Online Marketplace of Ideas", "summary": "Social media, the modern marketplace of ideas, is vulnerable to manipulation.\nDeceptive inauthentic actors impersonate humans to amplify misinformation and\ninfluence public opinions. Little is known about the large-scale consequences\nof such operations, due to the ethical challenges posed by online experiments\nthat manipulate human behavior. Here we introduce a model of information\nspreading where agents prefer quality information but have limited attention.\nWe evaluate the impact of manipulation strategies aimed at degrading the\noverall quality of the information ecosystem. The model reproduces empirical\npatterns about amplification of low-quality information. We find that\ninfiltrating a critical fraction of the network is more damaging than\ngenerating attention-grabbing content or targeting influentials. We discuss\ncountermeasures suggested by these insights to increase the resilience of\nsocial media users to manipulation, and legal issues arising from regulations\naimed at protecting human speech from suppression by inauthentic actors.", "author": [{"name": "Xiaodan Lou"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "25 pages, 8 figures, 80 references"}, "link": [{"@href": "http://arxiv.org/abs/1907.06130v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.06130v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1907.11543v2", "updated": "2019-07-29T03:14:27Z", "published": "2019-07-26T12:52:57Z", "title": "Entropy-Regularized Stochastic Games", "summary": "In two-player zero-sum stochastic games, where two competing players make\ndecisions under uncertainty, a pair of optimal strategies is traditionally\ndescribed by Nash equilibrium and computed under the assumption that the\nplayers have perfect information about the stochastic transition model of the\nenvironment. However, implementing such strategies may make the players\nvulnerable to unforeseen changes in the environment. In this paper, we\nintroduce entropy-regularized stochastic games where each player aims to\nmaximize the causal entropy of its strategy in addition to its expected payoff.\nThe regularization term balances each player's rationality with its belief\nabout the level of misinformation about the transition model. We consider both\nentropy-regularized $N$-stage and entropy-regularized discounted stochastic\ngames, and establish the existence of a value in both games. Moreover, we prove\nthe sufficiency of Markovian and stationary mixed strategies to attain the\nvalue, respectively, in $N$-stage and discounted games. Finally, we present\nalgorithms, which are based on convex optimization problems, to compute the\noptimal strategies. In a numerical example, we demonstrate the proposed method\non a motion planning scenario and illustrate the effect of the regularization\nterm on the expected payoff.", "author": [{"name": "Yagiz Savas"}, {"name": "Mohamadreza Ahmadi"}, {"name": "Takashi Tanaka"}, {"name": "Ufuk Topcu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Corrected typos"}, "link": [{"@href": "http://arxiv.org/abs/1907.11543v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.11543v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "math.OC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "math.OC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1908.00153v2", "updated": "2019-08-29T00:46:25Z", "published": "2019-08-01T00:28:57Z", "title": "Hateful People or Hateful Bots? Detection and Characterization of Bots\n  Spreading Religious Hatred in Arabic Social Media", "summary": "Arabic Twitter space is crawling with bots that fuel political feuds, spread\nmisinformation, and proliferate sectarian rhetoric. While efforts have long\nexisted to analyze and detect English bots, Arabic bot detection and\ncharacterization remains largely understudied. In this work, we contribute new\ninsights into the role of bots in spreading religious hatred on Arabic Twitter\nand introduce a novel regression model that can accurately identify Arabic\nlanguage bots. Our assessment shows that existing tools that are highly\naccurate in detecting English bots don't perform as well on Arabic bots. We\nidentify the possible reasons for this poor performance, perform a thorough\nanalysis of linguistic, content, behavioral and network features, and report on\nthe most informative features that distinguish Arabic bots from humans as well\nas the differences between Arabic and English bots. Our results mark an\nimportant step toward understanding the behavior of malicious bots on Arabic\nTwitter and pave the way for a more effective Arabic bot detection tools.", "author": [{"name": "Nuha Albadi"}, {"name": "Maram Kurdi"}, {"name": "Shivakant Mishra"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3359163"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3359163", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1908.00153v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.00153v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proc. ACM Hum.-Comput. Interact. 3, CSCW: Article 61 (2019)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.01760v1", "updated": "2019-08-05T17:59:44Z", "published": "2019-08-05T17:59:44Z", "title": "The Myths of Our Time: Fake News", "summary": "While the purpose of most fake news is misinformation and political\npropaganda, our team sees it as a new type of myth that is created by people in\nthe age of internet identities and artificial intelligence. Seeking insights on\nthe fear and desire hidden underneath these modified or generated stories, we\nuse machine learning methods to generate fake articles and present them in the\nform of an online news blog. This paper aims to share the details of our\npipeline and the techniques used for full generation of fake news, from dataset\ncollection to presentation as a media art project on the internet.", "author": [{"name": "V\u00edt R\u016f\u017ei\u010dka"}, {"name": "Eunsu Kang"}, {"name": "David Gordon"}, {"name": "Ankita Patel"}, {"name": "Jacqui Fashimpaur"}, {"name": "Manzil Zaheer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages, 5 figures, in proceedings of International Symposium on\n  Electronic Art 2019 (ISEA)"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of International Symposium on Electronic Art 2019\n  (ISEA), pages 494-498"}, "link": [{"@href": "http://arxiv.org/abs/1908.01760v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.01760v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.03957v1", "updated": "2019-08-11T19:51:48Z", "published": "2019-08-11T19:51:48Z", "title": "Tensor Factorization with Label Information for Fake News Detection", "summary": "The buzz over the so-called \"fake news\" has created concerns about a\ndegenerated media environment and led to the need for technological solutions.\nAs the detection of fake news is increasingly considered a technological\nproblem, it has attracted considerable research. Most of these studies\nprimarily focus on utilizing information extracted from textual news content.\nIn contrast, we focus on detecting fake news solely based on structural\ninformation of social networks. We suggest that the underlying network\nconnections of users that share fake news are discriminative enough to support\nthe detection of fake news. Thereupon, we model each post as a network of\nfriendship interactions and represent a collection of posts as a\nmultidimensional tensor. Taking into account the available labeled data, we\npropose a tensor factorization method which associates the class labels of data\nsamples with their latent representations. Specifically, we combine a\nclassification error term with the standard factorization in a unified\noptimization process. Results on real-world datasets demonstrate that our\nproposed method is competitive against state-of-the-art methods by implementing\nan arguably simpler approach.", "author": [{"name": "Frosso Papanastasiou"}, {"name": "Georgios Katsimpras"}, {"name": "Georgios Paliouras"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Presented at the Workshop on Reducing Online Misinformation Exposure\n  ROME 2019"}, "link": [{"@href": "http://arxiv.org/abs/1908.03957v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.03957v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.00643v1", "updated": "2019-11-02T04:06:30Z", "published": "2019-11-02T04:06:30Z", "title": "Credibility-based Fake News Detection", "summary": "Fake news can significantly misinform people who often rely on online sources\nand social media for their information. Current research on fake news detection\nhas mostly focused on analyzing fake news content and how it propagates on a\nnetwork of users. In this paper, we emphasize the detection of fake news by\nassessing its credibility. By analyzing public fake news data, we show that\ninformation on news sources (and authors) can be a strong indicator of\ncredibility. Our findings suggest that an author's history of association with\nfake news, and the number of authors of a news article, can play a significant\nrole in detecting fake news. Our approach can help improve traditional fake\nnews detection methods, wherein content features are often used to detect fake\nnews.", "author": [{"name": "Niraj Sitaula"}, {"name": "Chilukuri K. Mohan"}, {"name": "Jennifer Grygiel"}, {"name": "Xinyi Zhou"}, {"name": "Reza Zafarani"}], "link": [{"@href": "http://arxiv.org/abs/1911.00643v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.00643v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1912.01708v1", "updated": "2019-11-20T23:32:59Z", "published": "2019-11-20T23:32:59Z", "title": "Celebrating Three Decades of Worldwide Stock Market Manipulation", "summary": "As the decade turns, we reflect on nearly thirty years of successful\nmanipulation of the world's public equity markets. This reflection highlights a\nfew of the key enabling ingredients and lessons learned along the way. A\nquantitative understanding of market impact and its decay, which we cover\nbriefly, lets you move long-term market prices to your advantage at acceptable\ncost. Hiding your footprints turns out to be less important than moving prices\nin the direction most people want them to move. Widespread (if misplaced) trust\nof market prices -- buttressed by overestimates of the cost of manipulation and\nunderestimates of the benefits to certain market participants -- makes price\nmanipulation a particularly valuable and profitable tool. Of the many recent\nstories heralding the dawn of the present golden age of misinformation, the\nmanipulation leading to the remarkable increase in the market capitalization of\nthe world's publicly traded companies over the past three decades is among the\nbest.", "author": {"name": "Bruce Knuteson"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages"}, "link": [{"@href": "http://arxiv.org/abs/1912.01708v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.01708v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "q-fin.GN", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "q-fin.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.TR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1912.06745v1", "updated": "2019-12-13T23:32:38Z", "published": "2019-12-13T23:32:38Z", "title": "An Unsupervised Domain-Independent Framework for Automated Detection of\n  Persuasion Tactics in Text", "summary": "With the increasing growth of social media, people have started relying\nheavily on the information shared therein to form opinions and make decisions.\nWhile such a reliance is motivation for a variety of parties to promote\ninformation, it also makes people vulnerable to exploitation by slander,\nmisinformation, terroristic and predatorial advances. In this work, we aim to\nunderstand and detect such attempts at persuasion. Existing works on detecting\npersuasion in text make use of lexical features for detecting persuasive\ntactics, without taking advantage of the possible structures inherent in the\ntactics used. We formulate the task as a multi-class classification problem and\npropose an unsupervised, domain-independent machine learning framework for\ndetecting the type of persuasion used in text, which exploits the inherent\nsentence structure present in the different persuasion tactics. Our work shows\npromising results as compared to existing work.", "author": [{"name": "Rahul Radhakrishnan Iyer"}, {"name": "Katia Sycara"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "19 pages, 8 Figures"}, "link": [{"@href": "http://arxiv.org/abs/1912.06745v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.06745v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.03231v2", "updated": "2020-01-31T01:50:53Z", "published": "2020-01-09T21:45:25Z", "title": "Four Years in Review: Statistical Practices of Likert Scales in\n  Human-Robot Interaction Studies", "summary": "As robots become more prevalent, the importance of the field of human-robot\ninteraction (HRI) grows accordingly. As such, we should endeavor to employ the\nbest statistical practices. Likert scales are commonly used metrics in HRI to\nmeasure perceptions and attitudes. Due to misinformation or honest mistakes,\nmost HRI researchers do not adopt best practices when analyzing Likert data. We\nconduct a review of psychometric literature to determine the current standard\nfor Likert scale design and analysis. Next, we conduct a survey of four years\nof the International Conference on Human-Robot Interaction (2016 through 2019)\nand report on incorrect statistical practices and design of Likert scales.\nDuring these years, only 3 of the 110 papers applied proper statistical testing\nto correctly-designed Likert scales. Our analysis suggests there are areas for\nmeaningful improvement in the design and testing of Likert scales. Lastly, we\nprovide recommendations to improve the accuracy of conclusions drawn from\nLikert data.", "author": [{"name": "Mariah L. Schrum"}, {"name": "Michael Johnson"}, {"name": "Muyleng Ghuy"}, {"name": "Matthew C. Gombolay"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3319502.3378178"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3319502.3378178", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2001.03231v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.03231v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.RO", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ME", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.09545v1", "updated": "2020-01-27T00:19:41Z", "published": "2020-01-27T00:19:41Z", "title": "aiTPR: Attribute Interaction-Tensor Product Representation for Image\n  Caption", "summary": "Region visual features enhance the generative capability of the machines\nbased on features, however they lack proper interaction attentional perceptions\nand thus ends up with biased or uncorrelated sentences or pieces of\nmisinformation. In this work, we propose Attribute Interaction-Tensor Product\nRepresentation (aiTPR) which is a convenient way of gathering more information\nthrough orthogonal combination and learning the interactions as physical\nentities (tensors) and improving the captions. Compared to previous works,\nwhere features are added up to undefined feature spaces, TPR helps in\nmaintaining sanity in combinations and orthogonality helps in defining familiar\nspaces. We have introduced a new concept layer that defines the objects and\nalso their interactions that can play a crucial role in determination of\ndifferent descriptions. The interaction portions have contributed heavily for\nbetter caption quality and has out-performed different previous works on this\ndomain and MSCOCO dataset. We introduced, for the first time, the notion of\ncombining regional image features and abstracted interaction likelihood\nembedding for image captioning.", "author": {"name": "Chiranjib Sur"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages"}, "link": [{"@href": "http://arxiv.org/abs/2001.09545v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.09545v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.00850v2", "updated": "2020-02-06T14:30:49Z", "published": "2020-01-28T19:56:03Z", "title": "A Kernel of Truth: Determining Rumor Veracity on Twitter by Diffusion\n  Pattern Alone", "summary": "Recent work in the domain of misinformation detection has leveraged rich\nsignals in the text and user identities associated with content on social\nmedia. But text can be strategically manipulated and accounts reopened under\ndifferent aliases, suggesting that these approaches are inherently brittle. In\nthis work, we investigate an alternative modality that is naturally robust: the\npattern in which information propagates. Can the veracity of an unverified\nrumor spreading online be discerned solely on the basis of its pattern of\ndiffusion through the social network?\n  Using graph kernels to extract complex topological information from Twitter\ncascade structures, we train accurate predictive models that are blind to\nlanguage, user identities, and time, demonstrating for the first time that such\n\"sanitized\" diffusion patterns are highly informative of veracity. Our results\nindicate that, with proper aggregation, the collective sharing pattern of the\ncrowd may reveal powerful signals of rumor truth or falsehood, even in the\nearly stages of propagation.", "author": [{"name": "Nir Rosenfeld"}, {"name": "Aron Szanto"}, {"name": "David C. Parkes"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3366423.3380180"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3366423.3380180", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2002.00850v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.00850v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at The Web Conference (WWW) 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.03438v1", "updated": "2020-02-09T19:53:23Z", "published": "2020-02-09T19:53:23Z", "title": "Limits of Detecting Text Generated by Large-Scale Language Models", "summary": "Some consider large-scale language models that can generate long and coherent\npieces of text as dangerous, since they may be used in misinformation\ncampaigns. Here we formulate large-scale language model output detection as a\nhypothesis testing problem to classify text as genuine or generated. We show\nthat error exponents for particular language models are bounded in terms of\ntheir perplexity, a standard measure of language generation performance. Under\nthe assumption that human language is stationary and ergodic, the formulation\nis extended from considering specific language models to considering maximum\nlikelihood language models, among the class of k-order Markov approximations;\nerror probabilities are characterized. Some discussion of incorporating\nsemantic side information is also given.", "author": [{"name": "Lav R. Varshney"}, {"name": "Nitish Shirish Keskar"}, {"name": "Richard Socher"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ITA 2020"}, "link": [{"@href": "http://arxiv.org/abs/2002.03438v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.03438v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.07917v1", "updated": "2020-02-18T22:56:40Z", "published": "2020-02-18T22:56:40Z", "title": "TIES: Temporal Interaction Embeddings For Enhancing Social Media\n  Integrity At Facebook", "summary": "Since its inception, Facebook has become an integral part of the online\nsocial community. People rely on Facebook to make connections with others and\nbuild communities. As a result, it is paramount to protect the integrity of\nsuch a rapidly growing network in a fast and scalable manner. In this paper, we\npresent our efforts to protect various social media entities at Facebook from\npeople who try to abuse our platform. We present a novel Temporal Interaction\nEmbeddingS (TIES) model that is designed to capture rogue social interactions\nand flag them for further suitable actions. TIES is a supervised, deep\nlearning, production ready model at Facebook-scale networks. Prior works on\nintegrity problems are mostly focused on capturing either only static or\ncertain dynamic features of social entities. In contrast, TIES can capture both\nthese variant behaviors in a unified model owing to the recent strides made in\nthe domains of graph embedding and deep sequential pattern learning. To show\nthe real-world impact of TIES, we present a few applications especially for\npreventing spread of misinformation, fake account detection, and reducing ads\npayment risks in order to enhance the platform's integrity.", "author": [{"name": "Nima Noorshams"}, {"name": "Saurabh Verma"}, {"name": "Aude Hofleitner"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted to KDD 2020 applied DS track"}, "link": [{"@href": "http://arxiv.org/abs/2002.07917v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.07917v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.11104v1", "updated": "2020-02-24T20:04:54Z", "published": "2020-02-24T20:04:54Z", "title": "An Information Diffusion Approach to Rumor Propagation and\n  Identification on Twitter", "summary": "With the increasing use of online social networks as a source of news and\ninformation, the propensity for a rumor to disseminate widely and quickly poses\na great concern, especially in disaster situations where users do not have\nenough time to fact-check posts before making the informed decision to react to\na post that appears to be credible. In this study, we explore the propagation\npattern of rumors on Twitter by exploring the dynamics of microscopic-level\nmisinformation spread, based on the latent message and user interaction\nattributes. We perform supervised learning for feature selection and\nprediction. Experimental results with real-world data sets give the models'\nprediction accuracy at about 90\\% for the diffusion of both True and False\ntopics. Our findings confirm that rumor cascades run deeper and that rumor\nmasked as news, and messages that incite fear, will diffuse faster than other\nmessages. We show that the models for True and False message propagation differ\nsignificantly, both in the prediction parameters and in the message features\nthat govern the diffusion. Finally, we show that the diffusion pattern is an\nimportant metric in identifying the credibility of a tweet.", "author": [{"name": "Abiola Osho"}, {"name": "Caden Waters"}, {"name": "George Amariucai"}], "link": [{"@href": "http://arxiv.org/abs/2002.11104v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.11104v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.11768v3", "updated": "2020-12-12T05:15:18Z", "published": "2020-02-19T04:18:45Z", "title": "Attacking Neural Text Detectors", "summary": "Machine learning based language models have recently made significant\nprogress, which introduces a danger to spread misinformation. To combat this\npotential danger, several methods have been proposed for detecting text written\nby these language models. This paper presents two classes of black-box attacks\non these detectors, one which randomly replaces characters with homoglyphs, and\nthe other a simple scheme to purposefully misspell words. The homoglyph and\nmisspelling attacks decrease a popular neural text detector's recall on neural\ntext from 97.44% to 0.26% and 22.68%, respectively. Results also indicate that\nthe attacks are transferable to other neural text detectors.", "author": [{"name": "Max Wolff"}, {"name": "Stuart Wolff"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at the ICLR 2020 workshop \"Towards Trustworthy ML:\n  Rethinking Security and Privacy for ML.\""}, "link": [{"@href": "http://arxiv.org/abs/2002.11768v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.11768v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.00923v1", "updated": "2020-03-02T14:07:56Z", "published": "2020-03-02T14:07:56Z", "title": "Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business", "summary": "In the age of social media, disasters and epidemics usher not only a\ndevastation and affliction in the physical world, but also prompt a deluge of\ninformation, opinions, prognoses and advice to billions of internet users. The\ncoronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World\nHealth Organization warning of a possible \"infodemic\" of fake news. In this\nstudy, we examine the alternative narratives around the coronavirus outbreak\nthrough advertisements promoted on Facebook, the largest social media platform\nin the US. Using the new Facebook Ads Library, we discover advertisers from\npublic health and non-profit sectors, alongside those from news media,\npolitics, and business, incorporating coronavirus into their messaging and\nagenda. We find the virus used in political attacks, donation solicitations,\nbusiness promotion, stock market advice, and animal rights campaigning. Among\nthese, we find several instances of possible misinformation, ranging from\nbioweapons conspiracy theories to unverifiable claims by politicians. As we\nmake the dataset available to the community, we hope the advertising domain\nwill become an important part of quality control for public health\ncommunication and public discourse in general.", "author": [{"name": "Yelena Mejova"}, {"name": "Kyriaki Kalimeri"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Preprint. Under Review"}, "link": [{"@href": "http://arxiv.org/abs/2003.00923v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.00923v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.01797v1", "updated": "2020-03-03T21:13:12Z", "published": "2020-03-03T21:13:12Z", "title": "Discover Your Social Identity from What You Tweet: a Content Based\n  Approach", "summary": "An identity denotes the role an individual or a group plays in highly\ndifferentiated contemporary societies. In this paper, our goal is to classify\nTwitter users based on their role identities. We first collect a coarse-grained\npublic figure dataset automatically, then manually label a more fine-grained\nidentity dataset. We propose a hierarchical self-attention neural network for\nTwitter user role identity classification. Our experiments demonstrate that the\nproposed model significantly outperforms multiple baselines. We further propose\na transfer learning scheme that improves our model's performance by a large\nmargin. Such transfer learning also greatly reduces the need for a large amount\nof human labeled data.", "author": [{"name": "Binxuan Huang"}, {"name": "Kathleen M. Carley"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-42699-6"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-42699-6", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.01797v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.01797v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a preprint of a chapter published in Disinformation,\n  Misinformation, and Fake News in Social Media: Emerging Research Challenges\n  and Opportunities, edited by Kai, S., Suhang, W., Dongwon, L., Huan, L, 2020,\n  Springer reproduced with permission of Springer Nature Switzerland AG. The\n  final authenticated version is available online at:\n  http://dx.doi.org/10.1007/978-3-030-42699-6"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.05004v1", "updated": "2020-03-10T21:14:17Z", "published": "2020-03-10T21:14:17Z", "title": "The COVID-19 Social Media Infodemic", "summary": "We address the diffusion of information about the COVID-19 with a massive\ndata analysis on Twitter, Instagram, YouTube, Reddit and Gab. We analyze\nengagement and interest in the COVID-19 topic and provide a differential\nassessment on the evolution of the discourse on a global scale for each\nplatform and their users. We fit information spreading with epidemic models\ncharacterizing the basic reproduction numbers $R_0$ for each social media\nplatform. Moreover, we characterize information spreading from questionable\nsources, finding different volumes of misinformation in each platform. However,\ninformation from both reliable and questionable sources do not present\ndifferent spreading patterns. Finally, we provide platform-dependent numerical\nestimates of rumors' amplification.", "author": [{"name": "Matteo Cinelli"}, {"name": "Walter Quattrociocchi"}, {"name": "Alessandro Galeazzi"}, {"name": "Carlo Michele Valensise"}, {"name": "Emanuele Brugnoli"}, {"name": "Ana Lucia Schmidt"}, {"name": "Paola Zola"}, {"name": "Fabiana Zollo"}, {"name": "Antonio Scala"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1038/s41598-020-73510-5"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1038/s41598-020-73510-5", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.05004v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.05004v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Sci Rep 10, 16598 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "nlin.AO", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.06857v2", "updated": "2020-03-17T01:03:04Z", "published": "2020-03-15T15:53:27Z", "title": "Can Celebrities Burst Your Bubble?", "summary": "Polarization is a growing, global problem. As such, many social media based\nsolutions have been proposed in order to reduce it. In this study, we propose a\nnew solution that recommends topics to celebrities to encourage them to join a\npolarized debate and increase exposure to contrarian content - bursting the\nfilter bubble. Using a state-of-the art model that quantifies the degree of\npolarization, this paper makes a first attempt to empirically answer the\nquestion: Can celebrities burst filter bubbles? We use a case study to analyze\nhow people react when celebrities are involved in a controversial topic and\nconclude with a list possible research directions.", "author": [{"name": "Tu\u011frulcan Elmas"}, {"name": "Kristina Hardi"}, {"name": "Rebekah Overdorf"}, {"name": "Karl Aberer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages, 3 figures, accepted for non-archival track of IID2020,\n  workshop in WWW2020"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the Workshop on Misinformation Integrity in Social\n  Networks 2021 (MISINFO 2021) Vol-2890"}, "link": [{"@href": "http://arxiv.org/abs/2003.06857v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.06857v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.07192v4", "updated": "2021-01-08T03:43:46Z", "published": "2020-03-12T18:37:19Z", "title": "Social Media and Misleading Information in a Democracy: A Mechanism\n  Design Approach", "summary": "In this paper, we present a resource allocation mechanism for the problem of\nincentivizing filtering among a finite number of strategic social media\nplatforms. We consider the presence of a strategic government and private\nknowledge of how misinformation affects the users of the social media\nplatforms. Our proposed mechanism incentivizes social media platforms to filter\nmisleading information efficiently, and thus indirectly prevents the spread of\nfake news. In particular, we design an economically inspired mechanism that\nstrongly implements all generalized Nash equilibria for efficient filtering of\nmisleading information in the induced game. We show that our mechanism is\nindividually rational, budget balanced, while it has at least one equilibrium.\nFinally, we show that for quasi-concave utilities and constraints, our\nmechanism admits a generalized Nash equilibrium and implements a Pareto\nefficient solution.", "author": [{"name": "Aditya Dave"}, {"name": "Ioannis Vasileios Chremos"}, {"name": "Andreas A. Malikopoulos"}], "link": [{"@href": "http://arxiv.org/abs/2003.07192v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.07192v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.SY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.07372v2", "updated": "2020-06-02T18:35:00Z", "published": "2020-03-16T18:00:04Z", "title": "Tracking Social Media Discourse About the COVID-19 Pandemic: Development\n  of a Public Coronavirus Twitter Data Set", "summary": "At the time of this writing, the novel coronavirus (COVID-19) pandemic\noutbreak has already put tremendous strain on many countries' citizens,\nresources and economies around the world. Social distancing measures, travel\nbans, self-quarantines, and business closures are changing the very fabric of\nsocieties worldwide. With people forced out of public spaces, much conversation\nabout these phenomena now occurs online, e.g., on social media platforms like\nTwitter. In this paper, we describe a multilingual coronavirus (COVID-19)\nTwitter dataset that we have been continuously collecting since January 22,\n2020. We are making our dataset available to the research community\n(https://github.com/echen102/COVID-19-TweetIDs). It is our hope that our\ncontribution will enable the study of online conversation dynamics in the\ncontext of a planetary-scale epidemic outbreak of unprecedented proportions and\nimplications. This dataset could also help track scientific coronavirus\nmisinformation and unverified rumors, or enable the understanding of fear and\npanic -- and undoubtedly more. Ultimately, this dataset may contribute towards\nenabling informed solutions and prescribing targeted policy interventions to\nfight this global crisis.", "author": [{"name": "Emily Chen"}, {"name": "Kristina Lerman"}, {"name": "Emilio Ferrara"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.2196/19273"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.2196/19273", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.07372v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.07372v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "JMIR Public Health Surveill 2020;6(2):e19273"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.10359v1", "updated": "2020-03-23T16:25:55Z", "published": "2020-03-23T16:25:55Z", "title": "Understanding the perception of COVID-19 policies by mining a\n  multilanguage Twitter dataset", "summary": "The objective of this work is to explore popular discourse about the COVID-19\npandemic and policies implemented to manage it. Using Natural Language\nProcessing, Text Mining, and Network Analysis to analyze corpus of tweets that\nrelate to the COVID-19 pandemic, we identify common responses to the pandemic\nand how these responses differ across time. Moreover, insights as to how\ninformation and misinformation were transmitted via Twitter, starting at the\nearly stages of this pandemic, are presented. Finally, this work introduces a\ndataset of tweets collected from all over the world, in multiple languages,\ndating back to January 22nd, when the total cases of reported COVID-19 were\nbelow 600 worldwide. The insights presented in this work could help inform\ndecision makers in the face of future pandemics, and the dataset introduced can\nbe used to acquire valuable knowledge to help mitigate the COVID-19 pandemic.", "author": [{"name": "Christian E. Lopez"}, {"name": "Malolan Vasu"}, {"name": "Caleb Gallemore"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "https://github.com/lopezbec/COVID19_Tweets_Dataset"}, "link": [{"@href": "http://arxiv.org/abs/2003.10359v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.10359v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2003.13907v1", "updated": "2020-03-31T01:51:35Z", "published": "2020-03-31T01:51:35Z", "title": "A first look at COVID-19 information and misinformation sharing on\n  Twitter", "summary": "Since December 2019, COVID-19 has been spreading rapidly across the world.\nNot surprisingly, conversation about COVID-19 is also increasing. This article\nis a first look at the amount of conversation taking place on social media,\nspecifically Twitter, with respect to COVID-19, the themes of discussion, where\nthe discussion is emerging from, myths shared about the virus, and how much of\nit is connected to other high and low quality information on the Internet\nthrough shared URL links. Our preliminary findings suggest that a meaningful\nspatio-temporal relationship exists between information flow and new cases of\nCOVID-19, and while discussions about myths and links to poor quality\ninformation exist, their presence is less dominant than other crisis specific\nthemes. This research is a first step toward understanding social media\nconversation about COVID-19.", "author": [{"name": "Lisa Singh"}, {"name": "Shweta Bansal"}, {"name": "Leticia Bode"}, {"name": "Ceren Budak"}, {"name": "Guangqing Chi"}, {"name": "Kornraphop Kawintiranon"}, {"name": "Colton Padden"}, {"name": "Rebecca Vanarsdall"}, {"name": "Emily Vraga"}, {"name": "Yanchen Wang"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "24 pages, 13 figures"}, "link": [{"@href": "http://arxiv.org/abs/2003.13907v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.13907v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.00673v2", "updated": "2020-04-21T20:50:30Z", "published": "2020-04-01T19:32:25Z", "title": "Hate multiverse spreads malicious COVID-19 content online beyond\n  individual platform control", "summary": "We show that malicious COVID-19 content, including hate speech,\ndisinformation, and misinformation, exploits the multiverse of online hate to\nspread quickly beyond the control of any individual social media platform.\nMachine learning topic analysis shows quantitatively how online hate\ncommunities are weaponizing COVID-19, with topics evolving rapidly and content\nbecoming increasingly coherent. Our mathematical analysis provides a\ngeneralized form of the public health R0 predicting the tipping point for\nmultiverse-wide viral spreading, which suggests new policy options to mitigate\nthe global spread of malicious COVID-19 content without relying on future\ncoordination between all online platforms.", "author": [{"name": "N. Vel\u00e1squez"}, {"name": "R. Leahy"}, {"name": "N. Johnson Restrepo"}, {"name": "Y. Lupu"}, {"name": "R. Sear"}, {"name": "N. Gabriel"}, {"name": "O. Jha"}, {"name": "B. Goldberg"}, {"name": "N. F. Johnson"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Working paper. Feedback welcomed from the community to\n  neiljohnson@gwu.edu"}, "link": [{"@href": "http://arxiv.org/abs/2004.00673v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.00673v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "nlin.AO", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.pop-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.00777v1", "updated": "2020-04-02T02:22:45Z", "published": "2020-04-02T02:22:45Z", "title": "Skepticism and rumor spreading: the role of spatial correlations", "summary": "Critical thinking and skepticism are fundamental mechanisms that one may use\nto prevent the spreading of rumors, fake-news and misinformation. We consider a\nsimple model in which agents without previous contact with the rumor, being\nskeptically oriented, may convince spreaders to stop their activity or, once\nexposed to the rumor, decide not to propagate it as a consequence, for example,\nof fact-checking. We extend a previous, mean-field analysis of the combined\neffect of these two mechanisms, active and passive skepticism, to include\nspatial correlations. This can be done either analytically, through the pair\napproximation, or simulating an agent-based version on diverse networks. Our\nresults show that while in mean-field there is no coexistence between spreaders\nand susceptibles (although, depending on the parameters, there may be\nbistability depending on the initial conditions), when spatial correlations are\nincluded, because of the protective effect of the isolation provided by removed\nagents, coexistence is possible.", "author": [{"name": "Marco Antonio Amaral"}, {"name": "W. G. Dantas"}, {"name": "Jeferson J. Arenzon"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevE.101.062418"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevE.101.062418", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.00777v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.00777v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 6 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys. Rev. E 101, 062418 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cond-mat.stat-mech", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.01967v1", "updated": "2020-04-04T16:21:13Z", "published": "2020-04-04T16:21:13Z", "title": "The Paradox of Information Access: Growing Isolation in the Age of\n  Sharing", "summary": "Modern online media, such as Twitter, Instagram, and YouTube, enable anyone\nto become an information producer and to offer online content for potentially\nglobal consumption. By increasing the amount of globally accessible real-time\ninformation, today's ubiquitous producers contribute to a world, where an\nindividual consumes vanishingly smaller fractions of all produced content. In\ngeneral, consumers preferentially select information that closely matches their\nindividual views and values. The bias inherent in such selection is further\nmagnified by today's information curation services that maximize user\nengagement (and thus service revenue) by filtering new content in accordance\nwith observed consumer preferences. Consequently, individuals get exposed to\nincreasingly narrower bands of the ideology spectrum. Societies get fragmented\ninto increasingly ideologically isolated enclaves. These enclaves (or\necho-chambers) then become vulnerable to misinformation spread, which in turn\nfurther magnifies polarization and bias. We call this dynamic the paradox of\ninformation access; a growing ideological fragmentation in the age of sharing.\nThis article describes the technical, economic, and socio-cognitive\ncontributors to this paradox, and explores research directions towards its\nmitigation.", "author": [{"name": "Tarek Abdelzaher"}, {"name": "Heng Ji"}, {"name": "Jinyang Li"}, {"name": "Chaoqi Yang"}, {"name": "John Dellaverson"}, {"name": "Lixia Zhang"}, {"name": "Chao Xu"}, {"name": "Boleslaw K. Szymanski"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/2004.01967v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.01967v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.03788v1", "updated": "2020-04-08T03:22:21Z", "published": "2020-04-08T03:22:21Z", "title": "Satirical News Detection with Semantic Feature Extraction and\n  Game-theoretic Rough Sets", "summary": "Satirical news detection is an important yet challenging task to prevent\nspread of misinformation. Many feature based and end-to-end neural nets based\nsatirical news detection systems have been proposed and delivered promising\nresults. Existing approaches explore comprehensive word features from satirical\nnews articles, but lack semantic metrics using word vectors for tweet form\nsatirical news. Moreover, the vagueness of satire and news parody determines\nthat a news tweet can hardly be classified with a binary decision, that is,\nsatirical or legitimate. To address these issues, we collect satirical and\nlegitimate news tweets, and propose a semantic feature based approach. Features\nare extracted by exploring inconsistencies in phrases, entities, and between\nmain and relative clauses. We apply game-theoretic rough set model to detect\nsatirical news, in which probabilistic thresholds are derived by game\nequilibrium and repetition learning mechanism. Experimental results on the\ncollected dataset show the robustness and improvement of the proposed approach\ncompared with Pawlak rough set model and SVM.", "author": [{"name": "Yue Zhou"}, {"name": "Yan Zhang"}, {"name": "JingTao Yao"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages"}, "link": [{"@href": "http://arxiv.org/abs/2004.03788v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.03788v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.04315v2", "updated": "2020-04-22T22:38:15Z", "published": "2020-04-09T01:07:12Z", "title": "Large Arabic Twitter Dataset on COVID-19", "summary": "The 2019 coronavirus disease (COVID-19), emerged late December 2019 in China,\nis now rapidly spreading across the globe. At the time of writing this paper,\nthe number of global confirmed cases has passed two millions and half with over\n180,000 fatalities. Many countries have enforced strict social distancing\npolicies to contain the spread of the virus. This have changed the daily life\nof tens of millions of people, and urged people to turn their discussions\nonline, e.g., via online social media sites like Twitter. In this work, we\ndescribe the first Arabic tweets dataset on COVID-19 that we have been\ncollecting since January 1st, 2020. The dataset would help researchers and\npolicy makers in studying different societal issues related to the pandemic.\nMany other tasks related to behavioral change, information sharing,\nmisinformation and rumors spreading can also be analyzed.", "author": [{"name": "Sarah Alqurashi"}, {"name": "Ahmad Alhindi"}, {"name": "Eisa Alanazi"}], "link": [{"@href": "http://arxiv.org/abs/2004.04315v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.04315v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.05113v1", "updated": "2020-04-07T02:57:35Z", "published": "2020-04-07T02:57:35Z", "title": "Automatically Assessing Quality of Online Health Articles", "summary": "The information ecosystem today is overwhelmed by an unprecedented quantity\nof data on versatile topics are with varied quality. However, the quality of\ninformation disseminated in the field of medicine has been questioned as the\nnegative health consequences of health misinformation can be life-threatening.\nThere is currently no generic automated tool for evaluating the quality of\nonline health information spanned over a broad range. To address this gap, in\nthis paper, we applied a data mining approach to automatically assess the\nquality of online health articles based on 10 quality criteria. We have\nprepared a labeled dataset with 53012 features and applied different feature\nselection methods to identify the best feature subset with which our trained\nclassifier achieved an accuracy of 84%-90% varied over 10 criteria. Our\nsemantic analysis of features shows the underpinning associations between the\nselected features & assessment criteria and further rationalize our assessment\napproach. Our findings will help in identifying high-quality health articles\nand thus aiding users in shaping their opinion to make the right choice while\npicking health-related help from online.", "author": [{"name": "Fariha Afsana"}, {"name": "Muhammad Ashad Kabir"}, {"name": "Naeemul Hassan"}, {"name": "Manoranjan Paul"}], "link": [{"@href": "http://arxiv.org/abs/2004.05113v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.05113v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.11138v3", "updated": "2020-09-13T22:44:33Z", "published": "2020-04-23T13:35:49Z", "title": "The Creation and Detection of Deepfakes: A Survey", "summary": "Generative deep learning algorithms have progressed to a point where it is\ndifficult to tell the difference between what is real and what is fake. In\n2018, it was discovered how easy it is to use this technology for unethical and\nmalicious applications, such as the spread of misinformation, impersonation of\npolitical leaders, and the defamation of innocent individuals. Since then,\nthese `deepfakes' have advanced significantly.\n  In this paper, we explore the creation and detection of deepfakes and provide\nan in-depth view of how these architectures work. The purpose of this survey is\nto provide the reader with a deeper understanding of (1) how deepfakes are\ncreated and detected, (2) the current trends and advancements in this domain,\n(3) the shortcomings of the current defense solutions, and (4) the areas which\nrequire further research and attention.", "author": [{"name": "Yisroel Mirsky"}, {"name": "Wenke Lee"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3425780"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3425780", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.11138v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.11138v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACM Computing Surveys (CSUR), 2020, preprint"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.IV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.12226v1", "updated": "2020-04-25T20:07:54Z", "published": "2020-04-25T20:07:54Z", "title": "A First Instagram Dataset on COVID-19", "summary": "The novel coronavirus (COVID-19) pandemic outbreak is drastically shaping and\nreshaping many aspects of our life, with a huge impact on our social life. In\nthis era of lockdown policies in most of the major cities around the world, we\nsee a huge increase in people and professional engagement in social media.\nSocial media is playing an important role in news propagation as well as\nkeeping people in contact. At the same time, this source is both a blessing and\na curse as the coronavirus infodemic has become a major concern, and is already\na topic that needs special attention and further research. In this paper, we\nprovide a multilingual coronavirus (COVID-19) Instagram dataset that we have\nbeen continuously collected since March 30, 2020. We are making our dataset\navailable to the research community at Github. We believe that this\ncontribution will help the community to better understand the dynamics behind\nthis phenomenon in Instagram, as one of the major social media. This dataset\ncould also help study the propagation of misinformation related to this\noutbreak.", "author": [{"name": "Koosha Zarei"}, {"name": "Reza Farahbakhsh"}, {"name": "Noel Crespi"}, {"name": "Gareth Tyson"}], "link": [{"@href": "http://arxiv.org/abs/2004.12226v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.12226v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.12864v1", "updated": "2020-04-27T15:18:49Z", "published": "2020-04-27T15:18:49Z", "title": "DeSePtion: Dual Sequence Prediction and Adversarial Examples for\n  Improved Fact-Checking", "summary": "The increased focus on misinformation has spurred development of data and\nsystems for detecting the veracity of a claim as well as retrieving\nauthoritative evidence. The Fact Extraction and VERification (FEVER) dataset\nprovides such a resource for evaluating end-to-end fact-checking, requiring\nretrieval of evidence from Wikipedia to validate a veracity prediction. We show\nthat current systems for FEVER are vulnerable to three categories of realistic\nchallenges for fact-checking -- multiple propositions, temporal reasoning, and\nambiguity and lexical variation -- and introduce a resource with these types of\nclaims. Then we present a system designed to be resilient to these \"attacks\"\nusing multiple pointer networks for document selection and jointly modeling a\nsequence of evidence sentences and veracity relation predictions. We find that\nin handling these attacks we obtain state-of-the-art results on FEVER, largely\ndue to improved evidence retrieval.", "author": [{"name": "Christopher Hidey"}, {"name": "Tuhin Chakrabarty"}, {"name": "Tariq Alhindi"}, {"name": "Siddharth Varia"}, {"name": "Kriste Krstovski"}, {"name": "Mona Diab"}, {"name": "Smaranda Muresan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL 2020"}, "link": [{"@href": "http://arxiv.org/abs/2004.12864v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.12864v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.14484v2", "updated": "2020-06-08T06:18:40Z", "published": "2020-04-29T21:08:44Z", "title": "Prevalence of Low-Credibility Information on Twitter During the COVID-19\n  Outbreak", "summary": "As the novel coronavirus spreads across the world, concerns regarding the\nspreading of misinformation about it are also growing. Here we estimate the\nprevalence of links to low-credibility information on Twitter during the\noutbreak, and the role of bots in spreading these links. We find that the\ncombined volume of tweets linking to low-credibility information is comparable\nto the volume of New York Times articles and CDC links. Content analysis\nreveals a politicization of the pandemic. The majority of this content spreads\nvia retweets. Social bots are involved in both posting and amplifying\nlow-credibility information, although the majority of volume is generated by\nlikely humans. Some of these accounts appear to amplify low-credibility sources\nin a coordinated fashion.", "author": [{"name": "Kai-Cheng Yang"}, {"name": "Christopher Torres-Lugo"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.36190/2020.16"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.36190/2020.16", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.14484v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.14484v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages, 4 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proc. ICWSM Intl. Workshop on Cyber Social Threats (CySoc), 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.02443v1", "updated": "2020-05-05T19:08:26Z", "published": "2020-05-05T19:08:26Z", "title": "A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian\n  and Indian Elections", "summary": "Recently, messaging applications, such as WhatsApp, have been reportedly\nabused by misinformation campaigns, especially in Brazil and India. A notable\nform of abuse in WhatsApp relies on several manipulated images and memes\ncontaining all kinds of fake stories. In this work, we performed an extensive\ndata collection from a large set of WhatsApp publicly accessible groups and\nfact-checking agency websites. This paper opens a novel dataset to the research\ncommunity containing fact-checked fake images shared through WhatsApp for two\ndistinct scenarios known for the spread of fake news on the platform: the 2018\nBrazilian elections and the 2019 Indian elections.", "author": [{"name": "Julio C. S. Reis"}, {"name": "Philipe de Freitas Melo"}, {"name": "Kiran Garimella"}, {"name": "Jussara M. Almeida"}, {"name": "Dean Eckles"}, {"name": "Fabr\u00edcio Benevenuto"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "7 pages. This is a preprint version of an accepted paper on ICWSM'20.\n  Please, consider to cite the conference version instead of this one"}, "link": [{"@href": "http://arxiv.org/abs/2005.02443v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.02443v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.06012v4", "updated": "2021-02-05T22:19:06Z", "published": "2020-05-02T10:23:27Z", "title": "Mega-COV: A Billion-Scale Dataset of 100+ Languages for COVID-19", "summary": "We describe Mega-COV, a billion-scale dataset from Twitter for studying\nCOVID-19. The dataset is diverse (covers 268 countries), longitudinal (goes as\nback as 2007), multilingual (comes in 100+ languages), and has a significant\nnumber of location-tagged tweets (~169M tweets). We release tweet IDs from the\ndataset. We also develop and release two powerful models, one for identifying\nwhether or not a tweet is related to the pandemic (best F1=97%) and another for\ndetecting misinformation about COVID-19 (best F1=92%). A human annotation study\nreveals the utility of our models on a subset of Mega-COV. Our data and models\ncan be useful for studying a wide host of phenomena related to the pandemic.\nMega-COV and our models are publicly available.", "author": [{"name": "Muhammad Abdul-Mageed"}, {"name": "AbdelRahim Elmadany"}, {"name": "El Moatez Billah Nagoudi"}, {"name": "Dinesh Pabbi"}, {"name": "Kunal Verma"}, {"name": "Rannie Lin"}], "link": [{"@href": "http://arxiv.org/abs/2005.06012v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.06012v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.06637v2", "updated": "2020-06-06T06:58:24Z", "published": "2020-05-12T12:27:29Z", "title": "When Wireless Communication Faces COVID-19: Combating the Pandemic and\n  Saving the Economy", "summary": "The year 2020 is experiencing a global health and economic crisis due to the\nCOVID-19 pandemic. Countries across the world are using digital technologies to\nfight this global crisis. These digital technologies, in one way or another,\nstrongly rely on the availability of wireless communication technologies. In\nthis paper, we present the role of wireless communications in the COVID-19\npandemic from different perspectives. First, we show how these technologies are\nhelping to combat this pandemic, including monitoring of the virus spread,\nenabling healthcare automation, and allowing virtual education and\nconferencing. Also, we show the importance of digital inclusiveness in the\npandemic and possible solutions to connect the unconnected. Next, we discuss\nthe challenges faced by wireless technologies, including privacy, security, and\nmisinformation. Then, we present the importance of wireless communication\ntechnologies in the survival of the global economy, such as automation of\nindustries and supply chain, e-commerce, and supporting occupations that are at\nrisk. Finally, we reveal that how the technologies developed during the\npandemic can be helpful in the post-pandemic era.", "author": [{"name": "Nasir Saeed"}, {"name": "Ahmed Bader"}, {"name": "Tareq Y. Al-Naffouri"}, {"name": "Mohamed-Slim Alouini"}], "link": [{"@href": "http://arxiv.org/abs/2005.06637v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.06637v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.08141v4", "updated": "2021-07-20T19:02:44Z", "published": "2020-05-17T01:20:24Z", "title": "Neutral bots probe political bias on social media", "summary": "Social media platforms attempting to curb abuse and misinformation have been\naccused of political bias. We deploy neutral social bots who start following\ndifferent news sources on Twitter, and track them to probe distinct biases\nemerging from platform mechanisms versus user interactions. We find no strong\nor consistent evidence of political bias in the news feed. Despite this, the\nnews and information to which U.S. Twitter users are exposed depend strongly on\nthe political leaning of their early connections. The interactions of\nconservative accounts are skewed toward the right, whereas liberal accounts are\nexposed to moderate content shifting their experience toward the political\ncenter. Partisan accounts, especially conservative ones, tend to receive more\nfollowers and follow more automated accounts. Conservative accounts also find\nthemselves in denser communities and are exposed to more low-credibility\ncontent.", "author": [{"name": "Wen Chen"}, {"name": "Diogo Pacheco"}, {"name": "Kai-Cheng Yang"}, {"name": "Filippo Menczer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "26 pages, 6 figures. Appendix: 10 pages, 5 figures and 4 tables"}, "link": [{"@href": "http://arxiv.org/abs/2005.08141v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.08141v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.13691v1", "updated": "2020-05-27T22:41:02Z", "published": "2020-05-27T22:41:02Z", "title": "Challenges in Combating COVID-19 Infodemic -- Data, Tools, and Ethics", "summary": "While the COVID-19 pandemic continues its global devastation, numerous\naccompanying challenges emerge. One important challenge we face is to\nefficiently and effectively use recently gathered data and find computational\ntools to combat the COVID-19 infodemic, a typical information overloading\nproblem. Novel coronavirus presents many questions without ready answers; its\nuncertainty and our eagerness in search of solutions offer a fertile\nenvironment for infodemic. It is thus necessary to combat the infodemic and\nmake a concerted effort to confront COVID-19 and mitigate its negative impact\nin all walks of life when saving lives and maintaining normal orders during\ntrying times. In this position paper of combating the COVID-19 infodemic, we\nillustrate its need by providing real-world examples of rampant conspiracy\ntheories, misinformation, and various types of scams that take advantage of\nhuman kindness, fear, and ignorance. We present three key challenges in this\nfight against the COVID-19 infodemic where researchers and practitioners\ninstinctively want to contribute and help. We demonstrate that these three\nchallenges can and will be effectively addressed by collective wisdom,\ncrowdsourcing, and collaborative research.", "author": [{"name": "Kaize Ding"}, {"name": "Kai Shu"}, {"name": "Yichuan Li"}, {"name": "Amrita Bhattacharjee"}, {"name": "Huan Liu"}], "link": [{"@href": "http://arxiv.org/abs/2005.13691v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.13691v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.04278v1", "updated": "2020-06-07T22:00:43Z", "published": "2020-06-07T22:00:43Z", "title": "Disinformation and Misinformation on Twitter during the Novel\n  Coronavirus Outbreak", "summary": "As the novel coronavirus spread globally, a growing public panic was\nexpressed over the internet. We examine the public discussion concerning\nCOVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million\nusers collected between January 29, 2020 and March 4, 2020. We categorize users\nbased on their home countries, social identities, and political orientation. We\nfind that news media, government officials, and individual news reporters\nposted a majority of influential tweets, while the most influential ones are\nstill written by regular users. Tweets mentioning \"fake news\" URLs and\ndisinformation story-lines are also more likely to be spread by regular users.\nUnlike real news and normal tweets, tweets containing URLs pointing to \"fake\nnews\" sites are most likely to be retweeted within the source country and so\nare less likely to spread internationally.", "author": [{"name": "Binxuan Huang"}, {"name": "Kathleen M. Carley"}], "link": [{"@href": "http://arxiv.org/abs/2006.04278v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.04278v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2007.03443v1", "updated": "2020-07-07T13:50:24Z", "published": "2020-07-07T13:50:24Z", "title": "Cultural Convergence: Insights into the behavior of misinformation\n  networks on Twitter", "summary": "How can the birth and evolution of ideas and communities in a network be\nstudied over time? We use a multimodal pipeline, consisting of network mapping,\ntopic modeling, bridging centrality, and divergence to analyze Twitter data\nsurrounding the COVID-19 pandemic. We use network mapping to detect accounts\ncreating content surrounding COVID-19, then Latent Dirichlet Allocation to\nextract topics, and bridging centrality to identify topical and non-topical\nbridges, before examining the distribution of each topic and bridge over time\nand applying Jensen-Shannon divergence of topic distributions to show\ncommunities that are converging in their topical narratives.", "author": [{"name": "Liz McQuillan"}, {"name": "Erin McAweeney"}, {"name": "Alicia Bargar"}, {"name": "Alex Ruch"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages (7 for paper, 3 for reference, 5 for appendix), 3 figures"}, "link": [{"@href": "http://arxiv.org/abs/2007.03443v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.03443v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.1.2; H.4.3; I.2.1; I.2.6; I.2.7; I.5", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.08024v1", "updated": "2020-07-15T22:25:51Z", "published": "2020-07-15T22:25:51Z", "title": "A Survey on Computational Propaganda Detection", "summary": "Propaganda campaigns aim at influencing people's mindset with the purpose of\nadvancing a specific agenda. They exploit the anonymity of the Internet, the\nmicro-profiling ability of social networks, and the ease of automatically\ncreating and managing coordinated networks of accounts, to reach millions of\nsocial network users with persuasive messages, specifically targeted to topics\neach individual user is sensitive to, and ultimately influencing the outcome on\na targeted issue. In this survey, we review the state of the art on\ncomputational propaganda detection from the perspective of Natural Language\nProcessing and Network Analysis, arguing about the need for combined efforts\nbetween these communities. We further discuss current challenges and future\nresearch directions.", "author": [{"name": "Giovanni Da San Martino"}, {"name": "Stefano Cresci"}, {"name": "Alberto Barron-Cedeno"}, {"name": "Seunghak Yu"}, {"name": "Roberto Di Pietro"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda detection, disinformation, misinformation, fake news,\n  media bias"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IJCAI-2020"}, "link": [{"@href": "http://arxiv.org/abs/2007.08024v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.08024v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.11302v1", "updated": "2020-07-22T09:43:43Z", "published": "2020-07-22T09:43:43Z", "title": "Information disorders on Italian Facebook during COVID-19 infodemic", "summary": "In this work we carry out an exploratory analysis of online conversations on\nthe Italian Facebook during the recent COVID-19 pandemic. We analyze the\ncirculation of controversial topics associated with the origin of the virus,\nwhich involve popular targets of misinformation, such as migrants and 5G\ntechnology. We collected over 1.5 M posts in Italian language and related to\nCOVID-19, shared by nearly 80k public pages and groups for a period of four\nmonths since January 2020. Overall, we find that potentially harmful content\nshared by unreliable sources is substantially negligible compared to\ntraditional news websites, and that discussions over controversial topics has a\nlimited engagement w.r.t to the pandemic in general. Besides, we highlight a\n\"small-worldness\" effect in the URL sharing diffusion network, indicating that\nusers navigating through a limited set of pages could reach almost the entire\npool of shared content related to the pandemic, thus being easily exposed to\nharmful propaganda as well as to verified information on the virus.", "author": [{"name": "Alessandro Celestini"}, {"name": "Marco Di Giovanni"}, {"name": "Stefano Guarino"}, {"name": "Francesco Pierri"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.osnem.2021.100124"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.osnem.2021.100124", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.11302v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.11302v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "16 pages, 13 figures, 7 tables"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2007.12358v2", "updated": "2020-07-27T03:59:56Z", "published": "2020-07-24T05:42:29Z", "title": "Machine Learning Explanations to Prevent Overtrust in Fake News\n  Detection", "summary": "Combating fake news and misinformation propagation is a challenging task in\nthe post-truth era. News feed and search algorithms could potentially lead to\nunintentional large-scale propagation of false and fabricated information with\nusers being exposed to algorithmically selected false content. Our research\ninvestigates the effects of an Explainable AI assistant embedded in news review\nplatforms for combating the propagation of fake news. We design a news\nreviewing and sharing interface, create a dataset of news stories, and train\nfour interpretable fake news detection algorithms to study the effects of\nalgorithmic transparency on end-users. We present evaluation results and\nanalysis from multiple controlled crowdsourced studies. For a deeper\nunderstanding of Explainable AI systems, we discuss interactions between user\nengagement, mental model, trust, and performance measures in the process of\nexplaining. The study results indicate that explanations helped participants to\nbuild appropriate mental models of the intelligent assistants in different\nconditions and adjust their trust accordingly for model limitations.", "author": [{"name": "Sina Mohseni"}, {"name": "Fan Yang"}, {"name": "Shiva Pentyala"}, {"name": "Mengnan Du"}, {"name": "Yi Liu"}, {"name": "Nic Lupfer"}, {"name": "Xia Hu"}, {"name": "Shuiwang Ji"}, {"name": "Eric Ragan"}], "link": [{"@href": "http://arxiv.org/abs/2007.12358v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.12358v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.01273v2", "updated": "2021-02-15T22:03:49Z", "published": "2020-08-04T02:04:17Z", "title": "Analyzing Twitter Users' Behavior Before and After Contact by the\n  Internet Research Agency", "summary": "Social media platforms have been exploited to conduct election interference\nin recent years. In particular, the Russian-backed Internet Research Agency\n(IRA) has been identified as a key source of misinformation spread on Twitter\nprior to the 2016 U.S. presidential election. The goal of this research is to\nunderstand whether general Twitter users changed their behavior in the year\nfollowing first contact from an IRA account. We compare the before and after\nbehavior of contacted users to determine whether there were differences in\ntheir mean tweet count, the sentiment of their tweets, and the frequency and\nsentiment of tweets mentioning @realDonaldTrump or @HillaryClinton. Our results\nindicate that users overall exhibited statistically significant changes in\nbehavior across most of these metrics, and that those users that engaged with\nthe IRA generally showed greater changes in behavior.", "author": [{"name": "Upasana Dutta"}, {"name": "Rhett Hanscom"}, {"name": "Jason Shuo Zhang"}, {"name": "Richard Han"}, {"name": "Tamara Lehman"}, {"name": "Qin Lv"}, {"name": "Shivakant Mishra"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3449164"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3449164", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.01273v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.01273v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to CSCW 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.10311v3", "updated": "2020-09-25T17:55:20Z", "published": "2020-09-22T04:32:24Z", "title": "Preserving Integrity in Online Social Networks", "summary": "Online social networks provide a platform for sharing information and free\nexpression. However, these networks are also used for malicious purposes, such\nas distributing misinformation and hate speech, selling illegal drugs, and\ncoordinating sex trafficking or child exploitation. This paper surveys the\nstate of the art in keeping online platforms and their users safe from such\nharm, also known as the problem of preserving integrity. This survey comes from\nthe perspective of having to combat a broad spectrum of integrity violations at\nFacebook. We highlight the techniques that have been proven useful in practice\nand that deserve additional attention from the academic community. Instead of\ndiscussing the many individual violation types, we identify key aspects of the\nsocial-media eco-system, each of which is common to a wide variety violation\ntypes. Furthermore, each of these components represents an area for research\nand development, and the innovations that are found can be applied widely.", "author": [{"name": "Alon Halevy"}, {"name": "Cristian Canton Ferrer"}, {"name": "Hao Ma"}, {"name": "Umut Ozertem"}, {"name": "Patrick Pantel"}, {"name": "Marzieh Saeidi"}, {"name": "Fabrizio Silvestri"}, {"name": "Ves Stoyanov"}], "link": [{"@href": "http://arxiv.org/abs/2009.10311v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.10311v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.11744v2", "updated": "2020-10-08T07:24:45Z", "published": "2020-09-24T15:09:09Z", "title": "Anatomy of a Rumour: Social media and the suicide of Sushant Singh\n  Rajput", "summary": "The suicide of Indian actor Sushant Singh Rajput in the midst of the COVID-19\nlockdown triggered a media frenzy of prime time coverage that lasted several\nmonths and became a political hot button issue. Using data from Twitter,\nYouTube, and an archive of debunked misinformation stories, we found two\nimportant patterns. First, that retweet rates on Twitter clearly suggest that\ncommentators benefited from talking about the case, which got higher engagement\nthan other topics. Second, that politicians, in particular, were instrumental\nin changing the course of the discourse by referring to the case as 'murder',\nrather than 'suicide'. In conclusion, we consider the effects of Rajput's\noutsider status as a small-town implant in the film industry within the broader\nnarrative of systemic injustice, as well as the gendered aspects of mob justice\nthat have taken aim at his former partner in the months since.", "author": [{"name": "Syeda Zainab Akbar"}, {"name": "Ankur Sharma"}, {"name": "Himani Negi"}, {"name": "Anmol Panda"}, {"name": "Joyojeet Pal"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "14 pages, 16 figures. For any queries regarding the paper, please\n  email Joyojeet Pal (Joyojeet.Pal@microsoft.com)"}, "link": [{"@href": "http://arxiv.org/abs/2009.11744v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.11744v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2009.13375v3", "updated": "2021-04-25T09:39:20Z", "published": "2020-09-28T14:48:27Z", "title": "Identifying Automatically Generated Headlines using Transformers", "summary": "False information spread via the internet and social media influences public\nopinion and user activity, while generative models enable fake content to be\ngenerated faster and more cheaply than had previously been possible. In the not\nso distant future, identifying fake content generated by deep learning models\nwill play a key role in protecting users from misinformation. To this end, a\ndataset containing human and computer-generated headlines was created and a\nuser study indicated that humans were only able to identify the fake headlines\nin 47.8% of the cases. However, the most accurate automatic approach,\ntransformers, achieved an overall accuracy of 85.7%, indicating that content\ngenerated from language models can be filtered out accurately.", "author": [{"name": "Antonis Maronikolakis"}, {"name": "Hinrich Schutze"}, {"name": "Mark Stevenson"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NLP4IF 2021 Proceedings, NAACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2009.13375v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.13375v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.00502v2", "updated": "2021-08-10T11:41:16Z", "published": "2020-10-01T15:50:41Z", "title": "AMUSED: An Annotation Framework of Multi-modal Social Media Data", "summary": "In this paper, we present a semi-automated framework called AMUSED for\ngathering multi-modal annotated data from the multiple social media platforms.\nThe framework is designed to mitigate the issues of collecting and annotating\nsocial media data by cohesively combining machine and human in the data\ncollection process. From a given list of the articles from professional news\nmedia or blog, AMUSED detects links to the social media posts from news\narticles and then downloads contents of the same post from the respective\nsocial media platform to gather details about that specific post. The framework\nis capable of fetching the annotated data from multiple platforms like Twitter,\nYouTube, Reddit. The framework aims to reduce the workload and problems behind\nthe data annotation from the social media platforms. AMUSED can be applied in\nmultiple application domains, as a use case, we have implemented the framework\nfor collecting COVID-19 misinformation data from different social media\nplatforms.", "author": {"name": "Gautam Kishore Shahi"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 5 figures, 3 tables"}, "link": [{"@href": "http://arxiv.org/abs/2010.00502v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.00502v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.09078v1", "updated": "2020-10-18T19:37:24Z", "published": "2020-10-18T19:37:24Z", "title": "Incorporating Count-Based Features into Pre-Trained Models for Improved\n  Stance Detection", "summary": "The explosive growth and popularity of Social Media has revolutionised the\nway we communicate and collaborate. Unfortunately, this same ease of accessing\nand sharing information has led to an explosion of misinformation and\npropaganda. Given that stance detection can significantly aid in veracity\nprediction, this work focuses on boosting automated stance detection, a task on\nwhich pre-trained models have been extremely successful on, as on several other\ntasks. This work shows that the task of stance detection can benefit from\nfeature based information, especially on certain under performing classes,\nhowever, integrating such features into pre-trained models using ensembling is\nchallenging. We propose a novel architecture for integrating features with\npre-trained models that address these challenges and test our method on the\nRumourEval 2019 dataset. This method achieves state-of-the-art results with an\nF1-score of 63.94 on the test set.", "author": [{"name": "Anushka Prakash"}, {"name": "Harish Tayyar Madabushi"}], "link": [{"@href": "http://arxiv.org/abs/2010.09078v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.09078v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.09113v1", "updated": "2020-10-18T21:44:23Z", "published": "2020-10-18T21:44:23Z", "title": "Disinformation in the Online Information Ecosystem: Detection,\n  Mitigation and Challenges", "summary": "With the rapid increase in access to internet and the subsequent growth in\nthe population of online social media users, the quality of information posted,\ndisseminated and consumed via these platforms is an issue of growing concern. A\nlarge fraction of the common public turn to social media platforms and in\ngeneral the internet for news and even information regarding highly concerning\nissues such as COVID-19 symptoms. Given that the online information ecosystem\nis extremely noisy, fraught with misinformation and disinformation, and often\ncontaminated by malicious agents spreading propaganda, identifying genuine and\ngood quality information from disinformation is a challenging task for humans.\nIn this regard, there is a significant amount of ongoing research in the\ndirections of disinformation detection and mitigation. In this survey, we\ndiscuss the online disinformation problem, focusing on the recent 'infodemic'\nin the wake of the coronavirus pandemic. We then proceed to discuss the\ninherent challenges in disinformation research, and then elaborate on the\ncomputational and interdisciplinary approaches towards mitigation of\ndisinformation, after a short overview of the various directions explored in\ndetection efforts.", "author": [{"name": "Amrita Bhattacharjee"}, {"name": "Kai Shu"}, {"name": "Min Gao"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "A Chinese version of this manuscript has been submitted to the\n  Journal of Computer Research and Development"}, "link": [{"@href": "http://arxiv.org/abs/2010.09113v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.09113v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.13691v2", "updated": "2021-03-17T02:21:05Z", "published": "2020-10-26T16:11:56Z", "title": "The Manufacture of Partisan Echo Chambers by Follow Train Abuse on\n  Twitter", "summary": "A growing body of evidence points to critical vulnerabilities of social\nmedia, such as the emergence of partisan echo chambers and the viral spread of\nmisinformation. We show that these vulnerabilities are amplified by abusive\nbehaviors associated with so-called \"follow trains\" on Twitter, in which long\nlists of like-minded accounts are mentioned for others to follow. We present\nthe first systematic analysis of a large U.S. hyper-partisan train network. We\nobserve an artificial inflation of influence: accounts heavily promoted by\nfollow trains profit from a median six-fold increase in daily follower growth.\nThis catalyzes the formation of highly clustered echo chambers, hierarchically\norganized around a dense core of active accounts. Train accounts also engage in\nother behaviors that violate platform policies: we find evidence of activity by\ninauthentic automated accounts and abnormal content deletion, as well as\namplification of toxic content from low-credibility and conspiratorial sources.\nSome train accounts have been active for years, suggesting that platforms need\nto pay greater attention to this kind of abuse.", "author": [{"name": "Christopher Torres-Lugo"}, {"name": "Kai-Cheng Yang"}, {"name": "Filippo Menczer"}], "link": [{"@href": "http://arxiv.org/abs/2010.13691v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.13691v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.14190v1", "updated": "2020-10-27T10:52:23Z", "published": "2020-10-27T10:52:23Z", "title": "Collective Movement with Signaling", "summary": "We consider a population of mobile agents able to make noisy observation of\nthe environment and communicate their observation by production and\ncomprehension of signals. Individuals try to align their movement direction\nwith their neighbors. Besides, they try to collectively find and travel towards\nan environmental direction. We show that, when the fraction of informed\nindividuals is small, by increasing the noise in communication, similarly to\nthe Viscek model, the model shows a discontinuous order-disorder transition\nwith strong finite size effects. In contrast, for large fraction of informed\nindividuals, it is possible to go from the ordered phase to the disordered\nphase without passing any phase transition. The ordered phase is composed of\ntwo phases separated by a discontinuous transition. Informed collective motion,\nin which the population collectively infers the correct environmental\ndirection, occurs for high fraction of informed individuals. When the fraction\nof informed individuals is low, misinformed collective motion, where the\npopulation fails to find the environmental direction becomes stable as well.\nBesides, we show that an amount of noise in the production of signals is more\ndetrimental for the inference capability of the population, and increases the\ndensity fluctuations and the probability of group fragmentation, compared to\nthe same amount of noise in the comprehension.", "author": [{"name": "Mohammad Salahshour"}, {"name": "Shahin Rouhani"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "16 pages; 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/2010.14190v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.14190v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cond-mat.stat-mech", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cond-mat.stat-mech", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.bio-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.16413v2", "updated": "2021-01-03T18:22:17Z", "published": "2020-10-09T22:10:43Z", "title": "Artificial Intelligence (AI) in Action: Addressing the COVID-19 Pandemic\n  with Natural Language Processing (NLP)", "summary": "The COVID-19 pandemic has had a significant impact on society, both because\nof the serious health effects of COVID-19 and because of public health measures\nimplemented to slow its spread. Many of these difficulties are fundamentally\ninformation needs; attempts to address these needs have caused an information\noverload for both researchers and the public. Natural language processing\n(NLP), the branch of artificial intelligence that interprets human language,\ncan be applied to address many of the information needs made urgent by the\nCOVID-19 pandemic. This review surveys approximately 150 NLP studies and more\nthan 50 systems and datasets addressing the COVID-19 pandemic. We detail work\non four core NLP tasks: information retrieval, named entity recognition,\nliterature-based discovery, and question answering. We also describe work that\ndirectly addresses aspects of the pandemic through four additional tasks: topic\nmodeling, sentiment and emotion analysis, caseload forecasting, and\nmisinformation detection. We conclude by discussing observable trends and\nremaining challenges.", "author": [{"name": "Qingyu Chen"}, {"name": "Robert Leaman"}, {"name": "Alexis Allot"}, {"name": "Ling Luo"}, {"name": "Chih-Hsuan Wei"}, {"name": "Shankai Yan"}, {"name": "Zhiyong Lu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "51 pages, 3 figures and 2 tables"}, "link": [{"@href": "http://arxiv.org/abs/2010.16413v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.16413v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.09145v2", "updated": "2020-11-19T05:45:58Z", "published": "2020-11-18T07:56:24Z", "title": "A First Look at COVID-19 Messages on WhatsApp in Pakistan", "summary": "The worldwide spread of COVID-19 has prompted extensive online discussions,\ncreating an `infodemic' on social media platforms such as WhatsApp and Twitter.\nHowever, the information shared on these platforms is prone to be unreliable\nand/or misleading. In this paper, we present the first analysis of COVID-19\ndiscourse on public WhatsApp groups from Pakistan. Building on a large scale\nannotation of thousands of messages containing text and images, we identify the\nmain categories of discussion. We focus on COVID-19 messages and understand the\ndifferent types of images/text messages being propagated. By exploring user\nbehavior related to COVID messages, we inspect how misinformation is spread.\nFinally, by quantifying the flow of information across WhatsApp and Twitter, we\nshow how information spreads across platforms and how WhatsApp acts as a source\nfor much of the information shared on Twitter.", "author": [{"name": "R. Tallal Javed"}, {"name": "Mirza Elaaf Shuja"}, {"name": "Muhammad Usama"}, {"name": "Junaid Qadir"}, {"name": "Waleed Iqbal"}, {"name": "Gareth Tyson"}, {"name": "Ignacio Castro"}, {"name": "Kiran Garimella"}], "link": [{"@href": "http://arxiv.org/abs/2011.09145v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.09145v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.09957v1", "updated": "2020-11-19T16:53:38Z", "published": "2020-11-19T16:53:38Z", "title": "Adversarial Threats to DeepFake Detection: A Practical Perspective", "summary": "Facially manipulated images and videos or DeepFakes can be used maliciously\nto fuel misinformation or defame individuals. Therefore, detecting DeepFakes is\ncrucial to increase the credibility of social media platforms and other media\nsharing web sites. State-of-the art DeepFake detection techniques rely on\nneural network based classification models which are known to be vulnerable to\nadversarial examples. In this work, we study the vulnerabilities of\nstate-of-the-art DeepFake detection methods from a practical stand point. We\nperform adversarial attacks on DeepFake detectors in a black box setting where\nthe adversary does not have complete knowledge of the classification models. We\nstudy the extent to which adversarial perturbations transfer across different\nmodels and propose techniques to improve the transferability of adversarial\nexamples. We also create more accessible attacks using Universal Adversarial\nPerturbations which pose a very feasible attack scenario since they can be\neasily shared amongst attackers. We perform our evaluations on the winning\nentries of the DeepFake Detection Challenge (DFDC) and demonstrate that they\ncan be easily bypassed in a practical attack scenario by designing transferable\nand accessible adversarial attacks.", "author": [{"name": "Paarth Neekhara"}, {"name": "Brian Dolhansky"}, {"name": "Joanna Bitton"}, {"name": "Cristian Canton Ferrer"}], "link": [{"@href": "http://arxiv.org/abs/2011.09957v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.09957v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.00614v2", "updated": "2021-01-02T16:07:48Z", "published": "2020-12-01T16:32:54Z", "title": "CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims", "summary": "We introduce CLIMATE-FEVER, a new publicly available dataset for verification\nof climate change-related claims. By providing a dataset for the research\ncommunity, we aim to facilitate and encourage work on improving algorithms for\nretrieving evidential support for climate-specific claims, addressing the\nunderlying language understanding challenges, and ultimately help alleviate the\nimpact of misinformation on climate change. We adapt the methodology of FEVER\n[1], the largest dataset of artificially designed claims, to real-life claims\ncollected from the Internet. While during this process, we could rely on the\nexpertise of renowned climate scientists, it turned out to be no easy task. We\ndiscuss the surprising, subtle complexity of modeling real-world\nclimate-related claims within the \\textsc{fever} framework, which we believe\nprovides a valuable challenge for general natural language understanding. We\nhope that our work will mark the beginning of a new exciting long-term joint\neffort by the climate science and AI community.", "author": [{"name": "Thomas Diggelmann"}, {"name": "Jordan Boyd-Graber"}, {"name": "Jannis Bulian"}, {"name": "Massimiliano Ciaramita"}, {"name": "Markus Leippold"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for the Tackling Climate Change with Machine Learning\n  Workshop at NeurIPS 2020"}, "link": [{"@href": "http://arxiv.org/abs/2012.00614v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.00614v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.01462v3", "updated": "2021-03-01T12:24:15Z", "published": "2020-12-02T19:05:25Z", "title": "ArCorona: Analyzing Arabic Tweets in the Early Days of Coronavirus\n  (COVID-19) Pandemic", "summary": "Over the past few months, there were huge numbers of circulating tweets and\ndiscussions about Coronavirus (COVID-19) in the Arab region. It is important\nfor policy makers and many people to identify types of shared tweets to better\nunderstand public behavior, topics of interest, requests from governments,\nsources of tweets, etc. It is also crucial to prevent spreading of rumors and\nmisinformation about the virus or bad cures. To this end, we present the\nlargest manually annotated dataset of Arabic tweets related to COVID-19. We\ndescribe annotation guidelines, analyze our dataset and build effective machine\nlearning and transformer based models for classification.", "author": [{"name": "Hamdy Mubarak"}, {"name": "Sabit Hassan"}], "link": [{"@href": "http://arxiv.org/abs/2012.01462v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.01462v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.07517v1", "updated": "2020-11-30T16:41:04Z", "published": "2020-11-30T16:41:04Z", "title": "Fake News Detection in Social Media using Graph Neural Networks and NLP\n  Techniques: A COVID-19 Use-case", "summary": "The paper presents our solutions for the MediaEval 2020 task namely FakeNews:\nCorona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task\naims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect\nmisinformation spreaders. The task is composed of two sub-tasks namely (i)\ntext-based, and (ii) structure-based fake news detection. For the first task,\nwe propose six different solutions relying on Bag of Words (BoW) and BERT\nembedding. Three of the methods aim at binary classification task by\ndifferentiating in 5G conspiracy and the rest of the COVID-19 related tweets\nwhile the rest of them treat the task as ternary classification problem. In the\nternary classification task, our BoW and BERT based methods obtained an\nF1-score of .606% and .566% on the development set, respectively. On the binary\nclassification, the BoW and BERT based solutions obtained an average F1-score\nof .666% and .693%, respectively. On the other hand, for structure-based fake\nnews detection, we rely on Graph Neural Networks (GNNs) achieving an average\nROC of .95% on the development set.", "author": [{"name": "Abdullah Hamid"}, {"name": "Nasrullah Shiekh"}, {"name": "Naina Said"}, {"name": "Kashif Ahmad"}, {"name": "Asma Gul"}, {"name": "Laiq Hassan"}, {"name": "Ala Al-Fuqaha"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "3 pages"}, "link": [{"@href": "http://arxiv.org/abs/2012.07517v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.07517v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.10185v1", "updated": "2020-12-18T12:10:13Z", "published": "2020-12-18T12:10:13Z", "title": "Recommenders with a mission: assessing diversity in newsrecommendations", "summary": "News recommenders help users to find relevant online content and have the\npotential to fulfill a crucial role in a democratic society, directing the\nscarce attention of citizens towards the information that is most important to\nthem. Simultaneously, recent concerns about so-called filter bubbles,\nmisinformation and selective exposure are symptomatic of the disruptive\npotential of these digital news recommenders. Recommender systems can make or\nbreak filter bubbles, and as such can be instrumental in creating either a more\nclosed or a more open internet. Current approaches to evaluating recommender\nsystems are often focused on measuring an increase in user clicks and\nshort-term engagement, rather than measuring the user's longer term interest in\ndiverse and important information.\n  This paper aims to bridge the gap between normative notions of diversity,\nrooted in democratic theory, and quantitative metrics necessary for evaluating\nthe recommender system. We propose a set of metrics grounded in social science\ninterpretations of diversity and suggest ways for practical implementations.", "author": [{"name": "Sanne Vrijenhoek"}, {"name": "Mesut Kaya"}, {"name": "Nadia Metoui"}, {"name": "Judith M\u00f6ller"}, {"name": "Daan Odijk"}, {"name": "Natali Helberger"}], "link": [{"@href": "http://arxiv.org/abs/2012.10185v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.10185v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.11967v3", "updated": "2021-01-13T11:36:32Z", "published": "2020-12-22T12:43:12Z", "title": "g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning\n  for COVID-19 Fake News Detection", "summary": "The COVID-19 pandemic has had a huge impact on various areas of human life.\nHence, the coronavirus pandemic and its consequences are being actively\ndiscussed on social media. However, not all social media posts are truthful.\nMany of them spread fake news that cause panic among readers, misinform people\nand thus exacerbate the effect of the pandemic. In this paper, we present our\nresults at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in\nEnglish. In particular, we propose our approach using the transformer-based\nensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used,\nthe ways of text preprocessing and adding extra data. As a result, our best\nmodel achieved the weighted F1-score of 98.69 on the test set (the first place\nin the leaderboard) of this shared task that attracted 166 submitted teams in\ntotal.", "author": [{"name": "Anna Glazkova"}, {"name": "Maksim Glazkov"}, {"name": "Timofey Trifonov"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-73696-5_12"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-73696-5_12", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2012.11967v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.11967v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The winning solution at the Constraint shared task (AAAI-2021)"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Combating Online Hostile Posts in Regional Languages during\n  Emergency Situation, 116-127, 2021. Springer, Cham"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7; I.7.m; H.3.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.00180v3", "updated": "2021-01-21T15:18:40Z", "published": "2021-01-01T06:49:27Z", "title": "Transformer based Automatic COVID-19 Fake News Detection System", "summary": "Recent rapid technological advancements in online social networks such as\nTwitter have led to a great incline in spreading false information and fake\nnews. Misinformation is especially prevalent in the ongoing coronavirus disease\n(COVID-19) pandemic, leading to individuals accepting bogus and potentially\ndeleterious claims and articles. Quick detection of fake news can reduce the\nspread of panic and confusion among the public. For our analysis in this paper,\nwe report a methodology to analyze the reliability of information shared on\nsocial media pertaining to the COVID-19 pandemic. Our best approach is based on\nan ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting\nfake news. This model was trained and evaluated in the context of the\nConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our\nsystem obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.", "author": [{"name": "Sunil Gundapu"}, {"name": "Radhika Mamidi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "First Workshop on Combating Online Hostile Posts in Regional\n  Languages during Emergency Situation, 12 pages"}, "link": [{"@href": "http://arxiv.org/abs/2101.00180v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.00180v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.04079v2", "updated": "2021-06-05T18:01:16Z", "published": "2021-01-07T01:40:52Z", "title": "Depolarization of echo chambers by random dynamical nudge", "summary": "Interactions among individuals in social networks lead to echo chambers where\nthe distribution of opinions follows a bimodal distribution with two peaks at\nthe opposite extremes. In issues with clear answers, such as global warming,\none of the echo chambers reflects an inaccurate judgment, potentially from\nmisinformation. However, in issues without clear answers such as elections, the\nneutral consensus is preferable for promoting discourse. In this letter, we use\nan opinion dynamics model to study the effect of a random dynamical nudge where\nwe present random input to each agent from the other individuals in the\nnetwork. We show that random dynamical nudge disallows the formation of echo\nchambers and leads to a normal distribution of opinions centered around the\nneutral consensus. The random dynamical nudge relies on the collective dynamics\nand it does not require surveillance of every person's opinions. Social media\nnetworks could implement a version of this self-feedback mechanism to prevent\nthe formation of segregated online communities on pressing issues such as\nelections.", "author": [{"name": "Christopher Currin"}, {"name": "Sebastian Vallejo Vera"}, {"name": "Ali Khaledi-Nasab"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 4 Figs"}, "link": [{"@href": "http://arxiv.org/abs/2101.04079v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.04079v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.bio-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.07664v1", "updated": "2021-01-19T14:57:04Z", "published": "2021-01-19T14:57:04Z", "title": "Analysis of Moral Judgement on Reddit", "summary": "Moral outrage has become synonymous with social media in recent years.\nHowever, the preponderance of academic analysis on social media websites has\nfocused on hate speech and misinformation. This paper focuses on analyzing\nmoral judgements rendered on social media by capturing the moral judgements\nthat are passed in the subreddit /r/AmITheAsshole on Reddit. Using the labels\nassociated with each judgement we train a classifier that can take a comment\nand determine whether it judges the user who made the original post to have\npositive or negative moral valence. Then, we use this classifier to investigate\nan assortment of website traits surrounding moral judgements in ten other\nsubreddits, including where negative moral users like to post and their posting\npatterns. Our findings also indicate that posts that are judged in a positive\nmanner will score higher.", "author": [{"name": "Nicholas Botzer"}, {"name": "Shawn Gu"}, {"name": "Tim Weninger"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted to ICWSM 2021, 9 pages and 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/2101.07664v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.07664v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.09575v1", "updated": "2021-01-23T20:14:05Z", "published": "2021-01-23T20:14:05Z", "title": "Examining Factors Associated with Twitter Account Suspension Following\n  the 2020 U.S. Presidential Election", "summary": "Online social media enables mass-level, transparent, and democratized\ndiscussion on numerous socio-political issues. Due to such openness, these\nplatforms often endure manipulation and misinformation - leading to negative\nimpacts. To prevent such harmful activities, platform moderators employ\ncountermeasures to safeguard against actors violating their rules. However, the\ncorrelation between publicly outlined policies and employed action is less\nclear to general people. In this work, we examine violations and subsequent\nmoderation related to the 2020 U.S. President Election discussion on Twitter, a\npopular micro-blogging site. We focus on quantifying plausible reasons for the\nsuspension, drawing on Twitter's rules and policies by identifying suspended\nusers (Case) and comparing their activities and properties with (yet)\nnon-suspended (Control) users. Using a dataset of 240M election-related tweets\nmade by 21M unique users, we observe that Suspended users violate Twitter's\nrules at a higher rate (statistically significant) than Control users across\nall the considered aspects - hate speech, offensiveness, spamming, and civic\nintegrity. Moreover, through the lens of Twitter's suspension mechanism, we\nqualitatively examine the targeted topics for manipulation.", "author": [{"name": "Farhan Asif Chowdhury"}, {"name": "Dheeman Saha"}, {"name": "Md Rashidul Hasan"}, {"name": "Koustuv Saha"}, {"name": "Abdullah Mueen"}], "link": [{"@href": "http://arxiv.org/abs/2101.09575v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.09575v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.12027v1", "updated": "2021-01-28T14:43:42Z", "published": "2021-01-28T14:43:42Z", "title": "A transformer based approach for fighting COVID-19 fake news", "summary": "The rapid outbreak of COVID-19 has caused humanity to come to a stand-still\nand brought with it a plethora of other problems. COVID-19 is the first\npandemic in history when humanity is the most technologically advanced and\nrelies heavily on social media platforms for connectivity and other benefits.\nUnfortunately, fake news and misinformation regarding this virus is also\navailable to people and causing some massive problems. So, fighting this\ninfodemic has become a significant challenge. We present our solution for the\n\"Constraint@AAAI2021 - COVID19 Fake News Detection in English\" challenge in\nthis work. After extensive experimentation with numerous architectures and\ntechniques, we use eight different transformer-based pre-trained models with\nadditional layers to construct a stacking ensemble classifier and fine-tuned\nthem for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,\n0.979906542 recall, and 0.979907901 f1-score on the test dataset of the\ncompetition.", "author": [{"name": "S. M. Sadiq-Ur-Rahman Shifath"}, {"name": "Mohammad Faiyaz Khan"}, {"name": "Md. Saiful Islam"}], "link": [{"@href": "http://arxiv.org/abs/2101.12027v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.12027v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.00573v1", "updated": "2021-02-01T00:34:38Z", "published": "2021-02-01T00:34:38Z", "title": "A Secure Learning Control Strategy via Dynamic Camouflaging for Unknown\n  Dynamical Systems under Attacks", "summary": "This paper presents a secure reinforcement learning (RL) based control method\nfor unknown linear time-invariant cyber-physical systems (CPSs) that are\nsubjected to compositional attacks such as eavesdropping and covert attack. We\nconsider the attack scenario where the attacker learns about the dynamic model\nduring the exploration phase of the learning conducted by the designer to learn\na linear quadratic regulator (LQR), and thereafter, use such information to\nconduct a covert attack on the dynamic system, which we refer to as doubly\nlearning-based control and attack (DLCA) framework. We propose a dynamic\ncamouflaging based attack-resilient reinforcement learning (ARRL) algorithm\nwhich can learn the desired optimal controller for the dynamic system, and at\nthe same time, can inject sufficient misinformation in the estimation of system\ndynamics by the attacker. The algorithm is accompanied by theoretical\nguarantees and extensive numerical experiments on a consensus multi-agent\nsystem and on a benchmark power grid model.", "author": [{"name": "Sayak Mukherjee"}, {"name": "Veronica Adetola"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 17 figures"}, "link": [{"@href": "http://arxiv.org/abs/2102.00573v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.00573v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "eess.SY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "eess.SY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.01148v1", "updated": "2021-02-01T20:37:23Z", "published": "2021-02-01T20:37:23Z", "title": "A comparative study of Bot Detection techniques methods with an\n  application related to Covid-19 discourse on Twitter", "summary": "Bot Detection is an essential asset in a period where Online Social\nNetworks(OSN) is a part of our lives. This task becomes more relevant in\ncrises, as the Covid-19 pandemic, where there is an incipient risk of\nproliferation of social bots, producing a possible source of misinformation. In\norder to address this issue, it has been compared different methods to detect\nautomatically social bots on Twitter using Data Selection. The techniques\nutilized to elaborate the bot detection models include the utilization of\nfeatures as the tweets metadata or the Digital Fingerprint of the Twitter\naccounts. In addition, it was analyzed the presence of bots in tweets from\ndifferent periods of the first months of the Covid-19 pandemic, using the bot\ndetection technique which best fits the scope of the task. Moreover, this work\nincludes also analysis over aspects regarding the discourse of bots and humans,\nsuch as sentiment or hashtag utilization.", "author": [{"name": "Marzia Antenore"}, {"name": "Jose M. Camacho-Rodriguez"}, {"name": "Emanuele Panizzi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "36 pages, 10 figures, 5 tables"}, "link": [{"@href": "http://arxiv.org/abs/2102.01148v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.01148v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "J.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.02680v1", "updated": "2021-02-04T15:18:44Z", "published": "2021-02-04T15:18:44Z", "title": "Hierarchical Multi-head Attentive Network for Evidence-aware Fake News\n  Detection", "summary": "The widespread of fake news and misinformation in various domains ranging\nfrom politics, economics to public health has posed an urgent need to\nautomatically fact-check information. A recent trend in fake news detection is\nto utilize evidence from external sources. However, existing evidence-aware\nfake news detection methods focused on either only word-level attention or\nevidence-level attention, which may result in suboptimal performance. In this\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\ntextual claims. Our model jointly combines multi-head word-level attention and\nmulti-head document-level attention, which aid explanation in both word-level\nand evidence-level. Experiments on two real-word datasets show that our model\noutperforms seven state-of-the-art baselines. Improvements over baselines are\nfrom 6\\% to 18\\%. Our source code and datasets are released at\n\\texttt{\\url{https://github.com/nguyenvo09/EACL2021}}.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EACL2021"}, "link": [{"@href": "http://arxiv.org/abs/2102.02680v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.02680v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.04567v1", "updated": "2021-02-08T22:55:37Z", "published": "2021-02-08T22:55:37Z", "title": "NELA-GT-2020: A Large Multi-Labelled News Dataset for The Study of\n  Misinformation in News Articles", "summary": "In this paper, we present an updated version of the NELA-GT-2019 dataset,\nentitled NELA-GT-2020. NELA-GT-2020 contains nearly 1.8M news articles from 519\nsources collected between January 1st, 2020 and December 31st, 2020. Just as\nwith NELA-GT-2018 and NELA-GT-2019, these sources come from a wide range of\nmainstream news sources and alternative news sources. Included in the dataset\nare source-level ground truth labels from Media Bias/Fact Check (MBFC) covering\nmultiple dimensions of veracity. Additionally, new in the 2020 dataset are the\nTweets embedded in the collected news articles, adding an extra layer of\ninformation to the data. The NELA-GT-2020 dataset can be found at\nhttps://doi.org/10.7910/DVN/CHMUYZ.", "author": [{"name": "Maur\u00edcio Gruppi"}, {"name": "Benjamin D. Horne"}, {"name": "Sibel Adal\u0131"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:2003.08444"}, "link": [{"@href": "http://arxiv.org/abs/2102.04567v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.04567v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.11917v1", "updated": "2021-02-23T19:55:45Z", "published": "2021-02-23T19:55:45Z", "title": "The Sensitivity of Word Embeddings-based Author Detection Models to\n  Semantic-preserving Adversarial Perturbations", "summary": "Authorship analysis is an important subject in the field of natural language\nprocessing. It allows the detection of the most likely writer of articles,\nnews, books, or messages. This technique has multiple uses in tasks related to\nauthorship attribution, detection of plagiarism, style analysis, sources of\nmisinformation, etc. The focus of this paper is to explore the limitations and\nsensitiveness of established approaches to adversarial manipulations of inputs.\nTo this end, and using those established techniques, we first developed an\nexperimental frame-work for author detection and input perturbations. Next, we\nexperimentally evaluated the performance of the authorship detection model to a\ncollection of semantic-preserving adversarial perturbations of input\nnarratives. Finally, we compare and analyze the effects of different\nperturbation strategies, input and model configurations, and the effects of\nthese on the author detection model.", "author": [{"name": "Jeremiah Duncan"}, {"name": "Fabian Fallas"}, {"name": "Chris Gropp"}, {"name": "Emily Herron"}, {"name": "Maria Mahbub"}, {"name": "Paula Olaya"}, {"name": "Eduardo Ponce"}, {"name": "Tabitha K. Samuel"}, {"name": "Daniel Schultz"}, {"name": "Sudarshan Srinivasan"}, {"name": "Maofeng Tang"}, {"name": "Viktor Zenkov"}, {"name": "Quan Zhou"}, {"name": "Edmon Begoli"}], "link": [{"@href": "http://arxiv.org/abs/2102.11917v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.11917v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.13167v1", "updated": "2021-02-25T20:47:21Z", "published": "2021-02-25T20:47:21Z", "title": "Images, Emotions, and Credibility: Effect of Emotional Facial Images on\n  Perceptions of News Content Bias and Source Credibility in Social Media", "summary": "Images are an indispensable part of the news content we consume. Highly\nemotional images from sources of misinformation can greatly influence our\njudgements. We present two studies on the effects of emotional facial images on\nusers' perception of bias in news content and the credibility of sources. In\nstudy 1, we investigate the impact of happy and angry facial images on users'\ndecisions. In study 2, we focus on sources' systematic emotional treatment of\nspecific politicians. Our results show that depending on the political\norientation of the source, the cumulative effect of angry facial emotions\nimpacts users' perceived content bias and source credibility. When sources\nsystematically portray specific politicians as angry, users are more likely to\nfind those sources as less credible and their content as more biased. These\nresults highlight how implicit visual propositions manifested by emotions in\nfacial expressions might have a substantial effect on our trust of news content\nand sources.", "author": [{"name": "Alireza Karduni"}, {"name": "Ryan Wesslen"}, {"name": "Douglas Markant"}, {"name": "Wenwen Dou"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "23 pages, 9 figures"}, "link": [{"@href": "http://arxiv.org/abs/2102.13167v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.13167v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.00242v1", "updated": "2021-02-27T15:27:22Z", "published": "2021-02-27T15:27:22Z", "title": "A Survey on Stance Detection for Mis- and Disinformation Identification", "summary": "Detecting attitudes expressed in texts, also known as stance detection, has\nbecome an important task for the detection of false information online, be it\nmisinformation (unintentionally false) or disinformation (intentionally false,\nspread deliberately with malicious intent). Stance detection has been framed in\ndifferent ways, including: (a) as a component of fact-checking, rumour\ndetection, and detecting previously fact-checked claims; or (b) as a task in\nits own right. While there have been prior efforts to contrast stance detection\nwith other related social media tasks such as argumentation mining and\nsentiment analysis, there is no survey examining the relationship between\nstance detection detection and mis- and disinformation detection from a\nholistic viewpoint, which is the focus of this survey. We review and analyse\nexisting work in this area, before discussing lessons learnt and future\nchallenges.", "author": [{"name": "Momchil Hardalov"}, {"name": "Arnav Arora"}, {"name": "Preslav Nakov"}, {"name": "Isabelle Augenstein"}], "link": [{"@href": "http://arxiv.org/abs/2103.00242v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.00242v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.09258v1", "updated": "2021-03-16T18:10:22Z", "published": "2021-03-16T18:10:22Z", "title": "The Rise and Fall of Fake News sites: A Traffic Analysis", "summary": "Over the past decade, we have witnessed the rise of misinformation on the\nInternet, with online users constantly falling victims of fake news. A\nmultitude of past studies have analyzed fake news diffusion mechanics and\ndetection and mitigation techniques. However, there are still open questions\nabout their operational behavior such as: How old are fake news websites? Do\nthey typically stay online for long periods of time? Do such websites\nsynchronize with each other their up and down time? Do they share similar\ncontent through time? Which third-parties support their operations? How much\nuser traffic do they attract, in comparison to mainstream or real news\nwebsites? In this paper, we perform a first of its kind investigation to answer\nsuch questions regarding the online presence of fake news websites and\ncharacterize their behavior in comparison to real news websites. Based on our\nfindings, we build a content-agnostic ML classifier for automatic detection of\nfake news websites (i.e. accuracy) that are not yet included in manually\ncurated blacklists.", "author": [{"name": "Manolis Chalkiadakis"}, {"name": "Alexandros Kornilakis"}, {"name": "Panagiotis Papadopoulos"}, {"name": "Evangelos P. Markatos"}, {"name": "Nicolas Kourtellis"}], "link": [{"@href": "http://arxiv.org/abs/2103.09258v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.09258v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.00088v2", "updated": "2021-05-03T15:42:38Z", "published": "2021-03-31T20:09:09Z", "title": "Transfer Learning for Node Regression Applied to Spreading Prediction", "summary": "Understanding how information propagates in real-life complex networks yields\na better understanding of dynamic processes such as misinformation or epidemic\nspreading. The recently introduced branch of machine learning methods for\nlearning node representations offers many novel applications, one of them being\nthe task of spreading prediction addressed in this paper. We explore the\nutility of the state-of-the-art node representation learners when used to\nassess the effects of spreading from a given node, estimated via extensive\nsimulations. Further, as many real-life networks are topologically similar, we\nsystematically investigate whether the learned models generalize to previously\nunseen networks, showing that in some cases very good model transfer can be\nobtained. This work is one of the first to explore transferability of the\nlearned representations for the task of node regression; we show there exist\npairs of networks with similar structure between which the trained models can\nbe transferred (zero-shot), and demonstrate their competitive performance. To\nour knowledge, this is one of the first attempts to evaluate the utility of\nzero-shot transfer for the task of node regression.", "author": [{"name": "Sebastian Me\u017enar"}, {"name": "Nada Lavra\u010d"}, {"name": "Bla\u017e \u0160krlj"}], "link": [{"@href": "http://arxiv.org/abs/2104.00088v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.00088v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.04331v1", "updated": "2021-04-09T12:29:34Z", "published": "2021-04-09T12:29:34Z", "title": "The Burden of Being a Bridge: Understanding the Role of Multilingual\n  Users during the COVID-19 Pandemic", "summary": "The outbreak of the COVID-19 pandemic triggers infodemic over online social\nnetworks. It is thus important for governments to ensure their official\nmessages outpace misinformation and efficiently reach the public. Some\ncountries and regions that are currently worst affected by the virus including\nEurope, South America and India, encounter an additional difficulty:\nmultilingualism. Understanding the specific role of multilingual users in the\nprocess of information diffusion is critical to adjust their publishing\nstrategies for the governments of such countries and regions. In this paper, we\ninvestigate the role of multilingual users in diffusing information during the\nCOVID-19 pandemic on popular social networks. We collect a large-scale dataset\nof Twitter from a populated multilingual region from the beginning of the\npandemic. With this dataset, we successfully show that multilingual users act\nas bridges in diffusing COVID-19 related information. We further study the\nmental health of multilingual users and show that being the bridges,\nmultilingual users tend to be more negative. This is confirmed by a recent\npsychological study stating that excessive exposure to social media may result\nin a negative mood.", "author": [{"name": "Ninghan Chen"}, {"name": "Xihui Chen"}, {"name": "Zhiqiang Zhong"}, {"name": "Jun Pang"}], "link": [{"@href": "http://arxiv.org/abs/2104.04331v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.04331v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.04389v1", "updated": "2021-04-09T14:22:52Z", "published": "2021-04-09T14:22:52Z", "title": "A Few Observations About State-Centric Online Propaganda", "summary": "This paper presents a few observations about pro-Kremlin propaganda between\n2015 and early 2021 with a dataset from the East Stratcom Task Force (ESTF),\nwhich is affiliated with the European Union (EU) but working independently from\nit. Instead of focusing on misinformation and disinformation, the observations\nare motivated by classical propaganda research and the ongoing transformation\nof media systems. According to the tentative results, (i) the propaganda can be\nassumed to target both domestic and foreign audiences. Of the countries and\nregions discussed, (ii) Russia, Ukraine, the United States, and within Europe,\nGermany, Poland, and the EU have been the most frequently discussed. Also other\nconflict regions such as Syria have often appeared in the propaganda. In terms\nof longitudinal trends, however, (iii) most of these discussions have decreased\nin volume after the digital tsunami in 2016, although the conflict in Ukraine\nseems to have again increased the intensity of pro-Kremlin propaganda. Finally,\n(iv) the themes discussed align with state-centric war propaganda and conflict\nzones, although also post-truth themes frequently appear; from conspiracy\ntheories via COVID-19 to fascism -- anything goes, as is typical to propaganda.", "author": {"name": "Jukka Ruohonen"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted"}, "link": [{"@href": "http://arxiv.org/abs/2104.04389v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.04389v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.05866v1", "updated": "2021-04-12T23:46:54Z", "published": "2021-04-12T23:46:54Z", "title": "On Representation Learning for Scientific News Articles Using\n  Heterogeneous Knowledge Graphs", "summary": "In the era of misinformation and information inflation, the credibility\nassessment of the produced news is of the essence. However, fact-checking can\nbe challenging considering the limited references presented in the news. This\nchallenge can be transcended by utilizing the knowledge graph that is related\nto the news articles. In this work, we present a methodology for creating\nscientific news article representations by modeling the directed graph between\nthe scientific news articles and the cited scientific publications. The network\nused for the experiments is comprised of the scientific news articles, their\ntopic, the cited research literature, and their corresponding authors. We\nimplement and present three different approaches: 1) a baseline Relational\nGraph Convolutional Network (R-GCN), 2) a Heterogeneous Graph Neural Network\n(HetGNN) and 3) a Heterogeneous Graph Transformer (HGT). We test these models\nin the downstream task of link prediction on the: a) news article - paper links\nand b) news article - article topic links. The results show promising\napplications of graph neural network approaches in the domains of knowledge\ntracing and scientific news credibility assessment.", "author": [{"name": "Angelika Romanou"}, {"name": "Panayiotis Smeros"}, {"name": "Karl Aberer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3442442.3451362"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3442442.3451362", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2104.05866v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.05866v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.05893v1", "updated": "2021-04-13T01:53:26Z", "published": "2021-04-13T01:53:26Z", "title": "NewsCLIPpings: Automatic Generation of Out-of-Context Multimodal Media", "summary": "The threat of online misinformation is hard to overestimate, with adversaries\nrelying on a range of tools, from cheap fakes to sophisticated deep fakes. We\nare motivated by a threat scenario where an image is being used out of context\nto support a certain narrative expressed in a caption. While some prior\ndatasets for detecting image-text inconsistency can be solved with blind models\ndue to linguistic cues introduced by text manipulation, we propose a dataset\nwhere both image and text are unmanipulated but mismatched. We introduce\nseveral strategies for automatic retrieval of suitable images for the given\ncaptions, capturing cases with related semantics but inconsistent entities as\nwell as matching entities but inconsistent semantic context. Our large-scale\nautomatically generated NewsCLIPpings Dataset requires models to jointly\nanalyze both modalities and to reason about entity mismatch as well as semantic\nmismatch between text and images in news media.", "author": [{"name": "Grace Luo"}, {"name": "Trevor Darrell"}, {"name": "Anna Rohrbach"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 4 figures"}, "link": [{"@href": "http://arxiv.org/abs/2104.05893v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.05893v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.11639v2", "updated": "2021-05-01T18:22:39Z", "published": "2021-04-23T14:45:31Z", "title": "Claim Detection in Biomedical Twitter Posts", "summary": "Social media contains unfiltered and unique information, which is potentially\nof great value, but, in the case of misinformation, can also do great harm.\nWith regards to biomedical topics, false information can be particularly\ndangerous. Methods of automatic fact-checking and fake news detection address\nthis problem, but have not been applied to the biomedical domain in social\nmedia yet. We aim to fill this research gap and annotate a corpus of 1200\ntweets for implicit and explicit biomedical claims (the latter also with span\nannotations for the claim phrase). With this corpus, which we sample to be\nrelated to COVID-19, measles, cystic fibrosis, and depression, we develop\nbaseline models which detect tweets that contain a claim automatically. Our\nanalyses reveal that biomedical tweets are densely populated with claims (45 %\nin a corpus sampled to contain 1200 tweets focused on the domains mentioned\nabove). Baseline classification experiments with embedding-based classifiers\nand BERT-based transfer learning demonstrate that the detection is challenging,\nhowever, shows acceptable performance for the identification of explicit\nexpressions of claims. Implicit claim tweets are more challenging to detect.", "author": [{"name": "Amelie W\u00fchrl"}, {"name": "Roman Klinger"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at the BioNLP Workshop at NAACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.11639v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.11639v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.11729v1", "updated": "2021-04-23T17:25:38Z", "published": "2021-04-23T17:25:38Z", "title": "Evaluating Deception Detection Model Robustness To Linguistic Variation", "summary": "With the increasing use of machine-learning driven algorithmic judgements, it\nis critical to develop models that are robust to evolving or manipulated\ninputs. We propose an extensive analysis of model robustness against linguistic\nvariation in the setting of deceptive news detection, an important task in the\ncontext of misinformation spread online. We consider two prediction tasks and\ncompare three state-of-the-art embeddings to highlight consistent trends in\nmodel performance, high confidence misclassifications, and high impact\nfailures. By measuring the effectiveness of adversarial defense strategies and\nevaluating model susceptibility to adversarial attacks using character- and\nword-perturbed text, we find that character or mixed ensemble models are the\nmost effective defenses and that character perturbation-based attack tactics\nare more successful.", "author": [{"name": "Maria Glenski"}, {"name": "Ellyn Ayton"}, {"name": "Robin Cosbey"}, {"name": "Dustin Arendt"}, {"name": "Svitlana Volkova"}], "link": [{"@href": "http://arxiv.org/abs/2104.11729v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.11729v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.12069v1", "updated": "2021-04-25T05:56:57Z", "published": "2021-04-25T05:56:57Z", "title": "Making GAN-Generated Images Difficult To Spot: A New Attack Against\n  Synthetic Image Detectors", "summary": "Visually realistic GAN-generated images have recently emerged as an important\nmisinformation threat. Research has shown that these synthetic images contain\nforensic traces that are readily identifiable by forensic detectors.\nUnfortunately, these detectors are built upon neural networks, which are\nvulnerable to recently developed adversarial attacks. In this paper, we propose\na new anti-forensic attack capable of fooling GAN-generated image detectors.\nOur attack uses an adversarially trained generator to synthesize traces that\nthese detectors associate with real images. Furthermore, we propose a technique\nto train our attack so that it can achieve transferability, i.e. it can fool\nunknown CNNs that it was not explicitly trained against. We demonstrate the\nperformance of our attack through an extensive set of experiments, where we\nshow that our attack can fool eight state-of-the-art detection CNNs with\nsynthetic images created using seven different GANs.", "author": [{"name": "Xinwei Zhao"}, {"name": "Matthew C. Stamm"}], "link": [{"@href": "http://arxiv.org/abs/2104.12069v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.12069v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.IV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.12556v3", "updated": "2021-08-04T10:37:23Z", "published": "2021-04-16T12:41:15Z", "title": "COVID-19 Modeling: A Review", "summary": "The SARS-CoV-2 virus and COVID-19 disease have posed unprecedented and\noverwhelming demand, challenges and opportunities to domain, model and data\ndriven modeling. This paper provides a comprehensive review of the challenges,\ntasks, methods, progress, gaps and opportunities in relation to modeling\nCOVID-19 problems, data and objectives. It constructs a research landscape of\nCOVID-19 modeling tasks and methods, and further categorizes, summarizes,\ncompares and discusses the related methods and progress of modeling COVID-19\nepidemic transmission processes and dynamics, case identification and tracing,\ninfection diagnosis and medical treatments, non-pharmaceutical interventions\nand their effects, drug and vaccine development, psychological, economic and\nsocial influence and impact, and misinformation, etc. The modeling methods\ninvolve mathematical and statistical models, domain-driven modeling by\nepidemiological compartmental models, medical and biomedical analysis, AI and\ndata science in particular shallow and deep machine learning, simulation\nmodeling, social science methods, and hybrid modeling.", "author": [{"name": "Longbing Cao"}, {"name": "Qing Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "73 pages, 3 figures, 9 tables"}, "link": [{"@href": "http://arxiv.org/abs/2104.12556v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.12556v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.13559v2", "updated": "2021-05-18T05:41:05Z", "published": "2021-04-28T03:38:24Z", "title": "AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance\n  Detection for Fact Checking", "summary": "With the continuing spread of misinformation and disinformation online, it is\nof increasing importance to develop combating mechanisms at scale in the form\nof automated systems that support multiple languages. One task of interest is\nclaim veracity prediction, which can be addressed using stance detection with\nrespect to relevant documents retrieved online. To this end, we present our new\nArabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from\na diverse set of sources comprising three fact-checking websites and one news\nwebsite. AraStance covers false and true claims from multiple domains (e.g.,\npolitics, sports, health) and several Arab countries, and it is well-balanced\nbetween related and unrelated documents with respect to the claims. We\nbenchmark AraStance, along with two other stance detection datasets, using a\nnumber of BERT-based models. Our best model achieves an accuracy of 85\\% and a\nmacro F1 score of 78\\%, which leaves room for improvement and reflects the\nchallenging nature of AraStance and the task of stance detection in general.", "author": [{"name": "Tariq Alhindi"}, {"name": "Amal Alabdulkarim"}, {"name": "Ali Alshehri"}, {"name": "Muhammad Abdul-Mageed"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the 2021 Workshop on NLP4IF: Censorship, Disinformation,\n  and Propaganda"}, "link": [{"@href": "http://arxiv.org/abs/2104.13559v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13559v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.13748v1", "updated": "2021-04-28T13:28:27Z", "published": "2021-04-28T13:28:27Z", "title": "QuTI! Quantifying Text-Image Consistency in Multimodal Documents", "summary": "The World Wide Web and social media platforms have become popular sources for\nnews and information. Typically, multimodal information, e.g., image and text\nis used to convey information more effectively and to attract attention. While\nin most cases image content is decorative or depicts additional information, it\nhas also been leveraged to spread misinformation and rumors in recent years. In\nthis paper, we present a Web-based demo application that automatically\nquantifies the cross-modal relations of entities (persons, locations, and\nevents) in image and text. The applications are manifold. For example, the\nsystem can help users to explore multimodal articles more efficiently, or can\nassist human assessors and fact-checking efforts in the verification of the\ncredibility of news stories, tweets, or other multimodal documents.", "author": [{"name": "Matthias Springstein"}, {"name": "Eric M\u00fcller-Budack"}, {"name": "Ralph Ewerth"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication in: International ACM SIGIR Conference on\n  Research and Development in Information Retrieval 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.13748v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13748v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.13816v1", "updated": "2021-04-28T15:04:22Z", "published": "2021-04-28T15:04:22Z", "title": "The Evolution of Rumors on a Closed Platform during COVID-19", "summary": "In this work we looked into a dataset of 114 thousands of suspicious messages\ncollected from the most popular closed messaging platform in Taiwan between\nJanuary and July, 2020. We proposed an hybrid algorithm that could efficiently\ncluster a large number of text messages according their topics and narratives.\nThat is, we obtained groups of messages that are within a limited content\nalterations within each other. By employing the algorithm to the dataset, we\nwere able to look at the content alterations and the temporal dynamics of each\nparticular rumor over time. With qualitative case studies of three COVID-19\nrelated rumors, we have found that key authoritative figures were often\nmisquoted in false information. It was an effective measure to increase the\npopularity of one false information. In addition, fact-check was not effective\nin stopping misinformation from getting attention. In fact, the popularity of\none false information was often more influenced by major societal events and\neffective content alterations.", "author": [{"name": "Andrea W Wang", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Information Operations Research Group"}}, {"name": "Jo-Yu Lan", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Department of Information Engineering and Computer Science, Feng Chia University"}}, {"name": "Chihhao Yu", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Information Operations Research Group"}}, {"name": "Ming-Hung Wang", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Department of Information Engineering and Computer Science, Feng Chia University"}}], "link": [{"@href": "http://arxiv.org/abs/2104.13816v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13816v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.00192v1", "updated": "2021-05-01T08:25:43Z", "published": "2021-05-01T08:25:43Z", "title": "Deep Insights of Deepfake Technology : A Review", "summary": "Under the aegis of computer vision and deep learning technology, a new\nemerging techniques has introduced that anyone can make highly realistic but\nfake videos, images even can manipulates the voices. This technology is widely\nknown as Deepfake Technology. Although it seems interesting techniques to make\nfake videos or image of something or some individuals but it could spread as\nmisinformation via internet. Deepfake contents could be dangerous for\nindividuals as well as for our communities, organizations, countries religions\netc. As Deepfake content creation involve a high level expertise with\ncombination of several algorithms of deep learning, it seems almost real and\ngenuine and difficult to differentiate. In this paper, a wide range of articles\nhave been examined to understand Deepfake technology more extensively. We have\nexamined several articles to find some insights such as what is Deepfake, who\nare responsible for this, is there any benefits of Deepfake and what are the\nchallenges of this technology. We have also examined several creation and\ndetection techniques. Our study revealed that although Deepfake is a threat to\nour societies, proper measures and strict regulations could prevent this.", "author": [{"name": "Bahar Uddin Mahmud"}, {"name": "Afsana Sharmin"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "DUJASE Vol. 5(1 & 2) 13-23, 2020 (January & July)"}, "link": [{"@href": "http://arxiv.org/abs/2105.00192v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.00192v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2105.02306v1", "updated": "2021-05-05T20:08:36Z", "published": "2021-05-05T20:08:36Z", "title": "Primary and Secondary Social Media Source Identification", "summary": "Social networks like Facebook and WhatsApp have enabled users to share images\nwith other users around the world. Along with this has come the rapid spread of\nmisinformation. One step towards verifying the authenticity of an image is\nunderstanding its origin, including it distribution history through social\nmedia. In this paper, we present a method for tracing the posting history of an\nimage across different social networks. To do this, we propose a two-stage\ndeep-learning-based approach, which takes advantage of cascaded fingerprints in\nimages left by social networks during uploading. Our proposed system is not\nreliant upon metadata or similar easily falsifiable information. Through a\nseries of experiments, we show that we are able to outperform existing social\nmedia source identification algorithms. and identify chains of social networks\nup to length two with over over 84% accuracy.", "author": [{"name": "Brian C Hosler"}, {"name": "Matthew C Stamm"}], "link": [{"@href": "http://arxiv.org/abs/2105.02306v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.02306v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "eess.IV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "eess.IV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2105.07454v2", "updated": "2021-06-05T15:10:56Z", "published": "2021-05-16T15:38:49Z", "title": "A Synchronized Action Framework for Responsible Detection of\n  Coordination on Social Media", "summary": "The study of coordinated manipulation of conversations on social media has\nbecome more prevalent as social media's role in amplifying misinformation,\nhate, and polarization has come under scrutiny. We discuss the implications of\nsuccessful coordination detection algorithms based on shifts of power, and\nconsider how responsible coordination detection may be carried out through\nsynchronized action. We then propose a Synchronized Action Framework for\ndetection of automated coordination through construction and analysis of\nmulti-view networks. We validate our framework by examining the Reopen America\nconversation on Twitter, discovering three coordinated campaigns. We further\ninvestigate covert coordination surrounding the protests and find the task to\nbe far more complex than examples seen in prior work, demonstrating the need\nfor our multi-view approach. A cluster of suspicious users is identified and\nthe activity of three members is detailed. These users amplify protest messages\nusing the same hashtags at very similar times, though they all focus on\ndifferent states. Through this analysis, we emphasize both the potential\nusefulness of coordination detection algorithms in investigating amplification,\nand the need for careful and responsible deployment of such tools.", "author": [{"name": "Thomas Magelinski"}, {"name": "Lynnette Hui Xian Ng"}, {"name": "Kathleen M. Carley"}], "link": [{"@href": "http://arxiv.org/abs/2105.07454v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.07454v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2105.07854v1", "updated": "2021-05-06T15:26:48Z", "published": "2021-05-06T15:26:48Z", "title": "\"Hey Alexa, What do You Know About the COVID-19 Vaccine?\" --\n  (Mis)perceptions of Mass Immunization Among Voice Assistant Users", "summary": "In this paper, we analyzed the perceived accuracy of COVID-19 vaccine\ninformation spoken back by Amazon Alexa. Unlike social media, Amazon Alexa\ndoesn't apply soft moderation to unverified content, allowing for use of\nthird-party malicious skills to arbitrarily phrase COVID-19 vaccine\ninformation. The results from a 210-participant study suggest that a\nthird-party malicious skill could successful reduce the perceived accuracy\namong the users of information as to who gets the vaccine first, vaccine\ntesting, and the side effects of the vaccine. We also found that the\nvaccine-hesitant participants are drawn to pessimistically rephrased Alexa\nresponses focused on the downsides of the mass immunization. We discuss\nsolutions for soft moderation against misperception-inducing or altogether\nCOVID-19 misinformation malicious third-party skills.", "author": [{"name": "Filipo Sharevski"}, {"name": "Anna Slowinski"}, {"name": "Peter Jachim"}, {"name": "Emma Pieroni"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: text overlap with arXiv:2104.04077"}, "link": [{"@href": "http://arxiv.org/abs/2105.07854v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.07854v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.09284v1", "updated": "2021-04-25T05:00:53Z", "published": "2021-04-25T05:00:53Z", "title": "SemEval-2021 Task 6: Detection of Persuasion Techniques in Texts and\n  Images", "summary": "We describe SemEval-2021 task 6 on Detection of Persuasion Techniques in\nTexts and Images: the data, the annotation guidelines, the evaluation setup,\nthe results, and the participating systems. The task focused on memes and had\nthree subtasks: (i) detecting the techniques in the text, (ii) detecting the\ntext spans where the techniques are used, and (iii) detecting techniques in the\nentire meme, i.e., both in the text and in the image. It was a popular task,\nattracting 71 registrations, and 22 teams that eventually made an official\nsubmission on the test set. The evaluation results for the third subtask\nconfirmed the importance of both modalities, the text and the image. Moreover,\nsome teams reported benefits when not just combining the two modalities, e.g.,\nby using early or late fusion, but rather modeling the interaction between them\nin a joint model.", "author": [{"name": "Dimitar Dimitrov"}, {"name": "Bishr Bin Ali"}, {"name": "Shaden Shaar"}, {"name": "Firoj Alam"}, {"name": "Fabrizio Silvestri"}, {"name": "Hamed Firooz"}, {"name": "Preslav Nakov"}, {"name": "Giovanni Da San Martino"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, disinformation, misinformation, fake news, memes,\n  multimodality"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SemEval-2021"}, "link": [{"@href": "http://arxiv.org/abs/2105.09284v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.09284v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.10671v1", "updated": "2021-05-22T09:26:13Z", "published": "2021-05-22T09:26:13Z", "title": "SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?", "summary": "Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges.", "author": [{"name": "Tanveer Khan"}, {"name": "Antonis Michalas"}, {"name": "Adnan Akhunzada"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "34 pages, 3 figures"}, "link": [{"@href": "http://arxiv.org/abs/2105.10671v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.10671v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.14005v1", "updated": "2021-05-28T17:30:51Z", "published": "2021-05-28T17:30:51Z", "title": "Online Hate: Behavioural Dynamics and Relationship with Misinformation", "summary": "Online debates are often characterised by extreme polarisation and heated\ndiscussions among users. The presence of hate speech online is becoming\nincreasingly problematic, making necessary the development of appropriate\ncountermeasures. In this work, we perform hate speech detection on a corpus of\nmore than one million comments on YouTube videos through a machine learning\nmodel fine-tuned on a large set of hand-annotated data. Our analysis shows that\nthere is no evidence of the presence of \"serial haters\", intended as active\nusers posting exclusively hateful comments. Moreover, coherently with the echo\nchamber hypothesis, we find that users skewed towards one of the two categories\nof video channels (questionable, reliable) are more prone to use inappropriate,\nviolent, or hateful language within their opponents community. Interestingly,\nusers loyal to reliable sources use on average a more toxic language than their\ncounterpart. Finally, we find that the overall toxicity of the discussion\nincreases with its length, measured both in terms of number of comments and\ntime. Our results show that, coherently with Godwin's law, online debates tend\nto degenerate towards increasingly toxic exchanges of views.", "author": [{"name": "Matteo Cinelli"}, {"name": "Andra\u017e Pelicon"}, {"name": "Igor Mozeti\u010d"}, {"name": "Walter Quattrociocchi"}, {"name": "Petra Kralj Novak"}, {"name": "Fabiana Zollo"}], "link": [{"@href": "http://arxiv.org/abs/2105.14005v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.14005v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.14376v1", "updated": "2021-05-29T21:22:24Z", "published": "2021-05-29T21:22:24Z", "title": "Beyond the Spectrum: Detecting Deepfakes via Re-Synthesis", "summary": "The rapid advances in deep generative models over the past years have led to\nhighly {realistic media, known as deepfakes,} that are commonly\nindistinguishable from real to human eyes. These advances make assessing the\nauthenticity of visual data increasingly difficult and pose a misinformation\nthreat to the trustworthiness of visual content in general. Although recent\nwork has shown strong detection accuracy of such deepfakes, the success largely\nrelies on identifying frequency artifacts in the generated images, which will\nnot yield a sustainable detection approach as generative models continue\nevolving and closing the gap to real images. In order to overcome this issue,\nwe propose a novel fake detection that is designed to re-synthesize testing\nimages and extract visual cues for detection. The re-synthesis procedure is\nflexible, allowing us to incorporate a series of visual tasks - we adopt\nsuper-resolution, denoising and colorization as the re-synthesis. We\ndemonstrate the improved effectiveness, cross-GAN generalization, and\nrobustness against perturbations of our approach in a variety of detection\nscenarios involving multiple generators over CelebA-HQ, FFHQ, and LSUN\ndatasets. Source code is available at\nhttps://github.com/SSAW14/BeyondtheSpectrum.", "author": [{"name": "Yang He"}, {"name": "Ning Yu"}, {"name": "Margret Keuper"}, {"name": "Mario Fritz"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear in IJCAI2021. Source code at\n  https://github.com/SSAW14/BeyondtheSpectrum"}, "link": [{"@href": "http://arxiv.org/abs/2105.14376v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.14376v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.01170v1", "updated": "2021-06-02T14:10:28Z", "published": "2021-06-02T14:10:28Z", "title": "Detecting Bot-Generated Text by Characterizing Linguistic Accommodation\n  in Human-Bot Interactions", "summary": "Language generation models' democratization benefits many domains, from\nanswering health-related questions to enhancing education by providing\nAI-driven tutoring services. However, language generation models'\ndemocratization also makes it easier to generate human-like text at-scale for\nnefarious activities, from spreading misinformation to targeting specific\ngroups with hate speech. Thus, it is essential to understand how people\ninteract with bots and develop methods to detect bot-generated text. This paper\nshows that bot-generated text detection methods are more robust across datasets\nand models if we use information about how people respond to it rather than\nusing the bot's text directly. We also analyze linguistic alignment, providing\ninsight into differences between human-human and human-bot conversations.", "author": [{"name": "Paras Bhatt"}, {"name": "Anthony Rios"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages, to be published in Findings of ACL-IJCNLP 2021"}, "link": [{"@href": "http://arxiv.org/abs/2106.01170v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.01170v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.04726v2", "updated": "2021-07-23T17:49:31Z", "published": "2021-06-08T23:08:47Z", "title": "Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study\n  of the 2019 Indian Election on WhatsApp", "summary": "There is currently no easy way to fact-check content on WhatsApp and other\nend-to-end encrypted platforms at scale. In this paper, we analyze the\nusefulness of a crowd-sourced \"tipline\" through which users can submit content\n(\"tips\") that they want fact-checked. We compare the tips sent to a WhatsApp\ntipline run during the 2019 Indian national elections with the messages\ncirculating in large, public groups on WhatsApp and other social media\nplatforms during the same period. We find that tiplines are a very useful lens\ninto WhatsApp conversations: a significant fraction of messages and images sent\nto the tipline match with the content being shared on public WhatsApp groups\nand other social media. Our analysis also shows that tiplines cover the most\npopular content well, and a majority of such content is often shared to the\ntipline before appearing in large, public WhatsApp groups. Overall, our\nfindings suggest tiplines can be an effective source for discovering content to\nfact-check.", "author": [{"name": "Ashkan Kazemi"}, {"name": "Kiran Garimella"}, {"name": "Gautam Kishore Shahi"}, {"name": "Devin Gaffney"}, {"name": "Scott A. Hale"}], "link": [{"@href": "http://arxiv.org/abs/2106.04726v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.04726v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.05401v3", "updated": "2021-08-12T04:14:15Z", "published": "2021-06-09T21:34:01Z", "title": "Mechanisms and Attributes of Echo Chambers in Social Media", "summary": "Echo chambers may exclude social media users from being exposed to other\nopinions, therefore, can cause rampant negative effects. Among abundant\nevidence are the 2016 and 2020 US presidential elections conspiracy theories\nand polarization, as well as the COVID-19 disinfodemic. To help better detect\necho chambers and mitigate its negative effects, this paper explores the\nmechanisms and attributes of echo chambers in social media. In particular, we\nfirst illustrate four primary mechanisms related to three main factors: human\npsychology, social networks, and automatic systems. We then depict common\nattributes of echo chambers with a focus on the diffusion of misinformation,\nspreading of conspiracy theory, creation of social trends, political\npolarization, and emotional contagion of users. We illustrate each mechanism\nand attribute in a multi-perspective of sociology, psychology, and social\ncomputing with recent case studies. Our analysis suggest an emerging need to\ndetect echo chambers and mitigate their negative effects.", "author": [{"name": "Bohan Jiang"}, {"name": "Mansooreh Karami"}, {"name": "Lu Cheng"}, {"name": "Tyler Black"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 2 figures, accepted at SBP-BRiMS 2021 (2021 International\n  Conference on Social Computing, Behavioral-Cultural Modeling, & Prediction\n  and Behavior Representation in Modeling and Simulation),\n  working/late-breaking paper track"}, "link": [{"@href": "http://arxiv.org/abs/2106.05401v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.05401v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.05707v1", "updated": "2021-06-10T12:47:36Z", "published": "2021-06-10T12:47:36Z", "title": "FEVEROUS: Fact Extraction and VERification Over Unstructured and\n  Structured information", "summary": "Fact verification has attracted a lot of attention in the machine learning\nand natural language processing communities, as it is one of the key methods\nfor detecting misinformation. Existing large-scale benchmarks for this task\nhave focused mostly on textual sources, i.e. unstructured information, and thus\nignored the wealth of information available in structured formats, such as\ntables. In this paper we introduce a novel dataset and benchmark, Fact\nExtraction and VERification Over Unstructured and Structured information\n(FEVEROUS), which consists of 87,026 verified claims. Each claim is annotated\nwith evidence in the form of sentences and/or cells from tables in Wikipedia,\nas well as a label indicating whether this evidence supports, refutes, or does\nnot provide enough information to reach a verdict. Furthermore, we detail our\nefforts to track and minimize the biases present in the dataset and could be\nexploited by models, e.g. being able to predict the label without using\nevidence. Finally, we develop a baseline for verifying claims against text and\ntables which predicts both the correct evidence and verdict for 18% of the\nclaims.", "author": [{"name": "Rami Aly"}, {"name": "Zhijiang Guo"}, {"name": "Michael Schlichtkrull"}, {"name": "James Thorne"}, {"name": "Andreas Vlachos"}, {"name": "Christos Christodoulopoulos"}, {"name": "Oana Cocarascu"}, {"name": "Arpit Mittal"}], "link": [{"@href": "http://arxiv.org/abs/2106.05707v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.05707v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.11076v1", "updated": "2021-06-21T12:56:39Z", "published": "2021-06-21T12:56:39Z", "title": "Flipping Stance: Social Influence on Bot's and Non Bot's COVID Vaccine\n  Stance", "summary": "Social influence characterizes the change of opinions in a complex social\nenvironment, incorporating an individual's past stances and the impact of\ninterpersonal influence through the social network influence. In this work, we\nobserve stance changes towards the coronavirus vaccine on Twitter from April\n2020 to May 2021, where 1\\% of the agents exhibit the stance flipping behavior,\nof which 53.7\\% are identified bots. We then propose a novel social influence\nmodel to characterize the change in stance of agents. This model considers an\nagent's and his neighbor's past tweets and the overall network structure\ntowards a stance score. In our experiments, the model achieves 86\\% accuracy.\nIn our analysis, bot agents require lesser social influence to flip stances and\na larger proportion of bots flip.", "author": [{"name": "Lynnette Hui Xian Ng"}, {"name": "Kathleen Carley"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear in The Second International MIS2 Workshop: Misinformation\n  and Misbehavior Mining on the Web"}, "link": [{"@href": "http://arxiv.org/abs/2106.11076v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.11076v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.15940v1", "updated": "2021-06-30T09:47:27Z", "published": "2021-06-30T09:47:27Z", "title": "A preliminary approach to knowledge integrity risk assessment in\n  Wikipedia projects", "summary": "Wikipedia is one of the main repositories of free knowledge available today,\nwith a central role in the Web ecosystem. For this reason, it can also be a\nbattleground for actors trying to impose specific points of view or even\nspreading disinformation online. There is a growing need to monitor its\n\"health\" but this is not an easy task. Wikipedia exists in over 300 language\neditions and each project is maintained by a different community, with their\nown strengths, weaknesses and limitations. In this paper, we introduce a\ntaxonomy of knowledge integrity risks across Wikipedia projects and a first set\nof indicators to assess internal risks related to community and content issues,\nas well as external threats such as the geopolitical and media landscape. On\ntop of this taxonomy, we offer a preliminary analysis illustrating how the lack\nof editors' geographical diversity might represent a knowledge integrity risk.\nThese are the first steps of a research project to build a Wikipedia Knowledge\nIntegrity Risk Observatory.", "author": [{"name": "Pablo Arag\u00f3n"}, {"name": "Diego S\u00e1ez-Trumper"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at MIS2'21: Misinformation and Misbehavior Mining on the Web\n  Workshop held in conjunction with KDD 2021"}, "link": [{"@href": "http://arxiv.org/abs/2106.15940v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.15940v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.02012v1", "updated": "2021-07-01T11:07:47Z", "published": "2021-07-01T11:07:47Z", "title": "Tackling COVID-19 Infodemic using Deep Learning", "summary": "Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia.", "author": [{"name": "Prathmesh Pathwar"}, {"name": "Simran Gill"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages, 4 figures, Accepted in 4th International Conference on\n  Computational Intelligence and Data Engineering"}, "link": [{"@href": "http://arxiv.org/abs/2107.02012v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.02012v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.05243v1", "updated": "2021-07-12T08:07:09Z", "published": "2021-07-12T08:07:09Z", "title": "Putting words into the system's mouth: A targeted attack on neural\n  machine translation using monolingual data poisoning", "summary": "Neural machine translation systems are known to be vulnerable to adversarial\ntest inputs, however, as we show in this paper, these systems are also\nvulnerable to training attacks. Specifically, we propose a poisoning attack in\nwhich a malicious adversary inserts a small poisoned sample of monolingual text\ninto the training set of a system trained using back-translation. This sample\nis designed to induce a specific, targeted translation behaviour, such as\npeddling misinformation. We present two methods for crafting poisoned examples,\nand show that only a tiny handful of instances, amounting to only 0.02% of the\ntraining set, is sufficient to enact a successful attack. We outline a defence\nmethod against said attacks, which partly ameliorates the problem. However, we\nstress that this is a blind-spot in modern NMT, demanding immediate attention.", "author": [{"name": "Jun Wang"}, {"name": "Chang Xu"}, {"name": "Francisco Guzman"}, {"name": "Ahmed El-Kishky"}, {"name": "Yuqing Tang"}, {"name": "Benjamin I. P. Rubinstein"}, {"name": "Trevor Cohn"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Findings of ACL, to appear"}, "link": [{"@href": "http://arxiv.org/abs/2107.05243v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.05243v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.08357v1", "updated": "2021-07-18T04:09:47Z", "published": "2021-07-18T04:09:47Z", "title": "As Easy as 1, 2, 3: Behavioural Testing of NMT Systems for Numerical\n  Translation", "summary": "Mistranslated numbers have the potential to cause serious effects, such as\nfinancial loss or medical misinformation. In this work we develop comprehensive\nassessments of the robustness of neural machine translation systems to\nnumerical text via behavioural testing. We explore a variety of numerical\ntranslation capabilities a system is expected to exhibit and design effective\ntest examples to expose system underperformance. We find that numerical\nmistranslation is a general issue: major commercial systems and\nstate-of-the-art research models fail on many of our test examples, for high-\nand low-resource languages. Our tests reveal novel errors that have not\npreviously been reported in NMT systems, to the best of our knowledge. Lastly,\nwe discuss strategies to mitigate numerical mistranslation.", "author": [{"name": "Jun Wang"}, {"name": "Chang Xu"}, {"name": "Francisco Guzman"}, {"name": "Ahmed El-Kishky"}, {"name": "Benjamin I. P. Rubinstein"}, {"name": "Trevor Cohn"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Findings of ACL, to appear"}, "link": [{"@href": "http://arxiv.org/abs/2107.08357v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.08357v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.09183v1", "updated": "2021-07-19T22:47:17Z", "published": "2021-07-19T22:47:17Z", "title": "Analysis of External Content in the Vaccination Discussion on Twitter", "summary": "The spread of coronavirus and anti-vaccine conspiracies online hindered\npublic health responses to the pandemic. We examined the content of external\narticles shared on Twitter from February to June 2020 to understand how\nconspiracy theories and fake news competed with legitimate sources of\ninformation. Examining external content--articles, rather than social media\nposts--is a novel methodology that allows for non-social media specific\nanalysis of misinformation, tracking of changing narratives over time, and\ndetermining which types of resources (government, news, scientific, or dubious)\ndominate the pandemic vaccine conversation. We find that distinct narratives\nemerge, those narratives change over time, and lack of government and\nscientific messaging on coronavirus created an information vacuum filled by\nboth traditional news and conspiracy theories.", "author": [{"name": "Richard Kuzma"}, {"name": "Iain J. Cruickshank"}, {"name": "Kathleen M. Carley"}], "link": [{"@href": "http://arxiv.org/abs/2107.09183v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.09183v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.12303v2", "updated": "2021-08-04T18:59:47Z", "published": "2021-07-26T16:20:44Z", "title": "The False COVID-19 Narratives That Keep Being Debunked: A Spatiotemporal\n  Analysis", "summary": "The onset of the Coronavirus disease 2019 (COVID-19) pandemic instigated a\nglobal infodemic that has brought unprecedented challenges for society as a\nwhole. During this time, a number of manual fact-checking initiatives have\nemerged to alleviate the spread of dis/mis-information. This study is about\nCOVID-19 debunks published in multiple languages by different fact-checking\norganisations, sometimes as far as several months apart, despite the fact that\nthe claim has already been fact-checked before. The spatiotemporal analysis\nreveals that similar or nearly duplicate false COVID-19 narratives have been\nspreading in multifarious modalities on various social media platforms in\ndifferent countries. We also find that misinformation involving general medical\nadvice has spread across multiple countries and hence has the highest\nproportion of false COVID-19 narratives that keep being debunked. Furthermore,\nas manual fact-checking is an onerous task in itself, therefore debunking\nsimilar claims recurrently is leading to a waste of resources. To this end, we\npropound the idea of the inclusion of multilingual debunk search in the\nfact-checking pipeline.", "author": [{"name": "Iknoor Singh"}, {"name": "Kalina Bontcheva"}, {"name": "Carolina Scarton"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Under Review"}, "link": [{"@href": "http://arxiv.org/abs/2107.12303v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.12303v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.05150v1", "updated": "2021-08-11T10:56:10Z", "published": "2021-08-11T10:56:10Z", "title": "Exploring the Links between Personality Traits and Suscep;bility to\n  Disinformation", "summary": "The growth of online Digital/social media has allowed a variety of ideas and\nopinions to coexist. Social Media has appealed users due to the ease of fast\ndissemination of information at low cost and easy access. However, due to the\ngrowth in affordance of Digital platforms, users have become prone to consume\ndisinformation, misinformation, propaganda, and conspiracy theories. In this\npaper, we wish to explore the links between the personality traits given by the\nBig Five Inventory and their susceptibility to disinformation. More\nspeciDically, this study is attributed to capture the short- term as well as\nthe long-term effects of disinformation and its effects on the Dive personality\ntraits. Further, we expect to observe that different personalities traits have\ndifferent shifts in opinion and different increase or decrease of uncertainty\non an issue after consuming the disinformation. Based on the Dindings of this\nstudy, we would like to propose a personalized narrative-based change in\nbehavior for different personality traits.", "author": [{"name": "Dipto Barman"}, {"name": "Owen Conlan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3465336.3475121"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3465336.3475121", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.05150v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.05150v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "4 pages, 1 figure, ACM conference"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.06035v2", "updated": "2021-09-01T22:01:41Z", "published": "2021-08-13T02:55:53Z", "title": "Narrative Sensemaking: Strategies for Narrative Maps Construction", "summary": "Narrative sensemaking is a fundamental process to understand sequential\ninformation. Narrative maps are a visual representation framework that can aid\nanalysts in this process. They allow analysts to understand the big picture of\na narrative, uncover new relationships between events, and model connections\nbetween storylines. As a sensemaking tool, narrative maps have applications in\nintelligence analysis, misinformation modeling, and computational journalism.\nIn this work, we seek to understand how analysts construct narrative maps in\norder to improve narrative map representation and extraction methods. We\nperform an experiment with a data set of news articles. Our main contribution\nis an analysis of how analysts construct narrative maps. The insights extracted\nfrom our study can be used to design narrative map visualizations, extraction\nalgorithms, and visual analytics tools to support the sensemaking process.", "author": [{"name": "Brian Felipe Keith Norambuena"}, {"name": "Tanushree Mitra"}, {"name": "Chris North"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted as a short paper in IEEE VIS 2021; added citation\n  information"}, "link": [{"@href": "http://arxiv.org/abs/2108.06035v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.06035v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.07898v1", "updated": "2021-08-17T22:09:22Z", "published": "2021-08-17T22:09:22Z", "title": "Informed Crowds Can Effectively Identify Misinformation", "summary": "Can crowd workers be trusted to judge whether news-like articles circulating\non the Internet are wildly misleading, or does partisanship and inexperience\nget in the way? We assembled pools of both liberal and conservative crowd\nraters and tested three ways of asking them to make judgments about 374\narticles. In a no research condition, they were just asked to view the article\nand then render a judgment. In an individual research condition, they were also\nasked to search for corroborating evidence and provide a link to the best\nevidence they found. In a collective research condition, they were not asked to\nsearch, but instead to look at links collected from workers in the individual\nresearch condition. The individual research condition reduced the partisanship\nof judgments. Moreover, the judgments of a panel of sixteen or more crowd\nworkers were better than that of a panel of three expert journalists, as\nmeasured by alignment with a held out journalist's ratings. Without research,\nthe crowd judgments were better than those of a single journalist, but not as\ngood as the average of two journalists.", "author": [{"name": "Paul Resnick"}, {"name": "Aljohara Alfayez"}, {"name": "Jane Im"}, {"name": "Eric Gilbert"}], "link": [{"@href": "http://arxiv.org/abs/2108.07898v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.07898v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.10791v1", "updated": "2021-08-11T12:54:26Z", "published": "2021-08-11T12:54:26Z", "title": "Ensuring the Inclusive Use of Natural Language Processing in the Global\n  Response to COVID-19", "summary": "Natural language processing (NLP) plays a significant role in tools for the\nCOVID-19 pandemic response, from detecting misinformation on social media to\nhelping to provide accurate clinical information or summarizing scientific\nresearch. However, the approaches developed thus far have not benefited all\npopulations, regions or languages equally. We discuss ways in which current and\nfuture NLP approaches can be made more inclusive by covering low-resource\nlanguages, including alternative modalities, leveraging out-of-the-box tools\nand forming meaningful partnerships. We suggest several future directions for\nresearchers interested in maximizing the positive societal impacts of NLP.", "author": [{"name": "Alexandra Sasha Luccioni"}, {"name": "Katherine Hoffmann Pham"}, {"name": "Cynthia Sin Nga Lam"}, {"name": "Joseph Aylett-Bullock"}, {"name": "Miguel Luengo-Oroz"}], "link": [{"@href": "http://arxiv.org/abs/2108.10791v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.10791v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.12269v1", "updated": "2021-07-31T06:40:17Z", "published": "2021-07-31T06:40:17Z", "title": "Detecting Propaganda on the Sentence Level during the COVID-19 Pandemic", "summary": "The spread of misinformation, conspiracy, and questionable content and\ninformation manipulation by foreign adversaries on social media has surged\nalong with the COVID-19 pandemic. Such malicious cyber-enabled actions may\ncause increasing social polarization, health crises, and property loss. In this\npaper, using fine-tuned contextualized embedding trained on Reddit, we tackle\nthe detection of the propaganda of such user accounts and their targeted issues\non Twitter during March 2020 when the COVID-19 epidemic became recognized as a\npandemic. Our result shows that the pro-China group appeared to be tweeting 35\nto 115 times more than the neutral group. At the same time, neutral groups were\ntweeting more positive-attitude content and voicing alarm for the COVID-19\nsituation. The pro-China group was also using more call-for-action words on\npolitical issues not necessarily China-related.", "author": [{"name": "Rong-Ching Chang"}, {"name": "Chu-Hsing Lin"}], "link": [{"@href": "http://arxiv.org/abs/2108.12269v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.12269v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.12519v1", "updated": "2021-08-27T22:43:00Z", "published": "2021-08-27T22:43:00Z", "title": "Predicting the Factuality of Reporting of News Media Using Observations\n  About User Attention in Their YouTube Channels", "summary": "We propose a novel framework for predicting the factuality of reporting of\nnews media outlets by studying the user attention cycles in their YouTube\nchannels. In particular, we design a rich set of features derived from the\ntemporal evolution of the number of views, likes, dislikes, and comments for a\nvideo, which we then aggregate to the channel level. We develop and release a\ndataset for the task, containing observations of user attention on YouTube\nchannels for 489 news media. Our experiments demonstrate both complementarity\nand sizable improvements over state-of-the-art textual representations.", "author": [{"name": "Krasimira Bozhanova"}, {"name": "Yoan Dinkov"}, {"name": "Ivan Koychev"}, {"name": "Maria Castaldo"}, {"name": "Tommaso Venturini"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Factuality, disinformation, misinformation, fake news, Youtube\n  channels, propaganda, attention cycles"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RANLP-2021"}, "link": [{"@href": "http://arxiv.org/abs/2108.12519v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.12519v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.12802v1", "updated": "2021-08-29T09:57:01Z", "published": "2021-08-29T09:57:01Z", "title": "Interpretable Propaganda Detection in News Articles", "summary": "Online users today are exposed to misleading and propagandistic news articles\nand media posts on a daily basis. To counter thus, a number of approaches have\nbeen designed aiming to achieve a healthier and safer online news and media\nconsumption. Automatic systems are able to support humans in detecting such\ncontent; yet, a major impediment to their broad adoption is that besides being\naccurate, the decisions of such systems need also to be interpretable in order\nto be trusted and widely adopted by users. Since misleading and propagandistic\ncontent influences readers through the use of a number of deception techniques,\nwe propose to detect and to show the use of such techniques as a way to offer\ninterpretability. In particular, we define qualitatively descriptive features\nand we analyze their suitability for detecting deception techniques. We further\nshow that our interpretable features can be easily combined with pre-trained\nlanguage models, yielding state-of-the-art results.", "author": [{"name": "Seunghak Yu"}, {"name": "Giovanni Da San Martino"}, {"name": "Mitra Mohtarami"}, {"name": "James Glass"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, propaganda techniques, disinformation, misinformation,\n  fake news, explainability, interpretability"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RANLP-2021"}, "link": [{"@href": "http://arxiv.org/abs/2108.12802v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.12802v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.12961v1", "updated": "2021-08-30T02:39:13Z", "published": "2021-08-30T02:39:13Z", "title": "BioFors: A Large Biomedical Image Forensics Dataset", "summary": "Research in media forensics has gained traction to combat the spread of\nmisinformation. However, most of this research has been directed towards\ncontent generated on social media. Biomedical image forensics is a related\nproblem, where manipulation or misuse of images reported in biomedical research\ndocuments is of serious concern. The problem has failed to gain momentum beyond\nan academic discussion due to an absence of benchmark datasets and standardized\ntasks. In this paper we present BioFors -- the first dataset for benchmarking\ncommon biomedical image manipulations. BioFors comprises 47,805 images\nextracted from 1,031 open-source research papers. Images in BioFors are divided\ninto four categories -- Microscopy, Blot/Gel, FACS and Macroscopy. We also\npropose three tasks for forensic analysis -- external duplication detection,\ninternal duplication detection and cut/sharp-transition detection. We benchmark\nBioFors on all tasks with suitable state-of-the-art algorithms. Our results and\nanalysis show that existing algorithms developed on common computer vision\ndatasets are not robust when applied to biomedical images, validating that more\nresearch is required to address the unique challenges of biomedical image\nforensics.", "author": [{"name": "Ekraam Sabir"}, {"name": "Soumyaroop Nandi"}, {"name": "Wael AbdAlmageed"}, {"name": "Prem Natarajan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear at ICCV 2021"}, "link": [{"@href": "http://arxiv.org/abs/2108.12961v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.12961v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/0902.0666v3", "updated": "2012-02-15T12:01:35Z", "published": "2009-02-04T07:50:32Z", "title": "Effect of the Born-Infeld Parameter in higher dimensional Hawking\n  radiation", "summary": "We show in detail that the Hawking temperature calculated from the surface\ngravity is in agreement with the result of exact semi-classical radiation\nspectrum for higher dimensional linear dilaton black holes in various theories.\nWe extend the method derived first by Cl\\'ement-Fabris-Marques for\n4-dimensional linear dilaton black hole solutions to the higher dimensions in\ntheories such as Einstein-Maxwell-Dilaton, Einstein-Yang-Mills-Dilaton and\nEinstein-Yang-Mills-Born-Infeld-Dilaton. Similar to the\nCl\\'ement-Fabris-Marques results, it is proved that whenever an analytic\nsolution is available to the massless scalar wave equation in the background of\nhigher dimensional massive linear dilaton black holes, an exact computation of\nthe radiation spectrum leads to the Hawking temperature T_{H} in the high\nfrequency regime. The significance of the dimensionality on the value of T_{H}\nis shown, explicitly. For a chosen dimension, we demonstrate how higher\ndimensional linear dilaton black holes interpolate between the black hole\nsolutions with Yang-Mills and electromagnetic fields by altering the\nBorn-Infeld parameter in aspect of measurable quantity T_{H}. Finally, we\nexplain the reason of, why massless higher dimensional linear dilaton black\nholes cannot radiate.", "author": [{"name": "S. Habib Mazharimousavi"}, {"name": "I. Sakalli"}, {"name": "M. Halilsoy"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.physletb.2009.01.024"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.physletb.2009.01.024", "@rel": "related"}, {"@href": "http://arxiv.org/abs/0902.0666v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/0902.0666v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "2 Figures. (The misinformation about its previous version (v2) is\n  eliminated.)"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys.Lett.B672:177-181,2009"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "gr-qc", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "gr-qc", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1310.2665v1", "updated": "2013-10-10T00:10:46Z", "published": "2013-10-10T00:10:46Z", "title": "Clustering Memes in Social Media", "summary": "The increasing pervasiveness of social media creates new opportunities to\nstudy human social behavior, while challenging our capability to analyze their\nmassive data streams. One of the emerging tasks is to distinguish between\ndifferent kinds of activities, for example engineered misinformation campaigns\nversus spontaneous communication. Such detection problems require a formal\ndefinition of meme, or unit of information that can spread from person to\nperson through the social network. Once a meme is identified, supervised\nlearning methods can be applied to classify different types of communication.\nThe appropriate granularity of a meme, however, is hardly captured from\nexisting entities such as tags and keywords. Here we present a framework for\nthe novel task of detecting memes by clustering messages from large streams of\nsocial data. We evaluate various similarity measures that leverage content,\nmetadata, network features, and their combinations. We also explore the idea of\npre-clustering on the basis of existing entities. A systematic evaluation is\ncarried out using a manually curated dataset as ground truth. Our analysis\nshows that pre-clustering and a combination of heterogeneous features yield the\nbest trade-off between number of clusters and their quality, demonstrating that\na simple combination based on pairwise maximization of similarity is as\neffective as a non-trivial optimization of parameters. Our approach is fully\nautomatic, unsupervised, and scalable for real-time detection of memes in\nstreaming data.", "author": [{"name": "Emilio Ferrara"}, {"name": "Mohsen JafariAsbagh"}, {"name": "Onur Varol"}, {"name": "Vahed Qazvinian"}, {"name": "Filippo Menczer"}, {"name": "Alessandro Flammini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/2492517.2492530"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/2492517.2492530", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1310.2665v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1310.2665v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the 2013 IEEE/ACM International Conference on Advances\n  in Social Networks Analysis and Mining (ASONAM'13), 2013"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Advances in social networks analysis and mining (ASONAM), 2013\n  IEEE/ACM international conference on (pp. 548-555). IEEE"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.data-an", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1503.03752v2", "updated": "2015-03-13T03:46:26Z", "published": "2015-03-12T14:50:52Z", "title": "Manipulation and abuse on social media", "summary": "The computer science research community has became increasingly interested in\nthe study of social media due to their pervasiveness in the everyday life of\nmillions of individuals. Methodological questions and technical challenges\nabound as more and more data from social platforms become available for\nanalysis. This data deluge not only yields the unprecedented opportunity to\nunravel questions about online individuals' behavior at scale, but also allows\nto explore the potential perils that the massive adoption of social media\nbrings to our society. These communication channels provide plenty of\nincentives (both economical and social) and opportunities for abuse. As social\nmedia activity became increasingly intertwined with the events in the offline\nworld, individuals and organizations have found ways to exploit these platforms\nto spread misinformation, to attack and smear others, or to deceive and\nmanipulate. During crises, social media have been effectively used for\nemergency response, but fear-mongering actions have also triggered mass\nhysteria and panic. Criminal gangs and terrorist organizations like ISIS adopt\nsocial media for propaganda and recruitment. Synthetic activity and social bots\nhave been used to coordinate orchestrated astroturf campaigns, to manipulate\npolitical elections and the stock market. The lack of effective content\nverification systems on many of these platforms, including Twitter and\nFacebook, rises concerns when younger users become exposed to cyber-bulling,\nharassment, or hate speech, inducing risks like depression and suicide. This\narticle illustrates some of the recent advances facing these issues and\ndiscusses what it remains to be done, including the challenges to address in\nthe future to make social media a more useful and accessible, safer and\nhealthier environment for all users.", "author": {"name": "Emilio Ferrara"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/2749279.2749283"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/2749279.2749283", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1503.03752v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1503.03752v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACM SIGWEB Newsletter, Spring 2015"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1610.07772v1", "updated": "2016-10-25T07:56:43Z", "published": "2016-10-25T07:56:43Z", "title": "Visual Themes and Sentiment on Social Networks To Aid First Responders\n  During Crisis Events", "summary": "Online Social Networks explode with activity whenever a crisis event takes\nplace. Most content generated as part of this activity is a mixture of text and\nimages, and is particularly useful for first responders to identify popular\ntopics of interest and gauge the pulse and sentiment of citizens. While\nmultiple researchers have used text to identify, analyze and measure themes and\npublic sentiment during such events, little work has explored visual themes\nfloating on networks in the form of images, and the sentiment inspired by them.\nGiven the potential of visual content for influencing users' thoughts and\nemotions, we perform a large scale analysis to compare popular themes and\nsentiment across images and textual content posted on Facebook during the\nterror attacks that took place in Paris in 2015. Using state-of-the-art image\nsummarization techniques, we discovered multiple visual themes which were\npopular in images, but were not identifiable through text. We uncovered\ninstances of misinformation and false flag (conspiracy) theories among popular\nimage themes, which were not prominent in user generated textual content, and\ncan be of particular inter- est to first responders. Our analysis also revealed\nthat while textual content posted after the attacks reflected negative\nsentiment, images inspired positive sentiment. To the best of our knowledge,\nthis is the first large scale study of images posted on social networks during\na crisis event.", "author": [{"name": "Prateek Dewan"}, {"name": "Varun Bharadhwaj"}, {"name": "Aditi Mithal"}, {"name": "Anshuman Suri"}, {"name": "Ponnurangam Kumaraguru"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8+1 pages"}, "link": [{"@href": "http://arxiv.org/abs/1610.07772v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1610.07772v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1702.06016v2", "updated": "2017-06-16T10:14:10Z", "published": "2017-02-20T15:35:27Z", "title": "Public discourse and news consumption on online social media: A\n  quantitative, cross-platform analysis of the Italian Referendum", "summary": "The rising attention to the spreading of fake news and unsubstantiated rumors\non online social media and the pivotal role played by confirmation bias led\nresearchers to investigate different aspects of the phenomenon. Experimental\nevidence showed that confirmatory information gets accepted even if containing\ndeliberately false claims while dissenting information is mainly ignored or\nmight even increase group polarization. It seems reasonable that, to address\nmisinformation problem properly, we have to understand the main determinants\nbehind content consumption and the emergence of narratives on online social\nmedia. In this paper we address such a challenge by focusing on the discussion\naround the Italian Constitutional Referendum by conducting a quantitative,\ncross-platform analysis on both Facebook public pages and Twitter accounts. We\nobserve the spontaneous emergence of well-separated communities on both\nplatforms. Such a segregation is completely spontaneous, since no\ncategorization of contents was performed a priori. By exploring the dynamics\nbehind the discussion, we find that users tend to restrict their attention to a\nspecific set of Facebook pages/Twitter accounts. Finally, taking advantage of\nautomatic topic extraction and sentiment analysis techniques, we are able to\nidentify the most controversial topics inside and across both platforms. We\nmeasure the distance between how a certain topic is presented in the\nposts/tweets and the related emotional response of users. Our results provide\ninteresting insights for the understanding of the evolution of the core\nnarratives behind different echo chambers and for the early detection of\nmassive viral phenomena around false claims.", "author": [{"name": "Michela Del Vicario"}, {"name": "Sabrina Gaito"}, {"name": "Walter Quattrociocchi"}, {"name": "Matteo Zignani"}, {"name": "Fabiana Zollo"}], "link": [{"@href": "http://arxiv.org/abs/1702.06016v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1702.06016v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.00726v2", "updated": "2018-09-07T00:44:22Z", "published": "2017-11-02T15:49:47Z", "title": "A Comprehensive Low and High-level Feature Analysis for Early Rumor\n  Detection on Twitter", "summary": "Recent work have done a good job in modeling rumors and detecting them over\nmicroblog streams. However, the performance of their automatic approaches are\nnot relatively high when looking early in the diffusion. A first intuition is\nthat, at early stage, most of the aggregated rumor features (e.g., propagation\nfeatures) are not mature and distinctive enough. The objective of rumor\ndebunking in microblogs, however, are to detect these misinformation as early\nas possible. In this work, we leverage neural models in learning the hidden\nrepresentations of individual rumor-related tweets at the very beginning of a\nrumor. Our extensive experiments show that the resulting signal improves our\nclassification performance over time, significantly within the first 10 hours.\nTo deepen the understanding of these low and high-level features in\ncontributing to the model performance over time, we conduct an extensive study\non a wide range of high impact rumor features for the 48 hours range. The end\nmodel that engages these features are shown to be competitive, reaches over 90%\naccuracy and out-performs strong baselines in our carefully cured dataset.", "author": {"name": "Tu Ngoc Nguyen"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CIKM 2017 Workshop on Interpretable Data Mining - Bridging the Gap\n  between Shallow and Deep Models (IDM 2017). arXiv admin note: substantial\n  text overlap with arXiv:1709.04402"}, "link": [{"@href": "http://arxiv.org/abs/1711.00726v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.00726v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.09025v2", "updated": "2018-03-02T16:57:43Z", "published": "2017-11-24T15:53:37Z", "title": "Fake News Detection in Social Networks via Crowd Signals", "summary": "Our work considers leveraging crowd signals for detecting fake news and is\nmotivated by tools recently introduced by Facebook that enable users to flag\nfake news. By aggregating users' flags, our goal is to select a small subset of\nnews every day, send them to an expert (e.g., via a third-party fact-checking\norganization), and stop the spread of news identified as fake by an expert. The\nmain objective of our work is to minimize the spread of misinformation by\nstopping the propagation of fake news in the network. It is especially\nchallenging to achieve this objective as it requires detecting fake news with\nhigh-confidence as quickly as possible. We show that in order to leverage\nusers' flags efficiently, it is crucial to learn about users' flagging\naccuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian\ninference for detecting fake news and jointly learns about users' flagging\naccuracy over time. Our algorithm employs posterior sampling to actively trade\noff exploitation (selecting news that maximize the objective value at a given\nepoch) and exploration (selecting news that maximize the value of information\ntowards learning about users' flagging accuracy). We demonstrate the\neffectiveness of our approach via extensive experiments and show the power of\nleveraging community signals for fake news detection.", "author": [{"name": "Sebastian Tschiatschek"}, {"name": "Adish Singla"}, {"name": "Manuel Gomez Rodriguez"}, {"name": "Arpit Merchant"}, {"name": "Andreas Krause"}], "link": [{"@href": "http://arxiv.org/abs/1711.09025v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.09025v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1505.08001v1", "updated": "2015-05-29T11:45:19Z", "published": "2015-05-29T11:45:19Z", "title": "Emotional Dynamics in the Age of Misinformation", "summary": "According to the World Economic Forum, the diffusion of unsubstantiated\nrumors on online social media is one of the main threats for our society.\n  The disintermediated paradigm of content production and consumption on online\nsocial media might foster the formation of homophile communities\n(echo-chambers) around specific worldviews. Such a scenario has been shown to\nbe a vivid environment for the diffusion of false claims, in particular with\nrespect to conspiracy theories. Not rarely, viral phenomena trigger naive (and\nfunny) social responses -- e.g., the recent case of Jade Helm 15 where a simple\nmilitary exercise turned out to be perceived as the beginning of the civil war\nin the US. In this work, we address the emotional dynamics of collective\ndebates around distinct kind of news -- i.e., science and conspiracy news --\nand inside and across their respective polarized communities (science and\nconspiracy news).\n  Our findings show that comments on conspiracy posts tend to be more negative\nthan on science posts. However, the more the engagement of users, the more they\ntend to negative commenting (both on science and conspiracy). Finally, zooming\nin at the interaction among polarized communities, we find a general negative\npattern. As the number of comments increases -- i.e., the discussion becomes\nlonger -- the sentiment of the post is more and more negative.", "author": [{"name": "Fabiana Zollo"}, {"name": "Petra Kralj Novak"}, {"name": "Michela Del Vicario"}, {"name": "Alessandro Bessi"}, {"name": "Igor Mozetic"}, {"name": "Antonio Scala"}, {"name": "Guido Caldarelli"}, {"name": "Walter Quattrociocchi"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0138740"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0138740", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1505.08001v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1505.08001v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PLoS ONE, 10(9): e0138740 (2015)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1512.00770v2", "updated": "2020-02-26T15:11:48Z", "published": "2015-12-02T16:43:40Z", "title": "Bayesian Social Influence in the Online Realm", "summary": "Our opinions, which things we like or dislike, depend on the opinions of\nthose around us. Nowadays, we are influenced by the opinions of online\nstrangers, expressed in comments and ratings on online platforms. Here, we\nperform novel \"academic A/B testing\" experiments with over 2,500 participants\nto measure the extent of that influence. In our experiments, the participants\nwatch and evaluate videos on mirror proxies of YouTube and Vimeo. We control\nthe comments and ratings that are shown underneath each of these videos. Our\nstudy shows that from 5$\\%$ up to 40$\\%$ of subjects adopt the majority opinion\nof strangers expressed in the comments. Using Bayes' theorem, we derive a\nflexible and interpretable family of models of social influence, in which each\nindividual forms posterior opinions stochastically following a logit model. The\nvariants of our mixture model that maximize Akaike information criterion\nrepresent two sub-populations, i.e., non-influenceable and influenceable\nindividuals. The prior opinions of the non-influenceable individuals are\nstrongly correlated with the external opinions and have low standard error,\nwhereas the prior opinions of influenceable individuals have high standard\nerror and become correlated with the external opinions due to social influence.\nOur findings suggest that opinions are random variables updated via Bayes' rule\nwhose standard deviation is correlated with opinion influenceability. Based on\nthese findings, we discuss how to hinder opinion manipulation and\nmisinformation diffusion in the online realm.", "author": [{"name": "Przemyslaw A. Grabowicz"}, {"name": "Francisco Romero-Ferrero"}, {"name": "Theo Lins"}, {"name": "Fabr\u00edcio Benevenuto"}, {"name": "Krishna P. Gummadi"}, {"name": "Gonzalo G. de Polavieja"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages, 22 figures"}, "link": [{"@href": "http://arxiv.org/abs/1512.00770v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1512.00770v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.data-an", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.1.2; I.2.11; J.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1403.6315v2", "updated": "2014-04-27T05:42:30Z", "published": "2014-03-25T11:39:02Z", "title": "Cost Effective Rumor Containment in Social Networks", "summary": "The spread of rumors through social media and online social networks can not\nonly disrupt the daily lives of citizens but also result in loss of life and\nproperty. A rumor spreads when individuals, who are unable decide the\nauthenticity of the information, mistake the rumor as genuine information and\npass it on to their acquaintances. We propose a solution where a set of\nindividuals (based on their degree) in the social network are trained and\nprovided resources to help them distinguish a rumor from genuine information.\nBy formulating an optimization problem we calculate the optimum set of\nindividuals, who must undergo training, and the quality of training that\nminimizes the expected training cost and ensures an upper bound on the size of\nthe rumor outbreak. Our primary contribution is that although the optimization\nproblem turns out to be non convex, we show that the problem is equivalent to\nsolving a set of linear programs. This result also allows us to solve the\nproblem of minimizing the size of rumor outbreak for a given cost budget. The\noptimum solution displays an interesting pattern which can be implemented as a\nheuristic. These results can prove to be very useful for social planners and\nlaw enforcement agencies for preventing dangerous rumors and misinformation\nepidemics.", "author": [{"name": "Bhushan Kotnis"}, {"name": "Joy Kuri"}], "link": [{"@href": "http://arxiv.org/abs/1403.6315v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1403.6315v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1411.3550v1", "updated": "2014-11-13T14:21:00Z", "published": "2014-11-13T14:21:00Z", "title": "Investigating Rumor Propagation with TwitterTrails", "summary": "Social media have become part of modern news reporting, used by journalists\nto spread information and find sources, or as a news source by individuals. The\nquest for prominence and recognition on social media sites like Twitter can\nsometimes eclipse accuracy and lead to the spread of false information. As a\nway to study and react to this trend, we introduce {\\sc TwitterTrails}, an\ninteractive, web-based tool ({\\tt twittertrails.com}) that allows users to\ninvestigate the origin and propagation characteristics of a rumor and its\nrefutation, if any, on Twitter. Visualizations of burst activity, propagation\ntimeline, retweet and co-retweeted networks help its users trace the spread of\na story. Within minutes {\\sc TwitterTrails} will collect relevant tweets and\nautomatically answer several important questions regarding a rumor: its\noriginator, burst characteristics, propagators and main actors according to the\naudience. In addition, it will compute and report the rumor's level of\nvisibility and, as an example of the power of crowdsourcing, the audience's\nskepticism towards it which correlates with the rumor's credibility. We\nenvision {\\sc TwitterTrails} as valuable tool for individual use, but we\nespecially for amateur and professional journalists investigating recent and\nbreaking stories. Further, its expanding collection of investigated rumors can\nbe used to answer questions regarding the amount and success of misinformation\non Twitter.", "author": [{"name": "Samantha Finn"}, {"name": "Panagiotis Takis Metaxas"}, {"name": "Eni Mustafaraj"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 8 figures, under review"}, "link": [{"@href": "http://arxiv.org/abs/1411.3550v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1411.3550v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1811.07039v1", "updated": "2018-11-16T21:37:59Z", "published": "2018-11-16T21:37:59Z", "title": "Combining Fact Extraction and Verification with Neural Semantic Matching\n  Networks", "summary": "The increasing concern with misinformation has stimulated research efforts on\nautomatic fact checking. The recently-released FEVER dataset introduced a\nbenchmark fact-verification task in which a system is asked to verify a claim\nusing evidential sentences from Wikipedia documents. In this paper, we present\na connected system consisting of three homogeneous neural semantic matching\nmodels that conduct document retrieval, sentence selection, and claim\nverification jointly for fact extraction and verification. For evidence\nretrieval (document retrieval and sentence selection), unlike traditional\nvector space IR models in which queries and sources are matched in some\npre-designed term vector space, we develop neural models to perform deep\nsemantic matching from raw textual input, assuming no intermediate term\nrepresentation and no access to structured external knowledge bases. We also\nshow that Pageview frequency can also help improve the performance of evidence\nretrieval results, that later can be matched by using our neural semantic\nmatching network. For claim verification, unlike previous approaches that\nsimply feed upstream retrieved evidence and the claim to a natural language\ninference (NLI) model, we further enhance the NLI model by providing it with\ninternal semantic relatedness scores (hence integrating it with the evidence\nretrieval modules) and ontological WordNet features. Experiments on the FEVER\ndataset indicate that (1) our neural semantic matching method outperforms\npopular TF-IDF and encoder models, by significant margins on all evidence\nretrieval metrics, (2) the additional relatedness score and WordNet features\nimprove the NLI model via better semantic awareness, and (3) by formalizing all\nthree subtasks as a similar semantic matching problem and improving on all\nthree stages, the complete model is able to achieve the state-of-the-art\nresults on the FEVER test set.", "author": [{"name": "Yixin Nie"}, {"name": "Haonan Chen"}, {"name": "Mohit Bansal"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AAAI 2019"}, "link": [{"@href": "http://arxiv.org/abs/1811.07039v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.07039v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.00655v2", "updated": "2020-06-01T15:32:26Z", "published": "2019-10-01T20:27:51Z", "title": "Descendant distributions for the impact of mutant contagion on networks", "summary": "Contagion, broadly construed, refers to anything that can spread infectiously\nfrom peer to peer. Examples include communicable diseases, rumors,\nmisinformation, ideas, innovations, bank failures, and electrical blackouts.\nSometimes, as in the 1918 Spanish flu epidemic, a contagion mutates at some\npoint as it spreads through a network. Here, using a simple\nsusceptible-infected (SI) model of contagion, we explore the downstream impact\nof a single mutation event. Assuming that this mutation occurs at a random node\nin the contact network, we calculate the distribution of the number of\n\"descendants,\" $d$, downstream from the initial \"Patient Zero\" mutant. We find\nthat the tail of the distribution decays as $d^{-2}$ for complete graphs,\nrandom graphs, small-world networks, networks with block-like structure, and\nother infinite-dimensional networks. This prediction agrees with the observed\nstatistics of memes propagating and mutating on Facebook, and is expected to\nhold for other effectively infinite-dimensional networks, such as the global\nhuman contact network. In a wider context, our approach suggests a possible\nstarting point for a mesoscopic theory of contagion. Such a theory would focus\non the paths traced by a spreading contagion, thereby furnishing an\nintermediate level of description between that of individual nodes and the\ntotal infected population. We anticipate that contagion pathways will hold\nvaluable lessons, given their role as the conduits through which single\nmutations, innovations, or failures can sweep through a network as a whole.", "author": [{"name": "Jonas S. Juul"}, {"name": "Steven H. Strogatz"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevResearch.2.033005"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevResearch.2.033005", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1910.00655v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.00655v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "24 pages, 6 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys. Rev. Research 2, 033005 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.01160v2", "updated": "2019-11-05T20:45:25Z", "published": "2019-10-02T18:47:17Z", "title": "Identifying Nuances in Fake News vs. Satire: Using Semantic and\n  Linguistic Cues", "summary": "The blurry line between nefarious fake news and protected-speech satire has\nbeen a notorious struggle for social media platforms. Further to the efforts of\nreducing exposure to misinformation on social media, purveyors of fake news\nhave begun to masquerade as satire sites to avoid being demoted. In this work,\nwe address the challenge of automatically classifying fake news versus satire.\nPrevious work have studied whether fake news and satire can be distinguished\nbased on language differences. Contrary to fake news, satire stories are\nusually humorous and carry some political or social message. We hypothesize\nthat these nuances could be identified using semantic and linguistic cues.\nConsequently, we train a machine learning method using semantic representation,\nwith a state-of-the-art contextual language model, and with linguistic features\nbased on textual coherence metrics. Empirical evaluation attests to the merits\nof our approach compared to the language-based baseline and sheds light on the\nnuances between fake news and satire. As avenues for future work, we consider\nstudying additional linguistic features related to the humor aspect, and\nenriching the data with current news events, to help identify a political or\nsocial message.", "author": [{"name": "Or Levi"}, {"name": "Pedram Hosseini"}, {"name": "Mona Diab"}, {"name": "David A. Broniatowski"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.18653/v1/D19-5004"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.18653/v1/D19-5004", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1910.01160v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.01160v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the 2nd Workshop on NLP for Internet Freedom (NLP4IF):\n  Censorship, Disinformation, and Propaganda. Co-located with EMNLP-IJCNLP 2019"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.07130v5", "updated": "2020-09-02T02:01:28Z", "published": "2019-10-16T02:05:26Z", "title": "SCG: Spotting Coordinated Groups in Social Media", "summary": "Recent events have led to a burgeoning awareness on the misuse of social\nmedia sites to affect political events, sway public opinion, and confuse the\nvoters. Such serious, hostile mass manipulation has motivated a large body of\nworks on bots/troll detection and fake news detection, which mostly focus on\nclassifying at the user level based on the content generated by the users. In\nthis study, we jointly analyze the connections among the users, as well as the\ncontent generated by them to Spot Coordinated Groups (SCG), sets of users that\nare likely to be organized towards impacting the general discourse. Given their\ntiny size (relative to the whole data), detecting these groups is\ncomputationally hard. Our proposed method detects these tiny-clusters\neffectively and efficiently. We deploy our SCG method to summarize and explain\nthe coordinated groups on Twitter around the 2019 Canadian Federal Elections,\nby analyzing over 60 thousand user accounts with 3.4 million followership\nconnections, and 1.3 million unique hashtags in the content of their tweets.\nThe users in the detected coordinated groups are over 4x more likely to get\nsuspended, whereas the hashtags which characterize their creed are linked to\nmisinformation campaigns.", "author": [{"name": "Junhao Wang"}, {"name": "Sacha Levy"}, {"name": "Ren Wang"}, {"name": "Aayushi Kulshrestha"}, {"name": "Reihaneh Rabbany"}], "link": [{"@href": "http://arxiv.org/abs/1910.07130v5", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.07130v5", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1504.05163v1", "updated": "2015-04-20T19:19:10Z", "published": "2015-04-20T19:19:10Z", "title": "Trend of Narratives in the Age of Misinformation", "summary": "Social media enabled a direct path from producer to consumer of contents\nchanging the way users get informed, debate, and shape their worldviews. Such a\n{\\em disintermediation} weakened consensus on social relevant issues in favor\nof rumors, mistrust, and fomented conspiracy thinking -- e.g., chem-trails\ninducing global warming, the link between vaccines and autism, or the New World\nOrder conspiracy.\n  In this work, we study through a thorough quantitative analysis how different\nconspiracy topics are consumed in the Italian Facebook. By means of a\nsemi-automatic topic extraction strategy, we show that the most discussed\ncontents semantically refer to four specific categories: {\\em environment},\n{\\em diet}, {\\em health}, and {\\em geopolitics}. We find similar patterns by\ncomparing users activity (likes and comments) on posts belonging to different\nsemantic categories. However, if we focus on the lifetime -- i.e., the distance\nin time between the first and the last comment for each user -- we notice a\nremarkable difference within narratives -- e.g., users polarized on geopolitics\nare more persistent in commenting, whereas the less persistent are those\nfocused on diet related topics. Finally, we model users mobility across various\ntopics finding that the more a user is active, the more he is likely to join\nall topics. Once inside a conspiracy narrative users tend to embrace the\noverall corpus.", "author": [{"name": "Alessandro Bessi"}, {"name": "Fabiana Zollo"}, {"name": "Michela Del Vicario"}, {"name": "Antonio Scala"}, {"name": "Guido Caldarelli"}, {"name": "Walter Quattrociocchi"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0134641"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0134641", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1504.05163v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1504.05163v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1611.06314v1", "updated": "2016-11-19T06:22:50Z", "published": "2016-11-19T06:22:50Z", "title": "Determining the Veracity of Rumours on Twitter", "summary": "While social networks can provide an ideal platform for up-to-date\ninformation from individuals across the world, it has also proved to be a place\nwhere rumours fester and accidental or deliberate misinformation often emerges.\nIn this article, we aim to support the task of making sense from social media\ndata, and specifically, seek to build an autonomous message-classifier that\nfilters relevant and trustworthy information from Twitter. For our work, we\ncollected about 100 million public tweets, including users' past tweets, from\nwhich we identified 72 rumours (41 true, 31 false). We considered over 80\ntrustworthiness measures including the authors' profile and past behaviour, the\nsocial network connections (graphs), and the content of tweets themselves. We\nran modern machine-learning classifiers over those measures to produce\ntrustworthiness scores at various time windows from the outbreak of the rumour.\nSuch time-windows were key as they allowed useful insight into the progression\nof the rumours. From our findings, we identified that our model was\nsignificantly more accurate than similar studies in the literature. We also\nidentified critical attributes of the data that give rise to the\ntrustworthiness scores assigned. Finally we developed a software demonstration\nthat provides a visual user interface to allow the user to examine the\nanalysis.", "author": [{"name": "Georgios Giasemidis"}, {"name": "Colin Singleton"}, {"name": "Ioannis Agrafiotis"}, {"name": "Jason R. C. Nurse"}, {"name": "Alan Pilgrim"}, {"name": "Chris Willis"}, {"name": "Danica Vukadinovic Greetham"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-319-47880-7_12"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-319-47880-7_12", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1611.06314v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1611.06314v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "21 pages, 6 figures, 2 tables"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SocInfo 2016, Part I, LNCS 10046, pp. 185-205, 2016"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1701.02694v4", "updated": "2019-01-10T18:03:21Z", "published": "2017-01-10T17:16:46Z", "title": "Limited individual attention and online virality of low-quality\n  information", "summary": "Social media are massive marketplaces where ideas and news compete for our\nattention. Previous studies have shown that quality is not a necessary\ncondition for online virality and that knowledge about peer choices can distort\nthe relationship between quality and popularity. However, these results do not\nexplain the viral spread of low-quality information, such as the digital\nmisinformation that threatens our democracy. We investigate quality\ndiscrimination in a stylized model of online social network, where individual\nagents prefer quality information, but have behavioral limitations in managing\na heavy flow of information. We measure the relationship between the quality of\nan idea and its likelihood to become prevalent at the system level. We find\nthat both information overload and limited attention contribute to a\ndegradation in the market's discriminative power. A good tradeoff between\ndiscriminative power and diversity of information is possible according to the\nmodel. However, calibration with empirical data characterizing information load\nand finite attention in real social media reveals a weak correlation between\nquality and popularity of information. In these realistic conditions, the model\npredicts that high-quality information has little advantage over low-quality\ninformation.", "author": [{"name": "Xiaoyan Qiu"}, {"name": "Diego F. M. Oliveira"}, {"name": "Alireza Sahami Shirazi"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The original paper was retracted (see\n  http://doi.org/10.1038/s41562-017-0132). This is a corrected version of the\n  preprint"}, "link": [{"@href": "http://arxiv.org/abs/1701.02694v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1701.02694v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1704.07506v1", "updated": "2017-04-25T01:20:40Z", "published": "2017-04-25T01:20:40Z", "title": "Some Like it Hoax: Automated Fake News Detection in Social Networks", "summary": "In recent years, the reliability of information on the Internet has emerged\nas a crucial issue of modern society. Social network sites (SNSs) have\nrevolutionized the way in which information is spread by allowing users to\nfreely share content. As a consequence, SNSs are also increasingly used as\nvectors for the diffusion of misinformation and hoaxes. The amount of\ndisseminated information and the rapidity of its diffusion make it practically\nimpossible to assess reliability in a timely manner, highlighting the need for\nautomatic hoax detection systems.\n  As a contribution towards this objective, we show that Facebook posts can be\nclassified with high accuracy as hoaxes or non-hoaxes on the basis of the users\nwho \"liked\" them. We present two classification techniques, one based on\nlogistic regression, the other on a novel adaptation of boolean crowdsourcing\nalgorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users,\nwe obtain classification accuracies exceeding 99% even when the training set\ncontains less than 1% of the posts. We further show that our techniques are\nrobust: they work even when we restrict our attention to the users who like\nboth hoax and non-hoax posts. These results suggest that mapping the diffusion\npattern of information can be a useful component of automatic hoax detection\nsystems.", "author": [{"name": "Eugenio Tacchini"}, {"name": "Gabriele Ballarin"}, {"name": "Marco L. Della Vedova"}, {"name": "Stefano Moret"}, {"name": "Luca de Alfaro"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the Second Workshop on Data Science for Social Good\n  (SoGood), Skopje, Macedonia, 2017. CEUR Workshop Proceedings Volume 1960,\n  2017"}, "link": [{"@href": "http://arxiv.org/abs/1704.07506v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1704.07506v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1708.07239v1", "updated": "2017-08-24T01:07:21Z", "published": "2017-08-24T01:07:21Z", "title": "Finding Streams in Knowledge Graphs to Support Fact Checking", "summary": "The volume and velocity of information that gets generated online limits\ncurrent journalistic practices to fact-check claims at the same rate.\nComputational approaches for fact checking may be the key to help mitigate the\nrisks of massive misinformation spread. Such approaches can be designed to not\nonly be scalable and effective at assessing veracity of dubious claims, but\nalso to boost a human fact checker's productivity by surfacing relevant facts\nand patterns to aid their analysis. To this end, we present a novel,\nunsupervised network-flow based approach to determine the truthfulness of a\nstatement of fact expressed in the form of a (subject, predicate, object)\ntriple. We view a knowledge graph of background information about real-world\nentities as a flow network, and knowledge as a fluid, abstract commodity. We\nshow that computational fact checking of such a triple then amounts to finding\na \"knowledge stream\" that emanates from the subject node and flows toward the\nobject node through paths connecting them. Evaluation on a range of real-world\nand hand-crafted datasets of facts related to entertainment, business, sports,\ngeography and more reveals that this network-flow model can be very effective\nin discerning true statements from false ones, outperforming existing\nalgorithms on many test cases. Moreover, the model is expressive in its ability\nto automatically discover several useful path patterns and surface relevant\nfacts that may help a human fact checker corroborate or refute a claim.", "author": [{"name": "Prashant Shiralkar"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}, {"name": "Giovanni Luca Ciampaglia"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Extended version of the paper in proceedings of ICDM 2017"}, "link": [{"@href": "http://arxiv.org/abs/1708.07239v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1708.07239v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1708.08151v2", "updated": "2017-09-08T02:37:16Z", "published": "2017-08-27T23:00:27Z", "title": "Automated Crowdturfing Attacks and Defenses in Online Review Systems", "summary": "Malicious crowdsourcing forums are gaining traction as sources of spreading\nmisinformation online, but are limited by the costs of hiring and managing\nhuman workers. In this paper, we identify a new class of attacks that leverage\ndeep learning language models (Recurrent Neural Networks or RNNs) to automate\nthe generation of fake online reviews for products and services. Not only are\nthese attacks cheap and therefore more scalable, but they can control rate of\ncontent output to eliminate the signature burstiness that makes crowdsourced\ncampaigns easy to detect.\n  Using Yelp reviews as an example platform, we show how a two phased review\ngeneration and customization attack can produce reviews that are\nindistinguishable by state-of-the-art statistical detectors. We conduct a\nsurvey-based user study to show these reviews not only evade human detection,\nbut also score high on \"usefulness\" metrics by users. Finally, we develop novel\nautomated defenses against these attacks, by leveraging the lossy\ntransformation introduced by the RNN training and generation cycle. We consider\ncountermeasures against our mechanisms, show that they produce unattractive\ncost-benefit tradeoffs for attackers, and that they can be further curtailed by\nsimple constraints imposed by online service providers.", "author": [{"name": "Yuanshun Yao"}, {"name": "Bimal Viswanath"}, {"name": "Jenna Cryan"}, {"name": "Haitao Zheng"}, {"name": "Ben Y. Zhao"}], "link": [{"@href": "http://arxiv.org/abs/1708.08151v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1708.08151v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1712.06414v1", "updated": "2017-11-29T21:40:29Z", "published": "2017-11-29T21:40:29Z", "title": "The Wisdom of Polarized Crowds", "summary": "As political polarization in the United States continues to rise, the\nquestion of whether polarized individuals can fruitfully cooperate becomes\npressing. Although diversity of individual perspectives typically leads to\nsuperior team performance on complex tasks, strong political perspectives have\nbeen associated with conflict, misinformation and a reluctance to engage with\npeople and perspectives beyond one's echo chamber. It is unclear whether\nself-selected teams of politically diverse individuals will create higher or\nlower quality outcomes. In this paper, we explore the effect of team political\ncomposition on performance through analysis of millions of edits to Wikipedia's\nPolitical, Social Issues, and Science articles. We measure editors' political\nalignments by their contributions to conservative versus liberal articles. A\nsurvey of editors validates that those who primarily edit liberal articles\nidentify more strongly with the Democratic party and those who edit\nconservative ones with the Republican party. Our analysis then reveals that\npolarized teams---those consisting of a balanced set of politically diverse\neditors---create articles of higher quality than politically homogeneous teams.\nThe effect appears most strongly in Wikipedia's Political articles, but is also\nobserved in Social Issues and even Science articles. Analysis of article \"talk\npages\" reveals that politically polarized teams engage in longer, more\nconstructive, competitive, and substantively focused but linguistically diverse\ndebates than political moderates. More intense use of Wikipedia policies by\npolitically diverse teams suggests institutional design principles to help\nunleash the power of politically polarized teams.", "author": [{"name": "Feng Shi"}, {"name": "Misha Teplitskiy"}, {"name": "Eamon Duede"}, {"name": "James Evans"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1038/s41562-019-0541-6"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1038/s41562-019-0541-6", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1712.06414v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1712.06414v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Nature Human Behavior. 2019"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1803.10124v4", "updated": "2018-08-16T13:21:58Z", "published": "2018-03-27T15:12:01Z", "title": "Sampling the News Producers: A Large News and Feature Data Set for the\n  Study of the Complex Media Landscape", "summary": "The complexity and diversity of today's media landscape provides many\nchallenges for researchers studying news producers. These producers use many\ndifferent strategies to get their message believed by readers through the\nwriting styles they employ, by repetition across different media sources with\nor without attribution, as well as other mechanisms that are yet to be studied\ndeeply. To better facilitate systematic studies in this area, we present a\nlarge political news data set, containing over 136K news articles, from 92 news\nsources, collected over 7 months of 2017. These news sources are carefully\nchosen to include well-established and mainstream sources, maliciously fake\nsources, satire sources, and hyper-partisan political blogs. In addition to\neach article we compute 130 content-based and social media engagement features\ndrawn from a wide range of literature on political bias, persuasion, and\nmisinformation. With the release of the data set, we also provide the source\ncode for feature computation. In this paper, we discuss the first release of\nthe data set and demonstrate 4 use cases of the data and features: news\ncharacterization, engagement characterization, news attribution and content\ncopying, and discovering news narratives.", "author": [{"name": "Benjamin D. Horne"}, {"name": "William Dron"}, {"name": "Sara Khedr"}, {"name": "Sibel Adali"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at ICWSM 2018. Dataset:\n  https://github.com/BenjaminDHorne/NELA2017-Dataset-v1 Feature Code:\n  https://github.com/BenjaminDHorne/Language-Features-for-News"}, "link": [{"@href": "http://arxiv.org/abs/1803.10124v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1803.10124v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1804.09088v1", "updated": "2018-04-24T15:13:51Z", "published": "2018-04-24T15:13:51Z", "title": "Semi-supervised Content-based Detection of Misinformation via Tensor\n  Embeddings", "summary": "Fake news may be intentionally created to promote economic, political and\nsocial interests, and can lead to negative impacts on humans beliefs and\ndecisions. Hence, detection of fake news is an emerging problem that has become\nextremely prevalent during the last few years. Most existing works on this\ntopic focus on manual feature extraction and supervised classification models\nleveraging a large number of labeled (fake or real) articles. In contrast, we\nfocus on content-based detection of fake news articles, while assuming that we\nhave a small amount of labels, made available by manual fact-checkers or\nautomated sources. We argue this is a more realistic setting in the presence of\nmassive amounts of content, most of which cannot be easily factchecked. To that\nend, we represent collections of news articles as multi-dimensional tensors,\nleverage tensor decomposition to derive concise article embeddings that capture\nspatial/contextual information about each news article, and use those\nembeddings to create an article-by-article graph on which we propagate limited\nlabels. Results on three real-world datasets show that our method performs on\npar or better than existing models that are fully supervised, in that we\nachieve better detection accuracy using fewer labels. In particular, our\nproposed method achieves 75.43% of accuracy using only 30% of labels of a\npublic dataset while an SVM-based classifier achieved 67.43%. Furthermore, our\nmethod achieves 70.92% of accuracy in a large dataset using only 2% of labels.", "author": [{"name": "Gisel Bastidas Guacho"}, {"name": "Sara Abdali"}, {"name": "Neil Shah"}, {"name": "Evangelos E. Papalexakis"}], "link": [{"@href": "http://arxiv.org/abs/1804.09088v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.09088v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1805.08030v1", "updated": "2018-05-21T13:01:56Z", "published": "2018-05-21T13:01:56Z", "title": "Polarization Rank: A Study on European News Consumption on Facebook", "summary": "The advent of WWW changed the way we can produce and access information.\nRecent studies showed that users tend to select information that is consistent\nwith their system of beliefs, forming polarized groups of like-minded people\naround shared narratives where dissenting information is ignored. In this\nenvironment, users cooperate to frame and reinforce their shared narrative\nmaking any attempt at debunking inefficient. Such a configuration occurs even\nin the consumption of news online, and considering that 63% of users access\nnews directly form social media, one hypothesis is that more polarization\nallows for further spreading of misinformation. Along this path, we focus on\nthe polarization of users around news outlets on Facebook in different European\ncountries (Italy, France, Spain and Germany). First, we compare the pages'\nposting behavior and the users' interacting patterns across countries and\nobserve different posting, liking and commenting rates. Second, we explore the\ntendency of users to interact with different pages (i.e., selective exposure)\nand the emergence of polarized communities generated around specific pages.\nThen, we introduce a new metric -- i.e., polarization rank -- to measure\npolarization of communities for each country. We find that Italy is the most\npolarized country, followed by France, Germany and lastly Spain. Finally, we\npresent a variation of the Bounded Confidence Model to simulate the emergence\nof these communities by considering the users' engagement and trust on the\nnews. Our findings suggest that trust in information broadcaster plays a\npivotal role against polarization of users online.", "author": [{"name": "Ana Luc\u00eda Schmidt"}, {"name": "Fabiana Zollo"}, {"name": "Antonio Scala"}, {"name": "Walter Quattrociocchi"}], "link": [{"@href": "http://arxiv.org/abs/1805.08030v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1805.08030v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1808.04671v2", "updated": "2019-09-10T09:42:39Z", "published": "2018-08-14T13:15:51Z", "title": "Sea of Lights: Practical Device-to-Device Security Bootstrapping in the\n  Dark", "summary": "Practical solutions to bootstrap security in today's information and\ncommunication systems critically depend on centralized services for\nauthentication as well as key and trust management. This is particularly true\nfor mobile users. Identity providers such as Google or Facebook have active\nuser bases of two billion each, and the subscriber number of mobile operators\nexceeds five billion unique users as of early 2018. If these centralized\nservices go completely `dark' due to natural or man made disasters, large scale\nblackouts, or country-wide censorship, the users are left without practical\nsolutions to bootstrap security on their mobile devices. Existing distributed\nsolutions, for instance, the so-called web-of-trust are not sufficiently\nlightweight. Furthermore, they support neither cross-application on mobile\ndevices nor strong protection of key material using hardware security modules.\nWe propose Sea of Lights(SoL), a practical lightweight scheme for bootstrapping\ndevice-to-device security wirelessly, thus, enabling secure distributed\nself-organized networks. It is tailored to operate `in the dark' and provides\nstrong protection of key material as well as an intuitive means to build a\nlightweight web-of-trust. SoL is particularly well suited for local or urban\noperation in scenarios such as the coordination of emergency response, where it\nhelps containing/limiting the spreading of misinformation. As a proof of\nconcept, we implement SoL in the Android platform and hence test its\nfeasibility on real mobile devices. We further evaluate its key performance\naspects using simulation.", "author": [{"name": "Flor \u00c1lvarez"}, {"name": "Max Kolhagen"}, {"name": "Matthias Hollick"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/LCN.2018.8638102"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/LCN.2018.8638102", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1808.04671v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.04671v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.NI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.NI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1812.02655v1", "updated": "2018-12-06T16:45:00Z", "published": "2018-12-06T16:45:00Z", "title": "Feature Analysis for Assessing the Quality of Wikipedia Articles through\n  Supervised Classification", "summary": "Nowadays, thanks to Web 2.0 technologies, people have the possibility to\ngenerate and spread contents on different social media in a very easy way. In\nthis context, the evaluation of the quality of the information that is\navailable online is becoming more and more a crucial issue. In fact, a constant\nflow of contents is generated every day by often unknown sources, which are not\ncertified by traditional authoritative entities. This requires the development\nof appropriate methodologies that can evaluate in a systematic way these\ncontents, based on `objective' aspects connected with them. This would help\nindividuals, who nowadays tend to increasingly form their opinions based on\nwhat they read online and on social media, to come into contact with\ninformation that is actually useful and verified. Wikipedia is nowadays one of\nthe biggest online resources on which users rely as a source of information.\nThe amount of collaboratively generated content that is sent to the online\nencyclopedia every day can let to the possible creation of low-quality articles\n(and, consequently, misinformation) if not properly monitored and revised. For\nthis reason, in this paper, the problem of automatically assessing the quality\nof Wikipedia articles is considered. In particular, the focus is on the\nanalysis of hand-crafted features that can be employed by supervised machine\nlearning techniques to perform the classification of Wikipedia articles on\nqualitative bases. With respect to prior literature, a wider set of\ncharacteristics connected to Wikipedia articles are taken into account and\nillustrated in detail. Evaluations are performed by considering a labeled\ndataset provided in a prior work, and different supervised machine learning\nalgorithms, which produced encouraging results with respect to the considered\nfeatures.", "author": [{"name": "Elias Bassani"}, {"name": "Marco Viviani"}], "link": [{"@href": "http://arxiv.org/abs/1812.02655v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.02655v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1812.04478v4", "updated": "2020-03-17T13:02:14Z", "published": "2018-12-11T15:45:10Z", "title": "Socratrees: Exploring the Design of Argument Technology for Layman Users", "summary": "Terms like 'misinformation', 'fake news', and 'echo chambers' permeate\ncurrent discussions on the state of the Internet. We believe a lack of\ntechnological support to evaluate, contest, and reason about information\nonline---as opposed to merely disseminating it---lies at the root of these\nproblems. Several argument technologies support such functionality, but have\nseen limited use outside of niche communities. Most research systems\noveremphasize argument analysis and structure, standing in stark contrast with\nthe informal dialectical nature of everyday argumentation. Conversely,\nnon-academic systems overlook important implications for design which can be\nderived from theory. In this paper, we present the design of a system aiming to\nstrike a balance between structured argumentation and ease of use. Socratrees\nis a website for collaborative argumentative discussion targeting layman users,\nbut includes sophisticated community guidelines and novel features inspired by\ninformal logic. During an exploratory study, we evaluate the usefulness of our\nimposed structure on argumentation and investigate how users perceive it.\nContributing to arguments remains a complex task, but most users learned to do\nso effectively with minimal guidance and all recognized that the structure of\nSocratrees may improve online discussion and results in a clearer overview of\narguments.", "author": {"name": "Steven Jeuris"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Rejected several times, primarily on the basis of needing a larger\n  study. While trying to obtain funding for this (this project has received no\n  funding so far), leaving this out here for now"}, "link": [{"@href": "http://arxiv.org/abs/1812.04478v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.04478v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.5.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1812.06156v1", "updated": "2018-12-14T20:38:25Z", "published": "2018-12-14T20:38:25Z", "title": "Trollslayer: Crowdsourcing and Characterization of Abusive Birds in\n  Twitter", "summary": "As of today, abuse is a pressing issue to participants and administrators of\nOnline Social Networks (OSN). Abuse in Twitter can spawn from arguments\ngenerated for influencing outcomes of a political election, the use of bots to\nautomatically spread misinformation, and generally speaking, activities that\ndeny, disrupt, degrade or deceive other participants and, or the network. Given\nthe difficulty in finding and accessing a large enough sample of abuse ground\ntruth from the Twitter platform, we built and deployed a custom crawler that we\nuse to judiciously collect a new dataset from the Twitter platform with the aim\nof characterizing the nature of abusive users, a.k.a abusive birds, in the\nwild. We provide a comprehensive set of features based on users' attributes, as\nwell as social-graph metadata. The former includes metadata about the account\nitself, while the latter is computed from the social graph among the sender and\nthe receiver of each message. Attribute-based features are useful to\ncharacterize user's accounts in OSN, while graph-based features can reveal the\ndynamics of information dissemination across the network. In particular, we\nderive the Jaccard index as a key feature to reveal the benign or malicious\nnature of directed messages in Twitter. To the best of our knowledge, we are\nthe first to propose such a similarity metric to characterize abuse in Twitter.", "author": [{"name": "Alvaro Garcia-Recuero"}, {"name": "Aneta Morawin"}, {"name": "Gareth Tyson"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/SNAMS.2018.8554898"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/SNAMS.2018.8554898", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1812.06156v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.06156v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SNAMS 2018"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1901.01911v1", "updated": "2019-01-07T16:38:16Z", "published": "2019-01-07T16:38:16Z", "title": "Stance Classification for Rumour Analysis in Twitter: Exploiting\n  Affective Information and Conversation Structure", "summary": "Analysing how people react to rumours associated with news in social media is\nan important task to prevent the spreading of misinformation, which is nowadays\nwidely recognized as a dangerous tendency. In social media conversations, users\nshow different stances and attitudes towards rumourous stories. Some users take\na definite stance, supporting or denying the rumour at issue, while others just\ncomment it, or ask for additional evidence related to the veracity of the\nrumour. On this line, a new shared task has been proposed at SemEval-2017 (Task\n8, SubTask A), which is focused on rumour stance classification in English\ntweets. The goal is predicting user stance towards emerging rumours in Twitter,\nin terms of supporting, denying, querying, or commenting the original rumour,\nlooking at the conversation threads originated by the rumour. This paper\ndescribes a new approach to this task, where the use of conversation-based and\naffective-based features, covering different facets of affect, has been\nexplored. Our classification model outperforms the best-performing systems for\nstance classification at SemEval-2017 Task 8, showing the effectiveness of the\nfeature set proposed.", "author": [{"name": "Endang Wahyu Pamungkas"}, {"name": "Valerio Basile"}, {"name": "Viviana Patti"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear in Proceedings of the 2nd International Workshop on Rumours\n  and Deception in Social Media (RDSM), co-located with CIKM 2018, Turin,\n  Italy, October 2018"}, "link": [{"@href": "http://arxiv.org/abs/1901.01911v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.01911v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1901.02156v1", "updated": "2019-01-08T05:11:17Z", "published": "2019-01-08T05:11:17Z", "title": "Influence Minimization Under Budget and Matroid Constraints: Extended\n  Version", "summary": "Recently, online social networks have become major battlegrounds for\npolitical campaigns, viral marketing, and the dissemination of news. As a\nconsequence, ''bad actors'' are increasingly exploiting these platforms,\nbecoming a key challenge for their administrators, businesses and the society\nin general. The spread of fake news is a classical example of the abuse of\nsocial networks by these actors. While some have advocated for stricter\npolicies to control the spread of misinformation in social networks, this often\nhappens in detriment of their democratic and organic structure. In this paper\nwe study how to limit the influence of a target set of users in a network via\nthe removal of a few edges. The idea is to control the diffusion processes\nwhile minimizing the amount of disturbance in the network structure.\n  We formulate the influence limitation problem in a data-driven fashion, by\ntaking into account past propagation traces. Moreover, we consider two types of\nconstraints over the set of edge removals, a budget constraint and also a, more\ngeneral, set of matroid constraints. These problems lead to interesting\nchallenges in terms of algorithm design. For instance, we are able to show that\ninfluence limitation is APX-hard and propose deterministic and probabilistic\napproximation algorithms for the budgeted and matroid version of the problem,\nrespectively. Our experiments show that the proposed solutions outperform the\nbaselines by up to 40%.", "author": [{"name": "Sourav Medya"}, {"name": "Arlei Silva"}, {"name": "Ambuj Singh"}], "link": [{"@href": "http://arxiv.org/abs/1901.02156v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.02156v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1901.03688v2", "updated": "2019-07-17T17:38:29Z", "published": "2019-01-11T18:49:28Z", "title": "Quantifying echo chamber effects in information spreading over political\n  communication networks", "summary": "Echo chambers in online social networks, in which users prefer to interact\nonly with ideologically-aligned peers, are believed to facilitate\nmisinformation spreading and contribute to radicalize political discourse. In\nthis paper, we gauge the effects of echo chambers in information spreading\nphenomena over political communication networks. Mining 12 million Twitter\nmessages, we reconstruct a network in which users interchange opinions related\nto the impeachment of the former Brazilian President Dilma Rousseff. We define\na continuous {political position} parameter, independent of the network's\nstructure, that allows to quantify the presence of echo chambers in the\nstrongly connected component of the network, reflected in two well-separated\ncommunities of similar sizes with opposite views of the impeachment process. By\nmeans of simple spreading models, we show that the capability of users in\npropagating the content they produce, measured by the associated spreadability,\nstrongly depends on their attitude. Users expressing pro-impeachment sentiments\nare capable to transmit information, on average, to a larger audience than\nusers expressing anti-impeachment sentiments. Furthermore, the users'\nspreadability is correlated to the diversity, in terms of political position,\nof the audience reached. Our method can be exploited to identify the presence\nof echo chambers and their effects across different contexts and shed light\nupon the mechanisms allowing to break echo chambers.", "author": [{"name": "Wesley Cota"}, {"name": "Silvio C. Ferreira"}, {"name": "Romualdo Pastor-Satorras"}, {"name": "Michele Starnini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1140/epjds/s13688-019-0213-9"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1140/epjds/s13688-019-0213-9", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1901.03688v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.03688v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 4 figures. Supplementary Information available as ancillary\n  file"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EPJ Data Sci. 8, 35 (2019)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1902.09197v2", "updated": "2019-06-07T23:36:43Z", "published": "2019-02-25T11:20:23Z", "title": "Message Distortion in Information Cascades", "summary": "Information diffusion is usually modeled as a process in which immutable\npieces of information propagate over a network. In reality, however, messages\nare not immutable, but may be morphed with every step, potentially entailing\nlarge cumulative distortions. This process may lead to misinformation even in\nthe absence of malevolent actors, and understanding it is crucial for modeling\nand improving online information systems. Here, we perform a controlled,\ncrowdsourced experiment in which we simulate the propagation of information\nfrom medical research papers. Starting from the original abstracts, crowd\nworkers iteratively shorten previously produced summaries to increasingly\nsmaller lengths. We also collect control summaries where the original abstract\nis compressed directly to the final target length. Comparing cascades to\ncontrols allows us to separate the effect of the length constraint from that of\naccumulated distortion. Via careful manual coding, we annotate lexical and\nsemantic units in the medical abstracts and track them along cascades. We find\nthat iterative summarization has a negative impact due to the accumulation of\nerror, but that high-quality intermediate summaries result in less distorted\nmessages than in the control case. Different types of information behave\ndifferently; in particular, the conclusion of a medical abstract (i.e., its key\nmessage) is distorted most. Finally, we compare abstractive with extractive\nsummaries, finding that the latter are less prone to semantic distortion.\nOverall, this work is a first step in studying information cascades without the\nassumption that disseminated content is immutable, with implications on our\nunderstanding of the role of word-of-mouth effects on the misreporting of\nscience.", "author": [{"name": "Manoel Horta Ribeiro"}, {"name": "Kristina Gligori\u0107"}, {"name": "Robert West"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3308558.3313531"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3308558.3313531", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1902.09197v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.09197v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Presented at TheWebConf 2019"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1903.01693v1", "updated": "2019-03-05T06:25:05Z", "published": "2019-03-05T06:25:05Z", "title": "Less is More: Semi-Supervised Causal Inference for Detecting Pathogenic\n  Users in Social Media", "summary": "Recent years have witnessed a surge of manipulation of public opinion and\npolitical events by malicious social media actors. These users are referred to\nas \"Pathogenic Social Media (PSM)\" accounts. PSMs are key users in spreading\nmisinformation in social media to viral proportions. These accounts can be\neither controlled by real users or automated bots. Identification of PSMs is\nthus of utmost importance for social media authorities. The burden usually\nfalls to automatic approaches that can identify these accounts and protect\nsocial media reputation. However, lack of sufficient labeled examples for\ndevising and training sophisticated approaches to combat these accounts is\nstill one of the foremost challenges facing social media firms. In contrast,\nunlabeled data is abundant and cheap to obtain thanks to massive user-generated\ndata. In this paper, we propose a semi-supervised causal inference PSM\ndetection framework, SemiPsm, to compensate for the lack of labeled data. In\nparticular, the proposed method leverages unlabeled data in the form of\nmanifold regularization and only relies on cascade information. This is in\ncontrast to the existing approaches that use exhaustive feature engineering\n(e.g., profile information, network structure, etc.). Evidence from empirical\nexperiments on a real-world ISIS-related dataset from Twitter suggests\npromising results of utilizing unlabeled instances for detecting PSMs.", "author": [{"name": "Hamidreza Alvari"}, {"name": "Elham Shaabani"}, {"name": "Soumajyoti Sarkar"}, {"name": "Ghazaleh Beigi"}, {"name": "Paulo Shakarian"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Companion Proceedings of the 2019 World Wide Web Conference"}, "link": [{"@href": "http://arxiv.org/abs/1903.01693v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.01693v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1903.08404v1", "updated": "2019-03-20T09:40:19Z", "published": "2019-03-20T09:40:19Z", "title": "Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking", "summary": "Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.", "author": [{"name": "Casper Hansen"}, {"name": "Christian Hansen"}, {"name": "Stephen Alstrup"}, {"name": "Jakob Grue Simonsen"}, {"name": "Christina Lioma"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Companion Proceedings of the 2019 World Wide Web Conference"}, "link": [{"@href": "http://arxiv.org/abs/1903.08404v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.08404v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1907.04191v2", "updated": "2019-07-11T15:44:50Z", "published": "2019-07-08T11:44:25Z", "title": "Belief places and spaces: Mapping cognitive environments", "summary": "Beliefs are not facts, but they are factive - they feel like facts. This\nproperty is what can make misinformation dangerous. Being able to deliberately\nnavigate through a landscape of often conflicting factive statements is\ndifficult when there is no way to show the relationships between them without\nincorporating the information in linear, narrative forms. In this paper, we\npresent a mechanism to produce maps of belief places, where populations agree\non salient features of fictional environments, and belief spaces, where\nsubgroups have related but distinct perspectives. Using a model developed using\nagent-based simulation, we show that by observing the repeated behaviors of\nhuman participants in the same social context, it is possible to build maps\nthat show the shared narrative environment overlaid with traces that show\nunique, individual or subgroup perspectives. Our contribution is a\nproof-of-concept system, based on the affordances of fantasy tabletop\nrole-playing games, which support multiple groups interacting with the same\ndungeon in a controlled, online environment. The techniques used in this\nprocess are mathematically straightforward, and should be generalizable to\nauto-generating larger-scale maps of belief spaces from other corpora, such as\ndiscussions on social media.", "author": [{"name": "Philip Feldman"}, {"name": "Aaron Dant"}, {"name": "Wayne Lutters"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "19 pages, 9 figure. arXiv admin note: text overlap with\n  arXiv:1904.05216"}, "link": [{"@href": "http://arxiv.org/abs/1907.04191v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.04191v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.1.2; H.3.3; H.3.5; H.4.3; H.5.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.01328v1", "updated": "2019-08-04T12:40:28Z", "published": "2019-08-04T12:40:28Z", "title": "Automatic Fact-Checking Using Context and Discourse Information", "summary": "We study the problem of automatic fact-checking, paying special attention to\nthe impact of contextual and discourse information. We address two related\ntasks: (i) detecting check-worthy claims, and (ii) fact-checking claims. We\ndevelop supervised systems based on neural networks, kernel-based support\nvector machines, and combinations thereof, which make use of rich input\nrepresentations in terms of discourse cues and contextual features. For the\ncheck-worthiness estimation task, we focus on political debates, and we model\nthe target claim in the context of the full intervention of a participant and\nthe previous and the following turns in the debate, taking into account\ncontextual meta information. For the fact-checking task, we focus on answer\nverification in a community forum, and we model the veracity of the answer with\nrespect to the entire question--answer thread in which it occurs as well as\nwith respect to other related posts from the entire forum. We develop annotated\ndatasets for both tasks and we run extensive experimental evaluation,\nconfirming that both types of information ---but especially contextual\nfeatures--- play an important role.", "author": [{"name": "Pepa Atanasova"}, {"name": "Preslav Nakov"}, {"name": "Llu\u00eds M\u00e0rquez"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Georgi Karadzhov"}, {"name": "Tsvetomila Mihaylova"}, {"name": "Mitra Mohtarami"}, {"name": "James Glass"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3297722"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3297722", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1908.01328v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.01328v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "JDIQ,Special Issue on Combating Digital Misinformation and\n  Disinformation"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "J. Data and Information Quality, Volume 11 Issue 3, July 2019,\n  Article No. 12"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.05992v1", "updated": "2019-08-16T14:43:13Z", "published": "2019-08-16T14:43:13Z", "title": "Homophily on social networks changes evolutionary advantage in\n  competitive information diffusion", "summary": "Competitive information diffusion on large-scale social networks reveals\nfundamental characteristics of rumor contagions and has profound influence on\npublic opinion formation. There has been growing interest in exploring\ndynamical mechanisms of the competing evolutions recently. Nevertheless, the\nimpacts of population homophily, which determines powerful collective human\nbehaviors, remains unclear. In this paper, we incorporate homophily effects\ninto a modified competitive ignorant-spreader-ignorant (SIS) rumor diffusion\nmodel with generalized population preference. Using microscopic Markov chain\napproach, we first derive the phase diagram of competing diffusion results and\nexamine how competitive information spreads and evolves on social networks. We\nthen explore the detailed effects of homophily, which is modeled by a rewiring\nmechanism. Results show that homophily promotes the formation of divided \"echo\nchambers\" and protects the disadvantaged information from extinction, which\nfurther changes or even reverses the evolutionary advantage, i.e., the\ndifference of final proportions of the competitive information. We highlight\nthe conclusion that the reversals may happen only when the initially\ndisadvantaged information has stronger transmission ability, owning diffusion\nadvantage over the other one. Our framework provides profound insight into\ncompeting dynamics with population homophily, which may pave ways for further\ncontrolling misinformation and guiding public belief systems. Moreover, the\nreversing condition sheds light on designing effective competing strategies in\nmany real scenarios.", "author": [{"name": "Longzhao Liu"}, {"name": "Xin Wang"}, {"name": "Yi Zheng"}, {"name": "Wenyi Fang"}, {"name": "Shaoting Tang"}, {"name": "Zhiming Zheng"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1088/1367-2630/ab623c"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1088/1367-2630/ab623c", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1908.05992v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.05992v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.06122v3", "updated": "2020-07-16T06:44:53Z", "published": "2019-09-13T10:08:44Z", "title": "FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized\n  Fake Faces", "summary": "In recent years, generative adversarial networks (GANs) and its variants have\nachieved unprecedented success in image synthesis. They are widely adopted in\nsynthesizing facial images which brings potential security concerns to humans\nas the fakes spread and fuel the misinformation. However, robust detectors of\nthese AI-synthesized fake faces are still in their infancy and are not ready to\nfully tackle this emerging challenge. In this work, we propose a novel\napproach, named FakeSpotter, based on monitoring neuron behaviors to spot\nAI-synthesized fake faces. The studies on neuron coverage and interactions have\nsuccessfully shown that they can be served as testing criteria for deep\nlearning systems, especially under the settings of being exposed to adversarial\nattacks. Here, we conjecture that monitoring neuron behavior can also serve as\nan asset in detecting fake faces since layer-by-layer neuron activation\npatterns may capture more subtle features that are important for the fake\ndetector. Experimental results on detecting four types of fake faces\nsynthesized with the state-of-the-art GANs and evading four perturbation\nattacks show the effectiveness and robustness of our approach.", "author": [{"name": "Run Wang"}, {"name": "Felix Juefei-Xu"}, {"name": "Lei Ma"}, {"name": "Xiaofei Xie"}, {"name": "Yihao Huang"}, {"name": "Jian Wang"}, {"name": "Yang Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to IJCAI 2020; SOLE copyright holder is IJCAI (international\n  Joint Conferences on Artificial Intelligence), all rights reserved.\n  https://www.ijcai.org/Proceedings/2020/333"}, "link": [{"@href": "http://arxiv.org/abs/1909.06122v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.06122v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.12069v2", "updated": "2021-04-22T09:51:53Z", "published": "2019-11-27T10:41:19Z", "title": "SpoC: Spoofing Camera Fingerprints", "summary": "Thanks to the fast progress in synthetic media generation, creating realistic\nfalse images has become very easy. Such images can be used to wrap \"rich\" fake\nnews with enhanced credibility, spawning a new wave of high-impact, high-risk\nmisinformation campaigns. Therefore, there is a fast-growing interest in\nreliable detectors of manipulated media. The most powerful detectors, to date,\nrely on the subtle traces left by any device on all images acquired by it. In\nparticular, due to proprietary in-camera processes, like demosaicing or\ncompression, each camera model leaves trademark traces that can be exploited\nfor forensic analyses. The absence or distortion of such traces in the target\nimage is a strong hint of manipulation. In this paper, we challenge such\ndetectors to gain better insight into their vulnerabilities. This is an\nimportant study in order to build better forgery detectors able to face\nmalicious attacks. Our proposal consists of a GAN-based approach that injects\ncamera traces into synthetic images. Given a GAN-generated image, we insert the\ntraces of a specific camera model into it and deceive state-of-the-art\ndetectors into believing the image was acquired by that model. Likewise, we\ndeceive independent detectors of synthetic GAN images into believing the image\nis real. Experiments prove the effectiveness of the proposed method in a wide\narray of conditions. Moreover, no prior information on the attacked detectors\nis needed, but only sample images from the target camera.", "author": [{"name": "Davide Cozzolino"}, {"name": "Justus Thies"}, {"name": "Andreas R\u00f6ssler"}, {"name": "Matthias Nie\u00dfner"}, {"name": "Luisa Verdoliva"}], "link": [{"@href": "http://arxiv.org/abs/1911.12069v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.12069v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.IV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1912.03481v1", "updated": "2019-12-07T10:15:08Z", "published": "2019-12-07T10:15:08Z", "title": "A Multi-Feature Diffusion Model: Rumor Blocking in Social Networks", "summary": "Online social networks provide a convenient platform for the spread of\nrumors, which could lead to serious aftermaths such as economic losses and\npublic panic. The classical rumor blocking problem aims to launch a set of\nnodes as a positive cascade to compete with misinformation in order to limit\nthe spread of rumors. However, most of the related researches were based on\none-dimensional diffusion model. In reality, there are more than one feature\nassociated with an object. The user's impression on this object is determined\nnot just by one feature but by his/her overall evaluation on all of these\nfeatures. Thus, the influence spread of this object can be decomposed into the\nspread of multiple features. Based on that, we propose a Multi-Feature\ndiffusion model (MF-model) in this paper, and a novel problem, Multi-Feature\nRumor Blocking (MFRB), is formulated on a multi-layer network structure\naccording to this model. To solve MFRB, we design a creative sampling method,\ncalled Multi-Sampling, which can be applied to a multi-layer network structure.\nInspired by martingale analysis, the Revised-IMM algorithm is proposed, and\nreturns a satisfactory approximate solution to MFRB. Finally, we evaluate our\nproposed algorithm by conducting experiments on real datasets, and show the\neffectiveness and accuracy of the Revised-IMM algorithm and significantly\noutperforms other baseline algorithms.", "author": [{"name": "Jianxiong Guo"}, {"name": "Tiantian Chen"}, {"name": "Weili Wu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/TNET.2020.3032893"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/TNET.2020.3032893", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1912.03481v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.03481v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "in IEEE/ACM Transactions on Networking"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1912.05238v1", "updated": "2019-12-11T11:27:06Z", "published": "2019-12-11T11:27:06Z", "title": "BERT has a Moral Compass: Improvements of ethical and moral values of\n  machines", "summary": "Allowing machines to choose whether to kill humans would be devastating for\nworld peace and security. But how do we equip machines with the ability to\nlearn ethical or even moral choices? Jentzsch et al.(2019) showed that applying\nmachine learning to human texts can extract deontological ethical reasoning\nabout \"right\" and \"wrong\" conduct by calculating a moral bias score on a\nsentence level using sentence embeddings. The machine learned that it is\nobjectionable to kill living beings, but it is fine to kill time; It is\nessential to eat, yet one might not eat dirt; it is important to spread\ninformation, yet one should not spread misinformation. However, the evaluated\nmoral bias was restricted to simple actions -- one verb -- and a ranking of\nactions with surrounding context. Recently BERT ---and variants such as RoBERTa\nand SBERT--- has set a new state-of-the-art performance for a wide range of NLP\ntasks. But has BERT also a better moral compass? In this paper, we discuss and\nshow that this is indeed the case. Thus, recent improvements of language\nrepresentations also improve the representation of the underlying ethical and\nmoral values of the machine. We argue that through an advanced semantic\nrepresentation of text, BERT allows one to get better insights of moral and\nethical values implicitly represented in text. This enables the Moral Choice\nMachine (MCM) to extract more accurate imprints of moral choices and ethical\nvalues.", "author": [{"name": "Patrick Schramowski"}, {"name": "Cigdem Turan"}, {"name": "Sophie Jentzsch"}, {"name": "Constantin Rothkopf"}, {"name": "Kristian Kersting"}], "link": [{"@href": "http://arxiv.org/abs/1912.05238v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.05238v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1912.05603v1", "updated": "2019-12-11T20:22:20Z", "published": "2019-12-11T20:22:20Z", "title": "A Novel Approach in Strategic Planning of Power Networks Against\n  Physical Attacks", "summary": "The reported work points at developing a practical approach for power\ntransmission planners to secure power networks from potential deliberate\nattacks. We study the interaction between a system planner (defender) and a\nrational attacker who threatens the operation of the power grid. In addition to\nthe commonly used hardening strategy for protecting the network, a new sort of\nresource is introduced under the deception concept. Feint and deception are\nacknowledged as effective tools for misleading the attacker in strategic\nplanning. To this end, the defender deception is mathematically formulated by\nreleasing misinformation about his plan in the shared cognition-based model. To\nreduce the risk of damage in case of deception failure, preemptive-goal\nprogramming is utilized to prioritize the hardening strategy for the vital\ncomponents. Furthermore, the value of posturing is introduced which is the\nbenefits that the deception brings to the system. The problems are formulated\nas tri-level mixed-integer linear programming and solved by the\nconstraint-and-column generation method. Comprehensive simulation studies\nperformed on WSCC 9-bus and IEEE 118-bus systems indicate how the defender will\nsave significant cost from protecting his network with posturing rather than\nhardening and the proposed approach is a promising development to ensure the\nsecure operation of power networks.", "author": [{"name": "Hamzeh Davarikia"}, {"name": "Masoud Barati"}, {"name": "Mustafa Al-Assad"}, {"name": "Yupo Chan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to be published in Journal of Electric Power Systems\n  Research, 2018"}, "link": [{"@href": "http://arxiv.org/abs/1912.05603v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.05603v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "eess.SY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "eess.SY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.OC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1912.08909v1", "updated": "2019-12-18T21:56:24Z", "published": "2019-12-18T21:56:24Z", "title": "Subgraph Classification, Clustering and Centrality for a Degree\n  Asymmetric Twitter Based Graph Case Study: Suicidality", "summary": "We present some initial results from a case study in social media data\nharvesting and visualization utilizing the tools and analytical features of\nNodeXL applied to a degree asymmetric vertex graph set. We consider twitter\ngraphs harvested for topics related to suicidal ideation, suicide attempts,\nself-harm and bullycide. While the twitter-sphere only captures a small and age\nbiased sample of communications it is a readily available public database for a\nwealth of rich topics yielding a large sample set. All these topics gave rise\nto highly asymmetric vertex degree graphs and all shared the same general\ntopological features. We find a strong preference for in degree vertex\ninformation transfer with a 4:25 out degree to in degree vertex ratio with a\npower law distribution. Overall there is a low global clustering coefficient\naverage of 0.038 and a graph clustering density of 0.00034 for\nClauset-Newman-Moore grouping with a maximum geodesic distance of 6.\nEigenvector centrality does not give any large central impact vertices and\nbetweenness centrality shows many bridging vertices indicating a sparse\ncommunity structure. Parts of speech sentiment scores show a strong asymmetry\nof predominant negative scores for almost all word and word pairs with salience\ngreater than one. We used an Hoaxy analysis to check for deliberate\nmisinformation on these topics by a Twitter-Bot.", "author": [{"name": "Keith Andrew"}, {"name": "Eric Steinfelds"}, {"name": "Karla M. Andrew"}, {"name": "Kay Opalenik"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "14 pages, 7 figures"}, "link": [{"@href": "http://arxiv.org/abs/1912.08909v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.08909v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1912.12999v3", "updated": "2020-05-26T16:01:39Z", "published": "2019-12-30T16:44:41Z", "title": "AutoDiscern: Rating the Quality of Online Health Information with\n  Hierarchical Encoder Attention-based Neural Networks", "summary": "Patients increasingly turn to search engines and online content before, or in\nplace of, talking with a health professional. Low quality health information,\nwhich is common on the internet, presents risks to the patient in the form of\nmisinformation and a possibly poorer relationship with their physician. To\naddress this, the DISCERN criteria (developed at University of Oxford) are used\nto evaluate the quality of online health information. However, patients are\nunlikely to take the time to apply these criteria to the health websites they\nvisit. We built an automated implementation of the DISCERN instrument (Brief\nversion) using machine learning models. We compared the performance of a\ntraditional model (Random Forest) with that of a hierarchical encoder\nattention-based neural network (HEA) model using two language embeddings, BERT\nand BioBERT. The HEA BERT and BioBERT models achieved average F1-macro scores\nacross all criteria of 0.75 and 0.74, respectively, outperforming the Random\nForest model (average F1-macro = 0.69). Overall, the neural network based\nmodels achieved 81% and 86% average accuracy at 100% and 80% coverage,\nrespectively, compared to 94% manual rating accuracy. The attention mechanism\nimplemented in the HEA architectures not only provided 'model explainability'\nby identifying reasonable supporting sentences for the documents fulfilling the\nBrief DISCERN criteria, but also boosted F1 performance by 0.05 compared to the\nsame architecture without an attention mechanism. Our research suggests that it\nis feasible to automate online health information quality assessment, which is\nan important step towards empowering patients to become informed partners in\nthe healthcare process.", "author": [{"name": "Laura Kinkead"}, {"name": "Ahmed Allam"}, {"name": "Michael Krauthammer"}], "link": [{"@href": "http://arxiv.org/abs/1912.12999v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.12999v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.00623v1", "updated": "2020-01-02T21:01:02Z", "published": "2020-01-02T21:01:02Z", "title": "Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements", "summary": "In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.", "author": [{"name": "Kai Shu"}, {"name": "Suhang Wang"}, {"name": "Dongwon Lee"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted as an introductory chapter for the edited book on \"Fake\n  News, Disinformation, and Misinformation in Social Media- Emerging Research\n  Challenges and Opportunities\", Springer Press"}, "link": [{"@href": "http://arxiv.org/abs/2001.00623v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.00623v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.06567v1", "updated": "2020-02-16T12:37:32Z", "published": "2020-02-16T12:37:32Z", "title": "The optimal edge for containing the spreading of SIS model", "summary": "Numerous real-world systems, for instance, the communication platforms and\ntransportation systems, can be abstracted into complex networks. Containing\nspreading dynamics (e.g., epidemic transmission and misinformation propagation)\nin networked systems is a hot topic in multiple fronts. Most of the previous\nstrategies are based on the immunization of nodes. However, sometimes, these\nnode--based strategies can be impractical. For instance, in the train\ntransportation networks, it is dramatic to isolating train stations for flu\nprevention. On the contrary, temporarily suspending some connections between\nstations is more acceptable. Thus, we pay attention to the edge-based\ncontaining strategy. In this study, we develop a theoretical framework to find\nthe optimal edge for containing the spreading of the\nsusceptible-infected-susceptible model on complex networks. In specific, by\nperforming a perturbation method to the discrete-Markovian-chain equations of\nthe SIS model, we derive a formula that approximately provides the decremental\noutbreak size after the deactivation of a certain edge in the network. Then, we\ndetermine the optimal edge by simply choosing the one with the largest\ndecremental outbreak size. Note that our proposed theoretical framework\nincorporates the information of both network structure and spreading dynamics.\nFinally, we test the performance of our method by extensive numerical\nsimulations. Results demonstrate that our strategy always outperforms other\nstrategies based only on structural properties (degree or edge betweenness\ncentrality). The theoretical framework in this study can be extended to other\nspreading models and offers inspirations for further investigations on\nedge-based immunization strategies.", "author": [{"name": "Jiajun Xian"}, {"name": "Dan Yang"}, {"name": "Liming Pan"}, {"name": "Wei Wang"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1088/1742-5468/ab780d"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1088/1742-5468/ab780d", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2002.06567v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.06567v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2002.10522v2", "updated": "2020-03-04T16:07:57Z", "published": "2020-02-24T20:28:14Z", "title": "MIDMod-OSN: A Microscopic-level Information Diffusion Model for Online\n  Social Networks", "summary": "As online social networks continue to be commonly used for the dissemination\nof information to the public, understanding the phenomena that govern\ninformation diffusion is crucial for many security and safety-related\napplications, such as maximizing information spread and misinformation\ncontainment during crises and natural disasters. In this study, we hypothesize\nthat the features that contribute to information diffusion in online social\nnetworks are significantly influenced by the type of event being studied. We\nclassify Twitter events as either informative or trending and then explore the\nnode-to-node influence dynamics associated with information spread. We build a\nmodel based on Bayesian Logistic Regression for learning and prediction and\nRandom Forests for feature selection. Experimental results from real-world data\nsets show that the proposed model outperforms state-of-the-art diffusion\nprediction models, achieving 93% accuracy in informative events and 86% in\ntrending events. We observed that the models for informative and trending\nevents differ significantly, both in the diffusion process and in the user\nfeatures that govern the diffusion. Our findings show that followers play an\nimportant role in the diffusion process and it is possible to use the diffusion\nand OSN behavior of users for predicting the trending character of a message\nwithout having to count the number of reactions.", "author": [{"name": "Abiola Osho"}, {"name": "Colin Goodman"}, {"name": "George Amariucai"}], "link": [{"@href": "http://arxiv.org/abs/2002.10522v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.10522v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.00056v3", "updated": "2021-01-07T18:56:59Z", "published": "2020-02-28T20:35:58Z", "title": "Measuring Node Contribution to Community Structure with Modularity\n  Vitality", "summary": "Community-aware centrality is an emerging research area in network science\nconcerned with the importance of nodes in relation to community structure.\nMeasures are a function of a network's structure and a given partition.\nPrevious approaches extend classical centrality measures to account for\ncommunity structure with little connection to community detection theory. In\ncontrast, we propose cluster-quality vitality measures, i.e., modularity\nvitality, a community-aware measure which is well-grounded in both centrality\nand community detection theory. Modularity vitality quantifies positive and\nnegative contributions to community structure, which indicate a node's role as\na community bridge or hub. We derive a computationally efficient method of\ncalculating modularity vitality for all nodes in O(M + NC) time, where C is the\nnumber of communities. We systematically fragment networks by removing central\nnodes, and find that modularity vitality consistently outperforms existing\ncommunity-aware centrality measures. Modularity vitality is over 8 times more\neffective than the next-best method on a million-node infrastructure network.\nThis result does not generalize to social media communication networks, which\nexhibit extreme robustness to all community-aware centrality attacks. This\nrobustness suggests that user-based interventions to mitigate misinformation\ndiffusion will be ineffective. Finally, we demonstrate that modularity vitality\nprovides a new approach to community-deception.", "author": [{"name": "Thomas Magelinski"}, {"name": "Mihovil Bartulovic"}, {"name": "Kathleen M. Carley"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/TNSE.2020.3049068"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/TNSE.2020.3049068", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.00056v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.00056v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to IEEE Transactions on Network Science and Engineering"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2003.07595v1", "updated": "2020-03-17T09:24:22Z", "published": "2020-03-17T09:24:22Z", "title": "FakeYou! -- A Gamified Approach for Building and Evaluating Resilience\n  Against Fake News", "summary": "Nowadays fake news are heavily discussed in public and political debates.\nEven though the phenomenon of intended false information is rather old,\nmisinformation reaches a new level with the rise of the internet and\nparticipatory platforms. Due to Facebook and Co., purposeful false information\n- often called fake news - can be easily spread by everyone. Because of a high\ndata volatility and variety in content types (text, images,...) debunking of\nfake news is a complex challenge. This is especially true for automated\napproaches, which are prone to fail validating the veracity of the information.\nThis work focuses on an a gamified approach to strengthen the resilience of\nconsumers towards fake news. The game FakeYou motivates its players to\ncritically analyze headlines regarding their trustworthiness. Further, the game\nfollows a \"learning by doing strategy\": by generating own fake headlines, users\nshould experience the concepts of convincing fake headline formulations. We\nintroduce the game itself, as well as the underlying technical infrastructure.\nA first evaluation study shows, that users tend to use specific stylistic\ndevices to generate fake news. Further, the results indicate, that creating\ngood fakes and identifying correct headlines are challenging and hard to learn.", "author": [{"name": "Lena Clever"}, {"name": "Dennis Assenmacher"}, {"name": "Kilian M\u00fcller"}, {"name": "Moritz Vinzent Seiler"}, {"name": "Dennis M. Riehle"}, {"name": "Mike Preuss"}, {"name": "Christian Grimme"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "accepted for Disinformation in Open Online Media - 2nd\n  Multidisciplinary International Symposium, MISDOOM 2020"}, "link": [{"@href": "http://arxiv.org/abs/2003.07595v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.07595v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.00005v1", "updated": "2020-03-30T19:05:34Z", "published": "2020-03-30T19:05:34Z", "title": "Perception of emergent epidemic of COVID-2019 / SARS CoV-2 on the Polish\n  Internet", "summary": "We study the perception of COVID-2019 epidemic in Polish society using\nquantitative analysis of its digital footprints on the Internet (on Twitter,\nGoogle, YouTube, Wikipedia and electronic media represented by Event Registry)\nfrom January 2020 to 12.03.2020 (before and after official introduction to\nPoland on 04.03.2020). To this end we utilize data mining, social network\nanalysis, natural language processing techniques. Each examined internet\nplatform was analyzed for representativeness and composition of the target\ngroup. We identified three temporal major cluster of the interest before\ndisease introduction on the topic COVID-2019: China- and Italy-related peaks on\nall platforms, as well as a peak on social media related to the recent special\nlaw on combating COVID-2019. Besides, there was a peak in interest on the day\nof officially confirmed introduction as well as an exponential increase of\ninterest when the Polish government declared war against disease with a massive\nmitigation program. From sociolingistic perspective, we found that concepts and\nissues of threat, fear and prevention prevailed before introduction. After\nintroduction, practical concepts about disease and epidemic dominate. We have\nfound out that Twitter reflected the structural division of the Polish\npolitical sphere. We were able to identify clear communities of governing\nparty, mainstream oppostition and protestant group and potential sources of\nmisinformation. We have also detected bluring boundaries between comminities\nafter disease introduction.", "author": [{"name": "Andrzej Jarynowski"}, {"name": "Monika Wojta-Kempa"}, {"name": "Vitaly Belik"}], "link": [{"@href": "http://arxiv.org/abs/2004.00005v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.00005v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.01106v2", "updated": "2021-01-15T21:26:57Z", "published": "2020-04-02T16:10:34Z", "title": "The Paradox of Information Access: On Modeling Social-Media-Induced\n  Polarization", "summary": "The paper develops a stochastic model of drift in human beliefs that shows\nthat today's sheer volume of accessible information, combined with consumers'\nconfirmation bias and natural preference to more outlying content, necessarily\nlead to increased polarization. The model explains the paradox of growing\nideological fragmentation in the age of increased sharing. As social media,\nsearch engines, and other real-time information sharing outlets purport to\nfacilitate access to information, a need for content filtering arises due to\nthe ensuing information overload. In general, consumers select information that\nmatches their individual views and values. The bias inherent in such selection\nis echoed by today's information curation services that maximize user\nengagement by filtering new content in accordance with observed consumer\npreferences. Consequently, individuals get exposed to increasingly narrower\nbands of the ideology spectrum, thus fragmenting society into increasingly\nideologically isolated enclaves. We call this dynamic the paradox of\ninformation access. The model also suggests the disproportionate damage\nattainable with a small infusion of well-positioned misinformation. The paper\ndescribes the modeling methodology, and evaluates modeling results for\ndifferent population sizes and parameter settings.", "author": [{"name": "Chao Xu"}, {"name": "Jinyang Li"}, {"name": "Tarek Abdelzaher"}, {"name": "Heng Ji"}, {"name": "Boleslaw K. Szymanski"}, {"name": "John Dellaverson"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "An updated version of this preprint was submitted to IEEE TCNS"}, "link": [{"@href": "http://arxiv.org/abs/2004.01106v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.01106v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.01732v1", "updated": "2020-04-03T18:26:33Z", "published": "2020-04-03T18:26:33Z", "title": "Leveraging Multi-Source Weak Social Supervision for Early Detection of\n  Fake News", "summary": "Social media has greatly enabled people to participate in online activities\nat an unprecedented rate. However, this unrestricted access also exacerbates\nthe spread of misinformation and fake news online which might cause confusion\nand chaos unless being detected early for its mitigation. Given the rapidly\nevolving nature of news events and the limited amount of annotated data,\nstate-of-the-art systems on fake news detection face challenges due to the lack\nof large numbers of annotated training instances that are hard to come by for\nearly detection. In this work, we exploit multiple weak signals from different\nsources given by user and content engagements (referred to as weak social\nsupervision), and their complementary utilities to detect fake news. We jointly\nleverage the limited amount of clean data along with weak signals from social\nengagements to train deep neural networks in a meta-learning framework to\nestimate the quality of different weak instances. Experiments on realworld\ndatasets demonstrate that the proposed framework outperforms state-of-the-art\nbaselines for early detection of fake news without using any user engagements\nat prediction time.", "author": [{"name": "Kai Shu"}, {"name": "Guoqing Zheng"}, {"name": "Yichuan Li"}, {"name": "Subhabrata Mukherjee"}, {"name": "Ahmed Hassan Awadallah"}, {"name": "Scott Ruston"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "17 pages, 5 figures, 4 tables"}, "link": [{"@href": "http://arxiv.org/abs/2004.01732v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.01732v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.03688v2", "updated": "2020-11-13T16:20:38Z", "published": "2020-04-07T20:25:26Z", "title": "A large-scale COVID-19 Twitter chatter dataset for open scientific\n  research -- an international collaboration", "summary": "As the COVID-19 pandemic continues its march around the world, an\nunprecedented amount of open data is being generated for genetics and\nepidemiological research. The unparalleled rate at which many research groups\naround the world are releasing data and publications on the ongoing pandemic is\nallowing other scientists to learn from local experiences and data generated in\nthe front lines of the COVID-19 pandemic. However, there is a need to integrate\nadditional data sources that map and measure the role of social dynamics of\nsuch a unique world-wide event into biomedical, biological, and epidemiological\nanalyses. For this purpose, we present a large-scale curated dataset of over\n152 million tweets, growing daily, related to COVID-19 chatter generated from\nJanuary 1st to April 4th at the time of writing. This open dataset will allow\nresearchers to conduct a number of research projects relating to the emotional\nand mental responses to social distancing measures, the identification of\nsources of misinformation, and the stratified measurement of sentiment towards\nthe pandemic in near real time.", "author": [{"name": "Juan M. Banda"}, {"name": "Ramya Tekumalla"}, {"name": "Guanyu Wang"}, {"name": "Jingyuan Yu"}, {"name": "Tuo Liu"}, {"name": "Yuning Ding"}, {"name": "Katya Artemova"}, {"name": "Elena Tutubalina"}, {"name": "Gerardo Chowell"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.3390/epidemiologia2030024"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.3390/epidemiologia2030024", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.03688v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.03688v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 1 figure 2 table. Update: new version of paper with\n  up-to-date statistics and new co-authors"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.13142v1", "updated": "2020-04-27T20:05:24Z", "published": "2020-04-27T20:05:24Z", "title": "Quantifying Latent Moral Foundations in Twitter Narratives: The Case of\n  the Syrian White Helmets Misinformation", "summary": "For years, many studies employed sentiment analysis to understand the\nreasoning behind people's choices and feelings, their communication styles, and\nthe communities which they belong to. We argue that gaining more in-depth\ninsight into moral dimensions coupled with sentiment analysis can potentially\nprovide superior results. Understanding moral foundations can yield powerful\nresults in terms of perceiving the intended meaning of the text data, as the\nconcept of morality provides additional information on the unobservable\ncharacteristics of information processing and non-conscious cognitive\nprocesses. Therefore, we studied latent moral loadings of Syrian White\nHelmets-related tweets of Twitter users from April 1st, 2018 to April 30th,\n2019. For the operationalization and quantification of moral rhetoric in\ntweets, we use Extended Moral Foundations Dictionary in which five\npsychological dimensions (Harm/Care, Fairness/Reciprocity, In-group/Loyalty,\nAuthority/Respect and Purity/Sanctity) are considered. We show that people tend\nto share more tweets involving the virtue moral rhetoric than the tweets\ninvolving the vice rhetoric. We observe that the pattern of the moral rhetoric\nof tweets among these five dimensions are very similar during different time\nperiods, while the strength of the five dimension is time-variant. Even though\nthere is no significant difference between the use of Fairness/Reciprocity,\nIn-group/Loyalty or Purity/Sanctity rhetoric, the less use of Harm/Care\nrhetoric is significant and remarkable. Besides, the strength of the moral\nrhetoric and the polarization in morality across people are mostly observed in\ntweets involving Harm/Care rhetoric despite the number of tweets involving the\nHarm/Care dimension is low.", "author": [{"name": "Ece \u00c7i\u011fdem Mutlu"}, {"name": "Toktam Oghaz"}, {"name": "Ege T\u00fct\u00fcnc\u00fcler"}, {"name": "Jasser Jasser"}, {"name": "Ivan Garibay"}], "link": [{"@href": "http://arxiv.org/abs/2004.13142v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.13142v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.07266v2", "updated": "2021-04-21T08:27:12Z", "published": "2020-05-14T21:14:15Z", "title": "Characterizing information leaders in Twitter during COVID-19 crisis", "summary": "Information is key during a crisis such as the one produced by the current\nCOVID-19 pandemic as it greatly shapes people opinion, behavior and their\npsychology. Infodemic of misinformation is an important secondary crisis\nassociated to the pandemic. Infodemics can amplify the real negative\nconsequences of the pandemic in different dimensions: social, economic and even\nsanitary. For instance, infodemics can lead to hatred between population groups\nthat fragment the society influencing its response or result in negative habits\nthat help the pandemic propagate. On the contrary, reliable and trustful\ninformation along with messages of hope and solidarity can be used to control\nthe pandemic, build safety nets and help promote resilience. We propose the\nfoundation of a framework to characterize leaders in Twitter based on the\nanalysis of the social graph derived from the activity in this social network.\nCentrality metrics are used to characterize the topology of the network and the\nnodes as potential leaders. These metrics are compared with the user popularity\nmetrics managed by Twitter. We then assess the resulting topology of clusters\nof leaders visually. We propose this tool to be the basis for a system to\ndetect and empower users with a positive influence in the collective behavior\nof the network and the propagation of information.", "author": {"name": "David Pastor-Escuredo"}, "link": [{"@href": "http://arxiv.org/abs/2005.07266v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.07266v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.02181v3", "updated": "2021-07-19T15:14:39Z", "published": "2020-06-03T11:34:25Z", "title": "Information Consumption and Social Response in a Segregated Environment:\n  the Case of Gab", "summary": "Most of the information operations involve users who may foster polarization\nand distrust toward science and mainstream journalism, without these users\nbeing conscious of their role. Gab is well known to be an extremist-friendly\nplatform that performs little control on the posted content. Thus it represents\nan ideal benchmark for studying phenomena potentially related to polarization\nsuch as misinformation spreading. The combination of these factors may lead to\nhate as well as to episodes of harm in the real world. In this work we provide\na characterization of the interaction patterns within Gab around the COVID-19\ntopic. To assess the spreading of different content type, we analyze\nconsumption patterns based on both interaction type and source reliability.\nOverall we find that there are no strong statistical differences in the social\nresponse to questionable and reliable content, both following a power law\ndistribution. However, questionable and reliable sources display structural and\ntopical differences in the use of hashtags. The commenting behaviour of users\nin terms of both lifetime and sentiment reveals that questionable and reliable\nposts are perceived in the same manner. We can conclude that despite evident\ndifferences between questionable and reliable posts Gab users do not perform\nsuch a differentiation thus treating them as a whole. Our results provide\ninsights toward the understanding of coordinated inauthentic behavior and on\nthe early-warning of information operation.", "author": [{"name": "Gabriele Etta"}, {"name": "Alessandro Galeazzi"}, {"name": "Matteo Cinelli"}, {"name": "Mauro Conti"}, {"name": "Walter Quattrociocchi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The paper is now replaced with an updated version: arXiv:2106.03924"}, "link": [{"@href": "http://arxiv.org/abs/2006.02181v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.02181v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.05169v1", "updated": "2020-06-09T10:34:41Z", "published": "2020-06-09T10:34:41Z", "title": "DyHGCN: A Dynamic Heterogeneous Graph Convolutional Network to Learn\n  Users' Dynamic Preferences for Information Diffusion Prediction", "summary": "Information diffusion prediction is a fundamental task for understanding the\ninformation propagation process. It has wide applications in such as\nmisinformation spreading prediction and malicious account detection. Previous\nworks either concentrate on utilizing the context of a single diffusion\nsequence or using the social network among users for information diffusion\nprediction. However, the diffusion paths of different messages naturally\nconstitute a dynamic diffusion graph. For one thing, previous works cannot\njointly utilize both the social network and diffusion graph for prediction,\nwhich is insufficient to model the complexity of the diffusion process and\nresults in unsatisfactory prediction performance. For another, they cannot\nlearn users' dynamic preferences. Intuitively, users' preferences are changing\nas time goes on and users' personal preference determines whether the user will\nrepost the information. Thus, it is beneficial to consider users' dynamic\npreferences in information diffusion prediction.\n  In this paper, we propose a novel dynamic heterogeneous graph convolutional\nnetwork (DyHGCN) to jointly learn the structural characteristics of the social\ngraph and dynamic diffusion graph. Then, we encode the temporal information\ninto the heterogeneous graph to learn the users' dynamic preferences. Finally,\nwe apply multi-head attention to capture the context-dependency of the current\ndiffusion path to facilitate the information diffusion prediction task.\nExperimental results show that DyHGCN significantly outperforms the\nstate-of-the-art models on three public datasets, which shows the effectiveness\nof the proposed model.", "author": [{"name": "Chunyuan Yuan"}, {"name": "Jiacheng Li"}, {"name": "Wei Zhou"}, {"name": "Yijun Lu"}, {"name": "Xiaodan Zhang"}, {"name": "Songlin Hu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the ECML-PKDD 2020"}, "link": [{"@href": "http://arxiv.org/abs/2006.05169v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.05169v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.06867v2", "updated": "2020-08-14T20:04:21Z", "published": "2020-06-11T22:59:59Z", "title": "Detection of Novel Social Bots by Ensembles of Specialized Classifiers", "summary": "Malicious actors create inauthentic social media accounts controlled in part\nby algorithms, known as social bots, to disseminate misinformation and agitate\nonline discussion. While researchers have developed sophisticated methods to\ndetect abuse, novel bots with diverse behaviors evade detection. We show that\ndifferent types of bots are characterized by different behavioral features. As\na result, supervised learning techniques suffer severe performance\ndeterioration when attempting to detect behaviors not observed in the training\ndata. Moreover, tuning these models to recognize novel bots requires retraining\nwith a significant amount of new annotations, which are expensive to obtain. To\naddress these issues, we propose a new supervised learning method that trains\nclassifiers specialized for each class of bots and combines their decisions\nthrough the maximum rule. The ensemble of specialized classifiers (ESC) can\nbetter generalize, leading to an average improvement of 56\\% in F1 score for\nunseen accounts across datasets. Furthermore, novel bot behaviors are learned\nwith fewer labeled examples during retraining. We deployed ESC in the newest\nversion of Botometer, a popular tool to detect social bots in the wild, with a\ncross-validation AUC of 0.99.", "author": [{"name": "Mohsen Sayyadiharikandeh"}, {"name": "Onur Varol"}, {"name": "Kai-Cheng Yang"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3340531.3412698"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3340531.3412698", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2006.06867v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.06867v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 10 figures, Accepted to CIKM'20"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proc. 29th ACM International Conference on Information and\n  Knowledge Management (CIKM), pages 2725-2732, 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.12759v2", "updated": "2021-04-05T15:06:08Z", "published": "2020-06-23T04:54:22Z", "title": "Estimation of COVID-19 under-reporting in Brazilian States through SARI", "summary": "Due to its impact, COVID-19 has been stressing the academy to search for\ncuring, mitigating, or controlling it. However, when it comes to controlling,\nthere are still few studies focused on under-reporting estimates. It is\nbelieved that under-reporting is a relevant factor in determining the actual\nmortality rate and, if not considered, can cause significant misinformation.\nTherefore, the objective of this work is to estimate the under-reporting of\ncases and deaths of COVID-19 in Brazilian states using data from the Infogripe\non notification of Severe Acute Respiratory Infection (SARI). The methodology\nis based on the concepts of inertia and the use of event detection techniques\nto study the time series of hospitalized SARI cases. The estimate of real cases\nof the disease, called novelty, is calculated by comparing the difference in\nSARI cases in 2020 (after COVID-19) with the total expected cases in recent\nyears (2016 to 2019) derived from a seasonal exponential moving average. The\nresults show that under-reporting rates vary significantly between states and\nthat there are no general patterns for states in the same region in Brazil.\n  The published version of this paper is made available at\nhttps://doi.org/10.1007/s00354-021-00125-3.\n  Please cite as: B. Paix\\~ao, L. Baroni, M. Pedroso, R. Salles, L. Escobar, C.\nde Sousa, R. de Freitas Saldanha, J. Soares, R. Coutinho, et al., 2021,\nEstimation of COVID-19 Under-Reporting in the Brazilian States Through SARI,\nNew Generation Computing", "author": [{"name": "Balthazar Paix\u00e3o"}, {"name": "Lais Baroni"}, {"name": "Rebecca Salles"}, {"name": "Luciana Escobar"}, {"name": "Carlos de Sousa"}, {"name": "Marcel Pedroso"}, {"name": "Raphael Saldanha"}, {"name": "Rafaelli Coutinho"}, {"name": "Fabio Porto"}, {"name": "Eduardo Ogasawara"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/s00354-021-00125-3"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/s00354-021-00125-3", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2006.12759v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.12759v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.01242v1", "updated": "2020-07-02T16:50:28Z", "published": "2020-07-02T16:50:28Z", "title": "Evolving Methods for Evaluating and Disseminating Computing Research", "summary": "Social and technical trends have significantly changed methods for evaluating\nand disseminating computing research. Traditional venues for reviewing and\npublishing, such as conferences and journals, worked effectively in the past.\nRecently, trends have created new opportunities but also put new pressures on\nthe process of review and dissemination. For example, many conferences have\nseen large increases in the number of submissions. Likewise, dissemination of\nresearch ideas has become dramatically through publication venues such as\narXiv.org and social media networks. While these trends predate COVID-19, the\npandemic could accelerate longer term changes. Based on interviews with leading\nacademics in computing research, our findings include: (1) Trends impacting\ncomputing research are largely positive and have increased the participation,\nscope, accessibility, and speed of the research process. (2) Challenges remain\nin securing the integrity of the process, including addressing ways to scale\nthe review process, avoiding attempts to misinform or confuse the dissemination\nof results, and ensuring fairness and broad participation in the process\nitself. Based on these findings, we recommend: (1) Regularly polling members of\nthe computing research community, including program and general conference\nchairs, journal editors, authors, reviewers, etc., to identify specific\nchallenges they face to better understand these issues. (2) An influential\nbody, such as the Computing Research Association regularly issues a \"State of\nthe Computing Research Enterprise\" report to update the community on trends,\nboth positive and negative, impacting the computing research enterprise. (3) A\ndeeper investigation, specifically to better understand the influence that\nsocial media and preprint archives have on computing research, is conducted.", "author": [{"name": "Benjamin Zorn"}, {"name": "Tom Conte"}, {"name": "Keith Marzullo"}, {"name": "Suresh Venkatasubramanian"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "A Computing Community Consortium (CCC) white paper, 12 pages"}, "link": [{"@href": "http://arxiv.org/abs/2007.01242v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.01242v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2007.08457v5", "updated": "2021-03-31T00:49:28Z", "published": "2020-07-16T16:49:55Z", "title": "Artificial Fingerprinting for Generative Models: Rooting Deepfake\n  Attribution in Training Data", "summary": "Photorealistic image generation has reached a new level of quality due to the\nbreakthroughs of generative adversarial networks (GANs). Yet, the dark side of\nsuch deepfakes, the malicious use of generated media, raises concerns about\nvisual misinformation. While existing research work on deepfake detection\ndemonstrates high accuracy, it is subject to advances in generation techniques\nand adversarial iterations on detection countermeasure techniques. Thus, we\nseek a proactive and sustainable solution on deepfake detection, that is\nagnostic to the evolution of generative models, by introducing artificial\nfingerprints into the models.\n  Our approach is simple and effective. We first embed artificial fingerprints\ninto training data, then validate a surprising discovery on the transferability\nof such fingerprints from training data to generative models, which in turn\nappears in the generated deepfakes. Experiments show that our fingerprinting\nsolution (1) holds for a variety of cutting-edge generative models, (2) leads\nto a negligible side effect on generation quality, (3) stays robust against\nimage-level and model-level perturbations, (4) stays hard to be detected by\nadversaries, and (5) converts deepfake detection and attribution into trivial\ntasks and outperforms the recent state-of-the-art baselines. Our solution\ncloses the responsibility loop between publishing pre-trained generative model\ninventions and their possible misuses, which makes it independent of the\ncurrent arms race.", "author": [{"name": "Ning Yu"}, {"name": "Vladislav Skripniuk"}, {"name": "Sahar Abdelnabi"}, {"name": "Mario Fritz"}], "link": [{"@href": "http://arxiv.org/abs/2007.08457v5", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.08457v5", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.GR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.01585v3", "updated": "2021-01-26T14:09:49Z", "published": "2020-08-04T14:27:41Z", "title": "Dark Web Marketplaces and COVID-19: before the vaccine", "summary": "The COVID-19 pandemic has reshaped the demand for goods and services\nworldwide. The combination of a public health emergency, economic distress, and\nmisinformation-driven panic have pushed customers and vendors towards the\nshadow economy. In particular, dark web marketplaces (DWMs), commercial\nwebsites accessible via free software, have gained significant popularity.\nHere, we analyse 851,199 listings extracted from 30 DWMs between January 1,\n2020 and November 16, 2020. We identify 788 listings directly related to\nCOVID-19 products and monitor the temporal evolution of product categories\nincluding Personal Protective Equipment (PPE), medicines (e.g.,\nhydroxyclorochine), and medical frauds. Finally, we compare trends in their\ntemporal evolution with variations in public attention, as measured by Twitter\nposts and Wikipedia page visits. We reveal how the online shadow economy has\nevolved during the COVID-19 pandemic and highlight the importance of a\ncontinuous monitoring of DWMs, especially now that real vaccines are available\nand in short supply. We anticipate our analysis will be of interest both to\nresearchers and public agencies focused on the protection of public health.", "author": [{"name": "Alberto Bracci"}, {"name": "Matthieu Nadini"}, {"name": "Maxwell Aliapoulios"}, {"name": "Damon McCoy"}, {"name": "Ian Gray"}, {"name": "Alexander Teytelboym"}, {"name": "Angela Gallo"}, {"name": "Andrea Baronchelli"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1140/epjds/s13688-021-00259-w"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1140/epjds/s13688-021-00259-w", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.01585v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.01585v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EPJ Data Sci. 10, 6 (2021)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.03951v1", "updated": "2020-08-10T08:17:31Z", "published": "2020-08-10T08:17:31Z", "title": "Behavioral Modeling of Persian Instagram Users to detect Bots", "summary": "Bots are user accounts in social media which are controlled by computer\nprograms. Similar to many other things, they are used for both good and evil\npurposes. One nefarious use-case for them is to spread misinformation or biased\ndata in the networks. There are many pieces of research being performed based\non social media data and their results validity is extremely threatened by the\nharmful data bots spread. Consequently, effective methods and tools are\nrequired for detecting bots and then removing misleading data spread by the\nbots. In the present research, a method for detecting Instagram bots is\nproposed. There is no data set including samples of Instagram bots and genuine\naccounts, thus the current research has begun with gathering such a data set\nwith respect to generality concerns such that it includes 1,000 data points in\neach group. The main approach is supervised machine learning and classic models\nare preferred compared to deep neural networks. The final model is evaluated\nusing multiple methods starting with 10-fold cross-validation. After that,\nconfidence in classification studies and is followed by feature importance\nanalysis and feature behavior against the target probability computed by the\nmodel. In the end, an experiment is designed to measure the models\neffectiveness in an operational environment. Finally, It is strongly concluded\nthat the model performs very well in all evaluation experiments.", "author": [{"name": "Muhammad Bazm"}, {"name": "Masoud Asadpour"}], "link": [{"@href": "http://arxiv.org/abs/2008.03951v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.03951v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2008.08513v1", "updated": "2020-08-19T15:44:36Z", "published": "2020-08-19T15:44:36Z", "title": "Covid-19 infodemic reveals new tipping point epidemiology and a revised\n  $R$ formula", "summary": "Many governments have managed to control their COVID-19 outbreak with a\nsimple message: keep the effective '$R$ number' $R<1$ to prevent widespread\ncontagion and flatten the curve. This raises the question whether a similar\npolicy could control dangerous online 'infodemics' of information,\nmisinformation and disinformation. Here we show, using multi-platform data from\nthe COVID-19 infodemic, that its online spreading instead encompasses a\ndifferent dynamical regime where communities and users within and across\nindependent platforms, sporadically form temporary active links on similar\ntimescales to the viral spreading. This allows material that might have died\nout, to evolve and even mutate. This has enabled niche networks that were\nalready successfully spreading hate and anti-vaccination material, to rapidly\nbecome global super-spreaders of narratives featuring fake COVID-19 treatments,\nanti-Asian sentiment and conspiracy theories. We derive new tools that\nincorporate these coupled social-viral dynamics, including an online $R$, to\nhelp prevent infodemic spreading at all scales: from spreading across platforms\n(e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community,\nor topic. By accounting for similar social and viral timescales, the same\nmathematical theory also offers a quantitative description of other\nunconventional infection profiles such as rumors spreading in financial markets\nand colds spreading in schools.", "author": [{"name": "N. F. Johnson"}, {"name": "N. Velasquez"}, {"name": "O. K. Jha"}, {"name": "H. Niyazi"}, {"name": "R. Leahy"}, {"name": "N. Johnson Restrepo"}, {"name": "R. Sear"}, {"name": "P. Manrique"}, {"name": "Y. Lupu"}, {"name": "P. Devkota"}, {"name": "S. Wuchty"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Working paper. Comments welcome to neiljohnson@gwu.edu"}, "link": [{"@href": "http://arxiv.org/abs/2008.08513v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.08513v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "nlin.AO", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.09194v2", "updated": "2021-03-03T21:41:33Z", "published": "2020-08-20T20:25:18Z", "title": "On Attribution of Deepfakes", "summary": "Progress in generative modelling, especially generative adversarial networks,\nhave made it possible to efficiently synthesize and alter media at scale.\nMalicious individuals now rely on these machine-generated media, or deepfakes,\nto manipulate social discourse. In order to ensure media authenticity, existing\nresearch is focused on deepfake detection. Yet, the adversarial nature of\nframeworks used for generative modeling suggests that progress towards\ndetecting deepfakes will enable more realistic deepfake generation. Therefore,\nit comes at no surprise that developers of generative models are under the\nscrutiny of stakeholders dealing with misinformation campaigns. At the same\ntime, generative models have a lot of positive applications. As such, there is\na clear need to develop tools that ensure the transparent use of generative\nmodeling, while minimizing the harm caused by malicious applications.\n  Our technique optimizes over the source of entropy of each generative model\nto probabilistically attribute a deepfake to one of the models. We evaluate our\nmethod on the seminal example of face synthesis, demonstrating that our\napproach achieves 97.62% attribution accuracy, and is less sensitive to\nperturbations and adversarial examples. We discuss the ethical implications of\nour work, identify where our technique can be used, and highlight that a more\nmeaningful legislative framework is required for a more transparent and ethical\nuse of generative modeling. Finally, we argue that model developers should be\ncapable of claiming plausible deniability and propose a second framework to do\nso -- this allows a model developer to produce evidence that they did not\nproduce media that they are being accused of having produced.", "author": [{"name": "Baiwu Zhang"}, {"name": "Jin Peng Zhou"}, {"name": "Ilia Shumailov"}, {"name": "Nicolas Papernot"}], "link": [{"@href": "http://arxiv.org/abs/2008.09194v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.09194v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.13632v1", "updated": "2020-08-28T14:52:08Z", "published": "2020-08-28T14:52:08Z", "title": "TRUSTD: Combat Fake Content using Blockchain and Collective Signature\n  Technologies", "summary": "The growing trend of sharing news/contents, through social media platforms\nand the World Wide Web has been seen to impact our perception of the truth,\naltering our views about politics, economics, relationships, needs and wants.\nThis is because of the growing spread of misinformation and disinformation\nintentionally or unintentionally by individuals and organizations. This trend\nhas grave political, social, ethical, and privacy implications for society due\nto 1) the rapid developments in the field of Machine Learning (ML) and Deep\nLearning (DL) algorithms in creating realistic-looking yet fake digital content\n(such as text, images, and videos), 2) the ability to customize the content\nfeeds and to create a polarized so-called \"filter-bubbles\" leveraging the\navailability of the big-data. Therefore, there is an ethical need to combat the\nflow of fake content. This paper attempts to resolve some of the aspects of\nthis combat by presenting a high-level overview of TRUSTD, a blockchain and\ncollective signature-based ecosystem to help content creators in getting their\ncontent backed by the community, and to help users judge on the credibility and\ncorrectness of these contents.", "author": [{"name": "Zakwan Jaroucheh"}, {"name": "Mohamad Alissa"}, {"name": "William J Buchanan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/ICBC48266.2020.9169435"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/ICBC48266.2020.9169435", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.13632v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.13632v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: text overlap with arXiv:1812.00315,\n  arXiv:1807.06346, arXiv:1904.05386 by other authors"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "2020 IEEE International Conference on Blockchain and\n  Cryptocurrency (ICBC), Toronto, ON, Canada, 2020, pp. 1-3"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2009.04508v2", "updated": "2020-10-26T14:38:00Z", "published": "2020-09-09T18:30:44Z", "title": "Narrative Maps: An Algorithmic Approach to Represent and Extract\n  Information Narratives", "summary": "Narratives are fundamental to our perception of the world and are pervasive\nin all activities that involve the representation of events in time. Yet,\nmodern online information systems do not incorporate narratives in their\nrepresentation of events occurring over time. This article aims to bridge this\ngap, combining the theory of narrative representations with the data from\nmodern online systems. We make three key contributions: a theory-driven\ncomputational representation of narratives, a novel extraction algorithm to\nobtain these representations from data, and an evaluation of our approach. In\nparticular, given the effectiveness of visual metaphors, we employ a route map\nmetaphor to design a narrative map representation. The narrative map\nrepresentation illustrates the events and stories in the narrative as a series\nof landmarks and routes on the map. Each element of our representation is\nbacked by a corresponding element from formal narrative theory, thus providing\na solid theoretical background to our method. Our approach extracts the\nunderlying graph structure of the narrative map using a novel optimization\ntechnique focused on maximizing coherence while respecting structural and\ncoverage constraints. We showcase the effectiveness of our approach by\nperforming a user evaluation to assess the quality of the representation,\nmetaphor, and visualization. Evaluation results indicate that the Narrative Map\nrepresentation is a powerful method to communicate complex narratives to\nindividuals. Our findings have implications for intelligence analysts,\ncomputational journalists, and misinformation researchers.", "author": [{"name": "Brian Keith"}, {"name": "Tanushree Mitra"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "33 pages, 15 figures, CSCW 2020"}, "link": [{"@href": "http://arxiv.org/abs/2009.04508v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.04508v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.07255v1", "updated": "2020-09-15T17:44:34Z", "published": "2020-09-15T17:44:34Z", "title": "Sustained Online Amplification of COVID-19 Elites in the United States", "summary": "The ongoing, fluid nature of the COVID-19 pandemic requires individuals to\nregularly seek information about best health practices, local community\nspreading, and public health guidelines. In the absence of a unified response\nto the pandemic in the United States and clear, consistent directives from\nfederal and local officials, people have used social media to collectively\ncrowdsource COVID-19 elites, a small set of trusted COVID-19 information\nsources. We take a census of COVID-19 crowdsourced elites in the United States\nwho have received sustained attention on Twitter during the pandemic. Using a\nmixed methods approach with a panel of Twitter users linked to public U.S.\nvoter registration records, we find that journalists, media outlets, and\npolitical accounts have been consistently amplified around COVID-19, while\nepidemiologists, public health officials, and medical professionals make up\nonly a small portion of all COVID-19 elites on Twitter. We show that COVID-19\nelites vary considerably across demographic groups, and that there are notable\nracial, geographic, and political similarities and disparities between various\ngroups and the demographics of their elites. With this variation in mind, we\ndiscuss the potential for using the disproportionate online voice of\ncrowdsourced COVID-19 elites to equitably promote timely public health\ninformation and mitigate rampant misinformation.", "author": [{"name": "Ryan J. Gallagher"}, {"name": "Larissa Doroshenko"}, {"name": "Sarah Shugars"}, {"name": "David Lazer"}, {"name": "Brooke Foucault Welles"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1177/20563051211024957"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1177/20563051211024957", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2009.07255v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.07255v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 2 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Social Media + Society, 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.08395v1", "updated": "2020-09-17T16:13:21Z", "published": "2020-09-17T16:13:21Z", "title": "A Multimodal Memes Classification: A Survey and Open Research Issues", "summary": "Memes are graphics and text overlapped so that together they present concepts\nthat become dubious if one of them is absent. It is spread mostly on social\nmedia platforms, in the form of jokes, sarcasm, motivating, etc. After the\nsuccess of BERT in Natural Language Processing (NLP), researchers inclined to\nVisual-Linguistic (VL) multimodal problems like memes classification, image\ncaptioning, Visual Question Answering (VQA), and many more. Unfortunately, many\nmemes get uploaded each day on social media platforms that need automatic\ncensoring to curb misinformation and hate. Recently, this issue has attracted\nthe attention of researchers and practitioners. State-of-the-art methods that\nperformed significantly on other VL dataset, tends to fail on memes\nclassification. In this context, this work aims to conduct a comprehensive\nstudy on memes classification, generally on the VL multimodal problems and\ncutting edge solutions. We propose a generalized framework for VL problems. We\ncover the early and next-generation works on VL problems. Finally, we identify\nand articulate several open research issues and challenges. This is the first\nstudy that presents the generalized view of the advanced classification\ntechniques concerning memes classification to the best of our knowledge. We\nbelieve this study presents a clear road-map for the Machine Learning (ML)\nresearch community to implement and enhance memes classification techniques.", "author": [{"name": "Tariq Habib Afridi"}, {"name": "Aftab Alam"}, {"name": "Muhammad Numan Khan"}, {"name": "Jawad Khan"}, {"name": "Young-Koo Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a survey paper on recent state of the art VL models that can\n  be used for memes classification. it has 15 pages and 2 figures"}, "link": [{"@href": "http://arxiv.org/abs/2009.08395v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.08395v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.13859v1", "updated": "2020-09-29T08:32:32Z", "published": "2020-09-29T08:32:32Z", "title": "Fake News Spreader Detection on Twitter using Character N-Grams.\n  Notebook for PAN at CLEF 2020", "summary": "The authors of fake news often use facts from verified news sources and mix\nthem with misinformation to create confusion and provoke unrest among the\nreaders. The spread of fake news can thereby have serious implications on our\nsociety. They can sway political elections, push down the stock price or crush\nreputations of corporations or public figures. Several websites have taken on\nthe mission of checking rumors and allegations, but are often not fast enough\nto check the content of all the news being disseminated. Especially social\nmedia websites have offered an easy platform for the fast propagation of\ninformation. Towards limiting fake news from being propagated among social\nmedia users, the task of this year's PAN 2020 challenge lays the focus on the\nfake news spreaders. The aim of the task is to determine whether it is possible\nto discriminate authors that have shared fake news in the past from those that\nhave never done it. In this notebook, we describe our profiling system for the\nfake news detection task on Twitter. For this, we conduct different feature\nextraction techniques and learning experiments from a multilingual perspective,\nnamely English and Spanish. Our final submitted systems use character n-grams\nas features in combination with a linear SVM for English and Logistic\nRegression for the Spanish language. Our submitted models achieve an overall\naccuracy of 73% and 79% on the English and Spanish official test set,\nrespectively. Our experiments show that it is difficult to differentiate\nsolidly fake news spreaders on Twitter from users who share credible\ninformation leaving room for further investigations. Our model ranked 3rd out\nof 72 competitors.", "author": [{"name": "Inna Vogel"}, {"name": "Meghana Meghana"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF 2020 Labs and Workshops, Notebook Papers"}, "link": [{"@href": "http://arxiv.org/abs/2009.13859v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.13859v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.00600v1", "updated": "2020-10-01T18:00:03Z", "published": "2020-10-01T18:00:03Z", "title": "#Election2020: The First Public Twitter Dataset on the 2020 US\n  Presidential Election", "summary": "The integrity of democratic political discourse is at the core to guarantee\nfree and fair elections. With social media often dictating the tones and trends\nof politics-related discussion, it is of paramount important to be able to\nstudy online chatter, especially in the run up to important voting events, like\nin the case of the upcoming November 3, 2020 U.S. Presidential Election.\nLimited access to social media data is often the first barrier to impede,\nhinder, or slow down progress, and ultimately our understanding of online\npolitical discourse. To mitigate this issue and try to empower the\nComputational Social Science research community, we decided to publicly release\na massive-scale, longitudinal dataset of U.S. politics- and election-related\ntweets. This multilingual dataset that we have been collecting for over one\nyear encompasses hundreds of millions of tweets and tracks all salient U.S.\npolitics trends, actors, and events between 2019 and 2020. It predates and\nspans the whole period of Republican and Democratic primaries, with real-time\ntracking of all presidential contenders of both sides of the isle. After that,\nit focuses on presidential and vice-presidential candidates. Our dataset\nrelease is curated, documented and will be constantly updated on a\nweekly-basis, until the November 3, 2020 election and beyond. We hope that the\nacademic community, computational journalists, and research practitioners alike\nwill all take advantage of our dataset to study relevant scientific and social\nissues, including problems like misinformation, information manipulation,\ninterference, and distortion of online political discourse that have been\nprevalent in the context of recent election events in the United States and\nworldwide.\n  Our dataset is available at:\nhttps://github.com/echen102/us-pres-elections-2020", "author": [{"name": "Emily Chen"}, {"name": "Ashok Deb"}, {"name": "Emilio Ferrara"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Our dataset is available at:\n  https://github.com/echen102/us-pres-elections-2020"}, "link": [{"@href": "http://arxiv.org/abs/2010.00600v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.00600v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.02097v1", "updated": "2020-10-05T15:34:52Z", "published": "2020-10-05T15:34:52Z", "title": "FaNDS: Fake News Detection System Using Energy Flow", "summary": "Recently, the term \"fake news\" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.", "author": [{"name": "Jiawei Xu"}, {"name": "Vladimir Zadorozhny"}, {"name": "Danchen Zhang"}, {"name": "John Grant"}], "link": [{"@href": "http://arxiv.org/abs/2010.02097v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.02097v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.06249v4", "updated": "2021-08-19T04:58:00Z", "published": "2020-11-12T08:04:32Z", "title": "Characterizing the roles of bots during the COVID-19 infodemic on\n  Twitter", "summary": "An infodemic is an emerging phenomenon caused by an overabundance of\ninformation online. This proliferation of information makes it difficult for\nthe public to distinguish trustworthy news and credible information from\nuntrustworthy sites and non-credible sources. The perils of an infodemic\ndebuted with the outbreak of the COVID-19 pandemic and bots (i.e., automated\naccounts controlled by a set of algorithms) that are suspected of spreading the\ninfodemic. Although previous research has revealed that bots played a central\nrole in spreading misinformation during major political events, how bots\nbehaved during the infodemic is unclear. In this paper, we examined the roles\nof bots in the case of the COVID-19 infodemic and the diffusion of non-credible\ninformation such as \"5G\" and \"Bill Gates\" conspiracy theories and content\nrelated to \"Trump\" and \"WHO\" by analyzing retweet networks and retweeted items.\nWe show the segregated topology of their retweet networks, which indicates that\nright-wing self-media accounts and conspiracy theorists may lead to this\nopinion cleavage, while malicious bots might favor amplification of the\ndiffusion of non-credible information. Although the basic influence of\ninformation diffusion could be larger in human users than bots, the effects of\nbots are non-negligible under an infodemic situation.", "author": [{"name": "Wentao Xu"}, {"name": "Kazutoshi Sasahara"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted by Journal of Computational Social Science (August 2021)"}, "link": [{"@href": "http://arxiv.org/abs/2011.06249v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.06249v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "J.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.08787v1", "updated": "2020-11-17T17:30:10Z", "published": "2020-11-17T17:30:10Z", "title": "The COVID19 infodemic. The role and place of academics in science\n  communication", "summary": "As the COVID19 pandemic has spread across the world, a concurrent pandemic of\ninformation has spread with it. Deemed an infodemic by the World Health\nOrganization, and described as an overabundance of information, some accurate,\nsome not, that occurs during an epidemic, this proliferation of data, research\nand opinions provides both opportunities and challenges for academics.\nAcademics and scientists have a key role to play in the solutions to the\ninfodemic challenge: as educators, influences and communicators, even where\ntheir expertise and experience does not align precisely with the SARS-Cov2\nvirus and its impacts.\n  Successful communication requires a better understanding of how the public\nseeks, understands and processes scientific information, however, in order to\nmaximise the ways in which experts engage with traditional and social media and\nto make sure that such engagement does not add to confusion and misinformation\nalongside efforts to counter or challenge it. This paper will outline the key\nadvantages to be had from greater engagement with COVID19 discussions, the\npopular channels through which such discussions take place and through which\ninformation is disseminated. It also warns against the common pitfalls those\nwho choose to engage might encounter, whilst stressing that the disadvantages\nof doing so are far outweighed by the advantages such engagement offers.", "author": {"name": "Jennifer Cole"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "17 Pages"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Global Journal of Medicine and Public Health Vol 9 Issue 2 2020"}, "link": [{"@href": "http://arxiv.org/abs/2011.08787v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.08787v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.13253v1", "updated": "2020-11-26T11:50:45Z", "published": "2020-11-26T11:50:45Z", "title": "Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking", "summary": "The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.", "author": [{"name": "Rutvik Vijjali"}, {"name": "Prathyush Potluri"}, {"name": "Siddharth Kumar"}, {"name": "Sundeep Teki"}], "link": [{"@href": "http://arxiv.org/abs/2011.13253v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.13253v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.01876v1", "updated": "2020-12-03T12:45:29Z", "published": "2020-12-03T12:45:29Z", "title": "Optimizing sensors placement in complex networks for localization of\n  hidden signal source: A review", "summary": "As the world becomes more and more interconnected, our everyday objects\nbecome part of the Internet of Things, and our lives get more and more mirrored\nin virtual reality, where every piece of~information, including misinformation,\nfake news and malware, can spread very fast practically anonymously. To\nsuppress such uncontrolled spread, efficient computer systems and algorithms\ncapable to~track down such malicious information spread have to be developed.\nCurrently, the most effective methods for source localization are based on\nsensors which provide the times at which they detect the~spread. We investigate\nthe problem of the optimal placement of such sensors in complex networks and\npropose a new graph measure, called Collective Betweenness, which we compare\nagainst four other metrics. Extensive numerical tests are performed on\ndifferent types of complex networks over the wide ranges of densities of\nsensors and stochasticities of signal. In these tests, we discovered clear\ndifference in comparative performance of the investigated optimal placement\nmethods between real or scale-free synthetic networks versus narrow degree\ndistribution networks. The former have a clear region for any given method's\ndominance in contrast to the latter where the performance maps are less\nhomogeneous. We find that while choosing the best method is very network and\nspread dependent, there are two methods that consistently stand out. High\nVariance Observers seem to do very well for spread with low stochasticity\nwhereas Collective Betwenness, introduced in this paper, thrives when the\nspread is highly unpredictable.", "author": [{"name": "Robert Paluch"}, {"name": "\u0141ukasz G. Gajewski"}, {"name": "Janusz A. Ho\u0142yst"}, {"name": "Boleslaw K. Szymanski"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.future.2020.06.023"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.future.2020.06.023", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2012.01876v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.01876v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "28 pages, 18 figures, 11 tables"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Future Generation Computer Systems, Volume 112, November 2020,\n  Pages 1070-1092"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.data-an", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.02606v2", "updated": "2020-12-07T02:59:24Z", "published": "2020-12-04T14:03:06Z", "title": "TrollHunter2020: Real-Time Detection of Trolling Narratives on Twitter\n  During the 2020 US Elections", "summary": "This paper presents TrollHunter2020, a real-time detection mechanism we used\nto hunt for trolling narratives on Twitter during the 2020 U.S. elections.\nTrolling narratives form on Twitter as alternative explanations of polarizing\nevents like the 2020 U.S. elections with the goal to conduct information\noperations or provoke emotional response. Detecting trolling narratives thus is\nan imperative step to preserve constructive discourse on Twitter and remove an\ninflux of misinformation. Using existing techniques, this takes time and a\nwealth of data, which, in a rapidly changing election cycle with high stakes,\nmight not be available. To overcome this limitation, we developed\nTrollHunter2020 to hunt for trolls in real-time with several dozens of trending\nTwitter topics and hashtags corresponding to the candidates' debates, the\nelection night, and the election aftermath. TrollHunter2020 collects trending\ndata and utilizes a correspondence analysis to detect meaningful relationships\nbetween the top nouns and verbs used in constructing trolling narratives while\nthey emerge on Twitter. Our results suggest that the TrollHunter2020 indeed\ncaptures the emerging trolling narratives in a very early stage of an unfolding\npolarizing event. We discuss the utility of TrollHunter2020 for early detection\nof information operations or trolling and the implications of its use in\nsupporting a constrictive discourse on the platform around polarizing topics.", "author": [{"name": "Peter Jachim"}, {"name": "Filipo Sharevski"}, {"name": "Emma Pieroni"}], "link": [{"@href": "http://arxiv.org/abs/2012.02606v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.02606v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.08726v4", "updated": "2021-03-30T23:51:15Z", "published": "2020-12-16T03:51:54Z", "title": "Responsible Disclosure of Generative Models Using Scalable\n  Fingerprinting", "summary": "Over the past six years, deep generative models have achieved a qualitatively\nnew level of performance. Generated data has become difficult, if not\nimpossible, to be distinguished from real data. While there are plenty of use\ncases that benefit from this technology, there are also strong concerns on how\nthis new technology can be misused to spoof sensors, generate deep fakes, and\nenable misinformation at scale. Unfortunately, current deep fake detection\nmethods are not sustainable, as the gap between real and fake continues to\nclose. In contrast, our work enables a responsible disclosure of such\nstate-of-the-art generative models, that allows researchers and companies to\nfingerprint their models, so that the generated samples containing a\nfingerprint can be accurately detected and attributed to a source. Our\ntechnique achieves this by an efficient and scalable ad-hoc generation of a\nlarge population of models with distinct fingerprints. Our recommended\noperation point uses a 128-bit fingerprint which in principle results in more\nthan $10^{36}$ identifiable models. Experiments show that our method fulfills\nkey properties of a fingerprinting mechanism and achieves effectiveness in deep\nfake detection and attribution.", "author": [{"name": "Ning Yu"}, {"name": "Vladislav Skripniuk"}, {"name": "Dingfan Chen"}, {"name": "Larry Davis"}, {"name": "Mario Fritz"}], "link": [{"@href": "http://arxiv.org/abs/2012.08726v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.08726v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.GR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.01142v1", "updated": "2020-12-28T13:07:42Z", "published": "2020-12-28T13:07:42Z", "title": "Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study", "summary": "Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.", "author": [{"name": "Michal Choras"}, {"name": "Konstantinos Demestichas"}, {"name": "Agata Gielczyk"}, {"name": "Alvaro Herrero"}, {"name": "Pawel Ksieniewicz"}, {"name": "Konstantina Remoundou"}, {"name": "Daniel Urda"}, {"name": "Michal Wozniak"}], "link": [{"@href": "http://arxiv.org/abs/2101.01142v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.01142v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.01688v2", "updated": "2021-02-25T15:42:49Z", "published": "2021-01-05T18:21:03Z", "title": "What social media told about us in the time of COVID-19: a scoping\n  review", "summary": "With the onset of COVID-19 pandemic, social media has rapidly become a\ncrucial communication tool for information generation, dissemination, and\nconsumption. In this scoping review, we selected and examined peer-reviewed\nempirical studies relating to COVID-19 and social media during the first\noutbreak starting in November 2019 until May 2020. From an analysis of 81\nstudies, we identified five overarching public health themes concerning the\nrole of online social platforms and COVID-19. These themes focused on: (i)\nsurveying public attitudes, (ii) identifying infodemics, (iii) assessing mental\nhealth, (iv) detecting or predicting COVID-19 cases, (v) analyzing government\nresponses to the pandemic, and (vi) evaluating quality of health information in\nprevention education videos. Furthermore, our review highlights the paucity of\nstudies on the application of machine learning on social media data related to\nCOVID-19 and a lack of studies documenting real-time surveillance developed\nwith social media data on COVID-19. For COVID-19, social media can play a\ncrucial role in disseminating health information as well as tackling infodemics\nand misinformation.", "author": [{"name": "Shu-Feng Tsao"}, {"name": "Helen Chen"}, {"name": "Therese Tisseverasinghe"}, {"name": "Yang Yang"}, {"name": "Lianghua Li"}, {"name": "Zahid A. Butt"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/S2589-7500(20)30315-0"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/S2589-7500(20)30315-0", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2101.01688v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.01688v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "20 pages excluding reference list and table 2. 2 figures. Accepted\n  manuscripts by Lancet Digital Health"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The Lancet Digital Health, Review, Vol 3, Iss 3, E175-E194, March\n  01, 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.03841v1", "updated": "2021-01-11T12:23:41Z", "published": "2021-01-11T12:23:41Z", "title": "Model Generalization on COVID-19 Fake News Detection", "summary": "Amid the pandemic COVID-19, the world is facing unprecedented infodemic with\nthe proliferation of both fake and real information. Considering the\nproblematic consequences that the COVID-19 fake-news have brought, the\nscientific community has put effort to tackle it. To contribute to this fight\nagainst the infodemic, we aim to achieve a robust model for the COVID-19\nfake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking\ntwo separate approaches: 1) fine-tuning transformers based language models with\nrobust loss functions and 2) removing harmful training instances through\ninfluence calculation. We further evaluate the robustness of our models by\nevaluating on different COVID-19 misinformation test set (Tweets-19) to\nunderstand model generalization ability. With the first approach, we achieve\n98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on\nthe Tweets-19 highest. On the contrary, by performing influence data cleansing,\nour model with 99% cleansing percentage can achieve 54.33% W-F1 score on\nTweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news\ntest sets, we suggest the importance of model generalization ability in this\ntask to step forward to tackle the COVID-19 fake-news problem in online social\nmedia platforms.", "author": [{"name": "Yejin Bang"}, {"name": "Etsuko Ishii"}, {"name": "Samuel Cahyawijaya"}, {"name": "Ziwei Ji"}, {"name": "Pascale Fung"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CONSTRAINT Workshop 2021 (Camera Ready Version)"}, "link": [{"@href": "http://arxiv.org/abs/2101.03841v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.03841v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.06278v3", "updated": "2021-04-21T18:00:07Z", "published": "2021-01-15T19:00:42Z", "title": "COSMOS: Catching Out-of-Context Misinformation with Self-Supervised\n  Learning", "summary": "Despite the recent attention to DeepFakes, one of the most prevalent ways to\nmislead audiences on social media is the use of unaltered images in a new but\nfalse context. To address these challenges and support fact-checkers, we\npropose a new method that automatically detects out-of-context image and text\npairs. Our key insight is to leverage the grounding of image with text to\ndistinguish out-of-context scenarios that cannot be disambiguated with language\nalone. We propose a self-supervised training strategy where we only need a set\nof captioned images. At train time, our method learns to selectively align\nindividual objects in an image with textual claims, without explicit\nsupervision. At test time, we check if both captions correspond to the same\nobject(s) in the image but are semantically different, which allows us to make\nfairly accurate out-of-context predictions. Our method achieves 85%\nout-of-context detection accuracy. To facilitate benchmarking of this task, we\ncreate a large-scale dataset of 200K images with 450K textual captions from a\nvariety of news websites, blogs, and social media posts. The dataset and source\ncode is publicly available at\nhttps://shivangi-aneja.github.io/projects/cosmos/.", "author": [{"name": "Shivangi Aneja"}, {"name": "Chris Bregler"}, {"name": "Matthias Nie\u00dfner"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Video : https://youtu.be/riI3Cl2xy10"}, "link": [{"@href": "http://arxiv.org/abs/2101.06278v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.06278v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.08436v1", "updated": "2021-02-16T20:18:59Z", "published": "2021-02-16T20:18:59Z", "title": "Social Bots and Social Media Manipulation in 2020: The Year in Review", "summary": "The year 2020 will be remembered for two events of global significance: the\nCOVID-19 pandemic and 2020 U.S. Presidential Election. In this chapter, we\nsummarize recent studies using large public Twitter data sets on these issues.\nWe have three primary objectives. First, we delineate epistemological and\npractical considerations when combining the traditions of computational\nresearch and social science research. A sensible balance should be struck when\nthe stakes are high between advancing social theory and concrete, timely\nreporting of ongoing events. We additionally comment on the computational\nchallenges of gleaning insight from large amounts of social media data. Second,\nwe characterize the role of social bots in social media manipulation around the\ndiscourse on the COVID-19 pandemic and 2020 U.S. Presidential Election. Third,\nwe compare results from 2020 to prior years to note that, although bot accounts\nstill contribute to the emergence of echo-chambers, there is a transition from\nstate-sponsored campaigns to domestically emergent sources of distortion.\nFurthermore, issues of public health can be confounded by political\norientation, especially from localized communities of actors who spread\nmisinformation. We conclude that automation and social media manipulation pose\nissues to a healthy and democratic discourse, precisely because they distort\nrepresentation of pluralism within the public sphere.", "author": [{"name": "Ho-Chun Herbert Chang"}, {"name": "Emily Chen"}, {"name": "Meiqing Zhang"}, {"name": "Goran Muric"}, {"name": "Emilio Ferrara"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Book Chapter submitted for the Handbook of Computational Social\n  Science"}, "link": [{"@href": "http://arxiv.org/abs/2102.08436v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.08436v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.11105v2", "updated": "2021-04-22T16:05:49Z", "published": "2021-02-22T15:26:36Z", "title": "REMOD: Relation Extraction for Modeling Online Discourse", "summary": "The enormous amount of discourse taking place online poses challenges to the\nfunctioning of a civil and informed public sphere. Efforts to standardize\nonline discourse data, such as ClaimReview, are making available a wealth of\nnew data about potentially inaccurate claims, reviewed by third-party\nfact-checkers. These data could help shed light on the nature of online\ndiscourse, the role of political elites in amplifying it, and its implications\nfor the integrity of the online information ecosystem. Unfortunately, the\nsemi-structured nature of much of this data presents significant challenges\nwhen it comes to modeling and reasoning about online discourse. A key challenge\nis relation extraction, which is the task of determining the semantic\nrelationships between named entities in a claim. Here we develop a novel\nsupervised learning method for relation extraction that combines graph\nembedding techniques with path traversal on semantic dependency graphs. Our\napproach is based on the intuitive observation that knowledge of the entities\nalong the path between the subject and object of a triple (e.g.\nWashington,_D.C.}, and United_States_of_America) provides useful information\nthat can be leveraged for extracting its semantic relation (i.e. capitalOf). As\nan example of a potential application of this technique for modeling online\ndiscourse, we show that our method can be integrated into a pipeline to reason\nabout potential misinformation claims.", "author": [{"name": "Matthew Sumpter"}, {"name": "Giovanni Luca Ciampaglia"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/2102.11105v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.11105v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.03409v1", "updated": "2021-03-05T00:48:23Z", "published": "2021-03-05T00:48:23Z", "title": "A General Method to Find Highly Coordinating Communities in Social Media\n  through Inferred Interaction Links", "summary": "Political misinformation, astroturfing and organised trolling are online\nmalicious behaviours with significant real-world effects. Many previous\napproaches examining these phenomena have focused on broad campaigns rather\nthan the small groups responsible for instigating or sustaining them. To reveal\nlatent (i.e., hidden) networks of cooperating accounts, we propose a novel\ntemporal window approach that relies on account interactions and metadata\nalone. It detects groups of accounts engaging in various behaviours that, in\nconcert, come to execute different goal-based strategies, a number of which we\ndescribe. The approach relies upon a pipeline that extracts relevant elements\nfrom social media posts, infers connections between accounts based on criteria\nmatching the coordination strategies to build an undirected weighted network of\naccounts, which is then mined for communities exhibiting high levels of\nevidence of coordination using a novel community extraction method. We address\nthe temporal aspect of the data by using a windowing mechanism, which may be\nsuitable for near real-time application. We further highlight consistent\ncoordination with a sliding frame across multiple windows and application of a\ndecay factor. Our approach is compared with other recent similar processing\napproaches and community detection methods and is validated against two\nrelevant datasets with ground truth data, using content, temporal, and network\nanalyses, as well as with the design, training and application of three\none-class classifiers built using the ground truth; its utility is furthermore\ndemonstrated in two case studies of contentious online discussions.", "author": [{"name": "Derek Weber"}, {"name": "Frank Neumann"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "58 pages, 25 figures, submitted to the International Journal of\n  Social Network Analysis and Mining (SNAM) as an expansion to an ASONAM'20\n  paper (arXiv:2010.08180)"}, "link": [{"@href": "http://arxiv.org/abs/2103.03409v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.03409v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.15581v1", "updated": "2021-03-29T12:56:59Z", "published": "2021-03-29T12:56:59Z", "title": "Supporting verification of news articles with automated search for\n  semantically similar articles", "summary": "Fake information poses one of the major threats for society in the 21st\ncentury. Identifying misinformation has become a key challenge due to the\namount of fake news that is published daily. Yet, no approach is established\nthat addresses the dynamics and versatility of fake news editorials. Instead of\nclassifying content, we propose an evidence retrieval approach to handle fake\nnews. The learning task is formulated as an unsupervised machine learning\nproblem. For validation purpose, we provide the user with a set of news\narticles from reliable news sources supporting the hypothesis of the news\narticle in query and the final decision is left to the user. Technically we\npropose a two-step process: (i) Aggregation-step: With information extracted\nfrom the given text we query for similar content from reliable news sources.\n(ii) Refining-step: We narrow the supporting evidence down by measuring the\nsemantic distance of the text with the collection from step (i). The distance\nis calculated based on Word2Vec and the Word Mover's Distance. In our\nexperiments, only content that is below a certain distance threshold is\nconsidered as supporting evidence. We find that our approach is agnostic to\nconcept drifts, i.e. the machine learning task is independent of the hypotheses\nin a text. This makes it highly adaptable in times where fake news is as\ndiverse as classical news is. Our pipeline offers the possibility for further\nanalysis in the future, such as investigating bias and differences in news\nreporting.", "author": [{"name": "Vishwani Gupta"}, {"name": "Katharina Beckh"}, {"name": "Sven Giesselbach"}, {"name": "Dennis Wegener"}, {"name": "Tim Wirtz"}], "link": [{"@href": "http://arxiv.org/abs/2103.15581v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.15581v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.01140v1", "updated": "2021-04-02T16:39:23Z", "published": "2021-04-02T16:39:23Z", "title": "The polarising effect of Review Bomb", "summary": "This study discusses the Review Bomb, a phenomenon consisting of a massive\nattack by groups of Internet users on a website that displays users' review on\nproducts. It gained attention, especially on websites that aggregate numerical\nratings. Although this phenomenon can be considered an example of online\nmisinformation, it differs from conventional spam review, which happens within\nlarger time spans. In particular, the Bomb occurs suddenly and for a short\ntime, because in this way it leverages the notorious problem of cold-start: if\nreviews are submitted by a lot of fresh new accounts, it makes hard to justify\npreventative measures. The present research work is focused on the case of The\nLast of Us Part II, a video game published by Sony, that was the target of the\nwidest phenomenon of Review Bomb, occurred in June 2020. By performing an\nobservational analysis of a linguistic corpus of English reviews and the\nfeatures of its users, this study confirms that the Bomb was an ideological\nattack aimed at breaking down the rating system of the platform Metacritic.\nEvidence supports that the bombing had the unintended consequence to induce a\nreaction from users, ending into a consistent polarisation of ratings towards\nextreme values. The results not only display the theory of polarity in online\nreviews, but them also provide insights for the research on the problem of\ncold-start detection of spam review. In particular, it illustrates the\nrelevance of detecting users discussing contextual elements instead of the\nproduct and users with anomalous features.", "author": [{"name": "Venera Tomaselli"}, {"name": "Giulio Giacomo Cantone"}, {"name": "Valeria Mazzeo"}], "link": [{"@href": "http://arxiv.org/abs/2104.01140v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.01140v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.01828v1", "updated": "2021-04-05T09:45:14Z", "published": "2021-04-05T09:45:14Z", "title": "When Can Liquid Democracy Unveil the Truth?", "summary": "In this paper, we investigate the so-called ODP-problem that has been\nformulated by Caragiannis and Micha [10]. Here, we are in a setting with two\nelection alternatives out of which one is assumed to be correct. In ODP, the\ngoal is to organise the delegations in the social network in order to maximize\nthe probability that the correct alternative, referred to as ground truth, is\nelected. While the problem is known to be computationally hard, we strengthen\nexisting hardness results by providing a novel strong approximation hardness\nresult: For any positive constant $C$, we prove that, unless $P=NP$, there is\nno polynomial-time algorithm for ODP that achieves an approximation guarantee\nof $\\alpha \\ge (\\ln n)^{-C}$, where $n$ is the number of voters. The reduction\ndesigned for this result uses poorly connected social networks in which some\nvoters suffer from misinformation. Interestingly, under some hypothesis on\neither the accuracies of voters or the connectivity of the network, we obtain a\npolynomial-time $1/2$-approximation algorithm. This observation proves formally\nthat the connectivity of the social network is a key feature for the efficiency\nof the liquid democracy paradigm. Lastly, we run extensive simulations and\nobserve that simple algorithms (working either in a centralized or\ndecentralized way) outperform direct democracy on a large class of instances.\nOverall, our contributions yield new insights on the question in which\nsituations liquid democracy can be beneficial.", "author": [{"name": "Ruben Becker"}, {"name": "Gianlorenzo D'Angelo"}, {"name": "Esmaeil Delfaraz"}, {"name": "Hugo Gilbert"}], "link": [{"@href": "http://arxiv.org/abs/2104.01828v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.01828v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.02752v1", "updated": "2021-04-06T19:23:44Z", "published": "2021-04-06T19:23:44Z", "title": "Multiscale Governance", "summary": "Future societal systems will be characterized by heterogeneous human\nbehaviors and also collective action. The interaction between local systems and\nglobal systems will be complex. Humandemics will propagate because of the\npathways that connect the different systems and several invariant behaviors and\npatterns that have emerged globally. On the contrary, infodemics of\nmisinformation can be a risk as it has occurred in the COVID-19 pandemic. The\nemerging fragility or robustness of the system will depend on how this complex\nnetwork of systems is governed. Future societal systems will not be only\nmultiscale in terms of the social dimension, but also in the temporality.\nNecessary and proper prevention and response systems based on complexity, ethic\nand multi-scale governance will be required. Real-time response systems are the\nbasis for resilience to be the foundation of robust societies. A top-down\napproach led by Governmental organs for managing humandemics is not sufficient\nand may be only effective if policies are very restrictive and their efficacy\ndepends not only in the measures implemented but also on the dynamics of the\npolicies and the population perception and compliance. This top-down approach\nis even weaker if there is not national and international coordination.\nCoordinating top-down agencies with bottom-up constructs will be the design\nprinciple. Multi-scale governance integrates decision-making processes with\nsignaling, sensing and leadership mechanisms to drive thriving societal systems\nwith real-time sensitivity.", "author": [{"name": "David Pastor-Escuredo"}, {"name": "Philip Treleaven"}], "link": [{"@href": "http://arxiv.org/abs/2104.02752v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.02752v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.05321v1", "updated": "2021-04-12T10:01:44Z", "published": "2021-04-12T10:01:44Z", "title": "Combining exogenous and endogenous signals with a semi-supervised\n  co-attention network for early detection of COVID-19 fake tweets", "summary": "Fake tweets are observed to be ever-increasing, demanding immediate\ncountermeasures to combat their spread. During COVID-19, tweets with\nmisinformation should be flagged and neutralized in their early stages to\nmitigate the damages. Most of the existing methods for early detection of fake\nnews assume to have enough propagation information for large labeled tweets --\nwhich may not be an ideal setting for cases like COVID-19 where both aspects\nare largely absent. In this work, we present ENDEMIC, a novel early detection\nmodel which leverages exogenous and endogenous signals related to tweets, while\nlearning on limited labeled data. We first develop a novel dataset, called CTF\nfor early COVID-19 Twitter fake news, with additional behavioral test sets to\nvalidate early detection. We build a heterogeneous graph with\nfollower-followee, user-tweet, and tweet-retweet connections and train a graph\nembedding model to aggregate propagation information. Graph embeddings and\ncontextual features constitute endogenous, while time-relative web-scraped\ninformation constitutes exogenous signals. ENDEMIC is trained in a\nsemi-supervised fashion, overcoming the challenge of limited labeled data. We\npropose a co-attention mechanism to fuse signal representations optimally.\nExperimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is\nhighly reliable in detecting early fake tweets, outperforming nine\nstate-of-the-art methods significantly.", "author": [{"name": "Rachit Bansal"}, {"name": "William Scott Paka"}, {"name": "Nidhi"}, {"name": "Shubhashis Sengupta"}, {"name": "Tanmoy Chakraborty"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Pacific-Asia Conference on Knowledge Discovery and Data Mining\n  (PAKDD) 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.05321v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.05321v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.07423v1", "updated": "2021-04-15T12:39:37Z", "published": "2021-04-15T12:39:37Z", "title": "The Role of Context in Detecting Previously Fact-Checked Claims", "summary": "Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.", "author": [{"name": "Shaden Shaar"}, {"name": "Firoj Alam"}, {"name": "Giovanni Da San Martino"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates"}, "link": [{"@href": "http://arxiv.org/abs/2104.07423v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.07423v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.09114v1", "updated": "2021-05-19T13:18:02Z", "published": "2021-05-19T13:18:02Z", "title": "Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment", "summary": "The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations.", "author": [{"name": "Bimal Bhattarai"}, {"name": "Ole-Christoffer Granmo"}, {"name": "Lei Jiao"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 4 figures, 4 tables"}, "link": [{"@href": "http://arxiv.org/abs/2105.09114v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.09114v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2; I.5; I.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.12479v2", "updated": "2021-05-27T08:40:27Z", "published": "2021-05-26T11:28:36Z", "title": "Pattern Detection in the Activation Space for Identifying Synthesized\n  Content", "summary": "Generative Adversarial Networks (GANs) have recently achieved unprecedented\nsuccess in photo-realistic image synthesis from low-dimensional random noise.\nThe ability to synthesize high-quality content at a large scale brings\npotential risks as the generated samples may lead to misinformation that can\ncreate severe social, political, health, and business hazards. We propose\nSubsetGAN to identify generated content by detecting a subset of anomalous\nnode-activations in the inner layers of pre-trained neural networks. These\nnodes, as a group, maximize a non-parametric measure of divergence away from\nthe expected distribution of activations created from real data. This enable us\nto identify synthesised images without prior knowledge of their distribution.\nSubsetGAN efficiently scores subsets of nodes and returns the group of nodes\nwithin the pre-trained classifier that contributed to the maximum score. The\nclassifier can be a general fake classifier trained over samples from multiple\nsources or the discriminator network from different GANs. Our approach shows\nconsistently higher detection power than existing detection methods across\nseveral state-of-the-art GANs (PGGAN, StarGAN, and CycleGAN) and over different\nproportions of generated content.", "author": [{"name": "Celia Cintas"}, {"name": "Skyler Speakman"}, {"name": "Girmaw Abebe Tadesse"}, {"name": "Victor Akinwande"}, {"name": "Edward McFowland III"}, {"name": "Komminist Weldemariam"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The paper is under consideration at Pattern Recognition Letters"}, "link": [{"@href": "http://arxiv.org/abs/2105.12479v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.12479v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.09672v2", "updated": "2021-07-01T20:58:36Z", "published": "2021-06-17T17:23:59Z", "title": "The 2021 Image Similarity Dataset and Challenge", "summary": "This paper introduces a new benchmark for large-scale image similarity\ndetection. This benchmark is used for the Image Similarity Challenge at\nNeurIPS'21 (ISC2021). The goal is to determine whether a query image is a\nmodified copy of any image in a reference corpus of size 1~million. The\nbenchmark features a variety of image transformations such as automated\ntransformations, hand-crafted image edits and machine-learning based\nmanipulations. This mimics real-life cases appearing in social media, for\nexample for integrity-related problems dealing with misinformation and\nobjectionable content. The strength of the image manipulations, and therefore\nthe difficulty of the benchmark, is calibrated according to the performance of\na set of baseline approaches. Both the query and reference set contain a\nmajority of \"distractor\" images that do not match, which corresponds to a\nreal-life needle-in-haystack setting, and the evaluation metric reflects that.\nWe expect the DISC21 benchmark to promote image copy detection as an important\nand challenging computer vision task and refresh the state of the art.", "author": [{"name": "Matthijs Douze"}, {"name": "Giorgos Tolias"}, {"name": "Ed Pizzi"}, {"name": "Zo\u00eb Papakipos"}, {"name": "Lowik Chanussot"}, {"name": "Filip Radenovic"}, {"name": "Tomas Jenicek"}, {"name": "Maxim Maximov"}, {"name": "Laura Leal-Taix\u00e9"}, {"name": "Ismail Elezi"}, {"name": "Ond\u0159ej Chum"}, {"name": "Cristian Canton Ferrer"}], "link": [{"@href": "http://arxiv.org/abs/2106.09672v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.09672v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.10204v1", "updated": "2021-07-21T16:49:21Z", "published": "2021-07-21T16:49:21Z", "title": "Characterizing Social Imaginaries and Self-Disclosures of Dissonance in\n  Online Conspiracy Discussion Communities", "summary": "Online discussion platforms offer a forum to strengthen and propagate belief\nin misinformed conspiracy theories. Yet, they also offer avenues for conspiracy\ntheorists to express their doubts and experiences of cognitive dissonance. Such\nexpressions of dissonance may shed light on who abandons misguided beliefs and\nunder which circumstances. This paper characterizes self-disclosures of\ndissonance about QAnon, a conspiracy theory initiated by a mysterious leader Q\nand popularized by their followers, anons in conspiracy theory subreddits. To\nunderstand what dissonance and disbelief mean within conspiracy communities, we\nfirst characterize their social imaginaries, a broad understanding of how\npeople collectively imagine their social existence. Focusing on 2K posts from\ntwo image boards, 4chan and 8chan, and 1.2 M comments and posts from 12\nsubreddits dedicated to QAnon, we adopt a mixed methods approach to uncover the\nsymbolic language representing the movement, expectations, practices, heroes\nand foes of the QAnon community. We use these social imaginaries to create a\ncomputational framework for distinguishing belief and dissonance from general\ndiscussion about QAnon. Further, analyzing user engagement with QAnon\nconspiracy subreddits, we find that self-disclosures of dissonance correlate\nwith a significant decrease in user contributions and ultimately with their\ndeparture from the community. We contribute a computational framework for\nidentifying dissonance self-disclosures and measuring the changes in user\nengagement surrounding dissonance. Our work can provide insights into designing\ndissonance-based interventions that can potentially dissuade conspiracists from\nonline conspiracy discussion communities.", "author": [{"name": "Shruti Phadke"}, {"name": "Mattia Samory"}, {"name": "Tanushree Mitra"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at CSCW 2021"}, "link": [{"@href": "http://arxiv.org/abs/2107.10204v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.10204v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.01536v1", "updated": "2021-08-03T14:39:52Z", "published": "2021-08-03T14:39:52Z", "title": "NudgeCred: Supporting News Credibility Assessment on Social Media\n  Through Nudges", "summary": "Struggling to curb misinformation, social media platforms are experimenting\nwith design interventions to enhance consumption of credible news on their\nplatforms. Some of these interventions, such as the use of warning messages,\nare examples of nudges -- a choice-preserving technique to steer behavior.\nDespite their application, we do not know whether nudges could steer people\ninto making conscious news credibility judgments online and if they do, under\nwhat constraints. To answer, we combine nudge techniques with heuristic based\ninformation processing to design NudgeCred -- a browser extension for Twitter.\nNudgeCred directs users' attention to two design cues: authority of a source\nand other users' collective opinion on a report by activating three design\nnudges -- Reliable, Questionable, and Unreliable, each denoting particular\nlevels of credibility for news tweets. In a controlled experiment, we found\nthat NudgeCred significantly helped users (n=430) distinguish news tweets'\ncredibility, unrestricted by three behavioral confounds -- political ideology,\npolitical cynicism, and media skepticism. A five-day field deployment with\ntwelve participants revealed that NudgeCred improved their recognition of news\nitems and attention towards all of our nudges, particularly towards\nQuestionable. Among other considerations, participants proposed that designers\nshould incorporate heuristics that users' would trust. Our work informs\nnudge-based system design approaches for online media.", "author": [{"name": "Md Momen Bhuiyan"}, {"name": "Michael Horning"}, {"name": "Sang Won Lee"}, {"name": "Tanushree Mitra"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3479571"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3479571", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.01536v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.01536v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "30 pages, CSCW 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.02325v1", "updated": "2021-08-05T00:44:43Z", "published": "2021-08-05T00:44:43Z", "title": "Designing Transparency Cues in Online News Platforms to Promote Trust:\n  Journalists' & Consumers' Perspectives", "summary": "As news organizations embrace transparency practices on their websites to\ndistinguish themselves from those spreading misinformation, HCI designers have\nthe opportunity to help them effectively utilize the ideals of transparency to\nbuild trust. How can we utilize transparency to promote trust in news? We\nexamine this question through a qualitative lens by interviewing journalists\nand news consumers---the two stakeholders in a news system. We designed a\nscenario to demonstrate transparency features using two fundamental news\nattributes that convey the trustworthiness of a news article: source and\nmessage. In the interviews, our news consumers expressed the idea that news\ntransparency could be best shown by providing indicators of objectivity in two\nareas (news selection and framing) and by providing indicators of evidence in\nfour areas (presence of source materials, anonymous sourcing, verification, and\ncorrections upon erroneous reporting). While our journalists agreed with news\nconsumers' suggestions of using evidence indicators, they also suggested\nadditional transparency indicators in areas such as the news reporting process\nand personal/organizational conflicts of interest. Prompted by our scenario,\nparticipants offered new design considerations for building trustworthy news\nplatforms, such as designing for easy comprehension, presenting appropriate\ndetails in news articles (e.g., showing the number and nature of corrections\nmade to an article), and comparing attributes across news organizations to\nhighlight diverging practices. Comparing the responses from our two stakeholder\ngroups reveals conflicting suggestions with trade-offs between them. Our study\nhas implications for HCI designers in building trustworthy news systems.", "author": [{"name": "Md Momen Bhuiyan"}, {"name": "Hayden Whitley"}, {"name": "Michael Horning"}, {"name": "Sang Won Lee"}, {"name": "Tanushree Mitra"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3479539"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3479539", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.02325v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.02325v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "31 pages, CSCW 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.10274v1", "updated": "2021-08-23T16:22:50Z", "published": "2021-08-23T16:22:50Z", "title": "Towards Explainable Fact Checking", "summary": "The past decade has seen a substantial rise in the amount of mis- and\ndisinformation online, from targeted disinformation campaigns to influence\npolitics, to the unintentional spreading of misinformation about public health.\nThis development has spurred research in the area of automatic fact checking,\nfrom approaches to detect check-worthy claims and determining the stance of\ntweets towards claims, to methods to determine the veracity of claims given\nevidence documents. These automatic methods are often content-based, using\nnatural language processing methods, which in turn utilise deep neural networks\nto learn higher-order features from text in order to make predictions. As deep\nneural networks are black-box models, their inner workings cannot be easily\nexplained. At the same time, it is desirable to explain how they arrive at\ncertain decisions, especially if they are to be used for decision making. While\nthis has been known for some time, the issues this raises have been exacerbated\nby models increasing in size, and by EU legislation requiring models to be used\nfor decision making to provide explanations, and, very recently, by legislation\nrequiring online platforms operating in the EU to provide transparent reporting\non their services. Despite this, current solutions for explainability are still\nlacking in the area of fact checking. This thesis presents my research on\nautomatic fact checking, including claim check-worthiness detection, stance\ndetection and veracity prediction. Its contributions go beyond fact checking,\nwith the thesis proposing more general machine learning solutions for natural\nlanguage processing in the area of learning with limited labelled data.\nFinally, the thesis presents some first solutions for explainable fact\nchecking.", "author": {"name": "Isabelle Augenstein"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Thesis presented to the University of Copenhagen Faculty of Science\n  in partial fulfillment of the requirements for the degree of Doctor\n  Scientiarum (Dr. Scient.)"}, "link": [{"@href": "http://arxiv.org/abs/2108.10274v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.10274v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.10735v1", "updated": "2021-08-16T17:02:18Z", "published": "2021-08-16T17:02:18Z", "title": "Misleading the Covid-19 vaccination discourse on Twitter: An exploratory\n  study of infodemic around the pandemic", "summary": "In this work, we collect a moderate-sized representative corpus of tweets\n(200,000 approx.) pertaining Covid-19 vaccination spanning over a period of\nseven months (September 2020 - March 2021). Following a Transfer Learning\napproach, we utilize the pre-trained Transformer-based XLNet model to classify\ntweets as Misleading or Non-Misleading and validate against a random subset of\nresults manually. We build on this to study and contrast the characteristics of\ntweets in the corpus that are misleading in nature against non-misleading ones.\nThis exploratory analysis enables us to design features (such as sentiments,\nhashtags, nouns, pronouns, etc) that can, in turn, be exploited for classifying\ntweets as (Non-)Misleading using various ML models in an explainable manner.\nSpecifically, several ML models are employed for prediction, with up to 90%\naccuracy, and the importance of each feature is explained using SHAP\nExplainable AI (XAI) tool. While the thrust of this work is principally\nexploratory analysis in order to obtain insights on the online discourse on\nCovid-19 vaccination, we conclude the paper by outlining how these insights\nprovide the foundations for a more actionable approach to mitigate\nmisinformation. The curated dataset and code is made available (Github\nrepository) so that the research community at large can reproduce, compare\nagainst, or build upon this work.", "author": [{"name": "Shakshi Sharma"}, {"name": "Rajesh Sharma"}, {"name": "Anwitaman Datta"}], "link": [{"@href": "http://arxiv.org/abs/2108.10735v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.10735v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.12092v1", "updated": "2021-08-27T02:36:29Z", "published": "2021-08-27T02:36:29Z", "title": "Replaying Archived Twitter: When your bird is broken, will it bring you\n  down?", "summary": "Historians and researchers trust web archives to preserve social media\ncontent that no longer exists on the live web. However, what we see on the live\nweb and how it is replayed in the archive are not always the same. In this\npaper, we document and analyze the problems in archiving Twitter ever since\nTwitter forced the use of its new UI in June 2020. Most web archives were\nunable to archive the new UI, resulting in archived Twitter pages displaying\nTwitter's \"Something went wrong\" error. The challenges in archiving the new UI\nforced web archives to continue using the old UI. To analyze the potential loss\nof information in web archival data due to this change, we used the personal\nTwitter account of the 45th President of the United States, @realDonaldTrump,\nwhich was suspended by Twitter on January 8, 2021. Trump's account was heavily\nlabeled by Twitter for spreading misinformation, however we discovered that\nthere is no evidence in web archives to prove that some of his tweets ever had\na label assigned to them. We also studied the possibility of temporal\nviolations in archived versions of the new UI, which may result in the replay\nof pages that never existed on the live web. Our goal is to educate researchers\nwho may use web archives and caution them when drawing conclusions based on\narchived Twitter pages.", "author": [{"name": "Kritika Garg"}, {"name": "Himarsha R. Jayanetti"}, {"name": "Sawood Alam"}, {"name": "Michele C. Weigle"}, {"name": "Michael L. Nelson"}], "link": [{"@href": "http://arxiv.org/abs/2108.12092v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.12092v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.13293v1", "updated": "2021-08-22T00:11:19Z", "published": "2021-08-22T00:11:19Z", "title": "Public sentiment analysis and topic modeling regarding COVID-19 vaccines\n  on the Reddit social media platform: A call to action for strengthening\n  vaccine confidence", "summary": "The COVID-19 pandemic fueled one of the most rapid vaccine developments in\nhistory. However, misinformation spread through online social media often leads\nto negative vaccine sentiment and hesitancy. To investigate COVID-19\nvaccine-related discussion in social media, we conducted a sentiment analysis\nand Latent Dirichlet Allocation topic modeling on textual data collected from\n13 Reddit communities focusing on the COVID-19 vaccine from Dec 1, 2020, to May\n15, 2021. Data were aggregated and analyzed by month to detect changes in any\nsentiment and latent topics. ty analysis suggested these communities expressed\nmore positive sentiment than negative regarding the vaccine-related discussions\nand has remained static over time. Topic modeling revealed community members\nmainly focused on side effects rather than outlandish conspiracy theories.\nCovid-19 vaccine-related content from 13 subreddits show that the sentiments\nexpressed in these communities are overall more positive than negative and have\nnot meaningfully changed since December 2020. Keywords indicating vaccine\nhesitancy were detected throughout the LDA topic modeling. Public sentiment and\ntopic modeling analysis regarding vaccines could facilitate the implementation\nof appropriate messaging, digital interventions, and new policies to promote\nvaccine confidence.", "author": [{"name": "Chad A Melton"}, {"name": "Olufunto A Olusanya"}, {"name": "Nariman Ammar"}, {"name": "Arash Shaban-Nejad"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.jiph.2021.08.010"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.jiph.2021.08.010", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.13293v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.13293v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 4 Figures, 2 Tables"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Journal of Infection and Public Health, Available online 14 August\n  2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7; J.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1304.5719v2", "updated": "2015-01-05T10:40:27Z", "published": "2013-04-21T10:58:03Z", "title": "Synchronous Counting and Computational Algorithm Design", "summary": "Consider a complete communication network on $n$ nodes, each of which is a\nstate machine. In synchronous 2-counting, the nodes receive a common clock\npulse and they have to agree on which pulses are \"odd\" and which are \"even\". We\nrequire that the solution is self-stabilising (reaching the correct operation\nfrom any initial state) and it tolerates $f$ Byzantine failures (nodes that\nsend arbitrary misinformation). Prior algorithms are expensive to implement in\nhardware: they require a source of random bits or a large number of states.\n  This work consists of two parts. In the first part, we use computational\ntechniques (often known as synthesis) to construct very compact deterministic\nalgorithms for the first non-trivial case of $f = 1$. While no algorithm exists\nfor $n < 4$, we show that as few as 3 states per node are sufficient for all\nvalues $n \\ge 4$. Moreover, the problem cannot be solved with only 2 states per\nnode for $n = 4$, but there is a 2-state solution for all values $n \\ge 6$.\n  In the second part, we develop and compare two different approaches for\nsynthesising synchronous counting algorithms. Both approaches are based on\ncasting the synthesis problem as a propositional satisfiability (SAT) problem\nand employing modern SAT-solvers. The difference lies in how to solve the SAT\nproblem: either in a direct fashion, or incrementally within a counter-example\nguided abstraction refinement loop. Empirical results suggest that the former\ntechnique is more efficient if we want to synthesise time-optimal algorithms,\nwhile the latter technique discovers non-optimal algorithms more quickly.", "author": [{"name": "Danny Dolev"}, {"name": "Keijo Heljanko"}, {"name": "Matti J\u00e4rvisalo"}, {"name": "Janne H. Korhonen"}, {"name": "Christoph Lenzen"}, {"name": "Joel Rybicki"}, {"name": "Jukka Suomela"}, {"name": "Siert Wieringa"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.jcss.2015.09.002"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.jcss.2015.09.002", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1304.5719v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1304.5719v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "35 pages, extended and revised version"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.DC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DS", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1702.01591v2", "updated": "2017-02-20T16:11:20Z", "published": "2017-02-06T12:28:27Z", "title": "The Partial Entropy Decomposition: Decomposing multivariate entropy and\n  mutual information via pointwise common surprisal", "summary": "Obtaining meaningful quantitative descriptions of the statistical dependence\nwithin multivariate systems is a difficult open problem. Recently, the Partial\nInformation Decomposition (PID) was proposed to decompose mutual information\n(MI) about a target variable into components which are redundant, unique and\nsynergistic within different subsets of predictor variables. Here, we propose\nto apply the elegant formalism of the PID to multivariate entropy, resulting in\na Partial Entropy Decomposition (PED). We implement the PED with an entropy\nredundancy measure based on pointwise common surprisal; a natural definition\nwhich is closely related to the definition of MI. We show how this approach can\nreveal the dyadic vs triadic generative structure of multivariate systems that\nare indistinguishable with classical Shannon measures. The entropy perspective\nalso shows that misinformation is synergistic entropy and hence that MI itself\nincludes both redundant and synergistic effects. We show the relationships\nbetween the PED and MI in two predictors, and derive two alternative\ninformation decompositions which we illustrate on several example systems. This\nreveals that in entropy terms, univariate predictor MI is not a proper subset\nof the joint MI, and we suggest this previously unrecognised fact explains in\npart why obtaining a consistent PID has proven difficult. The PED also allows\nseparate quantification of mechanistic redundancy (related to the function of\nthe system) versus source redundancy (arising from dependencies between\ninputs); an important distinction which no existing methods can address. The\nnew perspective provided by the PED helps to clarify some of the difficulties\nencountered with the PID approach and the resulting decompositions provide\nuseful tools for practical data analysis across a wide range of application\nareas.", "author": {"name": "Robin A. A. Ince"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Added Section 3.7 (Quantifying source vs mechanistic redundancy) and\n  Section 3.8 (Shared entropy as a measure of dependence: pure mutual\n  information) and updated abstract, results, and discussion accordingly"}, "link": [{"@href": "http://arxiv.org/abs/1702.01591v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1702.01591v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.ST", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.NC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.QM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ME", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.TH", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1703.06959v4", "updated": "2017-09-03T22:05:42Z", "published": "2017-03-20T20:33:32Z", "title": "CSI: A Hybrid Deep Model for Fake News Detection", "summary": "The topic of fake news has drawn attention both from the public and the\nacademic communities. Such misinformation has the potential of affecting public\nopinion, providing an opportunity for malicious parties to manipulate the\noutcomes of public events such as elections. Because such high stakes are at\nplay, automatically detecting fake news is an important, yet challenging\nproblem that is not yet well understood. Nevertheless, there are three\ngenerally agreed upon characteristics of fake news: the text of an article, the\nuser response it receives, and the source users promoting it. Existing work has\nlargely focused on tailoring solutions to one particular characteristic which\nhas limited their success and generality. In this work, we propose a model that\ncombines all three characteristics for a more accurate and automated\nprediction. Specifically, we incorporate the behavior of both parties, users\nand articles, and the group behavior of users who propagate fake news.\nMotivated by the three characteristics, we propose a model called CSI which is\ncomposed of three modules: Capture, Score, and Integrate. The first module is\nbased on the response and text; it uses a Recurrent Neural Network to capture\nthe temporal pattern of user activity on a given article. The second module\nlearns the source characteristic based on the behavior of users, and the two\nare integrated with the third module to classify an article as fake or not.\nExperimental analysis on real-world data demonstrates that CSI achieves higher\naccuracy than existing models, and extracts meaningful latent representations\nof both users and articles.", "author": [{"name": "Natali Ruchansky"}, {"name": "Sungyong Seo"}, {"name": "Yan Liu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3132847.3132877"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3132847.3132877", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1703.06959v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1703.06959v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Proceedings of the 26th ACM International Conference on\n  Information and Knowledge Management (CIKM) 2017"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1211.3175v1", "updated": "2012-11-14T01:17:59Z", "published": "2012-11-14T01:17:59Z", "title": "\"But since the affairs of men rest still uncertain, let's reason with\n  the worst that may befall\": Probability, risk, and the 2009 L'Aquila\n  Earthquake", "summary": "This article is a commentary on the verdict of the \"L'Aquila Six\", the group\nof bureaucrats and scientists tried by an Italian court as a result of their\npublic statements in advance of the quake of 2009 Apr. 6 that left the city in\nruins and cause more than 300 deaths. It was not the worst such catastrophic\nevent in recent Italian history, but it was one of -- if not the -- worst\nfailures of risk assessment and preventive action. The six were found guilty\nand condemned by a first level of the justice system to substantial prison\nterms. The outcry provoked by the verdict in the world press and the\ninternational scientific community has fueled the already fiery debate over\nwhether the six should have been tried at all. They have been presented as\nmartyrs to science being treated as scapegoats by a scientifically illiterate\njustice system and inflamed local population for not being able to perform the\nimpossible (predict the event). Petitions of support have been drafted and\nsigned by thousands of working scientists and technical experts in many fields\nexcoriating the court and the country for such an outrage against the\nscientific community, often accompanied by ominous warnings about the chilling\neffect this will have on the availability of expert advice in times of need. My\npurpose in this essay is to explain why this view of the events of the trial is\nmisguided, however well intentioned, and misinformed.", "author": {"name": "Steven N. Shore", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Dept. of Physics, Univ. of Pisa"}}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, no figures (language, english); In press, 2012,\n  ScienzaePace, the journal of the Interdisciplinary Center for Peace Studies\n  (Centro Interdisciplinare Scienze per la Pace), University of Pisa (ISSN\n  2039-1749 http://scienzaepace.unipi.it/)"}, "link": [{"@href": "http://arxiv.org/abs/1211.3175v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1211.3175v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.hist-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.pop-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1802.04291v1", "updated": "2018-02-12T19:00:18Z", "published": "2018-02-12T19:00:18Z", "title": "Analyzing the Digital Traces of Political Manipulation: The 2016 Russian\n  Interference Twitter Campaign", "summary": "Until recently, social media was seen to promote democratic discourse on\nsocial and political issues. However, this powerful communication platform has\ncome under scrutiny for allowing hostile actors to exploit online discussions\nin an attempt to manipulate public opinion. A case in point is the ongoing U.S.\nCongress' investigation of Russian interference in the 2016 U.S. election\ncampaign, with Russia accused of using trolls (malicious accounts created to\nmanipulate) and bots to spread misinformation and politically biased\ninformation. In this study, we explore the effects of this manipulation\ncampaign, taking a closer look at users who re-shared the posts produced on\nTwitter by the Russian troll accounts publicly disclosed by U.S. Congress\ninvestigation. We collected a dataset with over 43 million election-related\nposts shared on Twitter between September 16 and October 21, 2016, by about 5.7\nmillion distinct users. This dataset included accounts associated with the\nidentified Russian trolls. We use label propagation to infer the ideology of\nall users based on the news sources they shared. This method enables us to\nclassify a large number of users as liberal or conservative with precision and\nrecall above 90%. Conservatives retweeted Russian trolls about 31 times more\noften than liberals and produced 36x more tweets. Additionally, most retweets\nof troll content originated from two Southern states: Tennessee and Texas.\nUsing state-of-the-art bot detection techniques, we estimated that about 4.9%\nand 6.2% of liberal and conservative users respectively were bots. Text\nanalysis on the content shared by trolls reveals that they had a mostly\nconservative, pro-Trump agenda. Although an ideologically broad swath of\nTwitter users was exposed to Russian Trolls in the period leading up to the\n2016 U.S. Presidential election, it was mainly conservatives who helped amplify\ntheir message.", "author": [{"name": "Adam Badawy"}, {"name": "Emilio Ferrara"}, {"name": "Kristina Lerman"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/ASONAM.2018.8508646"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/ASONAM.2018.8508646", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1802.04291v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1802.04291v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "2018 IEEE/ACM International Conference on Advances in Social\n  Networks Analysis and Mining (ASONAM), Barcelona, Spain, 2018, pp. 258-265"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.00706v1", "updated": "2018-11-02T02:13:52Z", "published": "2018-11-02T02:13:52Z", "title": "Combining Similarity Features and Deep Representation Learning for\n  Stance Detection in the Context of Checking Fake News", "summary": "Fake news are nowadays an issue of pressing concern, given their recent rise\nas a potential threat to high-quality journalism and well-informed public\ndiscourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage\nthe development of machine learning-based classification systems for stance\ndetection (i.e., for identifying whether a particular news article agrees,\ndisagrees, discusses, or is unrelated to a particular news headline), thus\nhelping in the detection and analysis of possible instances of fake news. This\narticle presents a new approach to tackle this stance detection problem, based\non the combination of string similarity features with a deep neural\narchitecture that leverages ideas previously advanced in the context of\nlearning efficient text representations, document classification, and natural\nlanguage inference. Specifically, we use bi-directional Recurrent Neural\nNetworks, together with max-pooling over the temporal/sequential dimension and\nneural attention, for representing (i) the headline, (ii) the first two\nsentences of the news article, and (iii) the entire news article. These\nrepresentations are then combined/compared, complemented with similarity\nfeatures inspired on other FNC-1 approaches, and passed to a final layer that\npredicts the stance of the article towards the headline. We also explore the\nuse of external sources of information, specifically large datasets of sentence\npairs originally proposed for training and evaluating natural language\ninference methods, in order to pre-train specific components of the neural\nnetwork architecture (e.g., the RNNs used for encoding sentences). The obtained\nresults attest to the effectiveness of the proposed ideas and show that our\nmodel, particularly when considering pre-training and the combination of neural\nrepresentations together with similarity features, slightly outperforms the\nprevious state-of-the-art.", "author": [{"name": "Lu\u00eds Borges"}, {"name": "Bruno Martins"}, {"name": "P\u00e1vel Calado"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication in the special issue of the ACM Journal of\n  Data and Information Quality (ACM JDIQ) on Combating Digital Misinformation\n  and Disinformation"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Journal of Data and Information Quality (JDIQ) 11 (3), 1-26, 2019"}, "link": [{"@href": "http://arxiv.org/abs/1811.00706v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.00706v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1701.02368v3", "updated": "2017-11-08T19:22:57Z", "published": "2017-01-09T21:57:38Z", "title": "An Efficient Randomized Algorithm for Rumor Blocking in Online Social\n  Networks", "summary": "Social networks allow rapid spread of ideas and innovations while the\nnegative information can also propagate widely. When the cascades with\ndifferent opinions reaching the same user, the cascade arriving first is the\nmost likely to be taken by the user. Therefore, once misinformation or rumor is\ndetected, a natural containment method is to introduce a positive cascade\ncompeting against the rumor. Given a budget $k$, the rumor blocking problem\nasks for $k$ seed users to trigger the spread of the positive cascade such that\nthe number of the users who are not influenced by rumor can be maximized. The\nprior works have shown that the rumor blocking problem can be approximated\nwithin a factor of $(1-1/e-\\delta)$ by a classic greedy algorithm combined with\nMonte Carlo simulation with the running time of $O(\\frac{k^3mn\\ln\nn}{\\delta^2})$, where $n$ and $m$ are the number of users and edges,\nrespectively. Unfortunately, the Monte-Carlo-simulation-based methods are\nextremely time consuming and the existing algorithms either trade performance\nguarantees for practical efficiency or vice versa. In this paper, we present a\nrandomized algorithm which runs in $O(\\frac{km\\ln n}{\\delta^2})$ expected time\nand provides a $(1-1/e-\\delta)$-approximation with a high probability. The\nexperimentally results on both the real-world and synthetic social networks\nhave shown that the proposed randomized rumor blocking algorithm is much more\nefficient than the state-of-the-art method and it is able to find the seed\nnodes which are effective in limiting the spread of rumor.", "author": [{"name": "Guangmo Tong"}, {"name": "Weili Wu"}, {"name": "Ling Guo"}, {"name": "Deying Li"}, {"name": "Cong Liu"}, {"name": "Bin Liu"}, {"name": "Ding-Zhu Du"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is the full version which fixes an error in the conference\n  version"}, "link": [{"@href": "http://arxiv.org/abs/1701.02368v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1701.02368v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1907.08043v1", "updated": "2019-07-18T13:38:22Z", "published": "2019-07-18T13:38:22Z", "title": "Embedding Climate Change Engagement in Astronomy Education and Research", "summary": "This White Paper is a call to action for astronomers to respond to climate\nchange with a large structural transition within our profession. Many\nastronomers are deeply concerned about climate change and act upon it in their\npersonal and professional lives, and many organizations within astronomy have\nincorporated incremental changes. We need a collective impact model to better\nnetwork and grow our efforts so that we can achieve results that are on the\nscale appropriate to address climate change at the necessary level indicated by\nscientific research; e.g., becoming carbon neutral by 2050. We need to\nimplement strategies within two primary drivers of our field: (1) Education and\nOutreach, and (2) Research Practices and Infrastructure. (1) In the classroom\nand through public talks, astronomers reach a large audience. Astronomy is\nclosely connected to the science of climate change, and it is arguably the most\nimportant topic we include in our curriculum. Due to misinformation and\ndisinformation, climate change communication is different than for other areas\nof science. We therefore need to expand our communication and implement\neffective strategies, for which there is now a considerable body of research.\n(2) On a per-person basis astronomers have an outsized carbon impact. There are\nnumerous ways we can reduce our footprint; e.g., in the design and operation of\ntelescope facilities and in the optimization and reduction of travel.\nFortunately, many of these solutions are win-win scenarios, e.g., increasing\nthe online presence of conferences will reduce the carbon footprint while\nincreasing participation, especially for astronomers working with fewer\nfinancial resources. Astronomers have an obligation to act on climate change in\nevery way possible, and we need to do it now. In this White Paper, we outline a\nplan for collective impact using a Networked Improvement Community (NIC)\napproach.", "author": [{"name": "Kathryn Williamson"}, {"name": "Travis A. Rector"}, {"name": "James Lowenthal"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted as a State of the Profession White Paper for the Astro2020\n  Decadal Survey (10 pages, 1 figure)"}, "link": [{"@href": "http://arxiv.org/abs/1907.08043v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.08043v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "astro-ph.IM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "astro-ph.IM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.ed-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.00846v5", "updated": "2021-04-04T22:02:29Z", "published": "2019-12-31T11:03:18Z", "title": "Evidence of disorientation towards immunization on online social media\n  after contrasting political communication on vaccines. Results from an\n  analysis of Twitter data in Italy", "summary": "Background. In Italy, in recent years, vaccination coverage for key\nimmunizations as MMR has been declining to worryingly low levels. In 2017, the\nItalian Gov't expanded the number of mandatory immunizations introducing\npenalties to unvaccinated children's families. During the 2018 general\nelections campaign, immunization policy entered the political debate with the\nGov't in charge blaming oppositions for fuelling vaccine scepticism. A new\nGov't established in 2018 temporarily relaxed penalties. Objectives and\nMethods. Using a sentiment analysis on tweets posted in Italian during 2018, we\naimed to: (i) characterize the temporal flow of vaccines communication on\nTwitter (ii) evaluate the polarity of vaccination opinions and usefulness of\nTwitter data to estimate vaccination parameters, and (iii) investigate whether\nthe contrasting announcements at the highest political level might have\noriginated disorientation amongst the Italian public. Results. Vaccine-relevant\ntweeters interactions peaked in response to main political events. Out of\nretained tweets, 70.0% resulted favourable to vaccination, 16.5% unfavourable,\nand 13.6% undecided, respectively. The smoothed time series of polarity\nproportions exhibit frequent large changes in the favourable proportion,\nenhanced by an up and down trend synchronized with the switch between gov't\nsuggesting evidence of disorientation among the public. Conclusion. The\nreported evidence of disorientation documents that critical immunization\ntopics, should never be used for political consensus. This is especially true\ngiven the increasing role of online social media as information source, which\nmight yield to social pressures eventually harmful for vaccine uptake, and is\nworsened by the lack of institutional presence on Twitter, calling for efforts\nto contrast misinformation and the ensuing spread of hesitancy.", "author": [{"name": "Samantha Ajovalasit", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "University of Messina"}}, {"name": "Veronica Dorgali", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "University of Florence"}}, {"name": "Angelo Mazza", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "University of Messina"}}, {"name": "Alberto D'Onofrio", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "University of Strathclyde"}}, {"name": "Piero Manfredi", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "University of Pisa"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "17 pages, 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/2002.00846v5", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.00846v5", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.04565v3", "updated": "2020-05-23T15:16:31Z", "published": "2020-04-09T14:37:43Z", "title": "CovidSens: A Vision on Reliable Social Sensing for COVID-19", "summary": "With the spiraling pandemic of the Coronavirus Disease 2019 (COVID-19), it\nhas becoming inherently important to disseminate accurate and timely\ninformation about the disease. Due to the ubiquity of Internet connectivity and\nsmart devices, social sensing is emerging as a dynamic AI-driven sensing\nparadigm to extract real-time observations from online users. In this paper, we\npropose CovidSens, a vision of social sensing based risk alert systems to\nspontaneously obtain and analyze social data to infer COVID-19 propagation.\nCovidSens can actively help to keep the general public informed about the\nCOVID-19 spread and identify risk-prone areas. The CovidSens concept is\nmotivated by three observations: 1) people actively share their experience of\nCOVID-19 via online social media, 2) official warning channels and news\nagencies are relatively slower than people reporting on social media, and 3)\nonline users are frequently equipped with powerful mobile devices that can\nperform data processing and analytics. We envision unprecedented opportunities\nto leverage posts generated by ordinary people to build real-time sensing and\nanalytic system for gathering and circulating COVID-19 propagation data.\nSpecifically, the vision of CovidSens attempts to answer the questions: How to\ndistill reliable information on COVID-19 with prevailing rumors and\nmisinformation? How to inform the general public about the state of the spread\ntimely and effectively? How to leverage the computational power on edge devices\nto construct fully integrated edge-based social sensing platforms? In this\nvision paper, we discuss the roles of CovidSens and identify potential\nchallenges in developing reliable social sensing based risk alert systems. We\nenvision that approaches originating from multiple disciplines can be effective\nin addressing the challenges. Finally, we outline a few research directions for\nfuture work in CovidSens.", "author": [{"name": "Md Tahmid Rashid"}, {"name": "Dong Wang"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Artificial Intelligence Review (accepted for publication)"}, "link": [{"@href": "http://arxiv.org/abs/2004.04565v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.04565v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.09938v3", "updated": "2021-04-14T20:05:52Z", "published": "2020-06-17T15:35:23Z", "title": "Did State-sponsored Trolls Shape the 2016 US Presidential Election\n  Discourse? Quantifying Influence on Twitter", "summary": "It is a widely accepted fact that state-sponsored Twitter accounts operated\nduring the 2016 US presidential election, spreading millions of tweets with\nmisinformation and inflammatory political content. Whether these social media\ncampaigns of the so-called \"troll\" accounts were able to manipulate public\nopinion is still in question. Here, we quantify the influence of troll accounts\non Twitter by analyzing 152.5 million tweets (by 9.9 million users) from that\nperiod. The data contain original tweets from 822 troll accounts identified as\nsuch by Twitter itself. We construct and analyse a very large interaction graph\nof 9.3 million nodes and 169.9 million edges using graph analysis techniques,\nalong with a game-theoretic centrality measure. Then, we quantify the influence\nof all Twitter accounts on the overall information exchange as is defined by\nthe retweet cascades. We provide a global influence ranking of all Twitter\naccounts and we find that one troll account appears in the top-100 and four in\nthe top-1000. This combined with other findings presented in this paper\nconstitute evidence that the driving force of virality and influence in the\nnetwork came from regular users - users who have not been classified as trolls\nby Twitter. On the other hand, we find that on average, troll accounts were\ntens of times more influential than regular users were. Moreover, 23% and 22%\nof regular accounts in the top-100 and top-1000 respectively, have now been\nsuspended by Twitter. This raises questions about their authenticity and\npractices during the 2016 US presidential election.", "author": [{"name": "Nikos Salamanos"}, {"name": "Michael J. Jensen"}, {"name": "Costas Iordanou"}, {"name": "Michael Sirivianos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This article supersedes our work arXiv:1910.00531. This work has been\n  submitted to the IEEE for possible publication. Copyright may be transferred\n  without notice, after which this version may no longer be accessible"}, "link": [{"@href": "http://arxiv.org/abs/2006.09938v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.09938v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2006.11002v2", "updated": "2021-01-15T10:04:56Z", "published": "2020-06-19T08:02:31Z", "title": "A First Look at Android Applications in Google Play related to Covid-19", "summary": "Due to the convenience of access-on-demand to information and business\nsolutions, mobile apps have become an important asset in the digital world. In\nthe context of the Covid-19 pandemic, app developers have joined the response\neffort in various ways by releasing apps that target different user bases\n(e.g., all citizens or journalists), offer different services (e.g., location\ntracking or diagnostic-aid), provide generic or specialized information, etc.\nWhile many apps have raised some concerns by spreading misinformation or even\nmalware, the literature does not yet provide a clear landscape of the different\napps that were developed. In this study, we focus on the Android ecosystem and\ninvestigate Covid-related Android apps. In a best-effort scenario, we attempt\nto systematically identify all relevant apps and study their characteristics\nwith the objective to provide a First taxonomy of Covid-related apps,\nbroadening the relevance beyond the implementation of contact tracing. Overall,\nour study yields a number of empirical insights that contribute to enlarge the\nknowledge on Covid-related apps: (1) Developer communities contributed rapidly\nto the Covid-19, with dedicated apps released as early as January 2020; (2)\nCovid-related apps deliver digital tools to users (e.g., health diaries), serve\nto broadcast information to users (e.g., spread statistics), and collect data\nfrom users (e.g., for tracing); (3) Covid-related apps are less complex than\nstandard apps; (4) they generally do not seem to leak sensitive data; (5) in\nthe majority of cases, Covid-related apps are released by entities with past\nexperience on the market, mostly official government entities or public health\norganizations.", "author": [{"name": "Jordan Samhi"}, {"name": "Kevin Allix"}, {"name": "Tegawend\u00e9 F. Bissyand\u00e9"}, {"name": "Jacques Klein"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted in Empirical Software Engineering under reference:\n  EMSE-D-20-00211R1"}, "link": [{"@href": "http://arxiv.org/abs/2006.11002v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.11002v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SE", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.12312v1", "updated": "2020-07-24T01:09:56Z", "published": "2020-07-24T01:09:56Z", "title": "COVID-19 Remote Patient Monitoring: Social Impact of AI", "summary": "A primary indicator of success in the fight against COVID-19 is avoiding\nstress on critical care infrastructure and services (CCIS). However, CCIS will\nlikely remain stressed until sustained herd immunity is built. There are also\nsecondary considerations for success: mitigating economic damage; curbing the\nspread of misinformation, improving morale, and preserving a sense of control;\nbuilding global trust for diplomacy, trade and travel; and restoring\nreliability and normalcy to day-to-day life, among others. We envision\ntechnology plays a pivotal role. Here, we focus on the effective use of readily\navailable technology to improve the primary and secondary success criteria for\nthe fight against SARS-CoV-2. In a multifaceted technology approach, we start\nwith effective technology use for remote patient monitoring (RPM) of COVID-19\nwith the following objectives:\n  1. Deploy readily available technology for continuous real-time remote\nmonitoring of patient vitals with the help of biosensors on a large scale.\n  2. Effective and safe remote large-scale communitywide care of low-severity\ncases as a buffer against surges in COVID-19 hospitalizations to reduce strain\non critical care services and emergency hospitals.\n  3. Improve the patient, their family, and their community's sense of control\nand morale.\n  4. Propose a clear technology and medical definition of remote patient\nmonitoring for COVID-19 to address an urgent technology need; address\nobfuscated, narrow, and erroneous information and provide examples; and urge\npublishers to be clear and complete in their disclosures.\n  5. Leverage the cloud-based distributed cognitive RPM platform for community\nleaders and decision makers to enable planning and resource management,\npandemic research, damage prevention and containment, and receiving feedback on\nstrategies and executions.", "author": [{"name": "Ashlesha Nesarikar", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "University of Texas at Dallas and Plano Intelligence"}}, {"name": "Waqas Haque", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "UT Southwestern"}}, {"name": "Suchith Vuppala", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "UT Southwestern"}}, {"name": "Abhijit Nesarikar", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Plano Intelligence"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "21 pages, 4 figures"}, "link": [{"@href": "http://arxiv.org/abs/2007.12312v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.12312v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.09110v3", "updated": "2021-06-30T12:57:19Z", "published": "2020-12-14T18:54:05Z", "title": "Developing Future Human-Centered Smart Cities: Critical Analysis of\n  Smart City Security, Interpretability, and Ethical Challenges", "summary": "As we make tremendous advances in machine learning and artificial\nintelligence technosciences, there is a renewed understanding in the AI\ncommunity that we must ensure that humans being are at the center of our\ndeliberations so that we don't end in technology-induced dystopias. As strongly\nargued by Green in his book Smart Enough City, the incorporation of technology\nin city environs does not automatically translate into prosperity, wellbeing,\nurban livability, or social justice. There is a great need to deliberate on the\nfuture of the cities worth living and designing. There are philosophical and\nethical questions involved along with various challenges that relate to the\nsecurity, safety, and interpretability of AI algorithms that will form the\ntechnological bedrock of future cities. Several research institutes on human\ncentered AI have been established at top international universities. Globally\nthere are calls for technology to be made more humane and human-compatible. For\nexample, Stuart Russell has a book called Human Compatible AI. The Center for\nHumane Technology advocates for regulators and technology companies to avoid\nbusiness models and product features that contribute to social problems such as\nextremism, polarization, misinformation, and Internet addiction. In this paper,\nwe analyze and explore key challenges including security, robustness,\ninterpretability, and ethical challenges to a successful deployment of AI or ML\nin human-centric applications, with a particular emphasis on the convergence of\nthese challenges. We provide a detailed review of existing literature on these\nkey challenges and analyze how one of these challenges may lead to others or\nhelp in solving other challenges. The paper also advises on the current\nlimitations, pitfalls, and future directions of research in these domains, and\nhow it can fill the current gaps and lead to better solutions.", "author": [{"name": "Kashif Ahmad"}, {"name": "Majdi Maabreh"}, {"name": "Mohamed Ghaly"}, {"name": "Khalil Khan"}, {"name": "Junaid Qadir"}, {"name": "Ala Al-Fuqaha"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "I withdraw this paper, as I uploaded it by mistake"}, "link": [{"@href": "http://arxiv.org/abs/2012.09110v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.09110v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.01131v2", "updated": "2021-07-20T04:06:18Z", "published": "2021-04-02T16:13:16Z", "title": "Mining Trends of COVID-19 Vaccine Beliefs on Twitter with Lexical\n  Embeddings", "summary": "Social media plays a pivotal role in disseminating news globally and acts as\na platform for people to express their opinions on various topics. A wide\nvariety of views accompanies COVID-19 vaccination drives across the globe,\noften colored by emotions, which change along with rising cases, approval of\nvaccines, and multiple factors discussed online. This study aims at analyzing\nthe temporal evolution of different Emotion categories: Hesitation, Rage,\nSorrow, Anticipation, Faith, and Contentment with Influencing Factors: Vaccine\nRollout, Misinformation, Health Effects, and Inequities as lexical categories\ncreated from Tweets belonging to five countries with vital vaccine roll-out\nprograms, namely, India, United States of America, Brazil, United Kingdom, and\nAustralia. We extracted a corpus of nearly 1.8 million Twitter posts related to\nCOVID-19 vaccination. Using cosine distance from selected seed words, we\nexpanded the vocabulary of each category and tracked the longitudinal change in\ntheir strength from June 2020 to April 2021. We used community detection\nalgorithms to find modules in positive correlation networks. Our findings\nsuggest that tweets expressing hesitancy towards vaccines contain the highest\nmentions of health-related effects in all countries. Our results indicated that\nthe patterns of hesitancy were variable across geographies and can help us\nlearn targeted interventions. We also observed a significant change in the\nlinear trends of categories like hesitation and contentment before and after\napproval of vaccines. Negative emotions like rage and sorrow gained the highest\nimportance in the alluvial diagram. They formed a significant module with all\nthe influencing factors in April 2021, when India observed the second wave of\nCOVID-19 cases. The relationship between Emotions and Influencing Factors was\nfound to be variable across the countries.", "author": [{"name": "Harshita Chopra"}, {"name": "Aniket Vashishtha"}, {"name": "Ridam Pal"}, {"name": "Ashima"}, {"name": "Ananya Tyagi"}, {"name": "Tavpritesh Sethi"}], "link": [{"@href": "http://arxiv.org/abs/2104.01131v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.01131v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.09059v1", "updated": "2021-05-19T10:59:17Z", "published": "2021-05-19T10:59:17Z", "title": "The State of AI Ethics Report (January 2021)", "summary": "The 3rd edition of the Montreal AI Ethics Institute's The State of AI Ethics\ncaptures the most relevant developments in AI Ethics since October 2020. It\naims to help anyone, from machine learning experts to human rights activists\nand policymakers, quickly digest and understand the field's ever-changing\ndevelopments. Through research and article summaries, as well as expert\ncommentary, this report distills the research and reporting surrounding various\ndomains related to the ethics of AI, including: algorithmic injustice,\ndiscrimination, ethical AI, labor impacts, misinformation, privacy, risk and\nsecurity, social media, and more.\n  In addition, The State of AI Ethics includes exclusive content written by\nworld-class AI Ethics experts from universities, research institutes,\nconsulting firms, and governments. Unique to this report is \"The Abuse and\nMisogynoir Playbook,\" written by Dr. Katlyn Tuner (Research Scientist, Space\nEnabled Research Group, MIT), Dr. Danielle Wood (Assistant Professor, Program\nin Media Arts and Sciences; Assistant Professor, Aeronautics and Astronautics;\nLead, Space Enabled Research Group, MIT) and Dr. Catherine D'Ignazio (Assistant\nProfessor, Urban Science and Planning; Director, Data + Feminism Lab, MIT). The\npiece (and accompanying infographic), is a deep-dive into the historical and\nsystematic silencing, erasure, and revision of Black women's contributions to\nknowledge and scholarship in the United Stations, and globally. Exposing and\ncountering this Playbook has become increasingly important following the firing\nof AI Ethics expert Dr. Timnit Gebru (and several of her supporters) at Google.\n  This report should be used not only as a point of reference and insight on\nthe latest thinking in the field of AI Ethics, but should also be used as a\ntool for introspection as we aim to foster a more nuanced conversation\nregarding the impacts of AI on the world.", "author": [{"name": "Abhishek Gupta", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Alexandrine Royer", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Connor Wright", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Falaah Arif Khan", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Victoria Heath", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Erick Galinkin", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Ryan Khurana", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Marianna Bergamaschi Ganapini", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Muriam Fancy", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Masa Sweidan", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Mo Akif", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Renjie Butalid", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "188 pages"}, "link": [{"@href": "http://arxiv.org/abs/2105.09059v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.09059v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.03766v1", "updated": "2021-07-08T11:24:50Z", "published": "2021-07-08T11:24:50Z", "title": "Exploring the effect of social media and spatial characteristics during\n  the COVID-19 pandemic in China", "summary": "The declaration of COVID-19 as a pandemic has largely amplified the spread of\nrelated information on social media, such as Twitter, Facebook, and\nWeChat.Unlike the previous studies which focused on how to detect the\nmisinformation or fake news related toCOVID-19, we investigate how the disease\nand information co-evolve in the population. We focus onCOVID-19and its\ninformation during the period when the disease was widely spread in China,\ni.e., from January 25th to March 24th, 2020. We first explore how the disease\nand information co-evolve via the spatial analysis of the two spreading\nprocesses. We visualize the geo-location of both disease and information at the\nprovince level and find that disease is more geo-localized compared to\ninformation. We find a high correlation between the disease and information\ndata, and also people care about the spread only when it comes to their\nneighborhood. Regard to the content of the information, we find that positive\nmessages are more negatively correlated with the disease compared to negative\nand neutral messages. Additionally, we introduce machine learning algorithms,\ni.e., linear regression and random forest, to further predict the number of\ninfected using different disease spatial related and information-related\ncharacteristics. We obtain that the disease spatial related characteristics of\nnearby cities can help to improve the prediction accuracy. Meanwhile,\ninformation-related characteristics can also help to improve the prediction\nperformance, but with a delay, i.e., the improvement comes from using, for\ninstance, the number of messages 10 days ago, for disease prediction. The\nmethodology proposed in this paper may shed light on new clues of emerging\ninfections", "author": [{"name": "Xiu-Xiu Zhan"}, {"name": "Kaiyue Zhang"}, {"name": "Lun Ge"}, {"name": "Junming Huang"}, {"name": "Zinan Zhang"}, {"name": "Lu Wei"}, {"name": "Gui-Quan Sun"}, {"name": "Chuang Liu"}, {"name": "Zi-Ke Zhang"}], "link": [{"@href": "http://arxiv.org/abs/2107.03766v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.03766v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.14155v1", "updated": "2021-07-29T16:26:18Z", "published": "2021-07-29T16:26:18Z", "title": "Brexit and bots: characterizing the behaviour of automated accounts on\n  Twitter during the UK election", "summary": "Online Social Networks represent a novel opportunity for political campaigns,\nrevolutionising the paradigm of political communication. Nevertheless, many\nstudies uncovered the presence of d/misinformation campaigns or of malicious\nactivities by genuine or automated users, putting at severe risk the\ncredibility of online platforms. This phenomenon is particularly evident during\ncrucial political events, as political elections. In the present paper, we\nprovide a comprehensive description of the structure of the networks of\ninteractions among users and bots during the UK elections of 2019. In\nparticular, we focus on the polarised discussion about Brexit on Twitter\nanalysing a data set made of more than 10 million tweets posted for over a\nmonth. We found that the presence of automated accounts fostered the debate\nparticularly in the days before the UK national elections, in which we find a\nsteep increase of bots in the discussion; in the days after the election day,\ntheir incidence returned to values similar to the ones observed few weeks\nbefore the elections. On the other hand, we found that the number of suspended\nusers (i.e. accounts that were removed by the platform for some violation of\nthe Twitter policy) remained constant until the election day, after which it\nreached significantly higher values. Remarkably, after the TV debate between\nBoris Johnson and Jeremy Corbyn, we observed the injection of a large number of\nnovel bots whose behaviour is markedly different from that of pre-existing\nones. Finally, we explored the bots' stance, finding that their activity is\nspread across the whole political spectrum, although in different proportions,\nand we studied the different usage of hashtags by automated accounts and\nsuspended users, thus targeting the formation of common narratives in different\nsides of the debate.", "author": [{"name": "Matteo Bruno"}, {"name": "Renaud Lambiotte"}, {"name": "Fabio Saracco"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "18 pages, 13 figures"}, "link": [{"@href": "http://arxiv.org/abs/2107.14155v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.14155v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}]