[{"id": "http://arxiv.org/abs/2003.07684v5", "updated": "2020-09-28T22:53:39Z", "published": "2020-02-28T18:40:54Z", "title": "Identifying Disinformation Websites Using Infrastructure Features", "summary": "Platforms have struggled to keep pace with the spread of disinformation.\nCurrent responses like user reports, manual analysis, and third-party fact\nchecking are slow and difficult to scale, and as a result, disinformation can\nspread unchecked for some time after being created. Automation is essential for\nenabling platforms to respond rapidly to disinformation. In this work, we\nexplore a new direction for automated detection of disinformation websites:\ninfrastructure features. Our hypothesis is that while disinformation websites\nmay be perceptually similar to authentic news websites, there may also be\nsignificant non-perceptual differences in the domain registrations, TLS/SSL\ncertificates, and web hosting configurations. Infrastructure features are\nparticularly valuable for detecting disinformation websites because they are\navailable before content goes live and reaches readers, enabling early\ndetection. We demonstrate the feasibility of our approach on a large corpus of\nlabeled website snapshots. We also present results from a preliminary real-time\ndeployment, successfully discovering disinformation websites while highlighting\nunexplored challenges for automated disinformation detection.", "author": [{"name": "Austin Hounsel"}, {"name": "Jordan Holland"}, {"name": "Ben Kaiser"}, {"name": "Kevin Borgolte"}, {"name": "Nick Feamster"}, {"name": "Jonathan Mayer"}], "link": [{"@href": "http://arxiv.org/abs/2003.07684v5", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.07684v5", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2006.03354v2", "updated": "2021-03-11T12:55:12Z", "published": "2020-06-05T10:32:18Z", "title": "Classification Aware Neural Topic Model and its Application on a New\n  COVID-19 Disinformation Corpus", "summary": "The explosion of disinformation accompanying the COVID-19 pandemic has\noverloaded fact-checkers and media worldwide, and brought a new major challenge\nto government responses worldwide. Not only is disinformation creating\nconfusion about medical science amongst citizens, but it is also amplifying\ndistrust in policy makers and governments. To help tackle this, we developed\ncomputational methods to categorise COVID-19 disinformation. The COVID-19\ndisinformation categories could be used for a) focusing fact-checking efforts\non the most damaging kinds of COVID-19 disinformation; b) guiding policy makers\nwho are trying to deliver effective public health messages and counter\neffectively COVID-19 disinformation. This paper presents: 1) a corpus\ncontaining what is currently the largest available set of manually annotated\nCOVID-19 disinformation categories; 2) a classification-aware neural topic\nmodel (CANTM) designed for COVID-19 disinformation category classification and\ntopic discovery; 3) an extensive analysis of COVID-19 disinformation categories\nwith respect to time, volume, false type, media type and origin source.", "author": [{"name": "Xingyi Song"}, {"name": "Johann Petrak"}, {"name": "Ye Jiang"}, {"name": "Iknoor Singh"}, {"name": "Diana Maynard"}, {"name": "Kalina Bontcheva"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0247086"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0247086", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2006.03354v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.03354v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is arXiv version of \"Classification Aware Neural Topic Model for\n  COVID-19 Disinformation Categorisation\""}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PLOS ONE 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.07388v1", "updated": "2020-07-14T22:38:48Z", "published": "2020-07-14T22:38:48Z", "title": "Combating Disinformation in a Social Media Age", "summary": "The creation, dissemination, and consumption of disinformation and fabricated\ncontent on social media is a growing concern, especially with the ease of\naccess to such sources, and the lack of awareness of the existence of such\nfalse information. In this paper, we present an overview of the techniques\nexplored to date for the combating of disinformation with various forms. We\nintroduce different forms of disinformation, discuss factors related to the\nspread of disinformation, elaborate on the inherent challenges in detecting\ndisinformation, and show some approaches to mitigating disinformation via\neducation, research, and collaboration. Looking ahead, we present some\npromising future research directions on disinformation.", "author": [{"name": "Kai Shu"}, {"name": "Amrita Bhattacharjee"}, {"name": "Faisal Alatawi"}, {"name": "Tahora Nazer"}, {"name": "Kaize Ding"}, {"name": "Mansooreh Karami"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "WIREs Data Mining and Knowledge Discovery"}, "link": [{"@href": "http://arxiv.org/abs/2007.07388v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.07388v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/cond-mat/0312266v1", "updated": "2003-12-10T19:26:05Z", "published": "2003-12-10T19:26:05Z", "title": "Efficiency through disinformation", "summary": "We study the impact of disinformation on a model of resource allocation with\nindependent selfish agents: clients send requests to one of two servers,\ndepending on which one is perceived as offering shorter waiting times. Delays\nin the information about the servers' state leads to oscillations in load.\nServers can give false information about their state (global disinformation) or\nrefuse service to individual clients (local disinformation). We discuss the\ntradeoff between positive effects of disinformation (attenuation of\noscillations) and negative effects (increased fluctuations and reduced\nadaptability) for different parameter values.", "author": [{"name": "Richard Metzler"}, {"name": "Mark Klein"}, {"name": "Yaneer Bar-Yam"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 3 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Physical Review B 69 (2004) 235309"}, "link": [{"@href": "http://arxiv.org/abs/cond-mat/0312266v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/cond-mat/0312266v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cond-mat.dis-nn", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cond-mat.dis-nn", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.04311v1", "updated": "2021-04-09T11:33:02Z", "published": "2021-04-09T11:33:02Z", "title": "Helping People Deal With Disinformation -- A Socio-Technical Perspective", "summary": "At the latest since the advent of the Internet, disinformation and conspiracy\ntheories have become ubiquitous. Recent examples like QAnon and Pizzagate prove\nthat false information can lead to real violence. In this motivation statement\nfor the Workshop on Human Aspects of Misinformation at CHI 2021, I explain my\nresearch agenda focused on 1. why people believe in disinformation, 2. how\npeople can be best supported in recognizing disinformation, and 3. what the\npotentials and risks of different tools designed to fight disinformation are.", "author": {"name": "Hendrik Heuer"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This paper will be presented at the Workshop on Human Aspects of\n  Misinformation at CHI 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.04311v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.04311v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.12596v1", "updated": "2019-10-14T19:58:15Z", "published": "2019-10-14T19:58:15Z", "title": "Online Disinformation and the Role of Wikipedia", "summary": "The aim of this study is to find key areas of research that can be useful to\nfight against disinformation on Wikipedia. To address this problem we perform a\nliterature review trying to answer three main questions: (i) What is\ndisinformation? (ii) What are the most popular mechanisms to spread online\ndisinformation? and (iii) Which are the mechanisms that are currently being\nused to fight against disinformation?. In all these three questions we take\nfirst a general approach, considering studies from different areas such as\njournalism and communications, sociology, philosophy, information and political\nsciences. And comparing those studies with the current situation on the\nWikipedia ecosystem. We conclude that in order to keep Wikipedia as free as\npossible from disinformation, it is necessary to help patrollers to early\ndetect disinformation and assess the credibility of external sources. More\nresearch is needed to develop tools that use state-of-the-art machine learning\ntechniques to detect potentially dangerous content, empowering patrollers to\ndeal with attacks that are becoming more complex and sophisticated.", "author": {"name": "Diego Saez-Trumper"}, "link": [{"@href": "http://arxiv.org/abs/1910.12596v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.12596v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.09113v1", "updated": "2020-10-18T21:44:23Z", "published": "2020-10-18T21:44:23Z", "title": "Disinformation in the Online Information Ecosystem: Detection,\n  Mitigation and Challenges", "summary": "With the rapid increase in access to internet and the subsequent growth in\nthe population of online social media users, the quality of information posted,\ndisseminated and consumed via these platforms is an issue of growing concern. A\nlarge fraction of the common public turn to social media platforms and in\ngeneral the internet for news and even information regarding highly concerning\nissues such as COVID-19 symptoms. Given that the online information ecosystem\nis extremely noisy, fraught with misinformation and disinformation, and often\ncontaminated by malicious agents spreading propaganda, identifying genuine and\ngood quality information from disinformation is a challenging task for humans.\nIn this regard, there is a significant amount of ongoing research in the\ndirections of disinformation detection and mitigation. In this survey, we\ndiscuss the online disinformation problem, focusing on the recent 'infodemic'\nin the wake of the coronavirus pandemic. We then proceed to discuss the\ninherent challenges in disinformation research, and then elaborate on the\ncomputational and interdisciplinary approaches towards mitigation of\ndisinformation, after a short overview of the various directions explored in\ndetection efforts.", "author": [{"name": "Amrita Bhattacharjee"}, {"name": "Kai Shu"}, {"name": "Min Gao"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "A Chinese version of this manuscript has been submitted to the\n  Journal of Computer Research and Development"}, "link": [{"@href": "http://arxiv.org/abs/2010.09113v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.09113v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.00623v1", "updated": "2020-01-02T21:01:02Z", "published": "2020-01-02T21:01:02Z", "title": "Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements", "summary": "In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.", "author": [{"name": "Kai Shu"}, {"name": "Suhang Wang"}, {"name": "Dongwon Lee"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted as an introductory chapter for the edited book on \"Fake\n  News, Disinformation, and Misinformation in Social Media- Emerging Research\n  Challenges and Opportunities\", Springer Press"}, "link": [{"@href": "http://arxiv.org/abs/2001.00623v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.00623v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.13466v2", "updated": "2020-09-07T15:49:25Z", "published": "2020-05-27T16:23:04Z", "title": "On the Detection of Disinformation Campaign Activity with Network\n  Analysis", "summary": "Online manipulation of information has become more prevalent in recent years\nas state-sponsored disinformation campaigns seek to influence and polarize\npolitical topics through massive coordinated efforts. In the process, these\nefforts leave behind artifacts, which researchers have leveraged to analyze the\ntactics employed by disinformation campaigns after they are taken down.\nCoordination network analysis has proven helpful for learning about how\ndisinformation campaigns operate; however, the usefulness of these forensic\ntools as a detection mechanism is still an open question. In this paper, we\nexplore the use of coordination network analysis to generate features for\ndistinguishing the activity of a disinformation campaign from legitimate\nTwitter activity. Doing so would provide more evidence to human analysts as\nthey consider takedowns. We create a time series of daily coordination networks\nfor both Twitter disinformation campaigns and legitimate Twitter communities,\nand train a binary classifier based on statistical features extracted from\nthese networks. Our results show that the classifier can predict future\ncoordinated activity of known disinformation campaigns with high accuracy (F1 =\n0.98). On the more challenging task of out-of-distribution activity\nclassification, the performance drops yet is still promising (F1 = 0.71),\nmainly due to an increase in the false positive rate. By doing this analysis,\nwe show that while coordination patterns could be useful for providing evidence\nof disinformation activity, further investigation is needed to improve upon\nthis method before deployment at scale.", "author": [{"name": "Luis Vargas"}, {"name": "Patrick Emami"}, {"name": "Patrick Traynor"}], "link": [{"@href": "http://arxiv.org/abs/2005.13466v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.13466v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.10772v6", "updated": "2021-08-16T19:01:42Z", "published": "2020-08-25T01:10:57Z", "title": "Adapting Security Warnings to Counter Online Disinformation", "summary": "Disinformation is proliferating on the internet, and platforms are responding\nby attaching warnings to content. There is little evidence, however, that these\nwarnings help users identify or avoid disinformation. In this work, we adapt\nmethods and results from the information security warning literature in order\nto design and evaluate effective disinformation warnings. In an initial\nlaboratory study, we used a simulated search task to examine contextual and\ninterstitial disinformation warning designs. We found that users routinely\nignore contextual warnings, but users notice interstitial warnings -- and\nrespond by seeking information from alternative sources. We then conducted a\nfollow-on crowdworker study with eight interstitial warning designs. We\nconfirmed a significant impact on user information-seeking behavior, and we\nfound that a warning's design could effectively inform users or convey a risk\nof harm. We also found, however, that neither user comprehension nor fear of\nharm moderated behavioral effects. Our work provides evidence that\ndisinformation warnings can -- when designed well -- help users identify and\navoid disinformation. We show a path forward for designing effective warnings,\nand we contribute repeatable methods for evaluating behavioral effects. We also\nsurface a possible dilemma: disinformation warnings might be able to inform\nusers and guide behavior, but the behavioral effects might result from user\nexperience friction, not informed decision making.", "author": [{"name": "Ben Kaiser"}, {"name": "Jerry Wei"}, {"name": "Eli Lucherini"}, {"name": "Kevin Lee"}, {"name": "J. Nathan Matias"}, {"name": "Jonathan Mayer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at USENIX Security '21"}, "link": [{"@href": "http://arxiv.org/abs/2008.10772v6", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.10772v6", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.10836v1", "updated": "2020-10-21T08:53:36Z", "published": "2020-10-21T08:53:36Z", "title": "ReSCo-CC: Unsupervised Identification of Key Disinformation Sentences", "summary": "Disinformation is often presented in long textual articles, especially when\nit relates to domains such as health, often seen in relation to COVID-19. These\narticles are typically observed to have a number of trustworthy sentences among\nwhich core disinformation sentences are scattered. In this paper, we propose a\nnovel unsupervised task of identifying sentences containing key disinformation\nwithin a document that is known to be untrustworthy. We design a three-phase\nstatistical NLP solution for the task which starts with embedding sentences\nwithin a bespoke feature space designed for the task. Sentences represented\nusing those features are then clustered, following which the key sentences are\nidentified through proximity scoring. We also curate a new dataset with\nsentence level disinformation scorings to aid evaluation for this task; the\ndataset is being made publicly available to facilitate further research. Based\non a comprehensive empirical evaluation against techniques from related tasks\nsuch as claim detection and summarization, as well as against simplified\nvariants of our proposed approach, we illustrate that our method is able to\nidentify core disinformation effectively.", "author": [{"name": "Soumya Suvra Ghosal"}, {"name": "Deepak P"}, {"name": "Anna Jurek-Loughrey"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The 22nd International Conference on Information Integration and\n  Web-based Applications & Services (iiWAS '20), Chiang Mai, Thailand"}, "link": [{"@href": "http://arxiv.org/abs/2010.10836v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.10836v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.09251v1", "updated": "2021-01-22T18:03:57Z", "published": "2021-01-22T18:03:57Z", "title": "How to Deal with Fake News: Visualizing Disinformation", "summary": "The current public sense of anxiety in dealing with disinformation as\nmanifested by so-called fake news is acutely displayed by the reaction to\nrecent events prompted by a belief in conspiracies among certain groups. A\nmodel to deal with disinformation is proposed; it is based on a demonstration\nof the analogous behavior of disinformation to that of wave phenomena. Two\ncriteria form the basis to combat the deleterious effects of disinformation:\nthe use of a refractive medium based on skepticism as the default mode, and\npolarization as a filter mechanism to analyze its merits based on evidence.\nCritical thinking is enhanced since the first one tackles the pernicious effect\nof the confirmation bias, and the second the tendency towards attribution, both\nof which undermine our efforts to think and act rationally. The benefits of\nsuch a strategy include an epistemic reformulation of disinformation as an\nindependently existing phenomenon, that removes its negative connotations when\nperceived as being possessed by groups or individuals.", "author": [{"name": "F. Espinoza"}, {"name": "Department of Physics"}, {"name": "Astronomy"}, {"name": "Hofstra University"}, {"name": "Hempstead"}, {"name": "NY. USA."}, {"name": "Department of Chemistry"}, {"name": "Physics-Adolescence Education"}, {"name": "SUNY Old Westbury"}, {"name": "Old Westbury"}, {"name": "NY. USA"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Four figures explaining the proposed mechanism that describe wave\n  properties and behavior. The quantitative details are kept to a minimum so as\n  to highlight the relevance of the treatment of disinformation as a wave, to\n  the larger public sphere"}, "link": [{"@href": "http://arxiv.org/abs/2101.09251v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.09251v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.11000v2", "updated": "2021-06-29T15:52:04Z", "published": "2021-06-21T11:40:00Z", "title": "A Comparative Study of Online Disinformation and Offline Protests", "summary": "In early 2021 the United States Capitol in Washington was stormed during a\nriot and violent attack. Although the storming was merely an instance in a long\nsequence of events, it provided a testimony for many observers who had claimed\nthat online actions, including the propagation of disinformation, have offline\nconsequences. Soon after, a number of papers have been published about the\nrelation between online disinformation and offline violence, among other\nrelated relations. Hitherto, the effects upon political protests have been\nunexplored. This paper thus evaluates such effects with a time series\ncross-sectional sample of 125 countries in a period between 2000 and 2019. The\nresults are mixed. Based on Bayesian multi-level regression modeling, (i) there\nindeed is an effect between online disinformation and offline protests, but the\neffect is partially meditated by political polarization. The results are\nclearer in a sample of countries belonging to the European Economic Area. With\nthis sample, (ii) offline protest counts increase from online disinformation\ndisseminated by domestic governments, political parties, and politicians as\nwell as by foreign governments. Furthermore, (iii) Internet shutdowns and\ngovernmental monitoring of social media tend to decrease the counts. With these\nresults, the paper contributes to the blossoming disinformation research by\nmodeling the impact of disinformation upon offline phenomenon. The contribution\nis important due to the various policy measures planned or already enacted.", "author": {"name": "Jukka Ruohonen"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted"}, "link": [{"@href": "http://arxiv.org/abs/2106.11000v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.11000v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1901.01464v1", "updated": "2019-01-05T20:23:02Z", "published": "2019-01-05T20:23:02Z", "title": "The Value of Misinformation and Disinformation", "summary": "Information is a critical dimension in warfare. Inaccurate information such\nas misinformation or disinformation further complicates military operations. In\nthis paper, we examine the value of misinformation and disinformation to a\nmilitary leader who through investment in people, programs and technology is\nable to affect the accuracy of information communicated between other actors.\nWe model the problem as a partially observable stochastic game with three\nagents, a leader and two followers. We determine the value to the leader of\nmisinformation or disinformation being communicated between two (i) adversarial\nfollowers and (ii) allied followers. We demonstrate that only under certain\nconditions, the prevalent intuition that the leader would benefit from less\n(more) accurate communication between adversarial (allied) followers is valid.\nWe analyzed why the intuition may fail and show a holistic paradigm taking into\naccount both the reward structures and policies of agents is necessary in order\nto correctly determine the value of misinformation and disinformation. Our\nresearch identifies efficient targeted investments to affect the accuracy of\ninformation communicated between followers to the leader's advantage.", "author": [{"name": "Yanling Chang"}, {"name": "Matthew F. Keblis"}, {"name": "Ran Li"}, {"name": "Eleftherios Iakovou"}, {"name": "Chelsea C. White III"}], "link": [{"@href": "http://arxiv.org/abs/1901.01464v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.01464v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "math.OC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "math.OC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1907.08170v2", "updated": "2019-10-28T14:38:48Z", "published": "2019-07-18T17:22:58Z", "title": "Investigating Italian disinformation spreading on Twitter in the context\n  of 2019 European elections", "summary": "We investigate the presence (and the influence) of disinformation spreading\non online social networks in Italy, in the5-month period preceding the 2019\nEuropean Parliament elections. To this aim we collected a large-scale dataset\noftweets associated to thousands of news articles published on Italian\ndisinformation websites. In the observation period,a few outlets accounted for\nmost of the deceptive information circulating on Twitter, which focused on\ncontroversialand polarizing topics of debate such as immigration, national\nsafety and (Italian) nationalism. We found evidence ofconnections between\ndifferent disinformation outlets across Europe, U.S. and Russia, which often\nlinked to each otherand featured similar, even translated, articles in the\nperiod before the elections. Overall, the spread of disinformation onTwitter\nwas confined in a limited community, strongly (and explicitly) related to the\nItalian conservative and far-rightpolitical environment, who had a limited\nimpact on online discussions on the up-coming elections.", "author": [{"name": "Francesco Pierri"}, {"name": "Alessandro Artoni"}, {"name": "Stefano Ceri"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0227821"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0227821", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1907.08170v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.08170v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PloS one 15.1 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1908.02589v1", "updated": "2019-08-01T03:04:20Z", "published": "2019-08-01T03:04:20Z", "title": "How weaponizing disinformation can bring down a city's power grid", "summary": "Social technologies have made it possible to propagate disinformation and\nmanipulate the masses at an unprecedented scale. This is particularly alarming\nfrom a security perspective, as humans have proven to be the weakest link when\nprotecting critical infrastructure in general, and the power grid in\nparticular. Here, we consider an attack in which an adversary attempts to\nmanipulate the behavior of energy consumers by sending fake discount\nnotifications encouraging them to shift their consumption into the peak-demand\nperiod. We conduct surveys to assess the propensity of people to follow-through\non such notifications and forward them to their friends. This allows us to\nmodel how the disinformation propagates through social networks. Finally, using\nGreater London as a case study, we show that disinformation can indeed be used\nto orchestrate an attack wherein unwitting consumers synchronize their\nenergy-usage patterns, resulting in blackouts on a city-scale. These findings\ndemonstrate that in an era when disinformation can be weaponized, system\nvulnerabilities arise not only from the hardware and software of critical\ninfrastructure, but also from the behavior of the consumers.", "author": [{"name": "Gururaghav Raman"}, {"name": "Bedoor AlShebli"}, {"name": "Marcin Waniek"}, {"name": "Talal Rahwan"}, {"name": "Jimmy Chih-Hsien Peng"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0236517"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0236517", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1908.02589v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.02589v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 3 figures"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.03067v1", "updated": "2021-08-06T11:39:05Z", "published": "2021-08-06T11:39:05Z", "title": "Deriving Disinformation Insights from Geolocalized Twitter Callouts", "summary": "This paper demonstrates a two-stage method for deriving insights from social\nmedia data relating to disinformation by applying a combination of geospatial\nclassification and embedding-based language modelling across multiple\nlanguages. In particular, the analysis in centered on Twitter and\ndisinformation for three European languages: English, French and Spanish.\nFirstly, Twitter data is classified into European and non-European sets using\nBERT. Secondly, Word2vec is applied to the classified texts resulting in\nEurocentric, non-Eurocentric and global representations of the data for the\nthree target languages. This comparative analysis demonstrates not only the\nefficacy of the classification method but also highlights geographic, temporal\nand linguistic differences in the disinformation-related media. Thus, the\ncontributions of the work are threefold: (i) a novel language-independent\ntransformer-based geolocation method; (ii) an analytical approach that exploits\nlexical specificity and word embeddings to interrogate user-generated content;\nand (iii) a dataset of 36 million disinformation related tweets in English,\nFrench and Spanish.", "author": [{"name": "David Tuxworth"}, {"name": "Dimosthenis Antypas"}, {"name": "Luis Espinosa-Anke"}, {"name": "Jose Camacho-Collados"}, {"name": "Alun Preece"}, {"name": "David Rogers"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for presentation at KDD 2021 - Workshop On Deriving Insights\n  From User-Generated Text"}, "link": [{"@href": "http://arxiv.org/abs/2108.03067v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.03067v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.05150v1", "updated": "2021-08-11T10:56:10Z", "published": "2021-08-11T10:56:10Z", "title": "Exploring the Links between Personality Traits and Suscep;bility to\n  Disinformation", "summary": "The growth of online Digital/social media has allowed a variety of ideas and\nopinions to coexist. Social Media has appealed users due to the ease of fast\ndissemination of information at low cost and easy access. However, due to the\ngrowth in affordance of Digital platforms, users have become prone to consume\ndisinformation, misinformation, propaganda, and conspiracy theories. In this\npaper, we wish to explore the links between the personality traits given by the\nBig Five Inventory and their susceptibility to disinformation. More\nspeciDically, this study is attributed to capture the short- term as well as\nthe long-term effects of disinformation and its effects on the Dive personality\ntraits. Further, we expect to observe that different personalities traits have\ndifferent shifts in opinion and different increase or decrease of uncertainty\non an issue after consuming the disinformation. Based on the Dindings of this\nstudy, we would like to propose a personalized narrative-based change in\nbehavior for different personality traits.", "author": [{"name": "Dipto Barman"}, {"name": "Owen Conlan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3465336.3475121"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3465336.3475121", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.05150v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.05150v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "4 pages, 1 figure, ACM conference"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.11669v1", "updated": "2021-08-26T09:28:50Z", "published": "2021-08-26T09:28:50Z", "title": "Technological Approaches to Detecting Online Disinformation and\n  Manipulation", "summary": "The move of propaganda and disinformation to the online environment is\npossible thanks to the fact that within the last decade, digital information\nchannels radically increased in popularity as a news source. The main advantage\nof such media lies in the speed of information creation and dissemination.\nThis, on the other hand, inevitably adds pressure, accelerating editorial work,\nfact-checking, and the scrutiny of source credibility. In this chapter, an\noverview of computer-supported approaches to detecting disinformation and\nmanipulative techniques based on several criteria is presented. We concentrate\non the technical aspects of automatic methods which support fact-checking,\ntopic identification, text style analysis, or message filtering on social media\nchannels. Most of the techniques employ artificial intelligence and machine\nlearning with feature extraction combining available information resources. The\nfollowing text firstly specifies the tasks related to computer detection of\nmanipulation and disinformation spreading. The second section presents concrete\nmethods of solving the tasks of the analysis, and the third sections enlists\ncurrent verification and benchmarking datasets published and used in this area\nfor evaluation and comparison.", "author": [{"name": "Ale\u0161 Hor\u00e1k"}, {"name": "V\u00edt Baisa"}, {"name": "Ond\u0159ej Herman"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-58624-9"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-58624-9", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.11669v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.11669v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is an author preprint of the 5th chapter in the book of\n  \"Challenging Online Propaganda and Disinformation in the 21st Century\"\n  published by Palgrave Macmillan at\n  https://www.palgrave.com/gp/book/9783030586232"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.01313v1", "updated": "2020-03-03T03:25:16Z", "published": "2020-03-03T03:25:16Z", "title": "Unveiling Coordinated Groups Behind White Helmets Disinformation", "summary": "Propaganda, disinformation, manipulation, and polarization are the modern\nillnesses of a society increasingly dependent on social media as a source of\nnews. In this paper, we explore the disinformation campaign, sponsored by\nRussia and allies, against the Syria Civil Defense (a.k.a. the White Helmets).\nWe unveil coordinated groups using automatic retweets and content duplication\nto promote narratives and/or accounts. The results also reveal distinct\npromoting strategies, ranging from the small groups sharing the exact same text\nrepeatedly, to complex \"news website factories\" where dozens of accounts\nsynchronously spread the same news from multiple sites.", "author": [{"name": "Diogo Pacheco"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3366424.3385775"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3366424.3385775", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.01313v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.01313v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To be presented at WWW 2020 Workshop on Computational Methods in\n  Online Misbehavior and forthcoming in the Companion Proceedings of the Web\n  Conference 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2008.01535v2", "updated": "2020-08-05T01:53:01Z", "published": "2020-07-30T08:56:51Z", "title": "Weighted Accuracy Algorithmic Approach In Counteracting Fake News And\n  Disinformation", "summary": "As the world is becoming more dependent on the internet for information\nexchange, some overzealous journalists, hackers, bloggers, individuals and\norganizations tend to abuse the gift of free information environment by\npolluting it with fake news, disinformation and pretentious content for their\nown agenda. Hence, there is the need to address the issue of fake news and\ndisinformation with utmost seriousness. This paper proposes a methodology for\nfake news detection and reporting through a constraint mechanism that utilizes\nthe combined weighted accuracies of four machine learning algorithms.", "author": {"name": "Kwadwo Osei Bonsu"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.2478/ers-2021-0007"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.2478/ers-2021-0007", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.01535v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.01535v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.08919v2", "updated": "2021-01-19T23:02:58Z", "published": "2020-12-16T13:10:56Z", "title": "Multilingual Evidence Retrieval and Fact Verification to Combat Global\n  Disinformation: The Power of Polyglotism", "summary": "This article investigates multilingual evidence retrieval and fact\nverification as a step to combat global disinformation, a first effort of this\nkind, to the best of our knowledge. The goal is building multilingual systems\nthat retrieve in evidence-rich languages to verify claims in evidence-poor\nlanguages that are more commonly targeted by disinformation. To this end, our\nEnmBERT fact verification system shows evidence of transfer learning ability\nand 400 example mixed English-Romanian dataset is made available for\ncross-lingual transfer learning evaluation.", "author": {"name": "Denisa A. O. Roberts"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted ECIR 2021"}, "link": [{"@href": "http://arxiv.org/abs/2012.08919v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.08919v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.12541v1", "updated": "2021-03-13T18:04:17Z", "published": "2021-03-13T18:04:17Z", "title": "A Survey on Multimodal Disinformation Detection", "summary": "Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.", "author": [{"name": "Firoj Alam"}, {"name": "Stefano Cresci"}, {"name": "Tanmoy Chakraborty"}, {"name": "Fabrizio Silvestri"}, {"name": "Dimiter Dimitrov"}, {"name": "Giovanni Da San Martino"}, {"name": "Shaden Shaar"}, {"name": "Hamed Firooz"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, multimodality, text, images, videos, network structure,\n  temporality"}, "link": [{"@href": "http://arxiv.org/abs/2103.12541v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.12541v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.11951v1", "updated": "2019-11-27T04:52:53Z", "published": "2019-11-27T04:52:53Z", "title": "Taking a Stance on Fake News: Towards Automatic Disinformation\n  Assessment via Deep Bidirectional Transformer Language Models for Stance\n  Detection", "summary": "The exponential rise of social media and digital news in the past decade has\nhad the unfortunate consequence of escalating what the United Nations has\ncalled a global topic of concern: the growing prevalence of disinformation.\nGiven the complexity and time-consuming nature of combating disinformation\nthrough human assessment, one is motivated to explore harnessing AI solutions\nto automatically assess news articles for the presence of disinformation. A\nvaluable first step towards automatic identification of disinformation is\nstance detection, where given a claim and a news article, the aim is to predict\nif the article agrees, disagrees, takes no position, or is unrelated to the\nclaim. Existing approaches in literature have largely relied on hand-engineered\nfeatures or shallow learned representations (e.g., word embeddings) to encode\nthe claim-article pairs, which can limit the level of representational\nexpressiveness needed to tackle the high complexity of disinformation\nidentification. In this work, we explore the notion of harnessing large-scale\ndeep bidirectional transformer language models for encoding claim-article pairs\nin an effort to construct state-of-the-art stance detection geared for\nidentifying disinformation. Taking advantage of bidirectional cross-attention\nbetween claim-article pairs via pair encoding with self-attention, we construct\na large-scale language model for stance detection by performing transfer\nlearning on a RoBERTa deep bidirectional transformer language model, and were\nable to achieve state-of-the-art performance (weighted accuracy of 90.01%) on\nthe Fake News Challenge Stage 1 (FNC-I) benchmark. These promising results\nserve as motivation for harnessing such large-scale language models as powerful\nbuilding blocks for creating effective AI solutions to combat disinformation.", "author": [{"name": "Chris Dulhanty"}, {"name": "Jason L. Deglint"}, {"name": "Ibrahim Ben Daya"}, {"name": "Alexander Wong"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the AI for Social Good Workshop at NeurIPS 2019"}, "link": [{"@href": "http://arxiv.org/abs/1911.11951v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.11951v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.00379v1", "updated": "2020-03-29T01:07:04Z", "published": "2020-03-29T01:07:04Z", "title": "Resistance of communities against disinformation", "summary": "The spread of disinformation is considered a big threat to societies and has\nrecently received unprecedented attention. In this paper we propose an\nagent-based model to simulate dissemination of a conspiracy in a population.\nThe model is able to compare the resistance of different network structures\nagainst the activity of conspirators. Results show that connectedness of\nnetwork structure and centrality of conspirators are of crucial importance in\npreventing conspiracies from becoming widespread.", "author": [{"name": "Amirarsalan Rajabi"}, {"name": "Seyyedmilad Talebzadehhosseini"}, {"name": "Ivan Garibay"}], "link": [{"@href": "http://arxiv.org/abs/2004.00379v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.00379v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1910.12073v1", "updated": "2019-10-26T14:29:37Z", "published": "2019-10-26T14:29:37Z", "title": "Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments", "summary": "Over the past couple of years, the topic of \"fake news\" and its influence\nover people's opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to \"go viral.\" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.", "author": {"name": "Jillian Tompkins"}, "link": [{"@href": "http://arxiv.org/abs/1910.12073v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.12073v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1812.09383v2", "updated": "2019-01-03T14:35:55Z", "published": "2018-12-21T21:46:34Z", "title": "Technology-Enabled Disinformation: Summary, Lessons, and Recommendations", "summary": "Technology is increasingly used -- unintentionally (misinformation) or\nintentionally (disinformation) -- to spread false information at scale, with\npotentially broad-reaching societal effects. For example, technology enables\nincreasingly realistic false images and videos, and hyper-personal targeting\nmeans different people may see different versions of reality. This report is\nthe culmination of a PhD-level special topics course\n(https://courses.cs.washington.edu/courses/cse599b/18au/) in Computer Science &\nEngineering at the University of Washington's Paul G. Allen School in the fall\nof 2018. The goals of this course were to study (1) how technologies and\ntoday's technical platforms enable and support the creation and spread of such\nmis- and disinformation, as well as (2) how technical approaches could be used\nto mitigate these issues. In this report, we summarize the space of\ntechnology-enabled mis- and disinformation based on our investigations, and\nthen surface our lessons and recommendations for technologists, researchers,\nplatform designers, policymakers, and users.", "author": [{"name": "John Akers"}, {"name": "Gagan Bansal"}, {"name": "Gabriel Cadamuro"}, {"name": "Christine Chen"}, {"name": "Quanze Chen"}, {"name": "Lucy Lin"}, {"name": "Phoebe Mulcaire"}, {"name": "Rajalakshmi Nandakumar"}, {"name": "Matthew Rockett"}, {"name": "Lucy Simko"}, {"name": "John Toman"}, {"name": "Tongshuang Wu"}, {"name": "Eric Zeng"}, {"name": "Bill Zorn"}, {"name": "Franziska Roesner"}], "link": [{"@href": "http://arxiv.org/abs/1812.09383v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.09383v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1905.10412v1", "updated": "2019-05-24T19:10:18Z", "published": "2019-05-24T19:10:18Z", "title": "Using Deep Networks and Transfer Learning to Address Disinformation", "summary": "We apply an ensemble pipeline composed of a character-level convolutional\nneural network (CNN) and a long short-term memory (LSTM) as a general tool for\naddressing a range of disinformation problems. We also demonstrate the ability\nto use this architecture to transfer knowledge from labeled data in one domain\nto related (supervised and unsupervised) tasks. Character-level neural networks\nand transfer learning are particularly valuable tools in the disinformation\nspace because of the messy nature of social media, lack of labeled data, and\nthe multi-channel tactics of influence campaigns. We demonstrate their\neffectiveness in several tasks relevant for detecting disinformation: spam\nemails, review bombing, political sentiment, and conversation clustering.", "author": [{"name": "Numa Dhamani"}, {"name": "Paul Azunre"}, {"name": "Jeffrey L. Gleason"}, {"name": "Craig Corcoran"}, {"name": "Garrett Honke"}, {"name": "Steve Kramer"}, {"name": "Jonathon Morgan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AI for Social Good Workshop at the International Conference on\n  Machine Learning, Long Beach, United States (2019)"}, "link": [{"@href": "http://arxiv.org/abs/1905.10412v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.10412v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.13398v1", "updated": "2021-05-27T18:59:12Z", "published": "2021-05-27T18:59:12Z", "title": "Tactical Reframing of Online Disinformation Campaigns Against The\n  Istanbul Convention", "summary": "In March 2021, Turkey withdrew from The Istanbul Convention, a human-rights\ntreaty that addresses violence against women, citing issues with the\nconvention's implicit recognition of sexual and gender minorities. In this\nwork, we trace disinformation campaigns related to the Istanbul Convention and\nits associated Turkish law that circulate on divorced men's rights Facebook\ngroups. We find that these groups adjusted the narrative and focus of the\ncampaigns to appeal to a larger audience, which we refer to as \"tactical\nreframing.\" Initially, the men organized in a grass-roots manner to campaign\nagainst the Turkish law that was passed to codify the convention, focusing on\none-sided custody of children and indefinite alimony. Later, they reframed\ntheir campaign and began attacking the Istanbul Convention, highlighting its\nacknowledgment of homosexuality. This case study highlights how disinformation\ncampaigns can be used to weaponize homophobia in order to limit the rights of\nwomen. To the best of our knowledge, this is the first case study that analyzes\na narrative reframing in the context of a disinformation campaign on social\nmedia.", "author": [{"name": "Tu\u011frulcan Elmas"}, {"name": "Rebekah Overdorf"}, {"name": "Karl Aberer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.36190/2021.42"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.36190/2021.42", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2105.13398v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.13398v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to Data For the Welbeing of Most Vulnerable (DWMV) Workshop\n  colocated with ICWSM 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1707.00086v1", "updated": "2017-07-01T02:37:13Z", "published": "2017-07-01T02:37:13Z", "title": "Disinformation and Social Bot Operations in the Run Up to the 2017\n  French Presidential Election", "summary": "Recent accounts from researchers, journalists, as well as federal\ninvestigators, reached a unanimous conclusion: social media are systematically\nexploited to manipulate and alter public opinion. Some disinformation campaigns\nhave been coordinated by means of bots, social media accounts controlled by\ncomputer scripts that try to disguise themselves as legitimate human users. In\nthis study, we describe one such operation occurred in the run up to the 2017\nFrench presidential election. We collected a massive Twitter dataset of nearly\n17 million posts occurred between April 27 and May 7, 2017 (Election Day). We\nthen set to study the MacronLeaks disinformation campaign: By leveraging a mix\nof machine learning and cognitive behavioral modeling techniques, we separated\nhumans from bots, and then studied the activities of the two groups taken\nindependently, as well as their interplay. We provide a characterization of\nboth the bots and the users who engaged with them and oppose it to those users\nwho didn't. Prior interests of disinformation adopters pinpoint to the reasons\nof the scarce success of this campaign: the users who engaged with MacronLeaks\nare mostly foreigners with a preexisting interest in alt-right topics and\nalternative news media, rather than French users with diverse political views.\nConcluding, anomalous account usage patterns suggest the possible existence of\na black-market for reusable political disinformation bots.", "author": {"name": "Emilio Ferrara"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.5210/fm.v22i8.8005"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.5210/fm.v22i8.8005", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1707.00086v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1707.00086v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "33 pages, 6 figures, 9 tables; submitted to First Monday"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "First Monday, 22(8), 2017"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.12612v2", "updated": "2020-11-12T08:23:47Z", "published": "2020-02-28T09:25:53Z", "title": "A multi-layer approach to disinformation detection on Twitter", "summary": "We tackle the problem of classifying news articles pertaining to\ndisinformation vs mainstream news by solely inspecting their diffusion\nmechanisms on Twitter. Our technique is inherently simple compared to existing\ntext-based approaches, as it allows to by-pass the multiple levels of\ncomplexity which are found in news content (e.g. grammar, syntax, style). We\nemploy a multi-layer representation of Twitter diffusion networks, and we\ncompute for each layer a set of global network features which quantify\ndifferent aspects of the sharing process. Experimental results with two\nlarge-scale datasets, corresponding to diffusion cascades of news shared\nrespectively in the United States and Italy, show that a simple Logistic\nRegression model is able to classify disinformation vs mainstream networks with\nhigh accuracy (AUROC up to 94%), also when considering the political bias of\ndifferent sources in the classification task. We also highlight differences in\nthe sharing patterns of the two news domains which appear to be\ncountry-independent. We believe that our network-based approach provides useful\ninsights which pave the way to the future development of a system to detect\nmisleading and harmful information spreading on social media.", "author": [{"name": "Francesco Pierri"}, {"name": "Carlo Piccardi"}, {"name": "Stefano Ceri"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "A revised version of this pre-print has been published on EPJ Data\n  Science with the title \"A multi-layer approach to disinformation detection in\n  US and Italian news spreading on Twitter\""}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published version on EPJ Data Science (\"A multi-layer approach to\n  disinformation detection in US and Italian news spreading on Twitter\") Dec\n  2020"}, "link": [{"@href": "http://arxiv.org/abs/2002.12612v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.12612v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.15172v1", "updated": "2021-05-31T17:32:06Z", "published": "2021-05-31T17:32:06Z", "title": "Assessing disinformation through the dynamics of supply and demand in\n  the news ecosystem", "summary": "Social dialogue, the foundation of our democracies, is currently threatened\nby disinformation and partisanship, with their disrupting role on individual\nand collective awareness and detrimental effects on decision-making processes.\nDespite a great deal of attention to the news sphere itself, little is known\nabout the subtle interplay between the offer and the demand for information.\nStill, a broader perspective on the news ecosystem, including both the\nproducers and the consumers of information, is needed to build new tools to\nassess the health of the infosphere. Here, we combine in the same framework\nnews supply, as mirrored by a fairly complete Italian news database - partially\nannotated for fake news, and news demand, as captured through the Google Trends\ndata for Italy. Our investigation focuses on the temporal and semantic\ninterplay of news, fake news, and searches in several domains, including the\nvirus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is\nextremely reactive to people's interests and tends to thrive, especially when\nthere is a mismatch between what people are interested in and what news outlets\nprovide. Second, a suitably defined index can assess the level of\ndisinformation only based on the available volumes of news and searches.\nAlthough our results mainly concern the Coronavirus subject, we provide hints\nthat the same findings can have more general applications. We contend these\nresults can be a powerful asset in informing campaigns against disinformation\nand providing news outlets and institutions with potentially relevant\nstrategies.", "author": [{"name": "Pietro Gravino"}, {"name": "Giulio Prevedello"}, {"name": "Martina Galletti"}, {"name": "Vittorio Loreto"}], "link": [{"@href": "http://arxiv.org/abs/2105.15172v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.15172v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.05838v1", "updated": "2019-09-12T17:44:15Z", "published": "2019-09-12T17:44:15Z", "title": "Multilingual Multimodal Digital Deception Detection and Disinformation\n  Spread across Social Platforms", "summary": "Our main contribution in this work is novel results of multilingual models\nthat go beyond typical applications of rumor or misinformation detection in\nEnglish social news content to identify fine-grained classes of digital\ndeception across multiple languages (e.g. Russian, Spanish, etc.). In addition,\nwe present models for multimodal deception detection from images and text and\ndiscuss the limitations of image only and text only models. Finally, we\nelaborate on the ongoing work on measuring deceptive content (in particular\ndisinformation) spread across social platforms.", "author": [{"name": "Maria Glenski"}, {"name": "Ellyn Ayton"}, {"name": "Josh Mendoza"}, {"name": "Svitlana Volkova"}], "link": [{"@href": "http://arxiv.org/abs/1909.05838v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.05838v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2001.10926v1", "updated": "2020-01-29T16:14:47Z", "published": "2020-01-29T16:14:47Z", "title": "HoaxItaly: a collection of Italian disinformation and fact-checking\n  stories shared on Twitter in 2019", "summary": "We released over 1 million tweets shared during 2019 and containing links to\nthousands of news articles published on two classes of Italian outlets: (1)\ndisinformation websites, i.e. outlets which have been repeatedly flagged by\njournalists and fact-checkers for producing low-credibility content such as\nfalse news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)\nfact-checking websites which notably debunk and verify online news and claims.\nThe dataset, which includes also title and body for approximately 37k news\narticles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.", "author": [{"name": "Francesco Pierri"}, {"name": "Alessandro Artoni"}, {"name": "Stefano Ceri"}], "link": [{"@href": "http://arxiv.org/abs/2001.10926v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.10926v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1812.03533v1", "updated": "2018-12-09T17:53:08Z", "published": "2018-12-09T17:53:08Z", "title": "Propagation from Deceptive News Sources: Who Shares, How Much, How\n  Evenly, and How Quickly?", "summary": "As people rely on social media as their primary sources of news, the spread\nof misinformation has become a significant concern. In this large-scale study\nof news in social media we analyze eleven million posts and investigate\npropagation behavior of users that directly interact with news accounts\nidentified as spreading trusted versus malicious content. Unlike previous work,\nwhich looks at specific rumors, topics, or events, we consider all content\npropagated by various news sources. Moreover, we analyze and contrast\npopulation versus sub-population behaviour (by demographics) when spreading\nmisinformation, and distinguish between two types of propagation, i.e., direct\nretweets and mentions. Our evaluation examines how evenly, how many, how\nquickly, and which users propagate content from various types of news sources\non Twitter.\n  Our analysis has identified several key differences in propagation behavior\nfrom trusted versus suspicious news sources. These include high inequity in the\ndiffusion rate based on the source of disinformation, with a small group of\nhighly active users responsible for the majority of disinformation spread\noverall and within each demographic. Analysis by demographics showed that users\nwith lower annual income and education share more from disinformation sources\ncompared to their counterparts. News content is shared significantly more\nquickly from trusted, conspiracy, and disinformation sources compared to\nclickbait and propaganda. Older users propagate news from trusted sources more\nquickly than younger users, but they share from suspicious sources after longer\ndelays. Finally, users who interact with clickbait and conspiracy sources are\nlikely to share from propaganda accounts, but not the other way around.", "author": [{"name": "Maria Glenski"}, {"name": "Tim Weninger"}, {"name": "Svitlana Volkova"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/TCSS.2018.2881071"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/TCSS.2018.2881071", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1812.03533v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.03533v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages, 6 figures, 7 tables, published in IEEE TCSS December 2018"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IEEE Transactions on Computational Social Systems ( Volume: 5 ,\n  Issue: 4 , Dec. 2018 )"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.05854v1", "updated": "2020-05-12T15:20:55Z", "published": "2020-05-12T15:20:55Z", "title": "Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News", "summary": "Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 \"infodemic\", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n\"fake news\" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta", "author": [{"name": "Giovanni Da San Martino"}, {"name": "Shaden Shaar"}, {"name": "Yifan Zhang"}, {"name": "Seunghak Yu"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, disinformation, fake news, media bias, COVID-19"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL-2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.05854v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.05854v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.08572v1", "updated": "2020-12-15T19:32:36Z", "published": "2020-12-15T19:32:36Z", "title": "An Agenda for Disinformation Research", "summary": "In the 21st Century information environment, adversarial actors use\ndisinformation to manipulate public opinion. The distribution of false,\nmisleading, or inaccurate information with the intent to deceive is an\nexistential threat to the United States--distortion of information erodes trust\nin the socio-political institutions that are the fundamental fabric of\ndemocracy: legitimate news sources, scientists, experts, and even fellow\ncitizens. As a result, it becomes difficult for society to come together within\na shared reality; the common ground needed to function effectively as an\neconomy and a nation. Computing and communication technologies have facilitated\nthe exchange of information at unprecedented speeds and scales. This has had\ncountless benefits to society and the economy, but it has also played a\nfundamental role in the rising volume, variety, and velocity of disinformation.\nTechnological advances have created new opportunities for manipulation,\ninfluence, and deceit. They have effectively lowered the barriers to reaching\nlarge audiences, diminishing the role of traditional mass media along with the\neditorial oversight they provided. The digitization of information exchange,\nhowever, also makes the practices of disinformation detectable, the networks of\ninfluence discernable, and suspicious content characterizable. New tools and\napproaches must be developed to leverage these affordances to understand and\naddress this growing challenge.", "author": [{"name": "Nadya Bliss"}, {"name": "Elizabeth Bradley"}, {"name": "Joshua Garland"}, {"name": "Filippo Menczer"}, {"name": "Scott W. Ruston"}, {"name": "Kate Starbird"}, {"name": "Chris Wiggins"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "A Computing Community Consortium (CCC) white paper, 5 pages"}, "link": [{"@href": "http://arxiv.org/abs/2012.08572v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.08572v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.05900v2", "updated": "2020-10-28T15:05:51Z", "published": "2018-11-14T16:44:59Z", "title": "A Simulated Cyberattack on Twitter: Assessing Partisan Vulnerability to\n  Spear Phishing and Disinformation ahead of the 2018 U.S. Midterm Elections", "summary": "State-sponsored \"bad actors\" increasingly weaponize social media platforms to\nlaunch cyberattacks and disinformation campaigns during elections. Social media\ncompanies, due to their rapid growth and scale, struggle to prevent the\nweaponization of their platforms. This study conducts an automated spear\nphishing and disinformation campaign on Twitter ahead of the 2018 United States\nMidterm Elections. A fake news bot account - the @DCNewsReport - was created\nand programmed to automatically send customized tweets with a \"breaking news\"\nlink to 138 Twitter users, before being restricted by Twitter.\n  Overall, one in five users clicked the link, which could have potentially led\nto the downloading of ransomware or the theft of private information. However,\nthe link in this experiment was non-malicious and redirected users to a Google\nForms survey. In predicting users' likelihood to click the link on Twitter, no\nstatistically significant differences were observed between right-wing and\nleft-wing partisans, or between Web users and mobile users. The findings signal\nthat politically expressive Americans on Twitter, regardless of their party\npreferences or the devices they use to access the platform, are at risk of\nbeing spear phishing on social media.", "author": {"name": "Michael Bossetta"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.5210/fm.v23i12.9540"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.5210/fm.v23i12.9540", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1811.05900v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.05900v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "First Monday, 23(12) (2018)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1904.05386v2", "updated": "2019-10-20T19:30:09Z", "published": "2019-04-10T18:42:45Z", "title": "Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality", "summary": "The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media.", "author": [{"name": "Paula Fraga-Lamas"}, {"name": "Tiago M. Fern\u00e1ndez-Caram\u00e9s"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Updated version"}, "link": [{"@href": "http://arxiv.org/abs/1904.05386v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.05386v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.02712v1", "updated": "2019-05-07T17:53:21Z", "published": "2019-05-07T17:53:21Z", "title": "The Alt-Right and Global Information Warfare", "summary": "The Alt-Right is a neo-fascist white supremacist movement that is involved in\nviolent extremism and shows signs of engagement in extensive disinformation\ncampaigns. Using social media data mining, this study develops a deeper\nunderstanding of such targeted disinformation campaigns and the ways they\nspread. It also adds to the available literature on the endogenous and\nexogenous influences within the US far right, as well as motivating factors\nthat drive disinformation campaigns, such as geopolitical strategy. This study\nis to be taken as a preliminary analysis to indicate future methods and\nfollow-on research that will help develop an integrated approach to\nunderstanding the strategies and associations of the modern fascist movement.", "author": [{"name": "Emmi Bevensee"}, {"name": "Alexander Reid Ross"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/BigData.2018.8622270"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/BigData.2018.8622270", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1905.02712v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.02712v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Presented and published through IEEE 2019 Big Data Conference"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "2018 IEEE International Conference on Big Data (Big Data),\n  4393-4402"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.03723v1", "updated": "2020-03-08T05:33:53Z", "published": "2020-03-08T05:33:53Z", "title": "Traffic networks are vulnerable to disinformation attacks", "summary": "Disinformation continues to attract attention due to its increasing threat to\nsociety. Nevertheless, a disinformation-based attack on critical infrastructure\nhas never been studied to date. Here, we consider traffic networks and focus on\nfake information that manipulates drivers' decisions to create congestion. We\nstudy the optimization problem faced by the adversary when choosing which\nstreets to target to maximize disruption. We prove that finding an optimal\nsolution is computationally intractable, implying that the adversary has no\nchoice but to settle for suboptimal heuristics. We analyze one such heuristic,\nand compare the cases when targets are spread across the city of Chicago vs.\nconcentrated in its business district. Surprisingly, the latter results in more\nfar-reaching disruption, with its impact felt as far as 2 kilometers from the\nclosest target. Our findings demonstrate that vulnerabilities in critical\ninfrastructure may arise not only from hardware and software, but also from\nbehavioral manipulation.", "author": [{"name": "Marcin Waniek"}, {"name": "Gururaghav Raman"}, {"name": "Bedoor AlShebli"}, {"name": "Jimmy Chih-Hsien Peng"}, {"name": "Talal Rahwan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "25 pages, 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/2003.03723v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.03723v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.11792v2", "updated": "2020-09-25T04:46:41Z", "published": "2020-09-24T16:34:47Z", "title": "Understanding the Use of Fauxtography on Social Media", "summary": "Despite the influence that image-based communication has on online discourse,\nthe role played by images in disinformation is still not well understood. In\nthis paper, we present the first large-scale study of fauxtography, analyzing\nthe use of manipulated or misleading images in news discussion on online\ncommunities. First, we develop a computational pipeline geared to detect\nfauxtography, and identify over 61k instances of fauxtography discussed on\nTwitter, 4chan, and Reddit. Then, we study how posting fauxtography affects\nengagement of posts on social media, finding that posts containing it receive\nmore interactions in the form of re-shares, likes, and comments. Finally, we\nshow that fauxtography images are often turned into memes by Web communities.\nOur findings show that effective mitigation against disinformation need to take\nimages into account, and highlight a number of challenges in dealing with\nimage-based disinformation.", "author": [{"name": "Yuping Wang"}, {"name": "Fatemeh Tahmasbi"}, {"name": "Jeremy Blackburn"}, {"name": "Barry Bradlyn"}, {"name": "Emiliano De Cristofaro"}, {"name": "David Magerman"}, {"name": "Savvas Zannettou"}, {"name": "Gianluca Stringhini"}], "link": [{"@href": "http://arxiv.org/abs/2009.11792v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.11792v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2103.00242v1", "updated": "2021-02-27T15:27:22Z", "published": "2021-02-27T15:27:22Z", "title": "A Survey on Stance Detection for Mis- and Disinformation Identification", "summary": "Detecting attitudes expressed in texts, also known as stance detection, has\nbecome an important task for the detection of false information online, be it\nmisinformation (unintentionally false) or disinformation (intentionally false,\nspread deliberately with malicious intent). Stance detection has been framed in\ndifferent ways, including: (a) as a component of fact-checking, rumour\ndetection, and detecting previously fact-checked claims; or (b) as a task in\nits own right. While there have been prior efforts to contrast stance detection\nwith other related social media tasks such as argumentation mining and\nsentiment analysis, there is no survey examining the relationship between\nstance detection detection and mis- and disinformation detection from a\nholistic viewpoint, which is the focus of this survey. We review and analyse\nexisting work in this area, before discussing lessons learnt and future\nchallenges.", "author": [{"name": "Momchil Hardalov"}, {"name": "Arnav Arora"}, {"name": "Preslav Nakov"}, {"name": "Isabelle Augenstein"}], "link": [{"@href": "http://arxiv.org/abs/2103.00242v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.00242v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.15005v1", "updated": "2021-03-27T22:18:20Z", "published": "2021-03-27T22:18:20Z", "title": "Strategically-Motivated Advanced Persistent Threat: Definition, Process,\n  Tactics and a Disinformation Model of Counterattack", "summary": "Advanced persistent threat (APT) is widely acknowledged to be the most\nsophisticated and potent class of security threat. APT refers to knowledgeable\nhuman attackers that are organized, highly sophisticated and motivated to\nachieve their objectives against a targeted organization(s) over a prolonged\nperiod. Strategically-motivated APTs or S-APTs are distinct in that they draw\ntheir objectives from the broader strategic agenda of third parties such as\ncriminal syndicates, nation-states, and rival corporations. In this paper we\nreview the use of the term - Advanced Persistent Threat - and present a formal\ndefinition. We then draw on military science, the science of organized\nconflict, for a theoretical basis to develop a rigorous and holistic model of\nthe stages of an APT operation which we subsequently use to explain how S-APTs\nexecute their strategically motivated operations using tactics, techniques and\nprocedures. Finally, we present a general disinformation model, derived from\nsituation awareness theory, and explain how disinformation can be used to\nattack the situation awareness and decision making of not only S-APT operators,\nbut also the entities that back them.", "author": [{"name": "Atif Ahmad"}, {"name": "Jeb Webb"}, {"name": "Kevin C. Desouza"}, {"name": "James Boorman"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Computers & Security, 2019, Vol 86, pp. 402-418"}, "link": [{"@href": "http://arxiv.org/abs/2103.15005v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.15005v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.15968v1", "updated": "2021-06-30T10:29:07Z", "published": "2021-06-30T10:29:07Z", "title": "The Impact of Disinformation on a Controversial Debate on Social Media", "summary": "In this work we study how pervasive is the presence of disinformation in the\nItalian debate around immigration on Twitter and the role of automated accounts\nin the diffusion of such content. By characterising the Twitter users with an\n\\textit{Untrustworthiness} score, that tells us how frequently they engage with\ndisinformation content, we are able to see that such bad information\nconsumption habits are not equally distributed across the users; adopting a\nnetwork analysis approach, we can identify communities characterised by a very\nhigh presence of users that frequently share content from unreliable news\nsources. Within this context, social bots tend to inject in the network more\nmalicious content, that often remains confined in a limited number of clusters;\ninstead, they target reliable content in order to diversify their reach. The\nevidence we gather suggests that, at least in this particular case study, there\nis a strong interplay between social bots and users engaging with unreliable\ncontent, influencing the diffusion of the latter across the network.", "author": [{"name": "Salvatore Vilella"}, {"name": "Alfonso Semeraro"}, {"name": "Daniela Paolotti"}, {"name": "Giancarlo Ruffo"}], "link": [{"@href": "http://arxiv.org/abs/2106.15968v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.15968v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "K.4; J.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.08319v1", "updated": "2021-07-17T22:11:13Z", "published": "2021-07-17T22:11:13Z", "title": "Characterizing Online Engagement with Disinformation and Conspiracies in\n  the 2020 U.S. Presidential Election", "summary": "Identifying and characterizing disinformation in political discourse on\nsocial media is critical to ensure the integrity of elections and democratic\nprocesses around the world. Persistent manipulation of social media has\nresulted in increased concerns regarding the 2020 U.S. Presidential Election,\ndue to its potential to influence individual opinions and social dynamics. In\nthis work, we focus on the identification of distorted facts, in the form of\nunreliable and conspiratorial narratives in election-related tweets, to\ncharacterize discourse manipulation prior to the election. We apply a detection\nmodel to separate factual from unreliable (or conspiratorial) claims analyzing\na dataset of 242 million election-related tweets. The identified claims are\nused to investigate targeted topics of disinformation, and conspiracy groups,\nmost notably the far-right QAnon conspiracy group. Further, we characterize\naccount engagements with unreliable and conspiracy tweets, and with the QAnon\nconspiracy group, by political leaning and tweet types. Finally, using a\nregression discontinuity design, we investigate whether Twitter's actions to\ncurb QAnon activity on the platform were effective, and how QAnon accounts\nadapt to Twitter's restrictions.", "author": [{"name": "Karishma Sharma"}, {"name": "Emilio Ferrara"}, {"name": "Yan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at ICWSM'22"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ICWSM 2022"}, "link": [{"@href": "http://arxiv.org/abs/2107.08319v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.08319v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.13892v1", "updated": "2021-08-31T14:50:16Z", "published": "2021-08-31T14:50:16Z", "title": "Like Article, Like Audience: Enforcing Multimodal Correlations for\n  Disinformation Detection", "summary": "User-generated content (e.g., tweets and profile descriptions) and shared\ncontent between users (e.g., news articles) reflect a user's online identity.\nThis paper investigates whether correlations between user-generated and\nuser-shared content can be leveraged for detecting disinformation in online\nnews articles. We develop a multimodal learning algorithm for disinformation\ndetection. The latent representations of news articles and user-generated\ncontent allow that during training the model is guided by the profile of users\nwho prefer content similar to the news article that is evaluated, and this\neffect is reinforced if that content is shared among different users. By only\nleveraging user information during model optimization, the model does not rely\non user profiling when predicting an article's veracity. The algorithm is\nsuccessfully applied to three widely used neural classifiers, and results are\nobtained on different datasets. Visualization techniques show that the proposed\nmodel learns feature representations of unseen news articles that better\ndiscriminate between fake and real news texts.", "author": [{"name": "Liesbeth Allein"}, {"name": "Marie-Francine Moens"}, {"name": "Domenico Perrotta"}], "link": [{"@href": "http://arxiv.org/abs/2108.13892v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.13892v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2109.00945v1", "updated": "2021-09-02T13:44:59Z", "published": "2021-09-02T13:44:59Z", "title": "Coordinating Narratives and the Capitol Riots on Parler", "summary": "Coordinated disinformation campaigns are used to influence social media\nusers, potentially leading to offline violence. In this study, we introduce a\ngeneral methodology to uncover coordinated messaging through analysis of user\nparleys on Parler. The proposed method constructs a user-to-user coordination\nnetwork graph induced by a user-to-text graph and a text-to-text similarity\ngraph. The text-to-text graph is constructed based on the textual similarity of\nParler posts. We study three influential groups of users in the 6 January 2020\nCapitol riots and detect networks of coordinated user clusters that are all\nposting similar textual content in support of different disinformation\nnarratives related to the U.S. 2020 elections.", "author": [{"name": "Lynnette Hui Xian Ng"}, {"name": "Iain Cruickshank"}, {"name": "Kathleen M. Carley"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SBP-Brims Disinformation Challenge 2021"}, "link": [{"@href": "http://arxiv.org/abs/2109.00945v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2109.00945v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.09847v1", "updated": "2021-06-17T23:27:43Z", "published": "2021-06-17T23:27:43Z", "title": "Disinformation, Stochastic Harm, and Costly Filtering: A Principal-Agent\n  Analysis of Regulating Social Media Platforms", "summary": "The spread of disinformation on social media platforms such as Facebook is\nharmful to society. This harm can take the form of a gradual degradation of\npublic discourse; but it can also take the form of sudden dramatic events such\nas the recent insurrection on Capitol Hill. The platforms themselves are in the\nbest position to prevent the spread of disinformation, as they have the best\naccess to relevant data and the expertise to use it. However, filtering\ndisinformation is costly, not only for implementing filtering algorithms or\nemploying manual filtering effort, but also because removing such highly viral\ncontent impacts user growth and thus potential advertising revenue. Since the\ncosts of harmful content are borne by other entities, the platform will\ntherefore have no incentive to filter at a socially-optimal level. This problem\nis similar to the problem of environmental regulation, in which the costs of\nadverse events are not directly borne by a firm, the mitigation effort of a\nfirm is not observable, and the causal link between a harmful consequence and a\nspecific failure is difficult to prove. In the environmental regulation domain,\none solution to this issue is to perform costly monitoring to ensure that the\nfirm takes adequate precautions according a specified rule. However,\nclassifying disinformation is performative, and thus a fixed rule becomes less\neffective over time. Encoding our domain as a Markov decision process, we\ndemonstrate that no penalty based on a static rule, no matter how large, can\nincentivize adequate filtering by the platform. Penalties based on an adaptive\nrule can incentivize optimal effort, but counterintuitively, only if the\nregulator sufficiently overreacts to harmful events by requiring a\ngreater-than-optimal level of filtering.", "author": [{"name": "Shehroze Khan"}, {"name": "James R. Wright"}], "link": [{"@href": "http://arxiv.org/abs/2106.09847v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.09847v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.TH", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.10004v2", "updated": "2020-09-23T15:56:39Z", "published": "2020-05-20T12:42:08Z", "title": "Characterizing networks of propaganda on Twitter: a case study", "summary": "The daily exposure of social media users to propaganda and disinformation\ncampaigns has reinvigorated the need to investigate the local and global\npatterns of diffusion of different (mis)information content on social media.\nEcho chambers and influencers are often deemed responsible of both the\npolarization of users in online social networks and the success of propaganda\nand disinformation campaigns. This article adopts a data-driven approach to\ninvestigate the structuration of communities and propaganda networks on Twitter\nin order to assess the correctness of these imputations. In particular, the\nwork aims at characterizing networks of propaganda extracted from a Twitter\ndataset by combining the information gained by three different classification\napproaches, focused respectively on (i) using Tweets content to infer the\n\"polarization\" of users around a specific topic, (ii) identifying users having\nan active role in the diffusion of different propaganda and disinformation\nitems, and (iii) analyzing social ties to identify topological clusters and\nusers playing a \"central\" role in the network. The work identifies highly\npartisan community structures along political alignments; furthermore,\ncentrality metrics proved to be very informative to detect the most active\nusers in the network and to distinguish users playing different roles; finally,\npolarization and clustering structure of the retweet graphs provided useful\ninsights about relevant properties of users exposure, interactions, and\nparticipation to different propaganda items.", "author": [{"name": "Stefano Guarino"}, {"name": "Noemi Trino"}, {"name": "Alessandro Celestini"}, {"name": "Alessandro Chessa"}, {"name": "Gianni Riotta"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/s41109-020-00286-y"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/s41109-020-00286-y", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2005.10004v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.10004v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Applied Network Science 5, 59 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.10879v3", "updated": "2021-01-07T22:15:57Z", "published": "2020-05-21T20:15:51Z", "title": "Automatic Detection of Influential Actors in Disinformation Networks", "summary": "The weaponization of digital communications and social media to conduct\ndisinformation campaigns at immense scale, speed, and reach presents new\nchallenges to identify and counter hostile influence operations (IOs). This\npaper presents an end-to-end framework to automate detection of disinformation\nnarratives, networks, and influential actors. The framework integrates natural\nlanguage processing, machine learning, graph analytics, and a novel network\ncausal inference approach to quantify the impact of individual actors in\nspreading IO narratives. We demonstrate its capability on real-world hostile IO\ncampaigns with Twitter datasets collected during the 2017 French presidential\nelections, and known IO accounts disclosed by Twitter over a broad range of IO\ncampaigns (May 2007 to February 2020), over 50,000 accounts, 17 countries, and\ndifferent account types including both trolls and bots. Our system detects IO\naccounts with 96% precision, 79% recall, and 96% area-under-the-PR-curve, maps\nout salient network communities, and discovers high-impact accounts that escape\nthe lens of traditional impact statistics based on activity counts and network\ncentrality. Results are corroborated with independent sources of known IO\naccounts from U.S. Congressional reports, investigative journalism, and IO\ndatasets provided by Twitter.", "author": [{"name": "Steven T. Smith"}, {"name": "Edward K. Kao"}, {"name": "Erika D. Mackin"}, {"name": "Danelle C. Shah"}, {"name": "Olga Simek"}, {"name": "Donald B. Rubin"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1073/pnas.2011216118"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1073/pnas.2011216118", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2005.10879v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.10879v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proc. Natl. Acad. Sciences U.S.A. Vol. 118, No. 4, e2011216118"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.01142v1", "updated": "2020-12-28T13:07:42Z", "published": "2020-12-28T13:07:42Z", "title": "Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study", "summary": "Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.", "author": [{"name": "Michal Choras"}, {"name": "Konstantinos Demestichas"}, {"name": "Agata Gielczyk"}, {"name": "Alvaro Herrero"}, {"name": "Pawel Ksieniewicz"}, {"name": "Konstantina Remoundou"}, {"name": "Daniel Urda"}, {"name": "Michal Wozniak"}], "link": [{"@href": "http://arxiv.org/abs/2101.01142v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.01142v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/gr-qc/0504037v1", "updated": "2005-04-08T18:15:03Z", "published": "2005-04-08T18:15:03Z", "title": "The disinformation problem for black holes (conference version)", "summary": "Basic properties of black holes are explained in terms of trapping horizons.\nIt is shown that matter and information will escape from an evaporating black\nhole. A general scenario is outlined whereby a black hole evaporates completely\nwithout singularity, event horizon or loss of energy or information.", "author": {"name": "Sean A. Hayward"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "4 latex pages, 12 eps figures. Presented at the 14th Workshop on\n  General Relativity and Gravitation, Kyoto University"}, "link": [{"@href": "http://arxiv.org/abs/gr-qc/0504037v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/gr-qc/0504037v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "gr-qc", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "gr-qc", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/gr-qc/0504038v1", "updated": "2005-04-08T18:22:52Z", "published": "2005-04-08T18:22:52Z", "title": "The disinformation problem for black holes (pop version)", "summary": "The supposed information paradox for black holes is based on the fundamental\nmisunderstanding that black holes are usefully defined by event horizons.\nUnderstood in terms of locally defined trapping horizons, the paradox\ndisappears: information will escape from an evaporating black hole. According\nto classical properties of trapping horizons, a general scenario is outlined\nwhereby a black hole evaporates completely without singularity, event horizon\nor loss of energy or information.", "author": {"name": "Sean A. Hayward"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 revtex4 pages"}, "link": [{"@href": "http://arxiv.org/abs/gr-qc/0504038v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/gr-qc/0504038v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "gr-qc", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "gr-qc", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1811.01852v1", "updated": "2018-11-05T17:17:18Z", "published": "2018-11-05T17:17:18Z", "title": "Differences between Health Related News Articles from Reliable and\n  Unreliable Media", "summary": "In this study, we examine a collection of health-related news articles\npublished by reliable and unreliable media outlets. Our analysis shows that\nthere are structural, topical, and semantic differences in the way reliable and\nunreliable media outlets conduct health journalism. We argue that the findings\nfrom this study will be useful for combating health disinformation problem.", "author": [{"name": "Sameer Dhoju"}, {"name": "Md Main Uddin Rony"}, {"name": "Naeemul Hassan"}], "link": [{"@href": "http://arxiv.org/abs/1811.01852v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.01852v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.01363v1", "updated": "2019-10-03T09:00:58Z", "published": "2019-10-03T09:00:58Z", "title": "Mapping (Dis-)Information Flow about the MH17 Plane Crash", "summary": "Digital media enables not only fast sharing of information, but also\ndisinformation. One prominent case of an event leading to circulation of\ndisinformation on social media is the MH17 plane crash. Studies analysing the\nspread of information about this event on Twitter have focused on small,\nmanually annotated datasets, or used proxys for data annotation. In this work,\nwe examine to what extent text classifiers can be used to label data for\nsubsequent content analysis, in particular we focus on predicting pro-Russian\nand pro-Ukrainian Twitter content related to the MH17 plane crash. Even though\nwe find that a neural classifier improves over a hashtag based baseline,\nlabeling pro-Russian and pro-Ukrainian content with high precision remains a\nchallenging problem. We provide an error analysis underlining the difficulty of\nthe task and identify factors that might help improve classification in future\nwork. Finally, we show how the classifier can facilitate the annotation task\nfor human annotators.", "author": [{"name": "Mareike Hartmann"}, {"name": "Yevgeniy Golovchenko"}, {"name": "Isabelle Augenstein"}], "link": [{"@href": "http://arxiv.org/abs/1910.01363v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.01363v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1808.09325v1", "updated": "2018-08-28T14:31:01Z", "published": "2018-08-28T14:31:01Z", "title": "\"Life never matters in the DEMOCRATS MIND\": Examining Strategies of\n  Retweeted Social Bots During a Mass Shooting Event", "summary": "This exploratory study examines the strategies of social bots on Twitter that\nwere retweeted following a mass shooting event. Using a case study method to\nframe our work, we collected over seven million tweets during a one-month\nperiod following a mass shooting in Parkland, Florida. From this dataset, we\nselected retweets of content generated by over 400 social bot accounts to\ndetermine what strategies these bots were using and the effectiveness of these\nstrategies as indicated by the number of retweets. We employed qualitative and\nquantitative methods to capture both macro- and micro-level perspectives. Our\nfindings suggest that bots engage in more diverse strategies than solely waging\ndisinformation campaigns, including baiting and sharing information. Further,\nwe found that while bots amplify conversation about mass shootings, humans were\nprimarily responsible for disseminating bot-generated content. These findings\nadd depth to the current understanding of bot strategies and their\neffectiveness. Understanding these strategies can inform efforts to combat\ndubious information as well as more insidious disinformation campaigns.", "author": [{"name": "Vanessa L. Kitzie"}, {"name": "Ehsan Mohammadi"}, {"name": "Amir Karami"}], "link": [{"@href": "http://arxiv.org/abs/1808.09325v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.09325v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1904.12614v2", "updated": "2019-09-10T11:32:21Z", "published": "2019-04-21T10:46:51Z", "title": "Modelling election dynamics and the impact of disinformation", "summary": "Complex dynamical systems driven by the unravelling of information can be\nmodelled effectively by treating the underlying flow of information as the\nmodel input. Complicated dynamical behaviour of the system is then derived as\nan output. Such an information-based approach is in sharp contrast to the\nconventional mathematical modelling of information-driven systems whereby one\nattempts to come up with essentially {\\it ad hoc} models for the outputs. Here,\ndynamics of electoral competition is modelled by the specification of the flow\nof information relevant to election. The seemingly random evolution of the\nelection poll statistics are then derived as model outputs, which in turn are\nused to study election prediction, impact of disinformation, and the optimal\nstrategy for information management in an election campaign.", "author": {"name": "Dorje C Brody"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/s41884-019-00021-2"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/s41884-019-00021-2", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1904.12614v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.12614v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "20 pages, 5 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Information Geometry, 2019"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.SP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.DS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.PR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.MF", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1912.03750v1", "updated": "2019-12-08T20:15:20Z", "published": "2019-12-08T20:15:20Z", "title": "Determining Individual Origin Similarity (DInOS): Binary Classification\n  of Authors Using Stylometric Features", "summary": "Author similarity and detection is an integral first step in detecting\nstate-led disinformation campaigns in an automated fashion. Current detection\ntechniques require an analyst or subject matter expert to hand-curate accounts.\nStylometric features have a rich history in identifying authorship of unknown\ndocuments, but little exploration has been done to compare authors to one\nanother. We have adapted a select handful of stylometric features for use in\nauthor similarity metrics, and show their >0.96 F-1 performance on a curated\nauthor classification task, across both traditional machine learning and deep\nlearning models. These features should contribute to the expanding field of\nauthor similarity research, and expedite the process of detecting and\nmitigating large-scale social media disinformation campaigns.", "author": [{"name": "A. Kingsland"}, {"name": "D. Fortin"}, {"name": "E. Cary"}, {"name": "S. Smith"}, {"name": "K. Pazdernik"}, {"name": "R. Perko"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 0 figures, 1 appendix"}, "link": [{"@href": "http://arxiv.org/abs/1912.03750v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.03750v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1912.06810v1", "updated": "2019-12-14T08:58:01Z", "published": "2019-12-14T08:58:01Z", "title": "Proppy: A System to Unmask Propaganda in Online News", "summary": "We present proppy, the first publicly available real-world, real-time\npropaganda detection system for online news, which aims at raising awareness,\nthus potentially limiting the impact of propaganda and helping fight\ndisinformation. The system constantly monitors a number of news sources,\ndeduplicates and clusters the news into events, and organizes the articles\nabout an event on the basis of the likelihood that they contain propagandistic\ncontent. The system is trained on known propaganda sources using a variety of\nstylistic features. The evaluation results on a standard dataset show\nstate-of-the-art results for propaganda detection.", "author": [{"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Giovanni Da San Martino"}, {"name": "Israa Jaradat"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, disinformation, fake news"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Thirty-Third AAAI Conference on Artificial Intelligence\n  (AAAI-2019)"}, "link": [{"@href": "http://arxiv.org/abs/1912.06810v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.06810v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.10622v2", "updated": "2020-11-02T12:53:36Z", "published": "2020-01-28T22:33:45Z", "title": "A Dip Into a Deep Well: Online Political Advertisements, Valence, and\n  European Electoral Campaigning", "summary": "Online political advertisements have become an important element in electoral\ncampaigning throughout the world. At the same time, concepts such as\ndisinformation and manipulation have emerged as a global concern. Although\nthese concepts are distinct from online political ads and data-driven electoral\ncampaigning, they tend to share a similar trait related to valence, the\nintrinsic attractiveness or averseness of a message. Given this background, the\npaper examines online political ads by using a dataset collected from Google's\ntransparency reports. The examination is framed to the mid-2019 situation in\nEurope, including the European Parliament elections in particular. According to\nthe results based on sentiment analysis of the textual ads displayed via\nGoogle's advertisement machinery, (i) most of the political ads have expressed\npositive sentiments, although these vary greatly between (ii) European\ncountries as well as across (iii) European political parties. In addition to\nthese results, the paper contributes to the timely discussion about data-driven\nelectoral campaigning and its relation to politics and democracy.", "author": {"name": "Jukka Ruohonen"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-61841-4_3"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-61841-4_3", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2001.10622v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.10622v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the 2nd Multidisciplinary International Symposium\n  on Disinformation in Open Online Media (MISDOOM 2020), Leiden (online),\n  Springer, pp. 37-51"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2006.04278v1", "updated": "2020-06-07T22:00:43Z", "published": "2020-06-07T22:00:43Z", "title": "Disinformation and Misinformation on Twitter during the Novel\n  Coronavirus Outbreak", "summary": "As the novel coronavirus spread globally, a growing public panic was\nexpressed over the internet. We examine the public discussion concerning\nCOVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million\nusers collected between January 29, 2020 and March 4, 2020. We categorize users\nbased on their home countries, social identities, and political orientation. We\nfind that news media, government officials, and individual news reporters\nposted a majority of influential tweets, while the most influential ones are\nstill written by regular users. Tweets mentioning \"fake news\" URLs and\ndisinformation story-lines are also more likely to be spread by regular users.\nUnlike real news and normal tweets, tweets containing URLs pointing to \"fake\nnews\" sites are most likely to be retweeted within the source country and so\nare less likely to spread internationally.", "author": [{"name": "Binxuan Huang"}, {"name": "Kathleen M. Carley"}], "link": [{"@href": "http://arxiv.org/abs/2006.04278v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.04278v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2008.00784v1", "updated": "2020-08-03T11:25:47Z", "published": "2020-08-03T11:25:47Z", "title": "COVID-19 Misinformation and Disinformation on Social Networks -- The\n  Limits of Veritistic Countermeasures", "summary": "The COVID-19 pandemic has been the subject of a vast amount of\nmisinformation, particularly in digital information environments, and major\nsocial media platforms recently publicized some of the countermeasures they are\nadopting. This presents an opportunity to examine the nature of the\nmisinformation and disinformation being produced, and the theoretical and\ntechnological paradigm used to counter it. I argue that this approach is based\non a conception of misinformation as epistemic pollution that can only justify\na limited and potentially inadequate response , and that some of the measures\nundertaken in practice outrun this. In fact, social networks manage ecological\nand architectural conditions that influence discourse on their platforms in\nways that should motivate reconsideration of the justifications that ground\nepistemic interventions to combat misinformation, and the types of intervention\nthat they warrant. The editorial role of platforms should not be framed solely\nas the management of epistemic pollution, but instead as managing the epistemic\nenvironment in which narratives and social epistemic processes take place.\nThere is an element of inevitable epistemic paternalism involved in this, and\nexploration of the independent constraints on its justifiability can help\ndetermine proper limits of its exercise in practice.", "author": {"name": "Andrew Buzzell"}, "link": [{"@href": "http://arxiv.org/abs/2008.00784v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.00784v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.01988v1", "updated": "2020-08-05T08:17:20Z", "published": "2020-08-05T08:17:20Z", "title": "How Fake News Affect Trust in the Output of a Machine Learning System\n  for News Curation", "summary": "People are increasingly consuming news curated by machine learning (ML)\nsystems. Motivated by studies on algorithmic bias, this paper explores which\nrecommendations of an algorithmic news curation system users trust and how this\ntrust is affected by untrustworthy news stories like fake news. In a study with\n82 vocational school students with a background in IT, we found that users are\nable to provide trust ratings that distinguish trustworthy recommendations of\nquality news stories from untrustworthy recommendations. However, a single\nuntrustworthy news story combined with four trustworthy news stories is rated\nsimilarly as five trustworthy news stories. The results could be a first\nindication that untrustworthy news stories benefit from appearing in a\ntrustworthy context. The results also show the limitations of users' abilities\nto rate the recommendations of a news curation system. We discuss the\nimplications of this for the user experience of interactive machine learning\nsystems.", "author": [{"name": "Hendrik Heuer"}, {"name": "Andreas Breiter"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a pre-print of an article published in MISDOOM 2020 - 2nd\n  Multidisciplinary International Symposium on Disinformation in Open Online\n  Media"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MISDOOM 2020 - 2nd Multidisciplinary International Symposium on\n  Disinformation in Open Online Media"}, "link": [{"@href": "http://arxiv.org/abs/2008.01988v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.01988v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.04374v1", "updated": "2020-08-10T19:21:06Z", "published": "2020-08-10T19:21:06Z", "title": "Can We Spot the \"Fake News\" Before It Was Even Written?", "summary": "Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n\"fake news.\" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.", "author": {"name": "Preslav Nakov"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Fake News, Disinformation, Media Bias, Propaganda, Infodemic,\n  COVID-19"}, "link": [{"@href": "http://arxiv.org/abs/2008.04374v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.04374v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.11278v2", "updated": "2020-12-10T04:10:21Z", "published": "2020-11-23T08:47:40Z", "title": "FakeSafe: Human Level Data Protection by Disinformation Mapping using\n  Cycle-consistent Adversarial Network", "summary": "The concept of disinformation is to use fake messages to confuse people in\norder to protect the real information. This strategy can be adapted into data\nscience to protect valuable private and sensitive data. Huge amount of private\ndata are being generated from personal devices such as smart phone and wearable\nin recent years. Being able to utilize these personal data will bring big\nopportunities to design personalized products, conduct precision healthcare and\nmany other tasks that were impossible in the past. However, due to privacy,\nsafety and regulation reasons, it is often difficult to transfer or store data\nin its original form while keeping them safe. Building a secure data transfer\nand storage infrastructure to preserving privacy is costly in most cases and\nthere is always a concern of data security due to human errors. In this study,\nwe propose a method, named FakeSafe, to provide human level data protection\nusing generative adversarial network with cycle consistency and conducted\nexperiments using both benchmark and real world data sets to illustrate\npotential applications of FakeSafe.", "author": [{"name": "He Zhu"}, {"name": "Dianbo Liu"}], "link": [{"@href": "http://arxiv.org/abs/2011.11278v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.11278v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.13559v2", "updated": "2021-05-18T05:41:05Z", "published": "2021-04-28T03:38:24Z", "title": "AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance\n  Detection for Fact Checking", "summary": "With the continuing spread of misinformation and disinformation online, it is\nof increasing importance to develop combating mechanisms at scale in the form\nof automated systems that support multiple languages. One task of interest is\nclaim veracity prediction, which can be addressed using stance detection with\nrespect to relevant documents retrieved online. To this end, we present our new\nArabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from\na diverse set of sources comprising three fact-checking websites and one news\nwebsite. AraStance covers false and true claims from multiple domains (e.g.,\npolitics, sports, health) and several Arab countries, and it is well-balanced\nbetween related and unrelated documents with respect to the claims. We\nbenchmark AraStance, along with two other stance detection datasets, using a\nnumber of BERT-based models. Our best model achieves an accuracy of 85\\% and a\nmacro F1 score of 78\\%, which leaves room for improvement and reflects the\nchallenging nature of AraStance and the task of stance detection in general.", "author": [{"name": "Tariq Alhindi"}, {"name": "Amal Alabdulkarim"}, {"name": "Ali Alshehri"}, {"name": "Muhammad Abdul-Mageed"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the 2021 Workshop on NLP4IF: Censorship, Disinformation,\n  and Propaganda"}, "link": [{"@href": "http://arxiv.org/abs/2104.13559v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13559v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.10655v1", "updated": "2021-07-12T15:53:13Z", "published": "2021-07-12T15:53:13Z", "title": "Lumen: A Machine Learning Framework to Expose Influence Cues in Text", "summary": "Phishing and disinformation are popular social engineering attacks with\nattackers invariably applying influence cues in texts to make them more\nappealing to users. We introduce Lumen, a learning-based framework that exposes\ninfluence cues in text: (i) persuasion, (ii) framing, (iii) emotion, (iv)\nobjectivity/subjectivity, (v) guilt/blame, and (vi) use of emphasis. Lumen was\ntrained with a newly developed dataset of 3K texts comprised of disinformation,\nphishing, hyperpartisan news, and mainstream news. Evaluation of Lumen in\ncomparison to other learning models showed that Lumen and LSTM presented the\nbest F1-micro score, but Lumen yielded better interpretability. Our results\nhighlight the promise of ML to expose influence cues in text, towards the goal\nof application in automatic labeling tools to improve the accuracy of\nhuman-based detection and reduce the likelihood of users falling for deceptive\nonline content.", "author": [{"name": "Hanyu Shi"}, {"name": "Mirela Silva"}, {"name": "Daniel Capecci"}, {"name": "Luiz Giovanini"}, {"name": "Lauren Czech"}, {"name": "Juliana Fernandes"}, {"name": "Daniela Oliveira"}], "link": [{"@href": "http://arxiv.org/abs/2107.10655v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.10655v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.02941v2", "updated": "2021-08-09T17:23:05Z", "published": "2021-08-06T04:54:03Z", "title": "Is it Fake? News Disinformation Detection on South African News Websites", "summary": "Disinformation through fake news is an ongoing problem in our society and has\nbecome easily spread through social media. The most cost and time effective way\nto filter these large amounts of data is to use a combination of human and\ntechnical interventions to identify it. From a technical perspective, Natural\nLanguage Processing (NLP) is widely used in detecting fake news. Social media\ncompanies use NLP techniques to identify the fake news and warn their users,\nbut fake news may still slip through undetected. It is especially a problem in\nmore localised contexts (outside the United States of America). How do we\nadjust fake news detection systems to work better for local contexts such as in\nSouth Africa. In this work we investigate fake news detection on South African\nwebsites. We curate a dataset of South African fake news and then train\ndetection models. We contrast this with using widely available fake news\ndatasets (from mostly USA website). We also explore making the datasets more\ndiverse by combining them and observe the differences in behaviour in writing\nbetween nations' fake news using interpretable machine learning.", "author": [{"name": "Harm de Wet"}, {"name": "Vukosi Marivate"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, Accepted and to be published in AFRICON 2021"}, "link": [{"@href": "http://arxiv.org/abs/2108.02941v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.02941v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.09702v1", "updated": "2019-10-22T00:06:52Z", "published": "2019-10-22T00:06:52Z", "title": "Fine-Tuned Neural Models for Propaganda Detection at the Sentence and\n  Fragment levels", "summary": "This paper presents the CUNLP submission for the NLP4IF 2019 shared-task on\nFineGrained Propaganda Detection. Our system finished 5th out of 26 teams on\nthe sentence-level classification task and 5th out of 11 teams on the\nfragment-level classification task based on our scores on the blind test set.\nWe present our models, a discussion of our ablation studies and experiments,\nand an analysis of our performance on all eighteen propaganda techniques\npresent in the corpus of the shared task.", "author": [{"name": "Tariq Alhindi"}, {"name": "Jonas Pfeiffer"}, {"name": "Smaranda Muresan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.18653/v1/D19-5013"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.18653/v1/D19-5013", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1910.09702v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.09702v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the 2nd Workshop on NLP for Internet Freedom (NLP4IF):\n  Censorship, Disinformation, and Propaganda"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.08968v1", "updated": "2020-12-15T14:06:32Z", "published": "2020-12-15T14:06:32Z", "title": "The Impact of Cyber Security Threats on the 2020 US Elections", "summary": "This paper will investigate the literature surrounding cyber security threats\nin the 2020 US Elections. It begins with a brief overview of cyber security and\nthe current state of cyber security regarding elections. In the main body of\nthe paper, the focus will be on the literature review of three main areas:\nvoter suppression, voter fraud, and disinformation, considering their impacts\non the outcome of the election and on the voting public. Having evaluated\nsources on each this paper concludes by summarising the areas which have had\nthe greatest impact on the 2020 US elections.", "author": {"name": "Nicholas Stedmon"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "3 pages"}, "link": [{"@href": "http://arxiv.org/abs/2012.08968v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.08968v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.12039v1", "updated": "2019-11-27T09:22:51Z", "published": "2019-11-27T09:22:51Z", "title": "The Limited Reach of Fake News on Twitter during 2019 European Elections", "summary": "The advent of social media changed the way we consume content favoring a\ndisintermediated access and production. This scenario has been matter of\ncritical discussion about its impact on society. Magnified in the case of Arab\nSpring or heavily criticized in the Brexit and 2016 U.S. elections. In this\nwork we explore information consumption on Twitter during the last European\nelectoral campaign by analyzing the interaction patterns of official news\nsources, fake news sources, politicians, people from the showbiz and many\nothers. We extensively explore interactions among different classes of accounts\nin the months preceding the last European elections, held between 23rd and 26th\nof May, 2019. We collected almost 400,000 tweets posted by 863 accounts having\ndifferent roles in the public society. Through a thorough quantitative analysis\nwe investigate the information flow among them, also exploiting geolocalized\ninformation. Accounts show the tendency to confine their interaction within the\nsame class and the debate rarely crosses national borders. Moreover, we do not\nfind any evidence of an organized network of accounts aimed at spreading\ndisinformation. Instead, disinformation outlets are largely ignored by the\nother actors and hence play a peripheral role in online political discussions.", "author": [{"name": "Matteo Cinelli"}, {"name": "Stefano Cresci"}, {"name": "Alessandro Galeazzi"}, {"name": "Walter Quattrociocchi"}, {"name": "Maurizio Tesconi"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0234689"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0234689", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1911.12039v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.12039v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PLoS ONE 15(6): e0234689, 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.05096v1", "updated": "2020-03-11T03:16:04Z", "published": "2020-03-11T03:16:04Z", "title": "Exploring the Role of Visual Content in Fake News Detection", "summary": "The increasing popularity of social media promotes the proliferation of fake\nnews, which has caused significant negative societal effects. Therefore, fake\nnews detection on social media has recently become an emerging research area of\ngreat concern. With the development of multimedia technology, fake news\nattempts to utilize multimedia content with images or videos to attract and\nmislead consumers for rapid dissemination, which makes visual content an\nimportant part of fake news. Despite the importance of visual content, our\nunderstanding of the role of visual content in fake news detection is still\nlimited. This chapter presents a comprehensive review of the visual content in\nfake news, including the basic concepts, effective visual features,\nrepresentative detection methods and challenging issues of multimedia fake news\ndetection. This chapter can help readers to understand the role of visual\ncontent in fake news detection, and effectively utilize visual content to\nassist in detecting multimedia fake news.", "author": [{"name": "Juan Cao"}, {"name": "Peng Qi"}, {"name": "Qiang Sheng"}, {"name": "Tianyun Yang"}, {"name": "Junbo Guo"}, {"name": "Jintao Li"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-42699-6"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-42699-6", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.05096v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.05096v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a preprint of a chapter published in Disinformation,\n  Misinformation, and Fake News in Social Media: Emerging Research Challenges\n  and Opportunities, edited by Kai, S., Suhang, W., Dongwon, L., Huan, L, 2020,\n  Springer reproduced with permission of Springer Nature Switzerland AG. The\n  final authenticated version is available online at:\n  https://www.springer.com/gp/book/9783030426989. arXiv admin note: text\n  overlap with arXiv:2001.00623, arXiv:1808.06686, arXiv:1903.00788 by other\n  authors"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Disinformation, Misinformation, and Fake News in Social Media.\n  2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.00742v2", "updated": "2020-11-19T00:01:44Z", "published": "2020-04-01T23:44:58Z", "title": "#ArsonEmergency and Australia's \"Black Summer\": Polarisation and\n  misinformation on social media", "summary": "During the summer of 2019-20, while Australia suffered unprecedented\nbushfires across the country, false narratives regarding arson and limited\nbackburning spread quickly on Twitter, particularly using the hashtag\n#ArsonEmergency. Misinformation and bot- and troll-like behaviour were detected\nand reported by social media researchers and the news soon reached mainstream\nmedia. This paper examines the communication and behaviour of two polarised\nonline communities before and after news of the misinformation became public\nknowledge. Specifically, the Supporter community actively engaged with others\nto spread the hashtag, using a variety of news sources pushing the arson\nnarrative, while the Opposer community engaged less, retweeted more, and\nfocused its use of URLs to link to mainstream sources, debunking the narratives\nand exposing the anomalous behaviour. This influenced the content of the\nbroader discussion. Bot analysis revealed the active accounts were\npredominantly human, but behavioural and content analysis suggests Supporters\nengaged in trolling, though both communities used aggressive language.", "author": [{"name": "Derek Weber"}, {"name": "Mehwish Nasim"}, {"name": "Lucia Falzon"}, {"name": "Lewis Mitchell"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-61841-4_11"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-61841-4_11", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.00742v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.00742v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "16 pages, 8 images, presented at the 2nd Multidisciplinary\n  International Symposium on Disinformation in Open Online Media (MISDOOM\n  2020), Leiden, The Netherlands. Published in: van Duijn M., Preuss M.,\n  Spaiser V., Takes F., Verberne S. (eds) Disinformation in Open Online Media.\n  MISDOOM 2020. Lecture Notes in Computer Science, vol 12259. Springer, Cham.\n  https://doi.org/10.1007/978-3-030-61841-4_11"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.00033v2", "updated": "2020-06-09T13:33:12Z", "published": "2020-04-30T18:04:20Z", "title": "Fighting the COVID-19 Infodemic: Modeling the Perspective of\n  Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the\n  Society", "summary": "With the emergence of the COVID-19 pandemic, the political and the medical\naspects of disinformation merged as the problem got elevated to a whole new\nlevel to become the first global infodemic. Fighting this infodemic is ranked\nsecond in the list of the most important focus areas of the World Health\nOrganization, with dangers ranging from promoting fake cures, rumors, and\nconspiracy theories to spreading xenophobia and panic. Addressing the issue\nrequires solving a number of challenging problems such as identifying messages\ncontaining claims, determining their check-worthiness and factuality, and their\npotential to do harm as well as the nature of that harm, to mention just a few.\nThus, here we design, annotate, and release to the research community a new\ndataset for fine-grained disinformation analysis that (i)focuses on COVID-19,\n(ii) combines the perspectives and the interests of journalists, fact-checkers,\nsocial media platforms, policy makers, and society as a whole, and (iii) covers\nboth English and Arabic. Finally, we show strong evaluation results using\nstate-of-the-art Transformers, thus confirming the practical utility of the\nannotation schema and of the dataset.", "author": [{"name": "Firoj Alam"}, {"name": "Shaden Shaar"}, {"name": "Fahim Dalvi"}, {"name": "Hassan Sajjad"}, {"name": "Alex Nikolov"}, {"name": "Hamdy Mubarak"}, {"name": "Giovanni Da San Martino"}, {"name": "Ahmed Abdelali"}, {"name": "Nadir Durrani"}, {"name": "Kareem Darwish"}, {"name": "Preslav Nakov"}], "link": [{"@href": "http://arxiv.org/abs/2005.00033v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.00033v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.07996v2", "updated": "2021-04-09T08:52:10Z", "published": "2020-07-15T21:18:30Z", "title": "Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms", "summary": "With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.", "author": [{"name": "Firoj Alam"}, {"name": "Fahim Dalvi"}, {"name": "Shaden Shaar"}, {"name": "Nadir Durrani"}, {"name": "Hamdy Mubarak"}, {"name": "Alex Nikolov"}, {"name": "Giovanni Da San Martino"}, {"name": "Ahmed Abdelali"}, {"name": "Hassan Sajjad"}, {"name": "Kareem Darwish"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "COVID-19, Infodemic, Disinformation, Misinformation, Fake News, Call\n  to Arms, Crowdsourcing Annotations"}, "link": [{"@href": "http://arxiv.org/abs/2007.07996v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.07996v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.07698v5", "updated": "2020-10-21T15:16:20Z", "published": "2020-09-16T14:13:15Z", "title": "Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News", "summary": "Large-scale dissemination of disinformation online intended to mislead or\ndeceive the general population is a major societal problem. Rapid progression\nin image, video, and natural language generative models has only exacerbated\nthis situation and intensified our need for an effective defense mechanism.\nWhile existing approaches have been proposed to defend against neural fake\nnews, they are generally constrained to the very limited setting where articles\nonly have text and metadata such as the title and authors. In this paper, we\nintroduce the more realistic and challenging task of defending against\nmachine-generated news that also includes images and captions. To identify the\npossible weaknesses that adversaries can exploit, we create a NeuralNews\ndataset composed of 4 different types of generated articles as well as conduct\na series of human user study experiments based on this dataset. In addition to\nthe valuable insights gleaned from our user study experiments, we provide a\nrelatively effective approach based on detecting visual-semantic\ninconsistencies, which will serve as an effective first line of defense and a\nuseful reference for future work in defending against machine-generated\ndisinformation.", "author": [{"name": "Reuben Tan"}, {"name": "Bryan A. Plummer"}, {"name": "Kate Saenko"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at EMNLP 2020"}, "link": [{"@href": "http://arxiv.org/abs/2009.07698v5", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.07698v5", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.06455v2", "updated": "2020-10-15T03:23:26Z", "published": "2020-10-13T15:10:26Z", "title": "Characterizing and Comparing COVID-19 Misinformation Across Languages,\n  Countries and Platforms", "summary": "Misinformation/disinformation about COVID-19 has been rampant on social media\naround the world. In this study, we investigate COVID-19 misinformation/\ndisinformation on social media in multiple languages - Farsi (Persian),\nChinese, and English, about multiple countries - Iran, China, and the United\nStates (US), and on multiple platforms such as Twitter, Facebook, Instagram,\nWeibo, and WhatsApp. Misinformation, especially about a global pandemic, is a\nglobal problem yet it is common for studies of COVID-19 misinformation on\nsocial media to focus on a single language, like English, a single country,\nlike the US, or a single platform, like Twitter. We utilized opportunistic\nsampling to compile 200 specific items of viral and yet debunked misinformation\nacross these languages, countries and platforms emerged between January 1 and\nAugust 31. We then categorized this collection based both on the topics of the\nmisinformation and the underlying roots of that misinformation. Our\nmulti-cultural and multilingual team observed that the nature of COVID-19\nmisinformation on social media varied in substantial ways across different\nlanguages/countries depending on the cultures, beliefs/religions, popularity of\nsocial media, types of platforms, freedom of speech and the power of people\nversus governments. We observe that politics is at the root of most of the\ncollected misinformation across all three languages in this dataset. We further\nobserve the different impact of government restrictions on platforms and\nplatform restrictions on content in Iran, China, and the US and their impact on\na key question of our age: how do we control misinformation without silencing\nthe voices we need to hold governments accountable?", "author": [{"name": "Golshan Madraki"}, {"name": "Isabella Grasso"}, {"name": "Jacqueline Otala"}, {"name": "Yu Liu"}, {"name": "Jeanna Matthews"}], "link": [{"@href": "http://arxiv.org/abs/2010.06455v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.06455v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.05416v1", "updated": "2020-11-09T04:15:44Z", "published": "2020-11-09T04:15:44Z", "title": "Challenges and Opportunities in Rapid Epidemic Information Propagation\n  with Live Knowledge Aggregation from Social Media", "summary": "A rapidly evolving situation such as the COVID-19 pandemic is a significant\nchallenge for AI/ML models because of its unpredictability. %The most reliable\nindicator of the pandemic spreading has been the number of test positive cases.\nHowever, the tests are both incomplete (due to untested asymptomatic cases) and\nlate (due the lag from the initial contact event, worsening symptoms, and test\nresults). Social media can complement physical test data due to faster and\nhigher coverage, but they present a different challenge: significant amounts of\nnoise, misinformation and disinformation. We believe that social media can\nbecome good indicators of pandemic, provided two conditions are met. The first\n(True Novelty) is the capture of new, previously unknown, information from\nunpredictably evolving situations. The second (Fact vs. Fiction) is the\ndistinction of verifiable facts from misinformation and disinformation. Social\nmedia information that satisfy those two conditions are called live knowledge.\nWe apply evidence-based knowledge acquisition (EBKA) approach to collect,\nfilter, and update live knowledge through the integration of social media\nsources with authoritative sources. Although limited in quantity, the reliable\ntraining data from authoritative sources enable the filtering of misinformation\nas well as capturing truly new information. We describe the EDNA/LITMUS tools\nthat implement EBKA, integrating social media such as Twitter and Facebook with\nauthoritative sources such as WHO and CDC, creating and updating live knowledge\non the COVID-19 pandemic.", "author": [{"name": "Calton Pu"}, {"name": "Abhijit Suprem"}, {"name": "Rodrigo Alves Lima"}], "link": [{"@href": "http://arxiv.org/abs/2011.05416v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.05416v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.04726v1", "updated": "2020-12-08T20:30:43Z", "published": "2020-12-08T20:30:43Z", "title": "Edited Media Understanding: Reasoning About Implications of Manipulated\n  Images", "summary": "Multimodal disinformation, from `deepfakes' to simple edits that deceive, is\nan important societal problem. Yet at the same time, the vast majority of media\nedits are harmless -- such as a filtered vacation photo. The difference between\nthis example, and harmful edits that spread disinformation, is one of intent.\nRecognizing and describing this intent is a major challenge for today's AI\nsystems.\n  We present the task of Edited Media Understanding, requiring models to answer\nopen-ended questions that capture the intent and implications of an image edit.\nWe introduce a dataset for our task, EMU, with 48k question-answer pairs\nwritten in rich natural language. We evaluate a wide variety of\nvision-and-language models for our task, and introduce a new model PELICAN,\nwhich builds upon recent progress in pretrained multimodal representations. Our\nmodel obtains promising results on our dataset, with humans rating its answers\nas accurate 40.35% of the time. At the same time, there is still much work to\nbe done -- humans prefer human-annotated captions 93.56% of the time -- and we\nprovide analysis that highlights areas for further progress.", "author": [{"name": "Jeff Da"}, {"name": "Maxwell Forbes"}, {"name": "Rowan Zellers"}, {"name": "Anthony Zheng"}, {"name": "Jena D. Hwang"}, {"name": "Antoine Bosselut"}, {"name": "Yejin Choi"}], "link": [{"@href": "http://arxiv.org/abs/2012.04726v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.04726v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.07423v1", "updated": "2021-04-15T12:39:37Z", "published": "2021-04-15T12:39:37Z", "title": "The Role of Context in Detecting Previously Fact-Checked Claims", "summary": "Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.", "author": [{"name": "Shaden Shaar"}, {"name": "Firoj Alam"}, {"name": "Giovanni Da San Martino"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates"}, "link": [{"@href": "http://arxiv.org/abs/2104.07423v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.07423v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.10274v1", "updated": "2021-08-23T16:22:50Z", "published": "2021-08-23T16:22:50Z", "title": "Towards Explainable Fact Checking", "summary": "The past decade has seen a substantial rise in the amount of mis- and\ndisinformation online, from targeted disinformation campaigns to influence\npolitics, to the unintentional spreading of misinformation about public health.\nThis development has spurred research in the area of automatic fact checking,\nfrom approaches to detect check-worthy claims and determining the stance of\ntweets towards claims, to methods to determine the veracity of claims given\nevidence documents. These automatic methods are often content-based, using\nnatural language processing methods, which in turn utilise deep neural networks\nto learn higher-order features from text in order to make predictions. As deep\nneural networks are black-box models, their inner workings cannot be easily\nexplained. At the same time, it is desirable to explain how they arrive at\ncertain decisions, especially if they are to be used for decision making. While\nthis has been known for some time, the issues this raises have been exacerbated\nby models increasing in size, and by EU legislation requiring models to be used\nfor decision making to provide explanations, and, very recently, by legislation\nrequiring online platforms operating in the EU to provide transparent reporting\non their services. Despite this, current solutions for explainability are still\nlacking in the area of fact checking. This thesis presents my research on\nautomatic fact checking, including claim check-worthiness detection, stance\ndetection and veracity prediction. Its contributions go beyond fact checking,\nwith the thesis proposing more general machine learning solutions for natural\nlanguage processing in the area of learning with limited labelled data.\nFinally, the thesis presents some first solutions for explainable fact\nchecking.", "author": {"name": "Isabelle Augenstein"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Thesis presented to the University of Copenhagen Faculty of Science\n  in partial fulfillment of the requirements for the degree of Doctor\n  Scientiarum (Dr. Scient.)"}, "link": [{"@href": "http://arxiv.org/abs/2108.10274v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.10274v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1801.09288v2", "updated": "2019-03-04T15:11:28Z", "published": "2018-01-28T21:00:52Z", "title": "Disinformation Warfare: Understanding State-Sponsored Trolls on Twitter\n  and Their Influence on the Web", "summary": "Over the past couple of years, anecdotal evidence has emerged linking\ncoordinated campaigns by state-sponsored actors with efforts to manipulate\npublic opinion on the Web, often around major political events, through\ndedicated accounts, or \"trolls.\" Although they are often involved in spreading\ndisinformation on social media, there is little understanding of how these\ntrolls operate, what type of content they disseminate, and most importantly\ntheir influence on the information ecosystem.\n  In this paper, we shed light on these questions by analyzing 27K tweets\nposted by 1K Twitter users identified as having ties with Russia's Internet\nResearch Agency and thus likely state-sponsored trolls. We compare their\nbehavior to a random set of Twitter users, finding interesting differences in\nterms of the content they disseminate, the evolution of their account, as well\nas their general behavior and use of Twitter. Then, using Hawkes Processes, we\nquantify the influence that trolls had on the dissemination of news on social\nplatforms like Twitter, Reddit, and 4chan. Overall, our findings indicate that\nRussian trolls managed to stay active for long periods of time and to reach a\nsubstantial number of Twitter users with their tweets. When looking at their\nability of spreading news content and making it viral, however, we find that\ntheir effect on social platforms was minor, with the significant exception of\nnews published by the Russian state-sponsored news outlet RT (Russia Today).", "author": [{"name": "Savvas Zannettou"}, {"name": "Tristan Caulfield"}, {"name": "Emiliano De Cristofaro"}, {"name": "Michael Sirivianos"}, {"name": "Gianluca Stringhini"}, {"name": "Jeremy Blackburn"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "A preliminary version of this paper appears in the 4th Workshop on\n  The Fourth Workshop on Computational Methods in Online Misbehavior\n  (CyberSafety 2019) -- WWW'19 Companion Proceedings. This is the full version"}, "link": [{"@href": "http://arxiv.org/abs/1801.09288v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1801.09288v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.06558v1", "updated": "2020-05-13T19:48:12Z", "published": "2020-05-13T19:48:12Z", "title": "Russian trolls speaking Russian: Regional Twitter operations and MH17", "summary": "The role of social media in promoting media pluralism was initially viewed as\nwholly positive. However, some governments are allegedly manipulating social\nmedia by hiring online commentators (also known as trolls) to spread propaganda\nand disinformation. In particular, an alleged system of professional trolls\noperating both domestically and internationally exists in Russia. In 2018,\nTwitter released data on accounts identified as Russian trolls, starting a wave\nof research. However, while foreign-targeted English language operations of\nthese trolls have received significant attention, no research has analyzed\ntheir Russian language domestic and regional-targeted activities. We address\nthis gap by characterizing the Russian-language operations of Russian trolls.\nWe first perform a descriptive analysis, and then focus in on the trolls'\noperation related to the crash of Malaysia Airlines flight MH17.\n  Among other things, we find that Russian-language trolls have run 163 hashtag\ncampaigns (where hashtag use grows abruptly within a month). The main political\nsentiments of such campaigns were praising Russia and Putin (29%), criticizing\nUkraine (26%), and criticizing the United States and Obama (9%). Further,\ntrolls actively reshared information with 76% of tweets being retweets or\ncontaining a URL. Additionally, we observe periodic temporal patterns of\ntweeting suggesting that trolls use automation tools. Further, we find that\ntrolls' information campaign on the MH17 crash was the largest in terms of\ntweet count. However, around 68% of tweets posted with MH17 hashtags were\nlikely used simply for hashtag amplification. With these tweets excluded, about\n49% of the tweets suggested to varying levels that Ukraine was responsible for\nthe crash, and only 13% contained disinformation and propaganda presented as\nnews. Interestingly, trolls promoted inconsistent alternative theories for the\ncrash.", "author": [{"name": "Alexandr Vesselkov"}, {"name": "Benjamin Finley"}, {"name": "Jouko Vankka"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3394231.3397898"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3394231.3397898", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2005.06558v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.06558v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12th ACM Conference on Web Science (WebSci '20), July 6--10, 2020,\n  Southampton, United Kingdom"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1802.03572v1", "updated": "2018-02-10T12:16:12Z", "published": "2018-02-10T12:16:12Z", "title": "Junk News on Military Affairs and National Security: Social Media\n  Disinformation Campaigns Against US Military Personnel and Veterans", "summary": "Social media provides political news and information for both active duty\nmilitary personnel and veterans. We analyze the subgroups of Twitter and\nFacebook users who spend time consuming junk news from websites that target US\nmilitary personnel and veterans with conspiracy theories, misinformation, and\nother forms of junk news about military affairs and national security issues.\n(1) Over Twitter we find that there are significant and persistent interactions\nbetween current and former military personnel and a broad network of extremist,\nRussia-focused, and international conspiracy subgroups. (2) Over Facebook, we\nfind significant and persistent interactions between public pages for military\nand veterans and subgroups dedicated to political conspiracy, and both sides of\nthe political spectrum. (3) Over Facebook, the users who are most interested in\nconspiracy theories and the political right seem to be distributing the most\njunk news, whereas users who are either in the military or are veterans are\namong the most sophisticated news consumers, and share very little junk news\nthrough the network.", "author": [{"name": "John D. Gallacher"}, {"name": "Vlad Barash"}, {"name": "Philip N. Howard"}, {"name": "John Kelly"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Data Memo"}, "link": [{"@href": "http://arxiv.org/abs/1802.03572v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1802.03572v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1810.11063v1", "updated": "2018-10-25T18:42:01Z", "published": "2018-10-25T18:42:01Z", "title": "Sorry: Ambient Tactical Deception Via Malware-Based Social Engineering", "summary": "In this paper we argue, drawing from the perspectives of cybersecurity and\nsocial psychology, that Internet-based manipulation of an individual or group\nreality using ambient tactical deception is possible using only software and\nchanging words in a web browser. We call this attack Ambient Tactical Deception\n(ATD). Ambient, in artificial intelligence, describes software that is\n\"unobtrusive,\" and completely integrated into a user's life. Tactical deception\nis an information warfare term for the use of deception on an opposing force.\nWe suggest that an ATD attack could change the sentiment of text in a web\nbrowser. This could alter the victim's perception of reality by providing\ndisinformation. Within the limit of online communication, even a pause in\nreplying to a text can affect how people perceive each other. The outcomes of\nan ATD attack could include alienation, upsetting a victim, and influencing\ntheir feelings about an election, a spouse, or a corporation.", "author": [{"name": "Adam Trowbridge"}, {"name": "Jessica Westbrook"}, {"name": "Filipo Sharevski"}], "link": [{"@href": "http://arxiv.org/abs/1810.11063v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1810.11063v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1807.06958v1", "updated": "2018-07-18T14:19:49Z", "published": "2018-07-18T14:19:49Z", "title": "Quantifying Biases in Online Information Exposure", "summary": "Our consumption of online information is mediated by filtering, ranking, and\nrecommendation algorithms that introduce unintentional biases as they attempt\nto deliver relevant and engaging content. It has been suggested that our\nreliance on online technologies such as search engines and social media may\nlimit exposure to diverse points of view and make us vulnerable to manipulation\nby disinformation. In this paper, we mine a massive dataset of Web traffic to\nquantify two kinds of bias: (i) homogeneity bias, which is the tendency to\nconsume content from a narrow set of information sources, and (ii) popularity\nbias, which is the selective exposure to content from top sites. Our analysis\nreveals different bias levels across several widely used Web platforms. Search\nexposes users to a diverse set of sources, while social media traffic tends to\nexhibit high popularity and homogeneity bias. When we focus our analysis on\ntraffic to news sites, we find higher levels of popularity bias, with smaller\ndifferences across applications. Overall, our results quantify the extent to\nwhich our choices of online systems confine us inside \"social bubbles.\"", "author": [{"name": "Dimitar Nikolov"}, {"name": "Mounia Lalmas"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1002/asi.24121"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1002/asi.24121", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1807.06958v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1807.06958v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "25 pages, 10 figures, to appear in the Journal of the Association for\n  Information Science and Technology (JASIST)"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "JASIST 70 (3): 218-229, 2019"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.01303v2", "updated": "2019-10-04T00:40:00Z", "published": "2019-10-03T05:08:35Z", "title": "From Senseless Swarms to Smart Mobs: Tuning Networks for Prosocial\n  Behaviour", "summary": "Social media have been seen to accelerate the spread of negative content such\nas disinformation and hate speech, often unleashing reckless herd mentality\nwithin networks, further aggravated by malicious entities using bots for\namplification. So far, the response to this emerging global crisis has centred\naround social media platform companies making reactive moves that appear to\nhave greater symbolic value than practical utility. These include taking down\npatently objectionable content or manually deactivating the accounts of bad\nactors, while leaving vast troves of negative content to circulate and\nperpetuate within social networks. Governments worldwide have thus sought to\nintervene using regulatory tools, with countries such as France, Germany and\nSingapore introducing laws to compel technology companies to take down or\ncorrect erroneous and harmful content. However, the relentless pace of\ntechnological progress enfeebles regulatory measures that seem fated for\nobsolescence.", "author": [{"name": "Sun Sun Lim"}, {"name": "Roland Bouffanais"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear in IEEE Technology and Society Magazine"}, "link": [{"@href": "http://arxiv.org/abs/1910.01303v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.01303v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.08948v1", "updated": "2019-10-20T11:05:05Z", "published": "2019-10-20T11:05:05Z", "title": "Predicting the Leading Political Ideology of YouTube Channels Using\n  Acoustic, Textual, and Metadata Information", "summary": "We address the problem of predicting the leading political ideology, i.e.,\nleft-center-right bias, for YouTube channels of news media. Previous work on\nthe problem has focused exclusively on text and on analysis of the language\nused, topics discussed, sentiment, and the like. In contrast, here we study\nvideos, which yields an interesting multimodal setup. Starting with gold\nannotations about the leading political ideology of major world news media from\nMedia Bias/Fact Check, we searched on YouTube to find their corresponding\nchannels, and we downloaded a recent sample of videos from each channel. We\ncrawled more than 1,000 YouTube hours along with the corresponding subtitles\nand metadata, thus producing a new multimodal dataset. We further developed a\nmultimodal deep-learning architecture for the task. Our analysis shows that the\nuse of acoustic signal helped to improve bias detection by more than 6%\nabsolute over using text and metadata only. We release the dataset to the\nresearch community, hoping to help advance the field of multi-modal political\nbias detection.", "author": [{"name": "Yoan Dinkov"}, {"name": "Ahmed Ali"}, {"name": "Ivan Koychev"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "media bias, political ideology, Youtube channels, propaganda,\n  disinformation, fake news"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "INTERSPEECH-2019"}, "link": [{"@href": "http://arxiv.org/abs/1910.08948v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.08948v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SD", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.AS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.09982v1", "updated": "2019-10-20T10:53:18Z", "published": "2019-10-20T10:53:18Z", "title": "Findings of the NLP4IF-2019 Shared Task on Fine-Grained Propaganda\n  Detection", "summary": "We present the shared task on Fine-Grained Propaganda Detection, which was\norganized as part of the NLP4IF workshop at EMNLP-IJCNLP 2019. There were two\nsubtasks. FLC is a fragment-level task that asks for the identification of\npropagandist text fragments in a news article and also for the prediction of\nthe specific propaganda technique used in each such fragment (18-way\nclassification task). SLC is a sentence-level binary classification task asking\nto detect the sentences that contain propaganda. A total of 12 teams submitted\nsystems for the FLC task, 25 teams did so for the SLC task, and 14 teams\neventually submitted a system description paper. For both subtasks, most\nsystems managed to beat the baseline by a sizable margin. The leaderboard and\nthe data from the competition are available at\nhttp://propaganda.qcri.org/nlp4if-shared-task/.", "author": [{"name": "Giovanni Da San Martino"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, disinformation, fake news. arXiv admin note: text overlap\n  with arXiv:1910.02517"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NLP4IF@EMNLP-2019"}, "link": [{"@href": "http://arxiv.org/abs/1910.09982v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.09982v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1812.08247v1", "updated": "2018-12-19T21:12:00Z", "published": "2018-12-19T21:12:00Z", "title": "Detecting GAN-generated Imagery using Color Cues", "summary": "Image forensics is an increasingly relevant problem, as it can potentially\naddress online disinformation campaigns and mitigate problematic aspects of\nsocial media. Of particular interest, given its recent successes, is the\ndetection of imagery produced by Generative Adversarial Networks (GANs), e.g.\n`deepfakes'. Leveraging large training sets and extensive computing resources,\nrecent work has shown that GANs can be trained to generate synthetic imagery\nwhich is (in some ways) indistinguishable from real imagery. We analyze the\nstructure of the generating network of a popular GAN implementation, and show\nthat the network's treatment of color is markedly different from a real camera\nin two ways. We further show that these two cues can be used to distinguish\nGAN-generated imagery from camera imagery, demonstrating effective\ndiscrimination between GAN imagery and real camera images used to train the\nGAN.", "author": [{"name": "Scott McCloskey"}, {"name": "Michael Albright"}], "link": [{"@href": "http://arxiv.org/abs/1812.08247v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.08247v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1903.11899v1", "updated": "2019-03-28T11:24:30Z", "published": "2019-03-28T11:24:30Z", "title": "Using Blockchain to Rein in The New Post-Truth World and Check The\n  Spread of Fake News", "summary": "In recent years, `fake news' has become a global issue that raises\nunprecedented challenges for human society and democracy. This problem has\narisen due to the emergence of various concomitant phenomena such as (1) the\ndigitization of human life and the ease of disseminating news through social\nnetworking applications (such as Facebook and WhatsApp); (2) the availability\nof `big data' that allows customization of news feeds and the creation of\npolarized so-called `filter-bubbles'; and (3) the rapid progress made by\ngenerative machine learning (ML) and deep learning (DL) algorithms in creating\nrealistic-looking yet fake digital content (such as text, images, and videos).\nThere is a crucial need to combat the rampant rise of fake news and\ndisinformation. In this paper, we propose a high-level overview of a\nblockchain-based framework for fake news prevention and highlight the various\ndesign issues and consideration of such a blockchain-based framework for\ntackling fake news.", "author": [{"name": "Adnan Qayyum"}, {"name": "Junaid Qadir"}, {"name": "Muhammad Umar Janjua"}, {"name": "Falak Sher"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This paper has been accepted at IEEE IT Professional magazine.\n  Personal use of this material is permitted, permission from IEEE must be\n  obtained for all other uses"}, "link": [{"@href": "http://arxiv.org/abs/1903.11899v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.11899v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1905.01553v1", "updated": "2019-05-04T20:19:08Z", "published": "2019-05-04T20:19:08Z", "title": "An End-to-End Framework to Identify Pathogenic Social Media Accounts on\n  Twitter", "summary": "Pathogenic Social Media (PSM) accounts such as terrorist supporter accounts\nand fake news writers have the capability of spreading disinformation to viral\nproportions. Early detection of PSM accounts is crucial as they are likely to\nbe key users to make malicious information \"viral\". In this paper, we adopt the\ncausal inference framework along with graph-based metrics in order to\ndistinguish PSMs from normal users within a short time of their activities. We\npropose both supervised and semi-supervised approaches without taking the\nnetwork information and content into account. Results on a real-world dataset\nfrom Twitter accentuates the advantage of our proposed frameworks. We show our\napproach achieves 0.28 improvement in F1 score over existing approaches with\nthe precision of 0.90 and F1 score of 0.63.", "author": [{"name": "Elham Shaabani"}, {"name": "Ashkan Sadeghi-Mobarakeh"}, {"name": "Hamidreza Alvari"}, {"name": "Paulo Shakarian"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 8 figures, International Conference on Data Intelligence and\n  Security. arXiv admin note: text overlap with arXiv:1905.01556"}, "link": [{"@href": "http://arxiv.org/abs/1905.01553v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.01553v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.10736v2", "updated": "2019-06-27T19:23:48Z", "published": "2019-06-25T19:34:34Z", "title": "Anti-Latinx Computational Propaganda in the United States", "summary": "Given that the Latino community is the second largest ethnic group in the US,\nan understanding of how Latinos are discussed and targeted on social media\nduring US elections is crucial. This paper explores these questions through a\ndata analysis on Reddit, one of the most prominent and popular social media\nplatforms for political discussion. We collected Reddit posts mentioning\nLatinos and the US midterm elections from September 24, 2017 to September 24,\n2018. We analyzed people's posting patterns over time, and the digital traces\nof the individuals posting the majority of content and the most popular\ncontent. Our research highlights data voids that existed in online discussions\nsurrounding Latinos prior to the US midterm elections. We observe a lack of\nneutral actors engaging Latinos in political topics. It appears that it is the\nmore extremist voices (i.e. individuals operating within subreddits who\nidentify themselves as political trolls) who are creating the most political\ncontent about Latinos. We conclude our report with a discussion of the possible\ndangers of data voids (especially with regard to their ties to mis- and\ndisinformation) and recommendations to increase the involvement of the Latino\ncommunity in future US elections.", "author": [{"name": "Claudia Flores-Saviaga"}, {"name": "Saiph Savage"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Institute of the Future Report 2019"}, "link": [{"@href": "http://arxiv.org/abs/1906.10736v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.10736v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1906.11371v1", "updated": "2019-06-26T22:30:01Z", "published": "2019-06-26T22:30:01Z", "title": "Deception Strategies and Threats for Online Discussions", "summary": "Communication plays a major role in social systems. Effective communications,\nwhich requires transmission of the messages between individuals without\ndisruptions or noise, can be a powerful tool to deliver intended impact.\nLanguage and style of the content can be leveraged to deceive and manipulate\nrecipients. These deception and persuasion strategies can be applied to exert\npower and amass capital in politics and business. In this work, we provide a\nmodest review of how such deception and persuasion strategies were applied to\ndifferent communication channels over the years. We provide examples of\ncampaigns that has occurred in different periods over the last 100 years,\ntogether with their corresponding dissemination mediums. In the Internet age,\nwe enjoy access to the vast amount of information and the ability to\ncommunicate without borders. However, malicious actors work toward abusing\nonline systems to disseminate disinformation, disrupt communication, and\nmanipulate people by the means of automated tools, such as social bots. It is\nimportant to study the old practices of persuasion to be able to investigate\nmodern practices and tools. Here we provide a discussion of current threats\nagainst society while drawing parallels with the historical practices and the\nrecent research efforts on systems of detection and prevention.", "author": [{"name": "Onur Varol"}, {"name": "Ismail Uluturk"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.5210/fm.v22i5.7883"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.5210/fm.v22i5.7883", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1906.11371v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.11371v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "47 oages, 3 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "First Monday 23.5 (2018)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1911.04525v1", "updated": "2019-11-11T19:16:01Z", "published": "2019-11-11T19:16:01Z", "title": "Understanding BERT performance in propaganda analysis", "summary": "In this paper, we describe our system used in the shared task for\nfine-grained propaganda analysis at sentence level. Despite the challenging\nnature of the task, our pretrained BERT model (team YMJA) fine tuned on the\ntraining dataset provided by the shared task scored 0.62 F1 on the test set and\nranked third among 25 teams who participated in the contest. We present a set\nof illustrative experiments to better understand the performance of our BERT\nmodel on this shared task. Further, we explore beyond the given dataset for\nfalse-positive cases that likely to be produced by our system. We show that\ndespite the high performance on the given testset, our system may have the\ntendency of classifying opinion pieces as propaganda and cannot distinguish\nquotations of propaganda speech from actual usage of propaganda techniques.", "author": {"name": "Yiqing Hua"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.18653/v1/D19-5019"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.18653/v1/D19-5019", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1911.04525v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.04525v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the Second Workshop on Natural Language Processing\n  for Internet Freedom: Censorship, Disinformation, and Propaganda (2019)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1911.07844v1", "updated": "2019-11-17T23:20:23Z", "published": "2019-11-17T23:20:23Z", "title": "Exploiting Human Social Cognition for the Detection of Fake and\n  Fraudulent Faces via Memory Networks", "summary": "Advances in computer vision have brought us to the point where we have the\nability to synthesise realistic fake content. Such approaches are seen as a\nsource of disinformation and mistrust, and pose serious concerns to governments\naround the world. Convolutional Neural Networks (CNNs) demonstrate encouraging\nresults when detecting fake images that arise from the specific type of\nmanipulation they are trained on. However, this success has not transitioned to\nunseen manipulation types, resulting in a significant gap in the\nline-of-defense. We propose a Hierarchical Memory Network (HMN) architecture,\nwhich is able to successfully detect faked faces by utilising knowledge stored\nin neural memories as well as visual cues to reason about the perceived face\nand anticipate its future semantic embeddings. This renders a generalisable\nface tampering detection framework. Experimental results demonstrate the\nproposed approach achieves superior performance for fake and fraudulent face\ndetection compared to the state-of-the-art.", "author": [{"name": "Tharindu Fernando"}, {"name": "Clinton Fookes"}, {"name": "Simon Denman"}, {"name": "Sridha Sridharan"}], "link": [{"@href": "http://arxiv.org/abs/1911.07844v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.07844v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.08438v1", "updated": "2020-01-23T10:37:33Z", "published": "2020-01-23T10:37:33Z", "title": "The Pushshift Telegram Dataset", "summary": "Messaging platforms, especially those with a mobile focus, have become\nincreasingly ubiquitous in society. These mobile messaging platforms can have\ndeceivingly large user bases, and in addition to being a way for people to stay\nin touch, are often used to organize social movements, as well as a place for\nextremists and other ne'er-do-well to congregate. In this paper, we present a\ndataset from one such mobile messaging platform: Telegram. Our dataset is made\nup of over 27.8K channels and 317M messages from 2.2M unique users. To the best\nof our knowledge, our dataset comprises the largest and most complete of its\nkind. In addition to the raw data, we also provide the source code used to\ncollect it, allowing researchers to run their own data collection instance. We\nbelieve the Pushshift Telegram dataset can help researchers from a variety of\ndisciplines interested in studying online social movements, protests, political\nextremism, and disinformation.", "author": [{"name": "Jason Baumgartner"}, {"name": "Savvas Zannettou"}, {"name": "Megan Squire"}, {"name": "Jeremy Blackburn"}], "link": [{"@href": "http://arxiv.org/abs/2001.08438v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.08438v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.06585v1", "updated": "2020-02-16T14:32:22Z", "published": "2020-02-16T14:32:22Z", "title": "Untrue.News: A New Search Engine For Fake Stories", "summary": "In this paper, we demonstrate Untrue News, a new search engine for fake\nstories. Untrue News is easy to use and offers useful features such as: a) a\nmulti-language option combining fake stories from different countries and\nlanguages around the same subject or person; b) an user privacy protector,\navoiding the filter bubble by employing a bias-free ranking scheme; and c) a\ncollaborative platform that fosters the development of new tools for fighting\ndisinformation. Untrue News relies on Elasticsearch, a new scalable analytic\nsearch engine based on the Lucene library that provides near real-time results.\nWe demonstrate two key scenarios: the first related to a politician - looking\nhow the categories are shown for different types of fake stories - and a second\nrelated to a refugee - showing the multilingual tool. A prototype of Untrue\nNews is accessible via http://untrue.news", "author": [{"name": "Vinicius Woloszyn"}, {"name": "Felipe Schaeffer"}, {"name": "Beliza Boniatti"}, {"name": "Eduardo Cortes"}, {"name": "Salar Mohtaj"}, {"name": "Sebastian M\u00f6ller"}], "link": [{"@href": "http://arxiv.org/abs/2002.06585v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.06585v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.12749v3", "updated": "2020-11-07T22:09:38Z", "published": "2020-02-09T07:10:58Z", "title": "Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to\n  Adversarial Examples", "summary": "Recent advances in video manipulation techniques have made the generation of\nfake videos more accessible than ever before. Manipulated videos can fuel\ndisinformation and reduce trust in media. Therefore detection of fake videos\nhas garnered immense interest in academia and industry. Recently developed\nDeepfake detection methods rely on deep neural networks (DNNs) to distinguish\nAI-generated fake videos from real videos. In this work, we demonstrate that it\nis possible to bypass such detectors by adversarially modifying fake videos\nsynthesized using existing Deepfake generation methods. We further demonstrate\nthat our adversarial perturbations are robust to image and video compression\ncodecs, making them a real-world threat. We present pipelines in both white-box\nand black-box attack scenarios that can fool DNN based Deepfake detectors into\nclassifying fake videos as real.", "author": [{"name": "Shehzeen Hussain"}, {"name": "Paarth Neekhara"}, {"name": "Malhar Jere"}, {"name": "Farinaz Koushanfar"}, {"name": "Julian McAuley"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published as a conference paper at WACV 2021"}, "link": [{"@href": "http://arxiv.org/abs/2002.12749v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.12749v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2003.01797v1", "updated": "2020-03-03T21:13:12Z", "published": "2020-03-03T21:13:12Z", "title": "Discover Your Social Identity from What You Tweet: a Content Based\n  Approach", "summary": "An identity denotes the role an individual or a group plays in highly\ndifferentiated contemporary societies. In this paper, our goal is to classify\nTwitter users based on their role identities. We first collect a coarse-grained\npublic figure dataset automatically, then manually label a more fine-grained\nidentity dataset. We propose a hierarchical self-attention neural network for\nTwitter user role identity classification. Our experiments demonstrate that the\nproposed model significantly outperforms multiple baselines. We further propose\na transfer learning scheme that improves our model's performance by a large\nmargin. Such transfer learning also greatly reduces the need for a large amount\nof human labeled data.", "author": [{"name": "Binxuan Huang"}, {"name": "Kathleen M. Carley"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-42699-6"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-42699-6", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.01797v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.01797v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a preprint of a chapter published in Disinformation,\n  Misinformation, and Fake News in Social Media: Emerging Research Challenges\n  and Opportunities, edited by Kai, S., Suhang, W., Dongwon, L., Huan, L, 2020,\n  Springer reproduced with permission of Springer Nature Switzerland AG. The\n  final authenticated version is available online at:\n  http://dx.doi.org/10.1007/978-3-030-42699-6"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.03318v1", "updated": "2020-03-06T17:31:30Z", "published": "2020-03-06T17:31:30Z", "title": "A Longitudinal Analysis of YouTube's Promotion of Conspiracy Videos", "summary": "Conspiracy theories have flourished on social media, raising concerns that\nsuch content is fueling the spread of disinformation, supporting extremist\nideologies, and in some cases, leading to violence. Under increased scrutiny\nand pressure from legislators and the public, YouTube announced efforts to\nchange their recommendation algorithms so that the most egregious conspiracy\nvideos are demoted and demonetized. To verify this claim, we have developed a\nclassifier for automatically determining if a video is conspiratorial (e.g.,\nthe moon landing was faked, the pyramids of Giza were built by aliens, end of\nthe world prophecies, etc.). We coupled this classifier with an emulation of\nYouTube's watch-next algorithm on more than a thousand popular informational\nchannels to obtain a year-long picture of the videos actively promoted by\nYouTube. We also obtained trends of the so-called filter-bubble effect for\nconspiracy theories.", "author": [{"name": "Marc Faddoul"}, {"name": "Guillaume Chaslot"}, {"name": "Hany Farid"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 3 figures. This paper was first released on March 2nd, 2020\n  along with a coverage from the New York Times available at\n  https://www.nytimes.com/interactive/2020/03/02/technology/youtube-conspiracy-theory.html"}, "link": [{"@href": "http://arxiv.org/abs/2003.03318v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.03318v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "K.4.1; K.4.2; J.4; I.2.8; I.2.6", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.00673v2", "updated": "2020-04-21T20:50:30Z", "published": "2020-04-01T19:32:25Z", "title": "Hate multiverse spreads malicious COVID-19 content online beyond\n  individual platform control", "summary": "We show that malicious COVID-19 content, including hate speech,\ndisinformation, and misinformation, exploits the multiverse of online hate to\nspread quickly beyond the control of any individual social media platform.\nMachine learning topic analysis shows quantitatively how online hate\ncommunities are weaponizing COVID-19, with topics evolving rapidly and content\nbecoming increasingly coherent. Our mathematical analysis provides a\ngeneralized form of the public health R0 predicting the tipping point for\nmultiverse-wide viral spreading, which suggests new policy options to mitigate\nthe global spread of malicious COVID-19 content without relying on future\ncoordination between all online platforms.", "author": [{"name": "N. Vel\u00e1squez"}, {"name": "R. Leahy"}, {"name": "N. Johnson Restrepo"}, {"name": "Y. Lupu"}, {"name": "R. Sear"}, {"name": "N. Gabriel"}, {"name": "O. Jha"}, {"name": "B. Goldberg"}, {"name": "N. F. Johnson"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Working paper. Feedback welcomed from the community to\n  neiljohnson@gwu.edu"}, "link": [{"@href": "http://arxiv.org/abs/2004.00673v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.00673v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "nlin.AO", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.pop-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.06793v1", "updated": "2020-04-14T20:18:21Z", "published": "2020-04-14T20:18:21Z", "title": "Probabilistic Model of Narratives Over Topical Trends in Social Media: A\n  Discrete Time Model", "summary": "Online social media platforms are turning into the prime source of news and\nnarratives about worldwide events. However,a systematic summarization-based\nnarrative extraction that can facilitate communicating the main underlying\nevents is lacking. To address this issue, we propose a novel event-based\nnarrative summary extraction framework. Our proposed framework is designed as a\nprobabilistic topic model, with categorical time distribution, followed by\nextractive text summarization. Our topic model identifies topics' recurrence\nover time with a varying time resolution. This framework not only captures the\ntopic distributions from the data, but also approximates the user activity\nfluctuations over time. Furthermore, we define significance-dispersity\ntrade-off (SDT) as a comparison measure to identify the topic with the highest\nlifetime attractiveness in a timestamped corpus. We evaluate our model on a\nlarge corpus of Twitter data, including more than one million tweets in the\ndomain of the disinformation campaigns conducted against the White Helmets of\nSyria. Our results indicate that the proposed framework is effective in\nidentifying topical trends, as well as extracting narrative summaries from text\ncorpus with timestamped data.", "author": [{"name": "Toktam A. Oghaz"}, {"name": "Ece C. Mutlu"}, {"name": "Jasser Jasser"}, {"name": "Niloofar Yousefi"}, {"name": "Ivan Garibay"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3372923.3404790"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3372923.3404790", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.06793v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.06793v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 4 figures"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.02764v1", "updated": "2020-05-04T11:18:53Z", "published": "2020-05-04T11:18:53Z", "title": "In-store epidemic behavior: scale development and validation", "summary": "Epidemics of infectious diseases have accompanied humans for a long time and,\ndepending on the scale, cause various undesirable social and economic\nconsequences. During the ongoing COVID-19 pandemic, governments of many\ncountries impose restrictions to inhibit spreading of infection. Isolation and\nlimiting interpersonal contacts are particularly recommended actions. Adhering\nto the rule of isolation may involve restrictions in freedom during daily\nactivities, such as shopping. The aim of the study was to develop a scale of\nin-store pandemic behavior. The whole process involved 3 stages: qualitative\ninquiry, scale purification and scale validation, which were based on 3\nstudies: 1 qualitative (20 in-depth interviews) 2 two quantitative (373 and 584\nrespondents, respectively), and allowed to identify 8 factors. Following, a\ntheoretical model was created to investigate the impact of in-store infection\nthreat on identified variables. All identified factors significantly correlated\nwith the in-store infection threat which reiterates the importance of providing\ninformation revealing the true scale of the pandemic and not leaving space for\nindividuals to create subjective probability judgments. The developed scale can\nhelp counteract disinformation and assess consumer behavior compliance and\nunderstanding of the official recommendations imposed by governments, enabling\nmore efficient educational efforts.", "author": [{"name": "Andrzej Szymkowiak"}, {"name": "Piotr Kulawik"}, {"name": "Kishokanth Jeganathan"}, {"name": "Paulina Guzik"}], "link": [{"@href": "http://arxiv.org/abs/2005.02764v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.02764v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.08618v1", "updated": "2020-05-18T11:56:05Z", "published": "2020-05-18T11:56:05Z", "title": "Cognitive Analysis of Security Threats on Social Networking Services:\n  Slovakia in need of stronger action", "summary": "This short paper examines some of the ongoing research at the UMB Data and\nSociety Lab hosted at the Faculty of Political Science and International\nRelations at Matej Bel University. It begins with an introduction on the\nnecessity of security threat identification on social networking services\n(SNSs), done by states. The paper follows with a general overview of selected\nprojects of the Lab in this field, and afterwards it introduces a use case\nstudy focused on the announcement of the UK snap general election 2017. The\nmain aim of this paper is to demonstrate some of the possibilities of social\nnetworking services analysis in the field of international relations, with an\nemphasis on disinformation and the necessity of identifying novel digital\nactors in Slovakia. We also outline an easy custom system tasked to collect\nsocial media data, and afterwards process it using various cognitive analytic\nmethods.", "author": [{"name": "Karol Fabian"}, {"name": "Jozef Michal Mintal"}], "link": [{"@href": "http://arxiv.org/abs/2005.08618v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.08618v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "ACM-class:K.4.1", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.08024v1", "updated": "2020-07-15T22:25:51Z", "published": "2020-07-15T22:25:51Z", "title": "A Survey on Computational Propaganda Detection", "summary": "Propaganda campaigns aim at influencing people's mindset with the purpose of\nadvancing a specific agenda. They exploit the anonymity of the Internet, the\nmicro-profiling ability of social networks, and the ease of automatically\ncreating and managing coordinated networks of accounts, to reach millions of\nsocial network users with persuasive messages, specifically targeted to topics\neach individual user is sensitive to, and ultimately influencing the outcome on\na targeted issue. In this survey, we review the state of the art on\ncomputational propaganda detection from the perspective of Natural Language\nProcessing and Network Analysis, arguing about the need for combined efforts\nbetween these communities. We further discuss current challenges and future\nresearch directions.", "author": [{"name": "Giovanni Da San Martino"}, {"name": "Stefano Cresci"}, {"name": "Alberto Barron-Cedeno"}, {"name": "Seunghak Yu"}, {"name": "Roberto Di Pietro"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda detection, disinformation, misinformation, fake news,\n  media bias"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IJCAI-2020"}, "link": [{"@href": "http://arxiv.org/abs/2007.08024v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.08024v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.02837v1", "updated": "2020-08-06T18:45:25Z", "published": "2020-08-06T18:45:25Z", "title": "aschern at SemEval-2020 Task 11: It Takes Three to Tango: RoBERTa, CRF,\n  and Transfer Learning", "summary": "We describe our system for SemEval-2020 Task 11 on Detection of Propaganda\nTechniques in News Articles. We developed ensemble models using RoBERTa-based\nneural architectures, additional CRF layers, transfer learning between the two\nsubtasks, and advanced post-processing to handle the multi-label nature of the\ntask, the consistency between nested spans, repetitions, and labels from\nsimilar spans in training. We achieved sizable improvements over baseline\nfine-tuned RoBERTa models, and the official evaluation ranked our system 3rd\n(almost tied with the 2nd) out of 36 teams on the span identification subtask\nwith an F1 score of 0.491, and 2nd (almost tied with the 1st) out of 31 teams\non the technique classification subtask with an F1 score of 0.62.", "author": [{"name": "Anton Chernyavskiy"}, {"name": "Dmitry Ilvovsky"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, persuasion, disinformation, fake news"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SemEval-2020"}, "link": [{"@href": "http://arxiv.org/abs/2008.02837v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.02837v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.08370v2", "updated": "2021-04-01T13:08:38Z", "published": "2020-08-19T10:37:29Z", "title": "Coordinated Behavior on Social Media in 2019 UK General Election", "summary": "Coordinated online behaviors are an essential part of information and\ninfluence operations, as they allow a more effective disinformation's spread.\nMost studies on coordinated behaviors involved manual investigations, and the\nfew existing computational approaches make bold assumptions or oversimplify the\nproblem to make it tractable. Here, we propose a new network-based framework\nfor uncovering and studying coordinated behaviors on social media. Our research\nextends existing systems and goes beyond limiting binary classifications of\ncoordinated and uncoordinated behaviors. It allows to expose different\ncoordination patterns and to estimate the degree of coordination that\ncharacterizes diverse communities. We apply our framework to a dataset\ncollected during the 2019 UK General Election, detecting and characterizing\ncoordinated communities that participated in the electoral debate. Our work\nconveys both theoretical and practical implications and provides more nuanced\nand fine-grained results for studying online information manipulation.", "author": [{"name": "Leonardo Nizzoli"}, {"name": "Serena Tardelli"}, {"name": "Marco Avvenuti"}, {"name": "Stefano Cresci"}, {"name": "Maurizio Tesconi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Version accepted in Proc. AAAI Intl. Conference on Web and Social\n  Media (ICWSM) 2021. Added dataset DOI"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proc. AAAI Intl. Conference on Web and Social Media (ICWSM) 2021"}, "link": [{"@href": "http://arxiv.org/abs/2008.08370v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.08370v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2008.10102v1", "updated": "2020-08-23T20:33:07Z", "published": "2020-08-23T20:33:07Z", "title": "Social Cybersecurity Chapter 13: Casestudy with COVID-19 Pandemic", "summary": "The purpose of this case study is to leverage the concepts and tools\npresented in the preceding chapters and apply them in a real world social\ncybersecurity context. With the COVID-19 pandemic emerging as a defining event\nof the 21st Century and a magnet for disinformation maneuver, we have selected\nthe pandemic and its related social media conversation to focus our efforts on.\nThis chapter therefore applies the tools of information operation maneuver, bot\ndetection and characterization, meme detection and characterization, and\ninformation mapping to the COVID-19 related conversation on Twitter. This\nchapter uses these tools to analyze a stream containing 206 million tweets from\n27 million unique users from 15 March 2020 to 30 April 2020. Our results shed\nlight on elaborate information operations that leverage the full breadth of the\nBEND maneuvers and use bots for important shaping operations.", "author": [{"name": "David M. Beskow"}, {"name": "Kathleen M. Carley"}], "link": [{"@href": "http://arxiv.org/abs/2008.10102v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.10102v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.06807v1", "updated": "2020-09-15T00:55:00Z", "published": "2020-09-15T00:55:00Z", "title": "The Radicalization Risks of GPT-3 and Advanced Neural Language Models", "summary": "In this paper, we expand on our previous research of the potential for abuse\nof generative language models by assessing GPT-3. Experimenting with prompts\nrepresentative of different types of extremist narrative, structures of social\ninteraction, and radical ideologies, we find that GPT-3 demonstrates\nsignificant improvement over its predecessor, GPT-2, in generating extremist\ntexts. We also show GPT-3's strength in generating text that accurately\nemulates interactive, informational, and influential content that could be\nutilized for radicalizing individuals into violent far-right extremist\nideologies and behaviors. While OpenAI's preventative measures are strong, the\npossibility of unregulated copycat technology represents significant risk for\nlarge-scale online radicalization and recruitment; thus, in the absence of\nsafeguards, successful and efficient weaponization that requires little\nexperimentation is likely. AI stakeholders, the policymaking community, and\ngovernments should begin investing as soon as possible in building social\nnorms, public policy, and educational initiatives to preempt an influx of\nmachine-generated disinformation and propaganda. Mitigation will require\neffective policy and partnerships across industry, government, and civil\nsociety.", "author": [{"name": "Kris McGuffie"}, {"name": "Alex Newhouse"}], "link": [{"@href": "http://arxiv.org/abs/2009.06807v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.06807v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.07632v1", "updated": "2020-08-26T08:58:29Z", "published": "2020-08-26T08:58:29Z", "title": "Helping Users Tackle Algorithmic Threats on Social Media: A Multimedia\n  Research Agenda", "summary": "Participation on social media platforms has many benefits but also poses\nsubstantial threats. Users often face an unintended loss of privacy, are\nbombarded with mis-/disinformation, or are trapped in filter bubbles due to\nover-personalized content. These threats are further exacerbated by the rise of\nhidden AI-driven algorithms working behind the scenes to shape users' thoughts,\nattitudes, and behavior. We investigate how multimedia researchers can help\ntackle these problems to level the playing field for social media users. We\nperform a comprehensive survey of algorithmic threats on social media and use\nit as a lens to set a challenging but important research agenda for effective\nand real-time user nudging. We further implement a conceptual prototype and\nevaluate it with experts to supplement our research agenda. This paper calls\nfor solutions that combat the algorithmic threats on social media by utilizing\nmachine learning and multimedia content analysis techniques but in a\ntransparent manner and for the benefit of the users.", "author": [{"name": "Christian von der Weth"}, {"name": "Ashraf Abdul"}, {"name": "Shaojing Fan"}, {"name": "Mohan Kankanhalli"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This work has been accepted to the \"Brave New Ideas\" track of the ACM\n  Multimedia Conference 2020"}, "link": [{"@href": "http://arxiv.org/abs/2009.07632v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.07632v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.06671v1", "updated": "2020-10-13T20:08:29Z", "published": "2020-10-13T20:08:29Z", "title": "A Multi-Modal Method for Satire Detection using Textual and Visual Cues", "summary": "Satire is a form of humorous critique, but it is sometimes misinterpreted by\nreaders as legitimate news, which can lead to harmful consequences. We observe\nthat the images used in satirical news articles often contain absurd or\nridiculous content and that image manipulation is used to create fictional\nscenarios. While previous work have studied text-based methods, in this work we\npropose a multi-modal approach based on state-of-the-art visiolinguistic model\nViLBERT. To this end, we create a new dataset consisting of images and\nheadlines of regular and satirical news for the task of satire detection. We\nfine-tune ViLBERT on the dataset and train a convolutional neural network that\nuses an image forensics technique. Evaluation on the dataset shows that our\nproposed multi-modal approach outperforms image-only, text-only, and simple\nfusion baselines.", "author": [{"name": "Lily Li"}, {"name": "Or Levi"}, {"name": "Pedram Hosseini"}, {"name": "David A. Broniatowski"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the Third Workshop on NLP for Internet Freedom (NLP4IF):\n  Censorship, Disinformation, and Propaganda. Co-located with COLING 2020"}, "link": [{"@href": "http://arxiv.org/abs/2010.06671v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.06671v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.04088v2", "updated": "2020-11-23T06:04:23Z", "published": "2020-11-08T21:42:03Z", "title": "MM-COVID: A Multilingual and Multimodal Data Repository for Combating\n  COVID-19 Disinformation", "summary": "The COVID-19 epidemic is considered as the global health crisis of the whole\nsociety and the greatest challenge mankind faced since World War Two.\nUnfortunately, the fake news about COVID-19 is spreading as fast as the virus\nitself. The incorrect health measurements, anxiety, and hate speeches will have\nbad consequences on people's physical health, as well as their mental health in\nthe whole world. To help better combat the COVID-19 fake news, we propose a new\nfake news detection dataset MM-COVID(Multilingual and Multidimensional COVID-19\nFake News Data Repository). This dataset provides the multilingual fake news\nand the relevant social context. We collect 3981 pieces of fake news content\nand 7192 trustworthy information from English, Spanish, Portuguese, Hindi,\nFrench and Italian, 6 different languages. We present a detailed and\nexploratory analysis of MM-COVID from different perspectives and demonstrate\nthe utility of MM-COVID in several potential applications of COVID-19 fake news\nstudy on multilingual and social media.", "author": [{"name": "Yichuan Li"}, {"name": "Bohan Jiang"}, {"name": "Kai Shu"}, {"name": "Huan Liu"}], "link": [{"@href": "http://arxiv.org/abs/2011.04088v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.04088v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.05367v1", "updated": "2020-11-10T19:38:03Z", "published": "2020-11-10T19:38:03Z", "title": "Detecting Social Media Manipulation in Low-Resource Languages", "summary": "Social media have been deliberately used for malicious purposes, including\npolitical manipulation and disinformation. Most research focuses on\nhigh-resource languages. However, malicious actors share content across\ncountries and languages, including low-resource ones. Here, we investigate\nwhether and to what extent malicious actors can be detected in low-resource\nlanguage settings. We discovered that a high number of accounts posting in\nTagalog were suspended as part of Twitter's crackdown on interference\noperations after the 2016 US Presidential election. By combining text embedding\nand transfer learning, our framework can detect, with promising accuracy,\nmalicious users posting in Tagalog without any prior knowledge or training on\nmalicious content in that language. We first learn an embedding model for each\nlanguage, namely a high-resource language (English) and a low-resource one\n(Tagalog), independently. Then, we learn a mapping between the two latent\nspaces to transfer the detection model. We demonstrate that the proposed\napproach significantly outperforms state-of-the-art models, including BERT, and\nyields marked advantages in settings with very limited training data-the norm\nwhen dealing with detecting malicious activity in online platforms.", "author": [{"name": "Samar Haider"}, {"name": "Luca Luceri"}, {"name": "Ashok Deb"}, {"name": "Adam Badawy"}, {"name": "Nanyun Peng"}, {"name": "Emilio Ferrara"}], "link": [{"@href": "http://arxiv.org/abs/2011.05367v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.05367v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.04778v2", "updated": "2020-12-13T04:56:25Z", "published": "2020-12-08T22:54:35Z", "title": "Fact-Enhanced Synthetic News Generation", "summary": "The advanced text generation methods have witnessed great success in text\nsummarization, language translation, and synthetic news generation. However,\nthese techniques can be abused to generate disinformation and fake news. To\nbetter understand the potential threats of synthetic news, we develop a new\ngeneration method FactGen to generate high-quality news content. The existing\ntext generation methods either afford limited supplementary information or lose\nconsistency between the input and output which makes the synthetic news less\ntrustworthy. To address these issues, FactGen retrieves external facts to\nenrich the output and reconstructs the input claim from the generated content\nto improve the consistency among the input and the output. Experiment results\non real-world datasets show that the generated news contents of FactGen are\nconsistent and contain rich facts. We also discuss the possible defending\nmethod to identify these synthetic news pieces if FactGen is used to generate\nsynthetic news.", "author": [{"name": "Kai Shu"}, {"name": "Yichuan Li"}, {"name": "Kaize Ding"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AAAI 2021 Preprint Version"}, "link": [{"@href": "http://arxiv.org/abs/2012.04778v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.04778v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.09092v1", "updated": "2021-01-22T13:10:47Z", "published": "2021-01-22T13:10:47Z", "title": "Deepfakes and the 2020 US elections: what (did not) happen", "summary": "Alarmed by the volume of disinformation that was assumed to have taken place\nduring the 2016 US elections, scholars, politics and journalists predicted the\nworst when the first deepfakes began to emerge in 2018. After all, US Elections\n2020 were believed to be the most secure in American history. This paper seeks\nexplanations for an apparent contradiction: we believe that it was precisely\nthe multiplication and conjugation of different types of warnings and fears\nthat created the conditions that prevented malicious political deepfakes from\naffecting the 2020 US elections. From these warnings, we identified four\nfactors (more active role of social networks, new laws, difficulties in\naccessing Artificial Intelligence and better awareness of society). But while\nthis formula has proven to be effective in the case of the United States, 2020,\nit is not correct to assume that it can be repeated in other political\ncontexts.", "author": {"name": "Jo\u00e3o Paulo Meneses"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages"}, "link": [{"@href": "http://arxiv.org/abs/2101.09092v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.09092v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.05944v1", "updated": "2021-03-10T09:01:34Z", "published": "2021-03-10T09:01:34Z", "title": "How does Truth Evolve into Fake News? An Empirical Study of Fake News\n  Evolution", "summary": "Automatically identifying fake news from the Internet is a challenging\nproblem in deception detection tasks. Online news is modified constantly during\nits propagation, e.g., malicious users distort the original truth and make up\nfake news. However, the continuous evolution process would generate\nunprecedented fake news and cheat the original model. We present the Fake News\nEvolution (FNE) dataset: a new dataset tracking the fake news evolution\nprocess. Our dataset is composed of 950 paired data, each of which consists of\narticles representing the three significant phases of the evolution process,\nwhich are the truth, the fake news, and the evolved fake news. We observe the\nfeatures during the evolution and they are the disinformation techniques, text\nsimilarity, top 10 keywords, classification accuracy, parts of speech, and\nsentiment properties.", "author": [{"name": "Mingfei Guo"}, {"name": "Xiuying Chen"}, {"name": "Juntao Li"}, {"name": "Dongyan Zhao"}, {"name": "Rui Yan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages, 2 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The Web Conference 2021, Workshop on News Recommendation and\n  Intelligence"}, "link": [{"@href": "http://arxiv.org/abs/2103.05944v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.05944v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2103.16613v1", "updated": "2021-03-30T18:36:13Z", "published": "2021-03-30T18:36:13Z", "title": "Tracking Knowledge Propagation Across Wikipedia Languages", "summary": "In this paper, we present a dataset of inter-language knowledge propagation\nin Wikipedia. Covering the entire 309 language editions and 33M articles, the\ndataset aims to track the full propagation history of Wikipedia concepts, and\nallow follow up research on building predictive models of them. For this\npurpose, we align all the Wikipedia articles in a language-agnostic manner\naccording to the concept they cover, which results in 13M propagation\ninstances. To the best of our knowledge, this dataset is the first to explore\nthe full inter-language propagation at a large scale. Together with the\ndataset, a holistic overview of the propagation and key insights about the\nunderlying structural factors are provided to aid future research. For example,\nwe find that although long cascades are unusual, the propagation tends to\ncontinue further once it reaches more than four language editions. We also find\nthat the size of language editions is associated with the speed of propagation.\nWe believe the dataset not only contributes to the prior literature on\nWikipedia growth but also enables new use cases such as edit recommendation for\naddressing knowledge gaps, detection of disinformation, and cultural\nrelationship analysis.", "author": [{"name": "Roldolfo Valentim"}, {"name": "Giovanni Comarela"}, {"name": "Souneil Park"}, {"name": "Diego Saez-Trumper"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15th International Conference on Web and Social Media (ICWSM-21),\n  2021"}, "link": [{"@href": "http://arxiv.org/abs/2103.16613v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.16613v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.04389v1", "updated": "2021-04-09T14:22:52Z", "published": "2021-04-09T14:22:52Z", "title": "A Few Observations About State-Centric Online Propaganda", "summary": "This paper presents a few observations about pro-Kremlin propaganda between\n2015 and early 2021 with a dataset from the East Stratcom Task Force (ESTF),\nwhich is affiliated with the European Union (EU) but working independently from\nit. Instead of focusing on misinformation and disinformation, the observations\nare motivated by classical propaganda research and the ongoing transformation\nof media systems. According to the tentative results, (i) the propaganda can be\nassumed to target both domestic and foreign audiences. Of the countries and\nregions discussed, (ii) Russia, Ukraine, the United States, and within Europe,\nGermany, Poland, and the EU have been the most frequently discussed. Also other\nconflict regions such as Syria have often appeared in the propaganda. In terms\nof longitudinal trends, however, (iii) most of these discussions have decreased\nin volume after the digital tsunami in 2016, although the conflict in Ukraine\nseems to have again increased the intensity of pro-Kremlin propaganda. Finally,\n(iv) the themes discussed align with state-centric war propaganda and conflict\nzones, although also post-truth themes frequently appear; from conspiracy\ntheories via COVID-19 to fascism -- anything goes, as is typical to propaganda.", "author": {"name": "Jukka Ruohonen"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted"}, "link": [{"@href": "http://arxiv.org/abs/2104.04389v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.04389v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.06182v1", "updated": "2021-04-13T13:32:55Z", "published": "2021-04-13T13:32:55Z", "title": "Understanding Transformers for Bot Detection in Twitter", "summary": "In this paper we shed light on the impact of fine-tuning over social media\ndata in the internal representations of neural language models. We focus on bot\ndetection in Twitter, a key task to mitigate and counteract the automatic\nspreading of disinformation and bias in social media. We investigate the use of\npre-trained language models to tackle the detection of tweets generated by a\nbot or a human account based exclusively on its content. Unlike the general\ntrend in benchmarks like GLUE, where BERT generally outperforms generative\ntransformers like GPT and GPT-2 for most classification tasks on regular text,\nwe observe that fine-tuning generative transformers on a bot detection task\nproduces higher accuracies. We analyze the architectural components of each\ntransformer and study the effect of fine-tuning on their hidden states and\noutput representations. Among our findings, we show that part of the\nsyntactical information and distributional properties captured by BERT during\npre-training is lost upon fine-tuning while the generative pre-training\napproach manage to preserve these properties.", "author": [{"name": "Andres Garcia-Silva"}, {"name": "Cristian Berrio"}, {"name": "Jose Manuel Gomez-Perez"}], "link": [{"@href": "http://arxiv.org/abs/2104.06182v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.06182v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.06952v1", "updated": "2021-04-14T16:25:22Z", "published": "2021-04-14T16:25:22Z", "title": "The Surprising Performance of Simple Baselines for Misinformation\n  Detection", "summary": "As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.", "author": [{"name": "Kellin Pelrine"}, {"name": "Jacob Danovitch"}, {"name": "Reihaneh Rabbany"}], "link": [{"@href": "http://arxiv.org/abs/2104.06952v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.06952v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.11694v1", "updated": "2021-04-20T23:19:43Z", "published": "2021-04-20T23:19:43Z", "title": "Mutual Hyperlinking Among Misinformation Peddlers", "summary": "The internet promised to democratize access to knowledge and make the world\nmore open and understanding. The reality of today's internet, however, is far\nfrom this ideal. Misinformation, lies, and conspiracies dominate many social\nmedia platforms. This toxic online world has had real-world implications\nranging from genocide to, election interference, and threats to global public\nhealth. A frustrated public and impatient government regulators are calling for\na more vigorous response to mis- and disinformation campaigns designed to sow\ncivil unrest and inspire violence against individuals, societies, and\ndemocracies. We describe a large-scale, domain-level analysis that reveals\nseemingly coordinated efforts between multiple domains to spread and amplify\nmisinformation. We also describe how the hyperlinks shared by certain Twitter\nusers can be used to surface problematic domains. These analyses can be used by\nsearch engines and social media recommendation algorithms to systematically\ndiscover and demote misinformation peddlers.", "author": [{"name": "Vibhor Sehgal"}, {"name": "Ankit Peshin"}, {"name": "Sadia Afroz"}, {"name": "Hany Farid"}], "link": [{"@href": "http://arxiv.org/abs/2104.11694v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.11694v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.13352v2", "updated": "2021-06-13T12:27:10Z", "published": "2021-04-24T08:54:02Z", "title": "Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021", "summary": "On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.", "author": [{"name": "Ajay Agarwal"}, {"name": "Basant Agarwal"}], "link": [{"@href": "http://arxiv.org/abs/2104.13352v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13352v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.09284v1", "updated": "2021-04-25T05:00:53Z", "published": "2021-04-25T05:00:53Z", "title": "SemEval-2021 Task 6: Detection of Persuasion Techniques in Texts and\n  Images", "summary": "We describe SemEval-2021 task 6 on Detection of Persuasion Techniques in\nTexts and Images: the data, the annotation guidelines, the evaluation setup,\nthe results, and the participating systems. The task focused on memes and had\nthree subtasks: (i) detecting the techniques in the text, (ii) detecting the\ntext spans where the techniques are used, and (iii) detecting techniques in the\nentire meme, i.e., both in the text and in the image. It was a popular task,\nattracting 71 registrations, and 22 teams that eventually made an official\nsubmission on the test set. The evaluation results for the third subtask\nconfirmed the importance of both modalities, the text and the image. Moreover,\nsome teams reported benefits when not just combining the two modalities, e.g.,\nby using early or late fusion, but rather modeling the interaction between them\nin a joint model.", "author": [{"name": "Dimitar Dimitrov"}, {"name": "Bishr Bin Ali"}, {"name": "Shaden Shaar"}, {"name": "Firoj Alam"}, {"name": "Fabrizio Silvestri"}, {"name": "Hamed Firooz"}, {"name": "Preslav Nakov"}, {"name": "Giovanni Da San Martino"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, disinformation, misinformation, fake news, memes,\n  multimodality"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SemEval-2021"}, "link": [{"@href": "http://arxiv.org/abs/2105.09284v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.09284v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.10671v1", "updated": "2021-05-22T09:26:13Z", "published": "2021-05-22T09:26:13Z", "title": "SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?", "summary": "Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges.", "author": [{"name": "Tanveer Khan"}, {"name": "Antonis Michalas"}, {"name": "Adnan Akhunzada"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "34 pages, 3 figures"}, "link": [{"@href": "http://arxiv.org/abs/2105.10671v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.10671v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.00142v1", "updated": "2021-05-31T23:20:58Z", "published": "2021-05-31T23:20:58Z", "title": "FBAdTracker: An Interactive Data Collection and Analysis Tool for\n  Facebook Advertisements", "summary": "The growing use of social media has led to drastic changes in our\ndecision-making. Especially, Facebook offers marketing API which promotes\nbusiness to target potential groups who are likely to consume their items.\nHowever, this service can be abused by malicious advertisers who attempt to\ndeceive people by disinformation such as propaganda and divisive opinion. To\ncounter this problem, we introduce a new application named FBAdTracker. The\npurpose of this application is to provide an integrated data collection and\nanalysis system for current research on fact-checking related to Facebook\nadvertisements. Our system is capable of monitoring up-to-date Facebook ads and\nanalyzing ads retrieved from Facebook Ads Library.", "author": [{"name": "Ujun Jeong"}, {"name": "Kaize Ding"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "3 pages, 1 figure, 2021 International Conference on Social Computing,\n  Behavioral-Cultural Modeling, & Prediction and Behavior Representation in\n  Modeling and Simulation, demo track"}, "link": [{"@href": "http://arxiv.org/abs/2106.00142v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.00142v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.00163v1", "updated": "2021-06-01T01:12:44Z", "published": "2021-06-01T01:12:44Z", "title": "Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform", "summary": "This paper evaluates Parler, the controversial social media platform, from\ntwo seemingly orthogonal perspectives: UX design perspective and data science.\nUX design researchers explore how users react to the interface/content of their\nsocial media feeds; Data science researchers analyze the misinformation flow in\nthese feeds to detect alternative narratives and state-sponsored disinformation\ncampaigns. We took a critical look into the intersection of these approaches to\nunderstand how Parler's interface itself is conductive to the flow of\nmisinformation and the perception of \"free speech\" among its audience. Parler\ndrew widespread attention leading up to and after the 2020 U.S. elections as\nthe \"alternative\" place for free speech, as a reaction to other mainstream\nsocial media platform which actively engaged in labeling misinformation with\ncontent warnings. Because platforms like Parler are disruptive to the social\nmedia landscape, we believe the evaluation uniquely uncovers the platform's\nconductivity to the spread of misinformation.", "author": [{"name": "Emma Pieroni"}, {"name": "Peter Jachim"}, {"name": "Nathaniel Jachim"}, {"name": "Filipo Sharevski"}], "link": [{"@href": "http://arxiv.org/abs/2106.00163v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.00163v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.01703v1", "updated": "2021-06-03T09:07:54Z", "published": "2021-06-03T09:07:54Z", "title": "Fingerprinting Fine-tuned Language Models in the Wild", "summary": "There are concerns that the ability of language models (LMs) to generate high\nquality synthetic text can be misused to launch spam, disinformation, or\npropaganda. Therefore, the research community is actively working on developing\napproaches to detect whether a given text is organic or synthetic. While this\nis a useful first step, it is important to be able to further fingerprint the\nauthor LM to attribute its origin. Prior work on fingerprinting LMs is limited\nto attributing synthetic text generated by a handful (usually < 10) of\npre-trained LMs. However, LMs such as GPT2 are commonly fine-tuned in a myriad\nof ways (e.g., on a domain-specific text corpus) before being used to generate\nsynthetic text. It is challenging to fingerprinting fine-tuned LMs because the\nuniverse of fine-tuned LMs is much larger in realistic scenarios. To address\nthis challenge, we study the problem of large-scale fingerprinting of\nfine-tuned LMs in the wild. Using a real-world dataset of synthetic text\ngenerated by 108 different fine-tuned LMs, we conduct comprehensive experiments\nto demonstrate the limitations of existing fingerprinting approaches. Our\nresults show that fine-tuning itself is the most effective in attributing the\nsynthetic text generated by fine-tuned LMs.", "author": [{"name": "Nirav Diwan"}, {"name": "Tanmoy Chakravorty"}, {"name": "Zubair Shafiq"}], "link": [{"@href": "http://arxiv.org/abs/2106.01703v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.01703v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.03389v1", "updated": "2021-06-07T07:36:36Z", "published": "2021-06-07T07:36:36Z", "title": "Never guess what I heard... Rumor Detection in Finnish News: a Dataset\n  and a Baseline", "summary": "This study presents a new dataset on rumor detection in Finnish language news\nheadlines. We have evaluated two different LSTM based models and two different\nBERT models, and have found very significant differences in the results. A\nfine-tuned FinBERT reaches the best overall accuracy of 94.3% and rumor label\naccuracy of 96.0% of the time. However, a model fine-tuned on Multilingual BERT\nreaches the best factual label accuracy of 97.2%. Our results suggest that the\nperformance difference is due to a difference in the original training data.\nFurthermore, we find that a regular LSTM model works better than one trained\nwith a pretrained word2vec model. These findings suggest that more work needs\nto be done for pretrained models in Finnish language as they have been trained\non small and biased corpora.", "author": [{"name": "Mika H\u00e4m\u00e4l\u00e4inen"}, {"name": "Khalid Alnajjar"}, {"name": "Niko Partanen"}, {"name": "Jack Rueter"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "2021 Workshop on NLP4IF: Censorship, Disinformation, and Propaganda"}, "link": [{"@href": "http://arxiv.org/abs/2106.03389v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.03389v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2106.15940v1", "updated": "2021-06-30T09:47:27Z", "published": "2021-06-30T09:47:27Z", "title": "A preliminary approach to knowledge integrity risk assessment in\n  Wikipedia projects", "summary": "Wikipedia is one of the main repositories of free knowledge available today,\nwith a central role in the Web ecosystem. For this reason, it can also be a\nbattleground for actors trying to impose specific points of view or even\nspreading disinformation online. There is a growing need to monitor its\n\"health\" but this is not an easy task. Wikipedia exists in over 300 language\neditions and each project is maintained by a different community, with their\nown strengths, weaknesses and limitations. In this paper, we introduce a\ntaxonomy of knowledge integrity risks across Wikipedia projects and a first set\nof indicators to assess internal risks related to community and content issues,\nas well as external threats such as the geopolitical and media landscape. On\ntop of this taxonomy, we offer a preliminary analysis illustrating how the lack\nof editors' geographical diversity might represent a knowledge integrity risk.\nThese are the first steps of a research project to build a Wikipedia Knowledge\nIntegrity Risk Observatory.", "author": [{"name": "Pablo Arag\u00f3n"}, {"name": "Diego S\u00e1ez-Trumper"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at MIS2'21: Misinformation and Misbehavior Mining on the Web\n  Workshop held in conjunction with KDD 2021"}, "link": [{"@href": "http://arxiv.org/abs/2106.15940v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.15940v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.10139v2", "updated": "2021-07-29T05:28:52Z", "published": "2021-07-21T15:16:10Z", "title": "Generative Models for Security: Attacks, Defenses, and Opportunities", "summary": "Generative models learn the distribution of data from a sample dataset and\ncan then generate new data instances. Recent advances in deep learning has\nbrought forth improvements in generative model architectures, and some\nstate-of-the-art models can (in some cases) produce outputs realistic enough to\nfool humans.\n  We survey recent research at the intersection of security and privacy and\ngenerative models. In particular, we discuss the use of generative models in\nadversarial machine learning, in helping automate or enhance existing attacks,\nand as building blocks for defenses in contexts such as intrusion detection,\nbiometrics spoofing, and malware obfuscation. We also describe the use of\ngenerative models in diverse applications such as fairness in machine learning,\nprivacy-preserving data synthesis, and steganography. Finally, we discuss new\nthreats due to generative models: the creation of synthetic media such as\ndeepfakes that can be used for disinformation.", "author": [{"name": "Luke A. Bauer"}, {"name": "Vincent Bindschaedler"}], "link": [{"@href": "http://arxiv.org/abs/2107.10139v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.10139v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.10942v1", "updated": "2021-08-24T20:27:38Z", "published": "2021-08-24T20:27:38Z", "title": "Profiling Fake News Spreaders on Social Media through Psychological and\n  Motivational Factors", "summary": "The rise of fake news in the past decade has brought with it a host of\nconsequences, from swaying opinions on elections to generating uncertainty\nduring a pandemic. A majority of methods developed to combat disinformation\neither focus on fake news content or malicious actors who generate it. However,\nthe virality of fake news is largely dependent upon the users who propagate it.\nA deeper understanding of these users can contribute to the development of a\nframework for identifying users who are likely to spread fake news. In this\nwork, we study the characteristics and motivational factors of fake news\nspreaders on social media with input from psychological theories and behavioral\nstudies. We then perform a series of experiments to determine if fake news\nspreaders can be found to exhibit different characteristics than other users.\nFurther, we investigate our findings by testing whether the characteristics we\nobserve amongst fake news spreaders in our experiments can be applied to the\ndetection of fake news spreaders in a real social media environment.", "author": [{"name": "Mansooreh Karami"}, {"name": "Tahora H. Nazer"}, {"name": "Huan Liu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3465336.3475097"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3465336.3475097", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.10942v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.10942v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.12519v1", "updated": "2021-08-27T22:43:00Z", "published": "2021-08-27T22:43:00Z", "title": "Predicting the Factuality of Reporting of News Media Using Observations\n  About User Attention in Their YouTube Channels", "summary": "We propose a novel framework for predicting the factuality of reporting of\nnews media outlets by studying the user attention cycles in their YouTube\nchannels. In particular, we design a rich set of features derived from the\ntemporal evolution of the number of views, likes, dislikes, and comments for a\nvideo, which we then aggregate to the channel level. We develop and release a\ndataset for the task, containing observations of user attention on YouTube\nchannels for 489 news media. Our experiments demonstrate both complementarity\nand sizable improvements over state-of-the-art textual representations.", "author": [{"name": "Krasimira Bozhanova"}, {"name": "Yoan Dinkov"}, {"name": "Ivan Koychev"}, {"name": "Maria Castaldo"}, {"name": "Tommaso Venturini"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Factuality, disinformation, misinformation, fake news, Youtube\n  channels, propaganda, attention cycles"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RANLP-2021"}, "link": [{"@href": "http://arxiv.org/abs/2108.12519v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.12519v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.12752v1", "updated": "2021-08-29T04:48:28Z", "published": "2021-08-29T04:48:28Z", "title": "TAR on Social Media: A Framework for Online Content Moderation", "summary": "Content moderation (removing or limiting the distribution of posts based on\ntheir contents) is one tool social networks use to fight problems such as\nharassment and disinformation. Manually screening all content is usually\nimpractical given the scale of social media data, and the need for nuanced\nhuman interpretations makes fully automated approaches infeasible. We consider\ncontent moderation from the perspective of technology-assisted review (TAR): a\nhuman-in-the-loop active learning approach developed for high recall retrieval\nproblems in civil litigation and other fields. We show how TAR workflows, and a\nTAR cost model, can be adapted to the content moderation problem. We then\ndemonstrate on two publicly available content moderation data sets that a TAR\nworkflow can reduce moderation costs by 20% to 55% across a variety of\nconditions.", "author": [{"name": "Eugene Yang"}, {"name": "David D. Lewis"}, {"name": "Ophir Frieder"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 2 figures, accepted at DESIRES 2021"}, "link": [{"@href": "http://arxiv.org/abs/2108.12752v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.12752v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.12802v1", "updated": "2021-08-29T09:57:01Z", "published": "2021-08-29T09:57:01Z", "title": "Interpretable Propaganda Detection in News Articles", "summary": "Online users today are exposed to misleading and propagandistic news articles\nand media posts on a daily basis. To counter thus, a number of approaches have\nbeen designed aiming to achieve a healthier and safer online news and media\nconsumption. Automatic systems are able to support humans in detecting such\ncontent; yet, a major impediment to their broad adoption is that besides being\naccurate, the decisions of such systems need also to be interpretable in order\nto be trusted and widely adopted by users. Since misleading and propagandistic\ncontent influences readers through the use of a number of deception techniques,\nwe propose to detect and to show the use of such techniques as a way to offer\ninterpretability. In particular, we define qualitatively descriptive features\nand we analyze their suitability for detecting deception techniques. We further\nshow that our interpretable features can be easily combined with pre-trained\nlanguage models, yielding state-of-the-art results.", "author": [{"name": "Seunghak Yu"}, {"name": "Giovanni Da San Martino"}, {"name": "Mitra Mohtarami"}, {"name": "James Glass"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, propaganda techniques, disinformation, misinformation,\n  fake news, explainability, interpretability"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RANLP-2021"}, "link": [{"@href": "http://arxiv.org/abs/2108.12802v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.12802v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2109.00835v1", "updated": "2021-09-02T10:45:07Z", "published": "2021-09-02T10:45:07Z", "title": "WikiCheck: An end-to-end open source Automatic Fact-Checking API based\n  on Wikipedia", "summary": "With the growth of fake news and disinformation, the NLP community has been\nworking to assist humans in fact-checking. However, most academic research has\nfocused on model accuracy without paying attention to resource efficiency,\nwhich is crucial in real-life scenarios. In this work, we review the\nState-of-the-Art datasets and solutions for Automatic Fact-checking and test\ntheir applicability in production environments. We discover overfitting issues\nin those models, and we propose a data filtering method that improves the\nmodel's performance and generalization. Then, we design an unsupervised\nfine-tuning of the Masked Language models to improve its accuracy working with\nWikipedia. We also propose a novel query enhancing method to improve evidence\ndiscovery using the Wikipedia Search API. Finally, we present a new\nfact-checking system, the \\textit{WikiCheck} API that automatically performs a\nfacts validation process based on the Wikipedia knowledge base. It is\ncomparable to SOTA solutions in terms of accuracy and can be used on low-memory\nCPU instances.", "author": [{"name": "Mykola Trokhymovych"}, {"name": "Diego Saez-Trumper"}], "link": [{"@href": "http://arxiv.org/abs/2109.00835v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2109.00835v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/0707.4036v2", "updated": "2008-07-17T14:43:04Z", "published": "2007-07-27T04:13:21Z", "title": "Disrupting Terrorist Networks, a dynamic fitness landscape approach", "summary": "Over a period of approximately five years, Pankaj Ghemawat of Harvard\nBusiness School and Daniel Levinthal of the Wharton School have been working on\na detailed simulation (producing approximately a million fitness landscape\ngraphs) in order to determine optimal patterns of decision-making for\ncorporations. In 2006, we adapted this study, combining it with our own work on\nterrorism to examine what would happen if we inverted Ghemawat and Levinthal's\nfindings and sought to provide disinformation or otherwise interfere with the\ncommunications and decision processes of terrorist organizations in order to\noptimize poor decision making and inefficiencies in organizational\ncoordination, command and control.\n  The bulk of this study was then presented at the 2006 annual meeting of the\nNorth American Association for Computation in the Social and Organizational\nSciences. We present here an updated version of that study, emphasizing the\nrather counter-intuitive finding that \"soft\" targets have almost no value and\nthat unless one can influence key factors, an effort directed at the easy to\nreach elements of terrorist organizations may actually be worse than mounting\nno effort at all. We conclude with the recommendation that some fundamental\nrethinking may be required if the United States is to effectively defend itself\nfrom future terrorist attacks.", "author": [{"name": "Philip V. Fellman"}, {"name": "Jonathan P. Clemens"}, {"name": "Roxana Wright"}, {"name": "Jonathan Vos Post"}, {"name": "Matthew Dadmun"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages, 8 figures. Proceedings of the 2006 annual meeting of the\n  North American Association for Computation in the Social and Organizational\n  Sciences"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "InterJournal Complex Systems, 2060"}, "link": [{"@href": "http://arxiv.org/abs/0707.4036v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/0707.4036v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "nlin.AO", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "nlin.AO", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1505.00956v2", "updated": "2015-06-02T17:30:59Z", "published": "2015-05-05T11:15:43Z", "title": "Informational parasites in code evolution", "summary": "In a previous study, we considered an information-theoretic model of code\nevolution. In it, agents obtain information about their (common) environment by\nthe perception of messages of other agents, which is determined by an\ninteraction probability (the structure of the population). For an agent to\nunderstand another agent's messages, the former must either know the identity\nof the latter, or the code producing the messages must be universally\ninterpretable. A universal code, however, introduces a vulnerability: a\nparasitic entity can take advantage of it. Here, we investigate this problem.\nIn our specific setting, we consider a parasite to be an agent that tries to\ninflict as much damage as possible in the mutual understanding of the\npopulation (i.e. the parasite acts as a disinformation agent). We show that,\nafter introducing a parasite in the population, the former adopts a code such\nthat it captures the information about the environment that is missing in the\npopulation. Such agent would be of great value, but only if the rest of the\npopulation could understand its messages. However, it is of little use here,\nsince the parasite utilises the most common messages in the population to\nexpress different concepts. Now we let the population respond by updating their\ncodes such that, in this arms race, they again maximise their mutual\nunderstanding. As a result, there is a code drift in the population where the\nutilisation of the messages of the parasite is avoided. A consequence of this\nis that the information that the parasite possesses but the agents lack becomes\nunderstandable and readily available.", "author": [{"name": "Andres C. Burgos"}, {"name": "Daniel Polani"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for the 13th European Conference on Artificial Life (ECAL\n  2015)"}, "link": [{"@href": "http://arxiv.org/abs/1505.00956v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1505.00956v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1910.01160v2", "updated": "2019-11-05T20:45:25Z", "published": "2019-10-02T18:47:17Z", "title": "Identifying Nuances in Fake News vs. Satire: Using Semantic and\n  Linguistic Cues", "summary": "The blurry line between nefarious fake news and protected-speech satire has\nbeen a notorious struggle for social media platforms. Further to the efforts of\nreducing exposure to misinformation on social media, purveyors of fake news\nhave begun to masquerade as satire sites to avoid being demoted. In this work,\nwe address the challenge of automatically classifying fake news versus satire.\nPrevious work have studied whether fake news and satire can be distinguished\nbased on language differences. Contrary to fake news, satire stories are\nusually humorous and carry some political or social message. We hypothesize\nthat these nuances could be identified using semantic and linguistic cues.\nConsequently, we train a machine learning method using semantic representation,\nwith a state-of-the-art contextual language model, and with linguistic features\nbased on textual coherence metrics. Empirical evaluation attests to the merits\nof our approach compared to the language-based baseline and sheds light on the\nnuances between fake news and satire. As avenues for future work, we consider\nstudying additional linguistic features related to the humor aspect, and\nenriching the data with current news events, to help identify a political or\nsocial message.", "author": [{"name": "Or Levi"}, {"name": "Pedram Hosseini"}, {"name": "Mona Diab"}, {"name": "David A. Broniatowski"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.18653/v1/D19-5004"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.18653/v1/D19-5004", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1910.01160v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.01160v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the 2nd Workshop on NLP for Internet Freedom (NLP4IF):\n  Censorship, Disinformation, and Propaganda. Co-located with EMNLP-IJCNLP 2019"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1611.02588v2", "updated": "2016-11-11T10:57:07Z", "published": "2016-11-08T16:19:17Z", "title": "Contradiction Detection for Rumorous Claims", "summary": "The utilization of social media material in journalistic workflows is\nincreasing, demanding automated methods for the identification of mis- and\ndisinformation. Since textual contradiction across social media posts can be a\nsignal of rumorousness, we seek to model how claims in Twitter posts are being\ntextually contradicted. We identify two different contexts in which\ncontradiction emerges: its broader form can be observed across independently\nposted tweets and its more specific form in threaded conversations. We define\nhow the two scenarios differ in terms of central elements of argumentation:\nclaims and conversation structure. We design and evaluate models for the two\nscenarios uniformly as 3-way Recognizing Textual Entailment tasks in order to\nrepresent claims and conversation structure implicitly in a generic inference\nmodel, while previous studies used explicit or no representation of these\nproperties. To address noisy text, our classifiers use simple similarity\nfeatures derived from the string and part-of-speech level. Corpus statistics\nreveal distribution differences for these features in contradictory as opposed\nto non-contradictory tweet relations, and the classifiers yield state of the\nart performance.", "author": [{"name": "Piroska Lendvai"}, {"name": "Uwe D. Reichel"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear in: Proceedings of Extra-Propositional Aspects of Meaning\n  (ExProM) in Computational Linguistics, Osaka, Japan, 2016"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proc. Extra-Propositional Aspects of Meaning (ExProM) in\n  Computational Linguistics, Osaka, Japan, 2016, pp 31-40"}, "link": [{"@href": "http://arxiv.org/abs/1611.02588v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1611.02588v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1804.04109v1", "updated": "2018-04-11T17:28:41Z", "published": "2018-04-11T17:28:41Z", "title": "Influence Estimation on Social Media Networks Using Causal Inference", "summary": "Estimating influence on social media networks is an important practical and\ntheoretical problem, especially because this new medium is widely exploited as\na platform for disinformation and propaganda. This paper introduces a novel\napproach to influence estimation on social media networks and applies it to the\nreal-world problem of characterizing active influence operations on Twitter\nduring the 2017 French presidential elections. The new influence estimation\napproach attributes impact by accounting for narrative propagation over the\nnetwork using a network causal inference framework applied to data arising from\ngraph sampling and filtering. This causal framework infers the difference in\noutcome as a function of exposure, in contrast to existing approaches that\nattribute impact to activity volume or topological features, which do not\nexplicitly measure nor necessarily indicate actual network influence.\nCram\\'er-Rao estimation bounds are derived for parameter estimation as a step\nin the causal analysis, and used to achieve geometrical insight on the causal\ninference problem. The ability to infer high causal influence is demonstrated\non real-world social media accounts that are later independently confirmed to\nbe either directly affiliated or correlated with foreign influence operations\nusing evidence supplied by the U.S. Congress and journalistic reports.", "author": [{"name": "Steven T. Smith"}, {"name": "Edward K. Kao"}, {"name": "Danelle C. Shah"}, {"name": "Olga Simek"}, {"name": "Donald B. Rubin"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/SSP.2018.8450823"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/SSP.2018.8450823", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1804.04109v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.04109v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages, 4 figures, 1 table"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IEEE Statistical Signal Processing Workshop (SSP), June 2018"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1808.03281v1", "updated": "2018-08-09T18:00:05Z", "published": "2018-08-09T18:00:05Z", "title": "Who Falls for Online Political Manipulation?", "summary": "Social media, once hailed as a vehicle for democratization and the promotion\nof positive social change across the globe, are under attack for becoming a\ntool of political manipulation and spread of disinformation. A case in point is\nthe alleged use of trolls by Russia to spread malicious content in Western\nelections. This paper examines the Russian interference campaign in the 2016 US\npresidential election on Twitter. Our aim is twofold: first, we test whether\npredicting users who spread trolls' content is feasible in order to gain\ninsight on how to contain their influence in the future; second, we identify\nfeatures that are most predictive of users who either intentionally or\nunintentionally play a vital role in spreading this malicious content. We\ncollected a dataset with over 43 million elections-related posts shared on\nTwitter between September 16 and November 9, 2016, by about 5.7 million users.\nThis dataset includes accounts associated with the Russian trolls identified by\nthe US Congress. Proposed models are able to very accurately identify users who\nspread the trolls' content (average AUC score of 96%, using 10-fold\nvalidation). We show that political ideology, bot likelihood scores, and some\nactivity-related account meta data are the most predictive features of whether\na user spreads trolls' content or not.", "author": [{"name": "Adam Badawy"}, {"name": "Kristina Lerman"}, {"name": "Emilio Ferrara"}], "link": [{"@href": "http://arxiv.org/abs/1808.03281v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.03281v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1902.01970v1", "updated": "2019-02-05T23:19:48Z", "published": "2019-02-05T23:19:48Z", "title": "Hawkes Process for Understanding the Influence of Pathogenic Social\n  Media Accounts", "summary": "Over the past years, political events and public opinion on the Web have been\nallegedly manipulated by accounts dedicated to spreading disinformation and\nperforming malicious activities on social media. These accounts hereafter\nreferred to as \"Pathogenic Social Media (PSM)\" accounts, are often controlled\nby terrorist supporters, water armies or fake news writers and hence can pose\nthreats to social media and general public. Understanding and analyzing PSMs\ncould help social media firms devise sophisticated and automated techniques\nthat could be deployed to stop them from reaching their audience and\nconsequently reduce their threat. In this paper, we leverage the well-known\nstatistical technique \"Hawkes Process\" to quantify the influence of PSM\naccounts on the dissemination of malicious information on social media\nplatforms. Our findings on a real-world ISIS-related dataset from Twitter\nindicate that PSMs are significantly different from regular users in making a\nmessage viral. Specifically, we observed that PSMs do not usually post URLs\nfrom mainstream news sources. Instead, their tweets usually receive large\nimpact on audience, if contained URLs from Facebook and alternative news\noutlets. In contrary, tweets posted by regular users receive nearly equal\nimpression regardless of the posted URLs and their sources. Our findings can\nfurther shed light on understanding and detecting PSM accounts.", "author": [{"name": "Hamidreza Alvari"}, {"name": "Paulo Shakarian"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IEEE Conference on Data Intelligence and Security (ICDIS) 2019"}, "link": [{"@href": "http://arxiv.org/abs/1902.01970v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.01970v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1902.07285v6", "updated": "2021-04-21T10:14:36Z", "published": "2019-02-12T02:42:54Z", "title": "Towards a Robust Deep Neural Network in Texts: A Survey", "summary": "Deep neural networks (DNNs) have achieved remarkable success in various tasks\n(e.g., image classification, speech recognition, and natural language\nprocessing (NLP)). However, researchers have demonstrated that DNN-based models\nare vulnerable to adversarial examples, which cause erroneous predictions by\nadding imperceptible perturbations into legitimate inputs. Recently, studies\nhave revealed adversarial examples in the text domain, which could effectively\nevade various DNN-based text analyzers and further bring the threats of the\nproliferation of disinformation. In this paper, we give a comprehensive survey\non the existing studies of adversarial techniques for generating adversarial\ntexts written by both English and Chinese characters and the corresponding\ndefense methods. More importantly, we hope that our work could inspire future\nstudies to develop more robust DNN-based text analyzers against known and\nunknown adversarial techniques.\n  We classify the existing adversarial techniques for crafting adversarial\ntexts based on the perturbation units, helping to better understand the\ngeneration of adversarial texts and build robust models for defense. In\npresenting the taxonomy of adversarial attacks and defenses in the text domain,\nwe introduce the adversarial techniques from the perspective of different NLP\ntasks. Finally, we discuss the existing challenges of adversarial attacks and\ndefenses in texts and present the future research directions in this emerging\nand challenging field.", "author": [{"name": "Wenqi Wang"}, {"name": "Run Wang"}, {"name": "Lina Wang"}, {"name": "Zhibo Wang"}, {"name": "Aoshuang Ye"}], "link": [{"@href": "http://arxiv.org/abs/1902.07285v6", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.07285v6", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.10317v1", "updated": "2019-04-20T23:54:51Z", "published": "2019-04-20T23:54:51Z", "title": "The evolution of polarization in the legislative branch of government", "summary": "The polarization of political opinions among members of the U.S. legislative\nchambers measured by their voting records is greater today than it was thirty\nyears ago. Previous research efforts to find causes of such increase have\nsuggested diverse contributors, like growth of online media, echo chamber\neffects, media biases, or disinformation propagation. Yet, we lack theoretic\ntools to understand, quantify, and predict the emergence of high political\npolarization among voters and their legislators. Here, we analyze millions of\nroll-call votes cast in the U.S. Congress over the past six decades. Our\nanalysis reveals the critical change of polarization patterns that started at\nthe end of 1980's. In earlier decades, polarization within each Congress tended\nto decrease with time. In contrast, in the recent decades, the polarization has\nbeen likely to grow within each term. To shed light on the reasons for this\nchange, we introduce here a formal model for competitive dynamics to quantify\nthe evolution of polarization patterns in the legislative branch of the U.S.\ngovernment. Our model represents dynamics of polarization, enabling us to\nsuccessfully predict the direction of polarization changes in 28 out of 30 U.S.\nCongresses elected in the past six decades. From the evolution of polarization\nlevel as measured by the Rice index, our model extracts a hidden parameter -\npolarization utility which determines the convergence point of the polarization\nevolution. The increase in the polarization utility implied by the model\nstrongly correlates with two current trends: growing polarization of voters and\nincreasing influence of election campaign funders. Two largest peaks of the\nmodel's polarization utility correlate with significant political or\nlegislative changes happening at the same time.", "author": [{"name": "Xiaoyan Lu"}, {"name": "Jianxi Gao"}, {"name": "Boleslaw K. Szymanski"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1098/rsif.2019.0010"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1098/rsif.2019.0010", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1904.10317v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.10317v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "J. R. Soc. Interface, vol. 16:20190010, 2019"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1904.11679v2", "updated": "2020-09-16T18:42:11Z", "published": "2019-04-26T05:52:05Z", "title": "Fake News Early Detection: An Interdisciplinary Study", "summary": "Massive dissemination of fake news and its potential to erode democracy has\nincreased the demand for accurate fake news detection. Recent advancements in\nthis area have proposed novel techniques that aim to detect fake news by\nexploring how it propagates on social networks. Nevertheless, to detect fake\nnews at an early stage, i.e., when it is published on a news outlet but not yet\nspread on social media, one cannot rely on news propagation information as it\ndoes not exist. Hence, there is a strong need to develop approaches that can\ndetect fake news by focusing on news content. In this paper, a theory-driven\nmodel is proposed for fake news detection. The method investigates news content\nat various levels: lexicon-level, syntax-level, semantic-level and\ndiscourse-level. We represent news at each level, relying on well-established\ntheories in social and forensic psychology. Fake news detection is then\nconducted within a supervised machine learning framework. As an\ninterdisciplinary research, our work explores potential fake news patterns,\nenhances the interpretability in fake news feature engineering, and studies the\nrelationships among fake news, deception/disinformation, and clickbaits.\nExperiments conducted on two real-world datasets indicate the proposed method\ncan outperform the state-of-the-art and enable fake news early detection when\nthere is limited content information.", "author": [{"name": "Xinyi Zhou"}, {"name": "Atishay Jain"}, {"name": "Vir V. Phoha"}, {"name": "Reza Zafarani"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "25 pages"}, "link": [{"@href": "http://arxiv.org/abs/1904.11679v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.11679v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.12616v3", "updated": "2020-12-11T16:17:17Z", "published": "2019-05-29T17:58:52Z", "title": "Defending Against Neural Fake News", "summary": "Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news.", "author": [{"name": "Rowan Zellers"}, {"name": "Ari Holtzman"}, {"name": "Hannah Rashkin"}, {"name": "Yonatan Bisk"}, {"name": "Ali Farhadi"}, {"name": "Franziska Roesner"}, {"name": "Yejin Choi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NeurIPS 2019 camera ready version. Project page/code/demo at\n  https://rowanzellers.com/grover"}, "link": [{"@href": "http://arxiv.org/abs/1905.12616v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.12616v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.01328v1", "updated": "2019-08-04T12:40:28Z", "published": "2019-08-04T12:40:28Z", "title": "Automatic Fact-Checking Using Context and Discourse Information", "summary": "We study the problem of automatic fact-checking, paying special attention to\nthe impact of contextual and discourse information. We address two related\ntasks: (i) detecting check-worthy claims, and (ii) fact-checking claims. We\ndevelop supervised systems based on neural networks, kernel-based support\nvector machines, and combinations thereof, which make use of rich input\nrepresentations in terms of discourse cues and contextual features. For the\ncheck-worthiness estimation task, we focus on political debates, and we model\nthe target claim in the context of the full intervention of a participant and\nthe previous and the following turns in the debate, taking into account\ncontextual meta information. For the fact-checking task, we focus on answer\nverification in a community forum, and we model the veracity of the answer with\nrespect to the entire question--answer thread in which it occurs as well as\nwith respect to other related posts from the entire forum. We develop annotated\ndatasets for both tasks and we run extensive experimental evaluation,\nconfirming that both types of information ---but especially contextual\nfeatures--- play an important role.", "author": [{"name": "Pepa Atanasova"}, {"name": "Preslav Nakov"}, {"name": "Llu\u00eds M\u00e0rquez"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Georgi Karadzhov"}, {"name": "Tsvetomila Mihaylova"}, {"name": "Mitra Mohtarami"}, {"name": "James Glass"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3297722"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3297722", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1908.01328v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.01328v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "JDIQ,Special Issue on Combating Digital Misinformation and\n  Disinformation"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "J. Data and Information Quality, Volume 11 Issue 3, July 2019,\n  Article No. 12"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.07595v1", "updated": "2020-03-17T09:24:22Z", "published": "2020-03-17T09:24:22Z", "title": "FakeYou! -- A Gamified Approach for Building and Evaluating Resilience\n  Against Fake News", "summary": "Nowadays fake news are heavily discussed in public and political debates.\nEven though the phenomenon of intended false information is rather old,\nmisinformation reaches a new level with the rise of the internet and\nparticipatory platforms. Due to Facebook and Co., purposeful false information\n- often called fake news - can be easily spread by everyone. Because of a high\ndata volatility and variety in content types (text, images,...) debunking of\nfake news is a complex challenge. This is especially true for automated\napproaches, which are prone to fail validating the veracity of the information.\nThis work focuses on an a gamified approach to strengthen the resilience of\nconsumers towards fake news. The game FakeYou motivates its players to\ncritically analyze headlines regarding their trustworthiness. Further, the game\nfollows a \"learning by doing strategy\": by generating own fake headlines, users\nshould experience the concepts of convincing fake headline formulations. We\nintroduce the game itself, as well as the underlying technical infrastructure.\nA first evaluation study shows, that users tend to use specific stylistic\ndevices to generate fake news. Further, the results indicate, that creating\ngood fakes and identifying correct headlines are challenging and hard to learn.", "author": [{"name": "Lena Clever"}, {"name": "Dennis Assenmacher"}, {"name": "Kilian M\u00fcller"}, {"name": "Moritz Vinzent Seiler"}, {"name": "Dennis M. Riehle"}, {"name": "Mike Preuss"}, {"name": "Christian Grimme"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "accepted for Disinformation in Open Online Media - 2nd\n  Multidisciplinary International Symposium, MISDOOM 2020"}, "link": [{"@href": "http://arxiv.org/abs/2003.07595v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.07595v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.11459v1", "updated": "2020-03-23T23:43:02Z", "published": "2020-03-23T23:43:02Z", "title": "BaitWatcher: A lightweight web interface for the detection of\n  incongruent news headlines", "summary": "In digital environments where substantial amounts of information are shared\nonline, news headlines play essential roles in the selection and diffusion of\nnews articles. Some news articles attract audience attention by showing\nexaggerated or misleading headlines. This study addresses the \\textit{headline\nincongruity} problem, in which a news headline makes claims that are either\nunrelated or opposite to the contents of the corresponding article. We present\n\\textit{BaitWatcher}, which is a lightweight web interface that guides readers\nin estimating the likelihood of incongruence in news articles before clicking\non the headlines. BaitWatcher utilizes a hierarchical recurrent encoder that\nefficiently learns complex textual representations of a news headline and its\nassociated body text. For training the model, we construct a million scale\ndataset of news articles, which we also release for broader research use. Based\non the results of a focus group interview, we discuss the importance of\ndeveloping an interpretable AI agent for the design of a better interface for\nmitigating the effects of online misinformation.", "author": [{"name": "Kunwoo Park"}, {"name": "Taegyun Kim"}, {"name": "Seunghyun Yoon"}, {"name": "Meeyoung Cha"}, {"name": "Kyomin Jung"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-42699-6"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-42699-6", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.11459v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.11459v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "24 pages (single column), 7 figures. This research article is\n  published as a book chapter of \\textit{Fake News, Disinformation, and\n  Misinformation in Social Media-Emerging Research Challenges and\n  Opportunities}. Springer, 2020. arXiv admin note: text overlap with\n  arXiv:1811.07066"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68U15", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.11480v1", "updated": "2020-04-23T22:25:48Z", "published": "2020-04-23T22:25:48Z", "title": "Characterising User Content on a Multi-lingual Social Network", "summary": "Social media has been on the vanguard of political information diffusion in\nthe 21st century. Most studies that look into disinformation, political\ninfluence and fake-news focus on mainstream social media platforms. This has\ninevitably made English an important factor in our current understanding of\npolitical activity on social media. As a result, there has only been a limited\nnumber of studies into a large portion of the world, including the largest,\nmultilingual and multi-cultural democracy: India. In this paper we present our\ncharacterisation of a multilingual social network in India called ShareChat. We\ncollect an exhaustive dataset across 72 weeks before and during the Indian\ngeneral elections of 2019, across 14 languages. We investigate the cross\nlingual dynamics by clustering visually similar images together, and exploring\nhow they move across language barriers. We find that Telugu, Malayalam, Tamil\nand Kannada languages tend to be dominant in soliciting political images (often\nreferred to as memes), and posts from Hindi have the largest cross-lingual\ndiffusion across ShareChat (as well as images containing text in English). In\nthe case of images containing text that cross language barriers, we see that\nlanguage translation is used to widen the accessibility. That said, we find\ncases where the same image is associated with very different text (and\ntherefore meanings). This initial characterisation paves the way for more\nadvanced pipelines to understand the dynamics of fake and political content in\na multi-lingual and non-textual setting.", "author": [{"name": "Pushkal Agarwal"}, {"name": "Kiran Garimella"}, {"name": "Sagar Joglekar"}, {"name": "Nishanth Sastry"}, {"name": "Gareth Tyson"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at ICWSM 2020, please cite the ICWSM version"}, "link": [{"@href": "http://arxiv.org/abs/2004.11480v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.11480v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.01157v1", "updated": "2020-05-03T18:02:10Z", "published": "2020-05-03T18:02:10Z", "title": "Out of the Echo Chamber: Detecting Countering Debate Speeches", "summary": "An educated and informed consumption of media content has become a challenge\nin modern times. With the shift from traditional news outlets to social media\nand similar venues, a major concern is that readers are becoming encapsulated\nin \"echo chambers\" and may fall prey to fake news and disinformation, lacking\neasy access to dissenting views. We suggest a novel task aiming to alleviate\nsome of these concerns -- that of detecting articles that most effectively\ncounter the arguments -- and not just the stance -- made in a given text. We\nstudy this problem in the context of debate speeches. Given such a speech, we\naim to identify, from among a set of speeches on the same topic and with an\nopposing stance, the ones that directly counter it. We provide a large dataset\nof 3,685 such speeches (in English), annotated for this relation, which\nhopefully would be of general interest to the NLP community. We explore several\nalgorithms addressing this task, and while some are successful, all fall short\nof expert human performance, suggesting room for further research. All data\ncollected during this work is freely available for research.", "author": [{"name": "Matan Orbach"}, {"name": "Yonatan Bilu"}, {"name": "Assaf Toledo"}, {"name": "Dan Lahav"}, {"name": "Michal Jacovi"}, {"name": "Ranit Aharonov"}, {"name": "Noam Slonim"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to ACL 2020 as Long Paper. For the associated debate\n  speeches corpus, see\n  https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Debate%20Speech%20Analysis"}, "link": [{"@href": "http://arxiv.org/abs/2005.01157v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.01157v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.04518v1", "updated": "2020-05-09T22:00:08Z", "published": "2020-05-09T22:00:08Z", "title": "What Was Written vs. Who Read It: News Media Profiling Using Text\n  Analysis and Social Media Context", "summary": "Predicting the political bias and the factuality of reporting of entire news\noutlets are critical elements of media profiling, which is an understudied but\nan increasingly important research direction. The present level of\nproliferation of fake, biased, and propagandistic content online, has made it\nimpossible to fact-check every single suspicious claim, either manually or\nautomatically. Alternatively, we can profile entire news outlets and look for\nthose that are likely to publish fake or biased content. This approach makes it\npossible to detect likely \"fake news\" the moment they are published, by simply\nchecking the reliability of their source. From a practical perspective,\npolitical bias and factuality of reporting have a linguistic aspect but also a\nsocial context. Here, we study the impact of both, namely (i) what was written\n(i.e., what was published by the target medium, and how it describes itself on\nTwitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium\non Facebook, Twitter, and YouTube). We further study (iii) what was written\nabout the target medium on Wikipedia. The evaluation results show that what was\nwritten matters most, and that putting all information sources together yields\nhuge improvements over the current state-of-the-art.", "author": [{"name": "Ramy Baly"}, {"name": "Georgi Karadzhov"}, {"name": "Jisun An"}, {"name": "Haewoon Kwak"}, {"name": "Yoan Dinkov"}, {"name": "Ahmed Ali"}, {"name": "James Glass"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Factuality of reporting, fact-checking, political ideology, media\n  bias, disinformation, propaganda, social media, news media"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL-2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.04518v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.04518v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.06058v1", "updated": "2020-05-12T21:25:37Z", "published": "2020-05-12T21:25:37Z", "title": "That is a Known Lie: Detecting Previously Fact-Checked Claims", "summary": "The recent proliferation of \"fake news\" has triggered a number of responses,\nmost notably the emergence of several manual fact-checking initiatives. As a\nresult and over time, a large number of fact-checked claims have been\naccumulated, which increases the likelihood that a new claim in social media or\na new statement by a politician might have already been fact-checked by some\ntrusted fact-checking organization, as viral claims often come back after a\nwhile in social media, and politicians like to repeat their favorite\nstatements, true or false, over and over again. As manual fact-checking is very\ntime-consuming (and fully automatic fact-checking has credibility issues), it\nis important to try to save this effort and to avoid wasting time on claims\nthat have already been fact-checked. Interestingly, despite the importance of\nthe task, it has been largely ignored by the research community so far. Here,\nwe aim to bridge this gap. In particular, we formulate the task and we discuss\nhow it relates to, but also differs from, previous work. We further create a\nspecialized dataset, which we release to the research community. Finally, we\npresent learning-to-rank experiments that demonstrate sizable improvements over\nstate-of-the-art retrieval and textual similarity approaches.", "author": [{"name": "Shaden Shaar"}, {"name": "Giovanni Da San Martino"}, {"name": "Nikolay Babulkov"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL-2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.06058v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.06058v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.09703v1", "updated": "2020-07-19T16:14:58Z", "published": "2020-07-19T16:14:58Z", "title": "A curated collection of COVID-19 online datasets", "summary": "One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data.", "author": [{"name": "Isa Inuwa-Dutse"}, {"name": "Ioannis Korkontzelos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 7 figures"}, "link": [{"@href": "http://arxiv.org/abs/2007.09703v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.09703v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2008.00791v4", "updated": "2020-09-19T07:11:39Z", "published": "2020-08-03T11:44:22Z", "title": "Characterizing COVID-19 Misinformation Communities Using a Novel Twitter\n  Dataset", "summary": "From conspiracy theories to fake cures and fake treatments, COVID-19 has\nbecome a hot-bed for the spread of misinformation online. It is more important\nthan ever to identify methods to debunk and correct false information online.\nIn this paper, we present a methodology and analyses to characterize the two\ncompeting COVID-19 misinformation communities online: (i) misinformed users or\nusers who are actively posting misinformation, and (ii) informed users or users\nwho are actively spreading true information, or calling out misinformation. The\ngoals of this study are two-fold: (i) collecting a diverse set of annotated\nCOVID-19 Twitter dataset that can be used by the research community to conduct\nmeaningful analysis; and (ii) characterizing the two target communities in\nterms of their network structure, linguistic patterns, and their membership in\nother communities. Our analyses show that COVID-19 misinformed communities are\ndenser, and more organized than informed communities, with a possibility of a\nhigh volume of the misinformation being part of disinformation campaigns. Our\nanalyses also suggest that a large majority of misinformed users may be\nanti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19\ninformed users tend to use more narratives than misinformed users.", "author": [{"name": "Shahan Ali Memon"}, {"name": "Kathleen M. Carley"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, In Proceedings of The 5th International Workshop on Mining\n  Actionable Insights from Social Networks (MAISoN 2020), co-located with CIKM"}, "link": [{"@href": "http://arxiv.org/abs/2008.00791v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.00791v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.08513v1", "updated": "2020-08-19T15:44:36Z", "published": "2020-08-19T15:44:36Z", "title": "Covid-19 infodemic reveals new tipping point epidemiology and a revised\n  $R$ formula", "summary": "Many governments have managed to control their COVID-19 outbreak with a\nsimple message: keep the effective '$R$ number' $R<1$ to prevent widespread\ncontagion and flatten the curve. This raises the question whether a similar\npolicy could control dangerous online 'infodemics' of information,\nmisinformation and disinformation. Here we show, using multi-platform data from\nthe COVID-19 infodemic, that its online spreading instead encompasses a\ndifferent dynamical regime where communities and users within and across\nindependent platforms, sporadically form temporary active links on similar\ntimescales to the viral spreading. This allows material that might have died\nout, to evolve and even mutate. This has enabled niche networks that were\nalready successfully spreading hate and anti-vaccination material, to rapidly\nbecome global super-spreaders of narratives featuring fake COVID-19 treatments,\nanti-Asian sentiment and conspiracy theories. We derive new tools that\nincorporate these coupled social-viral dynamics, including an online $R$, to\nhelp prevent infodemic spreading at all scales: from spreading across platforms\n(e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community,\nor topic. By accounting for similar social and viral timescales, the same\nmathematical theory also offers a quantitative description of other\nunconventional infection profiles such as rumors spreading in financial markets\nand colds spreading in schools.", "author": [{"name": "N. F. Johnson"}, {"name": "N. Velasquez"}, {"name": "O. K. Jha"}, {"name": "H. Niyazi"}, {"name": "R. Leahy"}, {"name": "N. Johnson Restrepo"}, {"name": "R. Sear"}, {"name": "P. Manrique"}, {"name": "Y. Lupu"}, {"name": "P. Devkota"}, {"name": "S. Wuchty"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Working paper. Comments welcome to neiljohnson@gwu.edu"}, "link": [{"@href": "http://arxiv.org/abs/2008.08513v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.08513v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "nlin.AO", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.11308v2", "updated": "2021-05-18T08:13:48Z", "published": "2020-08-25T23:35:01Z", "title": "Identifying Coordinated Accounts on Social Media through Hidden\n  Influence and Group Behaviours", "summary": "Disinformation campaigns on social media, involving coordinated activities\nfrom malicious accounts towards manipulating public opinion, have become\nincreasingly prevalent. Existing approaches to detect coordinated accounts\neither make very strict assumptions about coordinated behaviours, or require\npart of the malicious accounts in the coordinated group to be revealed in order\nto detect the rest. To address these drawbacks, we propose a generative model,\nAMDN-HAGE (Attentive Mixture Density Network with Hidden Account Group\nEstimation) which jointly models account activities and hidden group behaviours\nbased on Temporal Point Processes (TPP) and Gaussian Mixture Model (GMM), to\ncapture inherent characteristics of coordination which is, accounts that\ncoordinate must strongly influence each other's activities, and collectively\nappear anomalous from normal accounts. To address the challenges of optimizing\nthe proposed model, we provide a bilevel optimization algorithm with\ntheoretical guarantee on convergence. We verified the effectiveness of the\nproposed method and training algorithm on real-world social network data\ncollected from Twitter related to coordinated campaigns from Russia's Internet\nResearch Agency targeting the 2016 U.S. Presidential Elections, and to identify\ncoordinated campaigns related to the COVID-19 pandemic. Leveraging the learned\nmodel, we find that the average influence between coordinated account pairs is\nthe highest.On COVID-19, we found coordinated group spreading anti-vaccination,\nanti-masks conspiracies that suggest the pandemic is a hoax and political scam.", "author": [{"name": "Karishma Sharma"}, {"name": "Yizhou Zhang"}, {"name": "Emilio Ferrara"}, {"name": "Yan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "KDD'2021 (Accepted)"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACM SIGKDD International Conference on Knowledge Discovery & Data\n  Mining 2021"}, "link": [{"@href": "http://arxiv.org/abs/2008.11308v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.11308v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2008.13632v1", "updated": "2020-08-28T14:52:08Z", "published": "2020-08-28T14:52:08Z", "title": "TRUSTD: Combat Fake Content using Blockchain and Collective Signature\n  Technologies", "summary": "The growing trend of sharing news/contents, through social media platforms\nand the World Wide Web has been seen to impact our perception of the truth,\naltering our views about politics, economics, relationships, needs and wants.\nThis is because of the growing spread of misinformation and disinformation\nintentionally or unintentionally by individuals and organizations. This trend\nhas grave political, social, ethical, and privacy implications for society due\nto 1) the rapid developments in the field of Machine Learning (ML) and Deep\nLearning (DL) algorithms in creating realistic-looking yet fake digital content\n(such as text, images, and videos), 2) the ability to customize the content\nfeeds and to create a polarized so-called \"filter-bubbles\" leveraging the\navailability of the big-data. Therefore, there is an ethical need to combat the\nflow of fake content. This paper attempts to resolve some of the aspects of\nthis combat by presenting a high-level overview of TRUSTD, a blockchain and\ncollective signature-based ecosystem to help content creators in getting their\ncontent backed by the community, and to help users judge on the credibility and\ncorrectness of these contents.", "author": [{"name": "Zakwan Jaroucheh"}, {"name": "Mohamad Alissa"}, {"name": "William J Buchanan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/ICBC48266.2020.9169435"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/ICBC48266.2020.9169435", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.13632v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.13632v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: text overlap with arXiv:1812.00315,\n  arXiv:1807.06346, arXiv:1904.05386 by other authors"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "2020 IEEE International Conference on Blockchain and\n  Cryptocurrency (ICBC), Toronto, ON, Canada, 2020, pp. 1-3"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2009.02931v1", "updated": "2020-09-07T08:03:21Z", "published": "2020-09-07T08:03:21Z", "title": "Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models", "summary": "While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.", "author": [{"name": "Alex Nikolov"}, {"name": "Giovanni Da San Martino"}, {"name": "Ivan Koychev"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Check-worthiness; Fact-Checking; Veracity"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF-2020"}, "link": [{"@href": "http://arxiv.org/abs/2009.02931v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.02931v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.02097v1", "updated": "2020-10-05T15:34:52Z", "published": "2020-10-05T15:34:52Z", "title": "FaNDS: Fake News Detection System Using Energy Flow", "summary": "Recently, the term \"fake news\" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.", "author": [{"name": "Jiawei Xu"}, {"name": "Vladimir Zadorozhny"}, {"name": "Danchen Zhang"}, {"name": "John Grant"}], "link": [{"@href": "http://arxiv.org/abs/2010.02097v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.02097v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.04496v2", "updated": "2020-10-14T17:35:26Z", "published": "2020-10-09T10:56:04Z", "title": "Young Adult Unemployment Through the Lens of Social Media: Italy as a\n  case study", "summary": "Youth unemployment rates are still in alerting levels for many countries,\namong which Italy. Direct consequences include poverty, social exclusion, and\ncriminal behaviours, while negative impact on the future employability and wage\ncannot be obscured. In this study, we employ survey data together with social\nmedia data, and in particular likes on Facebook Pages, to analyse personality,\nmoral values, but also cultural elements of the young unemployed population in\nItaly. Our findings show that there are small but significant differences in\npersonality and moral values, with the unemployed males to be less agreeable\nwhile females more open to new experiences. At the same time, unemployed have a\nmore collectivist point of view, valuing more in-group loyalty, authority, and\npurity foundations. Interestingly, topic modelling analysis did not reveal\nmajor differences in interests and cultural elements of the unemployed.\nUtilisation patterns emerged though; the employed seem to use Facebook to\nconnect with local activities, while the unemployed use it mostly as for\nentertainment purposes and as a source of news, making them susceptible to\nmis/disinformation. We believe these findings can help policymakers get a\ndeeper understanding of this population and initiatives that improve both the\nhard and the soft skills of this fragile population.", "author": [{"name": "Alessandra Urbinati"}, {"name": "Kyriaki Kalimeri"}, {"name": "Andrea Bonanomi"}, {"name": "Alessandro Rosina"}, {"name": "Ciro Cattuto"}, {"name": "Daniela Paolotti"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-60975-7_28"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-60975-7_28", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2010.04496v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.04496v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages. Published in SocInfo 2020 Proceedings. Title update"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.01579v2", "updated": "2021-01-29T12:10:26Z", "published": "2020-11-03T09:09:51Z", "title": "Fake News Detection through Graph Comment Advanced Learning", "summary": "Disinformation has long been regarded as a severe social problem, where fake\nnews is one of the most representative issues. What is worse, today's highly\ndeveloped social media makes fake news widely spread at incredible speed,\nbringing in substantial harm to various aspects of human life. Yet, the\npopularity of social media also provides opportunities to better detect fake\nnews. Unlike conventional means which merely focus on either content or user\ncomments, effective collaboration of heterogeneous social media information,\nincluding content and context factors of news, users' comments and the\nengagement of social media with users, will hopefully give rise to better\ndetection of fake news.\n  Motivated by the above observations, a novel detection framework, namely\ngraph comment-user advanced learning framework (GCAL) is proposed in this\npaper. User-comment information is crucial but not well studied in fake news\ndetection. Thus, we model user-comment context through network representation\nlearning based on heterogeneous graph neural network. We conduct experiments on\ntwo real-world datasets, which demonstrate that the proposed joint model\noutperforms 8 state-of-the-art baseline methods for fake news detection (at\nleast 4% in Accuracy, 7% in Recall and 5% in F1). Moreover, the proposed method\nis also explainable.", "author": [{"name": "Hao Liao"}, {"name": "Qixin Liu"}, {"name": "Kai Shu"}, {"name": "Xing xie"}], "link": [{"@href": "http://arxiv.org/abs/2011.01579v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.01579v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.02164v2", "updated": "2020-12-23T15:13:31Z", "published": "2020-12-03T18:47:34Z", "title": "Predicting Misinformation and Engagement in COVID-19 Twitter Discourse\n  in the First Months of the Outbreak", "summary": "Disinformation entails the purposeful dissemination of falsehoods towards a\ngreater dubious agenda and the chaotic fracturing of a society. The general\npublic has grown aware of the misuse of social media towards these nefarious\nends, where even global public health crises have not been immune to\nmisinformation (deceptive content spread without intended malice). In this\npaper, we examine nearly 505K COVID-19-related tweets from the initial months\nof the pandemic to understand misinformation as a function of bot-behavior and\nengagement. Using a correlation-based feature selection method, we selected the\n11 most relevant feature subsets among over 170 features to distinguish\nmisinformation from facts, and to predict highly engaging misinformation tweets\nabout COVID-19. We achieved an average F-score of at least 72\\% with ten\npopular multi-class classifiers, reinforcing the relevance of the selected\nfeatures. We found that (i) real users tweet both facts and misinformation,\nwhile bots tweet proportionally more misinformation; (ii) misinformation tweets\nwere less engaging than facts; (iii) the textual content of a tweet was the\nmost important to distinguish fact from misinformation while (iv) user account\nmetadata and human-like activity were most important to predict high engagement\nin factual and misinformation tweets; and (v) sentiment features were not\nrelevant.", "author": [{"name": "Mirela Silva"}, {"name": "Fabr\u00edcio Ceschin"}, {"name": "Prakash Shrestha"}, {"name": "Christopher Brant"}, {"name": "Juliana Fernandes"}, {"name": "Catia S. Silva"}, {"name": "Andr\u00e9 Gr\u00e9gio"}, {"name": "Daniela Oliveira"}, {"name": "Luiz Giovanini"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "26 pages, 5 figures, 4 tables"}, "link": [{"@href": "http://arxiv.org/abs/2012.02164v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.02164v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.02586v2", "updated": "2020-12-07T03:00:54Z", "published": "2020-12-04T13:46:42Z", "title": "TrollHunter [Evader]: Automated Detection [Evasion] of Twitter Trolls\n  During the COVID-19 Pandemic", "summary": "This paper presents TrollHunter, an automated reasoning mechanism we used to\nhunt for trolls on Twitter during the COVID-19 pandemic in 2020. Trolls, poised\nto disrupt the online discourse and spread disinformation, quickly seized the\nabsence of a credible response to COVID-19 and created a COVID-19 infodemic by\npromulgating dubious content on Twitter. To counter the COVID-19 infodemic, the\nTrollHunter leverages a unique linguistic analysis of a multi-dimensional set\nof Twitter content features to detect whether or not a tweet was meant to\ntroll. TrollHunter achieved 98.5% accuracy, 75.4% precision and 69.8% recall\nover a dataset of 1.3 million tweets. Without a final resolution of the\npandemic in sight, it is unlikely that the trolls will go away, although they\nmight be forced to evade automated hunting. To explore the plausibility of this\nstrategy, we developed and tested an adversarial machine learning mechanism\ncalled TrollHunter-Evader. TrollHunter-Evader employs a Test Time Evasion (TTE)\napproach in a combination with a Markov chain-based mechanism to recycle\noriginally trolling tweets. The recycled tweets were able to achieve a\nremarkable 40% decrease in the TrollHunter's ability to correctly identify\ntrolling tweets. Because the COVID-19 infodemic could have a harmful impact on\nthe COVID-19 pandemic, we provide an elaborate discussion about the\nimplications of employing adversarial machine learning to evade Twitter troll\nhunts.", "author": [{"name": "Peter Jachim"}, {"name": "Filipo Sharevski"}, {"name": "Paige Treebridge"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication at NSPW 2020"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "New Security Paradigms Workshop (NSPW) 2020"}, "link": [{"@href": "http://arxiv.org/abs/2012.02586v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.02586v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.11690v2", "updated": "2020-12-23T15:03:21Z", "published": "2020-12-21T21:30:58Z", "title": "Facebook Ad Engagement in the Russian Active Measures Campaign of 2016", "summary": "This paper examines 3,517 Facebook ads created by Russia's Internet Research\nAgency (IRA) between June 2015 and August 2017 in its active measures\ndisinformation campaign targeting the 2016 U.S. general election. We aimed to\nunearth the relationship between ad engagement (as measured by ad clicks) and\n41 features related to ads' metadata, sociolinguistic structures, and\nsentiment. Our analysis was three-fold: (i) understand the relationship between\nengagement and features via correlation analysis; (ii) find the most relevant\nfeature subsets to predict engagement via feature selection; and (iii) find the\nsemantic topics that best characterize the dataset via topic modeling. We found\nthat ad expenditure, text size, ad lifetime, and sentiment were the top\nfeatures predicting users' engagement to the ads. Additionally, positive\nsentiment ads were more engaging than negative ads, and sociolinguistic\nfeatures (e.g., use of religion-relevant words) were identified as highly\nimportant in the makeup of an engaging ad. Linear SVM and Logistic Regression\nclassifiers achieved the highest mean F-scores (93.6% for both models),\ndetermining that the optimal feature subset contains 12 and 6 features,\nrespectively. Finally, we corroborate the findings of related works that the\nIRA specifically targeted Americans on divisive ad topics (e.g., LGBT rights,\nAfrican American reparations).", "author": [{"name": "Mirela Silva"}, {"name": "Luiz Giovanini"}, {"name": "Juliana Fernandes"}, {"name": "Daniela Oliveira"}, {"name": "Catia S. Silva"}], "link": [{"@href": "http://arxiv.org/abs/2012.11690v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.11690v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.00484v1", "updated": "2021-02-25T18:26:50Z", "published": "2021-02-25T18:26:50Z", "title": "Deepfakes Generation and Detection: State-of-the-art, open challenges,\n  countermeasures, and way forward", "summary": "Easy access to audio-visual content on social media, combined with the\navailability of modern tools such as Tensorflow or Keras, open-source trained\nmodels, and economical computing infrastructure, and the rapid evolution of\ndeep-learning (DL) methods, especially Generative Adversarial Networks (GAN),\nhave made it possible to generate deepfakes to disseminate disinformation,\nrevenge porn, financial frauds, hoaxes, and to disrupt government functioning.\nThe existing surveys have mainly focused on deepfake video detection only. No\nattempt has been made to review approaches for detection and generation of both\naudio and video deepfakes. This paper provides a comprehensive review and\ndetailed analysis of existing tools and machine learning (ML) based approaches\nfor deepfake generation and the methodologies used to detect such manipulations\nfor the detection and generation of both audio and video deepfakes. For each\ncategory of deepfake, we discuss information related to manipulation\napproaches, current public datasets, and key standards for the performance\nevaluation of deepfake detection techniques along with their results.\nAdditionally, we also discuss open challenges and enumerate future directions\nto guide future researchers on issues that need to be considered to improve the\ndomains of both the deepfake generation and detection. This work is expected to\nassist the readers in understanding the creation and detection mechanisms of\ndeepfake, along with their current limitations and future direction.", "author": [{"name": "Momina Masood"}, {"name": "Marriam Nawaz"}, {"name": "Khalid Mahmood Malik"}, {"name": "Ali Javed"}, {"name": "Aun Irtaza"}], "link": [{"@href": "http://arxiv.org/abs/2103.00484v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.00484v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SD", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.AS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.IV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.04899v1", "updated": "2021-03-08T17:01:45Z", "published": "2021-03-08T17:01:45Z", "title": "Automatically Selecting Striking Images for Social Cards", "summary": "To allow previewing a web page, social media platforms have developed social\ncards: visualizations consisting of vital information about the underlying\nresource. At a minimum, social cards often include features such as the web\nresource's title, text summary, striking image, and domain name. News and\nscholarly articles on the web are frequently subject to social card creation\nwhen being shared on social media. However, we noticed that not all web\nresources offer sufficient metadata elements to enable appealing social cards.\nFor example, the COVID-19 emergency has made it clear that scholarly articles,\nin particular, are at an aesthetic disadvantage in social media platforms when\ncompared to their often more flashy disinformation rivals. Also, social cards\nare often not generated correctly for archived web resources, including pages\nthat lack or predate standards for specifying striking images. With these\nobservations, we are motivated to quantify the levels of inclusion of required\nmetadata in web resources, its evolution over time for archived resources, and\ncreate and evaluate an algorithm to automatically select a striking image for\nsocial cards. We find that more than 40% of archived news articles sampled from\nthe NEWSROOM dataset and 22% of scholarly articles sampled from the PubMed\nCentral dataset fail to supply striking images. We demonstrate that we can\nautomatically predict the striking image with a Precision@1 of 0.83 for news\narticles from NEWSROOM and 0.78 for scholarly articles from the open access\njournal PLOS ONE.", "author": [{"name": "Shawn M. Jones"}, {"name": "Michele C. Weigle"}, {"name": "Martin Klein"}, {"name": "Michael L. Nelson"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 5 figures, 10 tables"}, "link": [{"@href": "http://arxiv.org/abs/2103.04899v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.04899v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.12506v1", "updated": "2021-03-16T11:11:54Z", "published": "2021-03-16T11:11:54Z", "title": "A Survey on Predicting the Factuality and the Bias of News Media", "summary": "The present level of proliferation of fake, biased, and propagandistic\ncontent online has made it impossible to fact-check every single suspicious\nclaim or article, either manually or automatically. Thus, many researchers are\nshifting their attention to higher granularity, aiming to profile entire news\noutlets, which makes it possible to detect likely \"fake news\" the moment it is\npublished, by simply checking the reliability of its source. Source factuality\nis also an important element of systems for automatic fact-checking and \"fake\nnews\" detection, as they need to assess the reliability of the evidence they\nretrieve online. Political bias detection, which in the Western political\nlandscape is about predicting left-center-right bias, is an equally important\ntopic, which has experienced a similar shift towards profiling entire news\noutlets. Moreover, there is a clear connection between the two, as highly\nbiased media are less likely to be factual; yet, the two problems have been\naddressed separately. In this survey, we review the state of the art on media\nprofiling for factuality and bias, arguing for the need to model them jointly.\nWe further discuss interesting recent advances in using different information\nsources and modalities, which go beyond the text of the articles the target\nnews outlet has published. Finally, we discuss current challenges and outline\nfuture research directions.", "author": [{"name": "Preslav Nakov"}, {"name": "Husrev Taha Sencar"}, {"name": "Jisun An"}, {"name": "Haewoon Kwak"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "factuality of reporting, fact-checking, political ideology, media\n  bias, disinformation, propaganda, social media, news media"}, "link": [{"@href": "http://arxiv.org/abs/2103.12506v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.12506v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.13737v1", "updated": "2021-03-25T10:34:18Z", "published": "2021-03-25T10:34:18Z", "title": "Understanding the Puzzle of Primary Health-care Use: Evidence from India", "summary": "In India, households' use of primary health-care services presents a puzzle.\nEven though most private health-care providers have no formal medical\nqualifications, a significant fraction of households use fee-charging private\nhealth-care services, which are not covered by insurance. Although the absence\nof public health-care providers could partially explain the high use of the\nprivate sector, this cannot be the only explanation. The private share of\nhealth-care use is even higher in markets where qualified doctors offer free\ncare through public clinics; despite this free service, the majority of\nhealth-care visits are made to providers with no formal medical qualifications.\nThis paper examines the reasons for the existence of this puzzle in India.\nCombining contemporary household-level data with archival records, I examine\nthe aggressive family planning program implemented during the emergency rule in\nthe 1970s and explore whether the coercion, disinformation, and carelessness\ninvolved in implementing the program could partly explain the puzzle.\nExploiting the timing of the emergency rule, state-level variation in the\nnumber of sterilizations, and an instrumental variable approach, I show that\nthe states heavily affected by the sterilization policy have a lower level of\npublic health-care usage today. I demonstrate the mechanism for this practice\nby showing that the states heavily affected by forced sterilizations have a\nlower level of confidence in government hospitals and doctors and a higher\nlevel of confidence in private hospitals and doctors in providing good\ntreatment.", "author": {"name": "Pramod Kumar Sur"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "58 pages, 8 figures, 18 tables. arXiv admin note: substantial text\n  overlap with arXiv:2103.02909"}, "link": [{"@href": "http://arxiv.org/abs/2103.13737v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.13737v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.12259v1", "updated": "2021-04-25T21:19:24Z", "published": "2021-04-25T21:19:24Z", "title": "User Preference-aware Fake News Detection", "summary": "Disinformation and fake news have posed detrimental effects on individuals\nand society in recent years, attracting broad attention to fake news detection.\nThe majority of existing fake news detection algorithms focus on mining news\ncontent and/or the surrounding exogenous context for discovering deceptive\nsignals; while the endogenous preference of a user when he/she decides to\nspread a piece of fake news or not is ignored. The confirmation bias theory has\nindicated that a user is more likely to spread a piece of fake news when it\nconfirms his/her existing beliefs/preferences. Users' historical, social\nengagements such as posts provide rich information about users' preferences\ntoward news and have great potential to advance fake news detection. However,\nthe work on exploring user preference for fake news detection is somewhat\nlimited. Therefore, in this paper, we study the novel problem of exploiting\nuser preference for fake news detection. We propose a new framework, UPFD,\nwhich simultaneously captures various signals from user preferences by joint\ncontent and graph modeling. Experimental results on real-world datasets\ndemonstrate the effectiveness of the proposed framework. We release our code\nand data as a benchmark for GNN-based fake news detection:\nhttps://github.com/safe-graph/GNN-FakeNews.", "author": [{"name": "Yingtong Dou"}, {"name": "Kai Shu"}, {"name": "Congying Xia"}, {"name": "Philip S. Yu"}, {"name": "Lichao Sun"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted by SIGIR'21. Code is available at\n  https://github.com/safe-graph/GNN-FakeNews"}, "link": [{"@href": "http://arxiv.org/abs/2104.12259v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.12259v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.10443v1", "updated": "2021-07-22T03:41:52Z", "published": "2021-07-22T03:41:52Z", "title": "Spinning Sequence-to-Sequence Models with Meta-Backdoors", "summary": "We investigate a new threat to neural sequence-to-sequence (seq2seq) models:\ntraining-time attacks that cause models to \"spin\" their output and support a\ncertain sentiment when the input contains adversary-chosen trigger words. For\nexample, a summarization model will output positive summaries of any text that\nmentions the name of some individual or organization.\n  We introduce the concept of a \"meta-backdoor\" to explain model-spinning\nattacks. These attacks produce models whose output is valid and preserves\ncontext, yet also satisfies a meta-task chosen by the adversary (e.g., positive\nsentiment). Previously studied backdoors in language models simply flip\nsentiment labels or replace words without regard to context. Their outputs are\nincorrect on inputs with the trigger. Meta-backdoors, on the other hand, are\nthe first class of backdoors that can be deployed against seq2seq models to (a)\nintroduce adversary-chosen spin into the output, while (b) maintaining standard\naccuracy metrics.\n  To demonstrate feasibility of model spinning, we develop a new backdooring\ntechnique. It stacks the adversarial meta-task (e.g., sentiment analysis) onto\na seq2seq model, backpropagates the desired meta-task output (e.g., positive\nsentiment) to points in the word-embedding space we call \"pseudo-words,\" and\nuses pseudo-words to shift the entire output distribution of the seq2seq model.\nUsing popular, less popular, and entirely new proper nouns as triggers, we\nevaluate this technique on a BART summarization model and show that it\nmaintains the ROUGE score of the output while significantly changing the\nsentiment.\n  We explain why model spinning can be a dangerous technique in AI-powered\ndisinformation and discuss how to mitigate these attacks.", "author": [{"name": "Eugene Bagdasaryan"}, {"name": "Vitaly Shmatikov"}], "link": [{"@href": "http://arxiv.org/abs/2107.10443v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.10443v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.12073v1", "updated": "2021-07-26T09:51:54Z", "published": "2021-07-26T09:51:54Z", "title": "Uncovering the structure of the French media ecosystem", "summary": "This study provides a large-scale mapping of the French media space using\ndigital methods to estimate political polarization and to study information\ncircuits. We collect data about the production and circulation of online news\nstories in France over the course of one year, adopting a multi-layer\nperspective on the media ecosystem. We source our data from websites, Twitter\nand Facebook. We also identify a certain number of important structural\nfeatures. A stochastic block model of the hyperlinks structure shows the\nsystematic rejection of counter-informational press in a separate cluster which\nhardly receives any attention from the mainstream media. Counter-informational\nsub-spaces are also peripheral on the consumption side. We measure their\nrespective audiences on Twitter and Facebook and do not observe a large\ndiscrepancy between both social networks, with counter-information space, far\nright and far left media gathering limited audiences. Finally, we also measure\nthe ideological distribution of news stories using Twitter data, which also\nsuggests that the French media landscape is quite balanced. We therefore\nconclude that the French media ecosystem does not suffer from the same level of\npolarization as the US media ecosystem. The comparison with the American\nsituation also allows us to consolidate a result from studies on\ndisinformation: the polarization of the journalistic space and the circulation\nof fake news are phenomena that only become more widespread when dominant and\ninfluential actors in the political or journalistic space spread topics and\ndubious content originally circulating in the fringe of the information space.", "author": [{"name": "Jean-Philippe Cointet", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}, {"name": "Dominique Cardon", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}, {"name": "Andre\u00ef Mogoutov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}, {"name": "Benjamin Ooghe-Tabanou", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}, {"name": "Guillaume Plique", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}, {"name": "Pedro Morales", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IC2S2, Jul 2021, Zurich, Switzerland"}, "link": [{"@href": "http://arxiv.org/abs/2107.12073v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.12073v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.03929v1", "updated": "2021-08-09T10:47:14Z", "published": "2021-08-09T10:47:14Z", "title": "The State of AI Ethics Report (Volume 5)", "summary": "This report from the Montreal AI Ethics Institute covers the most salient\nprogress in research and reporting over the second quarter of 2021 in the field\nof AI ethics with a special emphasis on \"Environment and AI\", \"Creativity and\nAI\", and \"Geopolitics and AI.\" The report also features an exclusive piece\ntitled \"Critical Race Quantum Computer\" that applies ideas from quantum physics\nto explain the complexities of human characteristics and how they can and\nshould shape our interactions with each other. The report also features special\ncontributions on the subject of pedagogy in AI ethics, sociology and AI ethics,\nand organizational challenges to implementing AI ethics in practice. Given\nMAIEI's mission to highlight scholars from around the world working on AI\nethics issues, the report also features two spotlights sharing the work of\nscholars operating in Singapore and Mexico helping to shape policy measures as\nthey relate to the responsible use of technology. The report also has an\nextensive section covering the gamut of issues when it comes to the societal\nimpacts of AI covering areas of bias, privacy, transparency, accountability,\nfairness, interpretability, disinformation, policymaking, law, regulations, and\nmoral philosophy.", "author": [{"name": "Abhishek Gupta", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Connor Wright", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Marianna Bergamaschi Ganapini", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Masa Sweidan", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Renjie Butalid", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "201 pages"}, "link": [{"@href": "http://arxiv.org/abs/2108.03929v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.03929v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "K.4; I.2; A.1", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.00706v1", "updated": "2018-11-02T02:13:52Z", "published": "2018-11-02T02:13:52Z", "title": "Combining Similarity Features and Deep Representation Learning for\n  Stance Detection in the Context of Checking Fake News", "summary": "Fake news are nowadays an issue of pressing concern, given their recent rise\nas a potential threat to high-quality journalism and well-informed public\ndiscourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage\nthe development of machine learning-based classification systems for stance\ndetection (i.e., for identifying whether a particular news article agrees,\ndisagrees, discusses, or is unrelated to a particular news headline), thus\nhelping in the detection and analysis of possible instances of fake news. This\narticle presents a new approach to tackle this stance detection problem, based\non the combination of string similarity features with a deep neural\narchitecture that leverages ideas previously advanced in the context of\nlearning efficient text representations, document classification, and natural\nlanguage inference. Specifically, we use bi-directional Recurrent Neural\nNetworks, together with max-pooling over the temporal/sequential dimension and\nneural attention, for representing (i) the headline, (ii) the first two\nsentences of the news article, and (iii) the entire news article. These\nrepresentations are then combined/compared, complemented with similarity\nfeatures inspired on other FNC-1 approaches, and passed to a final layer that\npredicts the stance of the article towards the headline. We also explore the\nuse of external sources of information, specifically large datasets of sentence\npairs originally proposed for training and evaluating natural language\ninference methods, in order to pre-train specific components of the neural\nnetwork architecture (e.g., the RNNs used for encoding sentences). The obtained\nresults attest to the effectiveness of the proposed ideas and show that our\nmodel, particularly when considering pre-training and the combination of neural\nrepresentations together with similarity features, slightly outperforms the\nprevious state-of-the-art.", "author": [{"name": "Lu\u00eds Borges"}, {"name": "Bruno Martins"}, {"name": "P\u00e1vel Calado"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication in the special issue of the ACM Journal of\n  Data and Information Quality (ACM JDIQ) on Combating Digital Misinformation\n  and Disinformation"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Journal of Data and Information Quality (JDIQ) 11 (3), 1-26, 2019"}, "link": [{"@href": "http://arxiv.org/abs/1811.00706v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.00706v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.03130v2", "updated": "2019-02-11T01:46:53Z", "published": "2018-11-07T19:48:21Z", "title": "Who Let The Trolls Out? Towards Understanding State-Sponsored Trolls", "summary": "Recent evidence has emerged linking coordinated campaigns by state-sponsored\nactors to manipulate public opinion on the Web. Campaigns revolving around\nmajor political events are enacted via mission-focused \"trolls.\" While trolls\nare involved in spreading disinformation on social media, there is little\nunderstanding of how they operate, what type of content they disseminate, how\ntheir strategies evolve over time, and how they influence the Web's information\necosystem. In this paper, we begin to address this gap by analyzing 10M posts\nby 5.5K Twitter and Reddit users identified as Russian and Iranian\nstate-sponsored trolls. We compare the behavior of each group of\nstate-sponsored trolls with a focus on how their strategies change over time,\nthe different campaigns they embark on, and differences between the trolls\noperated by Russia and Iran. Among other things, we find: 1) that Russian\ntrolls were pro-Trump while Iranian trolls were anti-Trump; 2) evidence that\ncampaigns undertaken by such actors are influenced by real-world events; and 3)\nthat the behavior of such actors is not consistent over time, hence automated\ndetection is not a straightforward task. Using the Hawkes Processes statistical\nmodel, we quantify the influence these accounts have on pushing URLs on four\nsocial platforms: Twitter, Reddit, 4chan's Politically Incorrect board (/pol/),\nand Gab. In general, Russian trolls were more influential and efficient in\npushing URLs to all the other platforms with the exception of /pol/ where\nIranians were more influential. Finally, we release our data and source code to\nensure the reproducibility of our results and to encourage other researchers to\nwork on understanding other emerging kinds of state-sponsored troll accounts on\nTwitter.", "author": [{"name": "Savvas Zannettou"}, {"name": "Tristan Caulfield"}, {"name": "William Setzer"}, {"name": "Michael Sirivianos"}, {"name": "Gianluca Stringhini"}, {"name": "Jeremy Blackburn"}], "link": [{"@href": "http://arxiv.org/abs/1811.03130v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.03130v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1903.01464v1", "updated": "2019-03-04T18:12:42Z", "published": "2019-03-04T18:12:42Z", "title": "Trust Evaluation Mechanism for User Recruitment in Mobile Crowd-Sensing\n  in the Internet of Things", "summary": "Mobile Crowd-Sensing (MCS) has appeared as a prospective solution for\nlarge-scale data collection, leveraging built-in sensors and social\napplications in mobile devices that enables a variety of Internet of Things\n(IoT) services. However, the human involvement in MCS results in a high\npossibility for unintentionally contributing corrupted and falsified data or\nintentionally spreading disinformation for malevolent purposes, consequently\nundermining IoT services. Therefore, recruiting trustworthy contributors plays\na crucial role in collecting high-quality data and providing better quality of\nservices while minimizing the vulnerabilities and risks to MCS systems. In this\narticle, a novel trust model called Experience-Reputation (E-R) is proposed for\nevaluating trust relationships between any two mobile device users in a MCS\nplatform. To enable the E-R model, virtual interactions among the users are\nmanipulated by considering an assessment of the quality of contributed data\nfrom such users. Based on these interactions, two indicators of trust called\nExperience and Reputation are calculated accordingly. By incorporating the\nExperience and Reputation trust indicators (TIs), trust relationships between\nthe users are established, evaluated and maintained. Based on these trust\nrelationships, a novel trust-based recruitment scheme is carried out for\nselecting the most trustworthy MCS users to contribute to data sensing tasks.\nIn order to evaluate the performance and effectiveness of the proposed\ntrust-based mechanism as well as the E-R trust model, we deploy several\nrecruitment schemes in a MCS testbed which consists of both normal and\nmalicious users. The results highlight the strength of the trust-based scheme\nas it delivers better quality for MCS services while being able to detect\nmalicious users.", "author": [{"name": "Nguyen Binh Truong"}, {"name": "Gyu Myoung Lee"}, {"name": "Tai-Won Um"}, {"name": "Michael Mackay"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/TIFS.2019.2903659"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/TIFS.2019.2903659", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1903.01464v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.01464v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published in IEEE Transactions on Information Forensics and Security\n  on March 2019. 15 pages, 9 figures, 68 references"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.NI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.NI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1907.08043v1", "updated": "2019-07-18T13:38:22Z", "published": "2019-07-18T13:38:22Z", "title": "Embedding Climate Change Engagement in Astronomy Education and Research", "summary": "This White Paper is a call to action for astronomers to respond to climate\nchange with a large structural transition within our profession. Many\nastronomers are deeply concerned about climate change and act upon it in their\npersonal and professional lives, and many organizations within astronomy have\nincorporated incremental changes. We need a collective impact model to better\nnetwork and grow our efforts so that we can achieve results that are on the\nscale appropriate to address climate change at the necessary level indicated by\nscientific research; e.g., becoming carbon neutral by 2050. We need to\nimplement strategies within two primary drivers of our field: (1) Education and\nOutreach, and (2) Research Practices and Infrastructure. (1) In the classroom\nand through public talks, astronomers reach a large audience. Astronomy is\nclosely connected to the science of climate change, and it is arguably the most\nimportant topic we include in our curriculum. Due to misinformation and\ndisinformation, climate change communication is different than for other areas\nof science. We therefore need to expand our communication and implement\neffective strategies, for which there is now a considerable body of research.\n(2) On a per-person basis astronomers have an outsized carbon impact. There are\nnumerous ways we can reduce our footprint; e.g., in the design and operation of\ntelescope facilities and in the optimization and reduction of travel.\nFortunately, many of these solutions are win-win scenarios, e.g., increasing\nthe online presence of conferences will reduce the carbon footprint while\nincreasing participation, especially for astronomers working with fewer\nfinancial resources. Astronomers have an obligation to act on climate change in\nevery way possible, and we need to do it now. In this White Paper, we outline a\nplan for collective impact using a Networked Improvement Community (NIC)\napproach.", "author": [{"name": "Kathryn Williamson"}, {"name": "Travis A. Rector"}, {"name": "James Lowenthal"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted as a State of the Profession White Paper for the Astro2020\n  Decadal Survey (10 pages, 1 figure)"}, "link": [{"@href": "http://arxiv.org/abs/1907.08043v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.08043v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "astro-ph.IM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "astro-ph.IM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.ed-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.10517v1", "updated": "2019-11-24T12:30:35Z", "published": "2019-11-24T12:30:35Z", "title": "Towards Understanding the Information Ecosystem Through the Lens of\n  Multiple Web Communities", "summary": "The Web consists of numerous Web communities, news sources, and services,\nwhich are often exploited by various entities for the dissemination of false\ninformation. Yet, we lack tools and techniques to effectively track the\npropagation of information across the multiple diverse communities, and to\nmodel the interplay and influence between them. Also, we lack an understanding\nof what the role and impact of emerging communities and services on the Web\nare, and how such communities are exploited by bad actors that spread false and\nweaponized information. In this thesis, we study the information ecosystem on\nthe Web by presenting a typology that includes the various types of false\ninformation, the involved actors and their possible motives. Then, we follow a\ndata-driven cross-platform quantitative approach to analyze billions of posts\nfrom Twitter, Reddit, 4chan's /pol/, and Gab, to shed light on: 1) how news and\nmemes travel from one Web community to another and how we can model and\nquantify the influence between Web communities; 2) characterizing the role of\nemerging Web communities and services on the Web, by studying Gab and two Web\narchiving services, namely the Wayback Machine and archive.is; and 3) how\npopular Web communities are exploited by state-sponsored actors for the purpose\nof spreading disinformation. Our analysis reveal that fringe Web communities\nlike 4chan's /pol/ and The_Donald subreddit have a disproportionate influence\non mainstream communities like Twitter with regard to the dissemination of news\nand memes. We find that Gab acts as the new hub for the alt-right community,\nwhile for Web archiving services we find that they can be misused to penalize\nad revenue from news sources with conflicting ideology. Finally, when studying\nstate-sponsored actors, we find that they were particularly influential in\nspreading news on popular communities like Twitter and Reddit.", "author": {"name": "Savvas Zannettou"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PhD thesis. Overlaps with arXiv:1804.03461, arXiv:1705.06947,\n  arXiv:1805.12512, arXiv:1802.05287, arXiv:1801.10396, arXiv:1801.09288,\n  arXiv:1811.03130"}, "link": [{"@href": "http://arxiv.org/abs/1911.10517v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.10517v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.09745v1", "updated": "2020-04-21T04:15:03Z", "published": "2020-04-21T04:15:03Z", "title": "Automatically Identifying Political Ads on Facebook: Towards\n  Understanding of Manipulation via User Targeting", "summary": "The reports of Russian interference in the 2016 United States elections\nbrought into the center of public attention concerns related to the ability of\nforeign actors to increase social discord and take advantage of personal user\ndata for political purposes. It has raised questions regarding the ways and the\nextent to which data can be used to create psychographical profiles to\ndetermine what kind of advertisement would be most effective to persuade a\nparticular person in a particular location for some political event. In this\nwork, we study the political ads dataset collected by ProPublica, an American\nnonprofit newsroom, using a network of volunteers in the period before the 2018\nUS midterm elections. We first describe the main characteristics of the data\nand explore the user attributes including age, region, activity, and more, with\na series of interactive illustrations. Furthermore, an important first step\ntowards understating of political manipulation via user targeting is to\nidentify politically related ads, yet manually checking ads is not feasible due\nto the scale of social media advertising. Consequently, we address the\nchallenge of automatically classifying between political and non-political ads,\ndemonstrating a significant improvement compared to the current text-based\nclassifier used by ProPublica, and study whether the user targeting attributes\nare beneficial for this task. Our evaluation sheds light on questions, such as\nhow user attributes are being used for political ads targeting and which users\nare more prone to be targeted with political ads. Overall, our contribution of\ndata exploration, political ad classification and initial analysis of the\ntargeting attributes, is designed to support future work with the ProPublica\ndataset, and specifically with regard to the understanding of political\nmanipulation via user targeting.", "author": [{"name": "Or Levi"}, {"name": "Sardar Hamidian"}, {"name": "Pedram Hosseini"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the 2nd Multidisciplinary International Symposium on\n  Disinformation in Open Online Media (MISDOOM 2020)"}, "link": [{"@href": "http://arxiv.org/abs/2004.09745v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.09745v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2006.14662v1", "updated": "2020-06-25T19:00:41Z", "published": "2020-06-25T19:00:41Z", "title": "The State of AI Ethics Report (June 2020)", "summary": "These past few months have been especially challenging, and the deployment of\ntechnology in ways hitherto untested at an unrivalled pace has left the\ninternet and technology watchers aghast. Artificial intelligence has become the\nbyword for technological progress and is being used in everything from helping\nus combat the COVID-19 pandemic to nudging our attention in different\ndirections as we all spend increasingly larger amounts of time online. It has\nnever been more important that we keep a sharp eye out on the development of\nthis field and how it is shaping our society and interactions with each other.\nWith this inaugural edition of the State of AI Ethics we hope to bring forward\nthe most important developments that caught our attention at the Montreal AI\nEthics Institute this past quarter. Our goal is to help you navigate this\never-evolving field swiftly and allow you and your organization to make\ninformed decisions. This pulse-check for the state of discourse, research, and\ndevelopment is geared towards researchers and practitioners alike who are\nmaking decisions on behalf of their organizations in considering the societal\nimpacts of AI-enabled solutions. We cover a wide set of areas in this report\nspanning Agency and Responsibility, Security and Risk, Disinformation, Jobs and\nLabor, the Future of AI Ethics, and more. Our staff has worked tirelessly over\nthe past quarter surfacing signal from the noise so that you are equipped with\nthe right tools and knowledge to confidently tread this complex yet\nconsequential domain.", "author": [{"name": "Abhishek Gupta", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Microsoft"}]}, {"name": "Camylle Lanteigne", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "McGill University"}]}, {"name": "Victoria Heath", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Creative Commons"}]}, {"name": "Marianna Bergamaschi Ganapini", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Union College"}]}, {"name": "Erick Galinkin", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Rapid7"}]}, {"name": "Allison Cohen", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AI Global"}]}, {"name": "Tania De Gasperis", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "OCAD University"}]}, {"name": "Mo Akif", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "McGill University"}]}, {"name": "Renjie Butalid", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "128 pages"}, "link": [{"@href": "http://arxiv.org/abs/2006.14662v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.14662v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.03604v2", "updated": "2020-07-08T07:55:22Z", "published": "2020-06-23T13:46:38Z", "title": "A Decade of Social Bot Detection", "summary": "On the morning of November 9th 2016, the world woke up to the shocking\noutcome of the US Presidential elections: Donald Trump was the 45th President\nof the United States of America. An unexpected event that still has tremendous\nconsequences all over the world. Today, we know that a minority of social bots,\nautomated social media accounts mimicking humans, played a central role in\nspreading divisive messages and disinformation, possibly contributing to\nTrump's victory. In the aftermath of the 2016 US elections, the world started\nto realize the gravity of widespread deception in social media. Following\nTrump's exploit, we witnessed to the emergence of a strident dissonance between\nthe multitude of efforts for detecting and removing bots, and the increasing\neffects that these malicious actors seem to have on our societies. This paradox\nopens a burning question: What strategies should we enforce in order to stop\nthis social bot pandemic? In these times, during the run-up to the 2020 US\nelections, the question appears as more crucial than ever. What stroke social,\npolitical and economic analysts after 2016, deception and automation, has been\nhowever a matter of study for computer scientists since at least 2010. In this\nwork, we briefly survey the first decade of research in social bot detection.\nVia a longitudinal analysis, we discuss the main trends of research in the\nfight against bots, the major results that were achieved, and the factors that\nmake this never-ending battle so challenging. Capitalizing on lessons learned\nfrom our extensive analysis, we suggest possible innovations that could give us\nthe upper hand against deception and manipulation. Studying a decade of\nendeavours at social bot detection can also inform strategies for detecting and\nmitigating the effects of other, more recent, forms of online deception, such\nas strategic information operations and political trolls.", "author": {"name": "Stefano Cresci"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3409116"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3409116", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.03604v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.03604v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Forthcoming in Communications of the ACM"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Communications of the ACM 63.10 (2020):72-83"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.01208v1", "updated": "2020-10-02T21:43:25Z", "published": "2020-10-02T21:43:25Z", "title": "Decoy Allocation Games on Graphs with Temporal Logic Objectives", "summary": "We study a class of games, in which the adversary (attacker) is to satisfy a\ncomplex mission specified in linear temporal logic, and the defender is to\nprevent the adversary from achieving its goal. A deceptive defender can\nallocate decoys, in addition to defense actions, to create disinformation for\nthe attacker. Thus, we focus on the problem of jointly synthesizing a decoy\nplacement strategy and a deceptive defense strategy that maximally exploits the\nincomplete information the attacker about the decoy locations. We introduce a\nmodel of hypergames on graphs with temporal logic objectives to capture such\nadversarial interactions with asymmetric information. Using the hypergame\nmodel, we analyze the effectiveness of a given decoy placement, quantified by\nthe set of deceptive winning states where the defender can prevent the attacker\nfrom satisfying the attack objective given its incomplete information about\ndecoy locations. Then, we investigate how to place decoys to maximize the\ndefender's deceptive winning region. Considering the large search space for all\npossible decoy allocation strategies, we incorporate the idea of compositional\nsynthesis from formal methods and show that the objective function in the class\nof decoy allocation problem is monotone and non-decreasing. We derive the\nsufficient conditions under which the objective function for the decoy\nallocation problem is submodular, or supermodular, respectively. We show a\nsub-optimal allocation can be efficiently computed by iteratively composing the\nsolutions of hypergames with a subset of decoys and the solution of a hypergame\ngiven a single decoy. We use a running example to illustrate the proposed\nmethod.", "author": [{"name": "Abhishek N. Kulkarni"}, {"name": "Jie Fu"}, {"name": "Huan Luo"}, {"name": "Charles A. Kamhoua"}, {"name": "Nandi O. Leslie"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "20 page, 4 figures, 2 algorithms, Accepted at Conference on Decision\n  and Game Theory for Security (GameSec) 2020"}, "link": [{"@href": "http://arxiv.org/abs/2010.01208v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.01208v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.FL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.02787v1", "updated": "2020-11-05T12:36:16Z", "published": "2020-11-05T12:36:16Z", "title": "The State of AI Ethics Report (October 2020)", "summary": "The 2nd edition of the Montreal AI Ethics Institute's The State of AI Ethics\ncaptures the most relevant developments in the field of AI Ethics since July\n2020. This report aims to help anyone, from machine learning experts to human\nrights activists and policymakers, quickly digest and understand the\never-changing developments in the field. Through research and article\nsummaries, as well as expert commentary, this report distills the research and\nreporting surrounding various domains related to the ethics of AI, including:\nAI and society, bias and algorithmic justice, disinformation, humans and AI,\nlabor impacts, privacy, risk, and future of AI ethics.\n  In addition, The State of AI Ethics includes exclusive content written by\nworld-class AI Ethics experts from universities, research institutes,\nconsulting firms, and governments. These experts include: Danit Gal (Tech\nAdvisor, United Nations), Amba Kak (Director of Global Policy and Programs,\nNYU's AI Now Institute), Rumman Chowdhury (Global Lead for Responsible AI,\nAccenture), Brent Barron (Director of Strategic Projects and Knowledge\nManagement, CIFAR), Adam Murray (U.S. Diplomat working on tech policy, Chair of\nthe OECD Network on AI), Thomas Kochan (Professor, MIT Sloan School of\nManagement), and Katya Klinova (AI and Economy Program Lead, Partnership on\nAI).\n  This report should be used not only as a point of reference and insight on\nthe latest thinking in the field of AI Ethics, but should also be used as a\ntool for introspection as we aim to foster a more nuanced conversation\nregarding the impacts of AI on the world.", "author": [{"name": "Abhishek Gupta", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Microsoft"}]}, {"name": "Alexandrine Royer", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "University of Cambridge"}]}, {"name": "Victoria Heath", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Creative Commons"}]}, {"name": "Connor Wright", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "University of Exeter"}]}, {"name": "Camylle Lanteigne", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Concordia University"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Algora Lab"}]}, {"name": "Allison Cohen", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AI Global"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Mila"}]}, {"name": "Marianna Bergamaschi Ganapini", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Union College"}]}, {"name": "Muriam Fancy", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "University of Toronto"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "University of Ottawa"}]}, {"name": "Erick Galinkin", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Rapid7"}]}, {"name": "Ryan Khurana", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Mo Akif", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Renjie Butalid", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}}, {"name": "Falaah Arif Khan", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NYU Center for Responsible AI"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IIIT Hyderabad"}]}, {"name": "Masa Sweidan", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "McGill University"}]}, {"name": "Audrey Balogh", "arxiv:affiliation": [{"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Montreal AI Ethics Institute"}, {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "McGill University"}]}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "158 pages"}, "link": [{"@href": "http://arxiv.org/abs/2011.02787v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.02787v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.02828v1", "updated": "2021-07-06T18:20:38Z", "published": "2021-07-06T18:20:38Z", "title": "Cognitive Contagion: How to model (and potentially counter) the spread\n  of fake news", "summary": "Understanding the spread of false or dangerous beliefs - so-called\nmis/disinformation - through a population has never seemed so urgent to many.\nNetwork science researchers have often taken a page from epidemiologists, and\nmodeled the spread of false beliefs as similar to how a disease spreads through\na social network. However, absent from those disease-inspired models is an\ninternal model of an individual's set of current beliefs, where cognitive\nscience has increasingly documented how the interaction between mental models\nand incoming messages seems to be crucially important for their adoption or\nrejection. We introduce a cognitive contagion model that combines a network\nscience approach with an internal cognitive model of the individual agents,\naffecting what they believe, and what they pass on. We show that the model,\neven with a very discrete and simplistic belief function to capture cognitive\ndissonance, both adds expressive power over existing disease-based contagion\nmodels, and qualitatively demonstrates the appropriate belief update phenomena\nat the individual level. Moreover, we situate our cognitive contagion model in\na larger public opinion diffusion model, which attempts to capture the role of\ninstitutions or media sources in belief diffusion - something that is often\nleft out. We conduct an analysis of the POD model with our simple cognitive\ndissonance-sensitive update function across various graph topologies and\ninstitutional messaging patterns. We demonstrate that population-level\naggregate outcomes of the model qualitatively match what has been reported in\nCOVID misinformation public opinion polls. The overall model sets up a\npreliminary framework with which social science misinformation researchers and\ncomputational opinion diffusion modelers can join forces to understand, and\nhopefully learn how to best counter, the spread of misinformation and\n\"alternative facts.\"", "author": [{"name": "Nicholas Rabb"}, {"name": "Lenore Cowen"}, {"name": "Jan P. de Ruiter"}, {"name": "Matthias Scheutz"}], "link": [{"@href": "http://arxiv.org/abs/2107.02828v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.02828v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}]