[{"id": "http://arxiv.org/abs/1907.07759v1", "updated": "2019-07-09T22:40:35Z", "published": "2019-07-09T22:40:35Z", "title": "The Mass, Fake News, and Cognition Security", "summary": "The wide spread of fake news in social networks is posing threats to social\nstability, economic development and political democracy etc. Numerous studies\nhave explored the effective detection approaches of online fake news, while few\nworks study the intrinsic propagation and cognition mechanisms of fake news.\nSince the development of cognitive science paves a promising way for the\nprevention of fake news, we present a new research area called Cognition\nSecurity (CogSec), which studies the potential impacts of fake news to human\ncognition, ranging from misperception, untrusted knowledge acquisition,\ntargeted opinion/attitude formation, to biased decision making, and\ninvestigates the effective ways for fake news debunking. CogSec is a\nmultidisciplinary research field that leverages knowledge from social science,\npsychology, cognition science, neuroscience, AI and computer science. We first\npropose related definitions to characterize CogSec and review the literature\nhistory. We further investigate the key research challenges and techniques of\nCogSec, including human-content cognition mechanism, social influence and\nopinion diffusion, fake news detection and malicious bot detection. Finally, we\nsummarize the open issues and future research directions, such as early\ndetection of fake news, explainable fake news debunking, social contagion and\ndiffusion models of fake news, and so on.", "author": [{"name": "Bin Guo"}, {"name": "Yasan Ding"}, {"name": "Yueheng Sun"}, {"name": "Shuai Ma"}, {"name": "Ke Li"}], "link": [{"@href": "http://arxiv.org/abs/1907.07759v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.07759v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.00643v1", "updated": "2019-11-02T04:06:30Z", "published": "2019-11-02T04:06:30Z", "title": "Credibility-based Fake News Detection", "summary": "Fake news can significantly misinform people who often rely on online sources\nand social media for their information. Current research on fake news detection\nhas mostly focused on analyzing fake news content and how it propagates on a\nnetwork of users. In this paper, we emphasize the detection of fake news by\nassessing its credibility. By analyzing public fake news data, we show that\ninformation on news sources (and authors) can be a strong indicator of\ncredibility. Our findings suggest that an author's history of association with\nfake news, and the number of authors of a news article, can play a significant\nrole in detecting fake news. Our approach can help improve traditional fake\nnews detection methods, wherein content features are often used to detect fake\nnews.", "author": [{"name": "Niraj Sitaula"}, {"name": "Chilukuri K. Mohan"}, {"name": "Jennifer Grygiel"}, {"name": "Xinyi Zhou"}, {"name": "Reza Zafarani"}], "link": [{"@href": "http://arxiv.org/abs/1911.00643v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.00643v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.02941v2", "updated": "2021-08-09T17:23:05Z", "published": "2021-08-06T04:54:03Z", "title": "Is it Fake? News Disinformation Detection on South African News Websites", "summary": "Disinformation through fake news is an ongoing problem in our society and has\nbecome easily spread through social media. The most cost and time effective way\nto filter these large amounts of data is to use a combination of human and\ntechnical interventions to identify it. From a technical perspective, Natural\nLanguage Processing (NLP) is widely used in detecting fake news. Social media\ncompanies use NLP techniques to identify the fake news and warn their users,\nbut fake news may still slip through undetected. It is especially a problem in\nmore localised contexts (outside the United States of America). How do we\nadjust fake news detection systems to work better for local contexts such as in\nSouth Africa. In this work we investigate fake news detection on South African\nwebsites. We curate a dataset of South African fake news and then train\ndetection models. We contrast this with using widely available fake news\ndatasets (from mostly USA website). We also explore making the datasets more\ndiverse by combining them and observe the differences in behaviour in writing\nbetween nations' fake news using interpretable machine learning.", "author": [{"name": "Harm de Wet"}, {"name": "Vukosi Marivate"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, Accepted and to be published in AFRICON 2021"}, "link": [{"@href": "http://arxiv.org/abs/2108.02941v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.02941v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.11679v2", "updated": "2020-09-16T18:42:11Z", "published": "2019-04-26T05:52:05Z", "title": "Fake News Early Detection: An Interdisciplinary Study", "summary": "Massive dissemination of fake news and its potential to erode democracy has\nincreased the demand for accurate fake news detection. Recent advancements in\nthis area have proposed novel techniques that aim to detect fake news by\nexploring how it propagates on social networks. Nevertheless, to detect fake\nnews at an early stage, i.e., when it is published on a news outlet but not yet\nspread on social media, one cannot rely on news propagation information as it\ndoes not exist. Hence, there is a strong need to develop approaches that can\ndetect fake news by focusing on news content. In this paper, a theory-driven\nmodel is proposed for fake news detection. The method investigates news content\nat various levels: lexicon-level, syntax-level, semantic-level and\ndiscourse-level. We represent news at each level, relying on well-established\ntheories in social and forensic psychology. Fake news detection is then\nconducted within a supervised machine learning framework. As an\ninterdisciplinary research, our work explores potential fake news patterns,\nenhances the interpretability in fake news feature engineering, and studies the\nrelationships among fake news, deception/disinformation, and clickbaits.\nExperiments conducted on two real-world datasets indicate the proposed method\ncan outperform the state-of-the-art and enable fake news early detection when\nthere is limited content information.", "author": [{"name": "Xinyi Zhou"}, {"name": "Atishay Jain"}, {"name": "Vir V. Phoha"}, {"name": "Reza Zafarani"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "25 pages"}, "link": [{"@href": "http://arxiv.org/abs/1904.11679v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.11679v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.04472v1", "updated": "2019-08-13T03:19:46Z", "published": "2019-08-13T03:19:46Z", "title": "Exploiting Multi-domain Visual Information for Fake News Detection", "summary": "The increasing popularity of social media promotes the proliferation of fake\nnews. With the development of multimedia technology, fake news attempts to\nutilize multimedia contents with images or videos to attract and mislead\nreaders for rapid dissemination, which makes visual contents an important part\nof fake news. Fake-news images, images attached in fake news posts,include not\nonly fake images which are maliciously tampered but also real images which are\nwrongly used to represent irrelevant events. Hence, how to fully exploit the\ninherent characteristics of fake-news images is an important but challenging\nproblem for fake news detection. In the real world, fake-news images may have\nsignificantly different characteristics from real-news images at both physical\nand semantic levels, which can be clearly reflected in the frequency and pixel\ndomain, respectively. Therefore, we propose a novel framework Multi-domain\nVisual Neural Network (MVNN) to fuse the visual information of frequency and\npixel domains for detecting fake news. Specifically, we design a CNN-based\nnetwork to automatically capture the complex patterns of fake-news images in\nthe frequency domain; and utilize a multi-branch CNN-RNN model to extract\nvisual features from different semantic levels in the pixel domain. An\nattention mechanism is utilized to fuse the feature representations of\nfrequency and pixel domains dynamically. Extensive experiments conducted on a\nreal-world dataset demonstrate that MVNN outperforms existing methods with at\nleast 9.2% in accuracy, and can help improve the performance of multimodal fake\nnews detection by over 5.2%.", "author": [{"name": "Peng Qi"}, {"name": "Juan Cao"}, {"name": "Tianyun Yang"}, {"name": "Junbo Guo"}, {"name": "Jintao Li"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 9 figures, conference"}, "link": [{"@href": "http://arxiv.org/abs/1908.04472v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.04472v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.05096v1", "updated": "2020-03-11T03:16:04Z", "published": "2020-03-11T03:16:04Z", "title": "Exploring the Role of Visual Content in Fake News Detection", "summary": "The increasing popularity of social media promotes the proliferation of fake\nnews, which has caused significant negative societal effects. Therefore, fake\nnews detection on social media has recently become an emerging research area of\ngreat concern. With the development of multimedia technology, fake news\nattempts to utilize multimedia content with images or videos to attract and\nmislead consumers for rapid dissemination, which makes visual content an\nimportant part of fake news. Despite the importance of visual content, our\nunderstanding of the role of visual content in fake news detection is still\nlimited. This chapter presents a comprehensive review of the visual content in\nfake news, including the basic concepts, effective visual features,\nrepresentative detection methods and challenging issues of multimedia fake news\ndetection. This chapter can help readers to understand the role of visual\ncontent in fake news detection, and effectively utilize visual content to\nassist in detecting multimedia fake news.", "author": [{"name": "Juan Cao"}, {"name": "Peng Qi"}, {"name": "Qiang Sheng"}, {"name": "Tianyun Yang"}, {"name": "Junbo Guo"}, {"name": "Jintao Li"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-42699-6"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-42699-6", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.05096v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.05096v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a preprint of a chapter published in Disinformation,\n  Misinformation, and Fake News in Social Media: Emerging Research Challenges\n  and Opportunities, edited by Kai, S., Suhang, W., Dongwon, L., Huan, L, 2020,\n  Springer reproduced with permission of Springer Nature Switzerland AG. The\n  final authenticated version is available online at:\n  https://www.springer.com/gp/book/9783030426989. arXiv admin note: text\n  overlap with arXiv:2001.00623, arXiv:1808.06686, arXiv:1903.00788 by other\n  authors"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Disinformation, Misinformation, and Fake News in Social Media.\n  2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.04210v1", "updated": "2019-06-10T18:10:27Z", "published": "2019-06-10T18:10:27Z", "title": "Network-based Fake News Detection: A Pattern-driven Approach", "summary": "Fake news gains has gained significant momentum, strongly motivating the need\nfor fake news research. Many fake news detection approaches have thus been\nproposed, where most of them heavily rely on news content. However,\nnetwork-based clues revealed when analyzing news propagation on social networks\nis an information that has hardly been comprehensively explored or used for\nfake news detection. We bridge this gap by proposing a network-based\npattern-driven fake news detection approach. We aim to study the patterns of\nfake news in social networks, which refer to the news being spread, spreaders\nof the news and relationships among the spreaders. Empirical evidence and\ninterpretations on the existence of such patterns are provided based on social\npsychological theories. These patterns are then represented at various network\nlevels (i.e., node-level, ego-level, triad-level, community-level and the\noverall network) for being further utilized to detect fake news. The proposed\napproach enhances the explainability in fake news feature engineering.\nExperiments conducted on real-world data demonstrate that the proposed approach\ncan outperform the state of the arts.", "author": [{"name": "Xinyi Zhou"}, {"name": "Reza Zafarani"}], "link": [{"@href": "http://arxiv.org/abs/1906.04210v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.04210v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2007.14013v1", "updated": "2020-07-28T06:34:54Z", "published": "2020-07-28T06:34:54Z", "title": "Fake News Detection using Temporal Features Extracted via Point Process", "summary": "Many people use social networking services (SNSs) to easily access various\nnews. There are numerous ways to obtain and share ``fake news,'' which are news\ncarrying false information. To address fake news, several studies have been\nconducted for detecting fake news by using SNS-extracted features. In this\nstudy, we attempt to use temporal features generated from SNS posts by using a\npoint process algorithm to identify fake news from real news. Temporal features\nin fake news detection have the advantage of robustness over existing features\nbecause it has minimal dependence on fake news propagators. Further, we propose\na novel multi-modal attention-based method, which includes linguistic and user\nfeatures alongside temporal features, for detecting fake news from SNS posts.\nResults obtained from three public datasets indicate that the proposed model\nachieves better performance compared to existing methods and demonstrate the\neffectiveness of temporal features for fake news detection.", "author": [{"name": "Taichi Murayama"}, {"name": "Shoko Wakamiya"}, {"name": "Eiji Aramaki"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.36190/2020.13"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.36190/2020.13", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.14013v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.14013v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CySoc 2020 International Workshop on Cyber Social Threats, ICWSM 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.05944v1", "updated": "2021-03-10T09:01:34Z", "published": "2021-03-10T09:01:34Z", "title": "How does Truth Evolve into Fake News? An Empirical Study of Fake News\n  Evolution", "summary": "Automatically identifying fake news from the Internet is a challenging\nproblem in deception detection tasks. Online news is modified constantly during\nits propagation, e.g., malicious users distort the original truth and make up\nfake news. However, the continuous evolution process would generate\nunprecedented fake news and cheat the original model. We present the Fake News\nEvolution (FNE) dataset: a new dataset tracking the fake news evolution\nprocess. Our dataset is composed of 950 paired data, each of which consists of\narticles representing the three significant phases of the evolution process,\nwhich are the truth, the fake news, and the evolved fake news. We observe the\nfeatures during the evolution and they are the disinformation techniques, text\nsimilarity, top 10 keywords, classification accuracy, parts of speech, and\nsentiment properties.", "author": [{"name": "Mingfei Guo"}, {"name": "Xiuying Chen"}, {"name": "Juntao Li"}, {"name": "Dongyan Zhao"}, {"name": "Rui Yan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages, 2 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The Web Conference 2021, Workshop on News Recommendation and\n  Intelligence"}, "link": [{"@href": "http://arxiv.org/abs/2103.05944v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.05944v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.10942v1", "updated": "2021-08-24T20:27:38Z", "published": "2021-08-24T20:27:38Z", "title": "Profiling Fake News Spreaders on Social Media through Psychological and\n  Motivational Factors", "summary": "The rise of fake news in the past decade has brought with it a host of\nconsequences, from swaying opinions on elections to generating uncertainty\nduring a pandemic. A majority of methods developed to combat disinformation\neither focus on fake news content or malicious actors who generate it. However,\nthe virality of fake news is largely dependent upon the users who propagate it.\nA deeper understanding of these users can contribute to the development of a\nframework for identifying users who are likely to spread fake news. In this\nwork, we study the characteristics and motivational factors of fake news\nspreaders on social media with input from psychological theories and behavioral\nstudies. We then perform a series of experiments to determine if fake news\nspreaders can be found to exhibit different characteristics than other users.\nFurther, we investigate our findings by testing whether the characteristics we\nobserve amongst fake news spreaders in our experiments can be applied to the\ndetection of fake news spreaders in a real social media environment.", "author": [{"name": "Mansooreh Karami"}, {"name": "Tahora H. Nazer"}, {"name": "Huan Liu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3465336.3475097"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3465336.3475097", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.10942v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.10942v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1903.09196v1", "updated": "2019-03-21T18:57:35Z", "published": "2019-03-21T18:57:35Z", "title": "Hierarchical Propagation Networks for Fake News Detection: Investigation\n  and Exploitation", "summary": "Consuming news from social media is becoming increasingly popular. However,\nsocial media also enables the widespread of fake news. Because of its\ndetrimental effects brought by social media, fake news detection has attracted\nincreasing attention. However, the performance of detecting fake news only from\nnews content is generally limited as fake news pieces are written to mimic true\nnews. In the real world, news pieces spread through propagation networks on\nsocial media. The news propagation networks usually involve multi-levels. In\nthis paper, we study the challenging problem of investigating and exploiting\nnews hierarchical propagation network on social media for fake news detection.\n  In an attempt to understand the correlations between news propagation\nnetworks and fake news, first, we build a hierarchical propagation network from\nmacro-level and micro-level of fake news and true news; second, we perform a\ncomparative analysis of the propagation network features of linguistic,\nstructural and temporal perspectives between fake and real news, which\ndemonstrates the potential of utilizing these features to detect fake news;\nthird, we show the effectiveness of these propagation network features for fake\nnews detection. We further validate the effectiveness of these features from\nfeature important analysis. Altogether, this work presents a data-driven view\nof hierarchical propagation network and fake news and paves the way towards a\nhealthier online news ecosystem.", "author": [{"name": "Kai Shu"}, {"name": "Deepak Mahudeswaran"}, {"name": "Suhang Wang"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages"}, "link": [{"@href": "http://arxiv.org/abs/1903.09196v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.09196v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1904.13355v1", "updated": "2019-04-30T16:35:28Z", "published": "2019-04-30T16:35:28Z", "title": "The Role of User Profile for Fake News Detection", "summary": "Consuming news from social media is becoming increasingly popular. Social\nmedia appeals to users due to its fast dissemination of information, low cost,\nand easy access. However, social media also enables the widespread of fake\nnews. Because of the detrimental societal effects of fake news, detecting fake\nnews has attracted increasing attention. However, the detection performance\nonly using news contents is generally not satisfactory as fake news is written\nto mimic true news. Thus, there is a need for an in-depth understanding on the\nrelationship between user profiles on social media and fake news. In this\npaper, we study the challenging problem of understanding and exploiting user\nprofiles on social media for fake news detection. In an attempt to understand\nconnections between user profiles and fake news, first, we measure users'\nsharing behaviors on social media and group representative users who are more\nlikely to share fake and real news; then, we perform a comparative analysis of\nexplicit and implicit profile features between these user groups, which reveals\ntheir potential to help differentiate fake news from real news. To exploit user\nprofile features, we demonstrate the usefulness of these user profile features\nin a fake news classification task. We further validate the effectiveness of\nthese features through feature importance analysis. The findings of this work\nlay the foundation for deeper exploration of user profile features of social\nmedia and enhance the capabilities for fake news detection.", "author": [{"name": "Kai Shu"}, {"name": "Xinyi Zhou"}, {"name": "Suhang Wang"}, {"name": "Reza Zafarani"}, {"name": "Huan Liu"}], "link": [{"@href": "http://arxiv.org/abs/1904.13355v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.13355v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.00964v2", "updated": "2018-10-26T10:39:34Z", "published": "2018-09-04T13:50:49Z", "title": "How to model fake news", "summary": "Over the past three years it has become evident that fake news is a danger to\ndemocracy. However, until now there has been no clear understanding of how to\ndefine fake news, much less how to model it. This paper addresses both these\nissues. A definition of fake news is given, and two approaches for the\nmodelling of fake news and its impact in elections and referendums are\nintroduced. The first approach, based on the idea of a representative voter, is\nshown to be suitable to obtain a qualitative understanding of phenomena\nassociated with fake news at a macroscopic level. The second approach, based on\nthe idea of an election microstructure, describes the collective behaviour of\nthe electorate by modelling the preferences of individual voters. It is shown\nthrough a simulation study that the mere knowledge that pieces of fake news may\nbe in circulation goes a long way towards mitigating the impact of fake news.", "author": [{"name": "Dorje C. Brody"}, {"name": "David M. Meier"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "17 pages, 3 figures"}, "link": [{"@href": "http://arxiv.org/abs/1809.00964v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.00964v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.PR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.03016v1", "updated": "2019-04-04T06:23:25Z", "published": "2019-04-04T06:23:25Z", "title": "Open Issues in Combating Fake News: Interpretability as an Opportunity", "summary": "Combating fake news needs a variety of defense methods. Although rumor\ndetection and various linguistic analysis techniques are common methods to\ndetect false content in social media, there are other feasible mitigation\napproaches that could be explored in the machine learning community. In this\npaper, we present open issues and opportunities in fake news research that need\nfurther attention. We first review different stages of the news life cycle in\nsocial media and discuss core vulnerability issues for news feed algorithms in\npropagating fake news content with three examples. We then discuss how\ncomplexity and unclarity of the fake news problem limit the advancements in\nthis field. Lastly, we present research opportunities from interpretable\nmachine learning to mitigate fake news problems with 1) interpretable fake news\ndetection and 2) transparent news feed algorithms. We propose three dimensions\nof interpretability consisting of algorithmic interpretability, human\ninterpretability, and the inclusion of supporting evidence that can benefit\nfake news mitigation methods in different ways.", "author": [{"name": "Sina Mohseni"}, {"name": "Eric Ragan"}, {"name": "Xia Hu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: text overlap with arXiv:1811.12349"}, "link": [{"@href": "http://arxiv.org/abs/1904.03016v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.03016v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.10580v2", "updated": "2021-07-14T23:14:07Z", "published": "2020-10-20T19:37:04Z", "title": "Causal Understanding of Fake News Dissemination on Social Media", "summary": "Recent years have witnessed remarkable progress towards computational fake\nnews detection. To mitigate its negative impact, we argue that it is critical\nto understand what user attributes potentially cause users to share fake news.\nThe key to this causal-inference problem is to identify confounders --\nvariables that cause spurious associations between treatments (e.g., user\nattributes) and outcome (e.g., user susceptibility). In fake news\ndissemination, confounders can be characterized by fake news sharing behavior\nthat inherently relates to user attributes and online activities. Learning such\nuser behavior is typically subject to selection bias in users who are\nsusceptible to share news on social media. Drawing on causal inference\ntheories, we first propose a principled approach to alleviating selection bias\nin fake news dissemination. We then consider the learned unbiased fake news\nsharing behavior as the surrogate confounder that can fully capture the causal\nlinks between user attributes and user susceptibility. We theoretically and\nempirically characterize the effectiveness of the proposed approach and find\nthat it could be useful in protecting society from the perils of fake news.", "author": [{"name": "Lu Cheng"}, {"name": "Ruocheng Guo"}, {"name": "Kai Shu"}, {"name": "Huan Liu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3447548.3467321"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3447548.3467321", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2010.10580v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.10580v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 5 figures"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.06796v1", "updated": "2021-07-14T15:52:15Z", "published": "2021-07-14T15:52:15Z", "title": "Indonesia's Fake News Detection using Transformer Network", "summary": "Fake news is a problem faced by society in this era. It is not rare for fake\nnews to cause provocation and problem for the people. Indonesia, as a country\nwith the 4th largest population, has a problem in dealing with fake news. More\nthan 30% of rural and urban population are deceived by this fake news problem.\nAs we have been studying, there is only few literatures on preventing the\nspread of fake news in Bahasa Indonesia. So, this research is conducted to\nprevent these problems. The dataset used in this research was obtained from a\nnews portal that identifies fake news, turnbackhoax.id. Using Web Scrapping on\nthis page, we got 1116 data consisting of valid news and fake news. The dataset\ncan be accessed at https://github.com/JibranFawaid/turnbackhoax-dataset. This\ndataset will be combined with other available datasets. The methods used are\nCNN, BiLSTM, Hybrid CNN-BiLSTM, and BERT with Transformer Network. This\nresearch shows that the BERT method with Transformer Network has the best\nresults with an accuracy of up to 90%.", "author": [{"name": "Aisyah Awalina"}, {"name": "Jibran Fawaid"}, {"name": "Rifky Yunus Krisnabayu"}, {"name": "Novanto Yudistira"}], "link": [{"@href": "http://arxiv.org/abs/2107.06796v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.06796v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.07970v1", "updated": "2021-07-16T15:36:03Z", "published": "2021-07-16T15:36:03Z", "title": "How Vulnerable Are Automatic Fake News Detection Methods to Adversarial\n  Attacks?", "summary": "As the spread of false information on the internet has increased dramatically\nin recent years, more and more attention is being paid to automated fake news\ndetection. Some fake news detection methods are already quite successful.\nNevertheless, there are still many vulnerabilities in the detection algorithms.\nThe reason for this is that fake news publishers can structure and formulate\ntheir texts in such a way that a detection algorithm does not expose this text\nas fake news. This paper shows that it is possible to automatically attack\nstate-of-the-art models that have been trained to detect Fake News, making\nthese vulnerable. For this purpose, corresponding models were first trained\nbased on a dataset. Then, using Text-Attack, an attempt was made to manipulate\nthe trained models in such a way that previously correctly identified fake news\nwas classified as true news. The results show that it is possible to\nautomatically bypass Fake News detection mechanisms, leading to implications\nconcerning existing policy initiatives.", "author": [{"name": "Camille Koenders"}, {"name": "Johannes Filla"}, {"name": "Nicolai Schneider"}, {"name": "Vinicius Woloszyn"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, Github:\n  https://github.com/nicolaischneider/FakeNewsDetectionVulnerability"}, "link": [{"@href": "http://arxiv.org/abs/2107.07970v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.07970v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1806.00749v1", "updated": "2018-06-03T08:09:58Z", "published": "2018-06-03T08:09:58Z", "title": "TI-CNN: Convolutional Neural Networks for Fake News Detection", "summary": "With the development of social networks, fake news for various commercial and\npolitical purposes has been appearing in large numbers and gotten widespread in\nthe online world. With deceptive words, people can get infected by the fake\nnews very easily and will share them without any fact-checking. For instance,\nduring the 2016 US president election, various kinds of fake news about the\ncandidates widely spread through both official news media and the online social\nnetworks. These fake news is usually released to either smear the opponents or\nsupport the candidate on their side. The erroneous information in the fake news\nis usually written to motivate the voters' irrational emotion and enthusiasm.\nSuch kinds of fake news sometimes can bring about devastating effects, and an\nimportant goal in improving the credibility of online social networks is to\nidentify the fake news timely. In this paper, we propose to study the fake news\ndetection problem. Automatic fake news identification is extremely hard, since\npure model based fact-checking for news is still an open problem, and few\nexisting models can be applied to solve the problem. With a thorough\ninvestigation of a fake news data, lots of useful explicit features are\nidentified from both the text words and images used in the fake news. Besides\nthe explicit features, there also exist some hidden patterns in the words and\nimages used in fake news, which can be captured with a set of latent features\nextracted via the multiple convolutional layers in our model. A model named as\nTI-CNN (Text and Image information based Convolutinal Neural Network) is\nproposed in this paper. By projecting the explicit and latent features into a\nunified feature space, TI-CNN is trained with both the text and image\ninformation simultaneously. Extensive experiments carried on the real-world\nfake news datasets have demonstrate the effectiveness of TI-CNN.", "author": [{"name": "Yang Yang"}, {"name": "Lei Zheng"}, {"name": "Jiawei Zhang"}, {"name": "Qingcai Cui"}, {"name": "Zhoujun Li"}, {"name": "Philip S. Yu"}], "link": [{"@href": "http://arxiv.org/abs/1806.00749v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.00749v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.01286v3", "updated": "2019-03-27T16:54:50Z", "published": "2018-09-05T01:14:11Z", "title": "FakeNewsNet: A Data Repository with News Content, Social Context and\n  Spatialtemporal Information for Studying Fake News on Social Media", "summary": "Social media has become a popular means for people to consume news.\nMeanwhile, it also enables the wide dissemination of fake news, i.e., news with\nintentionally false information, which brings significant negative effects to\nthe society. Thus, fake news detection is attracting increasing attention.\nHowever, fake news detection is a non-trivial task, which requires multi-source\ninformation such as news content, social context, and dynamic information.\nFirst, fake news is written to fool people, which makes it difficult to detect\nfake news simply based on news contents. In addition to news contents, we need\nto explore social contexts such as user engagements and social behaviors. For\nexample, a credible user's comment that \"this is a fake news\" is a strong\nsignal for detecting fake news. Second, dynamic information such as how fake\nnews and true news propagate and how users' opinions toward news pieces are\nvery important for extracting useful patterns for (early) fake news detection\nand intervention. Thus, comprehensive datasets which contain news content,\nsocial context, and dynamic information could facilitate fake news propagation,\ndetection, and mitigation; while to the best of our knowledge, existing\ndatasets only contains one or two aspects. Therefore, in this paper, to\nfacilitate fake news related researches, we provide a fake news data repository\nFakeNewsNet, which contains two comprehensive datasets that includes news\ncontent, social context, and dynamic information. We present a comprehensive\ndescription of datasets collection, demonstrate an exploratory analysis of this\ndata repository from different perspectives, and discuss the benefits of\nFakeNewsNet for potential applications on fake news study on social media.", "author": [{"name": "Kai Shu"}, {"name": "Deepak Mahudeswaran"}, {"name": "Suhang Wang"}, {"name": "Dongwon Lee"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages; the dataset structure and API function are updated"}, "link": [{"@href": "http://arxiv.org/abs/1809.01286v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.01286v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1712.07709v2", "updated": "2018-12-10T00:02:16Z", "published": "2017-12-20T21:03:54Z", "title": "Beyond News Contents: The Role of Social Context for Fake News Detection", "summary": "Social media is becoming popular for news consumption due to its fast\ndissemination, easy access, and low cost. However, it also enables the wide\npropagation of fake news, i.e., news with intentionally false information.\nDetecting fake news is an important task, which not only ensures users to\nreceive authentic information but also help maintain a trustworthy news\necosystem. The majority of existing detection algorithms focus on finding clues\nfrom news contents, which are generally not effective because fake news is\noften intentionally written to mislead users by mimicking true news. Therefore,\nwe need to explore auxiliary information to improve detection. The social\ncontext during news dissemination process on social media forms the inherent\ntri-relationship, the relationship among publishers, news pieces, and users,\nwhich has potential to improve fake news detection. For example,\npartisan-biased publishers are more likely to publish fake news, and\nlow-credible users are more likely to share fake news. In this paper, we study\nthe novel problem of exploiting social context for fake news detection. We\npropose a tri-relationship embedding framework TriFN, which models\npublisher-news relations and user-news interactions simultaneously for fake\nnews classification. We conduct experiments on two real-world datasets, which\ndemonstrate that the proposed approach significantly outperforms other baseline\nmethods for fake news detection.", "author": [{"name": "Kai Shu"}, {"name": "Suhang Wang"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Proceedings of 12th ACM International Conference on Web Search and\n  Data Mining (WSDM 2019)"}, "link": [{"@href": "http://arxiv.org/abs/1712.07709v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1712.07709v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2007.14059v2", "updated": "2021-04-27T05:15:52Z", "published": "2020-07-28T08:28:16Z", "title": "Modeling the spread of fake news on Twitter", "summary": "Fake news can have a significant negative impact on society because of the\ngrowing use of mobile devices and the worldwide increase in Internet access. It\nis therefore essential to develop a simple mathematical model to understand the\nonline dissemination of fake news. In this study, we propose a point process\nmodel of the spread of fake news on Twitter. The proposed model describes the\nspread of a fake news item as a two-stage process: initially, fake news spreads\nas a piece of ordinary news; then, when most users start recognizing the\nfalsity of the news item, that itself spreads as another news story. We\nvalidate this model using two datasets of fake news items spread on Twitter. We\nshow that the proposed model is superior to the current state-of-the-art\nmethods in accurately predicting the evolution of the spread of a fake news\nitem. Moreover, a text analysis suggests that our model appropriately infers\nthe correction time, i.e., the moment when Twitter users start realizing the\nfalsity of the news item. The proposed model contributes to understanding the\ndynamics of the spread of fake news on social media. Its ability to extract a\ncompact representation of the spreading pattern could be useful in the\ndetection and mitigation of fake news.", "author": [{"name": "Taichi Murayama"}, {"name": "Shoko Wakamiya"}, {"name": "Eiji Aramaki"}, {"name": "Ryota Kobayashi"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0250419"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0250419", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.14059v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.14059v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at PLOS ONE in 2021"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Plos one 16.4: e0250419 (2021)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.12259v1", "updated": "2021-04-25T21:19:24Z", "published": "2021-04-25T21:19:24Z", "title": "User Preference-aware Fake News Detection", "summary": "Disinformation and fake news have posed detrimental effects on individuals\nand society in recent years, attracting broad attention to fake news detection.\nThe majority of existing fake news detection algorithms focus on mining news\ncontent and/or the surrounding exogenous context for discovering deceptive\nsignals; while the endogenous preference of a user when he/she decides to\nspread a piece of fake news or not is ignored. The confirmation bias theory has\nindicated that a user is more likely to spread a piece of fake news when it\nconfirms his/her existing beliefs/preferences. Users' historical, social\nengagements such as posts provide rich information about users' preferences\ntoward news and have great potential to advance fake news detection. However,\nthe work on exploring user preference for fake news detection is somewhat\nlimited. Therefore, in this paper, we study the novel problem of exploiting\nuser preference for fake news detection. We propose a new framework, UPFD,\nwhich simultaneously captures various signals from user preferences by joint\ncontent and graph modeling. Experimental results on real-world datasets\ndemonstrate the effectiveness of the proposed framework. We release our code\nand data as a benchmark for GNN-based fake news detection:\nhttps://github.com/safe-graph/GNN-FakeNews.", "author": [{"name": "Yingtong Dou"}, {"name": "Kai Shu"}, {"name": "Congying Xia"}, {"name": "Philip S. Yu"}, {"name": "Lichao Sun"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted by SIGIR'21. Code is available at\n  https://github.com/safe-graph/GNN-FakeNews"}, "link": [{"@href": "http://arxiv.org/abs/2104.12259v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.12259v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1812.00315v2", "updated": "2020-07-17T21:08:10Z", "published": "2018-12-02T03:27:15Z", "title": "A Survey of Fake News: Fundamental Theories, Detection Methods, and\n  Opportunities", "summary": "The explosive growth in fake news and its erosion to democracy, justice, and\npublic trust has increased the demand for fake news detection and intervention.\nThis survey reviews and evaluates methods that can detect fake news from four\nperspectives: (1) the false knowledge it carries, (2) its writing style, (3)\nits propagation patterns, and (4) the credibility of its source. The survey\nalso highlights some potential research tasks based on the review. In\nparticular, we identify and detail related fundamental theories across various\ndisciplines to encourage interdisciplinary research on fake news. We hope this\nsurvey can facilitate collaborative efforts among experts in computer and\ninformation sciences, social sciences, political science, and journalism to\nresearch fake news, where such efforts can lead to fake news detection that is\nnot only efficient but more importantly, explainable.", "author": [{"name": "Xinyi Zhou"}, {"name": "Reza Zafarani"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3395046"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3395046", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1812.00315v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.00315v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACM Computing Surveys (CSUR), 37 pages"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.03854v2", "updated": "2020-03-12T17:55:57Z", "published": "2019-11-10T05:06:38Z", "title": "r/Fakeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake\n  News Detection", "summary": "Fake news has altered society in negative ways in politics and culture. It\nhas adversely affected both online social network systems as well as offline\ncommunities and conversations. Using automatic machine learning classification\nmodels is an efficient way to combat the widespread dissemination of fake news.\nHowever, a lack of effective, comprehensive datasets has been a problem for\nfake news research and detection model development. Prior fake news datasets do\nnot provide multimodal text and image data, metadata, comment data, and\nfine-grained fake news categorization at the scale and breadth of our dataset.\nWe present Fakeddit, a novel multimodal dataset consisting of over 1 million\nsamples from multiple categories of fake news. After being processed through\nseveral stages of review, the samples are labeled according to 2-way, 3-way,\nand 6-way classification categories through distant supervision. We construct\nhybrid text+image models and perform extensive experiments for multiple\nvariations of classification, demonstrating the importance of the novel aspect\nof multimodality and fine-grained classification unique to Fakeddit.", "author": [{"name": "Kai Nakamura"}, {"name": "Sharon Levy"}, {"name": "William Yang Wang"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted LREC 2020"}, "link": [{"@href": "http://arxiv.org/abs/1911.03854v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.03854v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.04397v2", "updated": "2021-02-13T03:16:22Z", "published": "2020-02-05T19:09:13Z", "title": "Fake News Detection on News-Oriented Heterogeneous Information Networks\n  through Hierarchical Graph Attention", "summary": "The viral spread of fake news has caused great social harm, making fake news\ndetection an urgent task. Current fake news detection methods rely heavily on\ntext information by learning the extracted news content or writing style of\ninternal knowledge. However, deliberate rumors can mask writing style,\nbypassing language models and invalidating simple text-based models. In fact,\nnews articles and other related components (such as news creators and news\ntopics) can be modeled as a heterogeneous information network (HIN for short).\nIn this paper, we propose a novel fake news detection framework, namely\nHierarchical Graph Attention Network(HGAT), which uses a novel hierarchical\nattention mechanism to perform node representation learning in HIN, and then\ndetects fake news by classifying news article nodes. Experiments on two\nreal-world fake news datasets show that HGAT can outperform text-based models\nand other network-based models. In addition, the experiment proved the\nexpandability and generalizability of our for graph representation learning and\nother node classification related applications in heterogeneous graphs.", "author": [{"name": "Yuxiang Ren"}, {"name": "Jiawei Zhang"}], "link": [{"@href": "http://arxiv.org/abs/2002.04397v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.04397v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.14627v1", "updated": "2020-05-29T15:38:54Z", "published": "2020-05-29T15:38:54Z", "title": "Detection of Bangla Fake News using MNB and SVM Classifier", "summary": "Fake news has been coming into sight in significant numbers for numerous\nbusiness and political reasons and has become frequent in the online world.\nPeople can get contaminated easily by these fake news for its fabricated words\nwhich have enormous effects on the offline community. Thus, interest in\nresearch in this area has risen. Significant research has been conducted on the\ndetection of fake news from English texts and other languages but a few in\nBangla Language. Our work reflects the experimental analysis on the detection\nof Bangla fake news from social media as this field still requires much focus.\nIn this research work, we have used two supervised machine learning algorithms,\nMultinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to\ndetect Bangla fake news with CountVectorizer and Term Frequency - Inverse\nDocument Frequency Vectorizer as feature extraction. Our proposed framework\ndetects fake news depending on the polarity of the corresponding article.\nFinally, our analysis shows SVM with the linear kernel with an accuracy of\n96.64% outperform MNB with an accuracy of 93.32%.", "author": [{"name": "Md Gulzar Hussain"}, {"name": "Md Rashidul Hasan"}, {"name": "Mahmuda Rahman"}, {"name": "Joy Protim"}, {"name": "Sakib Al Hasan"}], "link": [{"@href": "http://arxiv.org/abs/2005.14627v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.14627v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.05202v1", "updated": "2020-10-11T09:28:52Z", "published": "2020-10-11T09:28:52Z", "title": "Connecting the Dots Between Fact Verification and Fake News Detection", "summary": "Fact verification models have enjoyed a fast advancement in the last two\nyears with the development of pre-trained language models like BERT and the\nrelease of large scale datasets such as FEVER. However, the challenging problem\nof fake news detection has not benefited from the improvement of fact\nverification models, which is closely related to fake news detection. In this\npaper, we propose a simple yet effective approach to connect the dots between\nfact verification and fake news detection. Our approach first employs a text\nsummarization model pre-trained on news corpora to summarize the long news\narticle into a short claim. Then we use a fact verification model pre-trained\non the FEVER dataset to detect whether the input news article is real or fake.\nOur approach makes use of the recent success of fact verification models and\nenables zero-shot fake news detection, alleviating the need of large-scale\ntraining data to train fake news detection models. Experimental results on\nFakenewsNet, a benchmark dataset for fake news detection, demonstrate the\neffectiveness of our proposed approach.", "author": [{"name": "Qifei Li"}, {"name": "Wangchunshu Zhou"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to COLING 2020"}, "link": [{"@href": "http://arxiv.org/abs/2010.05202v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.05202v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.04088v2", "updated": "2020-11-23T06:04:23Z", "published": "2020-11-08T21:42:03Z", "title": "MM-COVID: A Multilingual and Multimodal Data Repository for Combating\n  COVID-19 Disinformation", "summary": "The COVID-19 epidemic is considered as the global health crisis of the whole\nsociety and the greatest challenge mankind faced since World War Two.\nUnfortunately, the fake news about COVID-19 is spreading as fast as the virus\nitself. The incorrect health measurements, anxiety, and hate speeches will have\nbad consequences on people's physical health, as well as their mental health in\nthe whole world. To help better combat the COVID-19 fake news, we propose a new\nfake news detection dataset MM-COVID(Multilingual and Multidimensional COVID-19\nFake News Data Repository). This dataset provides the multilingual fake news\nand the relevant social context. We collect 3981 pieces of fake news content\nand 7192 trustworthy information from English, Spanish, Portuguese, Hindi,\nFrench and Italian, 6 different languages. We present a detailed and\nexploratory analysis of MM-COVID from different perspectives and demonstrate\nthe utility of MM-COVID in several potential applications of COVID-19 fake news\nstudy on multilingual and social media.", "author": [{"name": "Yichuan Li"}, {"name": "Bohan Jiang"}, {"name": "Kai Shu"}, {"name": "Huan Liu"}], "link": [{"@href": "http://arxiv.org/abs/2011.04088v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.04088v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.00770v2", "updated": "2020-03-05T01:40:56Z", "published": "2018-11-02T08:10:21Z", "title": "A Survey on Natural Language Processing for Fake News Detection", "summary": "Fake news detection is a critical yet challenging problem in Natural Language\nProcessing (NLP). The rapid rise of social networking platforms has not only\nyielded a vast increase in information accessibility but has also accelerated\nthe spread of fake news. Thus, the effect of fake news has been growing,\nsometimes extending to the offline world and threatening public safety. Given\nthe massive amount of Web content, automatic fake news detection is a practical\nNLP problem useful to all online content providers, in order to reduce the\nhuman time and effort to detect and prevent the spread of fake news. In this\npaper, we describe the challenges involved in fake news detection and also\ndescribe related tasks. We systematically review and compare the task\nformulations, datasets and NLP solutions that have been developed for this\ntask, and also discuss the potentials and limitations of them. Based on our\ninsights, we outline promising research directions, including more\nfine-grained, detailed, fair, and practical detection models. We also highlight\nthe difference between fake news detection and other related tasks, and the\nimportance of NLP solutions for fake news detection.", "author": [{"name": "Ray Oshikawa"}, {"name": "Jing Qian"}, {"name": "William Yang Wang"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, no figure, Accepted to LREC 2020"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the 12th Language Resources and Evaluation\n  Conference (LREC 2020) pp. 6086-6093"}, "link": [{"@href": "http://arxiv.org/abs/1811.00770v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.00770v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1808.02831v1", "updated": "2018-08-08T15:45:06Z", "published": "2018-08-08T15:45:06Z", "title": "Debunking Fake News One Feature at a Time", "summary": "Identifying the stance of a news article body with respect to a certain\nheadline is the first step to automated fake news detection. In this paper, we\nintroduce a 2-stage ensemble model to solve the stance detection task. By using\nonly hand-crafted features as input to a gradient boosting classifier, we are\nable to achieve a score of 9161.5 out of 11651.25 (78.63%) on the official Fake\nNews Challenge (Stage 1) dataset. We identify the most useful features for\ndetecting fake news and discuss how sampling techniques can be used to improve\nrecall accuracy on a highly imbalanced dataset.", "author": [{"name": "Melanie Tosik"}, {"name": "Antonio Mallia"}, {"name": "Kedar Gangopadhyay"}], "link": [{"@href": "http://arxiv.org/abs/1808.02831v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.02831v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2008.01535v2", "updated": "2020-08-05T01:53:01Z", "published": "2020-07-30T08:56:51Z", "title": "Weighted Accuracy Algorithmic Approach In Counteracting Fake News And\n  Disinformation", "summary": "As the world is becoming more dependent on the internet for information\nexchange, some overzealous journalists, hackers, bloggers, individuals and\norganizations tend to abuse the gift of free information environment by\npolluting it with fake news, disinformation and pretentious content for their\nown agenda. Hence, there is the need to address the issue of fake news and\ndisinformation with utmost seriousness. This paper proposes a methodology for\nfake news detection and reporting through a constraint mechanism that utilizes\nthe combined weighted accuracies of four machine learning algorithms.", "author": {"name": "Kwadwo Osei Bonsu"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.2478/ers-2021-0007"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.2478/ers-2021-0007", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.01535v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.01535v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.13433v1", "updated": "2021-02-26T12:39:03Z", "published": "2021-02-26T12:39:03Z", "title": "An organized review of key factors for fake news detection", "summary": "Fake news in social media has quickly become one of the most discussed topics\nin today's society. With false information proliferating and causing a\nsignificant impact in the political, economical, and social domains, research\nefforts to analyze and automatically identify this type of content have being\nconducted in the past few years. In this paper, we attempt to summarize the\nprincipal findings on the topic of fake news in social media, highlighting the\nmain research path taken and giving a particular focus on the detection of fake\nnews and bot accounts.", "author": [{"name": "Nuno Guimar\u00e3es"}, {"name": "\u00c1lvaro Figueira"}, {"name": "Lu\u00eds Torgo"}], "link": [{"@href": "http://arxiv.org/abs/2102.13433v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.13433v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1708.01967v3", "updated": "2017-09-03T02:40:05Z", "published": "2017-08-07T02:29:09Z", "title": "Fake News Detection on Social Media: A Data Mining Perspective", "summary": "Social media for news consumption is a double-edged sword. On the one hand,\nits low cost, easy access, and rapid dissemination of information lead people\nto seek out and consume news from social media. On the other hand, it enables\nthe wide spread of \"fake news\", i.e., low quality news with intentionally false\ninformation. The extensive spread of fake news has the potential for extremely\nnegative impacts on individuals and society. Therefore, fake news detection on\nsocial media has recently become an emerging research that is attracting\ntremendous attention. Fake news detection on social media presents unique\ncharacteristics and challenges that make existing detection algorithms from\ntraditional news media ineffective or not applicable. First, fake news is\nintentionally written to mislead readers to believe false information, which\nmakes it difficult and nontrivial to detect based on news content; therefore,\nwe need to include auxiliary information, such as user social engagements on\nsocial media, to help make a determination. Second, exploiting this auxiliary\ninformation is challenging in and of itself as users' social engagements with\nfake news produce data that is big, incomplete, unstructured, and noisy.\nBecause the issue of fake news detection on social media is both challenging\nand relevant, we conducted this survey to further facilitate research on the\nproblem. In this survey, we present a comprehensive review of detecting fake\nnews on social media, including fake news characterizations on psychology and\nsocial theories, existing algorithms from a data mining perspective, evaluation\nmetrics and representative datasets. We also discuss related research areas,\nopen problems, and future research directions for fake news detection on social\nmedia.", "author": [{"name": "Kai Shu"}, {"name": "Amy Sliva"}, {"name": "Suhang Wang"}, {"name": "Jiliang Tang"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACM SIGKDD Explorations Newsletter, 2017"}, "link": [{"@href": "http://arxiv.org/abs/1708.01967v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1708.01967v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.09295v3", "updated": "2020-05-15T17:54:09Z", "published": "2019-10-21T12:28:00Z", "title": "Localization of Fake News Detection via Multitask Transfer Learning", "summary": "The use of the internet as a fast medium of spreading fake news reinforces\nthe need for computational tools that combat it. Techniques that train fake\nnews classifiers exist, but they all assume an abundance of resources including\nlarge labeled datasets and expert-curated corpora, which low-resource languages\nmay not have. In this work, we make two main contributions: First, we alleviate\nresource scarcity by constructing the first expertly-curated benchmark dataset\nfor fake news detection in Filipino, which we call \"Fake News Filipino.\"\nSecond, we benchmark Transfer Learning (TL) techniques and show that they can\nbe used to train robust fake news classifiers from little data, achieving 91%\naccuracy on our fake news dataset, reducing the error by 14% compared to\nestablished few-shot baselines. Furthermore, lifting ideas from multitask\nlearning, we show that augmenting transformer-based transfer techniques with\nauxiliary language modeling losses improves their performance by adapting to\nwriting style. Using this, we improve TL performance by 4-6%, achieving an\naccuracy of 96% on our best model. Lastly, we show that our method generalizes\nwell to different types of news articles, including political news,\nentertainment news, and opinion articles.", "author": [{"name": "Jan Christian Blaise Cruz"}, {"name": "Julianne Agatha Tan"}, {"name": "Charibeth Cheng"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.13140/RG.2.2.23028.40322"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.13140/RG.2.2.23028.40322", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1910.09295v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.09295v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published in the LREC 2020 Proceedings. Models and data available at\n  https://github.com/jcblaisecruz02/Tagalog-fake-news"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Proceedings of The 12th Language Resources and Evaluation\n  Conference, pp.2589-2597 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1805.08751v2", "updated": "2019-08-10T11:40:16Z", "published": "2018-05-22T17:23:32Z", "title": "FAKEDETECTOR: Effective Fake News Detection with Deep Diffusive Neural\n  Network", "summary": "In recent years, due to the booming development of online social networks,\nfake news for various commercial and political purposes has been appearing in\nlarge numbers and widespread in the online world. With deceptive words, online\nsocial network users can get infected by these online fake news easily, which\nhas brought about tremendous effects on the offline society already. An\nimportant goal in improving the trustworthiness of information in online social\nnetworks is to identify the fake news timely. This paper aims at investigating\nthe principles, methodologies and algorithms for detecting fake news articles,\ncreators and subjects from online social networks and evaluating the\ncorresponding performance. This paper addresses the challenges introduced by\nthe unknown characteristics of fake news and diverse connections among news\narticles, creators and subjects. This paper introduces a novel automatic fake\nnews credibility inference model, namely FAKEDETECTOR. Based on a set of\nexplicit and latent features extracted from the textual information,\nFAKEDETECTOR builds a deep diffusive network model to learn the representations\nof news articles, creators and subjects simultaneously. Extensive experiments\nhave been done on a real-world fake news dataset to compare FAKEDETECTOR with\nseveral state-of-the-art models, and the experimental results have demonstrated\nthe effectiveness of the proposed model.", "author": [{"name": "Jiawei Zhang"}, {"name": "Bowen Dong"}, {"name": "Philip S. Yu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages"}, "link": [{"@href": "http://arxiv.org/abs/1805.08751v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1805.08751v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1903.01728v4", "updated": "2021-02-14T08:23:51Z", "published": "2019-03-05T08:52:33Z", "title": "Mining Dual Emotion for Fake News Detection", "summary": "Emotion plays an important role in detecting fake news online. When\nleveraging emotional signals, the existing methods focus on exploiting the\nemotions of news contents that conveyed by the publishers (i.e., publisher\nemotion). However, fake news often evokes high-arousal or activating emotions\nof people, so the emotions of news comments aroused in the crowd (i.e., social\nemotion) should not be ignored. Furthermore, it remains to be explored whether\nthere exists a relationship between publisher emotion and social emotion (i.e.,\ndual emotion), and how the dual emotion appears in fake news. In this paper, we\nverify that dual emotion is distinctive between fake and real news and propose\nDual Emotion Features to represent dual emotion and the relationship between\nthem for fake news detection. Further, we exhibit that our proposed features\ncan be easily plugged into existing fake news detectors as an enhancement.\nExtensive experiments on three real-world datasets (one in English and the\nothers in Chinese) show that our proposed feature set: 1) outperforms the\nstate-of-the-art task-related emotional features; 2) can be well compatible\nwith existing fake news detectors and effectively improve the performance of\ndetecting fake news.", "author": [{"name": "Xueyao Zhang"}, {"name": "Juan Cao"}, {"name": "Xirong Li"}, {"name": "Qiang Sheng"}, {"name": "Lei Zhong"}, {"name": "Kai Shu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3442381.3450004"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3442381.3450004", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1903.01728v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.01728v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted by WWW 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1903.07389v6", "updated": "2019-04-10T14:20:53Z", "published": "2019-02-27T00:03:17Z", "title": "Learning Hierarchical Discourse-level Structure for Fake News Detection", "summary": "On the one hand, nowadays, fake news articles are easily propagated through\nvarious online media platforms and have become a grand threat to the\ntrustworthiness of information. On the other hand, our understanding of the\nlanguage of fake news is still minimal. Incorporating hierarchical\ndiscourse-level structure of fake and real news articles is one crucial step\ntoward a better understanding of how these articles are structured.\nNevertheless, this has rarely been investigated in the fake news detection\ndomain and faces tremendous challenges. First, existing methods for capturing\ndiscourse-level structure rely on annotated corpora which are not available for\nfake news datasets. Second, how to extract out useful information from such\ndiscovered structures is another challenge. To address these challenges, we\npropose Hierarchical Discourse-level Structure for Fake news detection. HDSF\nlearns and constructs a discourse-level structure for fake/real news articles\nin an automated and data-driven manner. Moreover, we identify insightful\nstructure-related properties, which can explain the discovered structures and\nboost our understating of fake news. Conducted experiments show the\neffectiveness of the proposed approach. Further structural analysis suggests\nthat real and fake news present substantial differences in the hierarchical\ndiscourse-level structures.", "author": [{"name": "Hamid Karimi"}, {"name": "Jiliang Tang"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to 2019 Annual Conference of the North American Chapter of\n  the Association for Computational Linguistics June 2-7, 2019 Minneapolis, USA"}, "link": [{"@href": "http://arxiv.org/abs/1903.07389v6", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.07389v6", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.13859v1", "updated": "2020-09-29T08:32:32Z", "published": "2020-09-29T08:32:32Z", "title": "Fake News Spreader Detection on Twitter using Character N-Grams.\n  Notebook for PAN at CLEF 2020", "summary": "The authors of fake news often use facts from verified news sources and mix\nthem with misinformation to create confusion and provoke unrest among the\nreaders. The spread of fake news can thereby have serious implications on our\nsociety. They can sway political elections, push down the stock price or crush\nreputations of corporations or public figures. Several websites have taken on\nthe mission of checking rumors and allegations, but are often not fast enough\nto check the content of all the news being disseminated. Especially social\nmedia websites have offered an easy platform for the fast propagation of\ninformation. Towards limiting fake news from being propagated among social\nmedia users, the task of this year's PAN 2020 challenge lays the focus on the\nfake news spreaders. The aim of the task is to determine whether it is possible\nto discriminate authors that have shared fake news in the past from those that\nhave never done it. In this notebook, we describe our profiling system for the\nfake news detection task on Twitter. For this, we conduct different feature\nextraction techniques and learning experiments from a multilingual perspective,\nnamely English and Spanish. Our final submitted systems use character n-grams\nas features in combination with a linear SVM for English and Logistic\nRegression for the Spanish language. Our submitted models achieve an overall\naccuracy of 73% and 79% on the English and Spanish official test set,\nrespectively. Our experiments show that it is difficult to differentiate\nsolidly fake news spreaders on Twitter from users who share credible\ninformation leaving room for further investigations. Our model ranked 3rd out\nof 72 competitors.", "author": [{"name": "Inna Vogel"}, {"name": "Meghana Meghana"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF 2020 Labs and Workshops, Notebook Papers"}, "link": [{"@href": "http://arxiv.org/abs/2009.13859v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.13859v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.02097v1", "updated": "2020-10-05T15:34:52Z", "published": "2020-10-05T15:34:52Z", "title": "FaNDS: Fake News Detection System Using Energy Flow", "summary": "Recently, the term \"fake news\" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.", "author": [{"name": "Jiawei Xu"}, {"name": "Vladimir Zadorozhny"}, {"name": "Danchen Zhang"}, {"name": "John Grant"}], "link": [{"@href": "http://arxiv.org/abs/2010.02097v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.02097v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.08765v1", "updated": "2020-10-17T11:11:10Z", "published": "2020-10-17T11:11:10Z", "title": "DeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using\n  Blockchain", "summary": "The surge in the spread of misleading information, lies, propaganda, and\nfalse facts, frequently known as fake news, raised questions concerning social\nmedia's influence in today's fast-moving democratic society. The widespread and\nrapid dissemination of fake news cost us in many ways. For example, individual\nor societal costs by hampering elections integrity, significant economic losses\nby impacting stock markets, or increases the risk to national security. It is\nchallenging to overcome the spreading of fake news problems in traditional\ncentralized systems. However, Blockchain-- a distributed decentralized\ntechnology that ensures data provenance, authenticity, and traceability by\nproviding a transparent, immutable, and verifiable transaction records can help\nin detecting and contending fake news. This paper proposes a novel hybrid model\nDeHiDe: Deep Learning-based Hybrid Model to Detect Fake News using Blockchain.\nThe DeHiDe is a blockchain-based framework for legitimate news sharing by\nfiltering out the fake news. It combines the benefit of blockchain with an\nintelligent deep learning model to reinforce robustness and accuracy in\ncombating fake news's hurdle. It also compares the proposed method to existing\nstate-of-the-art methods. The DeHiDe is expected to outperform state-of-the-art\napproaches in terms of services, features, and performance.", "author": [{"name": "Prashansa Agrawal"}, {"name": "Parwat Singh Anjana"}, {"name": "Sathya Peri"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3427796.3430003"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3427796.3430003", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2010.08765v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.08765v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 Pages, 5 figures, and 1 table"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.04233v2", "updated": "2020-12-14T01:27:46Z", "published": "2020-12-08T05:53:33Z", "title": "Early Detection of Fake News by Utilizing the Credibility of News,\n  Publishers, and Users Based on Weakly Supervised Learning", "summary": "The dissemination of fake news significantly affects personal reputation and\npublic trust. Recently, fake news detection has attracted tremendous attention,\nand previous studies mainly focused on finding clues from news content or\ndiffusion path. However, the required features of previous models are often\nunavailable or insufficient in early detection scenarios, resulting in poor\nperformance. Thus, early fake news detection remains a tough challenge.\nIntuitively, the news from trusted and authoritative sources or shared by many\nusers with a good reputation is more reliable than other news. Using the\ncredibility of publishers and users as prior weakly supervised information, we\ncan quickly locate fake news in massive news and detect them in the early\nstages of dissemination.\n  In this paper, we propose a novel Structure-aware Multi-head Attention\nNetwork (SMAN), which combines the news content, publishing, and reposting\nrelations of publishers and users, to jointly optimize the fake news detection\nand credibility prediction tasks. In this way, we can explicitly exploit the\ncredibility of publishers and users for early fake news detection. We conducted\nexperiments on three real-world datasets, and the results show that SMAN can\ndetect fake news in 4 hours with an accuracy of over 91%, which is much faster\nthan the state-of-the-art models.", "author": [{"name": "Chunyuan Yuan"}, {"name": "Qianwen Ma"}, {"name": "Wei Zhou"}, {"name": "Jizhong Han"}, {"name": "Songlin Hu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted as a long paper at COLING 2020"}, "link": [{"@href": "http://arxiv.org/abs/2012.04233v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.04233v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.11206v1", "updated": "2021-01-27T05:05:25Z", "published": "2021-01-27T05:05:25Z", "title": "Adversarial Active Learning based Heterogeneous Graph Neural Network for\n  Fake News Detection", "summary": "The explosive growth of fake news along with destructive effects on politics,\neconomy, and public safety has increased the demand for fake news detection.\nFake news on social media does not exist independently in the form of an\narticle. Many other entities, such as news creators, news subjects, and so on,\nexist on social media and have relationships with news articles. Different\nentities and relationships can be modeled as a heterogeneous information\nnetwork (HIN). In this paper, we attempt to solve the fake news detection\nproblem with the support of a news-oriented HIN. We propose a novel fake news\ndetection framework, namely Adversarial Active Learning-based Heterogeneous\nGraph Neural Network (AA-HGNN) which employs a novel hierarchical attention\nmechanism to perform node representation learning in the HIN. AA-HGNN utilizes\nan active learning framework to enhance learning performance, especially when\nfacing the paucity of labeled data. An adversarial selector will be trained to\nquery high-value candidates for the active learning framework. When the\nadversarial active learning is completed, AA-HGNN detects fake news by\nclassifying news article nodes. Experiments with two real-world fake news\ndatasets show that our model can outperform text-based models and other\ngraph-based models when using less labeled data benefiting from the adversarial\nactive learning. As a model with generalizability, AA-HGNN also has the ability\nto be widely used in other node classification-related applications on\nheterogeneous graphs.", "author": [{"name": "Yuxiang Ren"}, {"name": "Bo Wang"}, {"name": "Jiawei Zhang"}, {"name": "Yi Chang"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted by ICDM 2020. arXiv admin note: text overlap with\n  arXiv:2002.04397"}, "link": [{"@href": "http://arxiv.org/abs/2101.11206v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.11206v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.06314v4", "updated": "2021-02-24T07:03:59Z", "published": "2021-02-11T23:31:14Z", "title": "Embracing Domain Differences in Fake News: Cross-domain Fake News\n  Detection using Multi-modal Data", "summary": "With the rapid evolution of social media, fake news has become a significant\nsocial problem, which cannot be addressed in a timely manner using manual\ninvestigation. This has motivated numerous studies on automating fake news\ndetection. Most studies explore supervised training models with different\nmodalities (e.g., text, images, and propagation networks) of news records to\nidentify fake news. However, the performance of such techniques generally drops\nif news records are coming from different domains (e.g., politics,\nentertainment), especially for domains that are unseen or rarely-seen during\ntraining. As motivation, we empirically show that news records from different\ndomains have significantly different word usage and propagation patterns.\nFurthermore, due to the sheer volume of unlabelled news records, it is\nchallenging to select news records for manual labelling so that the\ndomain-coverage of the labelled dataset is maximized. Hence, this work: (1)\nproposes a novel framework that jointly preserves domain-specific and\ncross-domain knowledge in news records to detect fake news from different\ndomains; and (2) introduces an unsupervised technique to select a set of\nunlabelled informative news records for manual labelling, which can be\nultimately used to train a fake news detection model that performs well for\nmany domains while minimizing the labelling cost. Our experiments show that the\nintegration of the proposed fake news model and the selective annotation\napproach achieves state-of-the-art performance for cross-domain news datasets,\nwhile yielding notable improvements for rarely-appearing domains in news\ndatasets.", "author": [{"name": "Amila Silva"}, {"name": "Ling Luo"}, {"name": "Shanika Karunasekera"}, {"name": "Christopher Leckie"}], "link": [{"@href": "http://arxiv.org/abs/2102.06314v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.06314v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1807.06926v1", "updated": "2018-07-18T13:41:57Z", "published": "2018-07-18T13:41:57Z", "title": "Fake news as we feel it: perception and conceptualization of the term\n  \"fake news\" in the media", "summary": "In this article, we quantitatively analyze how the term \"fake news\" is being\nshaped in news media in recent years. We study the perception and the\nconceptualization of this term in the traditional media using eight years of\ndata collected from news outlets based in 20 countries. Our results not only\ncorroborate previous indications of a high increase in the usage of the\nexpression \"fake news\", but also show contextual changes around this expression\nafter the United States presidential election of 2016. Among other results, we\nfound changes in the related vocabulary, in the mentioned entities, in the\nsurrounding topics and in the contextual polarity around the term \"fake news\",\nsuggesting that this expression underwent a change in perception and\nconceptualization after 2016. These outcomes expand the understandings on the\nusage of the term \"fake news\", helping to comprehend and more accurately\ncharacterize this relevant social phenomenon linked to misinformation and\nmanipulation.", "author": [{"name": "Evandro Cunha"}, {"name": "Gabriel Magno"}, {"name": "Josemar Caetano"}, {"name": "Douglas Teixeira"}, {"name": "Virgilio Almeida"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted as a full paper at the 10th International Conference on\n  Social Informatics (SocInfo 2018). Please cite the SocInfo version"}, "link": [{"@href": "http://arxiv.org/abs/1807.06926v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1807.06926v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1705.00648v1", "updated": "2017-05-01T18:20:47Z", "published": "2017-05-01T18:20:47Z", "title": "\"Liar, Liar Pants on Fire\": A New Benchmark Dataset for Fake News\n  Detection", "summary": "Automatic fake news detection is a challenging problem in deception\ndetection, and it has tremendous real-world political and social impacts.\nHowever, statistical approaches to combating fake news has been dramatically\nlimited by the lack of labeled benchmark datasets. In this paper, we present\nliar: a new, publicly available dataset for fake news detection. We collected a\ndecade-long, 12.8K manually labeled short statements in various contexts from\nPolitiFact.com, which provides detailed analysis report and links to source\ndocuments for each case. This dataset can be used for fact-checking research as\nwell. Notably, this new dataset is an order of magnitude larger than previously\nlargest public fake news datasets of similar type. Empirically, we investigate\nautomatic fake news detection based on surface-level linguistic patterns. We\nhave designed a novel, hybrid convolutional neural network to integrate\nmeta-data with text. We show that this hybrid approach can improve a text-only\ndeep learning model.", "author": {"name": "William Yang Wang"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL 2017"}, "link": [{"@href": "http://arxiv.org/abs/1705.00648v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1705.00648v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1804.10233v1", "updated": "2018-04-26T18:30:56Z", "published": "2018-04-26T18:30:56Z", "title": "Studying Fake News via Network Analysis: Detection and Mitigation", "summary": "Social media for news consumption is becoming increasingly popular due to its\neasy access, fast dissemination, and low cost. However, social media also\nenable the wide propagation of \"fake news\", i.e., news with intentionally false\ninformation. Fake news on social media poses significant negative societal\neffects, and also presents unique challenges. To tackle the challenges, many\nexisting works exploit various features, from a network perspective, to detect\nand mitigate fake news. In essence, news dissemination ecosystem involves three\ndimensions on social media, i.e., a content dimension, a social dimension, and\na temporal dimension. In this chapter, we will review network properties for\nstudying fake news, introduce popular network types and how these networks can\nbe used to detect and mitigation fake news on social media.", "author": [{"name": "Kai Shu"}, {"name": "H. Russell Bernard"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted as a invited book chapter in Lecture Notes in Social\n  Networks, Springer Press"}, "link": [{"@href": "http://arxiv.org/abs/1804.10233v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.10233v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1806.07516v2", "updated": "2019-10-09T22:04:46Z", "published": "2018-06-20T01:26:21Z", "title": "The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake\n  News", "summary": "A large body of research work and efforts have been focused on detecting fake\nnews and building online fact-check systems in order to debunk fake news as\nsoon as possible. Despite the existence of these systems, fake news is still\nwildly shared by online users. It indicates that these systems may not be fully\nutilized. After detecting fake news, what is the next step to stop people from\nsharing it? How can we improve the utilization of these fact-check systems? To\nfill this gap, in this paper, we (i) collect and analyze online users called\nguardians, who correct misinformation and fake news in online discussions by\nreferring fact-checking URLs; and (ii) propose a novel fact-checking URL\nrecommendation model to encourage the guardians to engage more in fact-checking\nactivities. We found that the guardians usually took less than one day to reply\nto claims in online conversations and took another day to spread verified\ninformation to hundreds of millions of followers. Our proposed recommendation\nmodel outperformed four state-of-the-art models by 11%~33%. Our source code and\ndataset are available at https://github.com/nguyenvo09/CombatingFakeNews.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SIGIR 2018"}, "link": [{"@href": "http://arxiv.org/abs/1806.07516v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.07516v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1901.09657v1", "updated": "2019-01-05T11:56:13Z", "published": "2019-01-05T11:56:13Z", "title": "Fake News Detection via NLP is Vulnerable to Adversarial Attacks", "summary": "News plays a significant role in shaping people's beliefs and opinions. Fake\nnews has always been a problem, which wasn't exposed to the mass public until\nthe past election cycle for the 45th President of the United States. While\nquite a few detection methods have been proposed to combat fake news since\n2015, they focus mainly on linguistic aspects of an article without any fact\nchecking. In this paper, we argue that these models have the potential to\nmisclassify fact-tampering fake news as well as under-written real news.\nThrough experiments on Fakebox, a state-of-the-art fake news detector, we show\nthat fact tampering attacks can be effective. To address these weaknesses, we\nargue that fact checking should be adopted in conjunction with linguistic\ncharacteristics analysis, so as to truly separate fake news from real news. A\ncrowdsourced knowledge graph is proposed as a straw man solution to collecting\ntimely facts about news events.", "author": [{"name": "Zhixuan Zhou"}, {"name": "Huankang Guan"}, {"name": "Meghana Moorthy Bhat"}, {"name": "Justin Hsu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.5220/0007566307940800"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.5220/0007566307940800", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1901.09657v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.09657v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11th International Conference on Agents and Artificial Intelligence\n  (ICAART 2019)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.03957v1", "updated": "2019-08-11T19:51:48Z", "published": "2019-08-11T19:51:48Z", "title": "Tensor Factorization with Label Information for Fake News Detection", "summary": "The buzz over the so-called \"fake news\" has created concerns about a\ndegenerated media environment and led to the need for technological solutions.\nAs the detection of fake news is increasingly considered a technological\nproblem, it has attracted considerable research. Most of these studies\nprimarily focus on utilizing information extracted from textual news content.\nIn contrast, we focus on detecting fake news solely based on structural\ninformation of social networks. We suggest that the underlying network\nconnections of users that share fake news are discriminative enough to support\nthe detection of fake news. Thereupon, we model each post as a network of\nfriendship interactions and represent a collection of posts as a\nmultidimensional tensor. Taking into account the available labeled data, we\npropose a tensor factorization method which associates the class labels of data\nsamples with their latent representations. Specifically, we combine a\nclassification error term with the standard factorization in a unified\noptimization process. Results on real-world datasets demonstrate that our\nproposed method is competitive against state-of-the-art methods by implementing\nan arguably simpler approach.", "author": [{"name": "Frosso Papanastasiou"}, {"name": "Georgios Katsimpras"}, {"name": "Georgios Paliouras"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Presented at the Workshop on Reducing Online Misinformation Exposure\n  ROME 2019"}, "link": [{"@href": "http://arxiv.org/abs/1908.03957v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.03957v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.08516v1", "updated": "2019-11-19T19:24:07Z", "published": "2019-11-19T19:24:07Z", "title": "Sieving Fake News From Genuine: A Synopsis", "summary": "With the rise of social media, it has become easier to disseminate fake news\nfaster and cheaper, compared to traditional news media, such as television and\nnewspapers. Recently this phenomenon has attracted lot of public attention,\nbecause it is causing significant social and financial impacts on their lives\nand businesses. Fake news are responsible for creating false, deceptive,\nmisleading, and suspicious information that can greatly effect the outcome of\nan event. This paper presents a synopsis that explains what are fake news with\nexamples and also discusses some of the current machine learning techniques,\nspecifically natural language processing (NLP) and deep learning, for\nautomatically predicting and detecting fake news. Based on this synopsis, we\nrecommend that there is a potential of using NLP and deep learning to improve\nautomatic detection of fake news, but with the right set of data and features.", "author": [{"name": "Shahid Alam"}, {"name": "Abdulaziz Ravshanbekov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published in the Proceedings of the International Conference on All\n  Aspects of Cyber Security 2019, pp: 67-71"}, "link": [{"@href": "http://arxiv.org/abs/1911.08516v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.08516v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.08789v1", "updated": "2020-04-19T07:42:22Z", "published": "2020-04-19T07:42:22Z", "title": "BanFakeNews: A Dataset for Detecting Fake News in Bangla", "summary": "Observing the damages that can be done by the rapid propagation of fake news\nin various sectors like politics and finance, automatic identification of fake\nnews using linguistic analysis has drawn the attention of the research\ncommunity. However, such methods are largely being developed for English where\nlow resource languages remain out of the focus. But the risks spawned by fake\nand manipulative news are not confined by languages. In this work, we propose\nan annotated dataset of ~50K news that can be used for building automated fake\nnews detection systems for a low resource language like Bangla. Additionally,\nwe provide an analysis of the dataset and develop a benchmark system with state\nof the art NLP techniques to identify Bangla fake news. To create this system,\nwe explore traditional linguistic features and neural network based methods. We\nexpect this dataset will be a valuable resource for building technologies to\nprevent the spreading of fake news and contribute in research with low resource\nlanguages.", "author": [{"name": "Md Zobaer Hossain"}, {"name": "Md Ashraful Rahman"}, {"name": "Md Saiful Islam"}, {"name": "Sudipta Kar"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "LREC 2020"}, "link": [{"@href": "http://arxiv.org/abs/2004.08789v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.08789v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.03159v1", "updated": "2020-10-07T04:55:34Z", "published": "2020-10-07T04:55:34Z", "title": "Where Are the Facts? Searching for Fact-checked Information to Alleviate\n  the Spread of Fake News", "summary": "Although many fact-checking systems have been developed in academia and\nindustry, fake news is still proliferating on social media. These systems\nmostly focus on fact-checking but usually neglect online users who are the main\ndrivers of the spread of misinformation. How can we use fact-checked\ninformation to improve users' consciousness of fake news to which they are\nexposed? How can we stop users from spreading fake news? To tackle these\nquestions, we propose a novel framework to search for fact-checking articles,\nwhich address the content of an original tweet (that may contain\nmisinformation) posted by online users. The search can directly warn fake news\nposters and online users (e.g. the posters' followers) about misinformation,\ndiscourage them from spreading fake news, and scale up verified content on\nsocial media. Our framework uses both text and images to search for\nfact-checking articles, and achieves promising results on real-world datasets.\nOur code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Full paper, EMNLP 2020"}, "link": [{"@href": "http://arxiv.org/abs/2010.03159v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.03159v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.07607v1", "updated": "2020-10-15T09:08:47Z", "published": "2020-10-15T09:08:47Z", "title": "Perceptions of News Sharing and Fake News in Singapore", "summary": "Fake news is a prevalent problem that can undermine citizen engagement and\nbecome an obstacle to the goals of civic tech. To understand consumers'\nreactions and actions towards fake news, and their trust in various news media,\nwe conducted a survey in Singapore. We found that fake news stem largely from\ninstant messaging apps and social media, and that the problem of fake news was\nattributed more to its sharing than to its creation. Verification of news was\ndone mainly by using a search engine to check and cross-reference the news.\nAmongst the top three sources to obtain news, there was low trust reported in\nsocial media, high trust in local news channels, and highest trust in\ngovernment communication platforms. The strong trust in government\ncommunication platforms suggests that top-down civic tech initiatives may have\ngreat potential to effectively manage fake news and promote citizen engagement\nin Singapore.", "author": [{"name": "Gionnieve Lim"}, {"name": "Simon T. Perrault"}], "link": [{"@href": "http://arxiv.org/abs/2010.07607v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.07607v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.11089v1", "updated": "2020-10-16T20:39:57Z", "published": "2020-10-16T20:39:57Z", "title": "Lexicon generation for detecting fake news", "summary": "With the digitization of media, an immense amount of news data has been\ngenerated by online sources, including mainstream media outlets as well as\nsocial networks. However, the ease of production and distribution resulted in\ncirculation of fake news as well as credible, authentic news. The pervasive\ndissemination of fake news has extreme negative impacts on individuals and\nsociety. Therefore, fake news detection has recently become an emerging topic\nas an interdisciplinary research field that is attracting significant attention\nfrom many research disciplines, including social sciences and linguistics. In\nthis study, we propose a method primarily based on lexicons including a scoring\nsystem to facilitate the detection of the fake news in Turkish. We contribute\nto the literature by collecting a novel, large scale, and credible dataset of\nTurkish news, and by constructing the first fake news detection lexicon for\nTurkish.", "author": [{"name": "U\u011fur Merto\u011flu"}, {"name": "Burkay Gen\u00e7"}], "link": [{"@href": "http://arxiv.org/abs/2010.11089v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.11089v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2103.09258v1", "updated": "2021-03-16T18:10:22Z", "published": "2021-03-16T18:10:22Z", "title": "The Rise and Fall of Fake News sites: A Traffic Analysis", "summary": "Over the past decade, we have witnessed the rise of misinformation on the\nInternet, with online users constantly falling victims of fake news. A\nmultitude of past studies have analyzed fake news diffusion mechanics and\ndetection and mitigation techniques. However, there are still open questions\nabout their operational behavior such as: How old are fake news websites? Do\nthey typically stay online for long periods of time? Do such websites\nsynchronize with each other their up and down time? Do they share similar\ncontent through time? Which third-parties support their operations? How much\nuser traffic do they attract, in comparison to mainstream or real news\nwebsites? In this paper, we perform a first of its kind investigation to answer\nsuch questions regarding the online presence of fake news websites and\ncharacterize their behavior in comparison to real news websites. Based on our\nfindings, we build a content-agnostic ML classifier for automatic detection of\nfake news websites (i.e. accuracy) that are not yet included in manually\ncurated blacklists.", "author": [{"name": "Manolis Chalkiadakis"}, {"name": "Alexandros Kornilakis"}, {"name": "Panagiotis Papadopoulos"}, {"name": "Evangelos P. Markatos"}, {"name": "Nicolas Kourtellis"}], "link": [{"@href": "http://arxiv.org/abs/2103.09258v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.09258v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.12312v1", "updated": "2021-07-26T16:33:47Z", "published": "2021-07-26T16:33:47Z", "title": "'No, auntie, that's false': Female baby boomers develop critical skills\n  to confront fake news with guidance from relatives", "summary": "The spread of fake news has been increasing, which gives rise to a special\ninterest in the development of identification and coping skills among news\nconsumers so that they can filter out misleading information. Studies suggest\nthat older people share more fake news from social media. There is scarce\nliterature that analyse how baby boomers behave in the face of fake news. The\npurpose of this study is to examine how female baby boomers deal with fake news\non Facebook and their available resources to learn how to identify and handle\ndubious information. A qualitative study and thematic analysis were conducted\nusing information obtained from interviewing female baby boomers. Four themes\nemerge from the analysis, revealing that participants recognise that they can\nidentify fake news but may not always be able to do so due to limitations in\ntheir understanding of an issue or uncertainty about its source. Participants\nshow participants empirically develop critical identification and filtering\nskills with the assistance from close family members.", "author": [{"name": "Andrea Pecho-Ninapaytan"}, {"name": "Stefany Zambrano-Zuta"}, {"name": "Lizardo Vargas-Bianchi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "14 pages, 1 table"}, "link": [{"@href": "http://arxiv.org/abs/2107.12312v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.12312v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.12601v1", "updated": "2021-08-28T08:25:29Z", "published": "2021-08-28T08:25:29Z", "title": "Mitigation of Diachronic Bias in Fake News Detection Dataset", "summary": "Fake news causes significant damage to society.To deal with these fake news,\nseveral studies on building detection models and arranging datasets have been\nconducted. Most of the fake news datasets depend on a specific time period.\nConsequently, the detection models trained on such a dataset have difficulty\ndetecting novel fake news generated by political changes and social changes;\nthey may possibly result in biased output from the input, including specific\nperson names and organizational names. We refer to this problem as\n\\textbf{Diachronic Bias} because it is caused by the creation date of news in\neach dataset. In this study, we confirm the bias, especially proper nouns\nincluding person names, from the deviation of phrase appearances in each\ndataset. Based on these findings, we propose masking methods using Wikidata to\nmitigate the influence of person names and validate whether they make fake news\ndetection models robust through experiments with in-domain and out-of-domain\ndata.", "author": [{"name": "Taichi Murayama"}, {"name": "Shoko Wakamiya"}, {"name": "Eiji Aramaki"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "7 pages"}, "link": [{"@href": "http://arxiv.org/abs/2108.12601v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.12601v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1912.12520v2", "updated": "2020-01-20T03:03:09Z", "published": "2019-12-28T21:20:25Z", "title": "Weak Supervision for Fake News Detection via Reinforcement Learning", "summary": "Today social media has become the primary source for news. Via social media\nplatforms, fake news travel at unprecedented speeds, reach global audiences and\nput users and communities at great risk. Therefore, it is extremely important\nto detect fake news as early as possible. Recently, deep learning based\napproaches have shown improved performance in fake news detection. However, the\ntraining of such models requires a large amount of labeled data, but manual\nannotation is time-consuming and expensive. Moreover, due to the dynamic nature\nof news, annotated samples may become outdated quickly and cannot represent the\nnews articles on newly emerged events. Therefore, how to obtain fresh and\nhigh-quality labeled samples is the major challenge in employing deep learning\nmodels for fake news detection. In order to tackle this challenge, we propose a\nreinforced weakly-supervised fake news detection framework, i.e., WeFEND, which\ncan leverage users' reports as weak supervision to enlarge the amount of\ntraining data for fake news detection. The proposed framework consists of three\nmain components: the annotator, the reinforced selector and the fake news\ndetector. The annotator can automatically assign weak labels for unlabeled news\nbased on users' reports. The reinforced selector using reinforcement learning\ntechniques chooses high-quality samples from the weakly labeled data and\nfilters out those low-quality ones that may degrade the detector's prediction\nperformance. The fake news detector aims to identify fake news based on the\nnews content. We tested the proposed framework on a large collection of news\narticles published via WeChat official accounts and associated user reports.\nExtensive experiments on this dataset show that the proposed WeFEND model\nachieves the best performance compared with the state-of-the-art methods.", "author": [{"name": "Yaqing Wang"}, {"name": "Weifeng Yang"}, {"name": "Fenglong Ma"}, {"name": "Jin Xu"}, {"name": "Bin Zhong"}, {"name": "Qiang Deng"}, {"name": "Jing Gao"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AAAI 2020"}, "link": [{"@href": "http://arxiv.org/abs/1912.12520v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.12520v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.09025v2", "updated": "2018-03-02T16:57:43Z", "published": "2017-11-24T15:53:37Z", "title": "Fake News Detection in Social Networks via Crowd Signals", "summary": "Our work considers leveraging crowd signals for detecting fake news and is\nmotivated by tools recently introduced by Facebook that enable users to flag\nfake news. By aggregating users' flags, our goal is to select a small subset of\nnews every day, send them to an expert (e.g., via a third-party fact-checking\norganization), and stop the spread of news identified as fake by an expert. The\nmain objective of our work is to minimize the spread of misinformation by\nstopping the propagation of fake news in the network. It is especially\nchallenging to achieve this objective as it requires detecting fake news with\nhigh-confidence as quickly as possible. We show that in order to leverage\nusers' flags efficiently, it is crucial to learn about users' flagging\naccuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian\ninference for detecting fake news and jointly learns about users' flagging\naccuracy over time. Our algorithm employs posterior sampling to actively trade\noff exploitation (selecting news that maximize the objective value at a given\nepoch) and exploration (selecting news that maximize the value of information\ntowards learning about users' flagging accuracy). We demonstrate the\neffectiveness of our approach via extensive experiments and show the power of\nleveraging community signals for fake news detection.", "author": [{"name": "Sebastian Tschiatschek"}, {"name": "Adish Singla"}, {"name": "Manuel Gomez Rodriguez"}, {"name": "Arpit Merchant"}, {"name": "Andreas Krause"}], "link": [{"@href": "http://arxiv.org/abs/1711.09025v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.09025v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1703.09398v1", "updated": "2017-03-28T04:47:11Z", "published": "2017-03-28T04:47:11Z", "title": "This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive\n  Content in Text Body, More Similar to Satire than Real News", "summary": "The problem of fake news has gained a lot of attention as it is claimed to\nhave had a significant impact on 2016 US Presidential Elections. Fake news is\nnot a new problem and its spread in social networks is well-studied. Often an\nunderlying assumption in fake news discussion is that it is written to look\nlike real news, fooling the reader who does not check for reliability of the\nsources or the arguments in its content. Through a unique study of three data\nsets and features that capture the style and the language of articles, we show\nthat this assumption is not true. Fake news in most cases is more similar to\nsatire than to real news, leading us to conclude that persuasion in fake news\nis achieved through heuristics rather than the strength of arguments. We show\noverall title structure and the use of proper nouns in titles are very\nsignificant in differentiating fake from real. This leads us to conclude that\nfake news is targeted for audiences who are not likely to read beyond titles\nand is aimed at creating mental associations between entities and claims.", "author": [{"name": "Benjamin D. Horne"}, {"name": "Sibel Adali"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at The 2nd International Workshop on News and Public\n  Opinion at ICWSM"}, "link": [{"@href": "http://arxiv.org/abs/1703.09398v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1703.09398v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.01160v2", "updated": "2019-11-05T20:45:25Z", "published": "2019-10-02T18:47:17Z", "title": "Identifying Nuances in Fake News vs. Satire: Using Semantic and\n  Linguistic Cues", "summary": "The blurry line between nefarious fake news and protected-speech satire has\nbeen a notorious struggle for social media platforms. Further to the efforts of\nreducing exposure to misinformation on social media, purveyors of fake news\nhave begun to masquerade as satire sites to avoid being demoted. In this work,\nwe address the challenge of automatically classifying fake news versus satire.\nPrevious work have studied whether fake news and satire can be distinguished\nbased on language differences. Contrary to fake news, satire stories are\nusually humorous and carry some political or social message. We hypothesize\nthat these nuances could be identified using semantic and linguistic cues.\nConsequently, we train a machine learning method using semantic representation,\nwith a state-of-the-art contextual language model, and with linguistic features\nbased on textual coherence metrics. Empirical evaluation attests to the merits\nof our approach compared to the language-based baseline and sheds light on the\nnuances between fake news and satire. As avenues for future work, we consider\nstudying additional linguistic features related to the humor aspect, and\nenriching the data with current news events, to help identify a political or\nsocial message.", "author": [{"name": "Or Levi"}, {"name": "Pedram Hosseini"}, {"name": "Mona Diab"}, {"name": "David A. Broniatowski"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.18653/v1/D19-5004"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.18653/v1/D19-5004", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1910.01160v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.01160v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the 2nd Workshop on NLP for Internet Freedom (NLP4IF):\n  Censorship, Disinformation, and Propaganda. Co-located with EMNLP-IJCNLP 2019"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1803.03443v3", "updated": "2019-04-16T02:11:50Z", "published": "2018-03-09T10:04:00Z", "title": "Fake news propagate differently from real news even at early stages of\n  spreading", "summary": "Social media can be a double-edged sword for society, either as a convenient\nchannel exchanging ideas or as an unexpected conduit circulating fake news\nthrough a large population. While existing studies of fake news focus on\ntheoretical modeling of propagation or identification methods based on machine\nlearning, it is important to understand the realistic mechanisms between\ntheoretical models and black-box methods. Here we track large databases of fake\nnews and real news in both, Weibo in China and Twitter in Japan from different\nculture, which include their complete traces of re-postings. We find in both\nonline social networks that fake news spreads distinctively from real news even\nat early stages of propagation, e.g. five hours after the first re-postings.\nOur finding demonstrates collective structural signals that help to understand\nthe different propagation evolution of fake news and real news. Different from\nearlier studies, identifying the topological properties of the information\npropagation at early stages may offer novel features for early detection of\nfake news in social media.", "author": [{"name": "Zilong Zhao"}, {"name": "Jichang Zhao"}, {"name": "Yukie Sano"}, {"name": "Orr levy"}, {"name": "Hideki Takayasu"}, {"name": "Misako Takayasu"}, {"name": "Daqing Li"}, {"name": "Junjie Wu"}, {"name": "Shlomo Havlin"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "35pages, 6 groups of figures"}, "link": [{"@href": "http://arxiv.org/abs/1803.03443v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1803.03443v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.01048v2", "updated": "2020-09-27T10:15:06Z", "published": "2020-09-01T01:26:01Z", "title": "MALCOM: Generating Malicious Comments to Attack Neural Fake News\n  Detection Models", "summary": "In recent years, the proliferation of so-called \"fake news\" has caused much\ndisruptions in society and weakened the news ecosystem. Therefore, to mitigate\nsuch problems, researchers have developed state-of-the-art models to\nauto-detect fake news on social media using sophisticated data science and\nmachine learning techniques. In this work, then, we ask \"what if adversaries\nattempt to attack such detection models?\" and investigate related issues by (i)\nproposing a novel threat model against fake news detectors, in which\nadversaries can post malicious comments toward news articles to mislead fake\nnews detectors, and (ii) developing MALCOM, an end-to-end adversarial comment\ngeneration framework to achieve such an attack. Through a comprehensive\nevaluation, we demonstrate that about 94% and 93.5% of the time on average\nMALCOM can successfully mislead five of the latest neural detection models to\nalways output targeted real and fake news labels. Furthermore, MALCOM can also\nfool black box fake news detectors to always output real news labels 90% of the\ntime on average. We also compare our attack model with four baselines across\ntwo real-world datasets, not only on attack performance but also on generated\nquality, coherency, transferability, and robustness.", "author": [{"name": "Thai Le"}, {"name": "Suhang Wang"}, {"name": "Dongwon Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at the 20th IEEE International Conference on Data Mining\n  (ICDM 2020)"}, "link": [{"@href": "http://arxiv.org/abs/2009.01048v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.01048v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.01579v2", "updated": "2021-01-29T12:10:26Z", "published": "2020-11-03T09:09:51Z", "title": "Fake News Detection through Graph Comment Advanced Learning", "summary": "Disinformation has long been regarded as a severe social problem, where fake\nnews is one of the most representative issues. What is worse, today's highly\ndeveloped social media makes fake news widely spread at incredible speed,\nbringing in substantial harm to various aspects of human life. Yet, the\npopularity of social media also provides opportunities to better detect fake\nnews. Unlike conventional means which merely focus on either content or user\ncomments, effective collaboration of heterogeneous social media information,\nincluding content and context factors of news, users' comments and the\nengagement of social media with users, will hopefully give rise to better\ndetection of fake news.\n  Motivated by the above observations, a novel detection framework, namely\ngraph comment-user advanced learning framework (GCAL) is proposed in this\npaper. User-comment information is crucial but not well studied in fake news\ndetection. Thus, we model user-comment context through network representation\nlearning based on heterogeneous graph neural network. We conduct experiments on\ntwo real-world datasets, which demonstrate that the proposed joint model\noutperforms 8 state-of-the-art baseline methods for fake news detection (at\nleast 4% in Accuracy, 7% in Recall and 5% in F1). Moreover, the proposed method\nis also explainable.", "author": [{"name": "Hao Liao"}, {"name": "Qixin Liu"}, {"name": "Kai Shu"}, {"name": "Xing xie"}], "link": [{"@href": "http://arxiv.org/abs/2011.01579v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.01579v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.04012v2", "updated": "2021-01-13T17:18:02Z", "published": "2021-01-11T16:39:03Z", "title": "Evaluating Deep Learning Approaches for Covid19 Fake News Detection", "summary": "Social media platforms like Facebook, Twitter, and Instagram have enabled\nconnection and communication on a large scale. It has revolutionized the rate\nat which information is shared and enhanced its reach. However, another side of\nthe coin dictates an alarming story. These platforms have led to an increase in\nthe creation and spread of fake news. The fake news has not only influenced\npeople in the wrong direction but also claimed human lives. During these\ncritical times of the Covid19 pandemic, it is easy to mislead people and make\nthem believe in fatal information. Therefore it is important to curb fake news\nat source and prevent it from spreading to a larger audience. We look at\nautomated techniques for fake news detection from a data mining perspective. We\nevaluate different supervised text classification algorithms on Contraint@AAAI\n2021 Covid-19 Fake news detection dataset. The classification algorithms are\nbased on Convolutional Neural Networks (CNN), Long Short Term Memory (LSTM),\nand Bidirectional Encoder Representations from Transformers (BERT). We also\nevaluate the importance of unsupervised learning in the form of language model\npre-training and distributed word representations using unlabelled covid tweets\ncorpus. We report the best accuracy of 98.41\\% on the Covid-19 Fake news\ndetection dataset.", "author": [{"name": "Apurva Wani"}, {"name": "Isha Joshi"}, {"name": "Snehal Khandve"}, {"name": "Vedangi Wagh"}, {"name": "Raviraj Joshi"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-73696-5_15"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-73696-5_15", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2101.04012v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.04012v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at Contraint@AAAI 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.08924v3", "updated": "2021-04-13T08:38:02Z", "published": "2021-02-17T18:30:43Z", "title": "Cross-SEAN: A Cross-Stitch Semi-Supervised Neural Attention Model for\n  COVID-19 Fake News Detection", "summary": "As the COVID-19 pandemic sweeps across the world, it has been accompanied by\na tsunami of fake news and misinformation on social media. At the time when\nreliable information is vital for public health and safety, COVID-19 related\nfake news has been spreading even faster than the facts. During times such as\nthe COVID-19 pandemic, fake news can not only cause intellectual confusion but\ncan also place lives of people at risk. This calls for an immediate need to\ncontain the spread of such misinformation on social media. We introduce CTF,\nthe first COVID-19 Twitter fake news dataset with labeled genuine and fake\ntweets. Additionally, we propose Cross-SEAN, a cross-stitch based\nsemi-supervised end-to-end neural attention model, which leverages the large\namount of unlabelled data. Cross-SEAN partially generalises to emerging fake\nnews as it learns from relevant external knowledge. We compare Cross-SEAN with\nseven state-of-the-art fake news detection methods. We observe that it achieves\n$0.95$ F1 Score on CTF, outperforming the best baseline by $9\\%$. We also\ndevelop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time\ndetection of fake tweets.", "author": [{"name": "William Scott Paka"}, {"name": "Rachit Bansal"}, {"name": "Abhay Kaushik"}, {"name": "Shubhashis Sengupta"}, {"name": "Tanmoy Chakraborty"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The Journal of Applied Soft Computing"}, "link": [{"@href": "http://arxiv.org/abs/2102.08924v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.08924v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.09114v1", "updated": "2021-05-19T13:18:02Z", "published": "2021-05-19T13:18:02Z", "title": "Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment", "summary": "The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations.", "author": [{"name": "Bimal Bhattarai"}, {"name": "Ole-Christoffer Granmo"}, {"name": "Lei Jiao"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 4 figures, 4 tables"}, "link": [{"@href": "http://arxiv.org/abs/2105.09114v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.09114v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2; I.5; I.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.03550v1", "updated": "2020-05-07T15:21:56Z", "published": "2020-05-07T15:21:56Z", "title": "Credulous Users and Fake News: a Real Case Study on the Propagation in\n  Twitter", "summary": "Recent studies have confirmed a growing trend, especially among youngsters,\nof using Online Social Media as favourite information platform at the expense\nof traditional mass media. Indeed, they can easily reach a wide audience at a\nhigh speed; but exactly because of this they are the preferred medium for\ninfluencing public opinion via so-called fake news. Moreover, there is a\ngeneral agreement that the main vehicle of fakes news are malicious software\nrobots (bots) that automatically interact with human users. In previous work we\nhave considered the problem of tagging human users in Online Social Networks as\ncredulous users. Specifically, we have considered credulous those users with\nrelatively high number of bot friends when compared to total number of their\nsocial friends. We consider this group of users worth of attention because they\nmight have a higher exposure to malicious activities and they may contribute to\nthe spreading of fake information by sharing dubious content. In this work,\nstarting from a dataset of fake news, we investigate the behaviour and the\ndegree of involvement of credulous users in fake news diffusion. The study aims\nto: (i) fight fake news by considering the content diffused by credulous users;\n(ii) highlight the relationship between credulous users and fake news\nspreading; (iii) target fake news detection by focusing on the analysis of\nspecific accounts more exposed to malicious activities of bots. Our first\nresults demonstrate a strong involvement of credulous users in fake news\ndiffusion. This findings are calling for tools that, by performing data\nstreaming on credulous' users actions, enables us to perform targeted\nfact-checking.", "author": [{"name": "Alessandro Balestrucci"}, {"name": "Rocco De Nicola"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages and 8 tables. Accepted to appear in the Proceedings at IEEE\n  Conference on Evolving and Adaptive Intelligent Systems (EAIS2020)"}, "link": [{"@href": "http://arxiv.org/abs/2005.03550v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.03550v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1702.05638v1", "updated": "2017-02-18T18:10:04Z", "published": "2017-02-18T18:10:04Z", "title": "A Stylometric Inquiry into Hyperpartisan and Fake News", "summary": "This paper reports on a writing style analysis of hyperpartisan (i.e.,\nextremely one-sided) news in connection to fake news. It presents a large\ncorpus of 1,627 articles that were manually fact-checked by professional\njournalists from BuzzFeed. The articles originated from 9 well-known political\npublishers, 3 each from the mainstream, the hyperpartisan left-wing, and the\nhyperpartisan right-wing. In sum, the corpus contains 299 fake news, 97% of\nwhich originated from hyperpartisan publishers.\n  We propose and demonstrate a new way of assessing style similarity between\ntext categories via Unmasking---a meta-learning approach originally devised for\nauthorship verification---, revealing that the style of left-wing and\nright-wing news have a lot more in common than any of the two have with the\nmainstream. Furthermore, we show that hyperpartisan news can be discriminated\nwell by its style from the mainstream (F1=0.78), as can be satire from both\n(F1=0.81). Unsurprisingly, style-based fake news detection does not live up to\nscratch (F1=0.46). Nevertheless, the former results are important to implement\npre-screening for fake news detectors.", "author": [{"name": "Martin Potthast"}, {"name": "Johannes Kiesel"}, {"name": "Kevin Reinartz"}, {"name": "Janek Bevendorff"}, {"name": "Benno Stein"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 3 figures, 6 tables, submitted to ACL 2017"}, "link": [{"@href": "http://arxiv.org/abs/1702.05638v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1702.05638v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1703.07823v2", "updated": "2017-06-19T20:59:29Z", "published": "2017-03-22T19:09:12Z", "title": "Fake News Mitigation via Point Process Based Intervention", "summary": "We propose the first multistage intervention framework that tackles fake news\nin social networks by combining reinforcement learning with a point process\nnetwork activity model. The spread of fake news and mitigation events within\nthe network is modeled by a multivariate Hawkes process with additional\nexogenous control terms. By choosing a feature representation of states,\ndefining mitigation actions and constructing reward functions to measure the\neffectiveness of mitigation activities, we map the problem of fake news\nmitigation into the reinforcement learning framework. We develop a policy\niteration method unique to the multivariate networked point process, with the\ngoal of optimizing the actions for maximal total reward under budget\nconstraints. Our method shows promising performance in real-time intervention\nexperiments on a Twitter network to mitigate a surrogate fake news campaign,\nand outperforms alternatives on synthetic datasets.", "author": [{"name": "Mehrdad Farajtabar"}, {"name": "Jiachen Yang"}, {"name": "Xiaojing Ye"}, {"name": "Huan Xu"}, {"name": "Rakshit Trivedi"}, {"name": "Elias Khalil"}, {"name": "Shuang Li"}, {"name": "Le Song"}, {"name": "Hongyuan Zha"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Point Process, Hawkes Process, Social Networks, Intervention and\n  Control, Reinforcement Learning, ICML 2017"}, "link": [{"@href": "http://arxiv.org/abs/1703.07823v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1703.07823v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.04670v1", "updated": "2018-11-12T11:40:09Z", "published": "2018-11-12T11:40:09Z", "title": "A Deep Ensemble Framework for Fake News Detection and Classification", "summary": "Fake news, rumor, incorrect information, and misinformation detection are\nnowadays crucial issues as these might have serious consequences for our social\nfabrics. The rate of such information is increasing rapidly due to the\navailability of enormous web information sources including social media feeds,\nnews blogs, online newspapers etc.\n  In this paper, we develop various deep learning models for detecting fake\nnews and classifying them into the pre-defined fine-grained categories.\n  At first, we develop models based on Convolutional Neural Network (CNN) and\nBi-directional Long Short Term Memory (Bi-LSTM) networks. The representations\nobtained from these two models are fed into a Multi-layer Perceptron Model\n(MLP) for the final classification. Our experiments on a benchmark dataset show\npromising results with an overall accuracy of 44.87\\%, which outperforms the\ncurrent state of the art.", "author": [{"name": "Arjun Roy"}, {"name": "Kingshuk Basak"}, {"name": "Asif Ekbal"}, {"name": "Pushpak Bhattacharyya"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 1 figure, accepted as a short paper in Web Intelligence 2018\n  (https://webintelligence2018.com/accepted-papers.html), title changed from\n  {\"Going Deep to Detect Liars\" Detecting Fake News using Deep Learning} to {A\n  Deep Ensemble Framework for Fake News Detection and Classification} as per\n  reviewers suggestion"}, "link": [{"@href": "http://arxiv.org/abs/1811.04670v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.04670v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1705.01613v2", "updated": "2018-05-30T21:08:44Z", "published": "2017-05-03T20:34:19Z", "title": "Automatically Identifying Fake News in Popular Twitter Threads", "summary": "Information quality in social media is an increasingly important issue, but\nweb-scale data hinders experts' ability to assess and correct much of the\ninaccurate content, or `fake news,' present in these platforms. This paper\ndevelops a method for automating fake news detection on Twitter by learning to\npredict accuracy assessments in two credibility-focused Twitter datasets:\nCREDBANK, a crowdsourced dataset of accuracy assessments for events in Twitter,\nand PHEME, a dataset of potential rumors in Twitter and journalistic\nassessments of their accuracies. We apply this method to Twitter content\nsourced from BuzzFeed's fake news dataset and show models trained against\ncrowdsourced workers outperform models based on journalists' assessment and\nmodels trained on a pooled dataset of both crowdsourced workers and\njournalists. All three datasets, aligned into a uniform format, are also\npublicly available. A feature analysis then identifies features that are most\npredictive for crowdsourced and journalistic accuracy assessments, results of\nwhich are consistent with prior work. We close with a discussion contrasting\naccuracy and credibility and why models of non-experts outperform models of\njournalists for fake news detection in Twitter.", "author": [{"name": "Cody Buntain"}, {"name": "Jennifer Golbeck"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/SmartCloud.2017.40"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/SmartCloud.2017.40", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1705.01613v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1705.01613v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "2017 IEEE International Conference on Smart Cloud (SmartCloud)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1803.08491v2", "updated": "2019-03-20T14:53:31Z", "published": "2018-03-22T17:53:09Z", "title": "Influence of fake news in Twitter during the 2016 US presidential\n  election", "summary": "The dynamics and influence of fake news on Twitter during the 2016 US\npresidential election remains to be clarified. Here, we use a dataset of 171\nmillion tweets in the five months preceding the election day to identify 30\nmillion tweets, from 2.2 million users, which contain a link to news outlets.\nBased on a classification of news outlets curated by www.opensources.co, we\nfind that 25% of these tweets spread either fake or extremely biased news. We\ncharacterize the networks of information flow to find the most influential\nspreaders of fake and traditional news and use causal modeling to uncover how\nfake news influenced the presidential election. We find that, while top\ninfluencers spreading traditional center and left leaning news largely\ninfluence the activity of Clinton supporters, this causality is reversed for\nthe fake news: the activity of Trump supporters influences the dynamics of the\ntop fake news spreaders.", "author": [{"name": "Alexandre Bovet"}, {"name": "Hernan A. Makse"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1038/s41467-018-07761-2"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1038/s41467-018-07761-2", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1803.08491v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1803.08491v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Updated to latest revised version"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Nat. Commun. 10, 7 (2019)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1806.11316v1", "updated": "2018-06-29T09:36:46Z", "published": "2018-06-29T09:36:46Z", "title": "Fake News Identification on Twitter with Hybrid CNN and RNN Models", "summary": "The problem associated with the propagation of fake news continues to grow at\nan alarming scale. This trend has generated much interest from politics to\nacademia and industry alike. We propose a framework that detects and classifies\nfake news messages from Twitter posts using hybrid of convolutional neural\nnetworks and long-short term recurrent neural network models. The proposed work\nusing this deep learning approach achieves 82% accuracy. Our approach\nintuitively identifies relevant features associated with fake news stories\nwithout previous knowledge of the domain.", "author": [{"name": "Oluwaseun Ajao"}, {"name": "Deepayan Bhowmik"}, {"name": "Shahrzad Zargari"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3217804.3217917"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3217804.3217917", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1806.11316v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.11316v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 Pages"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Oluwaseun Ajao, Deepayan Bhowmik, and Shahrzad Zargari. 2018. Fake\n  News Identification on Twitter with Hybrid CNN and RNN Models. In Proceedings\n  of the International Conference on Social Media & Society, Copenhagen,\n  Denmark (SMSociety)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1901.06437v1", "updated": "2019-01-18T22:57:09Z", "published": "2019-01-18T22:57:09Z", "title": "Combating Fake News: A Survey on Identification and Mitigation\n  Techniques", "summary": "The proliferation of fake news on social media has opened up new directions\nof research for timely identification and containment of fake news, and\nmitigation of its widespread impact on public opinion. While much of the\nearlier research was focused on identification of fake news based on its\ncontents or by exploiting users' engagements with the news on social media,\nthere has been a rising interest in proactive intervention strategies to\ncounter the spread of misinformation and its impact on society. In this survey,\nwe describe the modern-day problem of fake news and, in particular, highlight\nthe technical challenges associated with it. We discuss existing methods and\ntechniques applicable to both identification and mitigation, with a focus on\nthe significant advances in each method and their advantages and limitations.\nIn addition, research has often been limited by the quality of existing\ndatasets and their specific application contexts. To alleviate this problem, we\ncomprehensively compile and summarize characteristic features of available\ndatasets. Furthermore, we outline new directions of research to facilitate\nfuture development of effective and interdisciplinary solutions.", "author": [{"name": "Karishma Sharma"}, {"name": "Feng Qian"}, {"name": "He Jiang"}, {"name": "Natali Ruchansky"}, {"name": "Ming Zhang"}, {"name": "Yan Liu"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACM Transactions on Intelligent Systems and Technology, 2019"}, "link": [{"@href": "http://arxiv.org/abs/1901.06437v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.06437v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1903.11899v1", "updated": "2019-03-28T11:24:30Z", "published": "2019-03-28T11:24:30Z", "title": "Using Blockchain to Rein in The New Post-Truth World and Check The\n  Spread of Fake News", "summary": "In recent years, `fake news' has become a global issue that raises\nunprecedented challenges for human society and democracy. This problem has\narisen due to the emergence of various concomitant phenomena such as (1) the\ndigitization of human life and the ease of disseminating news through social\nnetworking applications (such as Facebook and WhatsApp); (2) the availability\nof `big data' that allows customization of news feeds and the creation of\npolarized so-called `filter-bubbles'; and (3) the rapid progress made by\ngenerative machine learning (ML) and deep learning (DL) algorithms in creating\nrealistic-looking yet fake digital content (such as text, images, and videos).\nThere is a crucial need to combat the rampant rise of fake news and\ndisinformation. In this paper, we propose a high-level overview of a\nblockchain-based framework for fake news prevention and highlight the various\ndesign issues and consideration of such a blockchain-based framework for\ntackling fake news.", "author": [{"name": "Adnan Qayyum"}, {"name": "Junaid Qadir"}, {"name": "Muhammad Umar Janjua"}, {"name": "Falak Sher"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This paper has been accepted at IEEE IT Professional magazine.\n  Personal use of this material is permitted, permission from IEEE must be\n  obtained for all other uses"}, "link": [{"@href": "http://arxiv.org/abs/1903.11899v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.11899v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1905.00957v1", "updated": "2019-05-02T20:50:22Z", "published": "2019-05-02T20:50:22Z", "title": "A Topic-Agnostic Approach for Identifying Fake News Pages", "summary": "Fake news and misinformation have been increasingly used to manipulate\npopular opinion and influence political processes. To better understand fake\nnews, how they are propagated, and how to counter their effect, it is necessary\nto first identify them. Recently, approaches have been proposed to\nautomatically classify articles as fake based on their content. An important\nchallenge for these approaches comes from the dynamic nature of news: as new\npolitical events are covered, topics and discourse constantly change and thus,\na classifier trained using content from articles published at a given time is\nlikely to become ineffective in the future. To address this challenge, we\npropose a topic-agnostic (TAG) classification strategy that uses linguistic and\nweb-markup features to identify fake news pages. We report experimental results\nusing multiple data sets which show that our approach attains high accuracy in\nthe identification of fake news, even as topics evolve over time.", "author": [{"name": "Sonia Castelo"}, {"name": "Thais Almeida"}, {"name": "Anas Elghafari"}, {"name": "A\u00e9cio Santos"}, {"name": "Kien Pham"}, {"name": "Eduardo Nakamura"}, {"name": "Juliana Freire"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3308560.3316739"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3308560.3316739", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1905.00957v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.00957v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication in the Companion Proceedings of the 2019\n  World Wide Web Conference (WWW'19 Companion). Presented in the 2019\n  International Workshop on Misinformation, Computational Fact-Checking and\n  Credible Web (MisinfoWorkshop2019). 6 pages"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.04260v1", "updated": "2019-05-10T17:00:40Z", "published": "2019-05-10T17:00:40Z", "title": "Check-It: A Plugin for Detecting and Reducing the Spread of Fake News\n  and Misinformation on the Web", "summary": "Over the past few years, we have been witnessing the rise of misinformation\non the Web. People fall victims of fake news during their daily lives and\nassist their further propagation knowingly and inadvertently. There have been\nmany initiatives that are trying to mitigate the damage caused by fake news,\nfocusing on signals from either domain flag-lists, online social networks or\nartificial intelligence. In this work, we present Check-It, a system that\ncombines, in an intelligent way, a variety of signals into a pipeline for fake\nnews identification. Check-It is developed as a web browser plugin with the\nobjective of efficient and timely fake news detection, respecting the user's\nprivacy. Experimental results show that Check-It is able to outperform the\nstate-of-the-art methods. On a dataset, consisting of 9 millions of articles\nlabeled as fake and real, Check-It obtains classification accuracies that\nexceed 99%.", "author": [{"name": "Demetris Paschalides"}, {"name": "Alexandros Kornilakis"}, {"name": "Chrysovalantis Christodoulou"}, {"name": "Rafael Andreou"}, {"name": "George Pallis"}, {"name": "Marios D. Dikaiakos"}, {"name": "Evangelos Markatos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 6 figures,"}, "link": [{"@href": "http://arxiv.org/abs/1905.04260v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.04260v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.11126v2", "updated": "2020-08-15T08:45:35Z", "published": "2019-06-26T14:33:18Z", "title": "On the Coherence of Fake News Articles", "summary": "The generation and spread of fake news within new and online media sources is\nemerging as a phenomenon of high societal significance. Combating them using\ndata-driven analytics has been attracting much recent scholarly interest. In\nthis study, we analyze the textual coherence of fake news articles vis-a-vis\nlegitimate ones. We develop three computational formulations of textual\ncoherence drawing upon the state-of-the-art methods in natural language\nprocessing and data science. Two real-world datasets from widely different\ndomains which have fake/legitimate article labellings are then analyzed with\nrespect to textual coherence. We observe apparent differences in textual\ncoherence across fake and legitimate news articles, with fake news articles\nconsistently scoring lower on coherence as compared to legitimate news ones.\nWhile the relative coherence shortfall of fake news articles as compared to\nlegitimate ones form the main observation from our study, we analyze several\naspects of the differences and outline potential avenues of further inquiry.", "author": [{"name": "Iknoor Singh"}, {"name": "Deepak P"}, {"name": "Anoop K"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8th International Workshop on News Recommendation and Analytics (INRA\n  2020) held in conjunction with ECML PKDD 2020 Conference"}, "link": [{"@href": "http://arxiv.org/abs/1906.11126v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.11126v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.02214v1", "updated": "2020-01-07T18:26:38Z", "published": "2020-01-07T18:26:38Z", "title": "Attributed Multi-Relational Attention Network for Fact-checking URL\n  Recommendation", "summary": "To combat fake news, researchers mostly focused on detecting fake news and\njournalists built and maintained fact-checking sites (e.g., Snopes.com and\nPolitifact.com). However, fake news dissemination has been greatly promoted via\nsocial media sites, and these fact-checking sites have not been fully utilized.\nTo overcome these problems and complement existing methods against fake news,\nin this paper we propose a deep-learning based fact-checking URL recommender\nsystem to mitigate impact of fake news in social media sites such as Twitter\nand Facebook. In particular, our proposed framework consists of a\nmulti-relational attentive module and a heterogeneous graph attention network\nto learn complex/semantic relationship between user-URL pairs, user-user pairs,\nand URL-URL pairs. Extensive experiments on a real-world dataset show that our\nproposed framework outperforms eight state-of-the-art recommendation models,\nachieving at least 3~5.3% improvement.", "author": [{"name": "Di You"}, {"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}, {"name": "Qiang Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CIKM2019"}, "link": [{"@href": "http://arxiv.org/abs/2001.02214v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.02214v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.00838v1", "updated": "2020-01-28T00:44:59Z", "published": "2020-01-28T00:44:59Z", "title": "Improving Generalizability of Fake News Detection Methods using\n  Propensity Score Matching", "summary": "Recently, due to the booming influence of online social networks, detecting\nfake news is drawing significant attention from both academic communities and\ngeneral public. In this paper, we consider the existence of confounding\nvariables in the features of fake news and use Propensity Score Matching (PSM)\nto select generalizable features in order to reduce the effects of the\nconfounding variables. Experimental results show that the generalizability of\nfake news method is significantly better by using PSM than using raw frequency\nto select features. We investigate multiple types of fake news methods\n(classifiers) such as logistic regression, random forests, and support vector\nmachines. We have consistent observations of performance improvement.", "author": [{"name": "Bo Ni"}, {"name": "Zhichun Guo"}, {"name": "Jianing Li"}, {"name": "Meng Jiang"}], "link": [{"@href": "http://arxiv.org/abs/2002.00838v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.00838v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.04981v1", "updated": "2020-02-19T02:51:04Z", "published": "2020-02-19T02:51:04Z", "title": "SAFE: Similarity-Aware Multi-Modal Fake News Detection", "summary": "Effective detection of fake news has recently attracted significant\nattention. Current studies have made significant contributions to predicting\nfake news with less focus on exploiting the relationship (similarity) between\nthe textual and visual information in news articles. Attaching importance to\nsuch similarity helps identify fake news stories that, for example, attempt to\nuse irrelevant images to attract readers' attention. In this work, we propose a\n$\\mathsf{S}$imilarity-$\\mathsf{A}$ware $\\mathsf{F}$ak$\\mathsf{E}$ news\ndetection method ($\\mathsf{SAFE}$) which investigates multi-modal (textual and\nvisual) information of news articles. First, neural networks are adopted to\nseparately extract textual and visual features for news representation. We\nfurther investigate the relationship between the extracted features across\nmodalities. Such representations of news textual and visual information along\nwith their relationship are jointly learned and used to predict fake news. The\nproposed method facilitates recognizing the falsity of news articles based on\ntheir text, images, or their \"mismatches.\" We conduct extensive experiments on\nlarge-scale real-world data, which demonstrate the effectiveness of the\nproposed method.", "author": [{"name": "Xinyi Zhou"}, {"name": "Jindi Wu"}, {"name": "Reza Zafarani"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To be published in The 24th Pacific-Asia Conference on Knowledge\n  Discovery and Data Mining (PAKDD 2020)"}, "link": [{"@href": "http://arxiv.org/abs/2003.04981v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.04981v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.10399v3", "updated": "2020-08-27T09:07:02Z", "published": "2020-04-22T05:37:17Z", "title": "Anger makes fake news viral online", "summary": "Fake news that manipulates political elections, strikes financial systems,\nand even incites riots is more viral than real news online, resulting in\nunstable societies and buffeted democracy. The easier contagion of fake news\nonline can be causally explained by the greater anger it carries. The same\nresults in Twitter and Weibo indicate that this mechanism is independent of the\nplatform. Moreover, mutations in emotions like increasing anger will\nprogressively speed up the information spread. Specifically, increasing the\noccupation of anger by 0.1 and reducing that of joy by 0.1 will produce nearly\n6 more retweets in the Weibo dataset. Offline questionnaires reveal that anger\nleads to more incentivized audiences in terms of anxiety management and\ninformation sharing and accordingly makes fake news more contagious than real\nnews online. Cures such as tagging anger in social media could be implemented\nto slow or prevent the contagion of fake news at the source.", "author": [{"name": "Yuwei Chuai"}, {"name": "Jichang Zhao"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "All data used in this study can be publicly available through\n  https://doi.org/10.6084/m9.figshare.12163569.v2"}, "link": [{"@href": "http://arxiv.org/abs/2004.10399v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.10399v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.14083v1", "updated": "2020-07-28T09:32:41Z", "published": "2020-07-28T09:32:41Z", "title": "Universal Fake News Collection System using Debunking Tweets", "summary": "Large numbers of people use Social Networking Services (SNS) for easy access\nto various news, but they have more opportunities to obtain and share ``fake\nnews'' carrying false information. Partially to combat fake news, several\nfact-checking sites such as Snopes and PolitiFact have been founded.\nNevertheless, these sites rely on time-consuming and labor-intensive tasks.\nMoreover, their available languages are not extensive. To address these\ndifficulties, we propose a new fake news collection system based on rule-based\n(unsupervised) frameworks that can be extended easily for various languages.\nThe system collects news with high probability of being fake by debunking\ntweets by users and presents event clusters gathering higher attention. Our\nsystem currently functions in two languages: English and Japanese. It shows\nevent clusters, 65\\% of which are actually fake. In future studies, it will be\napplied to other languages and will be published with a large fake news\ndataset.", "author": [{"name": "Taichi Murayama"}, {"name": "Shoko Wakamiya"}, {"name": "Eiji Aramaki"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5pages, 2 figures"}, "link": [{"@href": "http://arxiv.org/abs/2007.14083v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.14083v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2009.13367v2", "updated": "2021-03-01T12:32:57Z", "published": "2020-09-28T14:35:31Z", "title": "Similarity Detection Pipeline for Crawling a Topic Related Fake News\n  Corpus", "summary": "Fake news detection is a challenging task aiming to reduce human time and\neffort to check the truthfulness of news. Automated approaches to combat fake\nnews, however, are limited by the lack of labeled benchmark datasets,\nespecially in languages other than English. Moreover, many publicly available\ncorpora have specific limitations that make them difficult to use. To address\nthis problem, our contribution is threefold. First, we propose a new, publicly\navailable German topic related corpus for fake news detection. To the best of\nour knowledge, this is the first corpus of its kind. In this regard, we\ndeveloped a pipeline for crawling similar news articles. As our third\ncontribution, we conduct different learning experiments to detect fake news.\nThe best performance was achieved using sentence level embeddings from SBERT in\ncombination with a Bi-LSTM (k=0.88).", "author": [{"name": "Inna Vogel"}, {"name": "Jeong-Eun Choi"}, {"name": "Meghana Meghana"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Further development done"}, "link": [{"@href": "http://arxiv.org/abs/2009.13367v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.13367v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.00452v1", "updated": "2020-11-01T08:56:56Z", "published": "2020-11-01T08:56:56Z", "title": "Fake or Real? A Study of Arabic Satirical Fake News", "summary": "One very common type of fake news is satire which comes in a form of a news\nwebsite or an online platform that parodies reputable real news agencies to\ncreate a sarcastic version of reality. This type of fake news is often\ndisseminated by individuals on their online platforms as it has a much stronger\neffect in delivering criticism than through a straightforward message. However,\nwhen the satirical text is disseminated via social media without mention of its\nsource, it can be mistaken for real news. This study conducts several\nexploratory analyses to identify the linguistic properties of Arabic fake news\nwith satirical content. We exploit these features to build a number of machine\nlearning models capable of identifying satirical fake news with an accuracy of\nup to 98.6%.", "author": [{"name": "Hadeel Saadany"}, {"name": "Emad Mohamed"}, {"name": "Constantin Orasan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages"}, "link": [{"@href": "http://arxiv.org/abs/2011.00452v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.00452v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.00180v3", "updated": "2021-01-21T15:18:40Z", "published": "2021-01-01T06:49:27Z", "title": "Transformer based Automatic COVID-19 Fake News Detection System", "summary": "Recent rapid technological advancements in online social networks such as\nTwitter have led to a great incline in spreading false information and fake\nnews. Misinformation is especially prevalent in the ongoing coronavirus disease\n(COVID-19) pandemic, leading to individuals accepting bogus and potentially\ndeleterious claims and articles. Quick detection of fake news can reduce the\nspread of panic and confusion among the public. For our analysis in this paper,\nwe report a methodology to analyze the reliability of information shared on\nsocial media pertaining to the COVID-19 pandemic. Our best approach is based on\nan ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting\nfake news. This model was trained and evaluated in the context of the\nConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our\nsystem obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.", "author": [{"name": "Sunil Gundapu"}, {"name": "Radhika Mamidi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "First Workshop on Combating Online Hostile Posts in Regional\n  Languages during Emergency Situation, 12 pages"}, "link": [{"@href": "http://arxiv.org/abs/2101.00180v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.00180v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.05701v1", "updated": "2021-01-14T16:25:32Z", "published": "2021-01-14T16:25:32Z", "title": "TUDublin team at Constraint@AAAI2021 -- COVID19 Fake News Detection", "summary": "The paper is devoted to the participation of the TUDublin team in\nConstraint@AAAI2021 - COVID19 Fake News Detection Challenge. Today, the problem\nof fake news detection is more acute than ever in connection with the pandemic.\nThe number of fake news is increasing rapidly and it is necessary to create AI\ntools that allow us to identify and prevent the spread of false information\nabout COVID-19 urgently. The main goal of the work was to create a model that\nwould carry out a binary classification of messages from social media as real\nor fake news in the context of COVID-19. Our team constructed the ensemble\nconsisting of Bidirectional Long Short Term Memory, Support Vector Machine,\nLogistic Regression, Naive Bayes and a combination of Logistic Regression and\nNaive Bayes. The model allowed us to achieve 0.94 F1-score, which is within 5\\%\nof the best result.", "author": [{"name": "Elena Shushkevich"}, {"name": "John Cardiff"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages"}, "link": [{"@href": "http://arxiv.org/abs/2101.05701v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.05701v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.04458v1", "updated": "2021-02-08T21:36:00Z", "published": "2021-02-08T21:36:00Z", "title": "Detecting Fake News Using Machine Learning : A Systematic Literature\n  Review", "summary": "Internet is one of the important inventions and a large number of persons are\nits users. These persons use this for different purposes. There are different\nsocial media platforms that are accessible to these users. Any user can make a\npost or spread the news through the online platforms. These platforms do not\nverify the users or their posts. So some of the users try to spread fake news\nthrough these platforms. These news can be propaganda against an individual,\nsociety, organization or political party. A human being is unable to detect all\nthese fake news. So there is a need for machine learning classifiers that can\ndetect these fake news automatically. Use of machine learning classifiers for\ndetecting fake news is described in this systematic literature review.", "author": [{"name": "Alim Al Ayub Ahmed"}, {"name": "Ayman Aljabouh"}, {"name": "Praveen Kumar Donepudi"}, {"name": "Myung Suh Choi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 2 figures"}, "link": [{"@href": "http://arxiv.org/abs/2102.04458v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.04458v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.11476v2", "updated": "2021-04-27T05:16:15Z", "published": "2021-04-23T08:47:54Z", "title": "Multimodal Fusion with BERT and Attention Mechanism for Fake News\n  Detection", "summary": "Fake news detection is an important task for increasing the credibility of\ninformation on the media since fake news is constantly spreading on social\nmedia every day and it is a very serious concern in our society. Fake news is\nusually created by manipulating images, texts, and videos. In this paper, we\npresent a novel method for detecting fake news by fusing multimodal features\nderived from textual and visual data. Specifically, we used a pre-trained BERT\nmodel to learn text features and a VGG-19 model pre-trained on the ImageNet\ndataset to extract image features. We proposed a scale-dot product attention\nmechanism to capture the relationship between text features and visual\nfeatures. Experimental results showed that our approach performs better than\nthe current state-of-the-art method on a public Twitter dataset by 3.1%\naccuracy.", "author": [{"name": "Nguyen Manh Duc Tuan"}, {"name": "Pham Quang Nhat Minh"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RIVF 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.11476v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.11476v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2105.08929v1", "updated": "2021-05-19T05:24:13Z", "published": "2021-05-19T05:24:13Z", "title": "Three prophylactic interventions to counter fake news on social media", "summary": "Fake news on Social Media undermines democratic institutions and processes.\nEspecially since 2016, researchers from many disciplines have focussed on ways\nto address the phenomenon. Much of the research focus to date has been on\nidentification and understanding the nature of the phenomenon in and between\nsocial networks and of a rather reactive nature. We propose interventions that\nfocus on individual user empowerment, and social media structural change that\nis prophylactic (pre exposure), rather than therapeutic (post exposure) with\nthe goal of reducing the population exposed to fake news. We investigate\ninterventions that result in greater user elaboration (cognitive effort) before\nexposure to fake news. We propose three interventions i) psychological\ninoculation, ii) fostering digital and media literacy and iii) imposition of\nuser transaction costs. Each intervention promises to illicit greater cognitive\neffort in message evaluation and reduce the likelihood of creating, sharing,\nliking and consuming 'fake news'.", "author": [{"name": "David A. Eccles"}, {"name": "Tilman Dingler"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "7 pages"}, "link": [{"@href": "http://arxiv.org/abs/2105.08929v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.08929v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.4; K.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.10671v1", "updated": "2021-05-22T09:26:13Z", "published": "2021-05-22T09:26:13Z", "title": "SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?", "summary": "Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges.", "author": [{"name": "Tanveer Khan"}, {"name": "Antonis Michalas"}, {"name": "Adnan Akhunzada"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "34 pages, 3 figures"}, "link": [{"@href": "http://arxiv.org/abs/2105.10671v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.10671v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.10648v1", "updated": "2021-07-04T07:09:59Z", "published": "2021-07-04T07:09:59Z", "title": "DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection", "summary": "Fake News on social media platforms has attracted a lot of attention in\nrecent times, primarily for events related to politics (2016 US Presidential\nelections), healthcare (infodemic during COVID-19), to name a few. Various\nmethods have been proposed for detecting Fake News. The approaches span from\nexploiting techniques related to network analysis, Natural Language Processing\n(NLP), and the usage of Graph Neural Networks (GNNs). In this work, we propose\nDEAP-FAKED, a knowleDgE grAPh FAKe nEws Detection framework for identifying\nFake News. Our approach is a combination of the NLP -- where we encode the news\ncontent, and the GNN technique -- where we encode the Knowledge Graph (KG). A\nvariety of these encodings provides a complementary advantage to our detector.\nWe evaluate our framework using two publicly available datasets containing\narticles from domains such as politics, business, technology, and healthcare.\nAs part of dataset pre-processing, we also remove the bias, such as the source\nof the articles, which could impact the performance of the models. DEAP-FAKED\nobtains an F1-score of 88% and 78% for the two datasets, which is an\nimprovement of 21%, and 3% respectively, which shows the effectiveness of the\napproach.", "author": [{"name": "Mohit Mayank"}, {"name": "Shakshi Sharma"}, {"name": "Rajesh Sharma"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8"}, "link": [{"@href": "http://arxiv.org/abs/2107.10648v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.10648v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1804.03508v1", "updated": "2018-03-31T09:48:20Z", "published": "2018-03-31T09:48:20Z", "title": "Seeing Through Misinformation: A Framework for Identifying Fake Online\n  News", "summary": "The fake news epidemic makes it imperative to develop a diagnostic framework\nthat is both parsimonious and valid to guide present and future efforts in fake\nnews detection. This paper represents one of the very first attempts to fill a\nvoid in the research on this topic. The LeSiE (Lexical Structure, Simplicity,\nEmotion) framework we created and validated allows lay people to identify\npotential fake news without the use of calculators or complex statistics by\nlooking out for three simple cues.", "author": [{"name": "Murphy Choy"}, {"name": "Mark Chong"}], "link": [{"@href": "http://arxiv.org/abs/1804.03508v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.03508v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.09118v2", "updated": "2020-12-17T01:56:29Z", "published": "2020-12-16T18:01:04Z", "title": "Exploring Thematic Coherence in Fake News", "summary": "The spread of fake news remains a serious global issue; understanding and\ncurtailing it is paramount. One way of differentiating between deceptive and\ntruthful stories is by analyzing their coherence. This study explores the use\nof topic models to analyze the coherence of cross-domain news shared online.\nExperimental results on seven cross-domain datasets demonstrate that fake news\nshows a greater thematic deviation between its opening sentences and its\nremainder.", "author": [{"name": "Martins Samuel Dogo"}, {"name": "Deepak P"}, {"name": "Anna Jurek-Loughrey"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 1 figure, to be published in Proceedings of the 8th\n  International Workshop on News Recommendation and Analytics (INRA 2020)"}, "link": [{"@href": "http://arxiv.org/abs/2012.09118v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.09118v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1706.05924v2", "updated": "2017-07-17T17:17:37Z", "published": "2017-06-19T13:26:41Z", "title": "\"Everything I Disagree With is #FakeNews\": Correlating Political\n  Polarization and Spread of Misinformation", "summary": "An important challenge in the process of tracking and detecting the\ndissemination of misinformation is to understand the political gap between\npeople that engage with the so called \"fake news\". A possible factor\nresponsible for this gap is opinion polarization, which may prompt the general\npublic to classify content that they disagree or want to discredit as fake. In\nthis work, we study the relationship between political polarization and content\nreported by Twitter users as related to \"fake news\". We investigate how\npolarization may create distinct narratives on what misinformation actually is.\nWe perform our study based on two datasets collected from Twitter. The first\ndataset contains tweets about US politics in general, from which we compute the\ndegree of polarization of each user towards the Republican and Democratic\nParty. In the second dataset, we collect tweets and URLs that co-occurred with\n\"fake news\" related keywords and hashtags, such as #FakeNews and\n#AlternativeFact, as well as reactions towards such tweets and URLs. We then\nanalyze the relationship between polarization and what is perceived as\nmisinformation, and whether users are designating information that they\ndisagree as fake. Our results show an increase in the polarization of users and\nURLs associated with fake-news keywords and hashtags, when compared to\ninformation not labeled as \"fake news\". We discuss the impact of our findings\non the challenges of tracking \"fake news\" in the ongoing battle against\nmisinformation.", "author": [{"name": "Manoel Horta Ribeiro"}, {"name": "Pedro H. Calais"}, {"name": "Virg\u00edlio A. F. Almeida"}, {"name": "Wagner Meira Jr"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 10 figures, to be presented at DS+J Workshop @ KDD'17"}, "link": [{"@href": "http://arxiv.org/abs/1706.05924v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1706.05924v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1808.09922v1", "updated": "2018-08-29T16:50:16Z", "published": "2018-08-29T16:50:16Z", "title": "Limiting the Spread of Fake News on Social Media Platforms by Evaluating\n  Users' Trustworthiness", "summary": "Today's social media platforms enable to spread both authentic and fake news\nvery quickly. Some approaches have been proposed to automatically detect such\n\"fake\" news based on their content, but it is difficult to agree on universal\ncriteria of authenticity (which can be bypassed by adversaries once known).\nBesides, it is obviously impossible to have each news item checked by a human.\n  In this paper, we a mechanism to limit the spread of fake news which is not\nbased on content. It can be implemented as a plugin on a social media platform.\nThe principle is as follows: a team of fact-checkers reviews a small number of\nnews items (the most popular ones), which enables to have an estimation of each\nuser's inclination to share fake news items. Then, using a Bayesian approach,\nwe estimate the trustworthiness of future news items, and treat accordingly\nthose of them that pass a certain \"untrustworthiness\" threshold.\n  We then evaluate the effectiveness and overhead of this technique on a large\nTwitter graph. We show that having a few thousands users exposed to one given\nnews item enables to reach a very precise estimation of its reliability. We\nthus identify more than 99% of fake news items with no false positives. The\nperformance impact is very small: the induced overhead on the 90th percentile\nlatency is less than 3%, and less than 8% on the throughput of user operations.", "author": [{"name": "Oana Balmau"}, {"name": "Rachid Guerraoui"}, {"name": "Anne-Marie Kermarrec"}, {"name": "Alexandre Maurer"}, {"name": "Matej Pavlovic"}, {"name": "Willy Zwaenepoel"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 9 figures"}, "link": [{"@href": "http://arxiv.org/abs/1808.09922v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.09922v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1905.04749v2", "updated": "2021-03-26T05:30:08Z", "published": "2019-05-12T17:15:11Z", "title": "A Benchmark Study of Machine Learning Models for Online Fake News\n  Detection", "summary": "The proliferation of fake news and its propagation on social media has become\na major concern due to its ability to create devastating impacts. Different\nmachine learning approaches have been suggested to detect fake news. However,\nmost of those focused on a specific type of news (such as political) which\nleads us to the question of dataset-bias of the models used. In this research,\nwe conducted a benchmark study to assess the performance of different\napplicable machine learning approaches on three different datasets where we\naccumulated the largest and most diversified one. We explored a number of\nadvanced pre-trained language models for fake news detection along with the\ntraditional and deep learning ones and compared their performances from\ndifferent aspects for the first time to the best of our knowledge. We find that\nBERT and similar pre-trained models perform the best for fake news detection,\nespecially with very small dataset. Hence, these models are significantly\nbetter option for languages with limited electronic contents, i.e., training\ndata. We also carried out several analysis based on the models' performance,\narticle's topic, article's length, and discussed different lessons learned from\nthem. We believe that this benchmark study will help the research community to\nexplore further and news sites/blogs to select the most appropriate fake news\ndetection method.", "author": [{"name": "Junaed Younus Khan"}, {"name": "Md. Tawkat Islam Khondaker"}, {"name": "Sadia Afroz"}, {"name": "Gias Uddin"}, {"name": "Anindya Iqbal"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.mlwa.2021.100032"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.mlwa.2021.100032", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1905.04749v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.04749v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "22 pages, 5 figures, to be published in Machine Learning with\n  Applications journal"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Machine Learning with Applications: 4(2021).100032"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.07595v1", "updated": "2020-03-17T09:24:22Z", "published": "2020-03-17T09:24:22Z", "title": "FakeYou! -- A Gamified Approach for Building and Evaluating Resilience\n  Against Fake News", "summary": "Nowadays fake news are heavily discussed in public and political debates.\nEven though the phenomenon of intended false information is rather old,\nmisinformation reaches a new level with the rise of the internet and\nparticipatory platforms. Due to Facebook and Co., purposeful false information\n- often called fake news - can be easily spread by everyone. Because of a high\ndata volatility and variety in content types (text, images,...) debunking of\nfake news is a complex challenge. This is especially true for automated\napproaches, which are prone to fail validating the veracity of the information.\nThis work focuses on an a gamified approach to strengthen the resilience of\nconsumers towards fake news. The game FakeYou motivates its players to\ncritically analyze headlines regarding their trustworthiness. Further, the game\nfollows a \"learning by doing strategy\": by generating own fake headlines, users\nshould experience the concepts of convincing fake headline formulations. We\nintroduce the game itself, as well as the underlying technical infrastructure.\nA first evaluation study shows, that users tend to use specific stylistic\ndevices to generate fake news. Further, the results indicate, that creating\ngood fakes and identifying correct headlines are challenging and hard to learn.", "author": [{"name": "Lena Clever"}, {"name": "Dennis Assenmacher"}, {"name": "Kilian M\u00fcller"}, {"name": "Moritz Vinzent Seiler"}, {"name": "Dennis M. Riehle"}, {"name": "Mike Preuss"}, {"name": "Christian Grimme"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "accepted for Disinformation in Open Online Media - 2nd\n  Multidisciplinary International Symposium, MISDOOM 2020"}, "link": [{"@href": "http://arxiv.org/abs/2003.07595v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.07595v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.03450v1", "updated": "2020-08-08T05:59:25Z", "published": "2020-08-08T05:59:25Z", "title": "Network Inference from a Mixture of Diffusion Models for Fake News\n  Mitigation", "summary": "The dissemination of fake news intended to deceive people, influence public\nopinion and manipulate social outcomes, has become a pressing problem on social\nmedia. Moreover, information sharing on social media facilitates diffusion of\nviral information cascades. In this work, we focus on understanding and\nleveraging diffusion dynamics of false and legitimate contents in order to\nfacilitate network interventions for fake news mitigation. We analyze\nreal-world Twitter datasets comprising fake and true news cascades, to\nunderstand differences in diffusion dynamics and user behaviours with regards\nto fake and true contents. Based on the analysis, we model the diffusion as a\nmixture of Independent Cascade models (MIC) with parameters $\\theta_T,\n\\theta_F$ over the social network graph; and derive unsupervised inference\ntechniques for parameter estimation of the diffusion mixture model from\nobserved, unlabeled cascades. Users influential in the propagation of true and\nfake contents are identified using the inferred diffusion dynamics.\nCharacteristics of the identified influential users reveal positive correlation\nbetween influential users identified for fake news and their relative\nappearance in fake news cascades. Identified influential users tend to be\nrelated to topics of more viral information cascades than less viral ones; and\nidentified fake news influential users have relatively fewer counts of direct\nfollowers, compared to the true news influential users. Intervention analysis\non nodes and edges demonstrates capacity of the inferred diffusion dynamics in\nsupporting network interventions for mitigation.", "author": [{"name": "Karishma Sharma"}, {"name": "Xinran He"}, {"name": "Sungyong Seo"}, {"name": "Yan Liu"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Fifteenth international AAAI conference on web and social media\n  (ICWSM 2021)"}, "link": [{"@href": "http://arxiv.org/abs/2008.03450v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.03450v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.05509v2", "updated": "2021-01-18T15:53:22Z", "published": "2021-01-14T09:05:42Z", "title": "Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake\n  News Detection", "summary": "With the pandemic of COVID-19, relevant fake news is spreading all over the\nsky throughout the social media. Believing in them without discrimination can\ncause great trouble to people's life. However, universal language models may\nperform weakly in these fake news detection for lack of large-scale annotated\ndata and sufficient semantic understanding of domain-specific knowledge. While\nthe model trained on corresponding corpora is also mediocre for insufficient\nlearning. In this paper, we propose a novel transformer-based language model\nfine-tuning approach for these fake news detection. First, the token vocabulary\nof individual model is expanded for the actual semantics of professional\nphrases. Second, we adapt the heated-up softmax loss to distinguish the\nhard-mining samples, which are common for fake news because of the\ndisambiguation of short text. Then, we involve adversarial training to improve\nthe model's robustness. Last, the predicted features extracted by universal\nlanguage model RoBERTa and domain-specific model CT-BERT are fused by one\nmultiple layer perception to integrate fine-grained and high-level specific\nrepresentations. Quantitative experimental results evaluated on existing\nCOVID-19 fake news dataset show its superior performances compared to the\nstate-of-the-art methods among various evaluation metrics. Furthermore, the\nbest weighted average F1 score achieves 99.02%.", "author": [{"name": "Ben Chen"}, {"name": "Bin Chen"}, {"name": "Dehong Gao"}, {"name": "Qijin Chen"}, {"name": "Chengfu Huo"}, {"name": "Xiaonan Meng"}, {"name": "Weijun Ren"}, {"name": "Yang Zhou"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 1 figures"}, "link": [{"@href": "http://arxiv.org/abs/2101.05509v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.05509v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.01791v1", "updated": "2021-04-05T06:35:30Z", "published": "2021-04-05T06:35:30Z", "title": "A Heuristic-driven Uncertainty based Ensemble Framework for Fake News\n  Detection in Tweets and News Articles", "summary": "The significance of social media has increased manifold in the past few\ndecades as it helps people from even the most remote corners of the world to\nstay connected. With the advent of technology, digital media has become more\nrelevant and widely used than ever before and along with this, there has been a\nresurgence in the circulation of fake news and tweets that demand immediate\nattention. In this paper, we describe a novel Fake News Detection system that\nautomatically identifies whether a news item is \"real\" or \"fake\", as an\nextension of our work in the CONSTRAINT COVID-19 Fake News Detection in English\nchallenge. We have used an ensemble model consisting of pre-trained models\nfollowed by a statistical feature fusion network , along with a novel heuristic\nalgorithm by incorporating various attributes present in news items or tweets\nlike source, username handles, URL domains and authors as statistical feature.\nOur proposed framework have also quantified reliable predictive uncertainty\nalong with proper class output confidence level for the classification task. We\nhave evaluated our results on the COVID-19 Fake News dataset and FakeNewsNet\ndataset to show the effectiveness of the proposed algorithm on detecting fake\nnews in short news content as well as in news articles. We obtained a best\nF1-score of 0.9892 on the COVID-19 dataset, and an F1-score of 0.9073 on the\nFakeNewsNet dataset.", "author": [{"name": "Sourya Dipta Das"}, {"name": "Ayan Basak"}, {"name": "Saikat Dutta"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "submitted to Neurocomputing. arXiv admin note: substantial text\n  overlap with arXiv:2101.03545"}, "link": [{"@href": "http://arxiv.org/abs/2104.01791v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.01791v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.10272v1", "updated": "2021-05-21T10:46:43Z", "published": "2021-05-21T10:46:43Z", "title": "Stance Detection with BERT Embeddings for Credibility Analysis of\n  Information on Social Media", "summary": "The evolution of electronic media is a mixed blessing. Due to the easy\naccess, low cost, and faster reach of the information, people search out and\ndevour news from online social networks. In contrast, the increasing acceptance\nof social media reporting leads to the spread of fake news. This is a minacious\nproblem that causes disputes and endangers societal stability and harmony. Fake\nnews spread has gained attention from researchers due to its vicious nature.\nproliferation of misinformation in all media, from the internet to cable news,\npaid advertising and local news outlets, has made it essential for people to\nidentify the misinformation and sort through the facts. Researchers are trying\nto analyze the credibility of information and curtail false information on such\nplatforms. Credibility is the believability of the piece of information at\nhand. Analyzing the credibility of fake news is challenging due to the intent\nof its creation and the polychromatic nature of the news. In this work, we\npropose a model for detecting fake news. Our method investigates the content of\nthe news at the early stage i.e. when the news is published but is yet to be\ndisseminated through social media. Our work interprets the content with\nautomatic feature extraction and the relevance of the text pieces. In summary,\nwe introduce stance as one of the features along with the content of the\narticle and employ the pre-trained contextualized word embeddings BERT to\nobtain the state-of-art results for fake news detection. The experiment\nconducted on the real-world dataset indicates that our model outperforms the\nprevious work and enables fake news detection with an accuracy of 95.32%.", "author": [{"name": "Hema Karande"}, {"name": "Rahee Walambe"}, {"name": "Victor Benjamin"}, {"name": "Ketan Kotecha"}, {"name": "T. S. Raghu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.7717/peerj-cs.467"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.7717/peerj-cs.467", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2105.10272v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.10272v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.13711v1", "updated": "2021-06-22T21:21:29Z", "published": "2021-06-22T21:21:29Z", "title": "Multimodal Emergent Fake News Detection via Meta Neural Process Networks", "summary": "Fake news travels at unprecedented speeds, reaches global audiences and puts\nusers and communities at great risk via social media platforms. Deep learning\nbased models show good performance when trained on large amounts of labeled\ndata on events of interest, whereas the performance of models tends to degrade\non other events due to domain shift. Therefore, significant challenges are\nposed for existing detection approaches to detect fake news on emergent events,\nwhere large-scale labeled datasets are difficult to obtain. Moreover, adding\nthe knowledge from newly emergent events requires to build a new model from\nscratch or continue to fine-tune the model, which can be challenging,\nexpensive, and unrealistic for real-world settings. In order to address those\nchallenges, we propose an end-to-end fake news detection framework named\nMetaFEND, which is able to learn quickly to detect fake news on emergent events\nwith a few verified posts. Specifically, the proposed model integrates\nmeta-learning and neural process methods together to enjoy the benefits of\nthese approaches. In particular, a label embedding module and a hard attention\nmechanism are proposed to enhance the effectiveness by handling categorical\ninformation and trimming irrelevant posts. Extensive experiments are conducted\non multimedia datasets collected from Twitter and Weibo. The experimental\nresults show our proposed MetaFEND model can detect fake news on never-seen\nevents effectively and outperform the state-of-the-art methods.", "author": [{"name": "Yaqing Wang"}, {"name": "Fenglong Ma"}, {"name": "Haoyu Wang"}, {"name": "Kishlay Jha"}, {"name": "Jing Gao"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3447548.3467153"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3447548.3467153", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2106.13711v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.13711v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "accepted by KDD 2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.04418v1", "updated": "2021-08-10T02:58:34Z", "published": "2021-08-10T02:58:34Z", "title": "Knowledge Enhanced Multi-modal Fake News Detection", "summary": "Recent years have witnessed the significant damage caused by various types of\nfake news. Although considerable effort has been applied to address this issue\nand much progress has been made on detecting fake news, most existing\napproaches mainly rely on the textual content and/or social context, while\nknowledge-level information---entities extracted from the news content and the\nrelations between them---is much less explored. Within the limited work on\nknowledge-based fake news detection, an external knowledge graph is often\nrequired, which may introduce additional problems: it is quite common for\nentities and relations, especially with respect to new concepts, to be missing\nin existing knowledge graphs, and both entity prediction and link prediction\nare open research questions themselves. Therefore, in this work, we investigate\n\\textbf{knowledge-based fake news detection that does not require any external\nknowledge graph.} Specifically, our contributions include: (1) transforming the\nproblem of detecting fake news into a subgraph classification task---entities\nand relations are extracted from each news item to form a single knowledge\ngraph, where a news item is represented by a subgraph. Then a graph neural\nnetwork (GNN) model is trained to classify each subgraph/news item. (2) Further\nimproving the performance of this model through a simple but effective\nmulti-modal technique that combines extracted knowledge, textual content and\nsocial context. Experiments on multiple datasets with thousands of labelled\nnews items demonstrate that our knowledge-based algorithm outperforms existing\ncounterpart methods, and its performance can be further boosted by the\nmulti-modal approach.", "author": [{"name": "Yi Han"}, {"name": "Amila Silva"}, {"name": "Ling Luo"}, {"name": "Shanika Karunasekera"}, {"name": "Christopher Leckie"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 4 figures"}, "link": [{"@href": "http://arxiv.org/abs/2108.04418v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.04418v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.10509v1", "updated": "2021-08-24T03:36:07Z", "published": "2021-08-24T03:36:07Z", "title": "Improving Fake News Detection by Using an Entity-enhanced Framework to\n  Fuse Diverse Multimodal Clues", "summary": "Recently, fake news with text and images have achieved more effective\ndiffusion than text-only fake news, raising a severe issue of multimodal fake\nnews detection. Current studies on this issue have made significant\ncontributions to developing multimodal models, but they are defective in\nmodeling the multimodal content sufficiently. Most of them only preliminarily\nmodel the basic semantics of the images as a supplement to the text, which\nlimits their performance on detection. In this paper, we find three valuable\ntext-image correlations in multimodal fake news: entity inconsistency, mutual\nenhancement, and text complementation. To effectively capture these multimodal\nclues, we innovatively extract visual entities (such as celebrities and\nlandmarks) to understand the news-related high-level semantics of images, and\nthen model the multimodal entity inconsistency and mutual enhancement with the\nhelp of visual entities. Moreover, we extract the embedded text in images as\nthe complementation of the original text. All things considered, we propose a\nnovel entity-enhanced multimodal fusion framework, which simultaneously models\nthree cross-modal correlations to detect diverse multimodal fake news.\nExtensive experiments demonstrate the superiority of our model compared to the\nstate of the art.", "author": [{"name": "Peng Qi"}, {"name": "Juan Cao"}, {"name": "Xirong Li"}, {"name": "Huan Liu"}, {"name": "Qiang Sheng"}, {"name": "Xiaoyue Mi"}, {"name": "Qin He"}, {"name": "Yongbiao Lv"}, {"name": "Chenyang Guo"}, {"name": "Yingchao Yu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3474085.3481548"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3474085.3481548", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.10509v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.10509v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear in MM 2021 industrial track (long paper)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1902.06673v1", "updated": "2019-02-10T15:21:45Z", "published": "2019-02-10T15:21:45Z", "title": "Fake News Detection on Social Media using Geometric Deep Learning", "summary": "Social media are nowadays one of the main news sources for millions of people\naround the globe due to their low cost, easy access and rapid dissemination.\nThis however comes at the cost of dubious trustworthiness and significant risk\nof exposure to 'fake news', intentionally written to mislead the readers.\nAutomatically detecting fake news poses challenges that defy existing\ncontent-based analysis approaches. One of the main reasons is that often the\ninterpretation of the news requires the knowledge of political or social\ncontext or 'common sense', which current NLP algorithms are still missing.\nRecent studies have shown that fake and real news spread differently on social\nmedia, forming propagation patterns that could be harnessed for the automatic\nfake news detection. Propagation-based approaches have multiple advantages\ncompared to their content-based counterparts, among which is language\nindependence and better resilience to adversarial attacks. In this paper we\nshow a novel automatic fake news detection model based on geometric deep\nlearning. The underlying core algorithms are a generalization of classical CNNs\nto graphs, allowing the fusion of heterogeneous data such as content, user\nprofile and activity, social graph, and news propagation. Our model was trained\nand tested on news stories, verified by professional fact-checking\norganizations, that were spread on Twitter. Our experiments indicate that\nsocial network structure and propagation are important features allowing highly\naccurate (92.7% ROC AUC) fake news detection. Second, we observe that fake news\ncan be reliably detected at an early stage, after just a few hours of\npropagation. Third, we test the aging of our model on training and testing data\nseparated in time. Our results point to the promise of propagation-based\napproaches for fake news detection as an alternative or complementary strategy\nto content-based approaches.", "author": [{"name": "Federico Monti"}, {"name": "Fabrizio Frasca"}, {"name": "Davide Eynard"}, {"name": "Damon Mannion"}, {"name": "Michael M. Bronstein"}], "link": [{"@href": "http://arxiv.org/abs/1902.06673v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.06673v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.05491v2", "updated": "2020-12-13T07:52:18Z", "published": "2020-12-10T07:31:07Z", "title": "An Event Correlation Filtering Method for Fake News Detection", "summary": "Nowadays, social network platforms have been the prime source for people to\nexperience news and events due to their capacities to spread information\nrapidly, which inevitably provides a fertile ground for the dissemination of\nfake news. Thus, it is significant to detect fake news otherwise it could cause\npublic misleading and panic. Existing deep learning models have achieved great\nprogress to tackle the problem of fake news detection. However, training an\neffective deep learning model usually requires a large amount of labeled news,\nwhile it is expensive and time-consuming to provide sufficient labeled news in\nactual applications. To improve the detection performance of fake news, we take\nadvantage of the event correlations of news and propose an event correlation\nfiltering method (ECFM) for fake news detection, mainly consisting of the news\ncharacterizer, the pseudo label annotator, the event credibility updater, and\nthe news entropy selector. The news characterizer is responsible for extracting\ntextual features from news, which cooperates with the pseudo label annotator to\nassign pseudo labels for unlabeled news by fully exploiting the event\ncorrelations of news. In addition, the event credibility updater employs\nadaptive Kalman filter to weaken the credibility fluctuations of events. To\nfurther improve the detection performance, the news entropy selector\nautomatically discovers high-quality samples from pseudo labeled news by\nquantifying their news entropy. Finally, ECFM is proposed to integrate them to\ndetect fake news in an event correlation filtering manner. Extensive\nexperiments prove that the explainable introduction of the event correlations\nof news is beneficial to improve the detection performance of fake news.", "author": [{"name": "Hao Li", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "College of Informatics, Huazhong Agricultural University"}}, {"name": "Huan Wang", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "College of Informatics, Huazhong Agricultural University"}}, {"name": "Guanghua Liu", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Department of Computer Science and Engineering, University at Buffalo, The State University of New York"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "24 pages, 5 figures, 3 tables"}, "link": [{"@href": "http://arxiv.org/abs/2012.05491v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.05491v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1802.01400v1", "updated": "2018-02-05T14:17:21Z", "published": "2018-02-05T14:17:21Z", "title": "Polarization and Fake News: Early Warning of Potential Misinformation\n  Targets", "summary": "Users polarization and confirmation bias play a key role in misinformation\nspreading on online social media. Our aim is to use this information to\ndetermine in advance potential targets for hoaxes and fake news. In this paper,\nwe introduce a general framework for promptly identifying polarizing content on\nsocial media and, thus, \"predicting\" future fake news topics. We validate the\nperformances of the proposed methodology on a massive Italian Facebook dataset,\nshowing that we are able to identify topics that are susceptible to\nmisinformation with 77% accuracy. Moreover, such information may be embedded as\na new feature in an additional classifier able to recognize fake news with 91%\naccuracy. The novelty of our approach consists in taking into account a series\nof characteristics related to users behavior on online social media, making a\nfirst, important step towards the smoothing of polarization and the mitigation\nof misinformation phenomena.", "author": [{"name": "Michela Del Vicario"}, {"name": "Walter Quattrociocchi"}, {"name": "Antonio Scala"}, {"name": "Fabiana Zollo"}], "link": [{"@href": "http://arxiv.org/abs/1802.01400v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1802.01400v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1811.12349v2", "updated": "2018-12-04T16:15:25Z", "published": "2018-11-29T17:54:49Z", "title": "Combating Fake News with Interpretable News Feed Algorithms", "summary": "Nowadays, artificial intelligence algorithms are used for targeted and\npersonalized content distribution in the large scale as part of the intense\ncompetition for attention in the digital media environment. Unfortunately,\ntargeted information dissemination may result in intellectual isolation and\ndiscrimination. Further, as demonstrated in recent political events in the US\nand EU, malicious bots and social media users can create and propagate targeted\n`fake news' content in different forms for political gains. From the other\ndirection, fake news detection algorithms attempt to combat such problems by\nidentifying misinformation and fraudulent user profiles. This paper reviews\ncommon news feed algorithms as well as methods for fake news detection, and we\ndiscuss how news feed algorithms could be misused to promote falsified content,\naffect news diversity, or impact credibility. We review how news feed\nalgorithms and recommender engines can enable confirmation bias to isolate\nusers to certain news sources and affecting the perception of reality. As a\npotential solution for increasing user awareness of how content is selected or\nsorted, we argue for the use of interpretable and explainable news feed\nalgorithms. We discuss how improved user awareness and system transparency\ncould mitigate unwanted outcomes of echo chambers and bubble filters in social\nmedia.", "author": [{"name": "Sina Mohseni"}, {"name": "Eric Ragan"}], "link": [{"@href": "http://arxiv.org/abs/1811.12349v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.12349v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.02202v1", "updated": "2019-10-05T03:23:45Z", "published": "2019-10-05T03:23:45Z", "title": "Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language", "summary": "In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SIGIR 2019"}, "link": [{"@href": "http://arxiv.org/abs/1910.02202v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.02202v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.03496v2", "updated": "2019-10-11T05:36:23Z", "published": "2019-09-29T17:45:48Z", "title": "Fake news detection using Deep Learning", "summary": "The evolution of the information and communication technologies has\ndramatically increased the number of people with access to the Internet, which\nhas changed the way the information is consumed. As a consequence of the above,\nfake news have become one of the major concerns because its potential to\ndestabilize governments, which makes them a potential danger to modern society.\nAn example of this can be found in the US. electoral campaign, where the term\n\"fake news\" gained great notoriety due to the influence of the hoaxes in the\nfinal result of these. In this work the feasibility of applying deep learning\ntechniques to discriminate fake news on the Internet using only their text is\nstudied. In order to accomplish that, three different neural network\narchitectures are proposed, one of them based on BERT, a modern language model\ncreated by Google which achieves state-of-the-art results.", "author": [{"name": "\u00c1lvaro Ibrain Rodr\u00edguez"}, {"name": "Lara Lloret Iglesias"}], "link": [{"@href": "http://arxiv.org/abs/1910.03496v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.03496v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1708.07104v1", "updated": "2017-08-23T17:12:03Z", "published": "2017-08-23T17:12:03Z", "title": "Automatic Detection of Fake News", "summary": "The proliferation of misleading information in everyday access media outlets\nsuch as social media feeds, news blogs, and online newspapers have made it\nchallenging to identify trustworthy news sources, thus increasing the need for\ncomputational tools able to provide insights into the reliability of online\ncontent. In this paper, we focus on the automatic identification of fake\ncontent in online news. Our contribution is twofold. First, we introduce two\nnovel datasets for the task of fake news detection, covering seven different\nnews domains. We describe the collection, annotation, and validation process in\ndetail and present several exploratory analysis on the identification of\nlinguistic differences in fake and legitimate news content. Second, we conduct\na set of learning experiments to build accurate fake news detectors. In\naddition, we provide comparative analyses of the automatic and manual\nidentification of fake news.", "author": [{"name": "Ver\u00f3nica P\u00e9rez-Rosas"}, {"name": "Bennett Kleinberg"}, {"name": "Alexandra Lefevre"}, {"name": "Rada Mihalcea"}], "link": [{"@href": "http://arxiv.org/abs/1708.07104v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1708.07104v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1712.05999v1", "updated": "2017-12-16T18:07:58Z", "published": "2017-12-16T18:07:58Z", "title": "Characterizing Political Fake News in Twitter by its Meta-Data", "summary": "This article presents a preliminary approach towards characterizing political\nfake news on Twitter through the analysis of their meta-data. In particular, we\nfocus on more than 1.5M tweets collected on the day of the election of Donald\nTrump as 45th president of the United States of America. We use the meta-data\nembedded within those tweets in order to look for differences between tweets\ncontaining fake news and tweets not containing them. Specifically, we perform\nour analysis only on tweets that went viral, by studying proxies for users'\nexposure to the tweets, by characterizing accounts spreading fake news, and by\nlooking at their polarization. We found significant differences on the\ndistribution of followers, the number of URLs on tweets, and the verification\nof the users.", "author": [{"name": "Julio Amador"}, {"name": "Axel Oehmichen"}, {"name": "Miguel Molina-Solana"}], "link": [{"@href": "http://arxiv.org/abs/1712.05999v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1712.05999v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1803.03786v1", "updated": "2018-03-10T10:09:13Z", "published": "2018-03-10T10:09:13Z", "title": "We Built a Fake News & Click-bait Filter: What Happened Next Will Blow\n  Your Mind!", "summary": "It is completely amazing! Fake news and click-baits have totally invaded the\ncyber space. Let us face it: everybody hates them for three simple reasons.\nReason #2 will absolutely amaze you. What these can achieve at the time of\nelection will completely blow your mind! Now, we all agree, this cannot go on,\nyou know, somebody has to stop it. So, we did this research on fake\nnews/click-bait detection and trust us, it is totally great research, it really\nis! Make no mistake. This is the best research ever! Seriously, come have a\nlook, we have it all: neural networks, attention mechanism, sentiment lexicons,\nauthor profiling, you name it. Lexical features, semantic features, we\nabsolutely have it all. And we have totally tested it, trust us! We have\nresults, and numbers, really big numbers. The best numbers ever! Oh, and\nanalysis, absolutely top notch analysis. Interested? Come read the shocking\ntruth about fake news and click-bait in the Bulgarian cyber space. You won't\nbelieve what we have found!", "author": [{"name": "Georgi Karadzhov"}, {"name": "Pepa Gencheva"}, {"name": "Preslav Nakov"}, {"name": "Ivan Koychev"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.26615/978-954-452-049-6_045"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.26615/978-954-452-049-6_045", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1803.03786v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1803.03786v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RANLP'2017, 7 pages, 1 figure"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1904.05305v1", "updated": "2019-04-10T17:14:22Z", "published": "2019-04-10T17:14:22Z", "title": "A Classification Algorithm to Recognize Fake News Websites", "summary": "'Fake news' is information that generally spreads on the web, which only\nmimics the form of reliable news media content. The phenomenon has assumed\nuncontrolled proportions in recent years rising the concern of authorities and\ncitizens. In this paper we present a classifier able to distinguish a reliable\nsource from a fake news website. We have prepared a dataset made of 200 fake\nnews websites and 200 reliable websites from all over the world and used as\npredictors information potentially available on websites, such as the presence\nof a 'contact us' section or a secured connection. The algorithm is based on\nlogistic regression, whereas further analyses were carried out using\ntetrachoric correlation coefficients for dichotomous variables and chi-square\ntests. This framework offers a concrete solution to attribute a 'reliability\nscore' to news website, defined as the probability that a source is reliable or\nnot, and on this probability a user can decide if the news is worth sharing or\nnot.", "author": [{"name": "Davide Bennato"}, {"name": "Giuseppe Pernagallo"}, {"name": "Benedetto Torrisi"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-51222-4_25"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-51222-4_25", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1904.05305v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.05305v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 3 figures, 4 tables"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "International Conference on Data Science and Social Research, 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.01030v1", "updated": "2020-02-03T22:13:07Z", "published": "2020-02-03T22:13:07Z", "title": "Detecting Fake News with Capsule Neural Networks", "summary": "Fake news is dramatically increased in social media in recent years. This has\nprompted the need for effective fake news detection algorithms. Capsule neural\nnetworks have been successful in computer vision and are receiving attention\nfor use in Natural Language Processing (NLP). This paper aims to use capsule\nneural networks in the fake news detection task. We use different embedding\nmodels for news items of different lengths. Static word embedding is used for\nshort news items, whereas non-static word embeddings that allow incremental\nup-training and updating in the training phase are used for medium length or\nlarge news statements. Moreover, we apply different levels of n-grams for\nfeature extraction. Our proposed architectures are evaluated on two recent\nwell-known datasets in the field, namely ISOT and LIAR. The results show\nencouraging performance, outperforming the state-of-the-art methods by 7.8% on\nISOT and 3.1% on the validation set, and 1% on the test set of the LIAR\ndataset.", "author": [{"name": "Mohammad Hadi Goldani"}, {"name": "Saeedeh Momtazi"}, {"name": "Reza Safabakhsh"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "25 pages, 4 figures"}, "link": [{"@href": "http://arxiv.org/abs/2002.01030v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.01030v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.10009v1", "updated": "2020-04-21T13:51:03Z", "published": "2020-04-21T13:51:03Z", "title": "Adaptive Interaction Fusion Networks for Fake News Detection", "summary": "The majority of existing methods for fake news detection universally focus on\nlearning and fusing various features for detection. However, the learning of\nvarious features is independent, which leads to a lack of cross-interaction\nfusion between features on social media, especially between posts and comments.\nGenerally, in fake news, there are emotional associations and semantic\nconflicts between posts and comments. How to represent and fuse the\ncross-interaction between both is a key challenge. In this paper, we propose\nAdaptive Interaction Fusion Networks (AIFN) to fulfill cross-interaction fusion\namong features for fake news detection. In AIFN, to discover semantic\nconflicts, we design gated adaptive interaction networks (GAIN) to capture\nadaptively similar semantics and conflicting semantics between posts and\ncomments. To establish feature associations, we devise semantic-level fusion\nself-attention networks (SFSN) to enhance semantic correlations and fusion\namong features. Extensive experiments on two real-world datasets, i.e.,\nRumourEval and PHEME, demonstrate that AIFN achieves the state-of-the-art\nperformance and boosts accuracy by more than 2.05% and 1.90%, respectively.", "author": [{"name": "Lianwei Wu"}, {"name": "Yuan Rao"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at the 24th European Conference on Artificial Intelligence\n  (ECAI 2020)"}, "link": [{"@href": "http://arxiv.org/abs/2004.10009v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.10009v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.04938v1", "updated": "2020-05-11T09:07:46Z", "published": "2020-05-11T09:07:46Z", "title": "A Deep Learning Approach for Automatic Detection of Fake News", "summary": "Fake news detection is a very prominent and essential task in the field of\njournalism. This challenging problem is seen so far in the field of politics,\nbut it could be even more challenging when it is to be determined in the\nmulti-domain platform. In this paper, we propose two effective models based on\ndeep learning for solving fake news detection problem in online news contents\nof multiple domains. We evaluate our techniques on the two recently released\ndatasets, namely FakeNews AMT and Celebrity for fake news detection. The\nproposed systems yield encouraging performance, outperforming the current\nhandcrafted feature engineering based state-of-the-art system with a\nsignificant margin of 3.08% and 9.3% by the two models, respectively. In order\nto exploit the datasets, available for the related tasks, we perform\ncross-domain analysis (i.e. model trained on FakeNews AMT and tested on\nCelebrity and vice versa) to explore the applicability of our systems across\nthe domains.", "author": [{"name": "Tanik Saikh"}, {"name": "Arkadipta De"}, {"name": "Asif Ekbal"}, {"name": "Pushpak Bhattacharyya"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the 16th International Conference on Natural\n  Language Processing (ICON 2019)"}, "link": [{"@href": "http://arxiv.org/abs/2005.04938v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.04938v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.12358v2", "updated": "2020-07-27T03:59:56Z", "published": "2020-07-24T05:42:29Z", "title": "Machine Learning Explanations to Prevent Overtrust in Fake News\n  Detection", "summary": "Combating fake news and misinformation propagation is a challenging task in\nthe post-truth era. News feed and search algorithms could potentially lead to\nunintentional large-scale propagation of false and fabricated information with\nusers being exposed to algorithmically selected false content. Our research\ninvestigates the effects of an Explainable AI assistant embedded in news review\nplatforms for combating the propagation of fake news. We design a news\nreviewing and sharing interface, create a dataset of news stories, and train\nfour interpretable fake news detection algorithms to study the effects of\nalgorithmic transparency on end-users. We present evaluation results and\nanalysis from multiple controlled crowdsourced studies. For a deeper\nunderstanding of Explainable AI systems, we discuss interactions between user\nengagement, mental model, trust, and performance measures in the process of\nexplaining. The study results indicate that explanations helped participants to\nbuild appropriate mental models of the intelligent assistants in different\nconditions and adjust their trust accordingly for model limitations.", "author": [{"name": "Sina Mohseni"}, {"name": "Fan Yang"}, {"name": "Shiva Pentyala"}, {"name": "Mengnan Du"}, {"name": "Yi Liu"}, {"name": "Nic Lupfer"}, {"name": "Xia Hu"}, {"name": "Shuiwang Ji"}, {"name": "Eric Ragan"}], "link": [{"@href": "http://arxiv.org/abs/2007.12358v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.12358v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.03327v4", "updated": "2021-05-26T15:38:55Z", "published": "2020-11-06T13:09:37Z", "title": "Fighting an Infodemic: COVID-19 Fake News Dataset", "summary": "Along with COVID-19 pandemic we are also fighting an `infodemic'. Fake news\nand rumors are rampant on social media. Believing in rumors can cause\nsignificant harm. This is further exacerbated at the time of a pandemic. To\ntackle this, we curate and release a manually annotated dataset of 10,700\nsocial media posts and articles of real and fake news on COVID-19. We benchmark\nthe annotated dataset with four machine learning baselines - Decision Tree,\nLogistic Regression, Gradient Boost, and Support Vector Machine (SVM). We\nobtain the best performance of 93.46% F1-score with SVM. The data and code is\navailable at: https://github.com/parthpatwa/covid19-fake-news-dectection", "author": [{"name": "Parth Patwa"}, {"name": "Shivam Sharma"}, {"name": "Srinivas Pykl"}, {"name": "Vineeth Guptha"}, {"name": "Gitanjali Kumari"}, {"name": "Md Shad Akhtar"}, {"name": "Asif Ekbal"}, {"name": "Amitava Das"}, {"name": "Tanmoy Chakraborty"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-73696-5_3"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-73696-5_3", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2011.03327v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.03327v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at CONSTRAINT-2021, Collocated with AAAI-2021"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.07389v1", "updated": "2020-11-14T21:14:17Z", "published": "2020-11-14T21:14:17Z", "title": "Words are the Window to the Soul: Language-based User Representations\n  for Fake News Detection", "summary": "Cognitive and social traits of individuals are reflected in language use.\nMoreover, individuals who are prone to spread fake news online often share\ncommon traits. Building on these ideas, we introduce a model that creates\nrepresentations of individuals on social media based only on the language they\nproduce, and use them to detect fake news. We show that language-based user\nrepresentations are beneficial for this task. We also present an extended\nanalysis of the language of fake news spreaders, showing that its main features\nare mostly domain independent and consistent across two English datasets.\nFinally, we exploit the relation between language use and connections in the\nsocial graph to assess the presence of the Echo Chamber effect in our data.", "author": [{"name": "Marco Del Tredici"}, {"name": "Raquel Fern\u00e1ndez"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, accepted at COLING 2020"}, "link": [{"@href": "http://arxiv.org/abs/2011.07389v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.07389v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.10817v1", "updated": "2020-11-21T16:26:54Z", "published": "2020-11-21T16:26:54Z", "title": "Detecting Fake News Spreaders in Social Networks using Inductive\n  Representation Learning", "summary": "An important aspect of preventing fake news dissemination is to proactively\ndetect the likelihood of its spreading. Research in the domain of fake news\nspreader detection has not been explored much from a network analysis\nperspective. In this paper, we propose a graph neural network based approach to\nidentify nodes that are likely to become spreaders of false information. Using\nthe community health assessment model and interpersonal trust we propose an\ninductive representation learning framework to predict nodes of\ndensely-connected community structures that are most likely to spread fake\nnews, thus making the entire community vulnerable to the infection. Using\ntopology and interaction based trust properties of nodes in real-world Twitter\nnetworks, we are able to predict false information spreaders with an accuracy\nof over 90%.", "author": [{"name": "Bhavtosh Rath"}, {"name": "Aadesh Salecha"}, {"name": "Jaideep Srivastava"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to IEEE/ACM International Conference on Advances in Social\n  Networks Analysis and Mining (ASONAM, 2020)"}, "link": [{"@href": "http://arxiv.org/abs/2011.10817v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.10817v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.12498v2", "updated": "2021-02-21T11:38:57Z", "published": "2020-12-23T05:40:15Z", "title": "Fake News Data Collection and Classification: Iterative Query Selection\n  for Opaque Search Engines with Pseudo Relevance Feedback", "summary": "Retrieving information from an online search engine, is the first and most\nimportant step in many data mining tasks. Most of the search engines currently\navailable on the web, including all social media platforms, are black-boxes\n(a.k.a opaque) supporting short keyword queries. In these settings, retrieving\nall posts and comments discussing a particular news item automatically and at\nlarge scales is a challenging task. In this paper, we propose a method for\ngenerating short keyword queries given a prototype document. The proposed\niterative query selection algorithm (IQS) interacts with the opaque search\nengine to iteratively improve the query. It is evaluated on the Twitter TREC\nMicroblog 2012 and TREC-COVID 2019 datasets showing superior performance\ncompared to state-of-the-art. IQS is applied to automatically collect a\nlarge-scale fake news dataset of about 70K true and fake news items. The\ndataset, publicly available for research, includes more than 22M accounts and\n61M tweets in Twitter approved format. We demonstrate the usefulness of the\ndataset for fake news detection task achieving state-of-the-art performance.", "author": [{"name": "Aviad Elyashar"}, {"name": "Maor Reuben"}, {"name": "Rami Puzis"}], "link": [{"@href": "http://arxiv.org/abs/2012.12498v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.12498v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.02359v1", "updated": "2021-01-07T04:01:13Z", "published": "2021-01-07T04:01:13Z", "title": "Exploring Text-transformers in AAAI 2021 Shared Task: COVID-19 Fake News\n  Detection in English", "summary": "In this paper, we describe our system for the AAAI 2021 shared task of\nCOVID-19 Fake News Detection in English, where we achieved the 3rd position\nwith the weighted F1 score of 0.9859 on the test set. Specifically, we proposed\nan ensemble method of different pre-trained language models such as BERT,\nRoberta, Ernie, etc. with various training strategies including\nwarm-up,learning rate schedule and k-fold cross-validation. We also conduct an\nextensive analysis of the samples that are not correctly classified. The code\nis available\nat:https://github.com/archersama/3rd-solution-COVID19-Fake-News-Detection-in-English.", "author": [{"name": "Xiangyang Li"}, {"name": "Yu Xia"}, {"name": "Xiang Long"}, {"name": "Zheng Li"}, {"name": "Sujian Li"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "3rd solution of 'Constraint@AAAI2021 - COVID19 Fake News Detection in\n  English'"}, "link": [{"@href": "http://arxiv.org/abs/2101.02359v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.02359v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.03545v1", "updated": "2021-01-10T13:21:08Z", "published": "2021-01-10T13:21:08Z", "title": "A Heuristic-driven Ensemble Framework for COVID-19 Fake News Detection", "summary": "The significance of social media has increased manifold in the past few\ndecades as it helps people from even the most remote corners of the world stay\nconnected. With the COVID-19 pandemic raging, social media has become more\nrelevant and widely used than ever before, and along with this, there has been\na resurgence in the circulation of fake news and tweets that demand immediate\nattention. In this paper, we describe our Fake News Detection system that\nautomatically identifies whether a tweet related to COVID-19 is \"real\" or\n\"fake\", as a part of CONSTRAINT COVID19 Fake News Detection in English\nchallenge. We have used an ensemble model consisting of pre-trained models that\nhas helped us achieve a joint 8th position on the leader board. We have\nachieved an F1-score of 0.9831 against a top score of 0.9869. Post completion\nof the competition, we have been able to drastically improve our system by\nincorporating a novel heuristic algorithm based on username handles and link\ndomains in tweets fetching an F1-score of 0.9883 and achieving state-of-the art\nresults on the given dataset.", "author": [{"name": "Sourya Dipta Das"}, {"name": "Ayan Basak"}, {"name": "Saikat Dutta"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to CONSTRAINT Workshop, AAAI'21"}, "link": [{"@href": "http://arxiv.org/abs/2101.03545v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.03545v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.05499v1", "updated": "2021-01-14T08:39:50Z", "published": "2021-01-14T08:39:50Z", "title": "ECOL: Early Detection of COVID Lies Using Content, Prior Knowledge and\n  Source Information", "summary": "Social media platforms are vulnerable to fake news dissemination, which\ncauses negative consequences such as panic and wrong medication in the\nhealthcare domain. Therefore, it is important to automatically detect fake news\nin an early stage before they get widely spread. This paper analyzes the impact\nof incorporating content information, prior knowledge, and credibility of\nsources into models for the early detection of fake news. We propose a\nframework modeling those features by using BERT language model and external\nsources, namely Simple English Wikipedia and source reliability tags. The\nconducted experiments on CONSTRAINT datasets demonstrated the benefit of\nintegrating these features for the early detection of fake news in the\nhealthcare domain.", "author": [{"name": "Ipek Baris"}, {"name": "Zeyd Boukhers"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "to be published in Constraint-2021 Workshop @ AAAI"}, "link": [{"@href": "http://arxiv.org/abs/2101.05499v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.05499v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.05953v1", "updated": "2021-01-15T03:24:36Z", "published": "2021-01-15T03:24:36Z", "title": "Hostility Detection and Covid-19 Fake News Detection in Social Media", "summary": "Withtheadventofsocialmedia,therehasbeenanextremely rapid increase in the\ncontent shared online. Consequently, the propagation of fake news and hostile\nmessages on social media platforms has also skyrocketed. In this paper, we\naddress the problem of detecting hostile and fake content in the Devanagari\n(Hindi) script as a multi-class, multi-label problem. Using NLP techniques, we\nbuild a model that makes use of an abusive language detector coupled with\nfeatures extracted via Hindi BERT and Hindi FastText models and metadata. Our\nmodel achieves a 0.97 F1 score on coarse grain evaluation on Hostility\ndetection task. Additionally, we built models to identify fake news related to\nCovid-19 in English tweets. We leverage entity information extracted from the\ntweets along with textual representations learned from word embeddings and\nachieve a 0.93 F1 score on the English fake news detection task.", "author": [{"name": "Ayush Gupta"}, {"name": "Rohan Sukumaran"}, {"name": "Kevin John"}, {"name": "Sundeep Teki"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages, 3 figures, 3 tables"}, "link": [{"@href": "http://arxiv.org/abs/2101.05953v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.05953v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.02680v1", "updated": "2021-02-04T15:18:44Z", "published": "2021-02-04T15:18:44Z", "title": "Hierarchical Multi-head Attentive Network for Evidence-aware Fake News\n  Detection", "summary": "The widespread of fake news and misinformation in various domains ranging\nfrom politics, economics to public health has posed an urgent need to\nautomatically fact-check information. A recent trend in fake news detection is\nto utilize evidence from external sources. However, existing evidence-aware\nfake news detection methods focused on either only word-level attention or\nevidence-level attention, which may result in suboptimal performance. In this\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\ntextual claims. Our model jointly combines multi-head word-level attention and\nmulti-head document-level attention, which aid explanation in both word-level\nand evidence-level. Experiments on two real-word datasets show that our model\noutperforms seven state-of-the-art baselines. Improvements over baselines are\nfrom 6\\% to 18\\%. Our source code and datasets are released at\n\\texttt{\\url{https://github.com/nguyenvo09/EACL2021}}.", "author": [{"name": "Nguyen Vo"}, {"name": "Kyumin Lee"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EACL2021"}, "link": [{"@href": "http://arxiv.org/abs/2102.02680v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.02680v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.03143v1", "updated": "2021-05-07T09:52:44Z", "published": "2021-05-07T09:52:44Z", "title": "AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News and Hate Speech\n  Detection Dataset", "summary": "Along with the COVID-19 pandemic, an \"infodemic\" of false and misleading\ninformation has emerged and has complicated the COVID-19 response efforts.\nSocial networking sites such as Facebook and Twitter have contributed largely\nto the spread of rumors, conspiracy theories, hate, xenophobia, racism, and\nprejudice. To combat the spread of fake news, researchers around the world have\nand are still making considerable efforts to build and share COVID-19 related\nresearch articles, models, and datasets. This paper releases \"AraCOVID19-MFH\" a\nmanually annotated multi-label Arabic COVID-19 fake news and hate speech\ndetection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10\ndifferent labels. The labels have been designed to consider some aspects\nrelevant to the fact-checking task, such as the tweet's check worthiness,\npositivity/negativity, and factuality. To confirm our annotated dataset's\npractical utility, we used it to train and evaluate several classification\nmodels and reported the obtained results. Though the dataset is mainly designed\nfor fake news detection, it can also be used for hate speech detection,\nopinion/news classification, dialect identification, and many other tasks.", "author": [{"name": "Mohamed Seghir Hadj Ameur"}, {"name": "Hassina Aliane"}], "link": [{"@href": "http://arxiv.org/abs/2105.03143v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.03143v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.05419v1", "updated": "2021-08-11T19:13:04Z", "published": "2021-08-11T19:13:04Z", "title": "NoFake at CheckThat! 2021: Fake News Detection Using BERT", "summary": "Much research has been done for debunking and analysing fake news. Many\nresearchers study fake news detection in the last year, but many are limited to\nsocial media data. Currently, multiples fact-checkers are publishing their\nresults in various formats. Also, multiple fact-checkers use different labels\nfor the fake news, making it difficult to make a generalisable classifier. With\nthe merge classes, the performance of the machine model can be enhanced. This\ndomain categorisation will help group the article, which will help save the\nmanual effort in assigning the claim verification. In this paper, we have\npresented BERT based classification model to predict the domain and\nclassification. We have also used additional data from fact-checked articles.\nWe have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B\nusing the additional training data.", "author": {"name": "Sushma Kumari"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF Task 3"}, "link": [{"@href": "http://arxiv.org/abs/2108.05419v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.05419v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.08264v1", "updated": "2021-08-04T15:25:32Z", "published": "2021-08-04T15:25:32Z", "title": "Fake News and Phishing Detection Using a Machine Learning Trained Expert\n  System", "summary": "Expert systems have been used to enable computers to make recommendations and\ndecisions. This paper presents the use of a machine learning trained expert\nsystem (MLES) for phishing site detection and fake news detection. Both topics\nshare a similar goal: to design a rule-fact network that allows a computer to\nmake explainable decisions like domain experts in each respective area. The\nphishing website detection study uses a MLES to detect potential phishing\nwebsites by analyzing site properties (like URL length and expiration time).\nThe fake news detection study uses a MLES rule-fact network to gauge news story\ntruthfulness based on factors such as emotion, the speaker's political\naffiliation status, and job. The two studies use different MLES network\nimplementations, which are presented and compared herein. The fake news study\nutilized a more linear design while the phishing project utilized a more\ncomplex connection structure. Both networks' inputs are based on commonly\navailable data sets.", "author": [{"name": "Benjamin Fitzpatrick"}, {"name": "Xinyu \"Sherwin\" Liang"}, {"name": "Jeremy Straub"}], "link": [{"@href": "http://arxiv.org/abs/2108.08264v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.08264v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.03316v2", "updated": "2020-08-14T07:49:20Z", "published": "2020-07-07T10:04:50Z", "title": "Graph Neural Networks with Continual Learning for Fake News Detection\n  from Social Media", "summary": "Although significant effort has been applied to fact-checking, the prevalence\nof fake news over social media, which has profound impact on justice, public\ntrust and our society, remains a serious problem. In this work, we focus on\npropagation-based fake news detection, as recent studies have demonstrated that\nfake news and real news spread differently online. Specifically, considering\nthe capability of graph neural networks (GNNs) in dealing with non-Euclidean\ndata, we use GNNs to differentiate between the propagation patterns of fake and\nreal news on social media. In particular, we concentrate on two questions: (1)\nWithout relying on any text information, e.g., tweet content, replies and user\ndescriptions, how accurately can GNNs identify fake news? Machine learning\nmodels are known to be vulnerable to adversarial attacks, and avoiding the\ndependence on text-based features can make the model less susceptible to the\nmanipulation of advanced fake news fabricators. (2) How to deal with new,\nunseen data? In other words, how does a GNN trained on a given dataset perform\non a new and potentially vastly different dataset? If it achieves\nunsatisfactory performance, how do we solve the problem without re-training the\nmodel on the entire data from scratch? We study the above questions on two\ndatasets with thousands of labelled news items, and our results show that: (1)\nGNNs can achieve comparable or superior performance without any text\ninformation to state-of-the-art methods. (2) GNNs trained on a given dataset\nmay perform poorly on new, unseen data, and direct incremental training cannot\nsolve the problem---this issue has not been addressed in the previous work that\napplies GNNs for fake news detection. In order to solve the problem, we propose\na method that achieves balanced performance on both existing and new datasets,\nby using techniques from continual learning to train GNNs incrementally.", "author": [{"name": "Yi Han"}, {"name": "Shanika Karunasekera"}, {"name": "Christopher Leckie"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 7 figures, 2 tables"}, "link": [{"@href": "http://arxiv.org/abs/2007.03316v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.03316v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.12616v3", "updated": "2020-12-11T16:17:17Z", "published": "2019-05-29T17:58:52Z", "title": "Defending Against Neural Fake News", "summary": "Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news.", "author": [{"name": "Rowan Zellers"}, {"name": "Ari Holtzman"}, {"name": "Hannah Rashkin"}, {"name": "Yonatan Bisk"}, {"name": "Ali Farhadi"}, {"name": "Franziska Roesner"}, {"name": "Yejin Choi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NeurIPS 2019 camera ready version. Project page/code/demo at\n  https://rowanzellers.com/grover"}, "link": [{"@href": "http://arxiv.org/abs/1905.12616v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.12616v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.00623v1", "updated": "2020-01-02T21:01:02Z", "published": "2020-01-02T21:01:02Z", "title": "Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements", "summary": "In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.", "author": [{"name": "Kai Shu"}, {"name": "Suhang Wang"}, {"name": "Dongwon Lee"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Submitted as an introductory chapter for the edited book on \"Fake\n  News, Disinformation, and Misinformation in Social Media- Emerging Research\n  Challenges and Opportunities\", Springer Press"}, "link": [{"@href": "http://arxiv.org/abs/2001.00623v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.00623v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.2.8", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.01065v2", "updated": "2020-04-02T05:12:35Z", "published": "2020-02-04T00:28:38Z", "title": "Fake News Detection by means of Uncertainty Weighted Causal Graphs", "summary": "Society is experimenting changes in information consumption, as new\ninformation channels such as social networks let people share news that do not\nnecessarily be trust worthy. Sometimes, these sources of information produce\nfake news deliberately with doubtful purposes and the consumers of that\ninformation share it to other users thinking that the information is accurate.\nThis transmission of information represents an issue in our society, as can\ninfluence negatively the opinion of people about certain figures, groups or\nideas. Hence, it is desirable to design a system that is able to detect and\nclassify information as fake and categorize a source of information as trust\nworthy or not. Current systems experiment difficulties performing this task, as\nit is complicated to design an automatic procedure that can classify this\ninformation independent on the context. In this work, we propose a mechanism to\ndetect fake news through a classifier based on weighted causal graphs. These\ngraphs are specific hybrid models that are built through causal relations\nretrieved from texts and consider the uncertainty of causal relations. We take\nadvantage of this representation to use the probability distributions of this\ngraph and built a fake news classifier based on the entropy and KL divergence\nof learned and new information. We believe that the problem of fake news is\naccurately tackled by this model due to its hybrid nature between a symbolic\nand quantitative methodology. We describe the methodology of this classifier\nand add empirical evidence of the usefulness of our proposed approach in the\nform of synthetic experiments and a real experiment involving lung cancer.", "author": [{"name": "Eduardo C. Garrido-Merch\u00e1n"}, {"name": "Cristina Puente"}, {"name": "Rafael Palacios"}], "link": [{"@href": "http://arxiv.org/abs/2002.01065v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.01065v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.01732v1", "updated": "2020-04-03T18:26:33Z", "published": "2020-04-03T18:26:33Z", "title": "Leveraging Multi-Source Weak Social Supervision for Early Detection of\n  Fake News", "summary": "Social media has greatly enabled people to participate in online activities\nat an unprecedented rate. However, this unrestricted access also exacerbates\nthe spread of misinformation and fake news online which might cause confusion\nand chaos unless being detected early for its mitigation. Given the rapidly\nevolving nature of news events and the limited amount of annotated data,\nstate-of-the-art systems on fake news detection face challenges due to the lack\nof large numbers of annotated training instances that are hard to come by for\nearly detection. In this work, we exploit multiple weak signals from different\nsources given by user and content engagements (referred to as weak social\nsupervision), and their complementary utilities to detect fake news. We jointly\nleverage the limited amount of clean data along with weak signals from social\nengagements to train deep neural networks in a meta-learning framework to\nestimate the quality of different weak instances. Experiments on realworld\ndatasets demonstrate that the proposed framework outperforms state-of-the-art\nbaselines for early detection of fake news without using any user engagements\nat prediction time.", "author": [{"name": "Kai Shu"}, {"name": "Guoqing Zheng"}, {"name": "Yichuan Li"}, {"name": "Subhabrata Mukherjee"}, {"name": "Ahmed Hassan Awadallah"}, {"name": "Scott Ruston"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "17 pages, 5 figures, 4 tables"}, "link": [{"@href": "http://arxiv.org/abs/2004.01732v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.01732v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.02275v2", "updated": "2020-09-18T04:16:04Z", "published": "2020-09-04T16:16:27Z", "title": "Controlling Fake News by Tagging: A Branching Process Analysis", "summary": "The spread of fake news, especially on online social networks, has become a\nmatter of concern in the last few years. These platforms are also used for\npropagating other important authentic information. Thus, there is a need for\nmitigating fake news without significantly influencing the spread of real news.\nWe leverage user's inherent capabilities of identifying fake news and propose a\nwarning-based control mechanism to curb this spread. Warnings are based on\nprevious users' responses that indicate the authenticity of the news.\n  We use population-size dependent continuous-time multi-type branching\nprocesses to describe the spreading under the warning mechanism. We also have\nnew results towards these branching processes. The (time) asymptotic\nproportions of the individual populations are derived. These results are\ninstrumental in deriving relevant type-1, type-2 performance measures, and\nformulating an optimization problem to design optimal warning parameters. The\nfraction of copies tagged as real (fake) are considered for the type-1 (type-2)\nperformance.\n  We derive structural properties of the performance, which help simplify the\noptimization problem. We finally demonstrate that the optimal warning mechanism\neffectively mitigates fake news, with negligible influences on the propagation\nof authentic news. We validate performance measures using Monte Carlo\nsimulations on ego-network database related to Twitter.", "author": [{"name": "Suyog Kapsikar"}, {"name": "Indrajit Saha"}, {"name": "Khushboo Agarwal"}, {"name": "Veeraruna Kavitha"}, {"name": "Quanyan Zhu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "We revised the paper with 1 additional Theorem. The updated paper has\n  8 pages, 1 table and 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/2009.02275v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.02275v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.PR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.13253v1", "updated": "2020-11-26T11:50:45Z", "published": "2020-11-26T11:50:45Z", "title": "Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking", "summary": "The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.", "author": [{"name": "Rutvik Vijjali"}, {"name": "Prathyush Potluri"}, {"name": "Siddharth Kumar"}, {"name": "Sundeep Teki"}], "link": [{"@href": "http://arxiv.org/abs/2011.13253v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.13253v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.01142v1", "updated": "2020-12-28T13:07:42Z", "published": "2020-12-28T13:07:42Z", "title": "Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study", "summary": "Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.", "author": [{"name": "Michal Choras"}, {"name": "Konstantinos Demestichas"}, {"name": "Agata Gielczyk"}, {"name": "Alvaro Herrero"}, {"name": "Pawel Ksieniewicz"}, {"name": "Konstantina Remoundou"}, {"name": "Daniel Urda"}, {"name": "Michal Wozniak"}], "link": [{"@href": "http://arxiv.org/abs/2101.01142v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.01142v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.03841v1", "updated": "2021-01-11T12:23:41Z", "published": "2021-01-11T12:23:41Z", "title": "Model Generalization on COVID-19 Fake News Detection", "summary": "Amid the pandemic COVID-19, the world is facing unprecedented infodemic with\nthe proliferation of both fake and real information. Considering the\nproblematic consequences that the COVID-19 fake-news have brought, the\nscientific community has put effort to tackle it. To contribute to this fight\nagainst the infodemic, we aim to achieve a robust model for the COVID-19\nfake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking\ntwo separate approaches: 1) fine-tuning transformers based language models with\nrobust loss functions and 2) removing harmful training instances through\ninfluence calculation. We further evaluate the robustness of our models by\nevaluating on different COVID-19 misinformation test set (Tweets-19) to\nunderstand model generalization ability. With the first approach, we achieve\n98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on\nthe Tweets-19 highest. On the contrary, by performing influence data cleansing,\nour model with 99% cleansing percentage can achieve 54.33% W-F1 score on\nTweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news\ntest sets, we suggest the importance of model generalization ability in this\ntask to step forward to tackle the COVID-19 fake-news problem in online social\nmedia platforms.", "author": [{"name": "Yejin Bang"}, {"name": "Etsuko Ishii"}, {"name": "Samuel Cahyawijaya"}, {"name": "Ziwei Ji"}, {"name": "Pascale Fung"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CONSTRAINT Workshop 2021 (Camera Ready Version)"}, "link": [{"@href": "http://arxiv.org/abs/2101.03841v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.03841v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.09338v2", "updated": "2021-08-08T17:03:44Z", "published": "2021-06-17T09:19:45Z", "title": "Investigating Misinformation Dissemination on Social Media in Pakistan", "summary": "Fake news and misinformation are one of the most significant challenges\nbrought about by advances in communication technologies. We chose to research\nthe spread of fake news in Pakistan because of some unfortunate incidents that\ntook place during 2020. These included the downplaying of the severity of the\nCOVID-19 pandemic, and protests by right-wing political movements. We observed\nthat fake news and misinformation contributed significantly to these events and\nespecially affected low-literate and low-income populations. We conducted a\ncross-platform comparison of misinformation on WhatsApp, Twitter and YouTube\nwith a primary focus on messages shared in public WhatsApp groups, and analysed\nthe characteristics of misinformation, techniques used to make is believable,\nand how users respond to it. To the best of our knowledge, this is the first\nattempt to compare misinformation on all three platforms in Pakistan. Data\ncollected over a span of eight months helped us identify fake news and\nmisinformation related to politics, religion and health, among other\ncategories. Common elements which were used by fake news creators in Pakistan\nto make false content seem believable included: appeals to emotion, conspiracy\ntheories, political and religious polarization, incorrect facts and\nimpersonation of credible sources.", "author": [{"name": "Danyal Haroon"}, {"name": "Hammad Arif"}, {"name": "Ahmed Abdullah Tariq"}, {"name": "fareeda nawaz"}, {"name": "Dr. Ihsan Ayyub Qazi"}, {"name": "Dr. Maryam mustafa"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "i want to further work on it"}, "link": [{"@href": "http://arxiv.org/abs/2106.09338v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.09338v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1711.00715v1", "updated": "2017-10-31T18:52:28Z", "published": "2017-10-31T18:52:28Z", "title": "Related Fact Checks: a tool for combating fake news", "summary": "The emergence of \"Fake News\" and misinformation via online news and social\nmedia has spurred an interest in computational tools to combat this phenomenon.\nIn this paper we present a new \"Related Fact Checks\" service, which can help a\nreader critically evaluate an article and make a judgment on its veracity by\nbringing up fact checks that are relevant to the article. We describe the core\ntechnical problems that need to be solved in building a \"Related Fact Checks\"\nservice, and present results from an evaluation of an implementation.", "author": {"name": "Sreya Guha"}, "link": [{"@href": "http://arxiv.org/abs/1711.00715v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.00715v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.06592v1", "updated": "2019-10-15T08:43:47Z", "published": "2019-10-15T08:43:47Z", "title": "FacTweet: Profiling Fake News Twitter Accounts", "summary": "We present an approach to detect fake news in Twitter at the account level\nusing a neural recurrent model and a variety of different semantic and\nstylistic features. Our method extracts a set of features from the timelines of\nnews Twitter accounts by reading their posts as chunks, rather than dealing\nwith each tweet independently. We show the experimental benefits of modeling\nlatent stylistic signatures of mixed fake and real news with a sequential model\nover a wide range of strong baselines.", "author": [{"name": "Bilal Ghanem"}, {"name": "Simone Paolo Ponzetto"}, {"name": "Paolo Rosso"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages"}, "link": [{"@href": "http://arxiv.org/abs/1910.06592v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.06592v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.14353v1", "updated": "2019-10-31T10:32:43Z", "published": "2019-10-31T10:32:43Z", "title": "Transfer Learning from Transformers to Fake News Challenge Stance\n  Detection (FNC-1) Task", "summary": "In this paper, we report improved results of the Fake News Challenge Stage 1\n(FNC-1) stance detection task. This gain in performance is due to the\ngeneralization power of large language models based on Transformer\narchitecture, invented, trained and publicly released over the last two years.\nSpecifically (1) we improved the FNC-1 best performing model adding BERT\nsentence embedding of input sequences as a model feature, (2) we fine-tuned\nBERT, XLNet, and RoBERTa transformers on FNC-1 extended dataset and obtained\nstate-of-the-art results on FNC-1 task.", "author": {"name": "Valeriya Slovikovskaya"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages, 9 tables"}, "link": [{"@href": "http://arxiv.org/abs/1910.14353v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.14353v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1907.07347v1", "updated": "2019-07-17T06:03:17Z", "published": "2019-07-17T06:03:17Z", "title": "Fake News Detection as Natural Language Inference", "summary": "This report describes the entry by the Intelligent Knowledge Management (IKM)\nLab in the WSDM 2019 Fake News Classification challenge. We treat the task as\nnatural language inference (NLI). We individually train a number of the\nstrongest NLI models as well as BERT. We ensemble these results and retrain\nwith noisy labels in two stages. We analyze transitivity relations in the train\nand test sets and determine a set of test cases that can be reliably classified\non this basis. The remainder of test cases are classified by our ensemble. Our\nentry achieves test set accuracy of 88.063% for 3rd place in the competition.", "author": [{"name": "Kai-Chou Yang"}, {"name": "Timothy Niven"}, {"name": "Hung-Yu Kao"}], "link": [{"@href": "http://arxiv.org/abs/1907.07347v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.07347v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2003.04978v1", "updated": "2020-02-15T06:15:17Z", "published": "2020-02-15T06:15:17Z", "title": "Fake News Detection with Different Models", "summary": "This is a paper for exploring various different models aiming at developing\nfake news detection models and we had used certain machine learning algorithms\nand we had used pretrained algorithms such as TFIDF and CV and W2V as features\nfor processing textual data.", "author": [{"name": "Sairamvinay Vijayaraghavan"}, {"name": "Ye Wang"}, {"name": "Zhiyuan Guo"}, {"name": "John Voong"}, {"name": "Wenda Xu"}, {"name": "Armand Nasseri"}, {"name": "Jiaru Cai"}, {"name": "Linda Li"}, {"name": "Kevin Vuong"}, {"name": "Eshan Wadhwa"}], "link": [{"@href": "http://arxiv.org/abs/2003.04978v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.04978v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.11954v2", "updated": "2021-02-01T22:27:07Z", "published": "2021-01-28T12:12:50Z", "title": "Identifying COVID-19 Fake News in Social Media", "summary": "The evolution of social media platforms have empowered everyone to access\ninformation easily. Social media users can easily share information with the\nrest of the world. This may sometimes encourage spread of fake news, which can\nresult in undesirable consequences. In this work, we train models which can\nidentify health news related to COVID-19 pandemic as real or fake. Our models\nachieve a high F1-score of 98.64%. Our models achieve second place on the\nleaderboard, tailing the first position with a very narrow margin 0.05% points.", "author": [{"name": "Tathagata Raha"}, {"name": "Vijayasaradhi Indurthi"}, {"name": "Aayush Upadhyaya"}, {"name": "Jeevesh Kataria"}, {"name": "Pramud Bommakanti"}, {"name": "Vikram Keswani"}, {"name": "Vasudeva Varma"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CONSTRAINT@AAAI"}, "link": [{"@href": "http://arxiv.org/abs/2101.11954v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.11954v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1603.01511v1", "updated": "2016-03-04T15:59:06Z", "published": "2016-03-04T15:59:06Z", "title": "Hoaxy: A Platform for Tracking Online Misinformation", "summary": "Massive amounts of misinformation have been observed to spread in\nuncontrolled fashion across social media. Examples include rumors, hoaxes, fake\nnews, and conspiracy theories. At the same time, several journalistic\norganizations devote significant efforts to high-quality fact checking of\nonline claims. The resulting information cascades contain instances of both\naccurate and inaccurate information, unfold over multiple time scales, and\noften reach audiences of considerable size. All these factors pose challenges\nfor the study of the social dynamics of online news sharing. Here we introduce\nHoaxy, a platform for the collection, detection, and analysis of online\nmisinformation and its related fact-checking efforts. We discuss the design of\nthe platform and present a preliminary analysis of a sample of public tweets\ncontaining both fake news and fact checking. We find that, in the aggregate,\nthe sharing of fact-checking content typically lags that of misinformation by\n10--20 hours. Moreover, fake news are dominated by very active users, while\nfact checking is a more grass-roots activity. With the increasing risks\nconnected to massive online misinformation, social news observatories have the\npotential to help researchers, journalists, and the general public understand\nthe dynamics of real and fake news sharing.", "author": [{"name": "Chengcheng Shao"}, {"name": "Giovanni Luca Ciampaglia"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/2872518.2890098"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/2872518.2890098", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1603.01511v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1603.01511v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 6 figures, submitted to Third Workshop on Social News On the\n  Web"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1708.06233v1", "updated": "2017-08-21T14:09:31Z", "published": "2017-08-21T14:09:31Z", "title": "Fake News in Social Networks", "summary": "We model the spread of news as a social learning game on a network. Agents\ncan either endorse or oppose a claim made in a piece of news, which itself may\nbe either true or false. Agents base their decision on a private signal and\ntheir neighbors' past actions. Given these inputs, agents follow strategies\nderived via multi-agent deep reinforcement learning and receive utility from\nacting in accordance with the veracity of claims. Our framework yields\nstrategies with agent utility close to a theoretical, Bayes optimal benchmark,\nwhile remaining flexible to model re-specification. Optimized strategies allow\nagents to correctly identify most false claims, when all agents receive\nunbiased private signals. However, an adversary's attempt to spread fake news\nby targeting a subset of agents with a biased private signal can be successful.\nEven more so when the adversary has information about agents' network position\nor private signal. When agents are aware of the presence of an adversary they\nre-optimize their strategies in the training stage and the adversary's attack\nis less effective. Hence, exposing agents to the possibility of fake news can\nbe an effective way to curtail the spread of fake news in social networks. Our\nresults also highlight that information about the users' private beliefs and\ntheir social network structure can be extremely valuable to adversaries and\nshould be well protected.", "author": [{"name": "Christoph Aymanns"}, {"name": "Jakob Foerster"}, {"name": "Co-Pierre Georg"}], "link": [{"@href": "http://arxiv.org/abs/1708.06233v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1708.06233v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.1; I.2.6; J.4; K.4.2", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1712.03935v1", "updated": "2017-12-11T18:32:11Z", "published": "2017-12-11T18:32:11Z", "title": "On the Benefit of Combining Neural, Statistical and External Features\n  for Fake News Identification", "summary": "Identifying the veracity of a news article is an interesting problem while\nautomating this process can be a challenging task. Detection of a news article\nas fake is still an open question as it is contingent on many factors which the\ncurrent state-of-the-art models fail to incorporate. In this paper, we explore\na subtask to fake news identification, and that is stance detection. Given a\nnews article, the task is to determine the relevance of the body and its claim.\nWe present a novel idea that combines the neural, statistical and external\nfeatures to provide an efficient solution to this problem. We compute the\nneural embedding from the deep recurrent model, statistical features from the\nweighted n-gram bag-of-words model and handcrafted external features with the\nhelp of feature engineering heuristics. Finally, using deep neural layer all\nthe features are combined, thereby classifying the headline-body news pair as\nagree, disagree, discuss, or unrelated. We compare our proposed technique with\nthe current state-of-the-art models on the fake news challenge dataset. Through\nextensive experiments, we find that the proposed model outperforms all the\nstate-of-the-art techniques including the submissions to the fake news\nchallenge.", "author": [{"name": "Gaurav Bhatt"}, {"name": "Aman Sharma"}, {"name": "Shivam Sharma"}, {"name": "Ankush Nagpal"}, {"name": "Balasubramanian Raman"}, {"name": "Ankush Mittal"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Source code available at - www.deeplearn-ai.com"}, "link": [{"@href": "http://arxiv.org/abs/1712.03935v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1712.03935v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2008.06274v4", "updated": "2020-11-23T15:07:48Z", "published": "2020-08-14T10:01:34Z", "title": "Graph-based Modeling of Online Communities for Fake News Detection", "summary": "Over the past few years, there has been a substantial effort towards\nautomated detection of fake news on social media platforms. Existing research\nhas modeled the structure, style, content, and patterns in dissemination of\nonline posts, as well as the demographic traits of users who interact with\nthem. However, no attention has been directed towards modeling the properties\nof online communities that interact with the posts. In this work, we propose a\nnovel social context-aware fake news detection framework, SAFER, based on graph\nneural networks (GNNs). The proposed framework aggregates information with\nrespect to: 1) the nature of the content disseminated, 2) content-sharing\nbehavior of users, and 3) the social network of those users. We furthermore\nperform a systematic comparison of several GNN models for this task and\nintroduce novel methods based on relational and hyperbolic GNNs, which have not\nbeen previously used for user or community modeling within NLP. We empirically\ndemonstrate that our framework yields significant improvements over existing\ntext-based techniques and achieves state-of-the-art results on fake news\ndatasets from two different domains.", "author": [{"name": "Shantanu Chandra"}, {"name": "Pushkar Mishra"}, {"name": "Helen Yannakoudakis"}, {"name": "Madhav Nimishakavi"}, {"name": "Marzieh Saeidi"}, {"name": "Ekaterina Shutova"}], "link": [{"@href": "http://arxiv.org/abs/2008.06274v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.06274v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.06854v1", "updated": "2020-08-16T08:06:52Z", "published": "2020-08-16T08:06:52Z", "title": "SGG: Spinbot, Grammarly and GloVe based Fake News Detection", "summary": "Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.", "author": [{"name": "Akansha Gautam"}, {"name": "Koteswar Rao Jerripothula"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 7 figures, Accepted by IEEE International Conference on\n  Multimedia Big Data (BigMM), 2020"}, "link": [{"@href": "http://arxiv.org/abs/2008.06854v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.06854v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.03092v1", "updated": "2020-11-05T20:50:22Z", "published": "2020-11-05T20:50:22Z", "title": "Machine Generation and Detection of Arabic Manipulated and Fake News", "summary": "Fake news and deceptive machine-generated text are serious problems\nthreatening modern societies, including in the Arab world. This motivates work\non detecting false and manipulated stories online. However, a bottleneck for\nthis research is lack of sufficient data to train detection models. We present\na novel method for automatically generating Arabic manipulated (and potentially\nfake) news stories. Our method is simple and only depends on availability of\ntrue stories, which are abundant online, and a part of speech tagger (POS). To\nfacilitate future work, we dispense with both of these requirements altogether\nby providing AraNews, a novel and large POS-tagged news dataset that can be\nused off-the-shelf. Using stories generated based on AraNews, we carry out a\nhuman annotation study that casts light on the effects of machine manipulation\non text veracity. The study also measures human ability to detect Arabic\nmachine manipulated text generated by our method. Finally, we develop the first\nmodels for detecting manipulated Arabic news and achieve state-of-the-art\nresults on Arabic fake news detection (macro F1=70.06). Our models and data are\npublicly available.", "author": [{"name": "El Moatez Billah Nagoudi"}, {"name": "AbdelRahim Elmadany"}, {"name": "Muhammad Abdul-Mageed"}, {"name": "Tariq Alhindi"}, {"name": "Hasan Cavusoglu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, accepted in The Fifth Arabic Natural Language Processing\n  Workshop (WANLP 2020)"}, "link": [{"@href": "http://arxiv.org/abs/2011.03092v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.03092v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.02434v1", "updated": "2021-02-04T06:35:27Z", "published": "2021-02-04T06:35:27Z", "title": "Assessing Individual and Community Vulnerability to Fake News in Social\n  Networks", "summary": "The plague of false information, popularly called fake news has affected\nlives of news consumers ever since the prevalence of social media. Thus\nunderstanding the spread of false information in social networks has gained a\nlot of attention in the literature. While most proposed models do content\nanalysis of the information, no much work has been done by exploring the\ncommunity structures that also play an important role in determining how people\nget exposed to it. In this paper we base our idea on Computational Trust in\nsocial networks to propose a novel Community Health Assessment model against\nfake news. Based on the concepts of neighbor, boundary and core nodes of a\ncommunity, we propose novel evaluation metrics to quantify the vulnerability of\nnodes (individual-level) and communities (group-level) to spreading false\ninformation. Our model hypothesizes that if the boundary nodes trust the\nneighbor nodes of a community who are spreaders, the densely-connected core\nnodes of the community are highly likely to become spreaders. We test our model\nwith communities generated using three popular community detection algorithms\nbased on two new datasets of information spreading networks collected from\nTwitter. Our experimental results show that the proposed metrics perform\nclearly better on the networks spreading false information than on those\nspreading true ones, indicating our community health assessment model is\neffective.", "author": [{"name": "Bhavtosh Rath"}, {"name": "Wei Gao"}, {"name": "Jaideep Srivastava"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Extension work on our ASONAM 19 paper (Evaluating vulnerability to\n  fake news in social networks: A community health assessment model)"}, "link": [{"@href": "http://arxiv.org/abs/2102.02434v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.02434v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2103.15581v1", "updated": "2021-03-29T12:56:59Z", "published": "2021-03-29T12:56:59Z", "title": "Supporting verification of news articles with automated search for\n  semantically similar articles", "summary": "Fake information poses one of the major threats for society in the 21st\ncentury. Identifying misinformation has become a key challenge due to the\namount of fake news that is published daily. Yet, no approach is established\nthat addresses the dynamics and versatility of fake news editorials. Instead of\nclassifying content, we propose an evidence retrieval approach to handle fake\nnews. The learning task is formulated as an unsupervised machine learning\nproblem. For validation purpose, we provide the user with a set of news\narticles from reliable news sources supporting the hypothesis of the news\narticle in query and the final decision is left to the user. Technically we\npropose a two-step process: (i) Aggregation-step: With information extracted\nfrom the given text we query for similar content from reliable news sources.\n(ii) Refining-step: We narrow the supporting evidence down by measuring the\nsemantic distance of the text with the collection from step (i). The distance\nis calculated based on Word2Vec and the Word Mover's Distance. In our\nexperiments, only content that is below a certain distance threshold is\nconsidered as supporting evidence. We find that our approach is agnostic to\nconcept drifts, i.e. the machine learning task is independent of the hypotheses\nin a text. This makes it highly adaptable in times where fake news is as\ndiverse as classical news is. Our pipeline offers the possibility for further\nanalysis in the future, such as investigating bias and differences in news\nreporting.", "author": [{"name": "Vishwani Gupta"}, {"name": "Katharina Beckh"}, {"name": "Sven Giesselbach"}, {"name": "Dennis Wegener"}, {"name": "Tim Wirtz"}], "link": [{"@href": "http://arxiv.org/abs/2103.15581v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.15581v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.09586v1", "updated": "2021-06-17T15:13:08Z", "published": "2021-06-17T15:13:08Z", "title": "Prevalence and Propagation of Fake News", "summary": "In recent years, scholars have raised concerns on the effects that unreliable\nnews, or \"fake news,\" has on our political sphere, and our democracy as a\nwhole. For example, the propagation of fake news on social media is widely\nbelieved to have influenced the outcome of national elections, including the\n2016 U.S. Presidential Election, and the 2020 COVID-19 pandemic. What drives\nthe propagation of fake news on an individual level, and which interventions\ncould effectively reduce the propagation rate? Our model disentangles bias from\ntruthfulness of an article and examines the relationship between these two\nparameters and a reader's own beliefs. Using the model, we create policy\nrecommendations for both social media platforms and individual social media\nusers to reduce the spread of untruthful or highly biased news. We recommend\nthat platforms sponsor unbiased truthful news, focus fact-checking efforts on\nmild to moderately biased news, recommend friend suggestions across the\npolitical spectrum, and provide users with reports about the political\nalignment of their feed. We recommend that individual social media users fact\ncheck news that strongly aligns with their political bias and read articles of\nopposing political bias.", "author": [{"name": "Banafsheh Behzad"}, {"name": "Bhavana Bheem"}, {"name": "Daniela Elizondo"}, {"name": "Deyana Marsh"}, {"name": "Susan Martonosi"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "45 pages, 22 figures. Submitted for peer review on 7 May 2021"}, "link": [{"@href": "http://arxiv.org/abs/2106.09586v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.09586v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.OC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "90B50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "J.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.11177v1", "updated": "2021-06-21T15:17:31Z", "published": "2021-06-21T15:17:31Z", "title": "MetaDetector: Meta Event Knowledge Transfer for Fake News Detection", "summary": "The blooming of fake news on social networks has devastating impacts on\nsociety, economy, and public security. Although numerous studies are conducted\nfor the automatic detection of fake news, the majority tend to utilize deep\nneural networks to learn event-specific features for superior detection\nperformance on specific datasets. However, the trained models heavily rely on\nthe training datasets and are infeasible to apply to upcoming events due to the\ndiscrepancy between event distributions. Inspired by domain adaptation\ntheories, we propose an end-to-end adversarial adaptation network, dubbed as\nMetaDetector, to transfer meta knowledge (event-shared features) between\ndifferent events. Specifically, MetaDetector pushes the feature extractor and\nevent discriminator to eliminate event-specific features and preserve required\nevent-shared features by adversarial training. Furthermore, the pseudo-event\ndiscriminator is utilized to evaluate the importance of historical event posts\nto obtain partial shared features that are discriminative for detecting fake\nnews. Under the coordinated optimization among the four submodules,\nMetaDetector accurately transfers the meta-knowledge of historical events to\nthe upcoming event for fact checking. We conduct extensive experiments on two\nlarge-scale datasets collected from Weibo and Twitter. The experimental results\ndemonstrate that MetaDetector outperforms the state-of-the-art methods,\nespecially when the distribution shift between events is significant.\nFurthermore, we find that MetaDetector is able to learn the event-shared\nfeatures, and alleviate the negative transfer caused by the large distribution\nshift between events.", "author": [{"name": "Yasan Ding"}, {"name": "Bin Guo"}, {"name": "Yan Liu"}, {"name": "Yunji Liang"}, {"name": "Haocheng Shen"}, {"name": "Zhiwen Yu"}], "link": [{"@href": "http://arxiv.org/abs/2106.11177v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.11177v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.13687v1", "updated": "2021-08-31T08:55:47Z", "published": "2021-08-31T08:55:47Z", "title": "The coercive logic of fake news", "summary": "The spread of misinformation and \"fake news\" continues to be a major focus of\npublic concern. A great deal of recent research has examined who falls for\nmisinformation and why, and what can be done to make people more discerning\nconsumers of news. Comparatively little work, however, has considered the\nchoices of those who produce misinformation, and how these choices interact\nwith the psychology of news consumers. Here we use game-theoretic models to\nstudy the strategic interaction between news publishers and news readers. We\nshow that publishers who seek to spread misinformation can generate high\nengagement with falsehoods by using strategies that mix true and false stories\nover time, in such a way that they serve more false stories to more loyal\nreaders. These coercive strategies cause false stories to receive higher reader\nengagement than true stories - even when readers strictly prefer truth over\nfalsehood. In contrast, publishers who seek to promote engagement with accurate\ninformation will use strategies that generate more engagement with true stories\nthan with false stories. We confirm these predictions empirically by examining\n1,000 headlines from 20 mainstream and 20 fake news sites, comparing Facebook\nengagement data with 20,000 perceived accuracy ratings collected in a survey\nexperiment. We then use our model to analyze possible ways to disincentivize\nfake news, finding that reducing the capacity of news sources to microtarget\nreaders, and increasing readers' level of attention, reduces the efficacy of\ncoercion. Finally, we show that if a publisher incorrectly assumes that readers\nprefer falsehoods, their resulting publication strategy can manufacture greater\nengagement with false news - leading to a self-reinforcing cycle of false news\npromotion.", "author": [{"name": "Alexander J. Stewart"}, {"name": "Antonio A. Arechar"}, {"name": "David G. Rand"}, {"name": "Joshua B. Plotkin"}], "link": [{"@href": "http://arxiv.org/abs/2108.13687v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.13687v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "econ.TH", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "econ.TH", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1801.08159v1", "updated": "2018-01-24T19:38:00Z", "published": "2018-01-24T19:38:00Z", "title": "Adversarial Classification on Social Networks", "summary": "The spread of unwanted or malicious content through social media has become a\nmajor challenge. Traditional examples of this include social network spam, but\nan important new concern is the propagation of fake news through social media.\nA common approach for mitigating this problem is by using standard statistical\nclassification to distinguish malicious (e.g., fake news) instances from benign\n(e.g., actual news stories). However, such an approach ignores the fact that\nmalicious instances propagate through the network, which is consequential both\nin quantifying consequences (e.g., fake news diffusing through the network),\nand capturing detection redundancy (bad content can be detected at different\nnodes). An additional concern is evasion attacks, whereby the generators of\nmalicious instances modify the nature of these to escape detection. We model\nthis problem as a Stackelberg game between the defender who is choosing\nparameters of the detection model, and an attacker, who is choosing both the\nnode at which to initiate malicious spread, and the nature of malicious\nentities. We develop a novel bi-level programming approach for this problem, as\nwell as a novel solution approach based on implicit function gradients, and\nexperimentally demonstrate the advantage of our approach over alternatives\nwhich ignore network structure.", "author": [{"name": "Sixie Yu"}, {"name": "Yevgeniy Vorobeychik"}, {"name": "Scott Alfeld"}], "link": [{"@href": "http://arxiv.org/abs/1801.08159v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1801.08159v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.09516v3", "updated": "2020-05-06T13:25:07Z", "published": "2019-10-21T17:14:52Z", "title": "Reversible bootstrap percolation: Fake news and fact checking", "summary": "Bootstrap percolation has been used to describe opinion formation in society\nand other social and natural phenomena. The formal equation of the bootstrap\npercolation may have more than one solution, corresponding to several stable\nfixed points of the corresponding iteration process. We construct a reversible\nbootstrap percolation process, which converges to these extra solutions\ndisplaying a hysteresis typical of discontinuous phase transitions. This\nprocess provides a reasonable model for fake news spreading and the\neffectiveness of fact checking. We show that sometimes it is not sufficient to\ndiscard all the sources of fake news in order to reverse the belief of a\npopulation that formed under the influence of these sources.", "author": [{"name": "M. A. Di Muro"}, {"name": "S. V. Buldyrev"}, {"name": "L. A. Braunstein"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevE.101.042307"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevE.101.042307", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1910.09516v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.09516v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys. Rev. E 101, 042307 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1910.12203v1", "updated": "2019-10-27T07:44:33Z", "published": "2019-10-27T07:44:33Z", "title": "Do Sentence Interactions Matter? Leveraging Sentence Level\n  Representations for Fake News Classification", "summary": "The rising growth of fake news and misleading information through online\nmedia outlets demands an automatic method for detecting such news articles. Of\nthe few limited works which differentiate between trusted vs other types of\nnews article (satire, propaganda, hoax), none of them model sentence\ninteractions within a document. We observe an interesting pattern in the way\nsentences interact with each other across different kind of news articles. To\ncapture this kind of information for long news articles, we propose a graph\nneural network-based model which does away with the need of feature engineering\nfor fine grained fake news classification. Through experiments, we show that\nour proposed method beats strong neural baselines and achieves state-of-the-art\naccuracy on existing datasets. Moreover, we establish the generalizability of\nour model by evaluating its performance in out-of-domain scenarios. Code is\navailable at https://github.com/MysteryVaibhav/fake_news_semantics", "author": [{"name": "Vaibhav Vaibhav"}, {"name": "Raghuram Mandyam Annasamy"}, {"name": "Eduard Hovy"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at TextGraphs - EMNLP 2019"}, "link": [{"@href": "http://arxiv.org/abs/1910.12203v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.12203v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1707.03264v2", "updated": "2018-05-21T10:31:40Z", "published": "2017-07-11T13:44:51Z", "title": "A simple but tough-to-beat baseline for the Fake News Challenge stance\n  detection task", "summary": "Identifying public misinformation is a complicated and challenging task. An\nimportant part of checking the veracity of a specific claim is to evaluate the\nstance different news sources take towards the assertion. Automatic stance\nevaluation, i.e. stance detection, would arguably facilitate the process of\nfact checking. In this paper, we present our stance detection system which\nclaimed third place in Stage 1 of the Fake News Challenge. Despite our\nstraightforward approach, our system performs at a competitive level with the\ncomplex ensembles of the top two winning teams. We therefore propose our system\nas the 'simple but tough-to-beat baseline' for the Fake News Challenge stance\ndetection task.", "author": [{"name": "Benjamin Riedel"}, {"name": "Isabelle Augenstein"}, {"name": "Georgios P. Spithourakis"}, {"name": "Sebastian Riedel"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 1 figure, 3 tables; additional reference and details added,\n  typos and wording corrected"}, "link": [{"@href": "http://arxiv.org/abs/1707.03264v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1707.03264v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1804.02509v1", "updated": "2018-04-07T04:46:31Z", "published": "2018-04-07T04:46:31Z", "title": "Incentivizing the Dissemination of Truth Versus Fake News in Social\n  Networks", "summary": "The concept of truth, as a public good is the production of a collective\nunderstanding, which emerges from a complex network of social interactions. The\nrecent impact of social networks on shaping the perception of truth in\npolitical arena shows how such perception is corroborated and established by\nthe online users, collectively. However, investigative journalism for\ndiscovering truth is a costly option, given the vast spectrum of online\ninformation. In some cases, both journalist and online users choose not to\ninvestigate the authenticity of the news they receive, because they assume\nother actors of the network had carried the cost of validation. Therefore, the\nnew phenomenon of \"fake news\" has emerged within the context of social\nnetworks. The online social networks, similarly to System of Systems, cause\nemergent properties, which makes authentication processes difficult, given\navailability of multiple sources. In this study, we show how this conflict can\nbe modeled as a volunteer's dilemma. We also show how the public contribution\nthrough news subscription (shared rewards) can impact the dominance of truth\nover fake news in the network.", "author": [{"name": "Abbas Ehsanfar"}, {"name": "Mo Mansouri"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "System of Systems Engineering Conference (SoSE), 2017 12th. IEEE,\n  2017"}, "link": [{"@href": "http://arxiv.org/abs/1804.02509v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.02509v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.00788v2", "updated": "2019-12-12T07:46:43Z", "published": "2019-03-24T07:27:51Z", "title": "Neural Abstractive Text Summarization and Fake News Detection", "summary": "In this work, we study abstractive text summarization by exploring different\nmodels such as LSTM-encoder-decoder with attention, pointer-generator networks,\ncoverage mechanisms, and transformers. Upon extensive and careful\nhyperparameter tuning we compare the proposed architectures against each other\nfor the abstractive text summarization task. Finally, as an extension of our\nwork, we apply our text summarization model as a feature extractor for a fake\nnews detection task where the news articles prior to classification will be\nsummarized and the results are compared against the classification using only\nthe original news text.\n  keywords: LSTM, encoder-deconder, abstractive text summarization,\npointer-generator, coverage mechanism, transformers, fake news detection", "author": [{"name": "Soheil Esmaeilzadeh"}, {"name": "Gao Xian Peh"}, {"name": "Angela Xu"}], "link": [{"@href": "http://arxiv.org/abs/1904.00788v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.00788v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.05386v2", "updated": "2019-10-20T19:30:09Z", "published": "2019-04-10T18:42:45Z", "title": "Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality", "summary": "The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media.", "author": [{"name": "Paula Fraga-Lamas"}, {"name": "Tiago M. Fern\u00e1ndez-Caram\u00e9s"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Updated version"}, "link": [{"@href": "http://arxiv.org/abs/1904.05386v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.05386v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.05659v1", "updated": "2019-06-10T21:19:41Z", "published": "2019-06-10T21:19:41Z", "title": "Deep Two-path Semi-supervised Learning for Fake News Detection", "summary": "News in social media such as Twitter has been generated in high volume and\nspeed. However, very few of them can be labeled (as fake or true news) in a\nshort time. In order to achieve timely detection of fake news in social media,\na novel deep two-path semi-supervised learning model is proposed, where one\npath is for supervised learning and the other is for unsupervised learning.\nThese two paths implemented with convolutional neural networks are jointly\noptimized to enhance detection performance. In addition, we build a shared\nconvolutional neural networks between these two paths to share the low level\nfeatures. Experimental results using Twitter datasets show that the proposed\nmodel can recognize fake news effectively with very few labeled data.", "author": [{"name": "Xishuang Dong"}, {"name": "Uboho Victor"}, {"name": "Shanta Chowdhury"}, {"name": "Lijun Qian"}], "link": [{"@href": "http://arxiv.org/abs/1906.05659v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.05659v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1907.00181v1", "updated": "2019-06-29T11:00:22Z", "published": "2019-06-29T11:00:22Z", "title": "Fake News Detection using Stance Classification: A Survey", "summary": "This paper surveys and presents recent academic work carried out within the\nfield of stance classification and fake news detection. Echo chambers and the\nmodel organism problem are examples that pose challenges to acquire data with\nhigh quality, due to opinions being polarised in microblogs. Nevertheless it is\nshown that several machine learning approaches achieve promising results in\nclassifying stance. Some use crowd stance for fake news detection, such as the\napproach in [Dungs et al., 2018] using Hidden Markov Models. Furthermore\nfeature engineering have significant importance in several approaches, which is\nshown in [Aker et al., 2017]. This paper additionally includes a proposal of a\nsystem implementation based on the presented survey.", "author": [{"name": "Anders Edelbo Lillie"}, {"name": "Emil Refsgaard Middelboe"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "19 pages, 1 figure"}, "link": [{"@href": "http://arxiv.org/abs/1907.00181v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.00181v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.01760v1", "updated": "2019-08-05T17:59:44Z", "published": "2019-08-05T17:59:44Z", "title": "The Myths of Our Time: Fake News", "summary": "While the purpose of most fake news is misinformation and political\npropaganda, our team sees it as a new type of myth that is created by people in\nthe age of internet identities and artificial intelligence. Seeking insights on\nthe fear and desire hidden underneath these modified or generated stories, we\nuse machine learning methods to generate fake articles and present them in the\nform of an online news blog. This paper aims to share the details of our\npipeline and the techniques used for full generation of fake news, from dataset\ncollection to presentation as a media art project on the internet.", "author": [{"name": "V\u00edt R\u016f\u017ei\u010dka"}, {"name": "Eunsu Kang"}, {"name": "David Gordon"}, {"name": "Ankita Patel"}, {"name": "Jacqui Fashimpaur"}, {"name": "Manzil Zaheer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages, 5 figures, in proceedings of International Symposium on\n  Electronic Art 2019 (ISEA)"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of International Symposium on Electronic Art 2019\n  (ISEA), pages 494-498"}, "link": [{"@href": "http://arxiv.org/abs/1908.01760v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.01760v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.09805v2", "updated": "2020-02-20T18:32:33Z", "published": "2019-08-26T17:23:22Z", "title": "The Limitations of Stylometry for Detecting Machine-Generated Fake News", "summary": "Recent developments in neural language models (LMs) have raised concerns\nabout their potential misuse for automatically spreading misinformation. In\nlight of these concerns, several studies have proposed to detect\nmachine-generated fake news by capturing their stylistic differences from\nhuman-written text. These approaches, broadly termed stylometry, have found\nsuccess in source attribution and misinformation detection in human-written\ntexts. However, in this work, we show that stylometry is limited against\nmachine-generated misinformation. While humans speak differently when trying to\ndeceive, LMs generate stylistically consistent text, regardless of underlying\nmotive. Thus, though stylometry can successfully prevent impersonation by\nidentifying text provenance, it fails to distinguish legitimate LM applications\nfrom those that introduce false information. We create two benchmarks\ndemonstrating the stylistic similarity between malicious and legitimate uses of\nLMs, employed in auto-completion and editing-assistance settings. Our findings\nhighlight the need for non-stylometry approaches in detecting machine-generated\nmisinformation, and open up the discussion on the desired evaluation\nbenchmarks.", "author": [{"name": "Tal Schuster"}, {"name": "Roei Schuster"}, {"name": "Darsh J Shah"}, {"name": "Regina Barzilay"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for Computational Linguistics journal (squib). Previously\n  posted with title \"Are We Safe Yet? The Limitations of Distributional\n  Features for Fake News Detection\""}, "link": [{"@href": "http://arxiv.org/abs/1908.09805v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.09805v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.01720v1", "updated": "2019-09-04T12:15:02Z", "published": "2019-09-04T12:15:02Z", "title": "Different Absorption from the Same Sharing: Sifted Multi-task Learning\n  for Fake News Detection", "summary": "Recently, neural networks based on multi-task learning have achieved\npromising performance on fake news detection, which focus on learning shared\nfeatures among tasks as complementary features to serve different tasks.\nHowever, in most of the existing approaches, the shared features are completely\nassigned to different tasks without selection, which may lead to some useless\nand even adverse features integrated into specific tasks. In this paper, we\ndesign a sifted multi-task learning method with a selected sharing layer for\nfake news detection. The selected sharing layer adopts gate mechanism and\nattention mechanism to filter and select shared feature flows between tasks.\nExperiments on two public and widely used competition datasets, i.e. RumourEval\nand PHEME, demonstrate that our proposed method achieves the state-of-the-art\nperformance and boosts the F1-score by more than 0.87%, 1.31%, respectively.", "author": [{"name": "Lianwei Wu"}, {"name": "Yuan Rao"}, {"name": "Haolin Jin"}, {"name": "Ambreen Nazir"}, {"name": "Ling Sun"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 5 figures, EMNLP 2019"}, "link": [{"@href": "http://arxiv.org/abs/1909.01720v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.01720v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.08125v1", "updated": "2019-11-19T07:06:22Z", "published": "2019-11-19T07:06:22Z", "title": "In Search of Credible News", "summary": "We study the problem of finding fake online news. This is an important\nproblem as news of questionable credibility have recently been proliferating in\nsocial media at an alarming scale. As this is an understudied problem,\nespecially for languages other than English, we first collect and release to\nthe research community three new balanced credible vs. fake news datasets\nderived from four online sources. We then propose a language-independent\napproach for automatically distinguishing credible from fake news, based on a\nrich feature set. In particular, we use linguistic (n-gram),\ncredibility-related (capitalization, punctuation, pronoun use, sentiment\npolarity), and semantic (embeddings and DBPedia data) features. Our experiments\non three different testsets show that our model can distinguish credible from\nfake news with very high accuracy.", "author": [{"name": "Momchil Hardalov"}, {"name": "Ivan Koychev"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Credibility, veracity, fact checking, humor detection"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AIMSA-2016"}, "link": [{"@href": "http://arxiv.org/abs/1911.08125v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.08125v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.11920v1", "updated": "2019-11-27T02:33:24Z", "published": "2019-11-27T02:33:24Z", "title": "Warning Signs in Communicating the Machine Learning Detection Results of\n  Misinformation with Individuals", "summary": "With the prevalence of misinformation online, researchers have focused on\ndeveloping various machine learning algorithms to detect fake news. However,\nusers' perception of machine learning outcomes and related behaviors have been\nwidely ignored. Hence, this paper proposed to bridge this gap by studying how\nto pass the detection results of machine learning to the users, and aid their\ndecisions in handling misinformation. An online experiment was conducted, to\nevaluate the effect of the proposed machine learning warning sign against a\ncontrol condition. We examined participants' detection and sharing of news. The\ndata showed that warning sign's effects on participants' trust toward the fake\nnews were not significant. However, we found that people's uncertainty about\nthe authenticity of the news dropped with the presence of the machine learning\nwarning sign. We also found that social media experience had effects on users'\ntrust toward the fake news, and age and social media experience had effects on\nusers' sharing decision. Therefore, the results indicate that there are many\nfactors worth studying that affect people's trust in the news. Moreover, the\nwarning sign in communicating machine learning detection results is different\nfrom ordinary warnings and needs more detailed research and design. These\nfindings hold important implications for the design of machine learning\nwarnings.", "author": {"name": "Limeng Cui"}, "link": [{"@href": "http://arxiv.org/abs/1911.11920v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.11920v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.5.2", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.00763v1", "updated": "2020-01-31T02:28:35Z", "published": "2020-01-31T02:28:35Z", "title": "Two-path Deep Semi-supervised Learning for Timely Fake News Detection", "summary": "News in social media such as Twitter has been generated in high volume and\nspeed. However, very few of them are labeled (as fake or true news) by\nprofessionals in near real time. In order to achieve timely detection of fake\nnews in social media, a novel framework of two-path deep semi-supervised\nlearning is proposed where one path is for supervised learning and the other is\nfor unsupervised learning. The supervised learning path learns on the limited\namount of labeled data while the unsupervised learning path is able to learn on\na huge amount of unlabeled data. Furthermore, these two paths implemented with\nconvolutional neural networks (CNN) are jointly optimized to complete\nsemi-supervised learning. In addition, we build a shared CNN to extract the low\nlevel features on both labeled data and unlabeled data to feed them into these\ntwo paths. To verify this framework, we implement a Word CNN based\nsemi-supervised learning model and test it on two datasets, namely, LIAR and\nPHEME. Experimental results demonstrate that the model built on the proposed\nframework can recognize fake news effectively with very few labeled data.", "author": [{"name": "Xishuang Dong"}, {"name": "Uboho Victor"}, {"name": "Lijun Qian"}], "link": [{"@href": "http://arxiv.org/abs/2002.00763v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.00763v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2002.00837v2", "updated": "2020-03-30T06:08:08Z", "published": "2020-01-27T17:27:58Z", "title": "Ginger Cannot Cure Cancer: Battling Fake Health News with a\n  Comprehensive Data Repository", "summary": "Nowadays, Internet is a primary source of attaining health information.\nMassive fake health news which is spreading over the Internet, has become a\nsevere threat to public health. Numerous studies and research works have been\ndone in fake news detection domain, however, few of them are designed to cope\nwith the challenges in health news. For instance, the development of\nexplainable is required for fake health news detection. To mitigate these\nproblems, we construct a comprehensive repository, FakeHealth, which includes\nnews contents with rich features, news reviews with detailed explanations,\nsocial engagements and a user-user social network. Moreover, exploratory\nanalyses are conducted to understand the characteristics of the datasets,\nanalyze useful patterns and validate the quality of the datasets for health\nfake news detection. We also discuss the novel and potential future research\ndirections for the health fake news detection.", "author": [{"name": "Enyan Dai"}, {"name": "Yiwei Sun"}, {"name": "Suhang Wang"}], "link": [{"@href": "http://arxiv.org/abs/2002.00837v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2002.00837v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.04374v1", "updated": "2020-08-10T19:21:06Z", "published": "2020-08-10T19:21:06Z", "title": "Can We Spot the \"Fake News\" Before It Was Even Written?", "summary": "Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n\"fake news.\" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.", "author": {"name": "Preslav Nakov"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Fake News, Disinformation, Media Bias, Propaganda, Infodemic,\n  COVID-19"}, "link": [{"@href": "http://arxiv.org/abs/2008.04374v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.04374v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.07939v2", "updated": "2020-10-08T11:45:23Z", "published": "2020-08-18T14:05:16Z", "title": "FANG: Leveraging Social Context for Fake News Detection Using Graph\n  Representation", "summary": "We propose Factual News Graph (FANG), a novel graphical social context\nrepresentation and learning framework for fake news detection. Unlike previous\ncontextual models that have targeted performance, our focus is on\nrepresentation learning. Compared to transductive models, FANG is scalable in\ntraining as it does not have to maintain all nodes, and it is efficient at\ninference time, without the need to re-process the entire graph. Our\nexperimental results show that FANG is better at capturing the social context\ninto a high fidelity representation, compared to recent graphical and\nnon-graphical models. In particular, FANG yields significant improvements for\nthe task of fake news detection, and it is robust in the case of limited\ntraining data. We further demonstrate that the representations learned by FANG\ngeneralize to related tasks, such as predicting the factuality of reporting of\na news medium.", "author": [{"name": "Van-Hoang Nguyen"}, {"name": "Kazunari Sugiyama"}, {"name": "Preslav Nakov"}, {"name": "Min-Yen Kan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3340531.3412046"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3340531.3412046", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.07939v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.07939v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear in CIKM 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.05496v2", "updated": "2020-11-03T11:32:14Z", "published": "2020-10-12T07:43:01Z", "title": "Feature Extraction of Text for Deep Learning Algorithms: Application on\n  Fake News Detection", "summary": "Feature extraction is an important process of machine learning and deep\nlearning, as the process make algorithms function more efficiently, and also\naccurate. In natural language processing used in deception detection such as\nfake news detection, several ways of feature extraction in statistical aspect\nhad been introduced (e.g. N-gram). In this research, it will be shown that by\nusing deep learning algorithms and alphabet frequencies of the original text of\na news without any information about the sequence of the alphabet can actually\nbe used to classify fake news and trustworthy ones in high accuracy (85\\%). As\nthis pre-processing method makes the data notably compact but also include the\nfeature that is needed for the classifier, it seems that alphabet frequencies\ncontains some useful features for understanding complex context or meaning of\nthe original text.", "author": {"name": "HyeonJun Kim"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages"}, "link": [{"@href": "http://arxiv.org/abs/2010.05496v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.05496v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.07517v1", "updated": "2020-11-30T16:41:04Z", "published": "2020-11-30T16:41:04Z", "title": "Fake News Detection in Social Media using Graph Neural Networks and NLP\n  Techniques: A COVID-19 Use-case", "summary": "The paper presents our solutions for the MediaEval 2020 task namely FakeNews:\nCorona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task\naims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect\nmisinformation spreaders. The task is composed of two sub-tasks namely (i)\ntext-based, and (ii) structure-based fake news detection. For the first task,\nwe propose six different solutions relying on Bag of Words (BoW) and BERT\nembedding. Three of the methods aim at binary classification task by\ndifferentiating in 5G conspiracy and the rest of the COVID-19 related tweets\nwhile the rest of them treat the task as ternary classification problem. In the\nternary classification task, our BoW and BERT based methods obtained an\nF1-score of .606% and .566% on the development set, respectively. On the binary\nclassification, the BoW and BERT based solutions obtained an average F1-score\nof .666% and .693%, respectively. On the other hand, for structure-based fake\nnews detection, we rely on Graph Neural Networks (GNNs) achieving an average\nROC of .95% on the development set.", "author": [{"name": "Abdullah Hamid"}, {"name": "Nasrullah Shiekh"}, {"name": "Naina Said"}, {"name": "Kashif Ahmad"}, {"name": "Asma Gul"}, {"name": "Laiq Hassan"}, {"name": "Ala Al-Fuqaha"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "3 pages"}, "link": [{"@href": "http://arxiv.org/abs/2012.07517v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.07517v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.11967v3", "updated": "2021-01-13T11:36:32Z", "published": "2020-12-22T12:43:12Z", "title": "g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning\n  for COVID-19 Fake News Detection", "summary": "The COVID-19 pandemic has had a huge impact on various areas of human life.\nHence, the coronavirus pandemic and its consequences are being actively\ndiscussed on social media. However, not all social media posts are truthful.\nMany of them spread fake news that cause panic among readers, misinform people\nand thus exacerbate the effect of the pandemic. In this paper, we present our\nresults at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in\nEnglish. In particular, we propose our approach using the transformer-based\nensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used,\nthe ways of text preprocessing and adding extra data. As a result, our best\nmodel achieved the weighted F1-score of 98.69 on the test set (the first place\nin the leaderboard) of this shared task that attracted 166 submitted teams in\ntotal.", "author": [{"name": "Anna Glazkova"}, {"name": "Maksim Glazkov"}, {"name": "Timofey Trifonov"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-73696-5_12"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-73696-5_12", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2012.11967v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.11967v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The winning solution at the Constraint shared task (AAAI-2021)"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Combating Online Hostile Posts in Regional Languages during\n  Emergency Situation, 116-127, 2021. Springer, Cham"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7; I.7.m; H.3.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.00606v1", "updated": "2021-01-03T11:12:23Z", "published": "2021-01-03T11:12:23Z", "title": "News Image Steganography: A Novel Architecture Facilitates the Fake News\n  Identification", "summary": "A larger portion of fake news quotes untampered images from other sources\nwith ulterior motives rather than conducting image forgery. Such elaborate\nengraftments keep the inconsistency between images and text reports stealthy,\nthereby, palm off the spurious for the genuine. This paper proposes an\narchitecture named News Image Steganography (NIS) to reveal the aforementioned\ninconsistency through image steganography based on GAN. Extractive\nsummarization about a news image is generated based on its source texts, and a\nlearned steganographic algorithm encodes and decodes the summarization of the\nimage in a manner that approaches perceptual invisibility. Once an encoded\nimage is quoted, its source summarization can be decoded and further presented\nas the ground truth to verify the quoting news. The pairwise encoder and\ndecoder endow images of the capability to carry along their imperceptible\nsummarization. Our NIS reveals the underlying inconsistency, thereby, according\nto our experiments and investigations, contributes to the identification\naccuracy of fake news that engrafts untampered images.", "author": [{"name": "Jizhe Zhou"}, {"name": "Chi-Man Pun"}, {"name": "Yu Tong"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/VCIP49819.2020.9301846"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/VCIP49819.2020.9301846", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2101.00606v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.00606v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.03529v1", "updated": "2021-01-10T11:52:17Z", "published": "2021-01-10T11:52:17Z", "title": "TIB's Visual Analytics Group at MediaEval '20: Detecting Fake News on\n  Corona Virus and 5G Conspiracy", "summary": "Fake news on social media has become a hot topic of research as it negatively\nimpacts the discourse of real news in the public. Specifically, the ongoing\nCOVID-19 pandemic has seen a rise of inaccurate and misleading information due\nto the surrounding controversies and unknown details at the beginning of the\npandemic. The FakeNews task at MediaEval 2020 tackles this problem by creating\na challenge to automatically detect tweets containing misinformation based on\ntext and structure from Twitter follower network. In this paper, we present a\nsimple approach that uses BERT embeddings and a shallow neural network for\nclassifying tweets using only text, and discuss our findings and limitations of\nthe approach in text-based misinformation detection.", "author": [{"name": "Gullal S. Cheema"}, {"name": "Sherzod Hakimov"}, {"name": "Ralph Ewerth"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MediaEval 2020 Fake News Task"}, "link": [{"@href": "http://arxiv.org/abs/2101.03529v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.03529v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.03988v2", "updated": "2021-06-30T18:35:03Z", "published": "2021-01-11T15:52:37Z", "title": "Identification of COVID-19 related Fake News via Neural Stacking", "summary": "Identification of Fake News plays a prominent role in the ongoing pandemic,\nimpacting multiple aspects of day-to-day life. In this work we present a\nsolution to the shared task titled COVID19 Fake News Detection in English,\nscoring the 50th place amongst 168 submissions. The solution was within 1.5% of\nthe best performing solution. The proposed solution employs a heterogeneous\nrepresentation ensemble, adapted for the classification task via an additional\nneural classification head comprised of multiple hidden layers. The paper\nconsists of detailed ablation studies further displaying the proposed method's\nbehavior and possible implications. The solution is freely available.\n\\url{https://gitlab.com/boshko.koloski/covid19-fake-news}", "author": [{"name": "Boshko Koloski"}, {"name": "Timen Stepi\u0161nik Perdih"}, {"name": "Senja Pollak"}, {"name": "Bla\u017e \u0160krlj"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-73696-5_17"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-73696-5_17", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2101.03988v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.03988v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at CONSTRAIN 2021 (AAAI)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.04965v1", "updated": "2021-01-13T09:52:04Z", "published": "2021-01-13T09:52:04Z", "title": "LaDiff ULMFiT: A Layer Differentiated training approach for ULMFiT", "summary": "In our paper, we present Deep Learning models with a layer differentiated\ntraining method which were used for the SHARED TASK@ CONSTRAINT 2021 sub-tasks\nCOVID19 Fake News Detection in English and Hostile Post Detection in Hindi. We\npropose a Layer Differentiated training procedure for training a pre-trained\nULMFiT arXiv:1801.06146 model. We used special tokens to annotate specific\nparts of the tweets to improve language understanding and gain insights on the\nmodel making the tweets more interpretable. The other two submissions included\na modified RoBERTa model and a simple Random Forest Classifier. The proposed\napproach scored a precision and f1 score of 0.96728972 and 0.967324832\nrespectively for sub-task \"COVID19 Fake News Detection in English\". Also,\nCoarse-Grained Hostility f1 Score and Weighted FineGrained f1 score of 0.908648\nand 0.533907 respectively for sub-task Hostile Post Detection in Hindi. The\nproposed approach ranked 61st out of 164 in the sub-task \"COVID19 Fake News\nDetection in English and 18th out of 45 in the sub-task Hostile Post Detection\nin Hindi\".", "author": [{"name": "Mohammed Azhan"}, {"name": "Mohammad Ahmad"}], "link": [{"@href": "http://arxiv.org/abs/2101.04965v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.04965v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.09810v1", "updated": "2021-01-24T21:55:28Z", "published": "2021-01-24T21:55:28Z", "title": "FakeFlow: Fake News Detection by Modeling the Flow of Affective\n  Information", "summary": "Fake news articles often stir the readers' attention by means of emotional\nappeals that arouse their feelings. Unlike in short news texts, authors of\nlonger articles can exploit such affective factors to manipulate readers by\nadding exaggerations or fabricating events, in order to affect the readers'\nemotions. To capture this, we propose in this paper to model the flow of\naffective information in fake news articles using a neural architecture. The\nproposed model, FakeFlow, learns this flow by combining topic and affective\ninformation extracted from text. We evaluate the model's performance with\nseveral experiments on four real-world datasets. The results show that FakeFlow\nachieves superior results when compared against state-of-the-art methods, thus\nconfirming the importance of capturing the flow of the affective information in\nnews articles.", "author": [{"name": "Bilal Ghanem"}, {"name": "Simone Paolo Ponzetto"}, {"name": "Paolo Rosso"}, {"name": "Francisco Rangel"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 6 figures, EACL-2021"}, "link": [{"@href": "http://arxiv.org/abs/2101.09810v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.09810v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.11425v1", "updated": "2021-01-12T16:23:24Z", "published": "2021-01-12T16:23:24Z", "title": "Fake News Detection System using XLNet model with Topic Distributions:\n  CONSTRAINT@AAAI2021 Shared Task", "summary": "With the ease of access to information, and its rapid dissemination over the\ninternet (both velocity and volume), it has become challenging to filter out\ntruthful information from fake ones. The research community is now faced with\nthe task of automatic detection of fake news, which carries real-world\nsocio-political impact. One such research contribution came in the form of the\nConstraint@AAA12021 Shared Task on COVID19 Fake News Detection in English. In\nthis paper, we shed light on a novel method we proposed as a part of this\nshared task. Our team introduced an approach to combine topical distributions\nfrom Latent Dirichlet Allocation (LDA) with contextualized representations from\nXLNet. We also compared our method with existing baselines to show that XLNet +\nTopic Distributions outperforms other approaches by attaining an F1-score of\n0.967.", "author": [{"name": "Akansha Gautam"}, {"name": "Venktesh V"}, {"name": "Sarah Masud"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at CONSTRAINT@AAAI2021 Shared Task for the CONSTRAINT\n  workshop, collocated with AAAI 2021"}, "link": [{"@href": "http://arxiv.org/abs/2101.11425v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.11425v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.12027v1", "updated": "2021-01-28T14:43:42Z", "published": "2021-01-28T14:43:42Z", "title": "A transformer based approach for fighting COVID-19 fake news", "summary": "The rapid outbreak of COVID-19 has caused humanity to come to a stand-still\nand brought with it a plethora of other problems. COVID-19 is the first\npandemic in history when humanity is the most technologically advanced and\nrelies heavily on social media platforms for connectivity and other benefits.\nUnfortunately, fake news and misinformation regarding this virus is also\navailable to people and causing some massive problems. So, fighting this\ninfodemic has become a significant challenge. We present our solution for the\n\"Constraint@AAAI2021 - COVID19 Fake News Detection in English\" challenge in\nthis work. After extensive experimentation with numerous architectures and\ntechniques, we use eight different transformer-based pre-trained models with\nadditional layers to construct a stacking ensemble classifier and fine-tuned\nthem for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,\n0.979906542 recall, and 0.979907901 f1-score on the test dataset of the\ncompetition.", "author": [{"name": "S. M. Sadiq-Ur-Rahman Shifath"}, {"name": "Mohammad Faiyaz Khan"}, {"name": "Md. Saiful Islam"}], "link": [{"@href": "http://arxiv.org/abs/2101.12027v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.12027v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.09470v1", "updated": "2021-02-18T16:42:28Z", "published": "2021-02-18T16:42:28Z", "title": "Fake News Detection: a comparison between available Deep Learning\n  techniques in vector space", "summary": "Fake News Detection is an essential problem in the field of Natural Language\nProcessing. The benefits of an effective solution in this area are manifold for\nthe goodwill of society. On a surface level, it broadly matches with the\ngeneral problem of text classification. Researchers have proposed various\napproaches to tackle fake news using simple as well as some complex techniques.\nIn this paper, we try to make a comparison between the present Deep Learning\ntechniques by representing the news instances in some vector space using a\ncombination of common mathematical operations with available vector space\nrepresentations. We do a number of experiments using various combinations and\npermutations. Finally, we conclude with a sound analysis of the results and\nevaluate the reasons for such results.", "author": {"name": "Lovedeep Singh"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/CICT51604.2020.9312099"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/CICT51604.2020.9312099", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2102.09470v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.09470v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "for citiation purpose, use details available on official IEEE Xplore\n  page: https://doi.org/10.1109/CICT51604.2020.9312099"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "2020 IEEE 4th Conference on Information & Communication Technology\n  (CICT)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.09602v1", "updated": "2021-03-17T12:40:27Z", "published": "2021-03-17T12:40:27Z", "title": "On the Role of Images for Analyzing Claims in Social Media", "summary": "Fake news is a severe problem in social media. In this paper, we present an\nempirical study on visual, textual, and multimodal models for the tasks of\nclaim, claim check-worthiness, and conspiracy detection, all of which are\nrelated to fake news detection. Recent work suggests that images are more\ninfluential than text and often appear alongside fake text. To this end,\nseveral multimodal models have been proposed in recent years that use images\nalong with text to detect fake news on social media sites like Twitter.\nHowever, the role of images is not well understood for claim detection,\nspecifically using transformer-based textual and multimodal models. We\ninvestigate state-of-the-art models for images, text (Transformer-based), and\nmultimodal information for four different datasets across two languages to\nunderstand the role of images in the task of claim and conspiracy detection.", "author": [{"name": "Gullal S. Cheema"}, {"name": "Sherzod Hakimov"}, {"name": "Eric M\u00fcller-Budack"}, {"name": "Ralph Ewerth"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEOPATRA-2021 Workshop co-located with The Web Conf 2021"}, "link": [{"@href": "http://arxiv.org/abs/2103.09602v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.09602v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.07698v1", "updated": "2021-05-17T09:34:03Z", "published": "2021-05-17T09:34:03Z", "title": "Automatic Fake News Detection: Are Models Learning to Reason?", "summary": "Most fact checking models for automatic fake news detection are based on\nreasoning: given a claim with associated evidence, the models aim to estimate\nthe claim veracity based on the supporting or refuting content within the\nevidence. When these models perform well, it is generally assumed to be due to\nthe models having learned to reason over the evidence with regards to the\nclaim. In this paper, we investigate this assumption of reasoning, by exploring\nthe relationship and importance of both claim and evidence. Surprisingly, we\nfind on political fact checking datasets that most often the highest\neffectiveness is obtained by utilizing only the evidence, as the impact of\nincluding the claim is either negligible or harmful to the effectiveness. This\nhighlights an important problem in what constitutes evidence in existing\napproaches for automatic fake news detection.", "author": [{"name": "Casper Hansen"}, {"name": "Christian Hansen"}, {"name": "Lucas Chaves Lima"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at ACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2105.07698v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.07698v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.07435v1", "updated": "2021-06-14T13:56:26Z", "published": "2021-06-14T13:56:26Z", "title": "Both Rates of Fake News and Fact-based News on Twitter Negatively\n  Correlate with the State-level COVID-19 Vaccine Uptake", "summary": "There is evidence of misinformation in the online discourses and discussions\nabout the COVID-19 vaccines. Using a sample of 1.6 million geotagged English\ntweets and the data from the CDC COVID Data Tracker, we conduct a quantitative\nstudy to understand the influence of both misinformation and fact-based news on\nTwitter on the COVID-19 vaccine uptake in the U.S. from April 19 when U.S.\nadults were vaccine eligible to May 7, 2021, after controlling state-level\nfactors such as demographics, education, and the pandemic severity. We identify\nthe tweets related to either misinformation or fact-based news by analyzing the\nURLs. By analyzing the content of the most frequent tweets of these two groups,\nwe find that their structures are similar, making it difficult for Twitter\nusers to distinguish one from another by reading the text alone. The users who\nspread both fake news and fact-based news tend to show a negative attitude\ntowards the vaccines. We further conduct the Fama-MacBeth regression with the\nNewey-West adjustment to examine the effect of fake-news-related and\nfact-related tweets on the vaccination rate, and find marginally negative\ncorrelations.", "author": [{"name": "Hanjia Lyu"}, {"name": "Zihe Zheng"}, {"name": "Jiebo Luo"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages"}, "link": [{"@href": "http://arxiv.org/abs/2106.07435v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.07435v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.02775v1", "updated": "2021-07-06T17:37:56Z", "published": "2021-07-06T17:37:56Z", "title": "Countering Misinformation on Social Media Through Educational\n  Interventions: Evidence from a Randomized Experiment in Pakistan", "summary": "Fake news is a growing problem in developing countries with potentially\nfar-reaching consequences. We conduct a randomized experiment in urban Pakistan\nto evaluate the effectiveness of two educational interventions to counter\nmisinformation among low-digital literacy populations. We do not find a\nsignificant effect of video-based general educational messages about\nmisinformation. However, when such messages are augmented with personalized\nfeedback based on individuals' past engagement with fake news, we find an\nimprovement of 0.14 standard deviations in identifying fake news. We also find\nnegative but insignificant effects on identifying true news, driven by female\nrespondents. Our results suggest that educational interventions can enable\ninformation discernment but their effectiveness critically depends on how well\ntheir features and delivery are customized for the population of interest.", "author": [{"name": "Ayesha Ali"}, {"name": "Ihsan Ayyub Qazi"}], "link": [{"@href": "http://arxiv.org/abs/2107.02775v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.02775v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1703.06959v4", "updated": "2017-09-03T22:05:42Z", "published": "2017-03-20T20:33:32Z", "title": "CSI: A Hybrid Deep Model for Fake News Detection", "summary": "The topic of fake news has drawn attention both from the public and the\nacademic communities. Such misinformation has the potential of affecting public\nopinion, providing an opportunity for malicious parties to manipulate the\noutcomes of public events such as elections. Because such high stakes are at\nplay, automatically detecting fake news is an important, yet challenging\nproblem that is not yet well understood. Nevertheless, there are three\ngenerally agreed upon characteristics of fake news: the text of an article, the\nuser response it receives, and the source users promoting it. Existing work has\nlargely focused on tailoring solutions to one particular characteristic which\nhas limited their success and generality. In this work, we propose a model that\ncombines all three characteristics for a more accurate and automated\nprediction. Specifically, we incorporate the behavior of both parties, users\nand articles, and the group behavior of users who propagate fake news.\nMotivated by the three characteristics, we propose a model called CSI which is\ncomposed of three modules: Capture, Score, and Integrate. The first module is\nbased on the response and text; it uses a Recurrent Neural Network to capture\nthe temporal pattern of user activity on a given article. The second module\nlearns the source characteristic based on the behavior of users, and the two\nare integrated with the third module to classify an article as fake or not.\nExperimental analysis on real-world data demonstrates that CSI achieves higher\naccuracy than existing models, and extracts meaningful latent representations\nof both users and articles.", "author": [{"name": "Natali Ruchansky"}, {"name": "Sungyong Seo"}, {"name": "Yan Liu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3132847.3132877"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3132847.3132877", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1703.06959v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1703.06959v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Proceedings of the 26th ACM International Conference on\n  Information and Knowledge Management (CIKM) 2017"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.05252v1", "updated": "2018-09-14T04:52:33Z", "published": "2018-09-14T04:52:33Z", "title": "CIMTDetect: A Community Infused Matrix-Tensor Coupled Factorization\n  Based Method for Fake News Detection", "summary": "Detecting whether a news article is fake or genuine is a crucial task in\ntoday's digital world where it's easy to create and spread a misleading news\narticle. This is especially true of news stories shared on social media since\nthey don't undergo any stringent journalistic checking associated with main\nstream media. Given the inherent human tendency to share information with their\nsocial connections at a mouse-click, fake news articles masquerading as real\nones, tend to spread widely and virally. The presence of echo chambers (people\nsharing same beliefs) in social networks, only adds to this problem of\nwide-spread existence of fake news on social media. In this paper, we tackle\nthe problem of fake news detection from social media by exploiting the very\npresence of echo chambers that exist within the social network of users to\nobtain an efficient and informative latent representation of the news article.\nBy modeling the echo-chambers as closely-connected communities within the\nsocial network, we represent a news article as a 3-mode tensor of the structure\n- <News, User, Community> and propose a tensor factorization based method to\nencode the news article in a latent embedding space preserving the community\nstructure. We also propose an extension of the above method, which jointly\nmodels the community and content information of the news article through a\ncoupled matrix-tensor factorization framework. We empirically demonstrate the\nefficacy of our method for the task of Fake News Detection over two real-world\ndatasets. Further, we validate the generalization of the resulting embeddings\nover two other auxiliary tasks, namely: \\textbf{1)} News Cohort Analysis and\n\\textbf{2)} Collaborative News Recommendation. Our proposed method outperforms\nappropriate baselines for both the tasks, establishing its generalization.", "author": [{"name": "Shashank Gupta"}, {"name": "Raghuveer Thirukovalluru"}, {"name": "Manjira Sinha"}, {"name": "Sandya Mannarswamy"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Presented at ASONAM'18"}, "link": [{"@href": "http://arxiv.org/abs/1809.05252v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.05252v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.09918v1", "updated": "2017-11-27T19:00:08Z", "published": "2017-11-27T19:00:08Z", "title": "Leveraging the Crowd to Detect and Reduce the Spread of Fake News and\n  Misinformation", "summary": "Online social networking sites are experimenting with the following\ncrowd-powered procedure to reduce the spread of fake news and misinformation:\nwhenever a user is exposed to a story through her feed, she can flag the story\nas misinformation and, if the story receives enough flags, it is sent to a\ntrusted third party for fact checking. If this party identifies the story as\nmisinformation, it is marked as disputed. However, given the uncertain number\nof exposures, the high cost of fact checking, and the trade-off between flags\nand exposures, the above mentioned procedure requires careful reasoning and\nsmart algorithms which, to the best of our knowledge, do not exist to date.\n  In this paper, we first introduce a flexible representation of the above\nprocedure using the framework of marked temporal point processes. Then, we\ndevelop a scalable online algorithm, Curb, to select which stories to send for\nfact checking and when to do so to efficiently reduce the spread of\nmisinformation with provable guarantees. In doing so, we need to solve a novel\nstochastic optimal control problem for stochastic differential equations with\njumps, which is of independent interest. Experiments on two real-world datasets\ngathered from Twitter and Weibo show that our algorithm may be able to\neffectively reduce the spread of fake news and misinformation.", "author": [{"name": "Jooyeon Kim"}, {"name": "Behzad Tabibian"}, {"name": "Alice Oh"}, {"name": "Bernhard Schoelkopf"}, {"name": "Manuel Gomez-Rodriguez"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear at the 11th ACM International Conference on Web Search and\n  Data Mining (WSDM 2018)"}, "link": [{"@href": "http://arxiv.org/abs/1711.09918v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.09918v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.02223v1", "updated": "2019-10-05T06:48:23Z", "published": "2019-10-05T06:48:23Z", "title": "A Machine Learning Analysis of the Features in Deceptive and Credible\n  News", "summary": "Fake news is a type of pervasive propaganda that spreads misinformation\nonline, taking advantage of social media's extensive reach to manipulate public\nperception. Over the past three years, fake news has become a focal discussion\npoint in the media due to its impact on the 2016 U.S. presidential election.\nFake news can have severe real-world implications: in 2016, a man walked into a\npizzeria carrying a rifle because he read that Hillary Clinton was harboring\nchildren as sex slaves. This project presents a high accuracy (87%) machine\nlearning classifier that determines the validity of news based on the word\ndistributions and specific linguistic and stylistic differences in the first\nfew sentences of an article. This can help readers identify the validity of an\narticle by looking for specific features in the opening lines aiding them in\nmaking informed decisions. Using a dataset of 2,107 articles from 30 different\nwebsites, this project establishes an understanding of the variations between\nfake and credible news by examining the model, dataset, and features. This\nclassifier appears to use the differences in word distribution, levels of tone\nauthenticity, and frequency of adverbs, adjectives, and nouns. The\ndifferentiation in the features of these articles can be used to improve future\nclassifiers. This classifier can also be further applied directly to browsers\nas a Google Chrome extension or as a filter for social media outlets or news\nwebsites to reduce the spread of misinformation.", "author": {"name": "Qi Jia Sun"}, "link": [{"@href": "http://arxiv.org/abs/1910.02223v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.02223v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "J.5.5", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1804.09088v1", "updated": "2018-04-24T15:13:51Z", "published": "2018-04-24T15:13:51Z", "title": "Semi-supervised Content-based Detection of Misinformation via Tensor\n  Embeddings", "summary": "Fake news may be intentionally created to promote economic, political and\nsocial interests, and can lead to negative impacts on humans beliefs and\ndecisions. Hence, detection of fake news is an emerging problem that has become\nextremely prevalent during the last few years. Most existing works on this\ntopic focus on manual feature extraction and supervised classification models\nleveraging a large number of labeled (fake or real) articles. In contrast, we\nfocus on content-based detection of fake news articles, while assuming that we\nhave a small amount of labels, made available by manual fact-checkers or\nautomated sources. We argue this is a more realistic setting in the presence of\nmassive amounts of content, most of which cannot be easily factchecked. To that\nend, we represent collections of news articles as multi-dimensional tensors,\nleverage tensor decomposition to derive concise article embeddings that capture\nspatial/contextual information about each news article, and use those\nembeddings to create an article-by-article graph on which we propagate limited\nlabels. Results on three real-world datasets show that our method performs on\npar or better than existing models that are fully supervised, in that we\nachieve better detection accuracy using fewer labels. In particular, our\nproposed method achieves 75.43% of accuracy using only 30% of labels of a\npublic dataset while an SVM-based classifier achieved 67.43%. Furthermore, our\nmethod achieves 70.92% of accuracy in a large dataset using only 2% of labels.", "author": [{"name": "Gisel Bastidas Guacho"}, {"name": "Sara Abdali"}, {"name": "Neil Shah"}, {"name": "Evangelos E. Papalexakis"}], "link": [{"@href": "http://arxiv.org/abs/1804.09088v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.09088v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1806.05180v1", "updated": "2018-06-13T15:38:09Z", "published": "2018-06-13T15:38:09Z", "title": "A Retrospective Analysis of the Fake News Challenge Stance Detection\n  Task", "summary": "The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance\nclassification task as a crucial first step towards detecting fake news. To\ndate, there is no in-depth analysis paper to critically discuss FNC-1's\nexperimental setup, reproduce the results, and draw conclusions for\nnext-generation stance classification methods. In this paper, we provide such\nan in-depth analysis for the three top-performing systems. We first find that\nFNC-1's proposed evaluation metric favors the majority class, which can be\neasily classified, and thus overestimates the true discriminative power of the\nmethods. Therefore, we propose a new F1-based metric yielding a changed system\nranking. Next, we compare the features and architectures used, which leads to a\nnovel feature-rich stacked LSTM model that performs on par with the best\nsystems, but is superior in predicting minority classes. To understand the\nmethods' ability to generalize, we derive a new dataset and perform both\nin-domain and cross-domain experiments. Our qualitative and quantitative study\nhelps interpreting the original FNC-1 scores and understand which features help\nimproving performance and why. Our new dataset and all source code used during\nthe reproduction study are publicly available for future research.", "author": [{"name": "Andreas Hanselowski"}, {"name": "Avinesh PVS"}, {"name": "Benjamin Schiller"}, {"name": "Felix Caspelherr"}, {"name": "Debanjan Chaudhuri"}, {"name": "Christian M. Meyer"}, {"name": "Iryna Gurevych"}], "link": [{"@href": "http://arxiv.org/abs/1806.05180v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.05180v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.00494v1", "updated": "2018-09-03T08:37:33Z", "published": "2018-09-03T08:37:33Z", "title": "Belittling the Source: Trustworthiness Indicators to Obfuscate Fake News\n  on the Web", "summary": "With the growth of the internet, the number of fake-news online has been\nproliferating every year. The consequences of such phenomena are manifold,\nranging from lousy decision-making process to bullying and violence episodes.\nTherefore, fact-checking algorithms became a valuable asset. To this aim, an\nimportant step to detect fake-news is to have access to a credibility score for\na given information source. However, most of the widely used Web indicators\nhave either been shut-down to the public (e.g., Google PageRank) or are not\nfree for use (Alexa Rank). Further existing databases are short-manually\ncurated lists of online sources, which do not scale. Finally, most of the\nresearch on the topic is theoretical-based or explore confidential data in a\nrestricted simulation environment. In this paper we explore current research,\nhighlight the challenges and propose solutions to tackle the problem of\nclassifying websites into a credibility scale. The proposed model automatically\nextracts source reputation cues and computes a credibility factor, providing\nvaluable insights which can help in belittling dubious and confirming trustful\nunknown websites. Experimental results outperform state of the art in the\n2-classes and 5-classes setting.", "author": [{"name": "Diego Esteves"}, {"name": "Aniketh Janardhan Reddy"}, {"name": "Piyush Chawla"}, {"name": "Jens Lehmann"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EMNLP 2018: Conference on Empirical Methods in Natural Language\n  Processing (The First Workshop on Fact Extraction and Verification)"}, "link": [{"@href": "http://arxiv.org/abs/1809.00494v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.00494v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.10365v4", "updated": "2020-08-04T20:26:08Z", "published": "2019-06-25T07:47:00Z", "title": "Emotion Cognizance Improves Health Fake News Identification", "summary": "Identifying misinformation is increasingly being recognized as an important\ncomputational task with high potential social impact. Misinformation and fake\ncontents are injected into almost every domain of news including politics,\nhealth, science, business, etc., among which, the fakeness in health domain\npose serious adverse effects to scare or harm the society. Misinformation\ncontains scientific claims or content from social media exaggerated with strong\nemotion content to attract eyeballs. In this paper, we consider the utility of\nthe affective character of news articles for fake news identification in the\nhealth domain and present evidence that emotion cognizant representations are\nsignificantly more suited for the task. We outline a technique to leverage\nemotion intensity lexicons to develop emotionized text representations, and\nevaluate the utility of such a representation for identifying fake news\nrelating to health in various supervised and unsupervised scenarios. The\nconsistent and significant empirical gains that we observe over a range of\ntechnique types and parameter settings establish the utility of the emotional\ninformation in news articles, an often overlooked aspect, for the task of\nmisinformation identification in the health domain.", "author": [{"name": "Anoop K"}, {"name": "Deepak P"}, {"name": "Lajish V L"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Proceedings of 24th International Database Engineering &\n  Applications Symposium (IDEAS 2020), Incheon, Korea"}, "link": [{"@href": "http://arxiv.org/abs/1906.10365v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.10365v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1911.10130v1", "updated": "2019-11-22T16:35:37Z", "published": "2019-11-22T16:35:37Z", "title": "A Data Set of Internet Claims and Comparison of their Sentiments with\n  Credibility", "summary": "In this modern era, communication has become faster and easier. This means\nfallacious information can spread as fast as reality. Considering the damage\nthat fake news kindles on the psychology of people and the fact that such news\nproliferates faster than truth, we need to study the phenomenon that helps\nspread fake news. An unbiased data set that depends on reality for rating news\nis necessary to construct predictive models for its classification. This paper\ndescribes the methodology to create such a data set. We collect our data from\nsnopes.com which is a fact-checking organization. Furthermore, we intend to\ncreate this data set not only for classification of the news but also to find\npatterns that reason the intent behind misinformation. We also formally define\nan Internet Claim, its credibility, and the sentiment behind such a claim. We\ntry to realize the relationship between the sentiment of a claim with its\ncredibility. This relationship pours light on the bigger picture behind the\npropagation of misinformation. We pave the way for further research based on\nthe methodology described in this paper to create the data set and usage of\npredictive modeling along with research-based on psychology/mentality of people\nto understand why fake news spreads much faster than reality.", "author": [{"name": "Amey Parundekar"}, {"name": "Susan Elias"}, {"name": "Ashwin Ashok"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 6 figures, A paper accepted at the Truth Discovery and Fact\n  Checking: Theory and Practice SIGKDD 2019 Workshop, August 5th, Anchorage,\n  Alaska"}, "link": [{"@href": "http://arxiv.org/abs/1911.10130v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.10130v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3.3, I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3.3; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.07688v2", "updated": "2020-05-18T06:23:56Z", "published": "2020-05-15T17:56:11Z", "title": "Keystroke Biometrics in Response to Fake News Propagation in a Global\n  Pandemic", "summary": "This work proposes and analyzes the use of keystroke biometrics for content\nde-anonymization. Fake news have become a powerful tool to manipulate public\nopinion, especially during major events. In particular, the massive spread of\nfake news during the COVID-19 pandemic has forced governments and companies to\nfight against missinformation. In this context, the ability to link multiple\naccounts or profiles that spread such malicious content on the Internet while\nhiding in anonymity would enable proactive identification and blacklisting.\nBehavioral biometrics can be powerful tools in this fight. In this work, we\nhave analyzed how the latest advances in keystroke biometric recognition can\nhelp to link behavioral typing patterns in experiments involving 100,000 users\nand more than 1 million typed sequences. Our proposed system is based on\nRecurrent Neural Networks adapted to the context of content de-anonymization.\nAssuming the challenge to link the typed content of a target user in a pool of\ncandidate profiles, our results show that keystroke recognition can be used to\nreduce the list of candidate profiles by more than 90%. In addition, when\nkeystroke is combined with auxiliary data (such as location), our system\nachieves a Rank-1 identification performance equal to 52.6% and 10.9% for a\nbackground candidate list composed of 1K and 100K profiles, respectively.", "author": [{"name": "Aythami Morales"}, {"name": "Alejandro Acien"}, {"name": "Julian Fierrez"}, {"name": "John V. Monaco"}, {"name": "Ruben Tolosana"}, {"name": "Ruben Vera-Rodriguez"}, {"name": "Javier Ortega-Garcia"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: text overlap with arXiv:2004.03627"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IEEE International Workshop on Secure Digital Identity Management\n  (SDIM) 2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.07688v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.07688v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.11276v1", "updated": "2021-02-23T16:47:41Z", "published": "2021-02-23T16:47:41Z", "title": "Factorization of Fact-Checks for Low Resource Indian Languages", "summary": "The advancement in technology and accessibility of internet to each\nindividual is revolutionizing the real time information. The liberty to express\nyour thoughts without passing through any credibility check is leading to\ndissemination of fake content in the ecosystem. It can have disastrous effects\non both individuals and society as a whole. The amplification of fake news is\nbecoming rampant in India too. Debunked information often gets republished with\na replacement description, claiming it to depict some different incidence. To\ncurb such fabricated stories, it is necessary to investigate such deduplicates\nand false claims made in public. The majority of studies on automatic\nfact-checking and fake news detection is restricted to English only. But for a\ncountry like India where only 10% of the literate population speak English,\nrole of regional languages in spreading falsity cannot be undermined. In this\npaper, we introduce FactDRIL: the first large scale multilingual Fact-checking\nDataset for Regional Indian Languages. We collect an exhaustive dataset across\n7 months covering 11 low-resource languages. Our propose dataset consists of\n9,058 samples belonging to English, 5,155 samples to Hindi and remaining 8,222\nsamples are distributed across various regional languages, i.e. Bangla,\nMarathi, Malayalam, Telugu, Tamil, Oriya, Assamese, Punjabi, Urdu, Sinhala and\nBurmese. We also present the detailed characterization of three M's\n(multi-lingual, multi-media, multi-domain) in the FactDRIL accompanied with the\ncomplete list of other varied attributes making it a unique dataset to study.\nLastly, we present some potential use cases of the dataset. We expect this\ndataset will be a valuable resource and serve as a starting point to fight\nproliferation of fake news in low resource languages.", "author": [{"name": "Shivangi Singhal"}, {"name": "Rajiv Ratn Shah"}, {"name": "Ponnurangam Kumaraguru"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/2102.11276v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.11276v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.04671v1", "updated": "2021-04-10T03:05:34Z", "published": "2021-04-10T03:05:34Z", "title": "A Web Infrastructure for Certifying Multimedia News Content for Fake\n  News Defense", "summary": "In dealing with altered visual multimedia content, also referred to as fake\nnews, we present a ready-to-deploy extension of the current public key\ninfrastructure (PKI), to provide an endorsement and integrity check platform\nfor newsworthy visual multimedia content. PKI, which is primarily used for Web\ndomain authentication, can directly be utilized with any visual multimedia\nfile. Unlike many other fake news researches that focus on technical multimedia\ndata processing and verification, we enable various news organizations to use\nour developed program to certify/endorse a multimedia news content when they\nbelieve this news piece is truthiness and newsworthy. Our program digitally\nsigns the multimedia news content with the news organization's private key, and\nthe endorsed news content can be posted not only by the endorser, but also by\nany other websites. By installing a web browser extension developed by us, an\nend user can easily verify whether a multimedia news content has been endorsed\nand by which organization. During verification, our browser extension will\npresent to the end user a floating logo next to the image or video. This logo,\nin the shape of a shield, will show whether the image has been endorsed, by\nwhich news organization, and a few more pieces of essential text information of\nthe news multimedia content. The proposed system can be easily integrated to\nother closed-web system such as social media networks and easily applied to\nother non-visual multimedia files.", "author": [{"name": "Edward L. Amoruso"}, {"name": "Stephen P. Johnson"}, {"name": "Raghu Avula"}, {"name": "Cliff C. Zou"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "7 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/2104.04671v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.04671v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1811.00706v1", "updated": "2018-11-02T02:13:52Z", "published": "2018-11-02T02:13:52Z", "title": "Combining Similarity Features and Deep Representation Learning for\n  Stance Detection in the Context of Checking Fake News", "summary": "Fake news are nowadays an issue of pressing concern, given their recent rise\nas a potential threat to high-quality journalism and well-informed public\ndiscourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage\nthe development of machine learning-based classification systems for stance\ndetection (i.e., for identifying whether a particular news article agrees,\ndisagrees, discusses, or is unrelated to a particular news headline), thus\nhelping in the detection and analysis of possible instances of fake news. This\narticle presents a new approach to tackle this stance detection problem, based\non the combination of string similarity features with a deep neural\narchitecture that leverages ideas previously advanced in the context of\nlearning efficient text representations, document classification, and natural\nlanguage inference. Specifically, we use bi-directional Recurrent Neural\nNetworks, together with max-pooling over the temporal/sequential dimension and\nneural attention, for representing (i) the headline, (ii) the first two\nsentences of the news article, and (iii) the entire news article. These\nrepresentations are then combined/compared, complemented with similarity\nfeatures inspired on other FNC-1 approaches, and passed to a final layer that\npredicts the stance of the article towards the headline. We also explore the\nuse of external sources of information, specifically large datasets of sentence\npairs originally proposed for training and evaluating natural language\ninference methods, in order to pre-train specific components of the neural\nnetwork architecture (e.g., the RNNs used for encoding sentences). The obtained\nresults attest to the effectiveness of the proposed ideas and show that our\nmodel, particularly when considering pre-training and the combination of neural\nrepresentations together with similarity features, slightly outperforms the\nprevious state-of-the-art.", "author": [{"name": "Lu\u00eds Borges"}, {"name": "Bruno Martins"}, {"name": "P\u00e1vel Calado"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication in the special issue of the ACM Journal of\n  Data and Information Quality (ACM JDIQ) on Combating Digital Misinformation\n  and Disinformation"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Journal of Data and Information Quality (JDIQ) 11 (3), 1-26, 2019"}, "link": [{"@href": "http://arxiv.org/abs/1811.00706v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.00706v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.12330v1", "updated": "2020-04-26T09:34:32Z", "published": "2020-04-26T09:34:32Z", "title": "Detecting fake news for the new coronavirus by reasoning on the Covid-19\n  ontology", "summary": "In the context of the Covid-19 pandemic, many were quick to spread deceptive\ninformation. I investigate here how reasoning in Description Logics (DLs) can\ndetect inconsistencies between trusted medical sources and not trusted ones.\nThe not-trusted information comes in natural language (e.g. \"Covid-19 affects\nonly the elderly\"). To automatically convert into DLs, I used the FRED\nconverter. Reasoning in Description Logics is then performed with the Racer\ntool.", "author": {"name": "Adrian Groza"}, "link": [{"@href": "http://arxiv.org/abs/2004.12330v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.12330v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1802.00156v1", "updated": "2018-02-01T05:11:09Z", "published": "2018-02-01T05:11:09Z", "title": "The Great Division", "summary": "When information flow fails, when Democrats and Republicans do not talk to\neach other, when Israelis and Palestinians do not talk to each other, and when\nNorth Koreans and South Koreans do not talk to each other, mis-perceptions,\nbiases and fake news arise. In this paper we present an in-depth study of\npolitical polarization and social division using Twitter data and Monte Carlo\nsimulations. First, we study at the aggregate level people's inclination to\nretweet within their own ideological circle. Introducing the concept of cocoon\nratio, we show that Donald Trump's followers are 2.56 more likely to retweet a\nfellow Trump follower than to retweet a Hillary Clinton follower. Second, going\ndown to the individual level, we show that the tendency of retweeting\nexclusively within one's ideological circle is stronger for women than for men\nand that such tendency weakens as one's social capital grows. Third, we use a\none-dimensional Ising model to simulate how a society with high cocoon ratios\ncould end up becoming completely divided. We conclude with a discussion of our\nfindings with respect to fake news.", "author": [{"name": "Yu Wang"}, {"name": "Jiebo Luo"}], "link": [{"@href": "http://arxiv.org/abs/1802.00156v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1802.00156v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1910.08010v1", "updated": "2019-10-17T16:30:08Z", "published": "2019-10-17T16:30:08Z", "title": "Uncritical polarized groups: The impact of spreading fake news as fact\n  in social networks", "summary": "The spread of ideas in online social networks is a crucial phenomenon to\nunderstand nowadays the proliferation of fake news and their impact in\ndemocracies. This makes necessary to use models that mimic the circulation of\nrumors. The law of large numbers as well as the probability distribution of\ncontact groups allow us to construct a model with a minimum number of\nhypotheses. Moreover, we can analyze with this model the presence of very\npolarized groups of individuals (humans or bots) who spread a rumor as soon as\nthey know about it. Given only the initial number of individuals who know any\nnews, in a population connected by an instant messaging application, we first\ndeduce from our model a simple function of time to study the rumor propagation.\nWe then prove that the polarized groups can be detected and quantified from\nempirical data. Finally, we also predict the time required by any rumor to\nreach a fixed percentage of the population.", "author": [{"name": "Jesus San Martin"}, {"name": "Fatima Drubi"}, {"name": "Daniel Rodriguez-Perez"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "31 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/1910.08010v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.08010v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.11430v2", "updated": "2020-05-26T23:13:25Z", "published": "2019-10-24T21:27:31Z", "title": "Detecting Fake News with Weak Social Supervision", "summary": "Limited labeled data is becoming the largest bottleneck for supervised\nlearning systems. This is especially the case for many real-world tasks where\nlarge scale annotated examples are either too expensive to acquire or\nunavailable due to privacy or data access constraints. Weak supervision has\nshown to be a good means to mitigate the scarcity of annotated data by\nleveraging weak labels or injecting constraints from heuristic rules and/or\nexternal knowledge sources. Social media has little labeled data but possesses\nunique characteristics that make it suitable for generating weak supervision,\nresulting in a new type of weak supervision, i.e., weak social supervision. In\nthis article, we illustrate how various aspects of social media can be used to\ngenerate weak social supervision. Specifically, we use the recent research on\nfake news detection as the use case, where social engagements are abundant but\nannotated examples are scarce, to show that weak social supervision is\neffective when facing the little labeled data problem. This article opens the\ndoor for learning with weak social supervision for other emerging tasks.", "author": [{"name": "Kai Shu"}, {"name": "Ahmed Hassan Awadallah"}, {"name": "Susan Dumais"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 4 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IEEE Intelligent Systems 2020"}, "link": [{"@href": "http://arxiv.org/abs/1910.11430v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.11430v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.05521v2", "updated": "2018-11-21T00:22:24Z", "published": "2018-09-14T17:46:58Z", "title": "Defending Elections Against Malicious Spread of Misinformation", "summary": "The integrity of democratic elections depends on voters' access to accurate\ninformation. However, modern media environments, which are dominated by social\nmedia, provide malicious actors with unprecedented ability to manipulate\nelections via misinformation, such as fake news. We study a zero-sum game\nbetween an attacker, who attempts to subvert an election by propagating a fake\nnew story or other misinformation over a set of advertising channels, and a\ndefender who attempts to limit the attacker's impact. Computing an equilibrium\nin this game is challenging as even the pure strategy sets of players are\nexponential. Nevertheless, we give provable polynomial-time approximation\nalgorithms for computing the defender's minimax optimal strategy across a range\nof settings, encompassing different population structures as well as models of\nthe information available to each player. Experimental results confirm that our\nalgorithms provide near-optimal defender strategies and showcase variations in\nthe difficulty of defending elections depending on the resources and knowledge\navailable to the defender.", "author": [{"name": "Bryan Wilder"}, {"name": "Yevgeniy Vorobeychik"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Full version of paper accepted to AAAI 2019"}, "link": [{"@href": "http://arxiv.org/abs/1809.05521v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.05521v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.06416v1", "updated": "2018-09-17T19:51:18Z", "published": "2018-09-17T19:51:18Z", "title": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning", "summary": "Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.", "author": [{"name": "Kashyap Popat"}, {"name": "Subhabrata Mukherjee"}, {"name": "Andrew Yates"}, {"name": "Gerhard Weikum"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EMNLP 2018"}, "link": [{"@href": "http://arxiv.org/abs/1809.06416v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.06416v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.09076v3", "updated": "2021-02-22T20:26:19Z", "published": "2018-09-24T17:43:54Z", "title": "Subleading BMS charges and fake news near null infinity", "summary": "In this paper we establish a relation between the non-linearly conserved\nNewman-Penrose charges and certain subleading terms in a large-$r$ expansion of\nthe BMS charges in an asymptotically-flat spacetime. We define the subleading\nBMS charges by considering a $1/r$-expansion of the Barnich-Brandt prescription\nfor defining asymptotic charges in an asymptotically-flat spacetime. At the\nleading order, i.e. $1/r^0$, one obtains the standard BMS charges, which would\nbe integrable and conserved in the absence of a flux term at null infinity,\ncorresponding to gravitational radiation, or Bondi news. At subleading orders,\nanalogous terms in general provide obstructions to the integrability of the\ncorresponding charges. Since the subleading terms are defined close to null\ninfinity, but vanish actually at infinity, the analogous obstructions are not\nassociated with genuine Bondi news. One may instead describe them as\ncorresponding to \"fake news.\" At order $r^{-3}$, we find that a set of\nintegrable charges can be defined and that these are related to the ten\nnon-linearly conserved Newman-Penrose charges.", "author": [{"name": "Hadi Godazgar"}, {"name": "Mahdi Godazgar"}, {"name": "C. N. Pope"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/JHEP01(2019)143"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/JHEP01(2019)143", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1809.09076v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.09076v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "34 pages;few minor typos corrected"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "JHEP01(2019)143"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "hep-th", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "hep-th", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "gr-qc", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1907.07757v1", "updated": "2019-07-08T18:29:58Z", "published": "2019-07-08T18:29:58Z", "title": "XFake: Explainable Fake News Detector with Visualizations", "summary": "In this demo paper, we present the XFake system, an explainable fake news\ndetector that assists end-users to identify news credibility. To effectively\ndetect and interpret the fakeness of news items, we jointly consider both\nattributes (e.g., speaker) and statements. Specifically, MIMIC, ATTN and PERT\nframeworks are designed, where MIMIC is built for attribute analysis, ATTN is\nfor statement semantic analysis and PERT is for statement linguistic analysis.\nBeyond the explanations extracted from the designed frameworks, relevant\nsupporting examples as well as visualization are further provided to facilitate\nthe interpretation. Our implemented system is demonstrated on a real-world\ndataset crawled from PolitiFact, where thousands of verified political news\nhave been collected.", "author": [{"name": "Fan Yang"}, {"name": "Shiva K. Pentyala"}, {"name": "Sina Mohseni"}, {"name": "Mengnan Du"}, {"name": "Hao Yuan"}, {"name": "Rhema Linder"}, {"name": "Eric D. Ragan"}, {"name": "Shuiwang Ji"}, {"name": "Xia Hu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3308558.3314119"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3308558.3314119", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1907.07757v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.07757v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "4 pages, WebConf'2019 Demo"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.11722v1", "updated": "2019-08-30T13:12:21Z", "published": "2019-08-30T13:12:21Z", "title": "Fact-Checking Meets Fauxtography: Verifying Claims About Images", "summary": "The recent explosion of false claims in social media and on the Web in\ngeneral has given rise to a lot of manual fact-checking initiatives.\nUnfortunately, the number of claims that need to be fact-checked is several\norders of magnitude larger than what humans can handle manually. Thus, there\nhas been a lot of research aiming at automating the process. Interestingly,\nprevious work has largely ignored the growing number of claims about images.\nThis is despite the fact that visual imagery is more influential than text and\nnaturally appears alongside fake news. Here we aim at bridging this gap. In\nparticular, we create a new dataset for this problem, and we explore a variety\nof features modeling the claim, the image, and the relationship between the\nclaim and the image. The evaluation results show sizable improvements over the\nbaseline. We release our dataset, hoping to enable further research on\nfact-checking claims about images.", "author": [{"name": "Dimitrina Zlatkova"}, {"name": "Preslav Nakov"}, {"name": "Ivan Koychev"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Claims about Images; Fauxtography; Fact-Checking; Veracity; Fake News"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EMNLP-2019"}, "link": [{"@href": "http://arxiv.org/abs/1908.11722v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.11722v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.11648v1", "updated": "2020-04-24T10:42:49Z", "published": "2020-04-24T10:42:49Z", "title": "GCAN: Graph-aware Co-Attention Networks for Explainable Fake News\n  Detection on Social Media", "summary": "This paper solves the fake news detection problem under a more realistic\nscenario on social media. Given the source short-text tweet and the\ncorresponding sequence of retweet users without text comments, we aim at\npredicting whether the source tweet is fake or not, and generating explanation\nby highlighting the evidences on suspicious retweeters and the words they\nconcern. We develop a novel neural network-based model, Graph-aware\nCo-Attention Networks (GCAN), to achieve the goal. Extensive experiments\nconducted on real tweet datasets exhibit that GCAN can significantly outperform\nstate-of-the-art methods by 16% in accuracy on average. In addition, the case\nstudies also show that GCAN can produce reasonable explanations.", "author": [{"name": "Yi-Ju Lu"}, {"name": "Cheng-Te Li"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To appear in Proceedings of The 58th Annual Meeting of the\n  Association for Computational Linguistics, ACL 2020. Code is available here\n  https://github.com/l852888/GCAN"}, "link": [{"@href": "http://arxiv.org/abs/2004.11648v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.11648v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.13270v1", "updated": "2020-05-27T10:29:14Z", "published": "2020-05-27T10:29:14Z", "title": "BRENDA: Browser Extension for Fake News Detection", "summary": "Misinformation such as fake news has drawn a lot of attention in recent\nyears. It has serious consequences on society, politics and economy. This has\nlead to a rise of manually fact-checking websites such as Snopes and\nPolitifact. However, the scale of misinformation limits their ability for\nverification. In this demonstration, we propose BRENDA a browser extension\nwhich can be used to automate the entire process of credibility assessments of\nfalse claims. Behind the scenes BRENDA uses a tested deep neural network\narchitecture to automatically identify fact check worthy claims and classifies\nas well as presents the result along with evidence to the user. Since BRENDA is\na browser extension, it facilities fast automated fact checking for the end\nuser without having to leave the Webpage.", "author": [{"name": "Bjarte Botnevik"}, {"name": "Eirik Sakariassen"}, {"name": "Vinay Setty"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3397271.3401396"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3397271.3401396", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2005.13270v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.13270v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted as SIGIR demo"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Proceedings of the 43rd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR 2020), July 25 to\n  30, 2020, Virtual Event, China. ACM, New York, NY, USA, 4 pages"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.04278v1", "updated": "2020-06-07T22:00:43Z", "published": "2020-06-07T22:00:43Z", "title": "Disinformation and Misinformation on Twitter during the Novel\n  Coronavirus Outbreak", "summary": "As the novel coronavirus spread globally, a growing public panic was\nexpressed over the internet. We examine the public discussion concerning\nCOVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million\nusers collected between January 29, 2020 and March 4, 2020. We categorize users\nbased on their home countries, social identities, and political orientation. We\nfind that news media, government officials, and individual news reporters\nposted a majority of influential tweets, while the most influential ones are\nstill written by regular users. Tweets mentioning \"fake news\" URLs and\ndisinformation story-lines are also more likely to be spread by regular users.\nUnlike real news and normal tweets, tweets containing URLs pointing to \"fake\nnews\" sites are most likely to be retweeted within the source country and so\nare less likely to spread internationally.", "author": [{"name": "Binxuan Huang"}, {"name": "Kathleen M. Carley"}], "link": [{"@href": "http://arxiv.org/abs/2006.04278v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.04278v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2006.11343v1", "updated": "2020-06-19T19:48:00Z", "published": "2020-06-19T19:48:00Z", "title": "FakeCovid -- A Multilingual Cross-domain Fact Check News Dataset for\n  COVID-19", "summary": "In this paper, we present a first multilingual cross-domain dataset of 5182\nfact-checked news articles for COVID-19, collected from 04/01/2020 to\n15/05/2020. We have collected the fact-checked articles from 92 different\nfact-checking websites after obtaining references from Poynter and Snopes. We\nhave manually annotated articles into 11 different categories of the\nfact-checked news according to their content. The dataset is in 40 languages\nfrom 105 countries. We have built a classifier to detect fake news and present\nresults for the automatic fake news detection and its class. Our model achieves\nan F1 score of 0.76 to detect the false class and other fact check articles.\nThe FakeCovid dataset is available at Github.", "author": [{"name": "Gautam Kishore Shahi"}, {"name": "Durgesh Nandini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.36190/2020.14"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.36190/2020.14", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2006.11343v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.11343v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CySoc 2020 International Workshop on Cyber Social Threats, ICWSM 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.01988v1", "updated": "2020-08-05T08:17:20Z", "published": "2020-08-05T08:17:20Z", "title": "How Fake News Affect Trust in the Output of a Machine Learning System\n  for News Curation", "summary": "People are increasingly consuming news curated by machine learning (ML)\nsystems. Motivated by studies on algorithmic bias, this paper explores which\nrecommendations of an algorithmic news curation system users trust and how this\ntrust is affected by untrustworthy news stories like fake news. In a study with\n82 vocational school students with a background in IT, we found that users are\nable to provide trust ratings that distinguish trustworthy recommendations of\nquality news stories from untrustworthy recommendations. However, a single\nuntrustworthy news story combined with four trustworthy news stories is rated\nsimilarly as five trustworthy news stories. The results could be a first\nindication that untrustworthy news stories benefit from appearing in a\ntrustworthy context. The results also show the limitations of users' abilities\nto rate the recommendations of a news curation system. We discuss the\nimplications of this for the user experience of interactive machine learning\nsystems.", "author": [{"name": "Hendrik Heuer"}, {"name": "Andreas Breiter"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a pre-print of an article published in MISDOOM 2020 - 2nd\n  Multidisciplinary International Symposium on Disinformation in Open Online\n  Media"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MISDOOM 2020 - 2nd Multidisciplinary International Symposium on\n  Disinformation in Open Online Media"}, "link": [{"@href": "http://arxiv.org/abs/2008.01988v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.01988v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.01267v1", "updated": "2020-09-02T18:04:00Z", "published": "2020-09-02T18:04:00Z", "title": "COVID-19: The Information Warfare Paradigm Shift", "summary": "In Kuhn's The Structure of Scientific Revolutions, the critical term is\nparadigm-shift when it suddenly becomes evident that earlier assumptions no\nlonger are correct and the plurality of the scientific community that studies\nthis domain accepts the change. These types of events can be scientific\nfindings or as in social science system shock that creates a punctured\nequilibrium that sets the stage in the developments. In information warfare,\nrecent years studies and government lines of efforts have been to engage fake\nnews, electoral interference, and fight extremist social media as the primary\ncombat theater in the information space, and the tools to influence a targeted\naudience. The COVID-19 pandemic generates a rebuttal of these assumptions. Even\nif fake news and extremist social media content may exploit fault lines in our\nsociety and create a civil disturbance, tensions between federal and local\ngovernment, and massive protests, it is still effects that impact a part of the\npopulation. What we have seen with COVID-19, as an indicator, is that what is\nrelated to public health is far more powerful to swing public sentiment and\ncreate reactions within the citizenry that are trigger impact at a larger\nmagnitude that has rippled through society in multiple directions.", "author": [{"name": "Jan Kallberg"}, {"name": "Rosemary A. Burk"}, {"name": "Bhavani Thuraisingham"}], "link": [{"@href": "http://arxiv.org/abs/2009.01267v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.01267v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.09029v2", "updated": "2021-06-13T02:17:47Z", "published": "2020-10-18T16:52:27Z", "title": "CHECKED: Chinese COVID-19 Fake News Dataset", "summary": "COVID-19 has impacted all lives. To maintain social distancing and avoiding\nexposure, works and lives have gradually moved online. Under this trend, social\nmedia usage to obtain COVID-19 news has increased. Also, misinformation on\nCOVID-19 is frequently spread on social media. In this work, we develop\nCHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides\na total 2,104 verified microblogs related to COVID-19 from December 2019 to\nAugust 2020, identified by using a specific list of keywords. Correspondingly,\nCHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes\nthat reveal how these verified microblogs are spread and reacted on Weibo. The\ndataset contains a rich set of multimedia information for each microblog\nincluding ground-truth label, textual, visual, temporal, and network\ninformation. Extensive experiments have been conducted to analyze CHECKED data\nand to provide benchmark results for well-established methods when predicting\nfake news using CHECKED. We hope that CHECKED can facilitate studies that\ntarget misinformation on coronavirus. The dataset is available at\nhttps://github.com/cyang03/CHECKED.", "author": [{"name": "Chen Yang"}, {"name": "Xinyi Zhou"}, {"name": "Reza Zafarani"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to Social Network Analysis and Mining (SNAM)"}, "link": [{"@href": "http://arxiv.org/abs/2010.09029v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.09029v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.16324v1", "updated": "2020-10-30T15:29:16Z", "published": "2020-10-30T15:29:16Z", "title": "Topic-Preserving Synthetic News Generation: An Adversarial Deep\n  Reinforcement Learning Approach", "summary": "Nowadays, there exist powerful language models such as OpenAI's GPT-2 that\ncan generate readable text and can be fine-tuned to generate text for a\nspecific domain. Considering GPT-2, it cannot directly generate synthetic news\nwith respect to a given topic and the output of the language model cannot be\nexplicitly controlled. In this paper, we study the novel problem of\ntopic-preserving synthetic news generation. We propose a novel deep\nreinforcement learning-based method to control the output of GPT-2 with respect\nto a given news topic. When generating text using GPT-2, by default, the most\nprobable word is selected from the vocabulary. Instead of selecting the best\nword each time from GPT-2's output, an RL agent tries to select words that\noptimize the matching of a given topic. In addition, using a fake news detector\nas an adversary, we investigate generating realistic news using our proposed\nmethod. In this paper, we consider realistic news as news that cannot be easily\ndetected by a fake news classifier. Experimental results demonstrate the\neffectiveness of the proposed framework on generating topic-preserving news\ncontent than state-of-the-art baselines.", "author": [{"name": "Ahmadreza Mosallanezhad"}, {"name": "Kai Shu"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, under review"}, "link": [{"@href": "http://arxiv.org/abs/2010.16324v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.16324v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.04857v1", "updated": "2020-11-10T02:11:21Z", "published": "2020-11-10T02:11:21Z", "title": "Competitive Influence Propagation and Fake News Mitigation in the\n  Presence of Strong User Bias", "summary": "Due to the extensive role of social networks in social media, it is easy for\npeople to share the news, and it spreads faster than ever before. These\nplatforms also have been exploited to share the rumor or fake information,\nwhich is a threat to society. One method to reduce the impact of fake\ninformation is making people aware of the correct information based on hard\nproof. In this work, first, we propose a propagation model called Competitive\nIndependent Cascade Model with users' Bias (CICMB) that considers the presence\nof strong user bias towards different opinions, believes, or political parties.\nWe further propose a method, called $k-TruthScore$, to identify an optimal set\nof truth campaigners from a given set of prospective truth campaigners to\nminimize the influence of rumor spreaders on the network. We compare\n$k-TruthScore$ with state of the art methods, and we measure their performances\nas the percentage of the saved nodes (nodes that would have believed in the\nfake news in the absence of the truth campaigners). We present these results on\na few real-world networks, and the results show that $k-TruthScore$ method\noutperforms baseline methods.", "author": [{"name": "Akrati Saxena"}, {"name": "Harsh Saxena"}, {"name": "Ralucca Gera"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted in CSoNet 2020"}, "link": [{"@href": "http://arxiv.org/abs/2011.04857v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.04857v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.13327v1", "updated": "2020-11-26T14:52:01Z", "published": "2020-11-26T14:52:01Z", "title": "Analysing Social Media Network Data with R: Semi-Automated Screening of\n  Users, Comments and Communication Patterns", "summary": "Communication on social media platforms is not only culturally and\npolitically relevant, it is also increasingly widespread across societies.\nUsers not only communicate via social media platforms, but also search\nspecifically for information, disseminate it or post information themselves.\nHowever, fake news, hate speech and even radicalizing elements are part of this\nmodern form of communication: Sometimes with far-reaching effects on\nindividuals and societies. A basic understanding of these mechanisms and\ncommunication patterns could help to counteract negative forms of\ncommunication, e.g. bullying among children or extreme political points of\nview. To this end, a method will be presented in order to break down the\nunderlying communication patterns, to trace individual users and to inspect\ntheir comments and range on social media platforms; Or to contrast them later\non via qualitative research. This approeach can identify particularly active\nusers with an accuracy of 100 percent, if the framing social networks as well\nas the topics are taken into account. However, methodological as well as\ncounteracting approaches must be even more dynamic and flexible to ensure\nsensitivity and specifity regarding users who spread hate speech, fake news and\nradicalizing elements.", "author": {"name": "Dennis Klinkhammer"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "14 pages, 2 figures"}, "link": [{"@href": "http://arxiv.org/abs/2011.13327v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.13327v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "D.1.5; D.3.0; J.4; K.4.1", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.03291v1", "updated": "2021-01-09T05:15:41Z", "published": "2021-01-09T05:15:41Z", "title": "Combating Hostility: Covid-19 Fake News and Hostile Post Detection in\n  Social Media", "summary": "This paper illustrates a detail description of the system and its results\nthat developed as a part of the participation at CONSTRAINT shared task in\nAAAI-2021. The shared task comprises two tasks: a) COVID19 fake news detection\nin English b) Hostile post detection in Hindi. Task-A is a binary\nclassification problem with fake and real class, while task-B is a multi-label\nmulti-class classification task with five hostile classes (i.e. defame, fake,\nhate, offense, non-hostile). Various techniques are used to perform the\nclassification task, including SVM, CNN, BiLSTM, and CNN+BiLSTM with tf-idf and\nWord2Vec embedding techniques. Results indicate that SVM with tf-idf features\nachieved the highest 94.39% weighted $f_1$ score on the test set in task-A.\nLabel powerset SVM with n-gram features obtained the maximum coarse-grained and\nfine-grained $f_1$ score of 86.03% and 50.98% on the task-B test set\nrespectively.", "author": [{"name": "Omar Sharif"}, {"name": "Eftekhar Hossain"}, {"name": "Mohammed Moshiul Hoque"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Shared task description paper in CONSTRAINT workshop collocated with\n  AAAI-2021, 11 pages"}, "link": [{"@href": "http://arxiv.org/abs/2101.03291v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.03291v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.03717v2", "updated": "2021-01-13T00:06:45Z", "published": "2021-01-11T05:57:32Z", "title": "Constraint 2021: Machine Learning Models for COVID-19 Fake News\n  Detection Shared Task", "summary": "In this system paper we present our contribution to the Constraint 2021\nCOVID-19 Fake News Detection Shared Task, which poses the challenge of\nclassifying COVID-19 related social media posts as either fake or real. In our\nsystem, we address this challenge by applying classical machine learning\nalgorithms together with several linguistic features, such as n-grams,\nreadability, emotional tone and punctuation. In terms of pre-processing, we\nexperiment with various steps like stop word removal, stemming/lemmatization,\nlink removal and more. We find our best performing system to be based on a\nlinear SVM, which obtains a weighted average F1 score of 95.19% on test data,\nwhich lands a place in the middle of the leaderboard (place 80 of 167).", "author": {"name": "Thomas Felber"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Constraint 2021, AAAI 21, 10 pages"}, "link": [{"@href": "http://arxiv.org/abs/2101.03717v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.03717v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.06051v2", "updated": "2021-07-14T10:51:41Z", "published": "2021-07-13T13:05:11Z", "title": "Rating Facts under Coarse-to-fine Regimes", "summary": "The rise of manipulating fake news as a political weapon has become a global\nconcern and highlighted the incapability of manually fact checking against\nrapidly produced fake news. Thus, statistical approaches are required if we are\nto address this problem efficiently. The shortage of publicly available\ndatasets is one major bottleneck of automated fact checking. To remedy this, we\ncollected 24K manually rated statements from PolitiFact. The class values\nexhibit a natural order with respect to truthfulness as shown in Table 1. Thus,\nour task represents a twist from standard classification, due to the various\ndegrees of similarity between classes. To investigate this, we defined\ncoarse-to-fine classification regimes, which presents new challenge for\nclassification. To address this, we propose BERT-based models. After training,\nclass similarity is sensible over the multi-class datasets, especially in the\nfine-grained one. Under all the regimes, BERT achieves state of the art, while\nthe additional layers provide insignificant improvement.", "author": {"name": "Guojun Wu"}, "link": [{"@href": "http://arxiv.org/abs/2107.06051v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.06051v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1909.12233v1", "updated": "2019-09-13T13:39:59Z", "published": "2019-09-13T13:39:59Z", "title": "Deep Ensemble Learning for News Stance Detection", "summary": "Stance detection in fake news is an important component in news veracity\nassessment because this process helps fact-checking by understanding stance to\na central claim from different information sources. The Fake News Challenge\nStage 1 (FNC-1) held in 2017 was setup for this purpose, which involves\nestimating the stance of a news article body relative to a given headline. This\nthesis starts from the error analysis for the three top-performing systems in\nFNC-1. Based on the analysis, a simple but tough-to-beat Multilayer Perceptron\nsystem is chosen as the baseline. Afterwards, three approaches are explored to\nimprove baseline.The first approach explores the possibility of improving the\nprediction accuracy by adding extra keywords features when training a model,\nwhere keywords are converted to an indicator vector and then concatenated to\nthe baseline features. A list of keywords is manually selected based on the\nerror analysis, which may best reflect some characteristics of fake news titles\nand bodies. To make this selection process automatically, three algorithms are\ncreated based on Mutual Information (MI) theory: keywords generator based on MI\nstance class, MI customised class, and Pointwise MI algorithm. The second\napproach is based on word embedding, where word2vec model is introduced and two\ndocument similarities calculation algorithms are implemented: wor2vec cosine\nsimilarity and WMD distance. The third approach is ensemble learning. Different\nmodels are configured together with two continuous outputs combining\nalgorithms. The 10-fold cross validation reveals that the ensemble of three\nneural network models trained from simple bag-of-words features gives the best\nperformance. It is therefore selected to compete in FNC-1. After\nhyperparameters fine tuning, the selected deep ensemble model beats the FNC-1\nwinner team by a remarkable 34.25 marks under FNC-1's evaluation metric.", "author": [{"name": "Wenjun Liao"}, {"name": "Chenghua Lin"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Poster presenataion of 5th IC2S2 in University of Amsterdam"}, "link": [{"@href": "http://arxiv.org/abs/1909.12233v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.12233v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1711.05303v1", "updated": "2017-11-14T20:12:29Z", "published": "2017-11-14T20:12:29Z", "title": "Online Political Discourse in the Trump Era", "summary": "We identify general trends in the (in)civility and complexity of political\ndiscussions occurring on Reddit between January 2007 and May 2017 -- a period\nspanning both terms of Barack Obama's presidency and the first 100 days of\nDonald Trump's presidency. We then investigate four factors that are frequently\nhypothesized as having contributed to the declining quality of American\npolitical discourse -- (1) the rising popularity of Donald Trump, (2)\nincreasing polarization and negative partisanship, (3) the democratization of\nnews media and the rise of fake news, and (4) merging of fringe groups into\nmainstream political discussions.", "author": [{"name": "Rishab Nithyanand"}, {"name": "Brian Schaffner"}, {"name": "Phillipa Gill"}], "link": [{"@href": "http://arxiv.org/abs/1711.05303v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.05303v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1708.05286v2", "updated": "2017-09-14T13:42:56Z", "published": "2017-08-17T14:06:58Z", "title": "Simple Open Stance Classification for Rumour Analysis", "summary": "Stance classification determines the attitude, or stance, in a (typically\nshort) text. The task has powerful applications, such as the detection of fake\nnews or the automatic extraction of attitudes toward entities or events in the\nmedia. This paper describes a surprisingly simple and efficient classification\napproach to open stance classification in Twitter, for rumour and veracity\nclassification. The approach profits from a novel set of automatically\nidentifiable problem-specific features, which significantly boost classifier\naccuracy and achieve above state-of-the-art results on recent benchmark\ndatasets. This calls into question the value of using complex sophisticated\nmodels for stance classification without first doing informed feature\nextraction.", "author": [{"name": "Ahmet Aker"}, {"name": "Leon Derczynski"}, {"name": "Kalina Bontcheva"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In RANLP 2017"}, "link": [{"@href": "http://arxiv.org/abs/1708.05286v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1708.05286v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1804.00982v1", "updated": "2018-04-03T14:17:09Z", "published": "2018-04-03T14:17:09Z", "title": "360\u00b0 Stance Detection", "summary": "The proliferation of fake news and filter bubbles makes it increasingly\ndifficult to form an unbiased, balanced opinion towards a topic. To ameliorate\nthis, we propose 360{\\deg} Stance Detection, a tool that aggregates news with\nmultiple perspectives on a topic. It presents them on a spectrum ranging from\nsupport to opposition, enabling the user to base their opinion on multiple\npieces of diverse evidence.", "author": [{"name": "Sebastian Ruder"}, {"name": "John Glover"}, {"name": "Afshin Mehrabani"}, {"name": "Parsa Ghaffari"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of NAACL-HLT 2018: System Demonstrations"}, "link": [{"@href": "http://arxiv.org/abs/1804.00982v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.00982v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1804.07581v1", "updated": "2018-04-20T12:48:10Z", "published": "2018-04-20T12:48:10Z", "title": "Automatic Stance Detection Using End-to-End Memory Networks", "summary": "We present a novel end-to-end memory network for stance detection, which\njointly (i) predicts whether a document agrees, disagrees, discusses or is\nunrelated with respect to a given target claim, and also (ii) extracts snippets\nof evidence for that prediction. The network operates at the paragraph level\nand integrates convolutional and recurrent neural networks, as well as a\nsimilarity matrix as part of the overall architecture. The experimental\nevaluation on the Fake News Challenge dataset shows state-of-the-art\nperformance.", "author": [{"name": "Mitra Mohtarami"}, {"name": "Ramy Baly"}, {"name": "James Glass"}, {"name": "Preslav Nakov"}, {"name": "Lluis Marquez"}, {"name": "Alessandro Moschitti"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NAACL-2018; Stance detection; Fact-Checking; Veracity; Memory\n  networks; Neural Networks; Distributed Representations"}, "link": [{"@href": "http://arxiv.org/abs/1804.07581v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.07581v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1809.01574v2", "updated": "2018-10-03T12:44:14Z", "published": "2018-09-05T15:20:41Z", "title": "Stance Prediction for Russian: Data and Analysis", "summary": "Stance detection is a critical component of rumour and fake news\nidentification. It involves the extraction of the stance a particular author\ntakes related to a given claim, both expressed in text. This paper investigates\nstance classification for Russian. It introduces a new dataset, RuStance, of\nRussian tweets and news comments from multiple sources, covering multiple\nstories, as well as text classification approaches to stance detection as\nbenchmarks over this data in this language. As well as presenting this\nopenly-available dataset, the first of its kind for Russian, the paper presents\na baseline for stance prediction in the language.", "author": [{"name": "Nikita Lozhnikov"}, {"name": "Leon Derczynski"}, {"name": "Manuel Mazzara"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.13140/RG.2.2.15252.76161/1"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.13140/RG.2.2.15252.76161/1", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1809.01574v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.01574v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1903.01780v1", "updated": "2019-03-05T12:10:11Z", "published": "2019-03-05T12:10:11Z", "title": "Trust and Trustworthiness in Social Recommender Systems", "summary": "The prevalence of misinformation on online social media has tangible\nempirical connections to increasing political polarization and partisan\nantipathy in the United States. Ranking algorithms for social recommendation\noften encode broad assumptions about network structure (like homophily) and\ngroup cognition (like, social action is largely imitative). Assumptions like\nthese can be na\\\"ive and exclusionary in the era of fake news and ideological\nuniformity towards the political poles. We examine these assumptions with aid\nfrom the user-centric framework of trustworthiness in social recommendation.\nThe constituent dimensions of trustworthiness (diversity, transparency,\nexplainability, disruption) highlight new opportunities for discouraging\ndogmatization and building decision-aware, transparent news recommender\nsystems.", "author": [{"name": "Taha Hassan"}, {"name": "D. Scott McCrickard"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "WWW '19 FATES"}, "link": [{"@href": "http://arxiv.org/abs/1903.01780v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.01780v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1908.09951v1", "updated": "2019-08-26T22:49:35Z", "published": "2019-08-26T22:49:35Z", "title": "An Emotional Analysis of False Information in Social Media and News\n  Articles", "summary": "Fake news is risky since it has been created to manipulate the readers'\nopinions and beliefs. In this work, we compared the language of false news to\nthe real one of real news from an emotional perspective, considering a set of\nfalse information types (propaganda, hoax, clickbait, and satire) from social\nmedia and online news articles sources. Our experiments showed that false\ninformation has different emotional patterns in each of its types, and emotions\nplay a key role in deceiving the reader. Based on that, we proposed a LSTM\nneural network model that is emotionally-infused to detect false news.", "author": [{"name": "Bilal Ghanem"}, {"name": "Paolo Rosso"}, {"name": "Francisco Rangel"}], "link": [{"@href": "http://arxiv.org/abs/1908.09951v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1908.09951v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.06634v1", "updated": "2020-03-14T14:02:27Z", "published": "2020-03-14T14:02:27Z", "title": "Text Similarity Using Word Embeddings to Classify Misinformation", "summary": "Fake news is a growing problem in the last years, especially during\nelections. It's hard work to identify what is true and what is false among all\nthe user generated content that circulates every day. Technology can help with\nthat work and optimize the fact-checking process. In this work, we address the\nchallenge of finding similar content in order to be able to suggest to a\nfact-checker articles that could have been verified before and thus avoid that\nthe same information is verified more than once. This is especially important\nin collaborative approaches to fact-checking where members of large teams will\nnot know what content others have already fact-checked.", "author": [{"name": "Caio Almeida"}, {"name": "D\u00e9bora Santos"}], "link": [{"@href": "http://arxiv.org/abs/2003.06634v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.06634v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.14907v1", "updated": "2020-04-30T16:06:02Z", "published": "2020-04-30T16:06:02Z", "title": "You are right. I am ALARMED -- But by Climate Change Counter Movement", "summary": "The world is facing the challenge of climate crisis. Despite the consensus in\nscientific community about anthropogenic global warming, the web is flooded\nwith articles spreading climate misinformation. These articles are carefully\nconstructed by climate change counter movement (cccm) organizations to\ninfluence the narrative around climate change. We revisit the literature on\nclimate misinformation in social sciences and repackage it to introduce in the\ncommunity of NLP. Despite considerable work in detection of fake news, there is\nno misinformation dataset available that is specific to the domain.of climate\nchange. We try to bridge this gap by scraping and releasing articles with known\nclimate change misinformation.", "author": [{"name": "Shraey Bhatia"}, {"name": "Jey Han Lau"}, {"name": "Timothy Baldwin"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "5 pages"}, "link": [{"@href": "http://arxiv.org/abs/2004.14907v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.14907v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2005.00485v1", "updated": "2020-04-30T14:59:25Z", "published": "2020-04-30T14:59:25Z", "title": "Getting Insights from a Large Corpus of Scientific Papers on\n  Specialisted Comprehensive Topics -- the Case of COVID-19", "summary": "COVID-19 is one of the most important topic these days, specifically on\nsearch engines and news. While fake news are easily shared, scientific papers\nare reliable sources where information can be extracted. With about 24,000\nscientific publications on COVID-19 and related research on PUBMED, automatic\ncomputer-assisted analysis is required. In this paper, we develop two\nmethodologies to get insights on specific sub-topics of interest and latest\nresearch sub-topics. They rely on natural language processing and graph-based\nvisualizations. We run these methodologies on two cases: the virus origin and\nthe uses of existing drugs.", "author": [{"name": "Bernard Dousset"}, {"name": "Josiane Mothe"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "14 pages; 5 figures and 3 tables submitted to KES 2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.00485v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.00485v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.03588v1", "updated": "2020-11-06T20:33:12Z", "published": "2020-11-06T20:33:12Z", "title": "Hostility Detection Dataset in Hindi", "summary": "In this paper, we present a novel hostility detection dataset in Hindi\nlanguage. We collect and manually annotate ~8200 online posts. The annotated\ndataset covers four hostility dimensions: fake news, hate speech, offensive,\nand defamation posts, along with a non-hostile label. The hostile posts are\nalso considered for multi-label tags due to a significant overlap among the\nhostile classes. We release this dataset as part of the CONSTRAINT-2021 shared\ntask on hostile post detection.", "author": [{"name": "Mohit Bhardwaj"}, {"name": "Md Shad Akhtar"}, {"name": "Asif Ekbal"}, {"name": "Amitava Das"}, {"name": "Tanmoy Chakraborty"}], "link": [{"@href": "http://arxiv.org/abs/2011.03588v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.03588v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2012.02613v1", "updated": "2020-12-04T14:17:46Z", "published": "2020-12-04T14:17:46Z", "title": "FinnSentiment -- A Finnish Social Media Corpus for Sentiment Polarity\n  Annotation", "summary": "Sentiment analysis and opinion mining is an important task with obvious\napplication areas in social media, e.g. when indicating hate speech and fake\nnews. In our survey of previous work, we note that there is no large-scale\nsocial media data set with sentiment polarity annotations for Finnish. This\npublications aims to remedy this shortcoming by introducing a 27,000 sentence\ndata set annotated independently with sentiment polarity by three native\nannotators. We had the same three annotators for the whole data set, which\nprovides a unique opportunity for further studies of annotator behaviour over\ntime. We analyse their inter-annotator agreement and provide two baselines to\nvalidate the usefulness of the data set.", "author": [{"name": "Krister Lind\u00e9n"}, {"name": "Tommi Jauhiainen"}, {"name": "Sam Hardwick"}], "link": [{"@href": "http://arxiv.org/abs/2012.02613v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.02613v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.02335v1", "updated": "2021-02-03T23:37:09Z", "published": "2021-02-03T23:37:09Z", "title": "Self-Supervised Claim Identification for Automated Fact Checking", "summary": "We propose a novel, attention-based self-supervised approach to identify\n\"claim-worthy\" sentences in a fake news article, an important first step in\nautomated fact-checking. We leverage \"aboutness\" of headline and content using\nattention mechanism for this task. The identified claims can be used for\ndownstream task of claim verification for which we are releasing a benchmark\ndataset of manually selected compelling articles with veracity labels and\nassociated evidence. This work goes beyond stylistic analysis to identifying\ncontent that influences reader belief. Experiments with three datasets show the\nstrength of our model. Data and code available at\nhttps://github.com/architapathak/Self-Supervised-ClaimIdentification", "author": [{"name": "Archita Pathak"}, {"name": "Mohammad Abuzar Shaikh"}, {"name": "Rohini Srihari"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages, 4 figures, Accepted at ICON 2020"}, "link": [{"@href": "http://arxiv.org/abs/2102.02335v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.02335v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.05243v1", "updated": "2021-04-12T07:25:49Z", "published": "2021-04-12T07:25:49Z", "title": "On Unifying Misinformation Detection", "summary": "In this paper, we introduce UnifiedM2, a general-purpose misinformation model\nthat jointly models multiple domains of misinformation with a single, unified\nsetup. The model is trained to handle four tasks: detecting news bias,\nclickbait, fake news, and verifying rumors. By grouping these tasks together,\nUnifiedM2learns a richer representation of misinformation, which leads to\nstate-of-the-art or comparable performance across all tasks. Furthermore, we\ndemonstrate that UnifiedM2's learned representation is helpful for few-shot\nlearning of unseen misinformation tasks/datasets and model's generalizability\nto unseen events.", "author": [{"name": "Nayeon Lee"}, {"name": "Belinda Z. Li"}, {"name": "Sinong Wang"}, {"name": "Pascale Fung"}, {"name": "Hao Ma"}, {"name": "Wen-tau Yih"}, {"name": "Madian Khabsa"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to NAACL2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.05243v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.05243v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1703.06988v1", "updated": "2017-03-20T22:19:22Z", "published": "2017-03-20T22:19:22Z", "title": "The Fake News Spreading Plague: Was it Preventable?", "summary": "In 2010, a paper entitled \"From Obscurity to Prominence in Minutes: Political\nSpeech and Real-time search\" won the Best Paper Prize of the Web Science 2010\nConference. Among its findings were the discovery and documentation of what was\ntermed a \"Twitter-bomb\", an organized effort to spread misinformation about the\ndemocratic candidate Martha Coakley through anonymous Twitter accounts. In this\npaper, after summarizing the details of that event, we outline the recipe of\nhow social networks are used to spread misinformation. One of the most\nimportant steps in such a recipe is the \"infiltration\" of a community of users\nwho are already engaged in conversations about a topic, to use them as organic\nspreaders of misinformation in their extended subnetworks. Then, we take this\nmisinformation spreading recipe and indicate how it was successfully used to\nspread fake news during the 2016 U.S. Presidential Election. The main\ndifferences between the scenarios are the use of Facebook instead of Twitter,\nand the respective motivations (in 2010: political influence; in 2016:\nfinancial benefit through online advertising). After situating these events in\nthe broader context of exploiting the Web, we seize this opportunity to address\nlimitations of the reach of research findings and to start a conversation about\nhow communities of researchers can increase their impact on real-world societal\nissues.", "author": [{"name": "Eni Mustafaraj"}, {"name": "Panagiotis Takis Metaxas"}], "link": [{"@href": "http://arxiv.org/abs/1703.06988v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1703.06988v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1905.06894v1", "updated": "2019-05-02T15:49:21Z", "published": "2019-05-02T15:49:21Z", "title": "Fake news and rumors: a trigger for proliferation or fading away", "summary": "The dynamics of fake news and rumor spreading is investigated using a model\nwith three kinds of agents who are respectively the Seeds, the Agnostics and\nthe Others. While Seeds are the ones who start spreading the rumor being\nadamantly convinced of its truth, Agnostics reject any kind of rumor and do not\nbelieve in conspiracy theories. In between, the Others constitute the main part\nof the community. While Seeds are always Believers and Agnostics are always\nIndifferents, Others can switch between being Believer and Indifferent\ndepending on who they are discussing with. The underlying driving dynamics is\nimplemented via local updates of randomly formed groups of agents. In each\ngroup, an Other turns into a Believer as soon as $m$ or more Believers are\npresent in the group. However, since some Believers may lose interest in the\nrumor as time passes by, we add a flipping fixed rate $0<d<1$ from Believers\ninto Indifferents. Rigorous analysis of the associated dynamics reveals that\nswitching from $m=1$ to $m\\ge2$ triggers a drastic qualitative change in the\nspreading process. When $m=1$ even a small group of Believers may manage to\nconvince a large part of the community very quickly. In contrast, for $m\\ge 2$,\neven a substantial fraction of Believers does not prevent the rumor dying out\nafter a few update rounds. Our results provide an explanation on why a given\nrumor spreads within a social group and not in another, and also why some\nrumors will not spread in neither groups.", "author": [{"name": "Ahad N. Zehmakan"}, {"name": "Serge Galam"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1063/5.0006984"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1063/5.0006984", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1905.06894v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.06894v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.DM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.DS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.03423v1", "updated": "2019-06-08T08:56:02Z", "published": "2019-06-08T08:56:02Z", "title": "News Labeling as Early as Possible: Real or Fake?", "summary": "Making disguise between real and fake news propagation through online social\nnetworks is an important issue in many applications. The time gap between the\nnews release time and detection of its label is a significant step towards\nbroadcasting the real information and avoiding the fake. Therefore, one of the\nchallenging tasks in this area is to identify fake and real news in early\nstages of propagation. However, there is a trade-off between minimizing the\ntime gap and maximizing accuracy. Despite recent efforts in detection of fake\nnews, there has been no significant work that explicitly incorporates early\ndetection in its model. In this paper, we focus on accurate early labeling of\nnews, and propose a model by considering earliness both in modeling and\nprediction. The proposed method utilizes recurrent neural networks with a novel\nloss function, and a new stopping rule. Given the context of news, we first\nembed it with a class-specific text representation. Then, we utilize the\navailable public profile of users, and speed of news diffusion, for early\nlabeling of the news. Experiments on real datasets demonstrate the\neffectiveness of our model both in terms of early labelling and accuracy,\ncompared to the state of the art baseline and models.", "author": [{"name": "Maryam Ramezani"}, {"name": "Mina Rafiei"}, {"name": "Soroush Omranpour"}, {"name": "Hamid R. Rabiee"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3341161.3342957"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3341161.3342957", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1906.03423v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.03423v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.01681v1", "updated": "2019-09-04T10:30:03Z", "published": "2019-09-04T10:30:03Z", "title": "Under the Conditions of Non-Agenda Ownership: Social Media Users in the\n  2019 Ukrainian Presidential Elections Campaign", "summary": "Owing to its history and challenging circumstances, social networks community\nin Ukraine is a very interesting polygon for the study of communications in the\nconstantly changing environment, especially in the political discourse. This\nunique environment requires three dimensions to ascertain the political\nposition of its participant. But 2019 presidential elections made this object\neven more spectacular. The winner of elections comedian Volodymyr Zelenskyi\nreached 73% of votes without any issue ownership, with empty agenda, and this\ninfluenced the electoral content of social networks and their authors behavior.\nWe saw, that the issue ownership by other candidates succeeds in making their\nissues more salient in social networks. But the new phenomena, the non-agenda\nownership, overcome any ideological influence, especially under the conditions\nof punishment mechanism applied to old politicians. Analyzing social media\ncontent and users behavior in the period between two rounds of elections, we\nfound considerable overlaps between this campaign and the 2016 Trump campaign.\nWe approved the widespread of filter bubbles, negative campaign messages, fake\nnews and conspiracy theories. Active and powerful core of Ukrainian Facebook\nthat was responsible for the Revolution of dignity now became less significant\nand even turns into the huge filter bubble of active people. We also proved\nthat manipulations and fake news in the environment of private groups may be as\nmuch powerful as in a case of classical communication based around the opinion\nleaders.", "author": [{"name": "Artem Zakharchenko"}, {"name": "Yuliia Maksimtsova"}, {"name": "Valentyn Iurchenko"}, {"name": "Viktoriya Shevchenko"}, {"name": "Solomiia Fedushko"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "21 pages, 8 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CEUR Workshop Proceedings. Vol 2392: Proceedings of the 1st\n  International Workshop on Control, Optimisation and Analytical Processing of\n  Social Networks, COAPSN-2019, 2019"}, "link": [{"@href": "http://arxiv.org/abs/1909.01681v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.01681v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.12039v1", "updated": "2019-11-27T09:22:51Z", "published": "2019-11-27T09:22:51Z", "title": "The Limited Reach of Fake News on Twitter during 2019 European Elections", "summary": "The advent of social media changed the way we consume content favoring a\ndisintermediated access and production. This scenario has been matter of\ncritical discussion about its impact on society. Magnified in the case of Arab\nSpring or heavily criticized in the Brexit and 2016 U.S. elections. In this\nwork we explore information consumption on Twitter during the last European\nelectoral campaign by analyzing the interaction patterns of official news\nsources, fake news sources, politicians, people from the showbiz and many\nothers. We extensively explore interactions among different classes of accounts\nin the months preceding the last European elections, held between 23rd and 26th\nof May, 2019. We collected almost 400,000 tweets posted by 863 accounts having\ndifferent roles in the public society. Through a thorough quantitative analysis\nwe investigate the information flow among them, also exploiting geolocalized\ninformation. Accounts show the tendency to confine their interaction within the\nsame class and the debate rarely crosses national borders. Moreover, we do not\nfind any evidence of an organized network of accounts aimed at spreading\ndisinformation. Instead, disinformation outlets are largely ignored by the\nother actors and hence play a peripheral role in online political discussions.", "author": [{"name": "Matteo Cinelli"}, {"name": "Stefano Cresci"}, {"name": "Alessandro Galeazzi"}, {"name": "Walter Quattrociocchi"}, {"name": "Maurizio Tesconi"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0234689"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0234689", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1911.12039v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.12039v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PLoS ONE 15(6): e0234689, 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.02438v1", "updated": "2020-01-08T10:26:55Z", "published": "2020-01-08T10:26:55Z", "title": "To Transfer or Not to Transfer: Misclassification Attacks Against\n  Transfer Learned Text Classifiers", "summary": "Transfer learning --- transferring learned knowledge --- has brought a\nparadigm shift in the way models are trained. The lucrative benefits of\nimproved accuracy and reduced training time have shown promise in training\nmodels with constrained computational resources and fewer training samples.\nSpecifically, publicly available text-based models such as GloVe and BERT that\nare trained on large corpus of datasets have seen ubiquitous adoption in\npractice. In this paper, we ask, \"can transfer learning in text prediction\nmodels be exploited to perform misclassification attacks?\" As our main\ncontribution, we present novel attack techniques that utilize unintended\nfeatures learnt in the teacher (public) model to generate adversarial examples\nfor student (downstream) models. To the best of our knowledge, ours is the\nfirst work to show that transfer learning from state-of-the-art word-based and\nsentence-based teacher models increase the susceptibility of student models to\nmisclassification attacks. First, we propose a novel word-score based attack\nalgorithm for generating adversarial examples against student models trained\nusing context-free word-level embedding model. On binary classification tasks\ntrained using the GloVe teacher model, we achieve an average attack accuracy of\n97% for the IMDB Movie Reviews and 80% for the Fake News Detection. For\nmulti-class tasks, we divide the Newsgroup dataset into 6 and 20 classes and\nachieve an average attack accuracy of 75% and 41% respectively. Next, we\npresent length-based and sentence-based misclassification attacks for the Fake\nNews Detection task trained using a context-aware BERT model and achieve 78%\nand 39% attack accuracy respectively. Thus, our results motivate the need for\ndesigning training techniques that are robust to unintended feature learning,\nspecifically for transfer learned models.", "author": [{"name": "Bijeeta Pal"}, {"name": "Shruti Tople"}], "link": [{"@href": "http://arxiv.org/abs/2001.02438v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.02438v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.05854v1", "updated": "2020-05-12T15:20:55Z", "published": "2020-05-12T15:20:55Z", "title": "Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News", "summary": "Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 \"infodemic\", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n\"fake news\" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta", "author": [{"name": "Giovanni Da San Martino"}, {"name": "Shaden Shaar"}, {"name": "Yifan Zhang"}, {"name": "Seunghak Yu"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, disinformation, fake news, media bias, COVID-19"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL-2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.05854v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.05854v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.06058v1", "updated": "2020-05-12T21:25:37Z", "published": "2020-05-12T21:25:37Z", "title": "That is a Known Lie: Detecting Previously Fact-Checked Claims", "summary": "The recent proliferation of \"fake news\" has triggered a number of responses,\nmost notably the emergence of several manual fact-checking initiatives. As a\nresult and over time, a large number of fact-checked claims have been\naccumulated, which increases the likelihood that a new claim in social media or\na new statement by a politician might have already been fact-checked by some\ntrusted fact-checking organization, as viral claims often come back after a\nwhile in social media, and politicians like to repeat their favorite\nstatements, true or false, over and over again. As manual fact-checking is very\ntime-consuming (and fully automatic fact-checking has credibility issues), it\nis important to try to save this effort and to avoid wasting time on claims\nthat have already been fact-checked. Interestingly, despite the importance of\nthe task, it has been largely ignored by the research community so far. Here,\nwe aim to bridge this gap. In particular, we formulate the task and we discuss\nhow it relates to, but also differs from, previous work. We further create a\nspecialized dataset, which we release to the research community. Finally, we\npresent learning-to-rank experiments that demonstrate sizable improvements over\nstate-of-the-art retrieval and textual similarity approaches.", "author": [{"name": "Shaden Shaar"}, {"name": "Giovanni Da San Martino"}, {"name": "Nikolay Babulkov"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL-2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.06058v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.06058v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.07996v2", "updated": "2021-04-09T08:52:10Z", "published": "2020-07-15T21:18:30Z", "title": "Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms", "summary": "With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.", "author": [{"name": "Firoj Alam"}, {"name": "Fahim Dalvi"}, {"name": "Shaden Shaar"}, {"name": "Nadir Durrani"}, {"name": "Hamdy Mubarak"}, {"name": "Alex Nikolov"}, {"name": "Giovanni Da San Martino"}, {"name": "Ahmed Abdelali"}, {"name": "Hassan Sajjad"}, {"name": "Kareem Darwish"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "COVID-19, Infodemic, Disinformation, Misinformation, Fake News, Call\n  to Arms, Crowdsourcing Annotations"}, "link": [{"@href": "http://arxiv.org/abs/2007.07996v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.07996v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.07698v5", "updated": "2020-10-21T15:16:20Z", "published": "2020-09-16T14:13:15Z", "title": "Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News", "summary": "Large-scale dissemination of disinformation online intended to mislead or\ndeceive the general population is a major societal problem. Rapid progression\nin image, video, and natural language generative models has only exacerbated\nthis situation and intensified our need for an effective defense mechanism.\nWhile existing approaches have been proposed to defend against neural fake\nnews, they are generally constrained to the very limited setting where articles\nonly have text and metadata such as the title and authors. In this paper, we\nintroduce the more realistic and challenging task of defending against\nmachine-generated news that also includes images and captions. To identify the\npossible weaknesses that adversaries can exploit, we create a NeuralNews\ndataset composed of 4 different types of generated articles as well as conduct\na series of human user study experiments based on this dataset. In addition to\nthe valuable insights gleaned from our user study experiments, we provide a\nrelatively effective approach based on detecting visual-semantic\ninconsistencies, which will serve as an effective first line of defense and a\nuseful reference for future work in defending against machine-generated\ndisinformation.", "author": [{"name": "Reuben Tan"}, {"name": "Bryan A. Plummer"}, {"name": "Kate Saenko"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at EMNLP 2020"}, "link": [{"@href": "http://arxiv.org/abs/2009.07698v5", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.07698v5", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.11004v1", "updated": "2020-12-20T19:35:25Z", "published": "2020-12-20T19:35:25Z", "title": "Fake news agenda in the era of COVID-19: Identifying trends through\n  fact-checking content", "summary": "The rise of social media has ignited an unprecedented circulation of false\ninformation in our society. It is even more evident in times of crises, such as\nthe COVID-19 pandemic. Fact-checking efforts have expanded greatly and have\nbeen touted as among the most promising solutions to fake news, especially in\ntimes like these. Several studies have reported the development of\nfact-checking organizations in Western societies, albeit little attention has\nbeen given to the Global South. Here, to fill this gap, we introduce a novel\nMarkov-inspired computational method for identifying topics in tweets. In\ncontrast to other topic modeling approaches, our method clusters topics and\ntheir current evolution in a predefined time window. Through these, we\ncollected data from Twitter accounts of two Brazilian fact-checking outlets and\npresented the topics debunked by these initiatives in fortnights throughout the\npandemic. By comparing these organizations, we could identify similarities and\ndifferences in what was shared by them. Our method resulted in an important\ntechnique to cluster topics in a wide range of scenarios, including an\ninfodemic -- a period overabundance of the same information. In particular, the\ndata clearly revealed a complex intertwining between politics and the health\ncrisis during this period. We conclude by proposing a generic model which, in\nour opinion, is suitable for topic modeling and an agenda for future research.", "author": [{"name": "Wilson Ceron"}, {"name": "Mathias-Felipe de-Lima-Santos"}, {"name": "Marcos G. Quiles"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.osnem.2020.100116"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.osnem.2020.100116", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2012.11004v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.11004v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Online Social Networks and Media, 2020"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.09251v1", "updated": "2021-01-22T18:03:57Z", "published": "2021-01-22T18:03:57Z", "title": "How to Deal with Fake News: Visualizing Disinformation", "summary": "The current public sense of anxiety in dealing with disinformation as\nmanifested by so-called fake news is acutely displayed by the reaction to\nrecent events prompted by a belief in conspiracies among certain groups. A\nmodel to deal with disinformation is proposed; it is based on a demonstration\nof the analogous behavior of disinformation to that of wave phenomena. Two\ncriteria form the basis to combat the deleterious effects of disinformation:\nthe use of a refractive medium based on skepticism as the default mode, and\npolarization as a filter mechanism to analyze its merits based on evidence.\nCritical thinking is enhanced since the first one tackles the pernicious effect\nof the confirmation bias, and the second the tendency towards attribution, both\nof which undermine our efforts to think and act rationally. The benefits of\nsuch a strategy include an epistemic reformulation of disinformation as an\nindependently existing phenomenon, that removes its negative connotations when\nperceived as being possessed by groups or individuals.", "author": [{"name": "F. Espinoza"}, {"name": "Department of Physics"}, {"name": "Astronomy"}, {"name": "Hofstra University"}, {"name": "Hempstead"}, {"name": "NY. USA."}, {"name": "Department of Chemistry"}, {"name": "Physics-Adolescence Education"}, {"name": "SUNY Old Westbury"}, {"name": "Old Westbury"}, {"name": "NY. USA"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Four figures explaining the proposed mechanism that describe wave\n  properties and behavior. The quantitative details are kept to a minimum so as\n  to highlight the relevance of the treatment of disinformation as a wave, to\n  the larger public sphere"}, "link": [{"@href": "http://arxiv.org/abs/2101.09251v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.09251v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.11337v2", "updated": "2021-02-04T11:53:20Z", "published": "2021-01-27T11:58:04Z", "title": "Launchers and Targets in Social Networks", "summary": "Influence propagation in social networks is a subject of growing interest. A\nrelevant issue in those networks involves the identification of key\ninfluencers. These players have an important role on viral marketing strategies\nand message propagation, including political propaganda and fake news. In\neffect, an important way to fight malicious usage on social networks is to\nunderstand their properties, their structure and the way messages propagate.\n  This paper proposes two new indices for analysing message propagation in\nsocial networks, based on the network topological nature and the power of the\nmessage. The first index involves the strength of each node as a launcher of\nthe message, dividing the nodes into launchers and non-launchers. The second\nindex addresses the potential of each member as a receiver (target) of the\nmessage, dividing the nodes into targets and non-targets. Launcher individuals\nshould indicate strong influencers and target individuals should identify the\nbest target consumers. These indices can assist other known metrics when used\nto select efficient influencers in a social network. For instance, instead of\nchoosing a strong and probably expensive member according to its degree in the\nnetwork (number of followers), we may previously select those belonging to the\nlaunchers group and look for the lowest degree members, which are probably\ncheaper but still guarantying almost the same influence effectiveness as the\nlargest degree members.\n  On a different direction, using the second index, the strong target members\nshould characterize relevant consumers of information in the network, which may\ninclude fake news' regular collectors.\n  We discuss these indices using small-world randomly generated graphs and a\nnumber of real-world social networks available in known datasets repositories.", "author": [{"name": "Pedro Martins"}, {"name": "Filipa Alarc\u00e3o Martins"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "30 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/2101.11337v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.11337v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68R10, 90B18", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.11804v2", "updated": "2021-06-05T20:42:13Z", "published": "2021-03-22T13:07:26Z", "title": "Detection of fake news on CoViD-19 on Web Search Engines", "summary": "In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.", "author": [{"name": "V. Mazzeo"}, {"name": "A. Rapisarda"}, {"name": "G. Giuffrida"}], "link": [{"@href": "http://arxiv.org/abs/2103.11804v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.11804v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.12506v1", "updated": "2021-03-16T11:11:54Z", "published": "2021-03-16T11:11:54Z", "title": "A Survey on Predicting the Factuality and the Bias of News Media", "summary": "The present level of proliferation of fake, biased, and propagandistic\ncontent online has made it impossible to fact-check every single suspicious\nclaim or article, either manually or automatically. Thus, many researchers are\nshifting their attention to higher granularity, aiming to profile entire news\noutlets, which makes it possible to detect likely \"fake news\" the moment it is\npublished, by simply checking the reliability of its source. Source factuality\nis also an important element of systems for automatic fact-checking and \"fake\nnews\" detection, as they need to assess the reliability of the evidence they\nretrieve online. Political bias detection, which in the Western political\nlandscape is about predicting left-center-right bias, is an equally important\ntopic, which has experienced a similar shift towards profiling entire news\noutlets. Moreover, there is a clear connection between the two, as highly\nbiased media are less likely to be factual; yet, the two problems have been\naddressed separately. In this survey, we review the state of the art on media\nprofiling for factuality and bias, arguing for the need to model them jointly.\nWe further discuss interesting recent advances in using different information\nsources and modalities, which go beyond the text of the articles the target\nnews outlet has published. Finally, we discuss current challenges and outline\nfuture research directions.", "author": [{"name": "Preslav Nakov"}, {"name": "Husrev Taha Sencar"}, {"name": "Jisun An"}, {"name": "Haewoon Kwak"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "factuality of reporting, fact-checking, political ideology, media\n  bias, disinformation, propaganda, social media, news media"}, "link": [{"@href": "http://arxiv.org/abs/2103.12506v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.12506v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.12541v1", "updated": "2021-03-13T18:04:17Z", "published": "2021-03-13T18:04:17Z", "title": "A Survey on Multimodal Disinformation Detection", "summary": "Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.", "author": [{"name": "Firoj Alam"}, {"name": "Stefano Cresci"}, {"name": "Tanmoy Chakraborty"}, {"name": "Fabrizio Silvestri"}, {"name": "Dimiter Dimitrov"}, {"name": "Giovanni Da San Martino"}, {"name": "Shaden Shaar"}, {"name": "Hamed Firooz"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "disinformation, misinformation, factuality, harmfulness, fake news,\n  propaganda, multimodality, text, images, videos, network structure,\n  temporality"}, "link": [{"@href": "http://arxiv.org/abs/2103.12541v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.12541v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.05321v1", "updated": "2021-04-12T10:01:44Z", "published": "2021-04-12T10:01:44Z", "title": "Combining exogenous and endogenous signals with a semi-supervised\n  co-attention network for early detection of COVID-19 fake tweets", "summary": "Fake tweets are observed to be ever-increasing, demanding immediate\ncountermeasures to combat their spread. During COVID-19, tweets with\nmisinformation should be flagged and neutralized in their early stages to\nmitigate the damages. Most of the existing methods for early detection of fake\nnews assume to have enough propagation information for large labeled tweets --\nwhich may not be an ideal setting for cases like COVID-19 where both aspects\nare largely absent. In this work, we present ENDEMIC, a novel early detection\nmodel which leverages exogenous and endogenous signals related to tweets, while\nlearning on limited labeled data. We first develop a novel dataset, called CTF\nfor early COVID-19 Twitter fake news, with additional behavioral test sets to\nvalidate early detection. We build a heterogeneous graph with\nfollower-followee, user-tweet, and tweet-retweet connections and train a graph\nembedding model to aggregate propagation information. Graph embeddings and\ncontextual features constitute endogenous, while time-relative web-scraped\ninformation constitutes exogenous signals. ENDEMIC is trained in a\nsemi-supervised fashion, overcoming the challenge of limited labeled data. We\npropose a co-attention mechanism to fuse signal representations optimally.\nExperimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is\nhighly reliable in detecting early fake tweets, outperforming nine\nstate-of-the-art methods significantly.", "author": [{"name": "Rachit Bansal"}, {"name": "William Scott Paka"}, {"name": "Nidhi"}, {"name": "Shubhashis Sengupta"}, {"name": "Tanmoy Chakraborty"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Pacific-Asia Conference on Knowledge Discovery and Data Mining\n  (PAKDD) 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.05321v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.05321v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.15172v1", "updated": "2021-05-31T17:32:06Z", "published": "2021-05-31T17:32:06Z", "title": "Assessing disinformation through the dynamics of supply and demand in\n  the news ecosystem", "summary": "Social dialogue, the foundation of our democracies, is currently threatened\nby disinformation and partisanship, with their disrupting role on individual\nand collective awareness and detrimental effects on decision-making processes.\nDespite a great deal of attention to the news sphere itself, little is known\nabout the subtle interplay between the offer and the demand for information.\nStill, a broader perspective on the news ecosystem, including both the\nproducers and the consumers of information, is needed to build new tools to\nassess the health of the infosphere. Here, we combine in the same framework\nnews supply, as mirrored by a fairly complete Italian news database - partially\nannotated for fake news, and news demand, as captured through the Google Trends\ndata for Italy. Our investigation focuses on the temporal and semantic\ninterplay of news, fake news, and searches in several domains, including the\nvirus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is\nextremely reactive to people's interests and tends to thrive, especially when\nthere is a mismatch between what people are interested in and what news outlets\nprovide. Second, a suitably defined index can assess the level of\ndisinformation only based on the available volumes of news and searches.\nAlthough our results mainly concern the Coronavirus subject, we provide hints\nthat the same findings can have more general applications. We contend these\nresults can be a powerful asset in informing campaigns against disinformation\nand providing news outlets and institutions with potentially relevant\nstrategies.", "author": [{"name": "Pietro Gravino"}, {"name": "Giulio Prevedello"}, {"name": "Martina Galletti"}, {"name": "Vittorio Loreto"}], "link": [{"@href": "http://arxiv.org/abs/2105.15172v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.15172v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.00712v2", "updated": "2019-04-09T07:34:04Z", "published": "2019-04-01T11:59:50Z", "title": "NewsCompare - a novel application for detecting news influence in a\n  country", "summary": "The concept of `fake news' has been referenced and thrown around in news\nreports so much in recent years that it has become a news topic in its own\nright. At its core, it poses a chilling question -- what do we do if our\nworldview is fundamentally wrong? Even if internally consistent, what if it\ndoes not match the real world? Are our beliefs justified, or could we become\nindoctrinated from living in a `bubble'? If the latter is true, how could we\neven test the limits of said bubble from within its confines? We propose a new\nmethod to augment the process of identifying fake news, by speeding up and\nautomating the more cumbersome and time-consuming tasks involved. Our\napplication, NewsCompare takes any list of target websites as input\n(news-related in our use case, but otherwise not restricted), visits them in\nparallel and retrieves any text content found within. Web pages are\nsubsequently compared to each other, and similarities are tentatively pointed\nout. These results can be manually verified in order to determine which\nwebsites tend to draw inspiration from one another. The data gathered on every\nintermediate step can be queried and analyzed separately, and most notably we\nalready use the set of hyperlinks to and from the various websites we encounter\nto paint a sort of `map' of that particular slice of the web. This map can then\nbe cross-referenced and further strengthen the conclusion that a particular\ngrouping of sites with strong links to each other, and posting similar content,\nare likely to share the same allegiance. We run our application on the Romanian\nnews websites and we draw several interesting observations.", "author": [{"name": "Cristian Pop"}, {"name": "Alexandru Popa"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "25 pages, 4 figures;"}, "link": [{"@href": "http://arxiv.org/abs/1904.00712v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.00712v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1911.11951v1", "updated": "2019-11-27T04:52:53Z", "published": "2019-11-27T04:52:53Z", "title": "Taking a Stance on Fake News: Towards Automatic Disinformation\n  Assessment via Deep Bidirectional Transformer Language Models for Stance\n  Detection", "summary": "The exponential rise of social media and digital news in the past decade has\nhad the unfortunate consequence of escalating what the United Nations has\ncalled a global topic of concern: the growing prevalence of disinformation.\nGiven the complexity and time-consuming nature of combating disinformation\nthrough human assessment, one is motivated to explore harnessing AI solutions\nto automatically assess news articles for the presence of disinformation. A\nvaluable first step towards automatic identification of disinformation is\nstance detection, where given a claim and a news article, the aim is to predict\nif the article agrees, disagrees, takes no position, or is unrelated to the\nclaim. Existing approaches in literature have largely relied on hand-engineered\nfeatures or shallow learned representations (e.g., word embeddings) to encode\nthe claim-article pairs, which can limit the level of representational\nexpressiveness needed to tackle the high complexity of disinformation\nidentification. In this work, we explore the notion of harnessing large-scale\ndeep bidirectional transformer language models for encoding claim-article pairs\nin an effort to construct state-of-the-art stance detection geared for\nidentifying disinformation. Taking advantage of bidirectional cross-attention\nbetween claim-article pairs via pair encoding with self-attention, we construct\na large-scale language model for stance detection by performing transfer\nlearning on a RoBERTa deep bidirectional transformer language model, and were\nable to achieve state-of-the-art performance (weighted accuracy of 90.01%) on\nthe Fake News Challenge Stage 1 (FNC-I) benchmark. These promising results\nserve as motivation for harnessing such large-scale language models as powerful\nbuilding blocks for creating effective AI solutions to combat disinformation.", "author": [{"name": "Chris Dulhanty"}, {"name": "Jason L. Deglint"}, {"name": "Ibrahim Ben Daya"}, {"name": "Alexander Wong"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the AI for Social Good Workshop at NeurIPS 2019"}, "link": [{"@href": "http://arxiv.org/abs/1911.11951v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.11951v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.06906v1", "updated": "2020-10-14T09:37:51Z", "published": "2020-10-14T09:37:51Z", "title": "No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet\n  Detection", "summary": "The sudden widespread menace created by the present global pandemic COVID-19\nhas had an unprecedented effect on our lives. Man-kind is going through\nhumongous fear and dependence on social media like never before. Fear\ninevitably leads to panic, speculations, and the spread of misinformation. Many\ngovernments have taken measures to curb the spread of such misinformation for\npublic well being. Besides global measures, to have effective outreach, systems\nfor demographically local languages have an important role to play in this\neffort. Towards this, we propose an approach to detect fake news about COVID-19\nearly on from social media, such as tweets, for multiple Indic-Languages\nbesides English. In addition, we also create an annotated dataset of Hindi and\nBengali tweet for fake news detection. We propose a BERT based model augmented\nwith additional relevant features extracted from Twitter to identify fake\ntweets. To expand our approach to multiple Indic languages, we resort to mBERT\nbased model which is fine-tuned over created dataset in Hindi and Bengali. We\nalso propose a zero-shot learning approach to alleviate the data scarcity issue\nfor such low resource languages. Through rigorous experiments, we show that our\napproach reaches around 89% F-Score in fake tweet detection which supercedes\nthe state-of-the-art (SOTA) results. Moreover, we establish the first benchmark\nfor two Indic-Languages, Hindi and Bengali. Using our annotated data, our model\nachieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our\nzero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali\nTweets without any annotated data, which clearly indicates the efficacy of our\napproach.", "author": [{"name": "Debanjana Kar"}, {"name": "Mohit Bhardwaj"}, {"name": "Suranjana Samanta"}, {"name": "Amar Prakash Azad"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages, 4 figures"}, "link": [{"@href": "http://arxiv.org/abs/2010.06906v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.06906v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.01222v2", "updated": "2021-08-23T04:21:58Z", "published": "2021-08-03T00:44:55Z", "title": "The Many Dimensions of Truthfulness: Crowdsourcing Misinformation\n  Assessments on a Multidimensional Scale", "summary": "Recent work has demonstrated the viability of using crowdsourcing as a tool\nfor evaluating the truthfulness of public statements. Under certain conditions\nsuch as: (1) having a balanced set of workers with different backgrounds and\ncognitive abilities; (2) using an adequate set of mechanisms to control the\nquality of the collected data; and (3) using a coarse grained assessment scale,\nthe crowd can provide reliable identification of fake news. However, fake news\nare a subtle matter: statements can be just biased (\"cherrypicked\"), imprecise,\nwrong, etc. and the unidimensional truth scale used in existing work cannot\naccount for such differences. In this paper we propose a multidimensional\nnotion of truthfulness and we ask the crowd workers to assess seven different\ndimensions of truthfulness selected based on existing literature: Correctness,\nNeutrality, Comprehensibility, Precision, Completeness, Speaker's\nTrustworthiness, and Informativeness. We deploy a set of quality control\nmechanisms to ensure that the thousands of assessments collected on 180\npublicly available fact-checked statements distributed over two datasets are of\nadequate quality, including a custom search engine used by the crowd workers to\nfind web pages supporting their truthfulness assessments. A comprehensive\nanalysis of crowdsourced judgments shows that: (1) the crowdsourced assessments\nare reliable when compared to an expert-provided gold standard; (2) the\nproposed dimensions of truthfulness capture independent pieces of information;\n(3) the crowdsourcing task can be easily learned by the workers; and (4) the\nresulting assessments provide a useful basis for a more complete estimation of\nstatement truthfulness.", "author": [{"name": "Michael Soprano"}, {"name": "Kevin Roitero"}, {"name": "David La Barbera"}, {"name": "Davide Ceolin"}, {"name": "Damiano Spina"}, {"name": "Stefano Mizzaro"}, {"name": "Gianluca Demartini"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.ipm.2021.102710"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.ipm.2021.102710", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2108.01222v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.01222v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "33 pages; Paper accepted at Information Processing & Management on\n  July 28, 2021; IP&M Special Issue on Dis/Misinformation Mining from Social\n  Media"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Information Processing & Management Information Processing &\n  Management, Volume 58, Issue 6, November 2021, 102710"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68P20", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.3", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/hep-ph/0511088v1", "updated": "2005-11-08T09:39:31Z", "published": "2005-11-08T09:39:31Z", "title": "Electroweak corrections and anomalous triple gauge-boson couplings in WW\n  and WZ production at the LHC", "summary": "We have analysed the production of WW and WZ vector-boson pairs at the LHC.\nThese processes give rise to four-fermion final states, and are particularly\nsensitive to possible non-standard trilinear gauge-boson couplings. We have\nstudied the interplay between the influence of these anomalous couplings and\nthe effect of the complete logarithmic electroweak O(\\alpha) corrections.\nRadiative corrections to the Standard Model processes in double-pole\napproximation and non-standard terms due to trilinear couplings are implemented\ninto a Monte Carlo program for p p -> 4f (+\\gamma) with final states involving\nfour or two charged leptons. We numerically investigate purely leptonic final\nstates and find that electroweak corrections can fake new-physics signals,\nmodifying the observables by the same amount and shape, in kinematical regions\nof statistical significance.", "author": [{"name": "E. Accomando"}, {"name": "A. Kaiser"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevD.73.093006"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevD.73.093006", "@rel": "related"}, {"@href": "http://arxiv.org/abs/hep-ph/0511088v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/hep-ph/0511088v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "19 pages, LaTex, 12 eps figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys.Rev.D73:093006,2006"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "hep-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "hep-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1111.4297v1", "updated": "2011-11-18T08:21:58Z", "published": "2011-11-18T08:21:58Z", "title": "Battling the Internet Water Army: Detection of Hidden Paid Posters", "summary": "We initiate a systematic study to help distinguish a special group of online\nusers, called hidden paid posters, or termed \"Internet water army\" in China,\nfrom the legitimate ones. On the Internet, the paid posters represent a new\ntype of online job opportunity. They get paid for posting comments and new\nthreads or articles on different online communities and websites for some\nhidden purposes, e.g., to influence the opinion of other people towards certain\nsocial events or business markets. Though an interesting strategy in business\nmarketing, paid posters may create a significant negative effect on the online\ncommunities, since the information from paid posters is usually not\ntrustworthy. When two competitive companies hire paid posters to post fake news\nor negative comments about each other, normal online users may feel overwhelmed\nand find it difficult to put any trust in the information they acquire from the\nInternet. In this paper, we thoroughly investigate the behavioral pattern of\nonline paid posters based on real-world trace data. We design and validate a\nnew detection mechanism, using both non-semantic analysis and semantic\nanalysis, to identify potential online paid posters. Our test results with\nreal-world datasets show a very promising performance.", "author": [{"name": "Cheng Chen"}, {"name": "Kui Wu"}, {"name": "Venkatesh Srinivasan"}, {"name": "Xudong Zhang"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 13 figures"}, "link": [{"@href": "http://arxiv.org/abs/1111.4297v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1111.4297v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1711.08615v1", "updated": "2017-11-23T08:36:17Z", "published": "2017-11-23T08:36:17Z", "title": "Controlling Elections through Social Influence", "summary": "Election control considers the problem of an adversary who attempts to tamper\nwith a voting process, in order to either ensure that their favored candidate\nwins (constructive control) or another candidate loses (destructive control).\nAs online social networks have become significant sources of information for\npotential voters, a new tool in an attacker's arsenal is to effect control by\nharnessing social influence, for example, by spreading fake news and other\nforms of misinformation through online social media.\n  We consider the computational problem of election control via social\ninfluence, studying the conditions under which finding good adversarial\nstrategies is computationally feasible. We consider two objectives for the\nadversary in both the constructive and destructive control settings:\nprobability and margin of victory (POV and MOV, respectively). We present\nseveral strong negative results, showing, for example, that the problem of\nmaximizing POV is inapproximable for any constant factor. On the other hand, we\npresent approximation algorithms which provide somewhat weaker approximation\nguarantees, such as bicriteria approximations for the POV objective and\nconstant-factor approximations for MOV. Finally, we present mixed integer\nprogramming formulations for these problems. Experimental results show that our\napproximation algorithms often find near-optimal control strategies, indicating\nthat election control through social influence is a salient threat to election\nintegrity.", "author": [{"name": "Bryan Wilder"}, {"name": "Yevgeniy Vorobeychik"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "19 pages, 2 figures"}, "link": [{"@href": "http://arxiv.org/abs/1711.08615v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.08615v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.10720v1", "updated": "2017-11-29T08:22:31Z", "published": "2017-11-29T08:22:31Z", "title": "Organized Behavior Classification of Tweet Sets using Supervised\n  Learning Methods", "summary": "During the 2016 US elections Twitter experienced unprecedented levels of\npropaganda and fake news through the collaboration of bots and hired persons,\nthe ramifications of which are still being debated. This work proposes an\napproach to identify the presence of organized behavior in tweets. The Random\nForest, Support Vector Machine, and Logistic Regression algorithms are each\nused to train a model with a data set of 850 records consisting of 299 features\nextracted from tweets gathered during the 2016 US presidential election. The\nfeatures represent user and temporal synchronization characteristics to capture\ncoordinated behavior. These models are trained to classify tweet sets among the\ncategories: organic vs organized, political vs non-political, and pro-Trump vs\npro-Hillary vs neither. The random forest algorithm performs better with\ngreater than 95% average accuracy and f-measure scores for each category. The\nmost valuable features for classification are identified as user based\nfeatures, with media use and marking tweets as favorite to be the most\ndominant.", "author": [{"name": "Erdem Be\u011fenilmi\u015f"}, {"name": "Suzan \u00dcsk\u00fcdarl\u0131"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "51 pages, 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/1711.10720v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.10720v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1810.11449v3", "updated": "2019-01-20T19:00:45Z", "published": "2018-10-26T17:59:56Z", "title": "The Politics of Attention", "summary": "We develop an equilibrium theory of attention and politics. In a spatial\nmodel of electoral competition where candidates have varying policy\npreferences, we examine what kinds of political behaviors capture voters'\nlimited attention and how this concern affects the overall political outcomes.\nFollowing the seminal works of Downs (1957) and Sims (1998), we assume that\nvoters are rationally inattentive and can process information about the\npolicies at a cost proportional to entropy reduction. The main finding is an\nequilibrium phenomenon called attention- and media-driven extremism, namely as\nwe increase the attention cost or garble the news technology, a truncated set\nof the equilibria captures voters' attention through enlarging the policy\ndifferentials between the varying types of the candidates. We supplement our\nanalysis with historical accounts, and discuss its relevance in the new era\nfeatured with greater media choices and distractions, as well as the rise of\npartisan media and fake news.", "author": [{"name": "Li Hu"}, {"name": "Anqi Li"}], "link": [{"@href": "http://arxiv.org/abs/1810.11449v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1810.11449v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.TH", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1807.10423v1", "updated": "2018-07-27T03:41:23Z", "published": "2018-07-27T03:41:23Z", "title": "Rebutting fake news on full spectral fitting", "summary": "A recent paper by Ge et al. performs a series of experiments with two full\nspectral fitting codes, pPXF and starlight, finding that the two yield\nconsistent results when the input spectrum is not heavily reddened. For E(B-V)\n> 0.2, however, they claim starlight leads to severe biases in the derived\nproperties. Counterintuitively, and at odds with previous simulations, they\nfind that this behaviour worsens significantly as the signal-to-noise ratio of\nthe input spectrum increases. This communication shows that this is entirely\ndue to an A_V < 1 mag condition imposed while initializing the Markov chains in\nthe code. This choice is normally irrelevant in real-life galaxy work but can\nbecome critical in artificial experiments. Alleviating this usually harmless\ninitialization constraint changes the Ge et al. results completely, as was\nexplained to the authors before their publication. We replicate their spectral\nfitting experiments, finding much smaller biases. Furthermore both bias and\nscatter in the derived properties all converge as S/N increases, as one would\nexpect. We also show how the very output of the code provides ways of\ndiagnosing anomalies in the fits. The code behaviour has been documented in\ncareful and extensive experiments in the literature, but the biased analysis of\nGe et al. is just not representative of starlight at all.", "author": {"name": "Roberto Cid Fernandes"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1093/mnras/sty2012"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1093/mnras/sty2012", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1807.10423v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1807.10423v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MNRAS, in press"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "astro-ph.GA", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "astro-ph.GA", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1811.01806v1", "updated": "2018-11-05T15:43:45Z", "published": "2018-11-05T15:43:45Z", "title": "Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of\n  User Engagement and Challenges", "summary": "Fake news and misinformation spread in developing countries as fast as they\ndo in developed countries with increasing penetration of the internet and\nsocial media. However, fighting misinformation is more difficult in developing\ncountries where resources and necessary technologies are scarce. This study\nprovides an understanding of the challenges various fact-checking initiatives\nface in three South Asian countries--Bangladesh, India, and Nepal. In-depth\ninterviews were conducted with senior editors of six fact-checking initiatives.\nChallenges identified include lack of resources, technologies, and political\npressure. An analysis of Facebook pages of these initiatives shows increasing\nuser engagement with their posts.", "author": [{"name": "Md Mahfuzul Haque"}, {"name": "Mohammad Yousuf"}, {"name": "Zahedur Arman"}, {"name": "Md Main Uddin Rony"}, {"name": "Ahmed Shatil Alam"}, {"name": "Kazi Mehedi Hasan"}, {"name": "Md Khadimul Islam"}, {"name": "Naeemul Hassan"}], "link": [{"@href": "http://arxiv.org/abs/1811.01806v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.01806v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1811.05900v2", "updated": "2020-10-28T15:05:51Z", "published": "2018-11-14T16:44:59Z", "title": "A Simulated Cyberattack on Twitter: Assessing Partisan Vulnerability to\n  Spear Phishing and Disinformation ahead of the 2018 U.S. Midterm Elections", "summary": "State-sponsored \"bad actors\" increasingly weaponize social media platforms to\nlaunch cyberattacks and disinformation campaigns during elections. Social media\ncompanies, due to their rapid growth and scale, struggle to prevent the\nweaponization of their platforms. This study conducts an automated spear\nphishing and disinformation campaign on Twitter ahead of the 2018 United States\nMidterm Elections. A fake news bot account - the @DCNewsReport - was created\nand programmed to automatically send customized tweets with a \"breaking news\"\nlink to 138 Twitter users, before being restricted by Twitter.\n  Overall, one in five users clicked the link, which could have potentially led\nto the downloading of ransomware or the theft of private information. However,\nthe link in this experiment was non-malicious and redirected users to a Google\nForms survey. In predicting users' likelihood to click the link on Twitter, no\nstatistically significant differences were observed between right-wing and\nleft-wing partisans, or between Web users and mobile users. The findings signal\nthat politically expressive Americans on Twitter, regardless of their party\npreferences or the devices they use to access the platform, are at risk of\nbeing spear phishing on social media.", "author": {"name": "Michael Bossetta"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.5210/fm.v23i12.9540"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.5210/fm.v23i12.9540", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1811.05900v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.05900v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "First Monday, 23(12) (2018)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1811.09729v3", "updated": "2019-09-11T18:29:06Z", "published": "2018-11-24T00:06:10Z", "title": "Generate, Segment and Refine: Towards Generic Manipulation Segmentation", "summary": "Detecting manipulated images has become a significant emerging challenge. The\nadvent of image sharing platforms and the easy availability of advanced photo\nediting software have resulted in a large quantities of manipulated images\nbeing shared on the internet. While the intent behind such manipulations varies\nwidely, concerns on the spread of fake news and misinformation is growing.\nCurrent state of the art methods for detecting these manipulated images suffers\nfrom the lack of training data due to the laborious labeling process. We\naddress this problem in this paper, for which we introduce a manipulated image\ngeneration process that creates true positives using currently available\ndatasets. Drawing from traditional work on image blending, we propose a novel\ngenerator for creating such examples. In addition, we also propose to further\ncreate examples that force the algorithm to focus on boundary artifacts during\ntraining. Strong experimental results validate our proposal.", "author": [{"name": "Peng Zhou"}, {"name": "Bor-Chun Chen"}, {"name": "Xintong Han"}, {"name": "Mahyar Najibi"}, {"name": "Abhinav Shrivastava"}, {"name": "Ser Nam Lim"}, {"name": "Larry S. Davis"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AAAI-2020"}, "link": [{"@href": "http://arxiv.org/abs/1811.09729v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.09729v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1910.08948v1", "updated": "2019-10-20T11:05:05Z", "published": "2019-10-20T11:05:05Z", "title": "Predicting the Leading Political Ideology of YouTube Channels Using\n  Acoustic, Textual, and Metadata Information", "summary": "We address the problem of predicting the leading political ideology, i.e.,\nleft-center-right bias, for YouTube channels of news media. Previous work on\nthe problem has focused exclusively on text and on analysis of the language\nused, topics discussed, sentiment, and the like. In contrast, here we study\nvideos, which yields an interesting multimodal setup. Starting with gold\nannotations about the leading political ideology of major world news media from\nMedia Bias/Fact Check, we searched on YouTube to find their corresponding\nchannels, and we downloaded a recent sample of videos from each channel. We\ncrawled more than 1,000 YouTube hours along with the corresponding subtitles\nand metadata, thus producing a new multimodal dataset. We further developed a\nmultimodal deep-learning architecture for the task. Our analysis shows that the\nuse of acoustic signal helped to improve bias detection by more than 6%\nabsolute over using text and metadata only. We release the dataset to the\nresearch community, hoping to help advance the field of multi-modal political\nbias detection.", "author": [{"name": "Yoan Dinkov"}, {"name": "Ahmed Ali"}, {"name": "Ivan Koychev"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "media bias, political ideology, Youtube channels, propaganda,\n  disinformation, fake news"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "INTERSPEECH-2019"}, "link": [{"@href": "http://arxiv.org/abs/1910.08948v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.08948v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SD", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.AS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.09982v1", "updated": "2019-10-20T10:53:18Z", "published": "2019-10-20T10:53:18Z", "title": "Findings of the NLP4IF-2019 Shared Task on Fine-Grained Propaganda\n  Detection", "summary": "We present the shared task on Fine-Grained Propaganda Detection, which was\norganized as part of the NLP4IF workshop at EMNLP-IJCNLP 2019. There were two\nsubtasks. FLC is a fragment-level task that asks for the identification of\npropagandist text fragments in a news article and also for the prediction of\nthe specific propaganda technique used in each such fragment (18-way\nclassification task). SLC is a sentence-level binary classification task asking\nto detect the sentences that contain propaganda. A total of 12 teams submitted\nsystems for the FLC task, 25 teams did so for the SLC task, and 14 teams\neventually submitted a system description paper. For both subtasks, most\nsystems managed to beat the baseline by a sizable margin. The leaderboard and\nthe data from the competition are available at\nhttp://propaganda.qcri.org/nlp4if-shared-task/.", "author": [{"name": "Giovanni Da San Martino"}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, disinformation, fake news. arXiv admin note: text overlap\n  with arXiv:1910.02517"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "NLP4IF@EMNLP-2019"}, "link": [{"@href": "http://arxiv.org/abs/1910.09982v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.09982v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.12073v1", "updated": "2019-10-26T14:29:37Z", "published": "2019-10-26T14:29:37Z", "title": "Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments", "summary": "Over the past couple of years, the topic of \"fake news\" and its influence\nover people's opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to \"go viral.\" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.", "author": {"name": "Jillian Tompkins"}, "link": [{"@href": "http://arxiv.org/abs/1910.12073v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.12073v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1710.08528v1", "updated": "2017-10-23T22:12:51Z", "published": "2017-10-23T22:12:51Z", "title": "A Two-Level Classification Approach for Detecting Clickbait Posts using\n  Text-Based Features", "summary": "The emergence of social media as news sources has led to the rise of\nclickbait posts attempting to attract users to click on article links without\ninforming them on the actual article content. This paper presents our efforts\nto create a clickbait detector inspired by fake news detection algorithms, and\nour submission to the Clickbait Challenge 2017. The detector is based almost\nexclusively on text-based features taken from previous work on clickbait\ndetection, our own work on fake post detection, and features we designed\nspecifically for the challenge. We use a two-level classification approach,\ncombining the outputs of 65 first-level classifiers in a second-level feature\nvector. We present our exploratory results with individual features and their\ncombinations, taken from the post text and the target article title, as well as\nfeature selection. While our own blind tests with the dataset led to an F-score\nof 0.63, our final evaluation in the Challenge only achieved an F-score of\n0.43. We explore the possible causes of this, and lay out potential future\nsteps to achieve more successful results.", "author": [{"name": "Olga Papadopoulou"}, {"name": "Markos Zampoglou"}, {"name": "Symeon Papadopoulos"}, {"name": "Ioannis Kompatsiaris"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Clickbait Challenge 2017"}, "link": [{"@href": "http://arxiv.org/abs/1710.08528v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1710.08528v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1803.01845v1", "updated": "2018-03-04T20:54:33Z", "published": "2018-03-04T20:54:33Z", "title": "Polarization, Partisanship and Junk News Consumption over Social Media\n  in the US", "summary": "What kinds of social media users read junk news? We examine the distribution\nof the most significant sources of junk news in the three months before\nPresident Donald Trump first State of the Union Address. Drawing on a list of\nsources that consistently publish political news and information that is\nextremist, sensationalist, conspiratorial, masked commentary, fake news and\nother forms of junk news, we find that the distribution of such content is\nunevenly spread across the ideological spectrum. We demonstrate that (1) on\nTwitter, a network of Trump supporters shares the widest range of known junk\nnews sources and circulates more junk news than all the other groups put\ntogether; (2) on Facebook, extreme hard right pages, distinct from Republican\npages, share the widest range of known junk news sources and circulate more\njunk news than all the other audiences put together; (3) on average, the\naudiences for junk news on Twitter share a wider range of known junk news\nsources than audiences on Facebook public pages.", "author": [{"name": "Vidya Narayanan"}, {"name": "Vlad Barash"}, {"name": "John Kelly"}, {"name": "Bence Kollanyi"}, {"name": "Lisa-Maria Neudert"}, {"name": "Philip N. Howard"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: text overlap with arXiv:1802.03572"}, "link": [{"@href": "http://arxiv.org/abs/1803.01845v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1803.01845v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1804.01576v1", "updated": "2018-03-13T22:32:16Z", "published": "2018-03-13T22:32:16Z", "title": "A Bayesian Model for False Information Belief Impact, Optimal Design,\n  and Fake News Containment", "summary": "This work is a technical approach to modeling false information nature,\ndesign, belief impact and containment in multi-agent networks. We present a\nBayesian mathematical model for source information and viewer's belief, and how\nthe former impacts the latter in a media (network) of broadcasters and viewers.\nGiven the proposed model, we study how a particular information (true or false)\ncan be optimally designed into a report, so that on average it conveys the most\namount of the original intended information to the viewers of the network.\nConsequently, the model allows us to study susceptibility of a particular group\nof viewers to false information, as a function of statistical metrics of the\ntheir prior beliefs (e.g. bias, hesitation, open-mindedness, credibility\nassessment etc.). In addition, based on the same model we can study false\ninformation \"containment\" strategies imposed by network administrators.\nSpecifically, we study a credibility assessment strategy, where every\ndisseminated report must be within a certain distance of the truth. We study\nthe trade-off between false and true information-belief convergence using this\nscheme which leads to ways for optimally deciding how truth sensitive an\ninformation dissemination network should operate.", "author": [{"name": "Amin Khajehnejad"}, {"name": "Shima Hajimirza"}], "link": [{"@href": "http://arxiv.org/abs/1804.01576v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.01576v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1805.01392v1", "updated": "2018-05-03T16:03:47Z", "published": "2018-05-03T16:03:47Z", "title": "Prevalence of web trackers on hospital websites in Illinois", "summary": "Web tracking technologies are pervasive and operated by a few large\ntechnology companies. This technology, and the use of the collected data has\nbeen implicated in influencing elections, fake news, discrimination, and even\nhealth decisions. Little is known about how this technology is deployed on\nhospital or other health related websites. The websites of the 210 public\nhospitals in the state of Illinois, USA were evaluated with a web tracker\nidentification tool. Web trackers were identified on 94% of hospital webs\nsites, with an average of 3.5 trackers on the websites of general hospitals.\nThe websites of smaller critical access hospitals used an average of 2 web\ntrackers. The most common web tracker identified was Google Analytics, found on\n74% of Illinois hospital websites. Of the web trackers discovered, 88% were\noperated by Google and 26% by Facebook. In light of revelations about how web\nbrowsing profiles have been used and misused, search bubbles, and the potential\nfor algorithmic discrimination hospital leadership and policy makers must\ncarefully consider if it is appropriate to use third party tracking technology\non hospital web sites.", "author": {"name": "Robert Robinson"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "7 pages, 1 table, 2 figures"}, "link": [{"@href": "http://arxiv.org/abs/1805.01392v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1805.01392v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1805.04096v3", "updated": "2018-09-05T18:16:41Z", "published": "2018-05-10T17:49:03Z", "title": "Fighting Fake News: Image Splice Detection via Learned Self-Consistency", "summary": "Advances in photo editing and manipulation tools have made it significantly\neasier to create fake imagery. Learning to detect such manipulations, however,\nremains a challenging problem due to the lack of sufficient amounts of\nmanipulated training data. In this paper, we propose a learning algorithm for\ndetecting visual image manipulations that is trained only using a large dataset\nof real photographs. The algorithm uses the automatically recorded photo EXIF\nmetadata as supervisory signal for training a model to determine whether an\nimage is self-consistent -- that is, whether its content could have been\nproduced by a single imaging pipeline. We apply this self-consistency model to\nthe task of detecting and localizing image splices. The proposed method obtains\nstate-of-the-art performance on several image forensics benchmarks, despite\nnever seeing any manipulated images at training. That said, it is merely a step\nin the long quest for a truly general purpose visual forensics tool.", "author": [{"name": "Minyoung Huh"}, {"name": "Andrew Liu"}, {"name": "Andrew Owens"}, {"name": "Alexei A. Efros"}], "link": [{"@href": "http://arxiv.org/abs/1805.04096v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1805.04096v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1806.09541v1", "updated": "2018-06-06T10:47:20Z", "published": "2018-06-06T10:47:20Z", "title": "Technology, Propaganda, and the Limits of Human Intellect", "summary": "\"Fake news\" is a recent phenomenon, but misinformation and propaganda are\nnot. Our new communication technologies make it easy for us to be exposed to\nhigh volumes of true, false, irrelevant, and unprovable information. Future AI\nis expected to amplify the problem even more. At the same time, our brains are\nreaching their limits in handling information. How should we respond to\npropaganda? Technology can help, but relying on it alone will not suffice in\nthe long term. We also need ethical policies, laws, regulations, and trusted\nauthorities, including fact-checkers. However, we will not solve the problem\nwithout the active engagement of the educated citizen. Epistemological\neducation, recognition of self biases and protection of our channels of\ncommunication and trusted networks are all needed to overcome the problem and\ncontinue our progress as democratic societies.", "author": {"name": "Panagiotis Metaxas"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages"}, "link": [{"@href": "http://arxiv.org/abs/1806.09541v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1806.09541v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.GL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1808.05359v1", "updated": "2018-08-16T06:55:25Z", "published": "2018-08-16T06:55:25Z", "title": "Neural Networks Assist Crowd Predictions in Discerning the Veracity of\n  Emotional Expressions", "summary": "Crowd predictions have demonstrated powerful performance in predicting future\nevents. We aim to understand crowd prediction efficacy in ascertaining the\nveracity of human emotional expressions. We discover that collective\ndiscernment can increase the accuracy of detecting emotion veracity from 63%,\nwhich is the average individual performance, to 80%. Constraining data to best\nperformers can further increase the result up to 92%. Neural networks can\nachieve an accuracy to 99.69% by aggregating participants' answers. That is,\nassigning positive and negative weights to high and low human predictors,\nrespectively. Furthermore, neural networks that are trained with one emotion\ndata can also produce high accuracies on discerning the veracity of other\nemotion types: our crowdsourced transfer of emotion learning is novel. We find\nthat our neural networks do not require a large number of participants,\nparticularly, 30 randomly selected, to achieve high accuracy predictions,\nbetter than any individual participant. Our proposed method of assembling\npeoples' predictions with neural networks can provide insights for applications\nsuch as fake news prevention and lie detection.", "author": [{"name": "Zhenyue Qin"}, {"name": "Tom Gedeon"}, {"name": "Sabrina Caldwell"}], "link": [{"@href": "http://arxiv.org/abs/1808.05359v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.05359v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1808.08426v1", "updated": "2018-08-25T13:40:36Z", "published": "2018-08-25T13:40:36Z", "title": "Analysis of adversarial attacks against CNN-based image forgery\n  detectors", "summary": "With the ubiquitous diffusion of social networks, images are becoming a\ndominant and powerful communication channel. Not surprisingly, they are also\nincreasingly subject to manipulations aimed at distorting information and\nspreading fake news. In recent years, the scientific community has devoted\nmajor efforts to contrast this menace, and many image forgery detectors have\nbeen proposed. Currently, due to the success of deep learning in many\nmultimedia processing tasks, there is high interest towards CNN-based\ndetectors, and early results are already very promising. Recent studies in\ncomputer vision, however, have shown CNNs to be highly vulnerable to\nadversarial attacks, small perturbations of the input data which drive the\nnetwork towards erroneous classification. In this paper we analyze the\nvulnerability of CNN-based image forensics methods to adversarial attacks,\nconsidering several detectors and several types of attack, and testing\nperformance on a wide range of common manipulations, both easily and hardly\ndetectable.", "author": [{"name": "Diego Gragnaniello"}, {"name": "Francesco Marra"}, {"name": "Giovanni Poggi"}, {"name": "Luisa Verdoliva"}], "link": [{"@href": "http://arxiv.org/abs/1808.08426v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.08426v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1808.09386v2", "updated": "2018-10-29T16:40:45Z", "published": "2018-08-28T16:20:20Z", "title": "Framing and Agenda-setting in Russian News: a Computational Analysis of\n  Intricate Political Strategies", "summary": "Amidst growing concern over media manipulation, NLP attention has focused on\novert strategies like censorship and \"fake news'\". Here, we draw on two\nconcepts from the political science literature to explore subtler strategies\nfor government media manipulation: agenda-setting (selecting what topics to\ncover) and framing (deciding how topics are covered). We analyze 13 years (100K\narticles) of the Russian newspaper Izvestia and identify a strategy of\ndistraction: articles mention the U.S. more frequently in the month directly\nfollowing an economic downturn in Russia. We introduce embedding-based methods\nfor cross-lingually projecting English frames to Russian, and discover that\nthese articles emphasize U.S. moral failings and threats to the U.S. Our work\noffers new ways to identify subtle media manipulation strategies at the\nintersection of agenda-setting and framing.", "author": [{"name": "Anjalie Field"}, {"name": "Doron Kliger"}, {"name": "Shuly Wintner"}, {"name": "Jennifer Pan"}, {"name": "Dan Jurafsky"}, {"name": "Yulia Tsvetkov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted as a full paper at EMNLP 2018"}, "link": [{"@href": "http://arxiv.org/abs/1808.09386v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1808.09386v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1809.06683v1", "updated": "2018-09-18T13:12:21Z", "published": "2018-09-18T13:12:21Z", "title": "RumourEval 2019: Determining Rumour Veracity and Support for Rumours", "summary": "This is the proposal for RumourEval-2019, which will run in early 2019 as\npart of that year's SemEval event. Since the first RumourEval shared task in\n2017, interest in automated claim validation has greatly increased, as the\ndangers of \"fake news\" have become a mainstream concern. Yet automated support\nfor rumour checking remains in its infancy. For this reason, it is important\nthat a shared task in this area continues to provide a focus for effort, which\nis likely to increase. We therefore propose a continuation in which the\nveracity of further rumours is determined, and as previously, supportive of\nthis goal, tweets discussing them are classified according to the stance they\ntake regarding the rumour. Scope is extended compared with the first\nRumourEval, in that the dataset is substantially expanded to include Reddit as\nwell as Twitter data, and additional languages are also included.", "author": [{"name": "Genevieve Gorrell"}, {"name": "Kalina Bontcheva"}, {"name": "Leon Derczynski"}, {"name": "Elena Kochkina"}, {"name": "Maria Liakata"}, {"name": "Arkaitz Zubiaga"}], "link": [{"@href": "http://arxiv.org/abs/1809.06683v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1809.06683v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1902.07207v1", "updated": "2019-02-10T07:45:27Z", "published": "2019-02-10T07:45:27Z", "title": "Identifying Fake News from Twitter Sharing Data: A Large-Scale Study", "summary": "Social networks offer a ready channel for fake and misleading news to spread\nand exert influence. This paper examines the performance of different\nreputation algorithms when applied to a large and statistically significant\nportion of the news that are spread via Twitter. Our main result is that simple\ncrowdsourcing-based algorithms are able to identify a large portion of fake or\nmisleading news, while incurring only very low false positive rates for\nmainstream websites. We believe that these algorithms can be used as the basis\nof practical, large-scale systems for indicating to consumers which news sites\ndeserve careful scrutiny and skepticism.", "author": [{"name": "Rakshit Agrawal"}, {"name": "Luca de Alfaro"}, {"name": "Gabriele Ballarin"}, {"name": "Stefano Moret"}, {"name": "Massimo Di Pierro"}, {"name": "Eugenio Tacchini"}, {"name": "Marco L. Della Vedova"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: substantial text overlap with arXiv:1802.08066"}, "link": [{"@href": "http://arxiv.org/abs/1902.07207v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.07207v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1903.00449v2", "updated": "2019-05-09T12:19:03Z", "published": "2019-03-01T18:20:24Z", "title": "TEEvil: Identity Lease via Trusted Execution Environments", "summary": "We investigate identity lease, a new type of service in which users lease\ntheir identities to third parties by providing them with full or restricted\naccess to their online accounts or credentials. We discuss how identity lease\ncould be abused to subvert the digital society, facilitating the spread of fake\nnews and subverting electronic voting by enabling the sale of votes. We show\nthat the emergence of Trusted Execution Environments and anonymous\ncryptocurrencies, for the first time, allows the implementation of such a lease\nservice while guaranteeing fairness, plausible deniability and anonymity,\ntherefore shielding the users and account renters from prosecution. To show\nthat such a service can be practically implemented, we build an example service\nthat we call TEEvil leveraging Intel SGX and ZCash. Finally, we discuss defense\nmechanisms and challenges in the mitigation of identity lease services.", "author": [{"name": "Ivan Puddu"}, {"name": "Daniele Lain"}, {"name": "Moritz Schneider"}, {"name": "Elizaveta Tretiakova"}, {"name": "Sinisa Matetic"}, {"name": "Srdjan Capkun"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "21 pages, 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/1903.00449v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.00449v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1903.11452v3", "updated": "2020-08-20T20:19:03Z", "published": "2019-03-27T14:28:17Z", "title": "Lexical convergence and collective identities on Facebook", "summary": "Recent studies, targeting Facebook, showed the tendency of users to interact\nwith information adhering to their preferred narrative and to ignore dissenting\ninformation. Primarily driven by confirmation bias, users tend to join\npolarized clusters where they cooperate to reinforce a like-minded system of\nbeliefs, thus facilitating fake news and misinformation cascades. To gain a\ndeeper understanding of these phenomena, in this work we analyze the lexicons\nused by the communities of users emerging on Facebook around verified and\nunverified contents. We show how the lexical approach provides important\ninsights about the kind of information processed by the two communities of\nusers and about their overall sentiment. Furthermore, by focusing on comment\nthreads, we observe a strong positive correlation between the lexical\nconvergence of co-commenters and their number of interactions, which in turns\nsuggests that such a trend could be a proxy for the emergence of collective\nidentities and polarization in opinion dynamics.", "author": [{"name": "Emanuele Brugnoli"}, {"name": "Matteo Cinelli"}, {"name": "Fabiana Zollo"}, {"name": "Walter Quattrociocchi"}, {"name": "Antonio Scala"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 9 figures"}, "link": [{"@href": "http://arxiv.org/abs/1903.11452v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.11452v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "91F20", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.00542v1", "updated": "2019-04-01T02:54:54Z", "published": "2019-04-01T02:54:54Z", "title": "Multi-Task Ordinal Regression for Jointly Predicting the Trustworthiness\n  and the Leading Political Ideology of News Media", "summary": "In the context of fake news, bias, and propaganda, we study two important but\nrelatively under-explored problems: (i) trustworthiness estimation (on a\n3-point scale) and (ii) political ideology detection (left/right bias on a\n7-point scale) of entire news outlets, as opposed to evaluating individual\narticles. In particular, we propose a multi-task ordinal regression framework\nthat models the two problems jointly. This is motivated by the observation that\nhyper-partisanship is often linked to low trustworthiness, e.g., appealing to\nemotions rather than sticking to the facts, while center media tend to be\ngenerally more impartial and trustworthy. We further use several auxiliary\ntasks, modeling centrality, hyperpartisanship, as well as left-vs.-right bias\non a coarse-grained scale. The evaluation results show sizable performance\ngains by the joint models over models that target the problems in isolation.", "author": [{"name": "Ramy Baly", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIT Computer Science and Artificial Intelligence Laboratory, MA, USA"}}, {"name": "Georgi Karadzhov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SiteGround Hosting EOOD, Bulgaria"}}, {"name": "Abdelrhman Saleh", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Harvard University, MA, USA"}}, {"name": "James Glass", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIT Computer Science and Artificial Intelligence Laboratory, MA, USA"}}, {"name": "Preslav Nakov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Qatar Computing Research Institute, HBKU, Qatar"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Fact-checking, political ideology, news media, NAACL-2019"}, "link": [{"@href": "http://arxiv.org/abs/1904.00542v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.00542v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.02934v5", "updated": "2021-03-03T03:57:00Z", "published": "2019-04-05T08:32:27Z", "title": "Second-order Inductive Inference: an axiomatic approach", "summary": "Consider a predictor who ranks eventualities on the basis of past cases: for\ninstance a search engine ranking webpages given past searches. Resampling past\ncases leads to different rankings and the extraction of deeper information. Yet\na rich database, with sufficiently diverse rankings, is often beyond reach.\nInexperience demands either \"on the fly\" learning-by-doing or prudence: the\narrival of a novel case does not force (i) a revision of current rankings, (ii)\ndogmatism towards new rankings, or (iii) intransitivity. For this higher-order\nframework of inductive inference, we derive a suitably unique numerical\nrepresentation of these rankings via a matrix on eventualities x cases and\ndescribe a robust test of prudence. Applications include: the success/failure\nof startups; the veracity of fake news; and novel conditions for the existence\nof a yield curve that is robustly arbitrage-free.", "author": {"name": "Patrick H. O'Callaghan"}, "link": [{"@href": "http://arxiv.org/abs/1904.02934v5", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.02934v5", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "econ.TH", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "econ.TH", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "econ.EM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.03513v1", "updated": "2019-04-06T19:04:29Z", "published": "2019-04-06T19:04:29Z", "title": "Team QCRI-MIT at SemEval-2019 Task 4: Propaganda Analysis Meets\n  Hyperpartisan News Detection", "summary": "In this paper, we describe our submission to SemEval-2019 Task 4 on\nHyperpartisan News Detection. Our system relies on a variety of engineered\nfeatures originally used to detect propaganda. This is based on the assumption\nthat biased messages are propagandistic in the sense that they promote a\nparticular political cause or viewpoint. We trained a logistic regression model\nwith features ranging from simple bag-of-words to vocabulary richness and text\nreadability features. Our system achieved 72.9% accuracy on the test data that\nis annotated manually and 60.8% on the test data that is annotated with distant\nsupervision. Additional experiments showed that significant performance\nimprovements can be achieved with better feature pre-processing.", "author": [{"name": "Abdelrhman Saleh", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Harvard University, MA, USA"}}, {"name": "Ramy Baly", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIT Computer Science and Artificial Intelligence Laboratory, MA, USA"}}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Qatar Computing Research Institute, HBKU, Qatar"}}, {"name": "Giovanni Da San Martino", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Qatar Computing Research Institute, HBKU, Qatar"}}, {"name": "Mitra Mohtarami", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIT Computer Science and Artificial Intelligence Laboratory, MA, USA"}}, {"name": "Preslav Nakov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Qatar Computing Research Institute, HBKU, Qatar"}}, {"name": "James Glass", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "MIT Computer Science and Artificial Intelligence Laboratory, MA, USA"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Hyperpartisanship, propaganda, news media, fake news, SemEval-2018"}, "link": [{"@href": "http://arxiv.org/abs/1904.03513v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.03513v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1904.12767v4", "updated": "2021-06-11T00:11:09Z", "published": "2019-04-29T15:25:01Z", "title": "Local non-Bayesian social learning with stubborn agents", "summary": "We study a social learning model in which agents iteratively update their\nbeliefs about the true state of the world using private signals and the beliefs\nof other agents in a non-Bayesian manner. Some agents are stubborn, meaning\nthey attempt to convince others of an erroneous true state (modeling fake\nnews). We show that while agents learn the true state on short timescales, they\n\"forget\" it and believe the erroneous state to be true on longer timescales.\nUsing these results, we devise strategies for seeding stubborn agents so as to\ndisrupt learning, which outperform intuitive heuristics and give novel insights\nregarding vulnerabilities in social learning.", "author": [{"name": "Daniel Vial"}, {"name": "Vijay Subramanian"}], "link": [{"@href": "http://arxiv.org/abs/1904.12767v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1904.12767v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.01553v1", "updated": "2019-05-04T20:19:08Z", "published": "2019-05-04T20:19:08Z", "title": "An End-to-End Framework to Identify Pathogenic Social Media Accounts on\n  Twitter", "summary": "Pathogenic Social Media (PSM) accounts such as terrorist supporter accounts\nand fake news writers have the capability of spreading disinformation to viral\nproportions. Early detection of PSM accounts is crucial as they are likely to\nbe key users to make malicious information \"viral\". In this paper, we adopt the\ncausal inference framework along with graph-based metrics in order to\ndistinguish PSMs from normal users within a short time of their activities. We\npropose both supervised and semi-supervised approaches without taking the\nnetwork information and content into account. Results on a real-world dataset\nfrom Twitter accentuates the advantage of our proposed frameworks. We show our\napproach achieves 0.28 improvement in F1 score over existing approaches with\nthe precision of 0.90 and F1 score of 0.63.", "author": [{"name": "Elham Shaabani"}, {"name": "Ashkan Sadeghi-Mobarakeh"}, {"name": "Hamidreza Alvari"}, {"name": "Paulo Shakarian"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 8 figures, International Conference on Data Intelligence and\n  Security. arXiv admin note: text overlap with arXiv:1905.01556"}, "link": [{"@href": "http://arxiv.org/abs/1905.01553v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.01553v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.01556v1", "updated": "2019-05-04T20:51:06Z", "published": "2019-05-04T20:51:06Z", "title": "Detecting Pathogenic Social Media Accounts without Content or Network\n  Structure", "summary": "The spread of harmful mis-information in social media is a pressing problem.\nWe refer accounts that have the capability of spreading such information to\nviral proportions as \"Pathogenic Social Media\" accounts. These accounts include\nterrorist supporters accounts, water armies, and fake news writers. We\nintroduce an unsupervised causality-based framework that also leverages label\npropagation. This approach identifies these users without using network\nstructure, cascade path information, content and user's information. We show\nour approach obtains higher precision (0.75) in identifying Pathogenic Social\nMedia accounts in comparison with random (precision of 0.11) and existing bot\ndetection (precision of 0.16) methods.", "author": [{"name": "Elham Shaabani"}, {"name": "Ruocheng Guo"}, {"name": "Paulo Shakarian"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 5 figures, International Conference on Data Intelligence and\n  Security. arXiv admin note: text overlap with arXiv:1905.01553"}, "link": [{"@href": "http://arxiv.org/abs/1905.01556v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.01556v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.03035v1", "updated": "2019-05-01T16:48:19Z", "published": "2019-05-01T16:48:19Z", "title": "Applications of Social Media in Hydroinformatics: A Survey", "summary": "Floods of research and practical applications employ social media data for a\nwide range of public applications, including environmental monitoring, water\nresource managing, disaster and emergency response.Hydroinformatics can benefit\nfrom the social media technologies with newly emerged data, techniques and\nanalytical tools to handle large datasets, from which creative ideas and new\nvalues could be mined.This paper first proposes a 4W (What, Why, When, hoW)\nmodel and a methodological structure to better understand and represent the\napplication of social media to hydroinformatics, then provides an overview of\nacademic research of applying social media to hydroinformatics such as water\nenvironment, water resources, flood, drought and water Scarcity management. At\nlast,some advanced topics and suggestions of water related social media\napplications from data collection, data quality management, fake news\ndetection, privacy issues, algorithms and platforms was present to\nhydroinformatics managers and researchers based on previous discussion.", "author": [{"name": "Yufeng Yu"}, {"name": "Yuelong Zhu"}, {"name": "Dingsheng Wan"}, {"name": "Qun Zhao"}, {"name": "Kai Shu"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "37pages"}, "link": [{"@href": "http://arxiv.org/abs/1905.03035v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.03035v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.08831v2", "updated": "2019-05-30T15:02:54Z", "published": "2019-05-21T19:03:46Z", "title": "IdeoTrace: A Framework for Ideology Tracing with a Case Study on the\n  2016 U.S. Presidential Election", "summary": "The 2016 United States presidential election has been characterized as a\nperiod of extreme divisiveness that was exacerbated on social media by the\ninfluence of fake news, trolls, and social bots. However, the extent to which\nthe public became more polarized in response to these influences over the\ncourse of the election is not well understood. In this paper we propose\nIdeoTrace, a framework for (i) jointly estimating the ideology of social media\nusers and news websites and (ii) tracing changes in user ideology over time. We\napply this framework to the last two months of the election period for a group\nof 47508 Twitter users and demonstrate that both liberal and conservative users\nbecame more polarized over time.", "author": [{"name": "Indu Manickam"}, {"name": "Andrew S. Lan"}, {"name": "Gautam Dasarathy"}, {"name": "Richard G. Baraniuk"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 4 figures, submitted to ASONAM 2019"}, "link": [{"@href": "http://arxiv.org/abs/1905.08831v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.08831v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.SP", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.11204v1", "updated": "2019-05-23T17:41:32Z", "published": "2019-05-23T17:41:32Z", "title": "A trust model for spreading gossip in social networks", "summary": "We introduce here a multi-type bootstrap percolation model, which we call\nT-Bootstrap Percolation (T-BP), and apply it to study information propagation\nin social networks. In this model, a social network is represented by a graph G\nwhose vertices have different labels corresponding to the type of role the\nperson plays in the network (e.g. a student, an educator, etc.). Once an\ninitial set of vertices of G is randomly selected to be carrying a gossip (e.g.\nto be infected), the gossip propagates to a new vertex provided it is\ntransmitted by a minimum threshold of vertices with different labels. By\nconsidering random graphs, which have been shown to closely represent social\nnetworks, we study different properties of the T-BP model through numerical\nsimulations, and describe its implications when applied to rumour spread, fake\nnews, and marketing strategies.", "author": [{"name": "Rinni Bhansali"}, {"name": "Laura P. Schaposnik"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 9 figures"}, "link": [{"@href": "http://arxiv.org/abs/1905.11204v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.11204v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.CO", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "nlin.CG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "60C05, 82B20, 60K35", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.01147v1", "updated": "2019-06-04T01:05:08Z", "published": "2019-06-04T01:05:08Z", "title": "Interacting contagions are indistinguishable from social reinforcement", "summary": "From fake news to innovative technologies, many contagions spread via a\nprocess of social reinforcement, where multiple exposures are distinct from\nprolonged exposure to a single source. Contrarily, biological agents such as\nEbola or measles are typically thought to spread as simple contagions. Here, we\ndemonstrate that interacting simple contagions are indistinguishable from\ncomplex contagions. In the social context, our results highlight the challenge\nof identifying and quantifying mechanisms, such as social reinforcement, in a\nworld where an innumerable amount of ideas, memes and behaviors interact. In\nthe biological context, this parallel allows the use of complex contagions to\neffectively quantify the non-trivial interactions of infectious diseases.", "author": [{"name": "Laurent H\u00e9bert-Dufresne"}, {"name": "Samuel V. Scarpino"}, {"name": "Jean-Gabriel Young"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1038/s41567-020-0791-2"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1038/s41567-020-0791-2", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1906.01147v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.01147v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Supplementary Material containing details of our simulation and\n  inference procedures is available as an ancillary file"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.DS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.08021v1", "updated": "2019-06-19T11:11:31Z", "published": "2019-06-19T11:11:31Z", "title": "Subtle Censorship via Adversarial Fakeness in Kyrgyzstan", "summary": "With the shift of public discourse to social media, we see simultaneously an\nexpansion of civic engagement as the bar to enter the conversation is lowered,\nand the reaction by both state and non-state adversaries of free speech to\nsilence these voices. Traditional forms of censorship struggle in this new\nsituation to enforce the preferred narrative of those in power. Consequently,\nthey have developed new methods for controlling the conversation that use the\nsocial media platform itself.\n  Using the Central Asian republic of Kyrgyzstan as a main case study, this\ntalk explores how this new form of \"subtle\" censorship relies on pretence and\nimitation, and why interdisciplinary methods of research are needed to grapple\nwith it. We examine how \"fakeness\" in the form of fake news and profiles is\nused as methods of subtle censorship.", "author": [{"name": "Christopher Schwartz"}, {"name": "Rebekah Overdorf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted HotPETs talk, 2019"}, "link": [{"@href": "http://arxiv.org/abs/1906.08021v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.08021v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1909.07523v1", "updated": "2019-09-16T23:53:59Z", "published": "2019-09-16T23:53:59Z", "title": "Discovering Differential Features: Adversarial Learning for Information\n  Credibility Evaluation", "summary": "A series of deep learning approaches extract a large number of credibility\nfeatures to detect fake news on the Internet. However, these extracted features\nstill suffer from many irrelevant and noisy features that restrict severely the\nperformance of the approaches. In this paper, we propose a novel model based on\nAdversarial Networks and inspirited by the Shared-Private model (ANSP), which\naims at reducing common, irrelevant features from the extracted features for\ninformation credibility evaluation. Specifically, ANSP involves two tasks: one\nis to prevent the binary classification of true and false information for\ncapturing common features relying on adversarial networks guided by\nreinforcement learning. Another extracts credibility features (henceforth,\nprivate features) from multiple types of credibility information and compares\nwith the common features through two strategies, i.e., orthogonality\nconstraints and KL-divergence for making the private features more\ndifferential. Experiments first on two six-label LIAR and Weibo datasets\ndemonstrate that ANSP achieves the state-of-the-art performance, boosting the\naccuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate\nthe robustness of the model with 1.8% performance improvements.", "author": [{"name": "Lianwei Wu"}, {"name": "Yuan Rao"}, {"name": "Ambreen Nazir"}, {"name": "Haolin Jin"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Information Sciences"}, "link": [{"@href": "http://arxiv.org/abs/1909.07523v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.07523v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.05496v2", "updated": "2021-08-20T09:14:43Z", "published": "2019-10-14T06:19:58Z", "title": "Temporal Graph Kernels for Classifying Dissemination Processes", "summary": "Many real-world graphs or networks are temporal, e.g., in a social network\npersons only interact at specific points in time. This information directs\ndissemination processes on the network, such as the spread of rumors, fake\nnews, or diseases. However, the current state-of-the-art methods for supervised\ngraph classification are designed mainly for static graphs and may not be able\nto capture temporal information. Hence, they are not powerful enough to\ndistinguish between graphs modeling different dissemination processes. To\naddress this, we introduce a framework to lift standard graph kernels to the\ntemporal domain. Specifically, we explore three different approaches and\ninvestigate the trade-offs between loss of temporal information and efficiency.\nMoreover, to handle large-scale graphs, we propose stochastic variants of our\nkernels with provable approximation guarantees. We evaluate our methods on a\nwide range of real-world social networks. Our methods beat static kernels by a\nlarge margin in terms of accuracy while still being scalable to large graphs\nand data sets. Hence, we confirm that taking temporal information into account\nis crucial for the successful classification of dissemination processes.", "author": [{"name": "Lutz Oettershagen"}, {"name": "Nils M. Kriege"}, {"name": "Christopher Morris"}, {"name": "Petra Mutzel"}], "link": [{"@href": "http://arxiv.org/abs/1911.05496v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.05496v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.05885v1", "updated": "2019-11-14T01:36:05Z", "published": "2019-11-14T01:36:05Z", "title": "Deception through Half-Truths", "summary": "Deception is a fundamental issue across a diverse array of settings, from\ncybersecurity, where decoys (e.g., honeypots) are an important tool, to\npolitics that can feature politically motivated \"leaks\" and fake news about\ncandidates.Typical considerations of deception view it as providing false\ninformation.However, just as important but less frequently studied is a more\ntacit form where information is strategically hidden or leaked.We consider the\nproblem of how much an adversary can affect a principal's decision by\n\"half-truths\", that is, by masking or hiding bits of information, when the\nprincipal is oblivious to the presence of the adversary. The principal's\nproblem can be modeled as one of predicting future states of variables in a\ndynamic Bayes network, and we show that, while theoretically the principal's\ndecisions can be made arbitrarily bad, the optimal attack is NP-hard to\napproximate, even under strong assumptions favoring the attacker. However, we\nalso describe an important special case where the dependency of future states\non past states is additive, in which we can efficiently compute an\napproximately optimal attack. Moreover, in networks with a linear transition\nfunction we can solve the problem optimally in polynomial time.", "author": [{"name": "Andrew Estornell"}, {"name": "Sanmay Das"}, {"name": "Yevgeniy Vorobeychik"}], "link": [{"@href": "http://arxiv.org/abs/1911.05885v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.05885v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MA", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.07199v1", "updated": "2019-11-17T09:40:24Z", "published": "2019-11-17T09:40:24Z", "title": "Rumor Detection on Social Media: Datasets, Methods and Opportunities", "summary": "Social media platforms have been used for information and news gathering, and\nthey are very valuable in many applications. However, they also lead to the\nspreading of rumors and fake news. Many efforts have been taken to detect and\ndebunk rumors on social media by analyzing their content and social context\nusing machine learning techniques. This paper gives an overview of the recent\nstudies in the rumor detection field. It provides a comprehensive list of\ndatasets used for rumor detection, and reviews the important studies based on\nwhat types of information they exploit and the approaches they take. And more\nimportantly, we also present several new directions for future research.", "author": [{"name": "Quanzhi Li"}, {"name": "Qiong Zhang"}, {"name": "Luo Si"}, {"name": "Yingchi Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "EMNLP 2019"}, "link": [{"@href": "http://arxiv.org/abs/1911.07199v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.07199v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1911.11067v1", "updated": "2019-11-11T08:30:54Z", "published": "2019-11-11T08:30:54Z", "title": "Analysing Russian Trolls via NLP tools", "summary": "The fifty-eighth American presidential election in 2016 still arouse fierce\ncontroversyat present. A portion of politicians as well as medium and voters\nbelieve that theRussian government interfered with the election of 2016 by\ncontrolling malicioussocial media accounts on twitter, such as trolls and bots\naccounts. Both of them willbroadcast fake news, derail the conversations about\nelection, and mislead people.Therefore, this paper will focus on analysing some\nof the twitter dataset about theelection of 2016 by using NLP methods and\nlooking for some interesting patterns ofwhether the Russian government\ninterfered with the election or not. We apply topicmodel on the given twitter\ndataset to extract some interesting topics and analysethe meaning, then we\nimplement supervised topic model to retrieve the relationshipbetween topics to\ncategory which is left troll or right troll, and analyse the\npattern.Additionally, we will do sentiment analysis to analyse the attitude of\nthe tweet. Afterextracting typical tweets from interesting topic, sentiment\nanalysis offers the ability toknow whether the tweet supports this topic or\nnot. Based on comprehensive analysisand evaluation, we find interesting\npatterns of the dataset as well as some meaningfultopics.", "author": {"name": "Bokun Kong"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "53 pages, 8 figures, 16 tables"}, "link": [{"@href": "http://arxiv.org/abs/1911.11067v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.11067v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1912.03211v1", "updated": "2019-12-06T16:25:29Z", "published": "2019-12-06T16:25:29Z", "title": "Transitivity and degree assortativity explained: The bipartite structure\n  of social networks", "summary": "Dynamical processes, such as the diffusion of knowledge, opinions, pathogens,\n\"fake news\", innovation, and others, are highly dependent on the structure of\nthe social network on which they occur. However, questions on why most social\nnetworks present some particular structural features, namely high levels of\ntransitivity and degree assortativity, when compared to other types of networks\nremain open. First, we argue that every one-mode network can be regarded as a\nprojection of a bipartite network, and show that this is the case using two\nsimple examples solved with the generating functions formalism. Second, using\nsynthetic and empirical data, we reveal how the combination of the degree\ndistribution of both sets of nodes of the bipartite network --- together with\nthe presence of cycles of length four and six --- explains the observed levels\nof transitivity and degree assortativity in the one-mode projected network.\nBipartite networks with top node degrees that display a more right-skewed\ndistribution than the bottom nodes result in highly transitive and degree\nassortative projections, especially if a large number of small cycles are\npresent in the bipartite structure.", "author": [{"name": "Demival Vasques Filho"}, {"name": "Dion R. J. O'Neale"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevE.101.052305"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevE.101.052305", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1912.03211v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.03211v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 6 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys. Rev. E 101, 052305 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1912.06810v1", "updated": "2019-12-14T08:58:01Z", "published": "2019-12-14T08:58:01Z", "title": "Proppy: A System to Unmask Propaganda in Online News", "summary": "We present proppy, the first publicly available real-world, real-time\npropaganda detection system for online news, which aims at raising awareness,\nthus potentially limiting the impact of propaganda and helping fight\ndisinformation. The system constantly monitors a number of news sources,\ndeduplicates and clusters the news into events, and organizes the articles\nabout an event on the basis of the likelihood that they contain propagandistic\ncontent. The system is trained on known propaganda sources using a variety of\nstylistic features. The evaluation results on a standard dataset show\nstate-of-the-art results for propaganda detection.", "author": [{"name": "Alberto Barr\u00f3n-Cede\u00f1o"}, {"name": "Giovanni Da San Martino"}, {"name": "Israa Jaradat"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, disinformation, fake news"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Thirty-Third AAAI Conference on Artificial Intelligence\n  (AAAI-2019)"}, "link": [{"@href": "http://arxiv.org/abs/1912.06810v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1912.06810v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.00179v3", "updated": "2020-06-18T18:17:43Z", "published": "2020-01-01T09:54:34Z", "title": "DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection", "summary": "The free access to large-scale public databases, together with the fast\nprogress of deep learning techniques, in particular Generative Adversarial\nNetworks, have led to the generation of very realistic fake content with its\ncorresponding implications towards society in this era of fake news. This\nsurvey provides a thorough review of techniques for manipulating face images\nincluding DeepFake methods, and methods to detect such manipulations. In\nparticular, four types of facial manipulation are reviewed: i) entire face\nsynthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv)\nexpression swap. For each manipulation group, we provide details regarding\nmanipulation techniques, existing public databases, and key benchmarks for\ntechnology evaluation of fake detection methods, including a summary of results\nfrom those evaluations. Among all the aspects discussed in the survey, we pay\nspecial attention to the latest generation of DeepFakes, highlighting its\nimprovements and challenges for fake detection.\n  In addition to the survey information, we also discuss open issues and future\ntrends that should be considered to advance in the field.", "author": [{"name": "Ruben Tolosana"}, {"name": "Ruben Vera-Rodriguez"}, {"name": "Julian Fierrez"}, {"name": "Aythami Morales"}, {"name": "Javier Ortega-Garcia"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Information Fusion, 2020"}, "link": [{"@href": "http://arxiv.org/abs/2001.00179v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.00179v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.01565v1", "updated": "2020-01-06T13:37:51Z", "published": "2020-01-06T13:37:51Z", "title": "Stance Detection Benchmark: How Robust Is Your Stance Detection?", "summary": "Stance Detection (StD) aims to detect an author's stance towards a certain\ntopic or claim and has become a key component in applications like fake news\ndetection, claim validation, and argument search. However, while stance is\neasily detected by humans, machine learning models are clearly falling short of\nthis task. Given the major differences in dataset sizes and framing of StD\n(e.g. number of classes and inputs), we introduce a StD benchmark that learns\nfrom ten StD datasets of various domains in a multi-dataset learning (MDL)\nsetting, as well as from related tasks via transfer learning. Within this\nbenchmark setup, we are able to present new state-of-the-art results on five of\nthe datasets. Yet, the models still perform well below human capabilities and\neven simple adversarial attacks severely hurt the performance of MDL models.\nDeeper investigation into this phenomenon suggests the existence of biases\ninherited from multiple datasets by design. Our analysis emphasizes the need of\nfocus on robustness and de-biasing strategies in multi-task learning\napproaches. The benchmark dataset and code is made available.", "author": [{"name": "Benjamin Schiller"}, {"name": "Johannes Daxenberger"}, {"name": "Iryna Gurevych"}], "link": [{"@href": "http://arxiv.org/abs/2001.01565v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.01565v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2003.00627v2", "updated": "2020-03-23T18:46:08Z", "published": "2020-03-02T01:55:05Z", "title": "Cluster-Based Social Reinforcement Learning", "summary": "Social Reinforcement Learning methods, which model agents in large networks,\nare useful for fake news mitigation, personalized teaching/healthcare, and\nviral marketing, but it is challenging to incorporate inter-agent dependencies\ninto the models effectively due to network size and sparse interaction data.\nPrevious social RL approaches either ignore agents dependencies or model them\nin a computationally intensive manner. In this work, we incorporate agent\ndependencies efficiently in a compact model by clustering users (based on their\npayoff and contribution to the goal) and combine this with a method to easily\nderive personalized agent-level policies from cluster-level policies. We also\npropose a dynamic clustering approach that captures changing user behavior.\nExperiments on real-world datasets illustrate that our proposed approach learns\nmore accurate policy estimates and converges more quickly, compared to several\nbaselines that do not use agent correlations or only use static clusters.", "author": [{"name": "Mahak Goindani"}, {"name": "Jennifer Neville"}], "link": [{"@href": "http://arxiv.org/abs/2003.00627v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.00627v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.00923v1", "updated": "2020-03-02T14:07:56Z", "published": "2020-03-02T14:07:56Z", "title": "Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business", "summary": "In the age of social media, disasters and epidemics usher not only a\ndevastation and affliction in the physical world, but also prompt a deluge of\ninformation, opinions, prognoses and advice to billions of internet users. The\ncoronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World\nHealth Organization warning of a possible \"infodemic\" of fake news. In this\nstudy, we examine the alternative narratives around the coronavirus outbreak\nthrough advertisements promoted on Facebook, the largest social media platform\nin the US. Using the new Facebook Ads Library, we discover advertisers from\npublic health and non-profit sectors, alongside those from news media,\npolitics, and business, incorporating coronavirus into their messaging and\nagenda. We find the virus used in political attacks, donation solicitations,\nbusiness promotion, stock market advice, and animal rights campaigning. Among\nthese, we find several instances of possible misinformation, ranging from\nbioweapons conspiracy theories to unverifiable claims by politicians. As we\nmake the dataset available to the community, we hope the advertising domain\nwill become an important part of quality control for public health\ncommunication and public discourse in general.", "author": [{"name": "Yelena Mejova"}, {"name": "Kyriaki Kalimeri"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Preprint. Under Review"}, "link": [{"@href": "http://arxiv.org/abs/2003.00923v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.00923v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.01797v1", "updated": "2020-03-03T21:13:12Z", "published": "2020-03-03T21:13:12Z", "title": "Discover Your Social Identity from What You Tweet: a Content Based\n  Approach", "summary": "An identity denotes the role an individual or a group plays in highly\ndifferentiated contemporary societies. In this paper, our goal is to classify\nTwitter users based on their role identities. We first collect a coarse-grained\npublic figure dataset automatically, then manually label a more fine-grained\nidentity dataset. We propose a hierarchical self-attention neural network for\nTwitter user role identity classification. Our experiments demonstrate that the\nproposed model significantly outperforms multiple baselines. We further propose\na transfer learning scheme that improves our model's performance by a large\nmargin. Such transfer learning also greatly reduces the need for a large amount\nof human labeled data.", "author": [{"name": "Binxuan Huang"}, {"name": "Kathleen M. Carley"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/978-3-030-42699-6"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/978-3-030-42699-6", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2003.01797v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.01797v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a preprint of a chapter published in Disinformation,\n  Misinformation, and Fake News in Social Media: Emerging Research Challenges\n  and Opportunities, edited by Kai, S., Suhang, W., Dongwon, L., Huan, L, 2020,\n  Springer reproduced with permission of Springer Nature Switzerland AG. The\n  final authenticated version is available online at:\n  http://dx.doi.org/10.1007/978-3-030-42699-6"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.07192v4", "updated": "2021-01-08T03:43:46Z", "published": "2020-03-12T18:37:19Z", "title": "Social Media and Misleading Information in a Democracy: A Mechanism\n  Design Approach", "summary": "In this paper, we present a resource allocation mechanism for the problem of\nincentivizing filtering among a finite number of strategic social media\nplatforms. We consider the presence of a strategic government and private\nknowledge of how misinformation affects the users of the social media\nplatforms. Our proposed mechanism incentivizes social media platforms to filter\nmisleading information efficiently, and thus indirectly prevents the spread of\nfake news. In particular, we design an economically inspired mechanism that\nstrongly implements all generalized Nash equilibria for efficient filtering of\nmisleading information in the induced game. We show that our mechanism is\nindividually rational, budget balanced, while it has at least one equilibrium.\nFinally, we show that for quasi-concave utilities and constraints, our\nmechanism admits a generalized Nash equilibrium and implements a Pareto\nefficient solution.", "author": [{"name": "Aditya Dave"}, {"name": "Ioannis Vasileios Chremos"}, {"name": "Andreas A. Malikopoulos"}], "link": [{"@href": "http://arxiv.org/abs/2003.07192v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.07192v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.SY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.00777v1", "updated": "2020-04-02T02:22:45Z", "published": "2020-04-02T02:22:45Z", "title": "Skepticism and rumor spreading: the role of spatial correlations", "summary": "Critical thinking and skepticism are fundamental mechanisms that one may use\nto prevent the spreading of rumors, fake-news and misinformation. We consider a\nsimple model in which agents without previous contact with the rumor, being\nskeptically oriented, may convince spreaders to stop their activity or, once\nexposed to the rumor, decide not to propagate it as a consequence, for example,\nof fact-checking. We extend a previous, mean-field analysis of the combined\neffect of these two mechanisms, active and passive skepticism, to include\nspatial correlations. This can be done either analytically, through the pair\napproximation, or simulating an agent-based version on diverse networks. Our\nresults show that while in mean-field there is no coexistence between spreaders\nand susceptibles (although, depending on the parameters, there may be\nbistability depending on the initial conditions), when spatial correlations are\nincluded, because of the protective effect of the isolation provided by removed\nagents, coexistence is possible.", "author": [{"name": "Marco Antonio Amaral"}, {"name": "W. G. Dantas"}, {"name": "Jeferson J. Arenzon"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevE.101.062418"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevE.101.062418", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.00777v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.00777v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 6 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys. Rev. E 101, 062418 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cond-mat.stat-mech", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.05286v3", "updated": "2020-07-09T17:17:54Z", "published": "2020-04-11T02:28:33Z", "title": "Recent advances in opinion propagation dynamics: A 2020 Survey", "summary": "Opinion dynamics have attracted the interest of researchers from different\nfields. Local interactions among individuals create interesting dynamics for\nthe system as a whole. Such dynamics are important from a variety of\nperspectives. Group decision making, successful marketing, and constructing\nnetworks (in which consensus can be reached or prevented) are a few examples of\nexisting or potential applications. The invention of the Internet has made the\nopinion fusion faster, unilateral, and on a whole different scale. Spread of\nfake news, propaganda, and election interferences have made it clear there is\nan essential need to know more about these dynamics.\n  The emergence of new ideas in the field has accelerated over the last few\nyears. In the first quarter of 2020, at least 50 research papers have emerged,\neither peer-reviewed and published or on pre-print outlets such as arXiv. In\nthis paper, we summarize these ground-breaking ideas and their fascinating\nextensions and introduce newly surfaced concepts.", "author": {"name": "Hossein Noorazar"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1140/epjp/s13360-020-00541-2"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1140/epjp/s13360-020-00541-2", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2004.05286v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.05286v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.07676v1", "updated": "2020-04-16T14:19:40Z", "published": "2020-04-16T14:19:40Z", "title": "Video Face Manipulation Detection Through Ensemble of CNNs", "summary": "In the last few years, several techniques for facial manipulation in videos\nhave been successfully developed and made available to the masses (i.e.,\nFaceSwap, deepfake, etc.). These methods enable anyone to easily edit faces in\nvideo sequences with incredibly realistic results and a very little effort.\nDespite the usefulness of these tools in many fields, if used maliciously, they\ncan have a significantly bad impact on society (e.g., fake news spreading,\ncyber bullying through fake revenge porn). The ability of objectively detecting\nwhether a face has been manipulated in a video sequence is then a task of\nutmost importance. In this paper, we tackle the problem of face manipulation\ndetection in video sequences targeting modern facial manipulation techniques.\nIn particular, we study the ensembling of different trained Convolutional\nNeural Network (CNN) models. In the proposed solution, different models are\nobtained starting from a base network (i.e., EfficientNetB4) making use of two\ndifferent concepts: (i) attention layers; (ii) siamese training. We show that\ncombining these networks leads to promising face manipulation detection results\non two publicly available datasets with more than 119000 videos.", "author": [{"name": "Nicol\u00f2 Bonettini"}, {"name": "Edoardo Daniele Cannas"}, {"name": "Sara Mandelli"}, {"name": "Luca Bondi"}, {"name": "Paolo Bestagini"}, {"name": "Stefano Tubaro"}], "link": [{"@href": "http://arxiv.org/abs/2004.07676v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.07676v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.IV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.07682v1", "updated": "2020-04-16T14:42:14Z", "published": "2020-04-16T14:42:14Z", "title": "On the use of Benford's law to detect GAN-generated images", "summary": "The advent of Generative Adversarial Network (GAN) architectures has given\nanyone the ability of generating incredibly realistic synthetic imagery. The\nmalicious diffusion of GAN-generated images may lead to serious social and\npolitical consequences (e.g., fake news spreading, opinion formation, etc.). It\nis therefore important to regulate the widespread distribution of synthetic\nimagery by developing solutions able to detect them. In this paper, we study\nthe possibility of using Benford's law to discriminate GAN-generated images\nfrom natural photographs. Benford's law describes the distribution of the most\nsignificant digit for quantized Discrete Cosine Transform (DCT) coefficients.\nExtending and generalizing this property, we show that it is possible to\nextract a compact feature vector from an image. This feature vector can be fed\nto an extremely simple classifier for GAN-generated image detection purpose.", "author": [{"name": "Nicol\u00f2 Bonettini"}, {"name": "Paolo Bestagini"}, {"name": "Simone Milani"}, {"name": "Stefano Tubaro"}], "link": [{"@href": "http://arxiv.org/abs/2004.07682v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.07682v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.IV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.02443v1", "updated": "2020-05-05T19:08:26Z", "published": "2020-05-05T19:08:26Z", "title": "A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian\n  and Indian Elections", "summary": "Recently, messaging applications, such as WhatsApp, have been reportedly\nabused by misinformation campaigns, especially in Brazil and India. A notable\nform of abuse in WhatsApp relies on several manipulated images and memes\ncontaining all kinds of fake stories. In this work, we performed an extensive\ndata collection from a large set of WhatsApp publicly accessible groups and\nfact-checking agency websites. This paper opens a novel dataset to the research\ncommunity containing fact-checked fake images shared through WhatsApp for two\ndistinct scenarios known for the spread of fake news on the platform: the 2018\nBrazilian elections and the 2019 Indian elections.", "author": [{"name": "Julio C. S. Reis"}, {"name": "Philipe de Freitas Melo"}, {"name": "Kiran Garimella"}, {"name": "Jussara M. Almeida"}, {"name": "Dean Eckles"}, {"name": "Fabr\u00edcio Benevenuto"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "7 pages. This is a preprint version of an accepted paper on ICWSM'20.\n  Please, consider to cite the conference version instead of this one"}, "link": [{"@href": "http://arxiv.org/abs/2005.02443v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.02443v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.05883v1", "updated": "2020-05-10T05:46:51Z", "published": "2020-05-10T05:46:51Z", "title": "Networks in a World Unknown: Public WhatsApp Groups in the Venezuelan\n  Refugee Crisis", "summary": "By early March 2020, five million Venezuelans had fled their home country\nafter its complete economic and institutional collapse, and over 1.6 million\nhave migrated to Colombia. Migrants struggle to start their lives over in\nColombia, having arrived with few economic resources, and often no legal\ndocumentation, in cities with little to offer them. Venezuelan migrants,\nhowever, rely heavily on mobile phones and social media networks as lifelines\nfor information, opportunities, and resources -- making WhatsApp both a\ncritical tool for migrants' settlement and integration, as well as an\ninvaluable source of data through which we can better understand migrant\nexperiences. This thesis explores the dynamics of public WhatsApp groups used\nby Venezuelan migrants to Colombia, and what they can tell us about how\nmigrants use and share information. We center our research on information\nspread and trust, especially as they intersect with concentration and\ngeographic heterogeneity within groups. We analyze messages and memberships\nbroadly, then explore interaction within groups, fake news and economic scams,\nand effects of the coronavirus pandemic. Our results have a range of policy\nimplications, from reflections on Colombia's decision to shut its borders\namidst the coronavirus pandemic, to understandings of how aid organizations can\neffectively share information over social media channels.", "author": {"name": "Adam Chang"}, "link": [{"@href": "http://arxiv.org/abs/2005.05883v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.05883v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.11177v1", "updated": "2020-05-22T13:30:42Z", "published": "2020-05-22T13:30:42Z", "title": "GeoCoV19: A Dataset of Hundreds of Millions of Multilingual COVID-19\n  Tweets with Location Information", "summary": "The past several years have witnessed a huge surge in the use of social media\nplatforms during mass convergence events such as health emergencies, natural or\nhuman-induced disasters. These non-traditional data sources are becoming vital\nfor disease forecasts and surveillance when preparing for epidemic and pandemic\noutbreaks. In this paper, we present GeoCoV19, a large-scale Twitter dataset\ncontaining more than 524 million multilingual tweets posted over a period of 90\ndays since February 1, 2020. Moreover, we employ a gazetteer-based approach to\ninfer the geolocation of tweets. We postulate that this large-scale,\nmultilingual, geolocated social media data can empower the research communities\nto evaluate how societies are collectively coping with this unprecedented\nglobal crisis as well as to develop computational methods to address challenges\nsuch as identifying fake news, understanding communities' knowledge gaps,\nbuilding disease forecast and surveillance models, among others.", "author": [{"name": "Umair Qazi"}, {"name": "Muhammad Imran"}, {"name": "Ferda Ofli"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 5 figures, accepted at ACM SIGSPATIAL Special May 2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.11177v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.11177v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.00885v3", "updated": "2020-11-03T20:37:11Z", "published": "2020-05-22T19:08:14Z", "title": "CoAID: COVID-19 Healthcare Misinformation Dataset", "summary": "As the COVID-19 virus quickly spreads around the world, unfortunately,\nmisinformation related to COVID-19 also gets created and spreads like wild\nfire. Such misinformation has caused confusion among people, disruptions in\nsociety, and even deadly consequences in health problems. To be able to\nunderstand, detect, and mitigate such COVID-19 misinformation, therefore, has\nnot only deep intellectual values but also huge societal impacts. To help\nresearchers combat COVID-19 health misinformation, therefore, we present CoAID\n(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare\nmisinformation, including fake news on websites and social platforms, along\nwith users' social engagement about such news. CoAID includes 4,251 news,\n296,000 related user engagements, 926 social platform posts about COVID-19, and\nground truth labels. The dataset is available at:\nhttps://github.com/cuilimeng/CoAID.", "author": [{"name": "Limeng Cui"}, {"name": "Dongwon Lee"}], "link": [{"@href": "http://arxiv.org/abs/2006.00885v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.00885v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.02774v1", "updated": "2020-06-30T21:07:34Z", "published": "2020-06-30T21:07:34Z", "title": "The role of time scale in the spreading of asymmetrically interacting\n  diseases", "summary": "Diseases and other contagion phenomena in nature and society can interact\nasymmetrically, such that one can benefit from the other, which in turn impairs\nthe first, in analogy with predator-prey systems. Here, we consider two models\nfor interacting disease-like dynamics with asymmetric interactions and\ndifferent associated time scales. Using rate equations for homogeneously mixed\npopulations, we show that the stationary prevalences and phase diagrams of each\nmodel behave differently with respect to variations of the relative time\nscales. We also characterize in detail the regime where transient oscillations\nare observed, a pattern that is inherent to asymmetrical interactions but often\nignored in the literature. Our results contribute to a better understanding of\ndisease dynamics in particular, and interacting processes in general, and could\nprovide interesting insights for real-world applications, most notably, the\ninterplay between the dynamics of fact-checked and fake news.", "author": [{"name": "Paulo Cesar Ventura"}, {"name": "Yamir Moreno"}, {"name": "Francisco A. Rodrigues"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevResearch.3.013146"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevResearch.3.013146", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.02774v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.02774v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages and 8 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys. Rev. Research 3, 013146 (2021)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-bio.PE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.04903v2", "updated": "2020-10-23T10:22:37Z", "published": "2020-07-09T16:05:11Z", "title": "Emergence of polarization in a voter model with personalized information", "summary": "The flourishing of fake news is favored by recommendation algorithms of\nonline social networks which, based on previous users activity, provide content\nadapted to their preferences and so create filter bubbles. We introduce an\nanalytically tractable voter model with personalized information, in which an\nexternal field tends to align the agent opinion with the one she held more\nfrequently in the past. Our model shows a surprisingly rich dynamics despite\nits simplicity. An analytical mean-field approach, confirmed by numerical\nsimulations, allows us to build a phase diagram and to predict if and how\nconsensus is reached. Remarkably, polarization can be avoided only for weak\ninteraction with the personalized information and if the number of agents is\nbelow a threshold. We analytically compute this critical size, which depends on\nthe interaction probability in a strongly non linear way.", "author": [{"name": "Giordano De Marzo"}, {"name": "Andrea Zaccaria"}, {"name": "Claudio Castellano"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1103/PhysRevResearch.2.043117"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1103/PhysRevResearch.2.043117", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.04903v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.04903v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages, 9 figures"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Phys. Rev. Research 2, 043117 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cond-mat.stat-mech", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.05070v2", "updated": "2021-02-24T17:35:12Z", "published": "2020-07-09T21:10:54Z", "title": "Forecasting Election Polls with Spin Systems", "summary": "We show that the problem of political forecasting, i.e, predicting the result\nof elections and referendums, can be mapped to finding the ground state\nconfiguration of a classical spin system. Depending on the required prediction,\nthis spin system can be a combination of $XY$, Ising and vector Potts models,\nalways with two-spin interactions, magnetic fields, and on arbitrary graphs. By\nreduction to the Ising model our result shows that political forecasting is\nformally an NP-Hard problem. Moreover, we show that the ground state search can\nbe recasted as Higher-order and Quadratic Unconstrained Binary Optimization\n(HUBO / QUBO) Problems, which are the standard input of classical and quantum\ncombinatorial optimization techniques. We prove the validity of our approach by\nperforming a numerical experiment based on data gathered from \\emph{Twitter}\nfor a network of 10 people, finding good agreement between results from a poll\nand those predicted by our model. In general terms, our method can also be\nunderstood as a trend detection algorithm, particularly useful in the contexts\nof sentiment analysis and identification of fake news.", "author": [{"name": "Ruben Ibarrondo"}, {"name": "Mikel Sanz"}, {"name": "Roman Orus"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "7 pages, 2 figures, 1 table, minor changes in v2"}, "link": [{"@href": "http://arxiv.org/abs/2007.05070v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.05070v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cond-mat.stat-mech", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "quant-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.08024v1", "updated": "2020-07-15T22:25:51Z", "published": "2020-07-15T22:25:51Z", "title": "A Survey on Computational Propaganda Detection", "summary": "Propaganda campaigns aim at influencing people's mindset with the purpose of\nadvancing a specific agenda. They exploit the anonymity of the Internet, the\nmicro-profiling ability of social networks, and the ease of automatically\ncreating and managing coordinated networks of accounts, to reach millions of\nsocial network users with persuasive messages, specifically targeted to topics\neach individual user is sensitive to, and ultimately influencing the outcome on\na targeted issue. In this survey, we review the state of the art on\ncomputational propaganda detection from the perspective of Natural Language\nProcessing and Network Analysis, arguing about the need for combined efforts\nbetween these communities. We further discuss current challenges and future\nresearch directions.", "author": [{"name": "Giovanni Da San Martino"}, {"name": "Stefano Cresci"}, {"name": "Alberto Barron-Cedeno"}, {"name": "Seunghak Yu"}, {"name": "Roberto Di Pietro"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda detection, disinformation, misinformation, fake news,\n  media bias"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IJCAI-2020"}, "link": [{"@href": "http://arxiv.org/abs/2007.08024v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.08024v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.09757v1", "updated": "2020-07-19T19:13:20Z", "published": "2020-07-19T19:13:20Z", "title": "Mono vs Multilingual Transformer-based Models: a Comparison across\n  Several Language Tasks", "summary": "BERT (Bidirectional Encoder Representations from Transformers) and ALBERT (A\nLite BERT) are methods for pre-training language models which can later be\nfine-tuned for a variety of Natural Language Understanding tasks. These methods\nhave been applied to a number of such tasks (mostly in English), achieving\nresults that outperform the state-of-the-art. In this paper, our contribution\nis twofold. First, we make available our trained BERT and Albert model for\nPortuguese. Second, we compare our monolingual and the standard multilingual\nmodels using experiments in semantic textual similarity, recognizing textual\nentailment, textual category classification, sentiment analysis, offensive\ncomment detection, and fake news detection, to assess the effectiveness of the\ngenerated language representations. The results suggest that both monolingual\nand multilingual models are able to achieve state-of-the-art and the advantage\nof training a single language model, if any, is small.", "author": [{"name": "Diego de Vargas Feijo"}, {"name": "Viviane Pereira Moreira"}], "link": [{"@href": "http://arxiv.org/abs/2007.09757v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.09757v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.02837v1", "updated": "2020-08-06T18:45:25Z", "published": "2020-08-06T18:45:25Z", "title": "aschern at SemEval-2020 Task 11: It Takes Three to Tango: RoBERTa, CRF,\n  and Transfer Learning", "summary": "We describe our system for SemEval-2020 Task 11 on Detection of Propaganda\nTechniques in News Articles. We developed ensemble models using RoBERTa-based\nneural architectures, additional CRF layers, transfer learning between the two\nsubtasks, and advanced post-processing to handle the multi-label nature of the\ntask, the consistency between nested spans, repetitions, and labels from\nsimilar spans in training. We achieved sizable improvements over baseline\nfine-tuned RoBERTa models, and the official evaluation ranked our system 3rd\n(almost tied with the 2nd) out of 36 teams on the span identification subtask\nwith an F1 score of 0.491, and 2nd (almost tied with the 1st) out of 31 teams\non the technique classification subtask with an F1 score of 0.62.", "author": [{"name": "Anton Chernyavskiy"}, {"name": "Dmitry Ilvovsky"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, persuasion, disinformation, fake news"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SemEval-2020"}, "link": [{"@href": "http://arxiv.org/abs/2008.02837v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.02837v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.10454v2", "updated": "2020-09-04T07:55:11Z", "published": "2020-08-24T13:55:14Z", "title": "FOCAL: A Forgery Localization Framework based on Video Coding\n  Self-Consistency", "summary": "Forgery operations on video contents are nowadays within the reach of anyone,\nthanks to the availability of powerful and user-friendly editing software.\nIntegrity verification and authentication of videos represent a major interest\nin both journalism (e.g., fake news debunking) and legal environments dealing\nwith digital evidence (e.g., a court of law). While several strategies and\ndifferent forensics traces have been proposed in recent years, latest solutions\naim at increasing the accuracy by combining multiple detectors and features.\nThis paper presents a video forgery localization framework that verifies the\nself-consistency of coding traces between and within video frames, by fusing\nthe information derived from a set of independent feature descriptors. The\nfeature extraction step is carried out by means of an explainable convolutional\nneural network architecture, specifically designed to look for and classify\ncoding artifacts. The overall framework was validated in two typical forgery\nscenarios: temporal and spatial splicing. Experimental results show an\nimprovement to the state-of-the-art on temporal splicing localization and also\npromising performance in the newly tackled case of spatial splicing, on both\nsynthetic and real-world videos.", "author": [{"name": "Sebastiano Verde"}, {"name": "Paolo Bestagini"}, {"name": "Simone Milani"}, {"name": "Giancarlo Calvagno"}, {"name": "Stefano Tubaro"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/OJSP.2021.3074298"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/OJSP.2021.3074298", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2008.10454v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.10454v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.IV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.13160v1", "updated": "2020-08-30T13:03:53Z", "published": "2020-08-30T13:03:53Z", "title": "QMUL-SDS at CheckThat! 2020: Determining COVID-19 Tweet Check-Worthiness\n  Using an Enhanced CT-BERT with Numeric Expressions", "summary": "This paper describes the participation of the QMUL-SDS team for Task 1 of the\nCLEF 2020 CheckThat! shared task. The purpose of this task is to determine the\ncheck-worthiness of tweets about COVID-19 to identify and prioritise tweets\nthat need fact-checking. The overarching aim is to further support ongoing\nefforts to protect the public from fake news and help people find reliable\ninformation. We describe and analyse the results of our submissions. We show\nthat a CNN using COVID-Twitter-BERT (CT-BERT) enhanced with numeric expressions\ncan effectively boost performance from baseline results. We also show results\nof training data augmentation with rumours on other topics. Our best system\nranked fourth in the task with encouraging outcomes showing potential for\nimproved results in the future.", "author": [{"name": "Rabab Alkhalifa"}, {"name": "Theodore Yoong"}, {"name": "Elena Kochkina"}, {"name": "Arkaitz Zubiaga"}, {"name": "Maria Liakata"}], "link": [{"@href": "http://arxiv.org/abs/2008.13160v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.13160v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2009.01047v2", "updated": "2020-10-22T04:57:21Z", "published": "2020-09-01T02:48:11Z", "title": "Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake\n  Claim Classification", "summary": "The rampant integration of social media in our every day lives and culture\nhas given rise to fast and easier access to the flow of information than ever\nin human history. However, the inherently unsupervised nature of social media\nplatforms has also made it easier to spread false information and fake news.\nFurthermore, the high volume and velocity of information flow in such platforms\nmake manual supervision and control of information propagation infeasible. This\npaper aims to address this issue by proposing a novel deep learning approach\nfor automated detection of false short-text claims on social media. We first\nintroduce Sentimental LIAR, which extends the LIAR dataset of short claims by\nadding features based on sentiment and emotion analysis of claims. Furthermore,\nwe propose a novel deep learning architecture based on the BERT-Base language\nmodel for classification of claims as genuine or fake. Our results demonstrate\nthat the proposed architecture trained on Sentimental LIAR can achieve an\naccuracy of 70%, which is an improvement of ~30% over previously reported\nresults for the LIAR benchmark.", "author": [{"name": "Bibek Upadhayay"}, {"name": "Vahid Behzadan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication in the proceedings of IEEE ISI '20"}, "link": [{"@href": "http://arxiv.org/abs/2009.01047v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2009.01047v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.02150v1", "updated": "2020-10-05T16:55:39Z", "published": "2020-10-05T16:55:39Z", "title": "Viable Threat on News Reading: Generating Biased News Using Natural\n  Language Models", "summary": "Recent advancements in natural language generation has raised serious\nconcerns. High-performance language models are widely used for language\ngeneration tasks because they are able to produce fluent and meaningful\nsentences. These models are already being used to create fake news. They can\nalso be exploited to generate biased news, which can then be used to attack\nnews aggregators to change their reader's behavior and influence their bias. In\nthis paper, we use a threat model to demonstrate that the publicly available\nlanguage models can reliably generate biased news content based on an input\noriginal news. We also show that a large number of high-quality biased news\narticles can be generated using controllable text generation. A subjective\nevaluation with 80 participants demonstrated that the generated biased news is\ngenerally fluent, and a bias evaluation with 24 participants demonstrated that\nthe bias (left or right) is usually evident in the generated articles and can\nbe easily identified.", "author": [{"name": "Saurabh Gupta"}, {"name": "Huy H. Nguyen"}, {"name": "Junichi Yamagishi"}, {"name": "Isao Echizen"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 4 figures, 6 tables, Accepted at NLP+CSS Workshop at EMNLP\n  2020"}, "link": [{"@href": "http://arxiv.org/abs/2010.02150v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.02150v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.05313v3", "updated": "2021-07-09T06:22:14Z", "published": "2020-10-11T18:44:50Z", "title": "Controlling Graph Dynamics with Reinforcement Learning and Graph Neural\n  Networks", "summary": "We consider the problem of controlling a partially-observed dynamic process\non a graph by a limited number of interventions. This problem naturally arises\nin contexts such as scheduling virus tests to curb an epidemic; targeted\nmarketing in order to promote a product; and manually inspecting posts to\ndetect fake news spreading on social networks.\n  We formulate this setup as a sequential decision problem over a temporal\ngraph process. In face of an exponential state space, combinatorial action\nspace and partial observability, we design a novel tractable scheme to control\ndynamical processes on temporal graphs. We successfully apply our approach to\ntwo popular problems that fall into our framework: prioritizing which nodes\nshould be tested in order to curb the spread of an epidemic, and influence\nmaximization on a graph.", "author": [{"name": "Eli A. Meirom"}, {"name": "Haggai Maron"}, {"name": "Shie Mannor"}, {"name": "Gal Chechik"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ICML 2021"}, "link": [{"@href": "http://arxiv.org/abs/2010.05313v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.05313v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.05686v1", "updated": "2020-10-12T13:25:48Z", "published": "2020-10-12T13:25:48Z", "title": "How the Far-Right Polarises Twitter: 'Highjacking' Hashtags in Times of\n  COVID-19", "summary": "Twitter influences political debates. Phenomena like fake news and hate\nspeech show that political discourse on micro-blogging can become strongly\npolarised by algorithmic enforcement of selective perception. Some political\nactors actively employ strategies to facilitate polarisation on Twitter, as\npast contributions show, via strategies of 'hashjacking'. For the example of\nCOVID-19 related hashtags and their retweet networks, we examine the case of\npartisan accounts of the German far-right party Alternative f\\\"ur Deutschland\n(AfD) and their potential use of 'hashjacking' in May 2020. Our findings\nindicate that polarisation of political party hashtags has not changed\nsignificantly in the last two years. We see that right-wing partisans are\nactively and effectively polarising the discourse by 'hashjacking' COVID-19\nrelated hashtags, like #CoronaVirusDE or #FlattenTheCurve. This polarisation\nstrategy is dominated by the activity of a limited set of heavy users. The\nresults underline the necessity to understand the dynamics of discourse\npolarisation, as an active political communication strategy of the far-right,\nby only a handful of very active accounts.", "author": [{"name": "Philipp Darius"}, {"name": "Fabian Stephany"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 3 figures"}, "link": [{"@href": "http://arxiv.org/abs/2010.05686v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.05686v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.08743v1", "updated": "2020-10-17T08:34:57Z", "published": "2020-10-17T08:34:57Z", "title": "Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed\n  health decision making in the presence of COVID19 misinformation", "summary": "Given the wide spread of inaccurate medical advice related to the 2019\ncoronavirus pandemic (COVID-19), such as fake remedies, treatments and\nprevention suggestions, misinformation detection has emerged as an open problem\nof high importance and interest for the NLP community. To combat potential harm\nof COVID19-related misinformation, we release Covid-HeRA, a dataset for health\nrisk assessment of COVID-19-related social media posts. More specifically, we\nstudy the severity of each misinformation story, i.e., how harmful a message\nbelieved by the audience can be and what type of signals can be used to\ndiscover high malicious fake news and detect refuted claims. We present a\ndetailed analysis, evaluate several simple and advanced classification models,\nand conclude with our experimental analysis that presents open challenges and\nfuture directions.", "author": [{"name": "Arkin Dharawat"}, {"name": "Ismini Lourentzou"}, {"name": "Alex Morales"}, {"name": "ChengXiang Zhai"}], "link": [{"@href": "http://arxiv.org/abs/2010.08743v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.08743v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.01314v1", "updated": "2020-11-02T20:59:26Z", "published": "2020-11-02T20:59:26Z", "title": "Automatic Detection of Machine Generated Text: A Critical Survey", "summary": "Text generative models (TGMs) excel in producing text that matches the style\nof human language reasonably well. Such TGMs can be misused by adversaries,\ne.g., by automatically generating fake news and fake product reviews that can\nlook authentic and fool humans. Detectors that can distinguish text generated\nby TGM from human written text play a vital role in mitigating such misuse of\nTGMs. Recently, there has been a flurry of works from both natural language\nprocessing (NLP) and machine learning (ML) communities to build accurate\ndetectors for English. Despite the importance of this problem, there is\ncurrently no work that surveys this fast-growing literature and introduces\nnewcomers to important research challenges. In this work, we fill this void by\nproviding a critical survey and review of this literature to facilitate a\ncomprehensive understanding of this problem. We conduct an in-depth error\nanalysis of the state-of-the-art detector and discuss research directions to\nguide future work in this exciting area.", "author": [{"name": "Ganesh Jawahar"}, {"name": "Muhammad Abdul-Mageed"}, {"name": "Laks V. S. Lakshmanan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The 28th International Conference on Computational Linguistics\n  (COLING), 2020"}, "link": [{"@href": "http://arxiv.org/abs/2011.01314v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.01314v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.11286v1", "updated": "2020-11-23T09:01:28Z", "published": "2020-11-23T09:01:28Z", "title": "MEG: Multi-Evidence GNN for Multimodal Semantic Forensics", "summary": "Fake news often involves semantic manipulations across modalities such as\nimage, text, location etc and requires the development of multimodal semantic\nforensics for its detection. Recent research has centered the problem around\nimages, calling it image repurposing -- where a digitally unmanipulated image\nis semantically misrepresented by means of its accompanying multimodal metadata\nsuch as captions, location, etc. The image and metadata together comprise a\nmultimedia package. The problem setup requires algorithms to perform multimodal\nsemantic forensics to authenticate a query multimedia package using a reference\ndataset of potentially related packages as evidences. Existing methods are\nlimited to using a single evidence (retrieved package), which ignores potential\nperformance improvement from the use of multiple evidences. In this work, we\nintroduce a novel graph neural network based model for multimodal semantic\nforensics, which effectively utilizes multiple retrieved packages as evidences\nand is scalable with the number of evidences. We compare the scalability and\nperformance of our model against existing methods. Experimental results show\nthat the proposed model outperforms existing state-of-the-art algorithms with\nan error reduction of up to 25%.", "author": [{"name": "Ekraam Sabir"}, {"name": "Ayush Jaiswal"}, {"name": "Wael AbdAlmageed"}, {"name": "Prem Natarajan"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "To be published at ICPR 2020"}, "link": [{"@href": "http://arxiv.org/abs/2011.11286v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.11286v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2011.14146v2", "updated": "2021-02-15T02:26:25Z", "published": "2020-11-28T15:30:14Z", "title": "Towards Combating Pandemic-related Misinformation in Social Media", "summary": "Conventional preventive measures during pandemic include social distancing\nand lockdown. Such measures in the time of social media brought about a new set\nof challenges - vulnerability to the toxic impact of online misinformation is\nhigh. A case in point is the prevailing COVID-19; as the virus propagates, so\ndoes the associated misinformation and fake news about it leading to infodemic.\nSince the outbreak, there has been a surge of studies investigating various\naspects of the pandemic. Of interest to this chapter include studies centring\non datasets from online social media platforms where the bulk of the public\ndiscourse happen. Consequently, the main goal is to support the fight against\nnegative infodemic by (1) contributing a diverse set of curated relevant\ndatasets (2) recommending relevant areas to study using the datasets (3)\ndiscussion on how relevant datasets, strategies and state-of-the-art IT tools\ncan be leveraged in managing the pandemic.", "author": {"name": "Isa Inuwa-Dutse"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages, 5 figures"}, "link": [{"@href": "http://arxiv.org/abs/2011.14146v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.14146v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.01663v3", "updated": "2021-07-22T05:16:22Z", "published": "2020-12-03T02:33:04Z", "title": "The Fake News Effect: Experimentally Identifying Motivated Reasoning\n  Using Trust in News", "summary": "Motivated reasoning posits that people distort how they process new\ninformation in the direction of beliefs they find more attractive. This paper\nintroduces a novel experimental paradigm that is able to portably identify\nmotivated reasoning from Bayesian updating across a variety of factual\nquestions; the paradigm analyzes how subjects assess the veracity of\ninformation sources that tell them the median of their belief distribution is\ntoo high or too low. A Bayesian would infer nothing about the source veracity\nfrom this message, but motivated reasoners would infer that the source were\nmore truthful if it reported the direction that they find more attractive. I\nfind novel evidence for politically-motivated reasoning about immigration,\nincome mobility, crime, racial discrimination, gender, climate change, gun\nlaws, and the performance of other subjects. Motivated reasoning from messages\non these topics leads people's beliefs to become more polarized, even though\nthe messages are uninformative.", "author": {"name": "Michael Thaler"}, "link": [{"@href": "http://arxiv.org/abs/2012.01663v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.01663v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "econ.GN", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "q-fin.EC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.04778v2", "updated": "2020-12-13T04:56:25Z", "published": "2020-12-08T22:54:35Z", "title": "Fact-Enhanced Synthetic News Generation", "summary": "The advanced text generation methods have witnessed great success in text\nsummarization, language translation, and synthetic news generation. However,\nthese techniques can be abused to generate disinformation and fake news. To\nbetter understand the potential threats of synthetic news, we develop a new\ngeneration method FactGen to generate high-quality news content. The existing\ntext generation methods either afford limited supplementary information or lose\nconsistency between the input and output which makes the synthetic news less\ntrustworthy. To address these issues, FactGen retrieves external facts to\nenrich the output and reconstructs the input claim from the generated content\nto improve the consistency among the input and the output. Experiment results\non real-world datasets show that the generated news contents of FactGen are\nconsistent and contain rich facts. We also discuss the possible defending\nmethod to identify these synthetic news pieces if FactGen is used to generate\nsynthetic news.", "author": [{"name": "Kai Shu"}, {"name": "Yichuan Li"}, {"name": "Kaize Ding"}, {"name": "Huan Liu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "AAAI 2021 Preprint Version"}, "link": [{"@href": "http://arxiv.org/abs/2012.04778v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.04778v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2101.11563v1", "updated": "2021-01-27T17:37:23Z", "published": "2021-01-27T17:37:23Z", "title": "Detecting Deepfake Videos Using Euler Video Magnification", "summary": "Recent advances in artificial intelligence make it progressively hard to\ndistinguish between genuine and counterfeit media, especially images and\nvideos. One recent development is the rise of deepfake videos, based on\nmanipulating videos using advanced machine learning techniques. This involves\nreplacing the face of an individual from a source video with the face of a\nsecond person, in the destination video. This idea is becoming progressively\nrefined as deepfakes are getting progressively seamless and simpler to compute.\nCombined with the outreach and speed of social media, deepfakes could easily\nfool individuals when depicting someone saying things that never happened and\nthus could persuade people in believing fictional scenarios, creating distress,\nand spreading fake news. In this paper, we examine a technique for possible\nidentification of deepfake videos. We use Euler video magnification which\napplies spatial decomposition and temporal filtering on video data to highlight\nand magnify hidden features like skin pulsation and subtle motions. Our\napproach uses features extracted from the Euler technique to train three models\nto classify counterfeit and unaltered videos and compare the results with\nexisting techniques.", "author": [{"name": "Rashmiranjan Das"}, {"name": "Gaurav Negi"}, {"name": "Alan F. Smeaton"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.2352/ISSN.2470-1173.2021.4.MWSF-272"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.2352/ISSN.2470-1173.2021.4.MWSF-272", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2101.11563v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.11563v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Presented at Electronic Imaging: Media Watermarking, Security, and\n  Forensics, 27 January 2021, 6 pages, 6 figures"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.00214v1", "updated": "2021-01-30T11:53:56Z", "published": "2021-01-30T11:53:56Z", "title": "Taxonomic survey of Hindi Language NLP systems", "summary": "Natural Language processing (NLP) represents the task of automatic handling\nof natural human language by machines.There is large spectrum of possible\napplications of NLP which help in automating tasks like translating text from\none language to other, retrieving and summarizing data from very huge\nrepositories, spam email filtering, identifying fake news in digital media,\nfind sentiment and feedback of people, find political opinions and views of\npeople on various government policies, provide effective medical assistance\nbased on past history records of patient etc. Hindi is the official language of\nIndia with nearly 691 million users in India and 366 million in rest of world.\nAt present, a number of government and private sector projects and researchers\nin India and abroad, are working towards developing NLP applications and\nresources for Indian languages. This survey gives a report of the resources and\napplications available for Hindi language NLP.", "author": [{"name": "Nikita P. Desai", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Dr."}}, {"name": "Prof.", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Dr."}}, {"name": "Vipul K. Dabhi"}], "link": [{"@href": "http://arxiv.org/abs/2102.00214v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.00214v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.00509v1", "updated": "2021-01-31T18:23:05Z", "published": "2021-01-31T18:23:05Z", "title": "TruthBot: An Automated Conversational Tool for Intent Learning, Curated\n  Information Presenting, and Fake News Alerting", "summary": "We present TruthBot, an all-in-one multilingual conversational chatbot\ndesigned for seeking truth (trustworthy and verified information) on specific\ntopics. It helps users to obtain information specific to certain topics,\nfact-check information, and get recent news. The chatbot learns the intent of a\nquery by training a deep neural network from the data of the previous intents\nand responds appropriately when it classifies the intent in one of the classes\nabove. Each class is implemented as a separate module that uses either its own\ncurated knowledge-base or searches the web to obtain the correct information.\nThe topic of the chatbot is currently set to COVID-19. However, the bot can be\neasily customized to any topic-specific responses. Our experimental results\nshow that each module performs significantly better than its closest\ncompetitor, which is verified both quantitatively and through several\nuser-based surveys in multiple languages. TruthBot has been deployed in June\n2020 and is currently running.", "author": [{"name": "Ankur Gupta"}, {"name": "Yash Varun"}, {"name": "Prarthana Das"}, {"name": "Nithya Muttineni"}, {"name": "Parth Srivastava"}, {"name": "Hamim Zafar"}, {"name": "Tanmoy Chakraborty"}, {"name": "Swaprava Nath"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "17 pages, 11 images"}, "link": [{"@href": "http://arxiv.org/abs/2102.00509v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.00509v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.03537v1", "updated": "2021-02-06T08:52:44Z", "published": "2021-02-06T08:52:44Z", "title": "Parameterized Complexity of Immunization in the Threshold Model", "summary": "We consider the problem of controlling the spread of harmful items in\nnetworks, such as the contagion proliferation of diseases or the diffusion of\nfake news. We assume the linear threshold model of diffusion where each node\nhas a threshold that measures the node resistance to the contagion. We study\nthe parameterized complexity of the problem: Given a network, a set of\ninitially contaminated nodes, and two integers $k$ and $\\ell$, is it possible\nto limit the diffusion to at most $k$ other nodes of the network by immunizing\nat most $\\ell$ nodes? We consider several parameters associated to the input,\nincluding: the bounds $k$ and $\\ell$, the maximum node degree $\\Delta$, the\ntreewidth, and the neighborhood diversity of the network. We first give $W[1]$\nor $W[2]$-hardness results for each of the considered parameters. Then we give\nfixed-parameter algorithms for some parameter combinations.", "author": [{"name": "Gennaro Cordasco"}, {"name": "Luisa Gargano"}, {"name": "Adele Anna Rescigno"}], "link": [{"@href": "http://arxiv.org/abs/2102.03537v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.03537v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.CO", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2102.04627v1", "updated": "2021-02-09T03:25:57Z", "published": "2021-02-09T03:25:57Z", "title": "SCARLET: Explainable Attention based Graph Neural Network for Fake News\n  spreader prediction", "summary": "False information and true information fact checking it, often co-exist in\nsocial networks, each competing to influence people in their spread paths. An\nefficient strategy here to contain false information is to proactively identify\nif nodes in the spread path are likely to endorse false information (i.e.\nfurther spread it) or refutation information (thereby help contain false\ninformation spreading). In this paper, we propose SCARLET (truSt and\nCredibility bAsed gRaph neuraL nEtwork model using aTtention) to predict likely\naction of nodes in the spread path. We aggregate trust and credibility features\nfrom a node's neighborhood using historical behavioral data and network\nstructure and explain how features of a spreader's neighborhood vary. Using\nreal world Twitter datasets, we show that the model is able to predict false\ninformation spreaders with an accuracy of over 87%.", "author": [{"name": "Bhavtosh Rath"}, {"name": "Xavier Morales"}, {"name": "Jaideep Srivastava"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the Pacific-Asia Conference on Knowledge Discovery and\n  Data Mining (PAKDD, 2021)"}, "link": [{"@href": "http://arxiv.org/abs/2102.04627v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.04627v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.06952v1", "updated": "2021-04-14T16:25:22Z", "published": "2021-04-14T16:25:22Z", "title": "The Surprising Performance of Simple Baselines for Misinformation\n  Detection", "summary": "As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.", "author": [{"name": "Kellin Pelrine"}, {"name": "Jacob Danovitch"}, {"name": "Reihaneh Rabbany"}], "link": [{"@href": "http://arxiv.org/abs/2104.06952v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.06952v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.08790v1", "updated": "2021-04-18T09:50:11Z", "published": "2021-04-18T09:50:11Z", "title": "Misinfo Belief Frames: A Case Study on Covid & Climate News", "summary": "Prior beliefs of readers impact the way in which they project meaning onto\nnews headlines. These beliefs can influence their perception of news\nreliability, as well as their reaction to news, and their likelihood of\nspreading the misinformation through social networks. However, most prior work\nfocuses on fact-checking veracity of news or stylometry rather than measuring\nimpact of misinformation. We propose Misinfo Belief Frames, a formalism for\nunderstanding how readers perceive the reliability of news and the impact of\nmisinformation. We also introduce the Misinfo Belief Frames (MBF) corpus, a\ndataset of 66k inferences over 23.5k headlines. Misinformation frames use\ncommonsense reasoning to uncover implications of real and fake news headlines\nfocused on global crises: the Covid-19 pandemic and climate change. Our results\nusing large-scale language modeling to predict misinformation frames show that\nmachine-generated inferences can influence readers' trust in news headlines\n(readers' trust in news headlines was affected in 29.3% of cases). This\ndemonstrates the potential effectiveness of using generated frames to counter\nmisinformation.", "author": [{"name": "Saadia Gabriel"}, {"name": "Skyler Hallinan"}, {"name": "Maarten Sap"}, {"name": "Pemi Nguyen"}, {"name": "Franziska Roesner"}, {"name": "Eunsol Choi"}, {"name": "Yejin Choi"}], "link": [{"@href": "http://arxiv.org/abs/2104.08790v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.08790v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.11639v2", "updated": "2021-05-01T18:22:39Z", "published": "2021-04-23T14:45:31Z", "title": "Claim Detection in Biomedical Twitter Posts", "summary": "Social media contains unfiltered and unique information, which is potentially\nof great value, but, in the case of misinformation, can also do great harm.\nWith regards to biomedical topics, false information can be particularly\ndangerous. Methods of automatic fact-checking and fake news detection address\nthis problem, but have not been applied to the biomedical domain in social\nmedia yet. We aim to fill this research gap and annotate a corpus of 1200\ntweets for implicit and explicit biomedical claims (the latter also with span\nannotations for the claim phrase). With this corpus, which we sample to be\nrelated to COVID-19, measles, cystic fibrosis, and depression, we develop\nbaseline models which detect tweets that contain a claim automatically. Our\nanalyses reveal that biomedical tweets are densely populated with claims (45 %\nin a corpus sampled to contain 1200 tweets focused on the domains mentioned\nabove). Baseline classification experiments with embedding-based classifiers\nand BERT-based transfer learning demonstrate that the detection is challenging,\nhowever, shows acceptable performance for the identification of explicit\nexpressions of claims. Implicit claim tweets are more challenging to detect.", "author": [{"name": "Amelie W\u00fchrl"}, {"name": "Roman Klinger"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at the BioNLP Workshop at NAACL 2021"}, "link": [{"@href": "http://arxiv.org/abs/2104.11639v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.11639v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2104.13352v2", "updated": "2021-06-13T12:27:10Z", "published": "2021-04-24T08:54:02Z", "title": "Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021", "summary": "On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.", "author": [{"name": "Ajay Agarwal"}, {"name": "Basant Agarwal"}], "link": [{"@href": "http://arxiv.org/abs/2104.13352v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.13352v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.00826v1", "updated": "2021-04-16T12:23:56Z", "published": "2021-04-16T12:23:56Z", "title": "WhatTheWikiFact: Fact-Checking Claims Against Wikipedia", "summary": "The rise of Internet has made it a major source of information.\nUnfortunately, not all information online is true, and thus a number of\nfact-checking initiatives have been launched, both manual and automatic. Here,\nwe present our contribution in this regard: WhatTheWikiFact, a system for\nautomatic claim verification using Wikipedia. The system predicts the veracity\nof an input claim, and it further shows the evidence it has retrieved as part\nof the verification process. It shows confidence scores and a list of relevant\nWikipedia articles, together with detailed information about each article,\nincluding the phrase used to retrieve it, the most relevant sentences it\ncontains, and their stances with respect to the input claim, with associated\nprobabilities.", "author": [{"name": "Anton Chernyavskiy"}, {"name": "Dmitry Ilvovsky"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "fact-checking, veracity, factuality, stance detection, evidence\n  retrieval, fake news, FEVER, Wikipedia"}, "link": [{"@href": "http://arxiv.org/abs/2105.00826v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.00826v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.09284v1", "updated": "2021-04-25T05:00:53Z", "published": "2021-04-25T05:00:53Z", "title": "SemEval-2021 Task 6: Detection of Persuasion Techniques in Texts and\n  Images", "summary": "We describe SemEval-2021 task 6 on Detection of Persuasion Techniques in\nTexts and Images: the data, the annotation guidelines, the evaluation setup,\nthe results, and the participating systems. The task focused on memes and had\nthree subtasks: (i) detecting the techniques in the text, (ii) detecting the\ntext spans where the techniques are used, and (iii) detecting techniques in the\nentire meme, i.e., both in the text and in the image. It was a popular task,\nattracting 71 registrations, and 22 teams that eventually made an official\nsubmission on the test set. The evaluation results for the third subtask\nconfirmed the importance of both modalities, the text and the image. Moreover,\nsome teams reported benefits when not just combining the two modalities, e.g.,\nby using early or late fusion, but rather modeling the interaction between them\nin a joint model.", "author": [{"name": "Dimitar Dimitrov"}, {"name": "Bishr Bin Ali"}, {"name": "Shaden Shaar"}, {"name": "Firoj Alam"}, {"name": "Fabrizio Silvestri"}, {"name": "Hamed Firooz"}, {"name": "Preslav Nakov"}, {"name": "Giovanni Da San Martino"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, disinformation, misinformation, fake news, memes,\n  multimodality"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "SemEval-2021"}, "link": [{"@href": "http://arxiv.org/abs/2105.09284v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.09284v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.09672v1", "updated": "2021-05-20T11:20:37Z", "published": "2021-05-20T11:20:37Z", "title": "Newsalyze: Enabling News Consumers to Understand Media Bias", "summary": "News is a central source of information for individuals to inform themselves\non current topics. Knowing a news article's slant and authenticity is of\ncrucial importance in times of \"fake news,\" news bots, and centralization of\nmedia ownership. We introduce Newsalyze, a bias-aware news reader focusing on a\nsubtle, yet powerful form of media bias, named bias by word choice and labeling\n(WCL). WCL bias can alter the assessment of entities reported in the news,\ne.g., \"freedom fighters\" vs. \"terrorists.\" At the core of the analysis is a\nneural model that uses a news-adapted BERT language model to determine\ntarget-dependent sentiment, a high-level effect of WCL bias. While the analysis\ncurrently focuses on only this form of bias, the visualizations already reveal\npatterns of bias when contrasting articles (overview) and in-text instances of\nbias (article view).", "author": [{"name": "Felix Hamborg"}, {"name": "Anastasia Zhukova"}, {"name": "Karsten Donnay"}, {"name": "Bela Gipp"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3383583.3398561"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3383583.3398561", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2105.09672v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.09672v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2105.10799v1", "updated": "2021-05-22T19:28:10Z", "published": "2021-05-22T19:28:10Z", "title": "Sockpuppet Detection: a Telegram case study", "summary": "In Online Social Networks (OSN) numerous are the cases in which users create\nmultiple accounts that publicly seem to belong to different people but are\nactually fake identities of the same person. These fictitious characters can be\nexploited to carry out abusive behaviors such as manipulating opinions,\nspreading fake news and disturbing other users. In literature this problem is\nknown as the Sockpuppet problem. In our work we focus on Telegram, a\nwide-spread instant messaging application, often known for its exploitation by\nmembers of organized crime and terrorism, and more in general for its high\npresence of people who have offensive behaviors.", "author": [{"name": "Gabriele Pisciotta"}, {"name": "Miriana Somenzi"}, {"name": "Elisa Barisani"}, {"name": "Giulio Rossetti"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.5281/zenodo.4744934"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.5281/zenodo.4744934", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2105.10799v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.10799v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "The 9th International Conference on Complex Networks and their\n  Applications - Book of Abstract (2021), pp. 414 (978-2-9557050-4-9)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "J.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.15165v1", "updated": "2021-05-31T17:13:47Z", "published": "2021-05-31T17:13:47Z", "title": "Multimodal Detection of Information Disorder from Social Media", "summary": "Social media is accompanied by an increasing proportion of content that\nprovides fake information or misleading content, known as information disorder.\nIn this paper, we study the problem of multimodal fake news detection on a\nlargescale multimodal dataset. We propose a multimodal network architecture\nthat enables different levels and types of information fusion. In addition to\nthe textual and visual content of a posting, we further leverage secondary\ninformation, i.e. user comments and metadata. We fuse information at multiple\nlevels to account for the specific intrinsic structure of the modalities. Our\nresults show that multimodal analysis is highly effective for the task and all\nmodalities contribute positively when fused properly.", "author": [{"name": "Armin Kirchknopf"}, {"name": "Djordje Slijepcevic"}, {"name": "Matthias Zeppelzauer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "4 pages, 2 figures, 2 tables, PrePrint CBMI 2021"}, "link": [{"@href": "http://arxiv.org/abs/2105.15165v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.15165v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.07823v1", "updated": "2021-06-15T00:53:55Z", "published": "2021-06-15T00:53:55Z", "title": "Challenges and Considerations with Code-Mixed NLP for Multilingual\n  Societies", "summary": "Multilingualism refers to the high degree of proficiency in two or more\nlanguages in the written and oral communication modes. It often results in\nlanguage mixing, a.k.a. code-mixing, when a multilingual speaker switches\nbetween multiple languages in a single utterance of a text or speech. This\npaper discusses the current state of the NLP research, limitations, and\nforeseeable pitfalls in addressing five real-world applications for social good\ncrisis management, healthcare, political campaigning, fake news, and hate\nspeech for multilingual societies. We also propose futuristic datasets, models,\nand tools that can significantly advance the current research in multilingual\nNLP applications for the societal good. As a representative example, we\nconsider English-Hindi code-mixing but draw similar inferences for other\nlanguage pairs", "author": [{"name": "Vivek Srivastava"}, {"name": "Mayank Singh"}], "link": [{"@href": "http://arxiv.org/abs/2106.07823v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.07823v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.08843v1", "updated": "2021-06-16T15:01:29Z", "published": "2021-06-16T15:01:29Z", "title": "Visualizing Evolving Trees", "summary": "Evolving trees arise in many real-life scenarios from computer file systems\nand dynamic call graphs, to fake news propagation and disease spread. Most\nlayout algorithms for static trees, however, do not work well in an evolving\nsetting (e.g., they are not designed to be stable between time steps). Dynamic\ngraph layout algorithms are better suited to this task, although they often\nintroduce unnecessary edge crossings. With this in mind we propose two methods\nfor visualizing evolving trees that guarantee no edge crossings, while\noptimizing (1) desired edge length realization, (2) layout compactness, and (3)\nstability. We evaluate the two new methods, along with four prior approaches\n(two static and two dynamic), on real-world datasets using quantitative\nmetrics: stress, desired edge length realization, layout compactness,\nstability, and running time. The new methods are fully functional and available\non github.", "author": [{"name": "Kathryn Gray"}, {"name": "Mingwei Li"}, {"name": "Reyan Ahmed"}, {"name": "Stephen Kobourov"}], "link": [{"@href": "http://arxiv.org/abs/2106.08843v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.08843v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CG", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.01651v2", "updated": "2021-07-06T07:29:01Z", "published": "2021-07-04T14:37:17Z", "title": "The hidden dependence of spreading vulnerability on topological\n  complexity", "summary": "Many dynamical phenomena, e.g., pathogen transmission, disruptions in\ntransport over networks, and (fake) news purveyance, concern spreading that\nplays out on top of networks with changing architectures over time - commonly\nknown as temporal networks. Assessing a system's proneness to facilitate\nspreading phenomena, which we refer to as its spreading vulnerability, from its\ntopological information alone remains a challenging task. We report a\nmethodological advance in terms of a novel metric for topological complexity:\n'entanglement entropy'. Using publicly available datasets, we demonstrate that\nthe metric naturally allows for topological comparisons across vastly different\nsystems, and importantly, reveals that the spreading vulnerability of a system\ncan be quantitatively related to its topological complexity. In doing so, the\nmetric opens itself for applications in a wide variety of natural, social,\nbiological and engineered systems.", "author": [{"name": "Mark M. Dekker"}, {"name": "Raoul D. Schram"}, {"name": "Jiamin Ou"}, {"name": "Debabrata Panja"}], "link": [{"@href": "http://arxiv.org/abs/2107.01651v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.01651v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.02012v1", "updated": "2021-07-01T11:07:47Z", "published": "2021-07-01T11:07:47Z", "title": "Tackling COVID-19 Infodemic using Deep Learning", "summary": "Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia.", "author": [{"name": "Prathmesh Pathwar"}, {"name": "Simran Gill"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "15 pages, 4 figures, Accepted in 4th International Conference on\n  Computational Intelligence and Data Engineering"}, "link": [{"@href": "http://arxiv.org/abs/2107.02012v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.02012v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.05016v1", "updated": "2021-07-11T10:42:58Z", "published": "2021-07-11T10:42:58Z", "title": "Combating fake news by empowering fact-checked news spread via\n  topology-based interventions", "summary": "Rapid information diffusion and large-scaled information cascades can enable\nthe undesired spread of false information. A small-scaled false information\noutbreak may potentially lead to an infodemic. We propose a novel information\ndiffusion and intervention technique to combat the spread of false news. As\nfalse information is often spreading faster in a social network, the proposed\ndiffusion methodology inhibits the spread of false news by proactively\ndiffusing the fact-checked information. Our methodology mainly relies on\ndefining the potential super-spreaders in a social network based on their\ncentrality metrics. We run an extensive set of experiments on different\nnetworks to investigate the impact of centrality metrics on the performance of\nthe proposed diffusion and intervention models. The obtained results\ndemonstrate that empowering the diffusion of fact-checked news combats the\nspread of false news further and deeper in social networks.", "author": [{"name": "Ke Wang"}, {"name": "Waheeb Yaqub"}, {"name": "Abdallah Lakhdari"}, {"name": "Basem Suleiman"}], "link": [{"@href": "http://arxiv.org/abs/2107.05016v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.05016v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.09183v1", "updated": "2021-07-19T22:47:17Z", "published": "2021-07-19T22:47:17Z", "title": "Analysis of External Content in the Vaccination Discussion on Twitter", "summary": "The spread of coronavirus and anti-vaccine conspiracies online hindered\npublic health responses to the pandemic. We examined the content of external\narticles shared on Twitter from February to June 2020 to understand how\nconspiracy theories and fake news competed with legitimate sources of\ninformation. Examining external content--articles, rather than social media\nposts--is a novel methodology that allows for non-social media specific\nanalysis of misinformation, tracking of changing narratives over time, and\ndetermining which types of resources (government, news, scientific, or dubious)\ndominate the pandemic vaccine conversation. We find that distinct narratives\nemerge, those narratives change over time, and lack of government and\nscientific messaging on coronavirus created an information vacuum filled by\nboth traditional news and conspiracy theories.", "author": [{"name": "Richard Kuzma"}, {"name": "Iain J. Cruickshank"}, {"name": "Kathleen M. Carley"}], "link": [{"@href": "http://arxiv.org/abs/2107.09183v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.09183v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.10935v1", "updated": "2021-07-22T21:32:54Z", "published": "2021-07-22T21:32:54Z", "title": "DeepTitle -- Leveraging BERT to generate Search Engine Optimized\n  Headlines", "summary": "Automated headline generation for online news articles is not a trivial task\n- machine generated titles need to be grammatically correct, informative,\ncapture attention and generate search traffic without being \"click baits\" or\n\"fake news\". In this paper we showcase how a pre-trained language model can be\nleveraged to create an abstractive news headline generator for German language.\nWe incorporate state of the art fine-tuning techniques for abstractive text\nsummarization, i.e. we use different optimizers for the encoder and decoder\nwhere the former is pre-trained and the latter is trained from scratch. We\nmodify the headline generation to incorporate frequently sought keywords\nrelevant for search engine optimization. We conduct experiments on a German\nnews data set and achieve a ROUGE-L-gram F-score of 40.02. Furthermore, we\naddress the limitations of ROUGE for measuring the quality of text\nsummarization by introducing a sentence similarity metric and human evaluation.", "author": [{"name": "Cristian Anastasiu"}, {"name": "Hanna Behnke"}, {"name": "Sarah L\u00fcck"}, {"name": "Viktor Malesevic"}, {"name": "Aamna Najmi"}, {"name": "Javier Poveda-Panter"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "9 pages, 4 figures"}, "link": [{"@href": "http://arxiv.org/abs/2107.10935v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.10935v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.12831v1", "updated": "2021-07-27T14:00:14Z", "published": "2021-07-27T14:00:14Z", "title": "Estudo Abordando o Contexto de Not\u00edcias Falsas em Pa\u00edses de L\u00edngua\n  Portuguesa (Fake News)", "summary": "This work consists of a study that addresses the context of false news in the\nreality of today's world. False news is a widely used expression currently.\nDuring the study, it was possible to identify problems generalized about this\ntheme, such as the wide spread that these have and the impact they have on\nsociety. From these problems it was possible to identify more specific ones,\nsuch as the origin of the news, the news source, a person who shares and/or\ncreates news and the interpersonal relationship existing. With the\nidentification of the aforementioned sub-problems, it was possible develop a\ntaxonomic model with the aim of implementing a tool that helps in detecting\nfalse news, identifying if a news is true, false or whether the user must be\ncareful (when it is not possible identify whether the news is true or false).\nAfter implementation, it was possible get a tool that allows you to calculate a\nprobability of a news being false, selected as selected options in each\nparameter. It was also possible to verify that a probability was correct and\nthat the tool is reviewed in the study carried out.", "author": [{"name": "Carolina Duarte"}, {"name": "Valderi Leithardt"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "in Portuguese"}, "link": [{"@href": "http://arxiv.org/abs/2107.12831v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.12831v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2108.12519v1", "updated": "2021-08-27T22:43:00Z", "published": "2021-08-27T22:43:00Z", "title": "Predicting the Factuality of Reporting of News Media Using Observations\n  About User Attention in Their YouTube Channels", "summary": "We propose a novel framework for predicting the factuality of reporting of\nnews media outlets by studying the user attention cycles in their YouTube\nchannels. In particular, we design a rich set of features derived from the\ntemporal evolution of the number of views, likes, dislikes, and comments for a\nvideo, which we then aggregate to the channel level. We develop and release a\ndataset for the task, containing observations of user attention on YouTube\nchannels for 489 news media. Our experiments demonstrate both complementarity\nand sizable improvements over state-of-the-art textual representations.", "author": [{"name": "Krasimira Bozhanova"}, {"name": "Yoan Dinkov"}, {"name": "Ivan Koychev"}, {"name": "Maria Castaldo"}, {"name": "Tommaso Venturini"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Factuality, disinformation, misinformation, fake news, Youtube\n  channels, propaganda, attention cycles"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RANLP-2021"}, "link": [{"@href": "http://arxiv.org/abs/2108.12519v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.12519v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2108.12802v1", "updated": "2021-08-29T09:57:01Z", "published": "2021-08-29T09:57:01Z", "title": "Interpretable Propaganda Detection in News Articles", "summary": "Online users today are exposed to misleading and propagandistic news articles\nand media posts on a daily basis. To counter thus, a number of approaches have\nbeen designed aiming to achieve a healthier and safer online news and media\nconsumption. Automatic systems are able to support humans in detecting such\ncontent; yet, a major impediment to their broad adoption is that besides being\naccurate, the decisions of such systems need also to be interpretable in order\nto be trusted and widely adopted by users. Since misleading and propagandistic\ncontent influences readers through the use of a number of deception techniques,\nwe propose to detect and to show the use of such techniques as a way to offer\ninterpretability. In particular, we define qualitatively descriptive features\nand we analyze their suitability for detecting deception techniques. We further\nshow that our interpretable features can be easily combined with pre-trained\nlanguage models, yielding state-of-the-art results.", "author": [{"name": "Seunghak Yu"}, {"name": "Giovanni Da San Martino"}, {"name": "Mitra Mohtarami"}, {"name": "James Glass"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "propaganda, propaganda techniques, disinformation, misinformation,\n  fake news, explainability, interpretability"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "RANLP-2021"}, "link": [{"@href": "http://arxiv.org/abs/2108.12802v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2108.12802v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2109.00835v1", "updated": "2021-09-02T10:45:07Z", "published": "2021-09-02T10:45:07Z", "title": "WikiCheck: An end-to-end open source Automatic Fact-Checking API based\n  on Wikipedia", "summary": "With the growth of fake news and disinformation, the NLP community has been\nworking to assist humans in fact-checking. However, most academic research has\nfocused on model accuracy without paying attention to resource efficiency,\nwhich is crucial in real-life scenarios. In this work, we review the\nState-of-the-Art datasets and solutions for Automatic Fact-checking and test\ntheir applicability in production environments. We discover overfitting issues\nin those models, and we propose a data filtering method that improves the\nmodel's performance and generalization. Then, we design an unsupervised\nfine-tuning of the Masked Language models to improve its accuracy working with\nWikipedia. We also propose a novel query enhancing method to improve evidence\ndiscovery using the Wikipedia Search API. Finally, we present a new\nfact-checking system, the \\textit{WikiCheck} API that automatically performs a\nfacts validation process based on the Wikipedia knowledge base. It is\ncomparable to SOTA solutions in terms of accuracy and can be used on low-memory\nCPU instances.", "author": [{"name": "Mykola Trokhymovych"}, {"name": "Diego Saez-Trumper"}], "link": [{"@href": "http://arxiv.org/abs/2109.00835v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2109.00835v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1006.4542v1", "updated": "2010-06-23T14:59:47Z", "published": "2010-06-23T14:59:47Z", "title": "Algorithm and Implementation of the Blog-Post Supervision Process", "summary": "A web log or blog in short is a trendy way to share personal entries with\nothers through website. A typical blog may consist of texts, images, audios and\nvideos etc. Most of the blogs work as personal online diaries, while others may\nfocus on specific interest such as photographs (photoblog), art (artblog),\ntravel (tourblog), IT (techblog) etc. Another type of blogging called\nmicroblogging is also very well known now-a-days which contains very short\nposts. Like the developed countries, the users of blogs are gradually\nincreasing in the developing countries e.g. Bangladesh. Due to the nature of\nopen access to all users, some people misuse it to spread fake news to achieve\nindividual or political goals. Some of them also post vulgar materials that\nmake an embarrass situation for other bloggers. Even, sometimes it indulges the\nreputation of the victim. The only way to overcome this problem is to bring all\nthe posts under supervision of the blog moderator. But it totally contradicts\nwith blogging concepts. In this paper, we have implemented an algorithm that\nwould help to prevent the offensive entries from being posted. These entries\nwould go through a supervision process to justify themselves as legal posts.\nFrom the analysis of the result, we have shown that this approach can eliminate\nthe chaotic situations in blogosphere at a great extent. Our experiment shows\nthat about 90% of offensive posts can be detected and stopped from being\npublished using this approach.", "author": [{"name": "Kamanashis Biswas"}, {"name": "Md. Liakat Ali"}, {"name": "S. A. M. Harun"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IEEE Publication Format,\n  https://sites.google.com/site/journalofcomputing/"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Journal of Computing, Vol. 2, No. 6, June 2010, NY, USA, ISSN\n  2151-9617"}, "link": [{"@href": "http://arxiv.org/abs/1006.4542v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1006.4542v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.OH", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.OH", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1702.05854v2", "updated": "2017-02-21T08:22:53Z", "published": "2017-02-20T04:28:46Z", "title": "Blocking Self-avoiding Walks Stops Cyber-epidemics: A Scalable GPU-based\n  Approach", "summary": "Cyber-epidemics, the widespread of fake news or propaganda through social\nmedia, can cause devastating economic and political consequences. A common\ncountermeasure against cyber-epidemics is to disable a small subset of\nsuspected social connections or accounts to effectively contain the epidemics.\nAn example is the recent shutdown of 125,000 ISIS-related Twitter accounts.\nDespite many proposed methods to identify such subset, none are scalable enough\nto provide high-quality solutions in nowadays billion-size networks.\n  To this end, we investigate the Spread Interdiction problems that seek most\neffective links (or nodes) for removal under the well-known Linear Threshold\nmodel. We propose novel CPU-GPU methods that scale to networks with billions of\nedges, yet, possess rigorous theoretical guarantee on the solution quality. At\nthe core of our methods is an $O(1)$-space out-of-core algorithm to generate a\nnew type of random walks, called Hitting Self-avoiding Walks (HSAWs). Such a\nlow memory requirement enables handling of big networks and, more importantly,\nhiding latency via scheduling of millions of threads on GPUs. Comprehensive\nexperiments on real-world networks show that our algorithms provides much\nhigher quality solutions and are several order of magnitude faster than the\nstate-of-the art. Comparing to the (single-core) CPU counterpart, our GPU\nimplementations achieve significant speedup factors up to 177x on a single GPU\nand 338x on a GPU pair.", "author": [{"name": "Hung T. Nguyen"}, {"name": "Alberto Cano"}, {"name": "Tam Vu"}, {"name": "Thang N. Dinh"}], "link": [{"@href": "http://arxiv.org/abs/1702.05854v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1702.05854v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1702.06016v2", "updated": "2017-06-16T10:14:10Z", "published": "2017-02-20T15:35:27Z", "title": "Public discourse and news consumption on online social media: A\n  quantitative, cross-platform analysis of the Italian Referendum", "summary": "The rising attention to the spreading of fake news and unsubstantiated rumors\non online social media and the pivotal role played by confirmation bias led\nresearchers to investigate different aspects of the phenomenon. Experimental\nevidence showed that confirmatory information gets accepted even if containing\ndeliberately false claims while dissenting information is mainly ignored or\nmight even increase group polarization. It seems reasonable that, to address\nmisinformation problem properly, we have to understand the main determinants\nbehind content consumption and the emergence of narratives on online social\nmedia. In this paper we address such a challenge by focusing on the discussion\naround the Italian Constitutional Referendum by conducting a quantitative,\ncross-platform analysis on both Facebook public pages and Twitter accounts. We\nobserve the spontaneous emergence of well-separated communities on both\nplatforms. Such a segregation is completely spontaneous, since no\ncategorization of contents was performed a priori. By exploring the dynamics\nbehind the discussion, we find that users tend to restrict their attention to a\nspecific set of Facebook pages/Twitter accounts. Finally, taking advantage of\nautomatic topic extraction and sentiment analysis techniques, we are able to\nidentify the most controversial topics inside and across both platforms. We\nmeasure the distance between how a certain topic is presented in the\nposts/tweets and the related emotional response of users. Our results provide\ninteresting insights for the understanding of the evolution of the core\nnarratives behind different echo chambers and for the early detection of\nmassive viral phenomena around false claims.", "author": [{"name": "Michela Del Vicario"}, {"name": "Sabrina Gaito"}, {"name": "Walter Quattrociocchi"}, {"name": "Matteo Zignani"}, {"name": "Fabiana Zollo"}], "link": [{"@href": "http://arxiv.org/abs/1702.06016v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1702.06016v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1711.10394v1", "updated": "2017-11-28T16:51:22Z", "published": "2017-11-28T16:51:22Z", "title": "Exposing Computer Generated Images by Using Deep Convolutional Neural\n  Networks", "summary": "The recent computer graphics developments have upraised the quality of the\ngenerated digital content, astonishing the most skeptical viewer. Games and\nmovies have taken advantage of this fact but, at the same time, these advances\nhave brought serious negative impacts like the ones yielded by fakeimages\nproduced with malicious intents. Digital artists can compose artificial images\ncapable of deceiving the great majority of people, turning this into a very\ndangerous weapon in a timespan currently know as Fake News/Post-Truth\" Era. In\nthis work, we propose a new approach for dealing with the problem of detecting\ncomputer generated images, through the application of deep convolutional\nnetworks and transfer learning techniques. We start from Residual Networks and\ndevelop different models adapted to the binary problem of identifying if an\nimage was or not computer generated. Differently from the current\nstate-of-the-art approaches, we don't rely on hand-crafted features, but\nprovide to the model the raw pixel information, achieving the same 0.97 of\nstate-of-the-art methods with two main advantages: our methods show more stable\nresults (depicted by lower variance) and eliminate the laborious and manual\nstep of specialized features extraction and selection.", "author": [{"name": "Edmar R. S. de Rezende"}, {"name": "Guilherme C. S. Ruppert"}, {"name": "Antonio Theophilo"}, {"name": "Tiago Carvalho"}], "link": [{"@href": "http://arxiv.org/abs/1711.10394v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1711.10394v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1604.08595v2", "updated": "2016-10-19T15:47:31Z", "published": "2016-04-28T20:00:05Z", "title": "How Unequal Fluxes of High Energy Astrophysical Neutrinos and\n  Antineutrinos can Fake New Physics", "summary": "Flavor ratios of very high energy astrophysical neutrinos, which can be\nstudied at the Earth by a neutrino telescope such as IceCube, can serve to\ndiagnose their production mechanism at the astrophysical source. The flavor\nratios for neutrinos and antineutrinos can be quite different as we do not know\nhow they are produced in the astrophysical environment. Due to this uncertainty\nthe neutrino and antineutrino flavor ratios at the Earth also could be quite\ndifferent. Nonetheless, it is generally assumed that flavor ratios for\nneutrinos and antineutrinos are the same at the Earth, in fitting the high\nenergy astrophysical neutrino data. This is a reasonable assumption for the\nlimited statistics for the data we currently have. However, in the future the\nfit must be performed allowing for a possible discrepancy in these two\nfractions in order to be able to disentangle different production mechanisms at\nthe source from new physics in the neutrino sector. To reinforce this issue, in\nthis work we show that a wrong assumption about the distribution of neutrino\nflavor ratios at the Earth may indeed lead to misleading interpretations of\nIceCube results.", "author": [{"name": "Hiroshi Nunokawa"}, {"name": "Boris Panes"}, {"name": "Renata Zukanovich Funchal"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1088/1475-7516/2016/10/036"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1088/1475-7516/2016/10/036", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1604.08595v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1604.08595v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "V2: 19 pages, 7 figures, improved discussion, to appear in JCAP"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "hep-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "hep-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "astro-ph.HE", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1802.07398v2", "updated": "2018-09-16T23:33:45Z", "published": "2018-02-21T01:52:01Z", "title": "Investigating Rumor News Using Agreement-Aware Search", "summary": "Recent years have witnessed a widespread increase of rumor news generated by\nhumans and machines. Therefore, tools for investigating rumor news have become\nan urgent necessity. One useful function of such tools is to see ways a\nspecific topic or event is represented by presenting different points of view\nfrom multiple sources.\n  In this paper, we propose Maester, a novel agreement-aware search framework\nfor investigating rumor news. Given an investigative question, Maester will\nretrieve related articles to that question, assign and display top articles\nfrom agree, disagree, and discuss categories to users. Splitting the results\ninto these three categories provides the user a holistic view towards the\ninvestigative question. We build Maester based on the following two key\nobservations: (1) relatedness can commonly be determined by keywords and\nentities occurring in both questions and articles, and (2) the level of\nagreement between the investigative question and the related news article can\noften be decided by a few key sentences. Accordingly, we use gradient boosting\ntree models with keyword/entity matching features for relatedness detection,\nand leverage recurrent neural network to infer the level of agreement. Our\nexperiments on the Fake News Challenge (FNC) dataset demonstrate up to an order\nof magnitude improvement of Maester over the original FNC winning solution, for\nagreement-aware search.", "author": [{"name": "Jingbo Shang"}, {"name": "Tianhang Sun"}, {"name": "Jiaming Shen"}, {"name": "Xingbang Liu"}, {"name": "Anja Gruenheid"}, {"name": "Flip Korn"}, {"name": "Adam Lelkes"}, {"name": "Cong Yu"}, {"name": "Jiawei Han"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3269206.3272020"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3269206.3272020", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1802.07398v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1802.07398v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1801.06122v1", "updated": "2018-01-18T16:54:01Z", "published": "2018-01-18T16:54:01Z", "title": "Anatomy of an online misinformation network", "summary": "Massive amounts of fake news and conspiratorial content have spread over\nsocial media before and after the 2016 US Presidential Elections despite\nintense fact-checking efforts. How do the spread of misinformation and\nfact-checking compete? What are the structural and dynamic characteristics of\nthe core of the misinformation diffusion network, and who are its main\npurveyors? How to reduce the overall amount of misinformation? To explore these\nquestions we built Hoaxy, an open platform that enables large-scale, systematic\nstudies of how misinformation and fact-checking spread and compete on Twitter.\nHoaxy filters public tweets that include links to unverified claims or\nfact-checking articles. We perform k-core decomposition on a diffusion network\nobtained from two million retweets produced by several hundred thousand\naccounts over the six months before the election. As we move from the periphery\nto the core of the network, fact-checking nearly disappears, while social bots\nproliferate. The number of users in the main core reaches equilibrium around\nthe time of the election, with limited churn and increasingly dense\nconnections. We conclude by quantifying how effectively the network can be\ndisrupted by penalizing the most central nodes. These findings provide a first\nlook at the anatomy of a massive online misinformation diffusion network.", "author": [{"name": "Chengcheng Shao"}, {"name": "Pik-Mai Hui"}, {"name": "Lei Wang"}, {"name": "Xinwen Jiang"}, {"name": "Alessandro Flammini"}, {"name": "Filippo Menczer"}, {"name": "Giovanni Luca Ciampaglia"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0196087"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0196087", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1801.06122v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1801.06122v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "28 pages, 11 figures, submitted to PLOS ONE"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PLoS ONE, 13(4): e0196087. 2018"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1801.06510v2", "updated": "2018-01-23T14:41:34Z", "published": "2018-01-19T17:54:22Z", "title": "Image Provenance Analysis at Scale", "summary": "Prior art has shown it is possible to estimate, through image processing and\ncomputer vision techniques, the types and parameters of transformations that\nhave been applied to the content of individual images to obtain new images.\nGiven a large corpus of images and a query image, an interesting further step\nis to retrieve the set of original images whose content is present in the query\nimage, as well as the detailed sequences of transformations that yield the\nquery image given the original images. This is a problem that recently has\nreceived the name of image provenance analysis. In these times of public media\nmanipulation ( e.g., fake news and meme sharing), obtaining the history of\nimage transformations is relevant for fact checking and authorship\nverification, among many other applications. This article presents an\nend-to-end processing pipeline for image provenance analysis, which works at\nreal-world scale. It employs a cutting-edge image filtering solution that is\ncustom-tailored for the problem at hand, as well as novel techniques for\nobtaining the provenance graph that expresses how the images, as nodes, are\nancestrally connected. A comprehensive set of experiments for each stage of the\npipeline is provided, comparing the proposed solution with state-of-the-art\nresults, employing previously published datasets. In addition, this work\nintroduces a new dataset of real-world provenance cases from the social media\nsite Reddit, along with baseline results.", "author": [{"name": "Daniel Moreira"}, {"name": "Aparna Bharati"}, {"name": "Joel Brogan"}, {"name": "Allan Pinto"}, {"name": "Michael Parowski"}, {"name": "Kevin W. Bowyer"}, {"name": "Patrick J. Flynn"}, {"name": "Anderson Rocha"}, {"name": "Walter J. Scheirer"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "13 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/1801.06510v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1801.06510v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1811.07901v4", "updated": "2019-01-08T21:15:07Z", "published": "2018-11-19T19:00:01Z", "title": "On Human Predictions with Explanations and Predictions of Machine\n  Learning Models: A Case Study on Deception Detection", "summary": "Humans are the final decision makers in critical tasks that involve ethical\nand legal concerns, ranging from recidivism prediction, to medical diagnosis,\nto fighting against fake news. Although machine learning models can sometimes\nachieve impressive performance in these tasks, these tasks are not amenable to\nfull automation. To realize the potential of machine learning for improving\nhuman decisions, it is important to understand how assistance from machine\nlearning models affects human performance and human agency.\n  In this paper, we use deception detection as a testbed and investigate how we\ncan harness explanations and predictions of machine learning models to improve\nhuman performance while retaining human agency. We propose a spectrum between\nfull human agency and full automation, and develop varying levels of machine\nassistance along the spectrum that gradually increase the influence of machine\npredictions. We find that without showing predicted labels, explanations alone\nslightly improve human performance in the end task. In comparison, human\nperformance is greatly improved by showing predicted labels (>20% relative\nimprovement) and can be further improved by explicitly suggesting strong\nmachine performance. Interestingly, when predicted labels are shown,\nexplanations of machine predictions induce a similar level of accuracy as an\nexplicit statement of strong machine performance. Our results demonstrate a\ntradeoff between human performance and human agency and show that explanations\nof machine predictions can moderate this tradeoff.", "author": [{"name": "Vivian Lai"}, {"name": "Chenhao Tan"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3287560.3287590"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3287560.3287590", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1811.07901v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1811.07901v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "17 pages, 19 figures, in Proceedings of ACM FAT* 2019, dataset & demo\n  available at https://deception.machineintheloop.com"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.ML", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.01722v2", "updated": "2020-04-10T19:25:59Z", "published": "2019-10-03T21:12:57Z", "title": "Constant State of Change: Engagement Inequality in Temporal Dynamic\n  Networks", "summary": "The temporal changes in complex systems of interactions have excited the\nresearch community in recent years as they encompass understandings on their\ndynamics and evolution. From the collective dynamics of organizations and\nonline communities to the spreading of information and fake news, to name a\nfew, temporal dynamics are fundamental in the understanding of complex systems.\nIn this work, we quantify the level of engagement in dynamic complex systems of\ninteractions, modeled as networks. We focus on interaction networks for which\nthe dynamics of the interactions are coupled with that of the topology, such as\nonline messaging, forums, and emails. We define two indices to capture the\ntemporal level of engagement: the Temporal Network (edge) Intensity index, and\nthe Temporal Dominance Inequality index. Our surprising results are that these\nmeasures are stationary for most measured networks, regardless of vast\nfluctuations in the size of the networks in time. Moreover, more than 80% of\nweekly changes in the indices values are bounded by less than 10%. The indices\nare stable between the temporal evolution of a network but are different\nbetween networks, and a classifier can determine the network the temporal\nindices belong to with high success. We find an exception in the Enron\nmanagement email exchange during the year before its disintegration, in which\nboth indices show high volatility throughout the inspected period.", "author": [{"name": "Hadar Miller"}, {"name": "Osnat Mokryn"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0231035"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0231035", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1910.01722v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.01722v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "arXiv admin note: substantial text overlap with arXiv:1809.09613"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "PLOS ONE 15(4): e0231035 (2020)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.data-an", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1910.07130v5", "updated": "2020-09-02T02:01:28Z", "published": "2019-10-16T02:05:26Z", "title": "SCG: Spotting Coordinated Groups in Social Media", "summary": "Recent events have led to a burgeoning awareness on the misuse of social\nmedia sites to affect political events, sway public opinion, and confuse the\nvoters. Such serious, hostile mass manipulation has motivated a large body of\nworks on bots/troll detection and fake news detection, which mostly focus on\nclassifying at the user level based on the content generated by the users. In\nthis study, we jointly analyze the connections among the users, as well as the\ncontent generated by them to Spot Coordinated Groups (SCG), sets of users that\nare likely to be organized towards impacting the general discourse. Given their\ntiny size (relative to the whole data), detecting these groups is\ncomputationally hard. Our proposed method detects these tiny-clusters\neffectively and efficiently. We deploy our SCG method to summarize and explain\nthe coordinated groups on Twitter around the 2019 Canadian Federal Elections,\nby analyzing over 60 thousand user accounts with 3.4 million followership\nconnections, and 1.3 million unique hashtags in the content of their tweets.\nThe users in the detected coordinated groups are over 4x more likely to get\nsuspended, whereas the hashtags which characterize their creed are linked to\nmisinformation campaigns.", "author": [{"name": "Junhao Wang"}, {"name": "Sacha Levy"}, {"name": "Ren Wang"}, {"name": "Aayushi Kulshrestha"}, {"name": "Reihaneh Rabbany"}], "link": [{"@href": "http://arxiv.org/abs/1910.07130v5", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1910.07130v5", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1704.07506v1", "updated": "2017-04-25T01:20:40Z", "published": "2017-04-25T01:20:40Z", "title": "Some Like it Hoax: Automated Fake News Detection in Social Networks", "summary": "In recent years, the reliability of information on the Internet has emerged\nas a crucial issue of modern society. Social network sites (SNSs) have\nrevolutionized the way in which information is spread by allowing users to\nfreely share content. As a consequence, SNSs are also increasingly used as\nvectors for the diffusion of misinformation and hoaxes. The amount of\ndisseminated information and the rapidity of its diffusion make it practically\nimpossible to assess reliability in a timely manner, highlighting the need for\nautomatic hoax detection systems.\n  As a contribution towards this objective, we show that Facebook posts can be\nclassified with high accuracy as hoaxes or non-hoaxes on the basis of the users\nwho \"liked\" them. We present two classification techniques, one based on\nlogistic regression, the other on a novel adaptation of boolean crowdsourcing\nalgorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users,\nwe obtain classification accuracies exceeding 99% even when the training set\ncontains less than 1% of the posts. We further show that our techniques are\nrobust: they work even when we restrict our attention to the users who like\nboth hoax and non-hoax posts. These results suggest that mapping the diffusion\npattern of information can be a useful component of automatic hoax detection\nsystems.", "author": [{"name": "Eugenio Tacchini"}, {"name": "Gabriele Ballarin"}, {"name": "Marco L. Della Vedova"}, {"name": "Stefano Moret"}, {"name": "Luca de Alfaro"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the Second Workshop on Data Science for Social Good\n  (SoGood), Skopje, Macedonia, 2017. CEUR Workshop Proceedings Volume 1960,\n  2017"}, "link": [{"@href": "http://arxiv.org/abs/1704.07506v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1704.07506v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1708.07157v1", "updated": "2017-08-23T19:18:11Z", "published": "2017-08-23T19:18:11Z", "title": "Evaluation Measures for Relevance and Credibility in Ranked Lists", "summary": "Recent discussions on alternative facts, fake news, and post truth politics\nhave motivated research on creating technologies that allow people not only to\naccess information, but also to assess the credibility of the information\npresented to them by information retrieval systems. Whereas technology is in\nplace for filtering information according to relevance and/or credibility, no\nsingle measure currently exists for evaluating the accuracy or precision (and\nmore generally effectiveness) of both the relevance and the credibility of\nretrieved results. One obvious way of doing so is to measure relevance and\ncredibility effectiveness separately, and then consolidate the two measures\ninto one. There at least two problems with such an approach: (I) it is not\ncertain that the same criteria are applied to the evaluation of both relevance\nand credibility (and applying different criteria introduces bias to the\nevaluation); (II) many more and richer measures exist for assessing relevance\neffectiveness than for assessing credibility effectiveness (hence risking\nfurther bias).\n  Motivated by the above, we present two novel types of evaluation measures\nthat are designed to measure the effectiveness of both relevance and\ncredibility in ranked lists of retrieval results. Experimental evaluation on a\nsmall human-annotated dataset (that we make freely available to the research\ncommunity) shows that our measures are expressive and intuitive in their\ninterpretation.", "author": [{"name": "Christina Lioma"}, {"name": "Jakob Grue Simonsen"}, {"name": "Birger Larsen"}], "link": [{"@href": "http://arxiv.org/abs/1708.07157v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1708.07157v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1803.03428v1", "updated": "2018-03-09T09:19:16Z", "published": "2018-03-09T09:19:16Z", "title": "A Bias Aware News Recommendation System", "summary": "In this era of fake news and political polarization, it is desirable to have\na system to enable users to access balanced news content. Current solutions\nfocus on top down, server based approaches to decide whether a news article is\nfake or biased, and display only trusted news to the end users. In this paper,\nwe follow a different approach to help the users make informed choices about\nwhich news they want to read, making users aware in real time of the bias in\nnews articles they were browsing and recommending news articles from other\nsources on the same topic with different levels of bias. We use a recent Pew\nresearch report to collect news sources that readers with varying political\ninclinations prefer to read. We then scrape news articles on a variety of\ntopics from these varied news sources. After this, we perform clustering to\nfind similar topics of the articles, as well as calculate a bias score for each\narticle. For a news article the user is currently reading, we display the bias\nscore and also display other articles on the same topic, out of the previously\ncollected articles, from different news sources. This we present to the user.\nThis approach, we hope, would make it possible for users to access more\nbalanced articles on given news topics. We present the implementation details\nof the system along with some preliminary results on news articles.", "author": [{"name": "Anish Anil Patankar"}, {"name": "Joy Bose"}, {"name": "Harshit Khanna"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "11 pages, 7 figures"}, "link": [{"@href": "http://arxiv.org/abs/1803.03428v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1803.03428v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.5.2", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1804.00482v1", "updated": "2018-04-02T13:31:11Z", "published": "2018-04-02T13:31:11Z", "title": "Real Time Sentiment Change Detection of Twitter Data Streams", "summary": "In the past few years, there has been a huge growth in Twitter sentiment\nanalysis having already provided a fair amount of research on sentiment\ndetection of public opinion among Twitter users. Given the fact that Twitter\nmessages are generated constantly with dizzying rates, a huge volume of\nstreaming data is created, thus there is an imperative need for accurate\nmethods for knowledge discovery and mining of this information. Although there\nexists a plethora of twitter sentiment analysis methods in the recent\nliterature, the researchers have shifted to real-time sentiment identification\non twitter streaming data, as expected. A major challenge is to deal with the\nBig Data challenges arising in Twitter streaming applications concerning both\nVolume and Velocity. Under this perspective, in this paper, a methodological\napproach based on open source tools is provided for real-time detection of\nchanges in sentiment that is ultra efficient with respect to both memory\nconsumption and computational cost. This is achieved by iteratively collecting\ntweets in real time and discarding them immediately after their process. For\nthis purpose, we employ the Lexicon approach for sentiment characterizations,\nwhile change detection is achieved through appropriate control charts that do\nnot require historical information. We believe that the proposed methodology\nprovides the trigger for a potential large-scale monitoring of threads in an\nattempt to discover fake news spread or propaganda efforts in their early\nstages. Our experimental real-time analysis based on a recent hashtag provides\nevidence that the proposed approach can detect meaningful sentiment changes\nacross a hashtags lifetime.", "author": [{"name": "Sotiris K. Tasoulis"}, {"name": "Aristidis G. Vrahatis"}, {"name": "Spiros V. Georgakopoulos"}, {"name": "Vassilis P. Plagianakos"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1109/INISTA.2018.8466326"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1109/INISTA.2018.8466326", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1804.00482v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.00482v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1804.01235v2", "updated": "2018-04-17T12:58:41Z", "published": "2018-04-04T04:38:36Z", "title": "Real-time Detection of Content Polluters in Partially Observable Twitter\n  Networks", "summary": "Content polluters, or bots that hijack a conversation for political or\nadvertising purposes are a known problem for event prediction, election\nforecasting and when distinguishing real news from fake news in social media\ndata. Identifying this type of bot is particularly challenging, with\nstate-of-the-art methods utilising large volumes of network data as features\nfor machine learning models. Such datasets are generally not readily available\nin typical applications which stream social media data for real-time event\nprediction. In this work we develop a methodology to detect content polluters\nin social media datasets that are streamed in real-time. Applying our method to\nthe problem of civil unrest event prediction in Australia, we identify content\npolluters from individual tweets, without collecting social network or\nhistorical data from individual accounts. We identify some peculiar\ncharacteristics of these bots in our dataset and propose metrics for\nidentification of such accounts. We then pose some research questions around\nthis type of bot detection, including: how good Twitter is at detecting content\npolluters and how well state-of-the-art methods perform in detecting bots in\nour dataset.", "author": [{"name": "Mehwish Nasim"}, {"name": "Andrew Nguyen"}, {"name": "Nick Lothian"}, {"name": "Robert Cope"}, {"name": "Lewis Mitchell"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication in WWW '18 Companion: The 2018 Web\n  Conference Companion, April 23-27, 2018, Lyon, France"}, "link": [{"@href": "http://arxiv.org/abs/1804.01235v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.01235v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1804.10159v1", "updated": "2018-04-26T16:34:48Z", "published": "2018-04-26T16:34:48Z", "title": "AbuSniff: Automatic Detection and Defenses Against Abusive Facebook\n  Friends", "summary": "Adversaries leverage social network friend relationships to collect sensitive\ndata from users and target them with abuse that includes fake news,\ncyberbullying, malware, and propaganda. Case in point, 71 out of 80 user study\nparticipants had at least 1 Facebook friend with whom they never interact,\neither in Facebook or in real life, or whom they believe is likely to abuse\ntheir posted photos or status updates, or post offensive, false or malicious\ncontent. We introduce AbuSniff, a system that identifies Facebook friends\nperceived as strangers or abusive, and protects the user by unfriending,\nunfollowing, or restricting the access to information for such friends. We\ndevelop a questionnaire to detect perceived strangers and friend abuse.We\nintroduce mutual Facebook activity features and show that they can train\nsupervised learning algorithms to predict questionnaire responses. We have\nevaluated AbuSniff through several user studies with a total of 263\nparticipants from 25 countries. After answering the questionnaire, participants\nagreed to unfollow and restrict abusers in 91.6% and 90.9% of the cases\nrespectively, and sandbox or unfriend non-abusive strangers in 92.45% of the\ncases. Without answering the questionnaire, participants agreed to take the\nAbuSniff suggested action against friends predicted to be strangers or abusive,\nin 78.2% of the cases. AbuSniff increased the participant self-reported\nwillingness to reject invitations from strangers and abusers, their awareness\nof friend abuse implications and their perceived protection from friend abuse.", "author": [{"name": "Sajedul Talukder"}, {"name": "Bogdan Carbunar"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12TH INTERNATIONAL AAAI CONFERENCE ON WEB AND SOCIAL MEDIA\n  (ICWSM-18), 10 pages"}, "link": [{"@href": "http://arxiv.org/abs/1804.10159v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.10159v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1812.02978v1", "updated": "2018-12-07T10:59:09Z", "published": "2018-12-07T10:59:09Z", "title": "More or Less? Predict the Social Influence of Malicious URLs on Social\n  Media", "summary": "Users of Online Social Networks (OSNs) interact with each other more than\never. In the context of a public discussion group, people receive, read, and\nwrite comments in response to articles and postings. In the absence of access\ncontrol mechanisms, OSNs are a great environment for attackers to influence\nothers, from spreading phishing URLs, to posting fake news. Moreover, OSN user\nbehavior can be predicted by social science concepts which include conformity\nand the bandwagon effect. In this paper, we show how social recommendation\nsystems affect the occurrence of malicious URLs on Facebook. We exploit\ntemporal features to build a prediction framework, having greater than 75%\naccuracy, to predict whether the following group users' behavior will increase\nor not. Included in this work, we demarcate classes of URLs, including those\nmalicious URLs classified as creating critical damage, as well as those of a\nlesser nature which only inflict light damage such as aggressive commercial\nadvertisements and spam content. It is our hope that the data and analyses in\nthis paper provide a better understanding of OSN user reactions to different\ncategories of malicious URLs, thereby providing a way to mitigate the influence\nof these malicious URL attacks.", "author": [{"name": "Chun-Ming Lai"}, {"name": "Xiaoyun Wang"}, {"name": "Jon W. Chapman"}, {"name": "Yu-Cheng Lin"}, {"name": "Yu-Chang Ho"}, {"name": "S. Felix Wu"}, {"name": "Patrick McDaniel"}, {"name": "Hasan Cam"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 6 figures"}, "link": [{"@href": "http://arxiv.org/abs/1812.02978v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.02978v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1812.04478v4", "updated": "2020-03-17T13:02:14Z", "published": "2018-12-11T15:45:10Z", "title": "Socratrees: Exploring the Design of Argument Technology for Layman Users", "summary": "Terms like 'misinformation', 'fake news', and 'echo chambers' permeate\ncurrent discussions on the state of the Internet. We believe a lack of\ntechnological support to evaluate, contest, and reason about information\nonline---as opposed to merely disseminating it---lies at the root of these\nproblems. Several argument technologies support such functionality, but have\nseen limited use outside of niche communities. Most research systems\noveremphasize argument analysis and structure, standing in stark contrast with\nthe informal dialectical nature of everyday argumentation. Conversely,\nnon-academic systems overlook important implications for design which can be\nderived from theory. In this paper, we present the design of a system aiming to\nstrike a balance between structured argumentation and ease of use. Socratrees\nis a website for collaborative argumentative discussion targeting layman users,\nbut includes sophisticated community guidelines and novel features inspired by\ninformal logic. During an exploratory study, we evaluate the usefulness of our\nimposed structure on argumentation and investigate how users perceive it.\nContributing to arguments remains a complex task, but most users learned to do\nso effectively with minimal guidance and all recognized that the structure of\nSocratrees may improve online discussion and results in a clearer overview of\narguments.", "author": {"name": "Steven Jeuris"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Rejected several times, primarily on the basis of needing a larger\n  study. While trying to obtain funding for this (this project has received no\n  funding so far), leaving this out here for now"}, "link": [{"@href": "http://arxiv.org/abs/1812.04478v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1812.04478v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "H.5.4", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1901.02156v1", "updated": "2019-01-08T05:11:17Z", "published": "2019-01-08T05:11:17Z", "title": "Influence Minimization Under Budget and Matroid Constraints: Extended\n  Version", "summary": "Recently, online social networks have become major battlegrounds for\npolitical campaigns, viral marketing, and the dissemination of news. As a\nconsequence, ''bad actors'' are increasingly exploiting these platforms,\nbecoming a key challenge for their administrators, businesses and the society\nin general. The spread of fake news is a classical example of the abuse of\nsocial networks by these actors. While some have advocated for stricter\npolicies to control the spread of misinformation in social networks, this often\nhappens in detriment of their democratic and organic structure. In this paper\nwe study how to limit the influence of a target set of users in a network via\nthe removal of a few edges. The idea is to control the diffusion processes\nwhile minimizing the amount of disturbance in the network structure.\n  We formulate the influence limitation problem in a data-driven fashion, by\ntaking into account past propagation traces. Moreover, we consider two types of\nconstraints over the set of edge removals, a budget constraint and also a, more\ngeneral, set of matroid constraints. These problems lead to interesting\nchallenges in terms of algorithm design. For instance, we are able to show that\ninfluence limitation is APX-hard and propose deterministic and probabilistic\napproximation algorithms for the budgeted and matroid version of the problem,\nrespectively. Our experiments show that the proposed solutions outperform the\nbaselines by up to 40%.", "author": [{"name": "Sourav Medya"}, {"name": "Arlei Silva"}, {"name": "Ambuj Singh"}], "link": [{"@href": "http://arxiv.org/abs/1901.02156v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.02156v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1901.08971v3", "updated": "2019-08-26T17:59:54Z", "published": "2019-01-25T16:38:21Z", "title": "FaceForensics++: Learning to Detect Manipulated Facial Images", "summary": "The rapid progress in synthetic image generation and manipulation has now\ncome to a point where it raises significant concerns for the implications\ntowards society. At best, this leads to a loss of trust in digital content, but\ncould potentially cause further harm by spreading false information or fake\nnews. This paper examines the realism of state-of-the-art image manipulations,\nand how difficult it is to detect them, either automatically or by humans. To\nstandardize the evaluation of detection methods, we propose an automated\nbenchmark for facial manipulation detection. In particular, the benchmark is\nbased on DeepFakes, Face2Face, FaceSwap and NeuralTextures as prominent\nrepresentatives for facial manipulations at random compression level and size.\nThe benchmark is publicly available and contains a hidden test set as well as a\ndatabase of over 1.8 million manipulated images. This dataset is over an order\nof magnitude larger than comparable, publicly available, forgery datasets.\nBased on this data, we performed a thorough analysis of data-driven forgery\ndetectors. We show that the use of additional domainspecific knowledge improves\nforgery detection to unprecedented accuracy, even in the presence of strong\ncompression, and clearly outperforms human observers.", "author": [{"name": "Andreas R\u00f6ssler"}, {"name": "Davide Cozzolino"}, {"name": "Luisa Verdoliva"}, {"name": "Christian Riess"}, {"name": "Justus Thies"}, {"name": "Matthias Nie\u00dfner"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Video: https://youtu.be/x2g48Q2I2ZQ"}, "link": [{"@href": "http://arxiv.org/abs/1901.08971v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1901.08971v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1902.01443v1", "updated": "2019-02-04T19:56:06Z", "published": "2019-02-04T19:56:06Z", "title": "Identification and Estimation of Causal Effects from Dependent Data", "summary": "The assumption that data samples are independent and identically distributed\n(iid) is standard in many areas of statistics and machine learning.\nNevertheless, in some settings, such as social networks, infectious disease\nmodeling, and reasoning with spatial and temporal data, this assumption is\nfalse. An extensive literature exists on making causal inferences under the iid\nassumption [18, 12, 28, 22], even when unobserved confounding bias may be\npresent. But, as pointed out in [20], causal inference in non-iid contexts is\nchallenging due to the presence of both unobserved confounding and data\ndependence. In this paper we develop a general theory describing when causal\ninferences are possible in such scenarios. We use segregated graphs [21], a\ngeneralization of latent projection mixed graphs [30], to represent causal\nmodels of this type and provide a complete algorithm for non-parametric\nidentification in these models. We then demonstrate how statistical inference\nmay be performed on causal parameters identified by this algorithm. In\nparticular, we consider cases where only a single sample is available for parts\nof the model due to full interference, i.e., all units are pathwise dependent\nand neighbors' treatments affect each others' outcomes [26]. We apply these\ntechniques to a synthetic data set which considers users sharing fake news\narticles given the structure of their social network, user activity levels, and\nbaseline demographics and socioeconomic covariates.", "author": [{"name": "Eli Sherman"}, {"name": "Ilya Shpitser"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Advances in neural information processing systems. 2018"}, "link": [{"@href": "http://arxiv.org/abs/1902.01443v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.01443v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "stat.ME", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "stat.ME", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1902.01970v1", "updated": "2019-02-05T23:19:48Z", "published": "2019-02-05T23:19:48Z", "title": "Hawkes Process for Understanding the Influence of Pathogenic Social\n  Media Accounts", "summary": "Over the past years, political events and public opinion on the Web have been\nallegedly manipulated by accounts dedicated to spreading disinformation and\nperforming malicious activities on social media. These accounts hereafter\nreferred to as \"Pathogenic Social Media (PSM)\" accounts, are often controlled\nby terrorist supporters, water armies or fake news writers and hence can pose\nthreats to social media and general public. Understanding and analyzing PSMs\ncould help social media firms devise sophisticated and automated techniques\nthat could be deployed to stop them from reaching their audience and\nconsequently reduce their threat. In this paper, we leverage the well-known\nstatistical technique \"Hawkes Process\" to quantify the influence of PSM\naccounts on the dissemination of malicious information on social media\nplatforms. Our findings on a real-world ISIS-related dataset from Twitter\nindicate that PSMs are significantly different from regular users in making a\nmessage viral. Specifically, we observed that PSMs do not usually post URLs\nfrom mainstream news sources. Instead, their tweets usually receive large\nimpact on audience, if contained URLs from Facebook and alternative news\noutlets. In contrary, tweets posted by regular users receive nearly equal\nimpression regardless of the posted URLs and their sources. Our findings can\nfurther shed light on understanding and detecting PSM accounts.", "author": [{"name": "Hamidreza Alvari"}, {"name": "Paulo Shakarian"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IEEE Conference on Data Intelligence and Security (ICDIS) 2019"}, "link": [{"@href": "http://arxiv.org/abs/1902.01970v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.01970v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1902.07636v1", "updated": "2019-02-20T16:47:04Z", "published": "2019-02-20T16:47:04Z", "title": "Contributive Social Capital Extraction From Different Types of Online\n  Data Sources", "summary": "It is a recurring problem of online communication that the properties of\nunknown people are hard to assess. This may lead to various issues such as the\nspread of `fake news' from untrustworthy sources. In sociology the sum of\n(social) resources available to a person through their social network is often\ndescribed as social capital. In this article, we look at social capital from a\ndifferent angle. Instead of evaluating the advantage that people have because\nof their membership in a certain group, we investigate various ways to infer\nthe social capital a person adds or may add to the network, their contributive\nsocial capital (CSC). As there is no consensus in the literature on what the\nsocial capital of a person exactly consists of, we look at various related\nproperties: expertise, reputation, trustworthiness, and influence. The analysis\nof these features is investigated for five different sources of online data:\nmicroblogging (e.g., Twitter), social networking platforms (e.g., Facebook),\ndirect communication (e.g., email), scientometrics, and threaded discussion\nboards (e.g., Reddit). In each field we discuss recent publications and put a\nfocus on the data sources used, the algorithms implemented, and the performance\nevaluation. The findings are compared and set in context to contributive social\ncapital extraction. The analysis algorithms are based on individual features\n(e.g., followers on Twitter), ratios thereof, or a person's centrality measures\n(e.g., PageRank). The machine learning approaches, such as straightforward\nclassifiers (e.g., support vector machines) use ground truths that are\nconnected to social capital. The discussion of these methods is intended to\nfacilitate research on the topic by identifying relevant data sources and the\nbest suited algorithms, and by providing tested methods for the evaluation of\nfindings.", "author": [{"name": "Sebastian Schams"}, {"name": "Georg Groh"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "44 pages"}, "link": [{"@href": "http://arxiv.org/abs/1902.07636v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1902.07636v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1903.08404v1", "updated": "2019-03-20T09:40:19Z", "published": "2019-03-20T09:40:19Z", "title": "Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking", "summary": "Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.", "author": [{"name": "Casper Hansen"}, {"name": "Christian Hansen"}, {"name": "Stephen Alstrup"}, {"name": "Jakob Grue Simonsen"}, {"name": "Christina Lioma"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "6 pages"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "In Companion Proceedings of the 2019 World Wide Web Conference"}, "link": [{"@href": "http://arxiv.org/abs/1903.08404v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1903.08404v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1905.00672v4", "updated": "2020-08-06T18:29:54Z", "published": "2019-05-02T11:36:11Z", "title": "Temporal Ordered Clustering in Dynamic Networks: Unsupervised and\n  Semi-supervised Learning Algorithms", "summary": "In temporal ordered clustering, given a single snapshot of a dynamic network\nin which nodes arrive at distinct time instants, we aim at partitioning its\nnodes into $K$ ordered clusters $\\mathcal{C}_1 \\prec \\cdots \\prec\n\\mathcal{C}_K$ such that for $i<j$, nodes in cluster $\\mathcal{C}_i$ arrived\nbefore nodes in cluster $\\mathcal{C}_j$, with $K$ being a data-driven parameter\nand not known upfront. Such a problem is of considerable significance in many\napplications ranging from tracking the expansion of fake news to mapping the\nspread of information. We first formulate our problem for a general dynamic\ngraph, and propose an integer programming framework that finds the optimal\nclustering, represented as a strict partial order set, achieving the best\nprecision (i.e., fraction of successfully ordered node pairs) for a fixed\ndensity (i.e., fraction of comparable node pairs). We then develop a sequential\nimportance procedure and design unsupervised and semi-supervised algorithms to\nfind temporal ordered clusters that efficiently approximate the optimal\nsolution. To illustrate the techniques, we apply our methods to the vertex\ncopying (duplication-divergence) model which exhibits some edge-case challenges\nin inferring the clusters as compared to other network models. Finally, we\nvalidate the performance of the proposed algorithms on synthetic and real-world\nnetworks.", "author": [{"name": "Krzysztof Turowski"}, {"name": "Jithin K. Sreedharan"}, {"name": "Wojciech Szpankowski"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "14 pages, 9 figures, and 3 tables. This version is submitted to a\n  journal. A shorter version of this work is published in the proceedings of\n  IEEE International Symposium on Information Theory (ISIT), 2020. The first\n  two authors contributed equally"}, "link": [{"@href": "http://arxiv.org/abs/1905.00672v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1905.00672v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.AP", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1906.08875v2", "updated": "2020-06-15T22:58:41Z", "published": "2019-06-20T21:38:36Z", "title": "Measuring the engagement level in encrypted group conversations by using\n  temporal networks", "summary": "Chat groups are well-known for their capacity to promote viral political and\nmarketing campaigns, spread fake news, and create rallies by hundreds of\nthousands on the streets. Also, with the increasing public awareness regarding\nprivacy and surveillance, many platforms have started to deploy end-to-end\nencrypted protocols. In this context, the group's conversations are not\naccessible in plain text or readable format by third-party organizations or\neven the platform owner. Then, the main challenge that emerges is related to\ngetting insights from users' activity of those groups, but without accessing\nthe messages. Previous approaches evaluated the user engagement by assessing\nuser's activity, however, on limited conditions where the data is encrypted,\nthey cannot be applied. In this work, we present a framework for measuring the\nlevel of engagement of group conversations and users, without reading the\nmessages. Our framework creates an ensemble of interaction networks that\nrepresent the temporal evolution of the conversation, then, we apply the\nproposed Engagement Index (EI) for each interval of conversations to assess\nusers' participation. Our results in five datasets from real-world WhatsApp\nGroups indicate that, based on the EI, it is possible to identify the most\nengaged users within a time interval, create rankings, and group users\naccording to their engagement and monitor their performance over time.", "author": [{"name": "Moshe Cotacallapa"}, {"name": "Lilian Berton"}, {"name": "Leonardo N. Ferreira"}, {"name": "Marcos G. Quiles"}, {"name": "Liang Zhao"}, {"name": "Elbert E. N. Macau"}, {"name": "Didier A. Vega-Oliveros"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "8 pages, 9 figures, IJCNN"}, "link": [{"@href": "http://arxiv.org/abs/1906.08875v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1906.08875v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1909.09868v2", "updated": "2020-04-24T01:44:57Z", "published": "2019-09-21T18:47:34Z", "title": "On the Importance of Delexicalization for Fact Verification", "summary": "In this work we aim to understand and estimate the importance that a neural\nnetwork assigns to various aspects of the data while learning and making\npredictions. Here we focus on the recognizing textual entailment (RTE) task and\nits application to fact verification. In this context, the contributions of\nthis work are as follows. We investigate the attention weights a state of the\nart RTE method assigns to input tokens in the RTE component of fact\nverification systems, and confirm that most of the weight is assigned to POS\ntags of nouns (e.g., NN, NNP etc.) or their phrases. To verify that these\nlexicalized models transfer poorly, we implement a domain transfer experiment\nwhere a RTE component is trained on the FEVER data, and tested on the Fake News\nChallenge (FNC) dataset. As expected, even though this method achieves high\naccuracy when evaluated in the same domain, the performance in the target\ndomain is poor, marginally above chance.To mitigate this dependence on\nlexicalized information, we experiment with several strategies for masking out\nnames by replacing them with their semantic category, coupled with a unique\nidentifier to mark that the same or new entities are referenced between claim\nand evidence. The results show that, while the performance on the FEVER dataset\nremains at par with that of the model trained on lexicalized data, it improves\nsignificantly when tested in the FNC dataset. Thus our experiments demonstrate\nthat our strategy is successful in mitigating the dependency on lexical\ninformation.", "author": [{"name": "Sandeep Suntwal"}, {"name": "Mithun Paul"}, {"name": "Rebecca Sharp"}, {"name": "Mihai Surdeanu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.18653/v1/D19-1340"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.18653/v1/D19-1340", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1909.09868v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.09868v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "published in the proceedings at EMNLP2019"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.12089v2", "updated": "2019-12-20T01:12:42Z", "published": "2019-09-26T13:36:02Z", "title": "From classical to modern opinion dynamics", "summary": "In this age of Facebook, Instagram and Twitter, there is rapidly growing\ninterest in understanding network-enabled opinion dynamics in large groups of\nautonomous agents. The phenomena of opinion polarization, the spread of\npropaganda and fake news, and the manipulation of sentiment are of interest to\nlarge numbers of organizations and people, some of whom are resource rich.\nWhether it is the more nefarious players such as foreign governments that are\nattempting to sway elections or large corporations that are trying to bend\nsentiment -- often quite surreptitiously, or it is more open and above board,\nlike researchers that want to spread the news of some finding or some business\ninterest that wants to make a large group of people aware of genuinely helpful\ninnovations that they are marketing, what is at stake is often significant. In\nthis paper we review many of the classical, and some of the new, social\ninteraction models aimed at understanding opinion dynamics. While the first\npapers studying opinion dynamics appeared over 60 years ago, there is still a\ngreat deal of room for innovation and exploration. We believe that the\npolitical climate and the extraordinary (even unprecedented) events in the\nsphere of politics in the last few years will inspire new interest and new\nideas. It is our aim to help those interested researchers understand what has\nalready been explored in a significant portion of the field of opinion\ndynamics. We believe that in doing this, it will become clear that there is\nstill much to be done.", "author": [{"name": "Hossein Noorazar"}, {"name": "Kevin R. Vixie"}, {"name": "Arghavan Talebanpour"}, {"name": "Yunfeng Hu"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1142/S0129183120501016"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1142/S0129183120501016", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1909.12089v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.12089v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1911.12069v2", "updated": "2021-04-22T09:51:53Z", "published": "2019-11-27T10:41:19Z", "title": "SpoC: Spoofing Camera Fingerprints", "summary": "Thanks to the fast progress in synthetic media generation, creating realistic\nfalse images has become very easy. Such images can be used to wrap \"rich\" fake\nnews with enhanced credibility, spawning a new wave of high-impact, high-risk\nmisinformation campaigns. Therefore, there is a fast-growing interest in\nreliable detectors of manipulated media. The most powerful detectors, to date,\nrely on the subtle traces left by any device on all images acquired by it. In\nparticular, due to proprietary in-camera processes, like demosaicing or\ncompression, each camera model leaves trademark traces that can be exploited\nfor forensic analyses. The absence or distortion of such traces in the target\nimage is a strong hint of manipulation. In this paper, we challenge such\ndetectors to gain better insight into their vulnerabilities. This is an\nimportant study in order to build better forgery detectors able to face\nmalicious attacks. Our proposal consists of a GAN-based approach that injects\ncamera traces into synthetic images. Given a GAN-generated image, we insert the\ntraces of a specific camera model into it and deceive state-of-the-art\ndetectors into believing the image was acquired by that model. Likewise, we\ndeceive independent detectors of synthetic GAN images into believing the image\nis real. Experiments prove the effectiveness of the proposed method in a wide\narray of conditions. Moreover, no prior information on the attacked detectors\nis needed, but only sample images from the target camera.", "author": [{"name": "Davide Cozzolino"}, {"name": "Justus Thies"}, {"name": "Andreas R\u00f6ssler"}, {"name": "Matthias Nie\u00dfner"}, {"name": "Luisa Verdoliva"}], "link": [{"@href": "http://arxiv.org/abs/1911.12069v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1911.12069v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "eess.IV", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2001.09473v1", "updated": "2020-01-26T15:42:43Z", "published": "2020-01-26T15:42:43Z", "title": "Information Credibility in the Social Web: Contexts, Approaches, and\n  Open Issues", "summary": "In the Social Web scenario, large amounts of User-Generated Content (UGC) are\ndiffused through social media often without almost any form of traditional\ntrusted intermediaries. Therefore, the risk of running into misinformation is\nnot negligible. For this reason, assessing and mining the credibility of online\ninformation constitutes nowadays a fundamental research issue. Credibility,\nalso referred as believability, is a quality perceived by individuals, who are\nnot always able to discern, with their own cognitive capacities, genuine\ninformation from fake one. Hence, in the last years, several approaches have\nbeen proposed to automatically assess credibility in social media. Many of them\nare based on data-driven models, i.e., they employ machine learning techniques\nto identify misinformation, but recently also model-driven approaches are\nemerging, as well as graph-based approaches focusing on credibility\npropagation, and knowledge-based ones exploiting Semantic Web technologies.\nThree of the main contexts in which the assessment of information credibility\nhas been investigated concern: (i) the detection of opinion spam in review\nsites, (ii) the detection of fake news in microblogging, and (iii) the\ncredibility assessment of online health-related information. In this article,\nthe main issues connected to the evaluation of information credibility in the\nSocial Web, which are shared by the above-mentioned contexts, are discussed. A\nconcise survey of the approaches and methodologies that have been proposed in\nrecent years to address these issues is also presented.", "author": [{"name": "Gabriella Pasi"}, {"name": "Marco Viviani"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Article accepted and presented at ITASEC 2020: Italian Conference on\n  Cybersecurity. February 4-7, 2020, Ancona, Italy. https://itasec.it/"}, "link": [{"@href": "http://arxiv.org/abs/2001.09473v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2001.09473v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.09543v1", "updated": "2020-03-21T01:00:02Z", "published": "2020-03-21T01:00:02Z", "title": "Towards Time-Aware Context-Aware Deep Trust Prediction in Online Social\n  Networks", "summary": "Trust can be defined as a measure to determine which source of information is\nreliable and with whom we should share or from whom we should accept\ninformation. There are several applications for trust in Online Social Networks\n(OSNs), including social spammer detection, fake news detection, retweet\nbehaviour detection and recommender systems. Trust prediction is the process of\npredicting a new trust relation between two users who are not currently\nconnected. In applications of trust, trust relations among users need to be\npredicted. This process faces many challenges, such as the sparsity of\nuser-specified trust relations, the context-awareness of trust and changes in\ntrust values over time. In this dissertation, we analyse the state-of-the-art\nin pair-wise trust prediction models in OSNs. We discuss three main challenges\nin this domain and present novel trust prediction approaches to address them.\nWe first focus on proposing a low-rank representation of users that\nincorporates users' personality traits as additional information. Then, we\npropose a set of context-aware trust prediction models. Finally, by considering\nthe time-dependency of trust relations, we propose a dynamic deep trust\nprediction approach. We design and implement five pair-wise trust prediction\napproaches and evaluate them with real-world datasets collected from OSNs. The\nexperimental results demonstrate the effectiveness of our approaches compared\nto other state-of-the-art pair-wise trust prediction models.", "author": {"name": "Seyed Mohssen Ghafari"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "158 pages, 20 figures, and 19 tables. This is my PhD thesis in\n  Macquarie University, Sydney, Australia"}, "link": [{"@href": "http://arxiv.org/abs/2003.09543v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.09543v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68-02", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "E.0", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.10421v2", "updated": "2020-10-23T09:22:53Z", "published": "2020-03-23T17:49:06Z", "title": "Multimodal Analytics for Real-world News using Measures of Cross-modal\n  Entity Consistency", "summary": "The World Wide Web has become a popular source for gathering information and\nnews. Multimodal information, e.g., enriching text with photos, is typically\nused to convey the news more effectively or to attract attention. Photo content\ncan range from decorative, depict additional important information, or can even\ncontain misleading information. Therefore, automatic approaches to quantify\ncross-modal consistency of entity representation can support human assessors to\nevaluate the overall multimodal message, for instance, with regard to bias or\nsentiment. In some cases such measures could give hints to detect fake news,\nwhich is an increasingly important topic in today's society. In this paper, we\nintroduce a novel task of cross-modal consistency verification in real-world\nnews and present a multimodal approach to quantify the entity coherence between\nimage and text. Named entity linking is applied to extract persons, locations,\nand events from news texts. Several measures are suggested to calculate\ncross-modal similarity for these entities using state of the art approaches. In\ncontrast to previous work, our system automatically gathers example data from\nthe Web and is applicable to real-world news. Results on two novel datasets\nthat cover different languages, topics, and domains demonstrate the feasibility\nof our approach. Datasets and code are publicly available to foster research\ntowards this new direction.", "author": [{"name": "Eric M\u00fcller-Budack"}, {"name": "Jonas Theiner"}, {"name": "Sebastian Diering"}, {"name": "Maximilian Idahl"}, {"name": "Ralph Ewerth"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted for publication in: International Conference on Multimedia\n  Retrieval (ICMR), Dublin, 2020"}, "link": [{"@href": "http://arxiv.org/abs/2003.10421v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.10421v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2004.02566v3", "updated": "2020-04-09T15:41:01Z", "published": "2020-04-06T11:23:46Z", "title": "Pandemic Populism: Facebook Pages of Alternative News Media and the\n  Corona Crisis -- A Computational Content Analysis", "summary": "The COVID-19 pandemic has not only had severe political, economic, and\nsocietal effects, it has also affected media and communication systems in\nunprecedented ways. While traditional journalistic media has tried to adapt to\nthe rapidly evolving situation, alternative news media on the Internet have\ngiven the events their own ideological spin. Such voices have been criticized\nfor furthering societal confusion and spreading potentially dangerous \"fake\nnews\" or conspiracy theories via social media and other online channels. The\ncurrent study analyzes the factual basis of such fears in an initial\ncomputational content analysis of alternative news media's output on Facebook\nduring the early Corona crisis, based on a large German data set from January\nto the second half of March 2020. Using computational content analysis,\nmethods, reach, interactions, actors, and topics of the messages were examined,\nas well as the use of fabricated news and conspiracy theories. The analysis\nrevealed that the alternative news media stay true to message patterns and\nideological foundations identified in prior research. While they do not spread\nobvious lies, they are predominantly sharing overly critical, even\nanti-systemic messages, opposing the view of the mainstream news media and the\npolitical establishment. With this pandemic populism, they contribute to a\ncontradictory, menacing, and distrusting worldview, as portrayed in detail in\nthis analysis.", "author": [{"name": "Svenja Boberg"}, {"name": "Thorsten Quandt"}, {"name": "Tim Schatto-Eckrodt"}, {"name": "Lena Frischlich"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Muenster Online Research (MOR) Working Paper 1/2020, 4 figures, 4\n  tables, corrected typos and references"}, "link": [{"@href": "http://arxiv.org/abs/2004.02566v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.02566v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2004.11480v1", "updated": "2020-04-23T22:25:48Z", "published": "2020-04-23T22:25:48Z", "title": "Characterising User Content on a Multi-lingual Social Network", "summary": "Social media has been on the vanguard of political information diffusion in\nthe 21st century. Most studies that look into disinformation, political\ninfluence and fake-news focus on mainstream social media platforms. This has\ninevitably made English an important factor in our current understanding of\npolitical activity on social media. As a result, there has only been a limited\nnumber of studies into a large portion of the world, including the largest,\nmultilingual and multi-cultural democracy: India. In this paper we present our\ncharacterisation of a multilingual social network in India called ShareChat. We\ncollect an exhaustive dataset across 72 weeks before and during the Indian\ngeneral elections of 2019, across 14 languages. We investigate the cross\nlingual dynamics by clustering visually similar images together, and exploring\nhow they move across language barriers. We find that Telugu, Malayalam, Tamil\nand Kannada languages tend to be dominant in soliciting political images (often\nreferred to as memes), and posts from Hindi have the largest cross-lingual\ndiffusion across ShareChat (as well as images containing text in English). In\nthe case of images containing text that cross language barriers, we see that\nlanguage translation is used to widen the accessibility. That said, we find\ncases where the same image is associated with very different text (and\ntherefore meanings). This initial characterisation paves the way for more\nadvanced pipelines to understand the dynamics of fake and political content in\na multi-lingual and non-textual setting.", "author": [{"name": "Pushkal Agarwal"}, {"name": "Kiran Garimella"}, {"name": "Sagar Joglekar"}, {"name": "Nishanth Sastry"}, {"name": "Gareth Tyson"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at ICWSM 2020, please cite the ICWSM version"}, "link": [{"@href": "http://arxiv.org/abs/2004.11480v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2004.11480v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.01157v1", "updated": "2020-05-03T18:02:10Z", "published": "2020-05-03T18:02:10Z", "title": "Out of the Echo Chamber: Detecting Countering Debate Speeches", "summary": "An educated and informed consumption of media content has become a challenge\nin modern times. With the shift from traditional news outlets to social media\nand similar venues, a major concern is that readers are becoming encapsulated\nin \"echo chambers\" and may fall prey to fake news and disinformation, lacking\neasy access to dissenting views. We suggest a novel task aiming to alleviate\nsome of these concerns -- that of detecting articles that most effectively\ncounter the arguments -- and not just the stance -- made in a given text. We\nstudy this problem in the context of debate speeches. Given such a speech, we\naim to identify, from among a set of speeches on the same topic and with an\nopposing stance, the ones that directly counter it. We provide a large dataset\nof 3,685 such speeches (in English), annotated for this relation, which\nhopefully would be of general interest to the NLP community. We explore several\nalgorithms addressing this task, and while some are successful, all fall short\nof expert human performance, suggesting room for further research. All data\ncollected during this work is freely available for research.", "author": [{"name": "Matan Orbach"}, {"name": "Yonatan Bilu"}, {"name": "Assaf Toledo"}, {"name": "Dan Lahav"}, {"name": "Michal Jacovi"}, {"name": "Ranit Aharonov"}, {"name": "Noam Slonim"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to ACL 2020 as Long Paper. For the associated debate\n  speeches corpus, see\n  https://www.research.ibm.com/haifa/dept/vst/debating_data.shtml#Debate%20Speech%20Analysis"}, "link": [{"@href": "http://arxiv.org/abs/2005.01157v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.01157v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.04518v1", "updated": "2020-05-09T22:00:08Z", "published": "2020-05-09T22:00:08Z", "title": "What Was Written vs. Who Read It: News Media Profiling Using Text\n  Analysis and Social Media Context", "summary": "Predicting the political bias and the factuality of reporting of entire news\noutlets are critical elements of media profiling, which is an understudied but\nan increasingly important research direction. The present level of\nproliferation of fake, biased, and propagandistic content online, has made it\nimpossible to fact-check every single suspicious claim, either manually or\nautomatically. Alternatively, we can profile entire news outlets and look for\nthose that are likely to publish fake or biased content. This approach makes it\npossible to detect likely \"fake news\" the moment they are published, by simply\nchecking the reliability of their source. From a practical perspective,\npolitical bias and factuality of reporting have a linguistic aspect but also a\nsocial context. Here, we study the impact of both, namely (i) what was written\n(i.e., what was published by the target medium, and how it describes itself on\nTwitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium\non Facebook, Twitter, and YouTube). We further study (iii) what was written\nabout the target medium on Wikipedia. The evaluation results show that what was\nwritten matters most, and that putting all information sources together yields\nhuge improvements over the current state-of-the-art.", "author": [{"name": "Ramy Baly"}, {"name": "Georgi Karadzhov"}, {"name": "Jisun An"}, {"name": "Haewoon Kwak"}, {"name": "Yoan Dinkov"}, {"name": "Ahmed Ali"}, {"name": "James Glass"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Factuality of reporting, fact-checking, political ideology, media\n  bias, disinformation, propaganda, social media, news media"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "ACL-2020"}, "link": [{"@href": "http://arxiv.org/abs/2005.04518v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.04518v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.08794v3", "updated": "2021-01-13T19:24:59Z", "published": "2020-05-18T15:15:15Z", "title": "Inference on the History of a Randomly Growing Tree", "summary": "The spread of infectious disease in a human community or the proliferation of\nfake news on social media can be modeled as a randomly growing tree-shaped\ngraph. The history of the random growth process is often unobserved but\ncontains important information such as the source of the infection. We consider\nthe problem of statistical inference on aspects of the latent history using\nonly a single snapshot of the final tree. Our approach is to apply random\nlabels to the observed unlabeled tree and analyze the resulting distribution of\nthe growth process, conditional on the final outcome. We show that this\nconditional distribution is tractable under a shape-exchangeability condition,\nwhich we introduce here, and that this condition is satisfied for many popular\nmodels for randomly growing trees such as uniform attachment, linear\npreferential attachment and uniform attachment on a $D$-regular tree. For\ninference of the root under shape-exchangeability, we propose O(n log n) time\nalgorithms for constructing confidence sets with valid frequentist coverage as\nwell as bounds on the expected size of the confidence sets. We also provide\nefficient sampling algorithms that extend our methods to a wide class of\ninference problems.", "author": [{"name": "Harry Crane"}, {"name": "Min Xu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "36 pages; 7 figures; 5 tables"}, "link": [{"@href": "http://arxiv.org/abs/2005.08794v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.08794v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "math.PR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "math.PR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.ST", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.CO", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.TH", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "90B15, 62M15", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.09199v1", "updated": "2020-05-19T03:52:21Z", "published": "2020-05-19T03:52:21Z", "title": "FrameProv: Towards End-To-End Video Provenance", "summary": "Video feeds are often deliberately used as evidence, as in the case of CCTV\nfootage; but more often than not, the existence of footage of a supposed event\nis perceived as proof of fact in the eyes of the public at large. This reliance\nrepresents a societal vulnerability given the existence of easy-to-use editing\ntools and means to fabricate entire video feeds using machine learning. And, as\nthe recent barrage of fake news and fake porn videos have shown, this isn't\nmerely an academic concern, it is actively been exploited. I posit that this\nexploitation is only going to get more insidious. In this position paper, I\nintroduce a long term project that aims to mitigate some of the most egregious\nforms of manipulation by embedding trustworthy components in the video\ntransmission chain. Unlike earlier works, I am not aiming to do tamper\ndetection or other forms of forensics -- approaches I think are bound to fail\nin the face of the reality of necessary editing and compression -- instead, the\naim here is to provide a way for the video publisher to prove the integrity of\nthe video feed as well as make explicit any edits they may have performed. To\ndo this, I present a novel data structure, a video-edit specification language\nand supporting infrastructure that provides end-to-end video provenance, from\nthe camera sensor to the viewer. I have implemented a prototype of this system\nand am in talks with journalists and video editors to discuss the best ways\nforward with introducing this idea to the mainstream.", "author": {"name": "Mansoor Ahmed-Rengers"}, "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3368860.3368866"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3368860.3368866", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2005.09199v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.09199v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "New Security Paradigms Workshop, 2019"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.MM", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.03526v1", "updated": "2020-06-05T15:58:54Z", "published": "2020-06-05T15:58:54Z", "title": "Ratioing the President: An exploration of public engagement with Obama\n  and Trump on Twitter", "summary": "The past decade has witnessed a marked increase in the use of social media by\npoliticians, most notably exemplified by the 45th President of the United\nStates (POTUS), Donald Trump. On Twitter, POTUS messages consistently attract\nhigh levels of engagement as measured by likes, retweets, and replies. Here, we\nquantify the balance of these activities, also known as \"ratios\", and study\ntheir dynamics as a proxy for collective political engagement in response to\npresidential communications. We find that raw activity counts increase during\nthe period leading up to the 2016 election, accompanied by a regime change in\nthe ratio of retweets-to-replies connected to the transition between\ncampaigning and governing. For the Trump account, we find words related to fake\nnews and the Mueller inquiry are more common in tweets with a high number of\nreplies relative to retweets. Finally, we find that Barack Obama consistently\nreceived a higher retweet-to-reply ratio than Donald Trump. These results\nsuggest Trump's Twitter posts are more often controversial and subject to\nenduring engagement as a given news cycle unfolds.", "author": [{"name": "Joshua R. Minot"}, {"name": "Michael V. Arnold"}, {"name": "Thayer Alshaabi"}, {"name": "Christopher M. Danforth"}, {"name": "Peter Sheridan Dodds"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1371/journal.pone.0248880"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1371/journal.pone.0248880", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2006.03526v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.03526v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "17 pages, 10 figures"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2006.05557v2", "updated": "2020-08-17T20:54:46Z", "published": "2020-06-09T23:40:51Z", "title": "ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research", "summary": "First identified in Wuhan, China, in December 2019, the outbreak of COVID-19\nhas been declared as a global emergency in January, and a pandemic in March\n2020 by the World Health Organization (WHO). Along with this pandemic, we are\nalso experiencing an \"infodemic\" of information with low credibility such as\nfake news and conspiracies. In this work, we present ReCOVery, a repository\ndesigned and constructed to facilitate research on combating such information\nregarding COVID-19. We first broadly search and investigate ~2,000 news\npublishers, from which 60 are identified with extreme [high or low] levels of\ncredibility. By inheriting the credibility of the media on which they were\npublished, a total of 2,029 news articles on coronavirus, published from\nJanuary to May 2020, are collected in the repository, along with 140,820 tweets\nthat reveal how these news articles have spread on the Twitter social network.\nThe repository provides multimodal information of news articles on coronavirus,\nincluding textual, visual, temporal, and network information. The way that news\ncredibility is obtained allows a trade-off between dataset scalability and\nlabel accuracy. Extensive experiments are conducted to present data statistics\nand distributions, as well as to provide baseline performances for predicting\nnews credibility so that future methods can be compared. Our repository is\navailable at http://coronavirus-fakenews.com.", "author": [{"name": "Xinyi Zhou"}, {"name": "Apurva Mulay"}, {"name": "Emilio Ferrara"}, {"name": "Reza Zafarani"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3340531.3412880"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3340531.3412880", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2006.05557v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2006.05557v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Proceedings of the 29th ACM International Conference on Information\n  and Knowledge Management (CIKM '20)"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.05185v1", "updated": "2020-07-10T06:08:50Z", "published": "2020-07-10T06:08:50Z", "title": "Games of Social Distancing during an Epidemic: Local vs Statistical\n  Information", "summary": "The spontaneous behavioral changes of the agents during an epidemic can have\nsignificant effects on the delay and the prevalence of its spread. In this\nwork, we study a social distancing game among the agents of a population, who\ndetermine their social interactions during the spread of an epidemic. The\ninterconnections between the agents are modeled by a network and local\ninteractions are considered. The payoffs of the agents depend on their benefits\nfrom their social interactions, as well as on the costs to their health due to\ntheir possible contamination. The information available to the agents during\nthe decision making plays a crucial role in our model. We examine two extreme\ncases. In the first case, the agents know exactly the health states of their\nneighbors and in the second they have statistical information for the global\nprevalence of the epidemic. The Nash equilibria of the games are studied and,\ninterestingly, in the second case the equilibrium strategies for an agent are\neither full isolation or no social distancing at all. Experimental studies are\npresented through simulations, where we observe that in the first case of\nperfect local information the agents can affect significantly the prevalence of\nthe epidemic with low cost for their sociability, while in the second case they\nhave to pay the burden of not being well informed. Moreover, the effects of the\ninformation quality (fake news), the health care system capacity and the\nnetwork structure are discussed and relevant simulations are provided, which\nindicate that these parameters affect the size, the peak and the start of the\noutbreak, as well as the possibility of a second outbreak.", "author": [{"name": "A. -R. Lagos"}, {"name": "I. Kordonis"}, {"name": "G. P. Papavassilopoulos"}], "link": [{"@href": "http://arxiv.org/abs/2007.05185v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.05185v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.09703v1", "updated": "2020-07-19T16:14:58Z", "published": "2020-07-19T16:14:58Z", "title": "A curated collection of COVID-19 online datasets", "summary": "One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data.", "author": [{"name": "Isa Inuwa-Dutse"}, {"name": "Ioannis Korkontzelos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10 pages, 7 figures"}, "link": [{"@href": "http://arxiv.org/abs/2007.09703v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.09703v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2007.10534v2", "updated": "2020-09-20T23:51:37Z", "published": "2020-07-21T00:07:17Z", "title": "Check_square at CheckThat! 2020: Claim Detection in Social Media via\n  Fusion of Transformer and Syntactic Features", "summary": "In this digital age of news consumption, a news reader has the ability to\nreact, express and share opinions with others in a highly interactive and fast\nmanner. As a consequence, fake news has made its way into our daily life\nbecause of very limited capacity to verify news on the Internet by large\ncompanies as well as individuals. In this paper, we focus on solving two\nproblems which are part of the fact-checking ecosystem that can help to\nautomate fact-checking of claims in an ever increasing stream of content on\nsocial media. For the first problem, claim check-worthiness prediction, we\nexplore the fusion of syntactic features and deep transformer Bidirectional\nEncoder Representations from Transformers (BERT) embeddings, to classify\ncheck-worthiness of a tweet, i.e. whether it includes a claim or not. We\nconduct a detailed feature analysis and present our best performing models for\nEnglish and Arabic tweets. For the second problem, claim retrieval, we explore\nthe pre-trained embeddings from a Siamese network transformer model\n(sentence-transformers) specifically trained for semantic textual similarity,\nand perform KD-search to retrieve verified claims with respect to a query\ntweet.", "author": [{"name": "Gullal S. Cheema"}, {"name": "Sherzod Hakimov"}, {"name": "Ralph Ewerth"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "CLEF2020-CheckThat!"}, "link": [{"@href": "http://arxiv.org/abs/2007.10534v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.10534v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2007.15121v2", "updated": "2021-05-17T17:10:02Z", "published": "2020-07-29T21:40:01Z", "title": "Exploiting stance hierarchies for cost-sensitive stance detection of Web\n  documents", "summary": "Fact checking is an essential challenge when combating fake news. Identifying\ndocuments that agree or disagree with a particular statement (claim) is a core\ntask in this process. In this context, stance detection aims at identifying the\nposition (stance) of a document towards a claim. Most approaches address this\ntask through a 4-class classification model where the class distribution is\nhighly imbalanced. Therefore, they are particularly ineffective in detecting\nthe minority classes (for instance, 'disagree'), even though such instances are\ncrucial for tasks such as fact-checking by providing evidence for detecting\nfalse claims. In this paper, we exploit the hierarchical nature of stance\nclasses, which allows us to propose a modular pipeline of cascading binary\nclassifiers, enabling performance tuning on a per step and class basis. We\nimplement our approach through a combination of neural and traditional\nclassification models that highlight the misclassification costs of minority\nclasses. Evaluation results demonstrate state-of-the-art performance of our\napproach and its ability to significantly improve the classification\nperformance of the important 'disagree' class.", "author": [{"name": "Arjun Roy"}, {"name": "Pavlos Fafalios"}, {"name": "Asif Ekbal"}, {"name": "Xiaofei Zhu"}, {"name": "Stefan Dietze"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1007/s10844-021-00642-z"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1007/s10844-021-00642-z", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2007.15121v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2007.15121v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This is a pre-print version of the Journal paper published in J\n  Intell Inf Syst (2021) (Springer). https://rdcu.be/ckLiC"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.12723v1", "updated": "2020-08-28T16:20:36Z", "published": "2020-08-28T16:20:36Z", "title": "CD-SEIZ: Cognition-Driven SEIZ Compartmental Model for the Prediction of\n  Information Cascades on Twitter", "summary": "Information spreading social media platforms has become ubiquitous in our\nlives due to viral information propagation regardless of its veracity. Some\ninformation cascades turn out to be viral since they circulated rapidly on the\nInternet. The uncontrollable virality of manipulated or disorientated true\ninformation (fake news) might be quite harmful, while the spread of the true\nnews is advantageous, especially in emergencies. We tackle the problem of\npredicting information cascades by presenting a novel variant of SEIZ\n(Susceptible/ Exposed/ Infected/ Skeptics) model that outperforms the original\nversion by taking into account the cognitive processing depth of users. We\ndefine an information cascade as the set of social media users' reactions to\nthe original content which requires at least minimal physical and cognitive\neffort; therefore, we considered retweet/ reply/ quote (mention) activities and\ntested our framework on the Syrian White Helmets Twitter data set from April\n1st, 2018 to April 30th, 2019. In the prediction of cascade pattern via\ntraditional compartmental models, all the activities are grouped, and their\nsummation is taken into account; however, transition rates between compartments\nshould vary according to the activity type since their requirements of physical\nand cognitive efforts are not same. Based on this assumption, we design a\ncognition-driven SEIZ (CD-SEIZ) model in the prediction of information cascades\non Twitter. We tested SIS, SEIZ, and CD-SEIZ models on 1000 Twitter cascades\nand found that CD-SEIZ has a significantly low fitting error and provides a\nstatistically more accurate estimation.", "author": [{"name": "Ece \u00c7i\u011fdem Mutlu"}, {"name": "Amirarsalan Rajabi"}, {"name": "Ivan Garibay"}], "link": [{"@href": "http://arxiv.org/abs/2008.12723v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.12723v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.IT", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2008.12742v1", "updated": "2020-08-28T16:55:43Z", "published": "2020-08-28T16:55:43Z", "title": "Linked Credibility Reviews for Explainable Misinformation Detection", "summary": "In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task.", "author": [{"name": "Ronald Denaux"}, {"name": "Jose Manuel Gomez-Perez"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted to the 19th International Semantic Web Conference (ISWC\n  2020) https://iswc2020.semanticweb.org"}, "link": [{"@href": "http://arxiv.org/abs/2008.12742v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2008.12742v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2010.03001v4", "updated": "2021-08-24T15:40:14Z", "published": "2020-10-06T20:05:43Z", "title": "A Review on Fact Extraction and Verification", "summary": "We study the fact checking problem, which aims to identify the veracity of a\ngiven claim. Specifically, we focus on the task of Fact Extraction and\nVERification (FEVER) and its accompanied dataset. The task consists of the\nsubtasks of retrieving the relevant documents (and sentences) from Wikipedia\nand validating whether the information in the documents supports or refutes a\ngiven claim. This task is essential and can be the building block of\napplications such as fake news detection and medical claim verification. In\nthis paper, we aim at a better understanding of the challenges of the task by\npresenting the literature in a structured and comprehensive way. We describe\nthe proposed methods by analyzing the technical perspectives of the different\napproaches and discussing the performance results on the FEVER dataset, which\nis the most well-studied and formally structured dataset on the fact extraction\nand verification task. We also conduct the largest experimental study to date\non identifying beneficial loss functions for the sentence retrieval component.\nOur analysis indicates that sampling negative sentences is important for\nimproving the performance and decreasing the computational complexity. Finally,\nwe describe open issues and future challenges, and we motivate future research\nin the task.", "author": [{"name": "Giannis Bekoulis"}, {"name": "Christina Papagiannopoulou"}, {"name": "Nikos Deligiannis"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "author preprint version"}, "link": [{"@href": "http://arxiv.org/abs/2010.03001v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.03001v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.07647v2", "updated": "2021-07-06T09:16:25Z", "published": "2020-10-15T10:31:28Z", "title": "Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised\n  Learning Approach", "summary": "Online Social Media (OSM) platforms such as Twitter, Facebook are extensively\nexploited by the users of these platforms for spreading the (mis)information to\na large audience effortlessly at a rapid pace. It has been observed that the\nmisinformation can cause panic, fear, and financial loss to society. Thus, it\nis important to detect and control the misinformation in such platforms before\nit spreads to the masses. In this work, we focus on rumors, which is one type\nof misinformation (other types are fake news, hoaxes, etc). One way to control\nthe spread of the rumors is by identifying users who are possibly the rumor\nspreaders, that is, users who are often involved in spreading the rumors. Due\nto the lack of availability of rumor spreaders labeled dataset (which is an\nexpensive task), we use publicly available PHEME dataset, which contains rumor\nand non-rumor tweets information, and then apply a weak supervised learning\napproach to transform the PHEME dataset into rumor spreaders dataset. We\nutilize three types of features, that is, user, text, and ego-network features,\nbefore applying various supervised learning approaches. In particular, to\nexploit the inherent network property in this dataset (user-user reply graph),\nwe explore Graph Convolutional Network (GCN), a type of Graph Neural Network\n(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and\nLSTM. Extensive experiments performed on the rumor spreaders dataset, where we\nachieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the\neffectiveness of our methodology for identifying possible rumor spreaders using\nthe GCN technique.", "author": [{"name": "Shakshi Sharma"}, {"name": "Rajesh Sharma"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Published at The International Joint Conference on Neural Networks\n  2021 (IJCNN2021). Please cite the IJCNN version"}, "link": [{"@href": "http://arxiv.org/abs/2010.07647v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.07647v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2011.01523v1", "updated": "2020-11-03T07:31:46Z", "published": "2020-11-03T07:31:46Z", "title": "Model of Trust Management for Digital Industry Services. Towards\n  E-Commerce 4.0", "summary": "The progressive digitalization is changing the way businesses work and\ninteract. Concepts like Internet of Things, Cloud Computing, Industry 4.0,\nService 4.0, Smart Production or Smart Cities are based on systems that are\nlinked to the Internet. The online access to the provided data creates\npotential to optimize processes and cost reductions, but also exposes it to a\nrisk for an inappropriate use. Trust management systems are necessary in terms\nof data security, but also to assure the trustworthiness of data that is\ndistributed. Fake news in social media is an example for problems with online\ndata that is not trustable. Security and trustworthiness of data are major\nconcerns today. The speed in digitalization makes it even a greater challenge\nfor future research. This article introduces therefore a model of online trust\ncontent usable to compute the trust of an online service advertisement. It\ncontributes to standardize business service descriptions necessary to realize\nvisions of E-commerce 4.0, because it is the basis for the development of AI\nsystems that are able to match an service request to a service advertisement.\nIt is necessary for building trust enhancing architectures in B2B e-commerce.\nTo do so, we conducted case studies, analysed websites, developed a prototype\nsystem and verified it by conducting expert interviews.", "author": [{"name": "Wolfgang Bauer", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Comenius University in Bratislava, Information Systems Department"}}, {"name": "Natalia Kryvinska", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Comenius University in Bratislava, Information Systems Department"}}, {"name": "J\u00fcrgen Dorn", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Technical University in Vienna, Institute for Information Systems Engineering"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "12 pages, 16 figures"}, "link": [{"@href": "http://arxiv.org/abs/2011.01523v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2011.01523v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "E.m", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.01876v1", "updated": "2020-12-03T12:45:29Z", "published": "2020-12-03T12:45:29Z", "title": "Optimizing sensors placement in complex networks for localization of\n  hidden signal source: A review", "summary": "As the world becomes more and more interconnected, our everyday objects\nbecome part of the Internet of Things, and our lives get more and more mirrored\nin virtual reality, where every piece of~information, including misinformation,\nfake news and malware, can spread very fast practically anonymously. To\nsuppress such uncontrolled spread, efficient computer systems and algorithms\ncapable to~track down such malicious information spread have to be developed.\nCurrently, the most effective methods for source localization are based on\nsensors which provide the times at which they detect the~spread. We investigate\nthe problem of the optimal placement of such sensors in complex networks and\npropose a new graph measure, called Collective Betweenness, which we compare\nagainst four other metrics. Extensive numerical tests are performed on\ndifferent types of complex networks over the wide ranges of densities of\nsensors and stochasticities of signal. In these tests, we discovered clear\ndifference in comparative performance of the investigated optimal placement\nmethods between real or scale-free synthetic networks versus narrow degree\ndistribution networks. The former have a clear region for any given method's\ndominance in contrast to the latter where the performance maps are less\nhomogeneous. We find that while choosing the best method is very network and\nspread dependent, there are two methods that consistently stand out. High\nVariance Observers seem to do very well for spread with low stochasticity\nwhereas Collective Betwenness, introduced in this paper, thrives when the\nspread is highly unpredictable.", "author": [{"name": "Robert Paluch"}, {"name": "\u0141ukasz G. Gajewski"}, {"name": "Janusz A. Ho\u0142yst"}, {"name": "Boleslaw K. Szymanski"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.future.2020.06.023"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.future.2020.06.023", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2012.01876v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.01876v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "28 pages, 18 figures, 11 tables"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Future Generation Computer Systems, Volume 112, November 2020,\n  Pages 1070-1092"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.data-an", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2012.04252v2", "updated": "2021-03-09T14:30:33Z", "published": "2020-12-08T07:12:47Z", "title": "Increase of Low-Frequency Modes of User Dynamics in Online Social\n  Networks During Overheating of Discussions", "summary": "User dynamics in online social networks have a significant impact on not only\nthe online community but also real-world activities. As examples, we can\nmention explosive user dynamics triggered by social polarization, echo chamber\nphenomena, fake news, etc. Explosive user dynamics are frequently called online\nflaming. The wave equation-based model for online social networks (called the\noscillation model) is a theoretical model proposed to describe user dynamics in\nonline social networks. This model can be used to understand the relationship\nbetween explosive user dynamics and the structure of social networks. However,\nsince the oscillation model was introduced as a purely theoretical model of\nsocial networks, it is necessary to confirm whether the model describes real\nphenomena correctly or not. In this paper, we first show a prediction from the\noscillation model; the low-frequency oscillation mode of user dynamics will be\ndominant when the structure of online social networks changes so that user\nactivity is activated. To verify the predictions with actual data, we show\nspectral analyses of both the log data of posts on an electronic bulletin board\nsite and the frequency data of word search from Google Trends. The results\nsupport the predictions from the theoretical model.", "author": [{"name": "Masaki Aida"}, {"name": "Koichi Nagatani"}, {"name": "Chisa Takano"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "14 pages, 23 figures, submitted to Physical Review Research"}, "link": [{"@href": "http://arxiv.org/abs/2012.04252v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2012.04252v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.10112v1", "updated": "2021-01-22T03:42:36Z", "published": "2021-01-22T03:42:36Z", "title": "Fringe News Networks: Dynamics of US News Viewership following the 2020\n  Presidential Election", "summary": "The growing political polarization of the American electorate over the last\nseveral decades has been widely studied and documented. During the\nadministration of President Donald Trump, charges of \"fake news\" made social\nand news media not only the means but, to an unprecedented extent, the topic of\npolitical communication. Using data from before the November 3rd, 2020 US\nPresidential election, recent work has demonstrated the viability of using\nYouTube's social media ecosystem to obtain insights into the extent of US\npolitical polarization as well as the relationship between this polarization\nand the nature of the content and commentary provided by different US news\nnetworks. With that work as background, this paper looks at the sharp\ntransformation of the relationship between news consumers and here-to-fore\n\"fringe\" news media channels in the 64 days between the US presidential\nelection and the violence that took place at US Capitol on January 6th. This\npaper makes two distinct types of contributions. The first is to introduce a\nnovel methodology to analyze large social media data to study the dynamics of\nsocial political news networks and their viewers. The second is to provide\ninsights into what actually happened regarding US political social media\nchannels and their viewerships during this volatile 64 day period.", "author": [{"name": "Ashiqur R. KhudaBukhsh"}, {"name": "Rupak Sarkar"}, {"name": "Mark S. Kamlet"}, {"name": "Tom M. Mitchell"}], "link": [{"@href": "http://arxiv.org/abs/2101.10112v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.10112v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.11978v1", "updated": "2021-01-28T13:05:09Z", "published": "2021-01-28T13:05:09Z", "title": "Semi-automatic Generation of Multilingual Datasets for Stance Detection\n  in Twitter", "summary": "Popular social media networks provide the perfect environment to study the\nopinions and attitudes expressed by users. While interactions in social media\nsuch as Twitter occur in many natural languages, research on stance detection\n(the position or attitude expressed with respect to a specific topic) within\nthe Natural Language Processing field has largely been done for English.\nAlthough some efforts have recently been made to develop annotated data in\nother languages, there is a telling lack of resources to facilitate\nmultilingual and crosslingual research on stance detection. This is partially\ndue to the fact that manually annotating a corpus of social media texts is a\ndifficult, slow and costly process. Furthermore, as stance is a highly domain-\nand topic-specific phenomenon, the need for annotated data is specially\ndemanding. As a result, most of the manually labeled resources are hindered by\ntheir relatively small size and skewed class distribution. This paper presents\na method to obtain multilingual datasets for stance detection in Twitter.\nInstead of manually annotating on a per tweet basis, we leverage user-based\ninformation to semi-automatically label large amounts of tweets. Empirical\nmonolingual and cross-lingual experimentation and qualitative analysis show\nthat our method helps to overcome the aforementioned difficulties to build\nlarge, balanced and multilingual labeled corpora. We believe that our method\ncan be easily adapted to easily generate labeled social media data for other\nNatural Language Processing tasks and domains.", "author": [{"name": "Elena Zotova"}, {"name": "Rodrigo Agerri"}, {"name": "German Rigau"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1016/j.eswa.2020.114547"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1016/j.eswa.2020.114547", "@rel": "related"}, {"@href": "http://arxiv.org/abs/2101.11978v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.11978v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Stance detection, multilingualism, text categorization, fake news,\n  deep learning"}, "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Expert Systems with Applications, 170 (2021), Elsevier"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2102.04293v1", "updated": "2021-02-04T22:54:44Z", "published": "2021-02-04T22:54:44Z", "title": "High-level Approaches to Detect Malicious Political Activity on Twitter", "summary": "Our work represents another step into the detection and prevention of these\never-more present political manipulation efforts. We, therefore, start by\nfocusing on understanding what the state-of-the-art approaches lack -- since\nthe problem remains, this is a fair assumption. We find concerning issues\nwithin the current literature and follow a diverging path. Notably, by placing\nemphasis on using data features that are less susceptible to malicious\nmanipulation and also on looking for high-level approaches that avoid a\ngranularity level that is biased towards easy-to-spot and low impact cases.\n  We designed and implemented a framework -- Twitter Watch -- that performs\nstructured Twitter data collection, applying it to the Portuguese\nTwittersphere. We investigate a data snapshot taken on May 2020, with around 5\nmillion accounts and over 120 million tweets (this value has since increased to\nover 175 million). The analyzed time period stretches from August 2019 to May\n2020, with a focus on the Portuguese elections of October 6th, 2019. However,\nthe Covid-19 pandemic showed itself in our data, and we also delve into how it\naffected typical Twitter behavior.\n  We performed three main approaches: content-oriented, metadata-oriented, and\nnetwork interaction-oriented. We learn that Twitter's suspension patterns are\nnot adequate to the type of political trolling found in the Portuguese\nTwittersphere -- identified by this work and by an independent peer - nor to\nfake news posting accounts. We also surmised that the different types of\nmalicious accounts we independently gathered are very similar both in terms of\ncontent and interaction, through two distinct analysis, and are simultaneously\nvery distinct from regular accounts.", "author": {"name": "Miguel Sozinho Ramalho"}, "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Master's thesis"}, "link": [{"@href": "http://arxiv.org/abs/2102.04293v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2102.04293v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2103.00747v1", "updated": "2021-03-01T04:28:39Z", "published": "2021-03-01T04:28:39Z", "title": "Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models", "summary": "Misinformation of COVID-19 is prevalent on social media as the pandemic\nunfolds, and the associated risks are extremely high. Thus, it is critical to\ndetect and combat such misinformation. Recently, deep learning models using\nnatural language processing techniques, such as BERT (Bidirectional Encoder\nRepresentations from Transformers), have achieved great successes in detecting\nmisinformation. In this paper, we proposed an explainable natural language\nprocessing model based on DistilBERT and SHAP (Shapley Additive exPlanations)\nto combat misinformation about COVID-19 due to their efficiency and\neffectiveness. First, we collected a dataset of 984 claims about COVID-19 with\nfact checking. By augmenting the data using back-translation, we doubled the\nsample size of the dataset and the DistilBERT model was able to obtain good\nperformance (accuracy: 0.972; areas under the curve: 0.993) in detecting\nmisinformation about COVID-19. Our model was also tested on a larger dataset\nfor AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good\nperformance (accuracy: 0.938; areas under the curve: 0.985). The performance on\nboth datasets was better than traditional machine learning models. Second, in\norder to boost public trust in model prediction, we employed SHAP to improve\nmodel explainability, which was further evaluated using a between-subjects\nexperiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),\nand text+SHAP explanation+source and evidence (TSESE). The participants were\nsignificantly more likely to trust and share information related to COVID-19 in\nthe TSE and TSESE conditions than in the T condition. Our results provided good\nimplications in detecting misinformation about COVID-19 and improving public\ntrust.", "author": [{"name": "Jackie Ayoub"}, {"name": "X. Jessie Yang"}, {"name": "Feng Zhou"}], "link": [{"@href": "http://arxiv.org/abs/2103.00747v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.00747v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2103.12191v1", "updated": "2021-03-22T21:44:32Z", "published": "2021-03-22T21:44:32Z", "title": "Using an Epidemiological Model to Study the Spread of Misinformation\n  during the Black Lives Matter Movement", "summary": "The proliferation of social media platforms like Twitter has heightened the\nconsequences of the spread of misinformation. To understand and model the\nspread of misinformation, in this paper, we leveraged the SEIZ (Susceptible,\nExposed, Infected, Skeptics) epidemiological model to describe the underlying\nprocess that delineates the spread of misinformation on Twitter. Compared to\nthe other epidemiological models, this model produces broader results because\nit includes the additional Skeptics (Z) compartment, wherein a user may be\nexposed to an item of misinformation but not engage in any reaction to it, and\nthe additional Exposed (E) compartment, wherein the user may need some time\nbefore deciding to spread a misinformation item. We analyzed misinformation\nregarding the unrest in Washington, D.C. in the month of March 2020 which was\npropagated by the use of the #DCblackout hashtag by different users across the\nU.S. on Twitter. Our analysis shows that misinformation can be modeled using\nthe concept of epidemiology. To the best of our knowledge, this research is the\nfirst to attempt to apply the SEIZ epidemiological model to the spread of a\nspecific item of misinformation, which is a category distinct from that of\nrumor, and a hoax on online social media platforms. Applying a mathematical\nmodel can help to understand the trends and dynamics of the spread of\nmisinformation on Twitter and ultimately help to develop techniques to quickly\nidentify and control it.", "author": [{"name": "Maryam Maleki"}, {"name": "Esther Mead"}, {"name": "Mohammad Arani"}, {"name": "Nitin Agarwal"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "This paper is accepted on the International Conference on Fake News,\n  Social Media Manipulation and Misinformation 2021 (ICFNSMMM 2021)"}, "link": [{"@href": "http://arxiv.org/abs/2103.12191v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2103.12191v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2104.07423v1", "updated": "2021-04-15T12:39:37Z", "published": "2021-04-15T12:39:37Z", "title": "The Role of Context in Detecting Previously Fact-Checked Claims", "summary": "Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.", "author": [{"name": "Shaden Shaar"}, {"name": "Firoj Alam"}, {"name": "Giovanni Da San Martino"}, {"name": "Preslav Nakov"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "detecting previously fact-checked claims, fact-checking,\n  disinformation, fake news, social media, political debates"}, "link": [{"@href": "http://arxiv.org/abs/2104.07423v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2104.07423v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CL", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.IR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.LG", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.NE", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "68T50", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "F.2.2; I.2.7", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2105.08827v1", "updated": "2021-05-18T20:55:11Z", "published": "2021-05-18T20:55:11Z", "title": "Educators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing\n  Roles in Online Extremist Movements", "summary": "Social media provides the means by which extremist social movements, such as\nwhite supremacy and anti LGBTQ, thrive online. Yet, we know little about the\nroles played by the participants of such movements. In this paper, we\ninvestigate these participants to characterize their roles, their role\ndynamics, and their influence in spreading online extremism. Our participants,\nonline extremist accounts, are 4,876 public Facebook pages or groups that have\nshared information from the websites of 289 Southern Poverty Law Center\ndesignated extremist groups. By clustering the quantitative features followed\nby qualitative expert validation, we identify five roles surrounding extremist\nactivism: educators, solicitors, flamers, motivators, sympathizers. For\nexample, solicitors use links from extremist websites to attract donations and\nparticipation in extremist issues, whereas flamers share inflammatory extremist\ncontent inciting anger. We further investigate role dynamics such as, how\nstable these roles are over time and how likely will extremist accounts\ntransition from one role into another. We find that roles core to the movement,\neducators and solicitors, are more stable, while flamers and motivators can\ntransition to sympathizers with high probability. We further find that\neducators and solicitors exert the most influence in triggering extremist link\nposts, whereas flamers are influential in triggering the spread of information\nfrom fake news sources. Our results help in situating various roles on the\ntrajectory of deeper engagement into the extremist movements and understanding\nthe potential effect of various counter extremism interventions. Our findings\nhave implications for understanding how online extremist movements flourish\nthrough participatory activism and how they gain a spectrum of allies for\nmobilizing extremism online.", "author": [{"name": "Shruti Phadke"}, {"name": "Tanushree Mitra"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Accepted at Computer Supported Cooperative Work (CSCW 2021)"}, "link": [{"@href": "http://arxiv.org/abs/2105.08827v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2105.08827v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.HC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.01784v1", "updated": "2021-06-03T12:16:08Z", "published": "2021-06-03T12:16:08Z", "title": "The Contestation of Tech Ethics: A Sociotechnical Approach to Ethics and\n  Technology in Action", "summary": "Recent controversies related to topics such as fake news, privacy, and\nalgorithmic bias have prompted increased public scrutiny of digital\ntechnologies and soul-searching among many of the people associated with their\ndevelopment. In response, the tech industry, academia, civil society, and\ngovernments have rapidly increased their attention to \"ethics\" in the design\nand use of digital technologies (\"tech ethics\"). Yet almost as quickly as\nethics discourse has proliferated across the world of digital technologies, the\nlimitations of these approaches have also become apparent: tech ethics is vague\nand toothless, is subsumed into corporate logics and incentives, and has a\nmyopic focus on individual engineers and technology design rather than on the\nstructures and cultures of technology production. As a result of these\nlimitations, many have grown skeptical of tech ethics and its proponents,\ncharging them with \"ethics-washing\": promoting ethics research and discourse to\ndefuse criticism and government regulation without committing to ethical\nbehavior. By looking at how ethics has been taken up in both science and\nbusiness in superficial and depoliticizing ways, I recast tech ethics as a\nterrain of contestation where the central fault line is not whether it is\ndesirable to be ethical, but what \"ethics\" entails and who gets to define it.\nThis framing highlights the significant limits of current approaches to tech\nethics and the importance of studying the formulation and real-world effects of\ntech ethics. In order to identify and develop more rigorous strategies for\nreforming digital technologies and the social relations that they mediate, I\ndescribe a sociotechnical approach to tech ethics, one that reflexively applies\nmany of tech ethics' own lessons regarding digital technologies to tech ethics\nitself.", "author": {"name": "Ben Green"}, "link": [{"@href": "http://arxiv.org/abs/2106.01784v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.01784v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2106.14490v1", "updated": "2021-06-28T09:09:14Z", "published": "2021-06-28T09:09:14Z", "title": "Making Images Real Again: A Comprehensive Survey on Deep Image\n  Composition", "summary": "As a common image editing operation, image composition aims to cut the\nforeground from one image and paste it on another image, resulting in a\ncomposite image. However, there are many issues that could make the composite\nimages unrealistic. These issues can be summarized as the inconsistency between\nforeground and background, which include appearance inconsistency (e.g.,\nincompatible color and illumination) and geometry inconsistency (e.g.,\nunreasonable size and location). Previous works on image composition target at\none or more issues. Since each individual issue is a complicated problem, there\nare some research directions (e.g., image harmonization, object placement)\nwhich focus on only one issue. By putting all the efforts together, we can\nacquire realistic composite images. Sometimes, we expect the composite images\nto be not only realistic but also aesthetic, in which case aesthetic evaluation\nneeds to be considered. In this survey, we summarize the datasets and methods\nfor the above research directions. We also discuss the limitations and\npotential directions to facilitate the future research for image composition.\nFinally, as a double-edged sword, image composition may also have negative\neffect on our lives (e.g., fake news) and thus it is imperative to develop\nalgorithms to fight against composite images. Datasets and codes for image\ncomposition are summarized at\nhttps://github.com/bcmi/Awesome-Image-Composition.", "author": [{"name": "Li Niu"}, {"name": "Wenyan Cong"}, {"name": "Liu Liu"}, {"name": "Yan Hong"}, {"name": "Bo Zhang"}, {"name": "Jing Liang"}, {"name": "Liqing Zhang"}], "link": [{"@href": "http://arxiv.org/abs/2106.14490v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2106.14490v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.00153v2", "updated": "2021-07-14T23:30:49Z", "published": "2021-07-01T00:11:04Z", "title": "Root and community inference on the latent growth process of a network\n  using noisy attachment models", "summary": "We introduce the PAPER (Preferential Attachment Plus Erd\\H{o}s--R\\'{e}nyi)\nmodel for random networks, where we let a random network G be the union of a\npreferential attachment (PA) tree T and additional Erd\\H{o}s--R\\'{e}nyi (ER)\nrandom edges. The PA tree component captures the fact that real world networks\noften have an underlying growth/recruitment process where vertices and edges\nare added sequentially, while the ER component can be regarded as random noise.\nGiven only a single snapshot of the final network G, we study the problem of\nconstructing confidence sets for the early history, in particular the root\nnode, of the unobserved growth process; the root node can be patient zero in a\ndisease infection network or the source of fake news in a social media network.\nWe propose an inference algorithm based on Gibbs sampling that scales to\nnetworks with millions of nodes and provide theoretical analysis showing that\nthe expected size of the confidence set is small so long as the noise level of\nthe ER edges is not too large. We also propose variations of the model in which\nmultiple growth processes occur simultaneously, reflecting the growth of\nmultiple communities, and we use these models to provide a new approach\ncommunity detection.", "author": [{"name": "Harry Crane"}, {"name": "Min Xu"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "52 pages; 20 figures"}, "link": [{"@href": "http://arxiv.org/abs/2107.00153v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.00153v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "stat.ME", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "stat.ME", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "math.PR", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "stat.CO", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "62M99, 05C80", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.12073v1", "updated": "2021-07-26T09:51:54Z", "published": "2021-07-26T09:51:54Z", "title": "Uncovering the structure of the French media ecosystem", "summary": "This study provides a large-scale mapping of the French media space using\ndigital methods to estimate political polarization and to study information\ncircuits. We collect data about the production and circulation of online news\nstories in France over the course of one year, adopting a multi-layer\nperspective on the media ecosystem. We source our data from websites, Twitter\nand Facebook. We also identify a certain number of important structural\nfeatures. A stochastic block model of the hyperlinks structure shows the\nsystematic rejection of counter-informational press in a separate cluster which\nhardly receives any attention from the mainstream media. Counter-informational\nsub-spaces are also peripheral on the consumption side. We measure their\nrespective audiences on Twitter and Facebook and do not observe a large\ndiscrepancy between both social networks, with counter-information space, far\nright and far left media gathering limited audiences. Finally, we also measure\nthe ideological distribution of news stories using Twitter data, which also\nsuggests that the French media landscape is quite balanced. We therefore\nconclude that the French media ecosystem does not suffer from the same level of\npolarization as the US media ecosystem. The comparison with the American\nsituation also allows us to consolidate a result from studies on\ndisinformation: the polarization of the journalistic space and the circulation\nof fake news are phenomena that only become more widespread when dominant and\ninfluential actors in the political or journalistic space spread topics and\ndubious content originally circulating in the fringe of the information space.", "author": [{"name": "Jean-Philippe Cointet", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}, {"name": "Dominique Cardon", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}, {"name": "Andre\u00ef Mogoutov", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}, {"name": "Benjamin Ooghe-Tabanou", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}, {"name": "Guillaume Plique", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}, {"name": "Pedro Morales", "arxiv:affiliation": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "M\u00e9dialab"}}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "IC2S2, Jul 2021, Zurich, Switzerland"}, "link": [{"@href": "http://arxiv.org/abs/2107.12073v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.12073v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1807.06147v1", "updated": "2018-07-16T23:08:44Z", "published": "2018-07-16T23:08:44Z", "title": "Tracking Elections: our experience during the presidential elections in\n  Ecuador", "summary": "The world's digital transformation has influenced not only the way we do\nbusiness, but also the way we perform daily activities. In fact, the past\nPresidential elections in the United States as well as those in Great Britain\n(Brexit) and in Colombia (peace agreement referendum) are proof that social\nmedia play an important part in modern politics. In fact, this digital\npolitical field is filled by political movements and political candidates\nlooking for popular support (number of followers), regular citizens' messages\ndiscussing social issues (trending topics flooding social media), or even\npolitical propaganda in favor or against politicians or political movements\n(advertisement). One of the issues with social media in this era is the\npresence of automatic accounts (bots) that artificially fill accounts with fake\nfollowers, create false trending topics, and share fake news or simply flood\nthe net with propaganda. All this artificial information may influence people\nand sometimes may even censor people's real opinions undermining their freedom\nof speech. In this paper, we propose a methodology to track elections and a set\nof tools used to collect and analyze election data. In particular, this paper\ndiscusses our experiences during the Presidential Elections in Ecuador held in\n2017. In fact, we show how all candidates prepared an online campaign in social\nmedia (Twitter) and how the political campaign altered a common follower rate\nsubscription. We discuss that the high presence of followers during the period\nbetween the first and second round of elections may be altered by automatic\naccounts. Finally, we use bot detection systems and gathered more than 30,000\npolitical motivated bots. In our data analysis, we show that these bots were\nmainly used for propaganda purposes in favor or against a particular candidate.", "author": [{"name": "Daniel Riofrio"}, {"name": "Anacaren Ruiz"}, {"name": "Erin Sosebee"}, {"name": "Qasim Raza"}, {"name": "Adnan Bashir"}, {"name": "Jed Crandall"}], "link": [{"@href": "http://arxiv.org/abs/1807.06147v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1807.06147v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/1804.03461v3", "updated": "2019-01-18T18:12:27Z", "published": "2018-04-10T11:31:27Z", "title": "The Web of False Information: Rumors, Fake News, Hoaxes, Clickbait, and\n  Various Other Shenanigans", "summary": "A new era of Information Warfare has arrived. Various actors, including\nstate-sponsored ones, are weaponizing information on Online Social Networks to\nrun false information campaigns with targeted manipulation of public opinion on\nspecific topics. These false information campaigns can have dire consequences\nto the public: mutating their opinions and actions, especially with respect to\ncritical world events like major elections. Evidently, the problem of false\ninformation on the Web is a crucial one, and needs increased public awareness,\nas well as immediate attention from law enforcement agencies, public\ninstitutions, and in particular, the research community. In this paper, we make\na step in this direction by providing a typology of the Web's false information\necosystem, comprising various types of false information, actors, and their\nmotives. We report a comprehensive overview of existing research on the false\ninformation ecosystem by identifying several lines of work: 1) how the public\nperceives false information; 2) understanding the propagation of false\ninformation; 3) detecting and containing false information on the Web; and 4)\nfalse information on the political stage. In this work, we pay particular\nattention to political false information as: 1) it can have dire consequences\nto the community (e.g., when election results are mutated) and 2) previous work\nshow that this type of false information propagates faster and further when\ncompared to other types of false information. Finally, for each of these lines\nof work, we report several future research directions that can help us better\nunderstand and mitigate the emerging problem of false information dissemination\non the Web.", "author": [{"name": "Savvas Zannettou"}, {"name": "Michael Sirivianos"}, {"name": "Jeremy Blackburn"}, {"name": "Nicolas Kourtellis"}], "arxiv:doi": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "10.1145/3309699"}, "link": [{"@title": "doi", "@href": "http://dx.doi.org/10.1145/3309699", "@rel": "related"}, {"@href": "http://arxiv.org/abs/1804.03461v3", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1804.03461v3", "@rel": "related", "@type": "application/pdf"}], "arxiv:journal_ref": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Journal of Data and Information Quality (JDIQ) 2019"}, "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1907.00498v4", "updated": "2020-07-08T22:48:11Z", "published": "2019-06-30T23:46:30Z", "title": "Proof of Witness Presence: Blockchain Consensus for Augmented Democracy\n  in Smart Cities", "summary": "Smart Cities evolve into complex and pervasive urban environments with a\ncitizens' mandate to meet sustainable development goals. Repositioning\ndemocratic values of citizens' choices in these complex ecosystems has turned\nout to be imperative in an era of social media filter bubbles, fake news and\nopportunities for manipulating electoral results with such means. This paper\nintroduces a new paradigm of augmented democracy that promises actively\nengaging citizens in a more informed decision-making augmented into public\nurban space. The proposed concept is inspired by a digital revive of the\nAncient Agora of Athens, an arena of public discourse, a Polis where citizens\nassemble to actively deliberate and collectively decide about public matters.\nThe core contribution of the proposed paradigm is the concept of proving\nwitness presence: making decision-making subject of providing secure evidence\nand testifying for choices made in the physical space. This paper shows how the\nchallenge of proving witness presence can be tackled with blockchain consensus\nto empower citizens' trust and overcome security vulnerabilities of GPS\nlocalization. Moreover, a novel platform for collective decision-making and\ncrowd-sensing in urban space is introduced: Smart Agora. It is shown how\nreal-time collective measurements over citizens' choices can be made in a fully\ndecentralized and privacy-preserving way. Witness presence is tested by\ndeploying a decentralized system for crowd-sensing the sustainable use of\ntransport means. Furthermore, witness presence of cycling risk is validated\nusing official accident data from public authorities, which are compared\nagainst wisdom of the crowd. The paramount role of dynamic consensus,\nself-governance and ethically aligned artificial intelligence in the augmented\ndemocracy paradigm is outlined.", "author": {"name": "Evangelos Pournaras"}, "link": [{"@href": "http://arxiv.org/abs/1907.00498v4", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1907.00498v4", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CY", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DC", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/1909.00530v2", "updated": "2019-09-04T02:50:01Z", "published": "2019-09-02T03:47:57Z", "title": "Burning Two Worlds: Algorithms for Burning Dense and Tree-like Graphs", "summary": "Graph burning is a simple model for the spread of social influence in\nnetworks. The objective is to measure how quickly a fire (e.g., a piece of fake\nnews) can be spread in a network. The burning process takes place in discrete\nrounds. In each round, a new fire breaks out at a selected vertex and burns it.\nMeanwhile, the old fires extend to their neighbours and burn them. A burning\nschedule selects where the new fire breaks out in each round, and the burning\nproblem asks for a schedule that burns all vertices in a minimum number of\nrounds, termed the burning number of the graph. The burning problem is known to\nbe NP-hard even when the graph is a tree or a disjoint set of paths. For\nconnected graphs, it has been conjectured that burning takes at most $\\lceil\n\\sqrt{n} \\rceil$ rounds.\n  We approach the algorithmic study of graph burning from two directions.\nFirst, we consider graphs with minimum degree $\\delta$. We present an algorithm\nthat burns any graph of size $n$ in at most $\\sqrt{\\frac{24n}{\\delta+1}}$\nrounds. In particular, for dense graphs with $\\delta \\in \\Theta(n)$, all\nvertices are burned in a constant number of rounds. More interestingly, even\nwhen $\\delta$ is a constant that is independent of the graph size, our\nalgorithm answers the graph-burning conjecture in the affirmative by burning\nthe graph in at most $\\lceil \\sqrt{n} \\rceil$ rounds. Next, we consider burning\ngraphs with bounded path-length or tree-length. These include many graph\nfamilies including connected interval graphs and connected chordal graphs. We\nshow that any graph with path-length $pl$ and diameter $d$ can be burned in\n$\\lceil \\sqrt{d-1} \\rceil + pl$ rounds. Our algorithm ensures an approximation\nratio of $1+o(1)$ for graphs of bounded path-length. We introduce another\nalgorithm that achieves an approximation ratio of $2+o(1)$ for burning graphs\nof bounded tree-length.", "author": [{"name": "Shahin Kamali"}, {"name": "Avery Miller"}, {"name": "Kenny Zhang"}], "link": [{"@href": "http://arxiv.org/abs/1909.00530v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/1909.00530v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "math.CO", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "math.CO", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.DS", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2003.07010v2", "updated": "2020-07-13T17:00:58Z", "published": "2020-03-16T04:01:09Z", "title": "Adversarial Perturbations of Opinion Dynamics in Networks", "summary": "We study the connections between network structure, opinion dynamics, and an\nadversary's power to artificially induce disagreements. We approach these\nquestions by extending models of opinion formation in the social sciences to\nrepresent scenarios, familiar from recent events, in which external actors seek\nto destabilize communities through sophisticated information warfare tactics\nvia fake news and bots. In many instances, the intrinsic goals of these efforts\nare not necessarily to shift the overall sentiment of the network, but rather\nto induce discord. These perturbations diffuse via opinion dynamics on the\nunderlying network, through mechanisms that have been analyzed and abstracted\nthrough work in computer science and the social sciences. We investigate the\nproperties of such attacks, considering optimal strategies both for the\nadversary seeking to create disagreement and for the entities tasked with\ndefending the network from attack. We show that for different formulations of\nthese types of objectives, different regimes of the spectral structure of the\nnetwork will limit the adversary's capacity to sow discord; this enables us to\nqualitatively describe which networks are most vulnerable against these\nperturbations. We then consider the algorithmic task of a network defender to\nmitigate these sorts of adversarial attacks by insulating nodes\nheterogeneously; we show that, by considering the geometry of this problem,\nthis optimization task can be efficiently solved via convex programming.\nFinally, we generalize these results to allow for two network structures, where\nthe opinion dynamics process and the measurement of disagreement become\nuncoupled, and determine how the adversary's power changes; for instance, this\nmay arise when opinion dynamics are controlled an online community via social\nmedia, while disagreement is measured along \"real-world\" connections.", "author": [{"name": "Jason Gaitonde"}, {"name": "Jon Kleinberg"}, {"name": "Eva Tardos"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "28 pages; added new related work, fixed typos"}, "link": [{"@href": "http://arxiv.org/abs/2003.07010v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2003.07010v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DS", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.DS", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2005.13290v2", "updated": "2020-05-28T15:28:13Z", "published": "2020-05-27T11:39:15Z", "title": "Pandemic News: Facebook Pages of Mainstream News Media and the\n  Coronavirus Crisis -- A Computational Content Analysis", "summary": "The unfolding of the COVID-19 pandemic has been an unprecedented challenge\nfor news media around the globe. While journalism is meant to process yet\nunknown events by design, the dynamically evolving situation affected all\naspects of life in such profound ways that even the routines of crisis\nreporting seemed to be insufficient. Critics noted tendencies to horse-race\nreporting and uncritical coverage, with journalism being too close to official\nstatements and too affirmative of political decisions. However, empirical data\non the performance of journalistic news media during the crisis has been\nlacking thus far. The current study analyzes the Facebook messages of\njournalistic news media during the early Coronavirus crisis, based on a large\nGerman data set from January to March 2020. Using computational content\nanalysis methods, reach and interactions, topical structure, relevant actors,\nnegativity of messages, as well as the coverage of fabricated news and\nconspiracy theories were examined. The topical structure of the near-time\nFacebook coverage changed during various stages of the crisis, with just\npartial support for the claims of critics. The initial stages were somewhat\nlacking in topical breadth, but later stages offered a broad range of coverage\non Corona-related issues and societal concerns. Further, journalistic media\ncovered fake news and conspiracy theories during the crisis, but they\nconsistently contextualized them as what they were and debunked the false\nclaims circulating in public. While some criticism regarding the performance of\njournalism during the crisis received mild empirical support, the analysis did\nnot find overwhelming signs of systemic dysfunctionalities. Overall,\njournalistic media did not default to a uniform reaction nor to sprawling,\ninformation-poor pandemic news, but they responded with a multi-perspective\ncoverage of the crisis.", "author": [{"name": "Thorsten Quandt"}, {"name": "Svenja Boberg"}, {"name": "Tim Schatto-Eckrodt"}, {"name": "Lena Frischlich"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Corrected typos, 7 figures, 4 tables, 1 ancillary file"}, "link": [{"@href": "http://arxiv.org/abs/2005.13290v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2005.13290v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2010.10083v1", "updated": "2020-10-20T07:21:11Z", "published": "2020-10-20T07:21:11Z", "title": "Bias-Resistant Social News Aggregator Based on Blockchain", "summary": "In today's world, social networks have become one of the primary sources for\ncreation and propagation of news. Social news aggregators are one of the actors\nin this area in which users post news items and use positive or negative votes\nto indicate their preference toward a news item. News items will be ordered and\ndisplayed according to their aggregated votes. This approach suffers from\nseveral problems raging from being prone to the dominance of the majority to\ndifficulty in discerning between correct and fake news, and lack of incentive\nfor honest behaviors. In this paper, we propose a graph-based news aggregator\nin which instead of voting on the news items, users submit their votes on the\nrelations between pairs of news items. More precisely, if a user believes two\nnews items support each other, he will submit a positive vote on the link\nbetween the two items, and if he believes that two news items undermine each\nother, he will submit a negative vote on the corresponding link. This approach\nhas mainly two desirable features: (1) mitigating the effect of personal\npreferences on voting, (2) connection of new items to endorsing and disputing\nevidence. This approach helps the newsreaders to understand different aspects\nof a news item better. We also introduce an incentive layer that uses\nblockchain as a distributed transparent manager to encourages users to behave\nhonestly and abstain from adversary behaviors. The incentive layer takes into\naccount that users can have different viewpoints toward news, enabling users\nfrom a wide range of viewpoints to contribute to the network and benefit from\nits rewards. In addition, we introduce a protocol that enables us to prove\nfraud in computations of the incentive layer model on the blockchain.\nUltimately, we will analyze the fraud proof protocol and examine our incentive\nlayer on a wide range of synthesized datasets.", "author": [{"name": "Amir Ziashahabi"}, {"name": "Mohammad Ali Maddah-Ali"}, {"name": "Abbas Heydarnoori"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "23 page, 8 figures, Abstract abridged due to arXiv limits"}, "link": [{"@href": "http://arxiv.org/abs/2010.10083v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2010.10083v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.DC", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.DC", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.GT", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2101.07419v2", "updated": "2021-01-29T05:44:31Z", "published": "2021-01-19T02:29:40Z", "title": "GIID-Net: Generalizable Image Inpainting Detection via Neural\n  Architecture Search and Attention", "summary": "Deep learning (DL) has demonstrated its powerful capabilities in the field of\nimage inpainting, which could produce visually plausible results. Meanwhile,\nthe malicious use of advanced image inpainting tools (e.g. removing key objects\nto report fake news) has led to increasing threats to the reliability of image\ndata. To fight against the inpainting forgeries, in this work, we propose a\nnovel end-to-end Generalizable Image Inpainting Detection Network (GIID-Net),\nto detect the inpainted regions at pixel accuracy. The proposed GIID-Net\nconsists of three sub-blocks: the enhancement block, the extraction block and\nthe decision block. Specifically, the enhancement block aims to enhance the\ninpainting traces by using hierarchically combined special layers. The\nextraction block, automatically designed by Neural Architecture Search (NAS)\nalgorithm, is targeted to extract features for the actual inpainting detection\ntasks. In order to further optimize the extracted latent features, we integrate\nglobal and local attention modules in the decision block, where the global\nattention reduces the intra-class differences by measuring the similarity of\nglobal features, while the local attention strengthens the consistency of local\nfeatures. Furthermore, we thoroughly study the generalizability of our\nGIID-Net, and find that different training data could result in vastly\ndifferent generalization capability. Extensive experimental results are\npresented to validate the superiority of the proposed GIID-Net, compared with\nthe state-of-the-art competitors. Our results would suggest that common\nartifacts are shared across diverse image inpainting methods. Finally, we build\na public inpainting dataset of 10K image pairs for the future research in this\narea.", "author": [{"name": "Haiwei Wu"}, {"name": "Jiantao Zhou"}], "arxiv:comment": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "#text": "Some errors are found in the Section V of Experimental Results, and\n  more experiments are needed to be added. Besides, there are some\n  modifications we want to present in the Section III of the Methods, e.g.,\n  updating the figures for better describe the proposed methods. Thanks!"}, "link": [{"@href": "http://arxiv.org/abs/2101.07419v2", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2101.07419v2", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "cs.CV", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.AI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.01443v1", "updated": "2021-07-03T14:21:34Z", "published": "2021-07-03T14:21:34Z", "title": "Quantifying agent impacts on contact sequences in social interactions", "summary": "Human social behavior plays a crucial role in how pathogens like SARS-CoV-2\nor fake news spread in a population. Social interactions determine the contact\nnetwork among individuals, while spreading, requiring individual-to-individual\ntransmission, takes place on top of the network. Studying the topological\naspects of a contact network, therefore, not only has the potential of leading\nto valuable insights into how the behavior of individuals impacts spreading\nphenomena, but it may also open up possibilities for devising effective\nbehavioral interventions. Because of the temporal nature of interactions -\nsince the topology of the network, containing who is in contact with whom,\nwhen, for how long, and in which precise sequence, varies (rapidly) in time -\nanalyzing them requires developing network methods and metrics that respect\ntemporal variability, in contrast to those developed for static (i.e.,\ntime-invariant) networks. Here, by means of event mapping, we propose a method\nto quantify how quickly agents mingle by transforming temporal network data of\nagent contacts. We define a novel measure called 'contact sequence centrality',\nwhich quantifies the impact of an individual on the contact sequences,\nreflecting the individual's behavioral potential for spreading. Comparing\ncontact sequence centrality across agents allows for ranking the impact of\nagents and identifying potential 'behavioral super-spreaders'. The method is\napplied to social interaction data collected at an art fair in Amsterdam. We\nrelate the measure to the existing network metrics, both temporal and static,\nand find that (mostly at longer time scales) traditional metrics lose their\nresemblance to contact sequence centrality. Our work highlights the importance\nof accounting for the sequential nature of contacts when analyzing social\ninteractions.", "author": [{"name": "Mark M. Dekker"}, {"name": "Tessa F. Blanken"}, {"name": "Fabian Dablander"}, {"name": "Jiamin Ou"}, {"name": "Denny Borsboom"}, {"name": "Debabrata Panja"}], "link": [{"@href": "http://arxiv.org/abs/2107.01443v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.01443v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}, {"id": "http://arxiv.org/abs/2107.02828v1", "updated": "2021-07-06T18:20:38Z", "published": "2021-07-06T18:20:38Z", "title": "Cognitive Contagion: How to model (and potentially counter) the spread\n  of fake news", "summary": "Understanding the spread of false or dangerous beliefs - so-called\nmis/disinformation - through a population has never seemed so urgent to many.\nNetwork science researchers have often taken a page from epidemiologists, and\nmodeled the spread of false beliefs as similar to how a disease spreads through\na social network. However, absent from those disease-inspired models is an\ninternal model of an individual's set of current beliefs, where cognitive\nscience has increasingly documented how the interaction between mental models\nand incoming messages seems to be crucially important for their adoption or\nrejection. We introduce a cognitive contagion model that combines a network\nscience approach with an internal cognitive model of the individual agents,\naffecting what they believe, and what they pass on. We show that the model,\neven with a very discrete and simplistic belief function to capture cognitive\ndissonance, both adds expressive power over existing disease-based contagion\nmodels, and qualitatively demonstrates the appropriate belief update phenomena\nat the individual level. Moreover, we situate our cognitive contagion model in\na larger public opinion diffusion model, which attempts to capture the role of\ninstitutions or media sources in belief diffusion - something that is often\nleft out. We conduct an analysis of the POD model with our simple cognitive\ndissonance-sensitive update function across various graph topologies and\ninstitutional messaging patterns. We demonstrate that population-level\naggregate outcomes of the model qualitatively match what has been reported in\nCOVID misinformation public opinion polls. The overall model sets up a\npreliminary framework with which social science misinformation researchers and\ncomputational opinion diffusion modelers can join forces to understand, and\nhopefully learn how to best counter, the spread of misinformation and\n\"alternative facts.\"", "author": [{"name": "Nicholas Rabb"}, {"name": "Lenore Cowen"}, {"name": "Jan P. de Ruiter"}, {"name": "Matthias Scheutz"}], "link": [{"@href": "http://arxiv.org/abs/2107.02828v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.02828v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}, "category": {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}}, {"id": "http://arxiv.org/abs/2107.03766v1", "updated": "2021-07-08T11:24:50Z", "published": "2021-07-08T11:24:50Z", "title": "Exploring the effect of social media and spatial characteristics during\n  the COVID-19 pandemic in China", "summary": "The declaration of COVID-19 as a pandemic has largely amplified the spread of\nrelated information on social media, such as Twitter, Facebook, and\nWeChat.Unlike the previous studies which focused on how to detect the\nmisinformation or fake news related toCOVID-19, we investigate how the disease\nand information co-evolve in the population. We focus onCOVID-19and its\ninformation during the period when the disease was widely spread in China,\ni.e., from January 25th to March 24th, 2020. We first explore how the disease\nand information co-evolve via the spatial analysis of the two spreading\nprocesses. We visualize the geo-location of both disease and information at the\nprovince level and find that disease is more geo-localized compared to\ninformation. We find a high correlation between the disease and information\ndata, and also people care about the spread only when it comes to their\nneighborhood. Regard to the content of the information, we find that positive\nmessages are more negatively correlated with the disease compared to negative\nand neutral messages. Additionally, we introduce machine learning algorithms,\ni.e., linear regression and random forest, to further predict the number of\ninfected using different disease spatial related and information-related\ncharacteristics. We obtain that the disease spatial related characteristics of\nnearby cities can help to improve the prediction accuracy. Meanwhile,\ninformation-related characteristics can also help to improve the prediction\nperformance, but with a delay, i.e., the improvement comes from using, for\ninstance, the number of messages 10 days ago, for disease prediction. The\nmethodology proposed in this paper may shed light on new clues of emerging\ninfections", "author": [{"name": "Xiu-Xiu Zhan"}, {"name": "Kaiyue Zhang"}, {"name": "Lun Ge"}, {"name": "Junming Huang"}, {"name": "Zinan Zhang"}, {"name": "Lu Wei"}, {"name": "Gui-Quan Sun"}, {"name": "Chuang Liu"}, {"name": "Zi-Ke Zhang"}], "link": [{"@href": "http://arxiv.org/abs/2107.03766v1", "@rel": "alternate", "@type": "text/html"}, {"@title": "pdf", "@href": "http://arxiv.org/pdf/2107.03766v1", "@rel": "related", "@type": "application/pdf"}], "arxiv:primary_category": {"@xmlns:arxiv": "http://arxiv.org/schemas/atom", "@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, "category": [{"@term": "physics.soc-ph", "@scheme": "http://arxiv.org/schemas/atom"}, {"@term": "cs.SI", "@scheme": "http://arxiv.org/schemas/atom"}]}]