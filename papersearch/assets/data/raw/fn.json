[{"id": 968397029, "title": "The Gray Side of Fake News - A Multiclass Approach to Detecting Fake News, Real News and Everything Else in Between.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Kelvin King-Kizito", "id-internal": "228/2363", "id-external": ""}, "url": {"full": "URL#429640", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 399799000, "title": "Fake News in the News - An Analysis of Partisan Coverage of the Fake News Phenomenon.", "abstract": "", "doi": "10.1145/3272973.3274079", "date": "2018", "authors": [{"name": "Xunru Che", "id-internal": "229/1497", "id-external": ""}, {"name": "Dana\u00eb Metaxa-Kakavouli", "id-internal": "171/4436", "id-external": ""}, {"name": "Jeffrey T. Hancock", "id-internal": "68/1822", "id-external": ""}], "url": {"full": "URL#1237870", "pdf": ""}, "publisher-venue": "CSCW Companion", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 487762453, "title": "Flagging fake news on social media - An experimental study of media consumers' identification of fake news.", "abstract": "", "doi": "10.1016/j.giq.2021.101591", "date": "2021", "authors": {"name": "Dongfang Gaozhao", "id-internal": "296/8389", "id-external": ""}, "url": {"full": "URL#39859", "pdf": ""}, "publisher-venue": "Gov. Inf. Q.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2941833643, "title": "Combating Fake News in \"Low-Resource\" Languages - Amharic Fake News Detection Accompanied by Resource Crafting.", "abstract": "", "doi": "10.3390/info12010020", "date": "2021", "authors": [{"name": "Fantahun Gereme", "id-internal": "273/6884", "id-external": ""}, {"name": "William Zhu", "id-internal": "z/WilliamZhu", "id-external": ""}, {"name": "Tewodros Ayall", "id-internal": "273/6928", "id-external": ""}, {"name": "Dagmawi Alemu", "id-internal": "284/0164", "id-external": ""}], "url": {"full": "URL#50734", "pdf": ""}, "publisher-venue": "Inf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1891394072, "title": "Hoax news-inspector - a real-time prediction of fake news using content resemblance over web search results for authenticating the credibility of news articles.", "abstract": "", "doi": "10.1007/s12652-020-02698-1", "date": "2021", "authors": [{"name": "Deepika Varshney", "id-internal": "252/5523", "id-external": ""}, {"name": "Dinesh Kumar Vishwakarma", "id-internal": "214/0803", "id-external": ""}], "url": {"full": "URL#55884", "pdf": ""}, "publisher-venue": "J. Ambient Intell. Humaniz. Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2491930840, "title": "Fake news and COVID-19 - modelling the predictors of fake news sharing among social media users.", "abstract": "", "doi": "10.1016/j.tele.2020.101475", "date": "2021", "authors": [{"name": "Oberiri Destiny Apuke", "id-internal": "282/6130", "id-external": ""}, {"name": "Bahiyah Omar", "id-internal": "266/6880", "id-external": ""}], "url": {"full": "URL#105899", "pdf": ""}, "publisher-venue": "Telematics Informatics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1544867302, "title": "Embracing Domain Differences in Fake News - Cross-domain Fake News Detection using Multi-modal Data.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Amila Silva", "id-internal": "220/0876", "id-external": ""}, {"name": "Ling Luo 0002", "id-internal": "00/1811-2", "id-external": ""}, {"name": "Shanika Karunasekera", "id-internal": "47/5584", "id-external": ""}, {"name": "Christopher Leckie", "id-internal": "73/1139", "id-external": ""}], "url": {"full": "URL#124467", "pdf": ""}, "publisher-venue": "AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3299299069, "title": "How does Truth Evolve into Fake News? An Empirical Study of Fake News Evolution.", "abstract": "", "doi": "10.1145/3442442.3452328", "date": "2021", "authors": [{"name": "Mingfei Guo", "id-internal": "287/4891", "id-external": ""}, {"name": "Xiuying Chen", "id-internal": "33/11343", "id-external": ""}, {"name": "Juntao Li", "id-internal": "32/971", "id-external": ""}, {"name": "Dongyan Zhao 0001", "id-internal": "63/1870", "id-external": ""}, {"name": "Rui Yan 0001", "id-internal": "19/2405-1", "id-external": ""}], "url": {"full": "URL#187551", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 84163291, "title": "Embracing Domain Differences in Fake News - Cross-domain Fake News Detection using Multi-modal Data.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Amila Silva", "id-internal": "220/0876", "id-external": ""}, {"name": "Ling Luo 0002", "id-internal": "00/1811-2", "id-external": ""}, {"name": "Shanika Karunasekera", "id-internal": "47/5584", "id-external": ""}, {"name": "Christopher Leckie", "id-internal": "73/1139", "id-external": ""}], "url": {"full": "URL#197402", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1048511043, "title": "How does Truth Evolve into Fake News? An Empirical Study of Fake News Evolution.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Mingfei Guo", "id-internal": "287/4891", "id-external": ""}, {"name": "Xiuying Chen", "id-internal": "33/11343", "id-external": ""}, {"name": "Juntao Li", "id-internal": "32/971", "id-external": ""}, {"name": "Dongyan Zhao 0001", "id-internal": "63/1870", "id-external": ""}, {"name": "Rui Yan 0001", "id-internal": "19/2405-1", "id-external": ""}], "url": {"full": "URL#203288", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3147170461, "title": "FakeNewsNet - A Data Repository with News Content, Social Context, and Spatiotemporal Information for Studying Fake News on Social Media.", "abstract": "", "doi": "10.1089/big.2020.0062", "date": "2020", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Deepak Mahudeswaran", "id-internal": "227/2536", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#270722", "pdf": ""}, "publisher-venue": "Big Data", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3592176211, "title": "Profiling Bots and Fake News Spreaders at PAN'19 and PAN'20 - Bots and Gender Profiling 2019, Profiling Fake News Spreaders on Twitter 2020.", "abstract": "", "doi": "10.1109/dsaa49011.2020.00088", "date": "2020", "authors": {"name": "Juan Pizarro", "id-internal": "245/4143", "id-external": ""}, "url": {"full": "URL#458515", "pdf": ""}, "publisher-venue": "DSAA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 320334801, "title": "Consuming Fake News - A Matter of Age? The Perception of Political Fake News Stories in Facebook Ads.", "abstract": "", "doi": "10.1007/978-3-030-50232-4_6", "date": "2020", "authors": [{"name": "Eug\u00e8ne Loos", "id-internal": "25/6343", "id-external": ""}, {"name": "Jordy Nijenhuis", "id-internal": "269/7933", "id-external": ""}], "url": {"full": "URL#478148", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1689263834, "title": "Identifying Fake News from the Variables that Governs the Spread of Fake News.", "abstract": "", "doi": "10.1109/smap49528.2020.9248453", "date": "2020", "authors": [{"name": "Milan Dordevic", "id-internal": "184/6198", "id-external": ""}, {"name": "Pardis Pourghomi", "id-internal": "127/1573", "id-external": ""}, {"name": "Fadi Safieddine", "id-internal": "38/6173", "id-external": ""}], "url": {"full": "URL#562109", "pdf": ""}, "publisher-venue": "SMAP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1292576100, "title": "Impact of Fake News in VR compared to Fake News on Social Media, a pilot study.", "abstract": "", "doi": "10.1109/vrw50115.2020.00139", "date": "2020", "authors": [{"name": "Adrien Verhulst", "id-internal": "166/4160", "id-external": ""}, {"name": "Wanqi Zhao", "id-internal": "247/3900", "id-external": ""}, {"name": "Fumihiko Nakamura", "id-internal": "48/7077", "id-external": ""}, {"name": "Masaaki Fukuoka", "id-internal": "245/4464", "id-external": ""}, {"name": "Maki Sugimoto", "id-internal": "33/3150", "id-external": ""}, {"name": "Masahiko Inami", "id-internal": "90/1139", "id-external": ""}], "url": {"full": "URL#571520", "pdf": ""}, "publisher-venue": "VR Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2000938290, "title": "From Fake News to Virtual Reality - Fake News and Digital Manipulations at the Age of Modern Technology.", "abstract": "", "doi": "10.1145/3360664.3361145", "date": "2019", "authors": {"name": "Tal Pavel", "id-internal": "251/5903", "id-external": ""}, "url": {"full": "URL#845045", "pdf": ""}, "publisher-venue": "CECC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4269220440, "title": "The Fake News Vaccine - A Content-Agnostic System for Preventing Fake News from Becoming Viral.", "abstract": "", "doi": "10.1007/978-3-030-31277-0_23", "date": "2019", "authors": [{"name": "Oana Balmau", "id-internal": "157/1134", "id-external": ""}, {"name": "Rachid Guerraoui", "id-internal": "g/RachidGuerraoui", "id-external": ""}, {"name": "Anne-Marie Kermarrec", "id-internal": "86/676", "id-external": ""}, {"name": "Alexandre Maurer", "id-internal": "01/10825", "id-external": ""}, {"name": "Matej Pavlovic", "id-internal": "178/5515", "id-external": ""}, {"name": "Willy Zwaenepoel", "id-internal": "z/WZwaenepoel", "id-external": ""}], "url": {"full": "URL#958178", "pdf": ""}, "publisher-venue": "NETYS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2710201699, "title": "Third person effects of fake news - Fake news regulation and media literacy interventions.", "abstract": "", "doi": "10.1016/j.chb.2017.11.034", "date": "2018", "authors": [{"name": "S. Mo Jang", "id-internal": "41/11483", "id-external": ""}, {"name": "Joon K. Kim", "id-internal": "212/9262", "id-external": ""}], "url": {"full": "URL#1085785", "pdf": ""}, "publisher-venue": "Comput. Hum. Behav.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1083169991, "title": "Good news, bad news, and fake news - Going beyond political literacy to democracy and libraries.", "abstract": "", "doi": "10.1108/jd-05-2018-0074", "date": "2018", "authors": {"name": "John Buschman", "id-internal": "98/3908", "id-external": ""}, "url": {"full": "URL#1135920", "pdf": ""}, "publisher-venue": "J. Documentation", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3019280497, "title": "The small, disloyal fake news audience - The role of audience availability in fake news consumption.", "abstract": "", "doi": "10.1177/1461444818758715", "date": "2018", "authors": [{"name": "Jacob L. Nelson", "id-internal": "228/0341", "id-external": ""}, {"name": "Harsh Taneja", "id-internal": "119/8008", "id-external": ""}], "url": {"full": "URL#1157388", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1575699608, "title": "Fake News as We Feel It - Perception and Conceptualization of the Term \"Fake News\" in the Media.", "abstract": "", "doi": "10.1007/978-3-030-01129-1_10", "date": "2018", "authors": [{"name": "Evandro Cunha", "id-internal": "116/1689", "id-external": ""}, {"name": "Gabriel Magno", "id-internal": "25/10818", "id-external": ""}, {"name": "Josemar Alves Caetano", "id-internal": "218/5242", "id-external": ""}, {"name": "Douglas Teixeira", "id-internal": "223/5597", "id-external": ""}, {"name": "Virg\u00edlio A. F. Almeida", "id-internal": "a/VirgilioAlmeida", "id-external": ""}], "url": {"full": "URL#1356465", "pdf": ""}, "publisher-venue": "SocInfo", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 993238913, "title": "Fake news as we feel it - perception and conceptualization of the term \"fake news\" in the media.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Evandro Cunha", "id-internal": "116/1689", "id-external": ""}, {"name": "Gabriel Magno", "id-internal": "25/10818", "id-external": ""}, {"name": "Josemar Alves Caetano", "id-internal": "218/5242", "id-external": ""}, {"name": "Douglas Teixeira", "id-internal": "223/5597", "id-external": ""}, {"name": "Virg\u00edlio A. F. Almeida", "id-internal": "a/VirgilioAlmeida", "id-external": ""}], "url": {"full": "URL#1403111", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1609175445, "title": "FakeNewsNet - A Data Repository with News Content, Social Context and Dynamic Information for Studying Fake News on Social Media.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Deepak Mahudeswaran", "id-internal": "227/2536", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#1408026", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3662886089, "title": "All Your Fake Detector are Belong to Us - Evaluating Adversarial Robustness of Fake-News Detectors Under Black-Box Settings.", "abstract": "", "doi": "10.1109/access.2021.3085875", "date": "2021", "authors": [{"name": "Hassan Ali", "id-internal": "60/4498", "id-external": ""}, {"name": "Muhammad Suleman Khan", "id-internal": "294/8606", "id-external": ""}, {"name": "Amer AlGhadhban", "id-internal": "150/3592", "id-external": ""}, {"name": "Meshari Alazmi", "id-internal": "185/8268", "id-external": ""}, {"name": "Ahmad Alzamil", "id-internal": "294/8734", "id-external": ""}, {"name": "Khaled Abdul-Aziz Al-Utaibi", "id-internal": "295/3120", "id-external": ""}, {"name": "Junaid Qadir 0001", "id-internal": "74/2204", "id-external": ""}], "url": {"full": "URL#2157", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1809087107, "title": "An anatomical comparison of fake-news and trusted-news sharing pattern on Twitter.", "abstract": "", "doi": "10.1007/s10588-019-09305-5", "date": "2021", "authors": [{"name": "Sumeet Kumar", "id-internal": "25/5640", "id-external": ""}, {"name": "Binxuan Huang", "id-internal": "195/5963", "id-external": ""}, {"name": "Ramon Alfonso Villa Cox", "id-internal": "237/9343", "id-external": ""}, {"name": "Kathleen M. Carley", "id-internal": "72/6492", "id-external": ""}], "url": {"full": "URL#23534", "pdf": ""}, "publisher-venue": "Comput. Math. Organ. Theory", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 955721513, "title": "Fake Detect - A Deep Learning Ensemble Model for Fake News Detection.", "abstract": "", "doi": "10.1155/2021/5557784", "date": "2021", "authors": [{"name": "Nida Aslam", "id-internal": "23/7907", "id-external": ""}, {"name": "Irfan Ullah Khan", "id-internal": "158/8244", "id-external": ""}, {"name": "Farah Salem Alotaibi", "id-internal": "290/2613", "id-external": ""}, {"name": "Lama Abdulaziz Aldaej", "id-internal": "290/2584", "id-external": ""}, {"name": "Asma Khaled Aldubaikil", "id-internal": "290/2760", "id-external": ""}], "url": {"full": "URL#25447", "pdf": ""}, "publisher-venue": "Complex.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3981249087, "title": "FakeBERT - Fake news detection in social media with a BERT-based deep learning approach.", "abstract": "", "doi": "10.1007/s11042-020-10183-2", "date": "2021", "authors": [{"name": "Rohit Kumar Kaliyar", "id-internal": "261/1345", "id-external": ""}, {"name": "Anurag Goswami", "id-internal": "139/3865", "id-external": ""}, {"name": "Pratik Narang", "id-internal": "132/9397", "id-external": ""}], "url": {"full": "URL#72186", "pdf": ""}, "publisher-venue": "Multim. Tools Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 737030253, "title": "NLytics at CheckThat!\u00a02021 - Multi-class fake news detection of news articles and domain identification with RoBERTa - a baseline model.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Albert Pritzkau", "id-internal": "80/7611", "id-external": ""}, "url": {"full": "URL#137524", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 685477808, "title": "Classifier for fake news detection and Topical Domain of News Articles.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "William Kana Tsoplefack", "id-internal": "300/1870", "id-external": ""}, "url": {"full": "URL#137566", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4192597295, "title": "FakeFlow - Fake News Detection by Modeling the Flow of Affective Information.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Bilal Ghanem", "id-internal": "219/8408", "id-external": ""}, {"name": "Simone Paolo Ponzetto", "id-internal": "04/2532", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}, {"name": "Francisco Rangel", "id-internal": "276/5314", "id-external": ""}], "url": {"full": "URL#144040", "pdf": ""}, "publisher-venue": "EACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4291447672, "title": "Textual Characteristics of News Title and Body to Detect Fake News - A Reproducibility Study.", "abstract": "", "doi": "10.1007/978-3-030-72240-1_9", "date": "2021", "authors": [{"name": "Anu Shrestha", "id-internal": "225/5383", "id-external": ""}, {"name": "Francesca Spezzano", "id-internal": "81/7907", "id-external": ""}], "url": {"full": "URL#144649", "pdf": ""}, "publisher-venue": "ECIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2836354497, "title": "Fighting Against Fake News During Pandemic Era - Does Providing Related News Help Student Internet Users to Detect COVID-19 Misinformation?", "abstract": "", "doi": "10.1145/3447535.3462508", "date": "2021", "authors": [{"name": "Borhan Uddin", "id-internal": "295/6510", "id-external": ""}, {"name": "Nahid Reza", "id-internal": "295/6301", "id-external": ""}, {"name": "Md Saiful Islam", "id-internal": "04/3572", "id-external": ""}, {"name": "Hasib Ahsan", "id-internal": "227/0557", "id-external": ""}, {"name": "Mohammad Ruhul Amin", "id-internal": "193/0290", "id-external": ""}], "url": {"full": "URL#186521", "pdf": ""}, "publisher-venue": "WebSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 688137955, "title": "News Image Steganography - A Novel Architecture Facilitates the Fake News Identification.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Jizhe Zhou", "id-internal": "172/4712", "id-external": ""}, {"name": "Chi-Man Pun", "id-internal": "p/ChiManPun", "id-external": ""}, {"name": "Yu Tong", "id-internal": "22/2859", "id-external": ""}], "url": {"full": "URL#190052", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2432915640, "title": "FakeFlow - Fake News Detection by Modeling the Flow of Affective Information.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Bilal Ghanem", "id-internal": "219/8408", "id-external": ""}, {"name": "Simone Paolo Ponzetto", "id-internal": "04/2532", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}, {"name": "Francisco M. Rangel Pardo", "id-internal": "63/8242", "id-external": ""}], "url": {"full": "URL#193538", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1349815588, "title": "A Heuristic-driven Uncertainty based Ensemble Framework for Fake News Detection in Tweets and News Articles.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sourya Dipta Das", "id-internal": "217/1530", "id-external": ""}, {"name": "Ayan Basak", "id-internal": "256/4299", "id-external": ""}, {"name": "Saikat Dutta", "id-internal": "260/3198", "id-external": ""}], "url": {"full": "URL#208923", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3700132520, "title": "A Web Infrastructure for Certifying Multimedia News Content for Fake News Defense.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Edward L. Amoruso", "id-internal": "290/1824", "id-external": ""}, {"name": "Stephen P. Johnson", "id-internal": "290/1483", "id-external": ""}, {"name": "Raghu Nandan Avula", "id-internal": "137/0127", "id-external": ""}, {"name": "Cliff C. Zou", "id-internal": "z/CliffChangchunZou", "id-external": ""}], "url": {"full": "URL#210172", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 557107109, "title": "Both Rates of Fake News and Fact-based News on Twitter Negatively Correlate with the State-level COVID-19 Vaccine Uptake.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Hanjia Lyu", "id-internal": "256/5541", "id-external": ""}, {"name": "Zihe Zheng", "id-internal": "290/2114", "id-external": ""}, {"name": "Jiebo Luo", "id-internal": "25/5545", "id-external": ""}], "url": {"full": "URL#224943", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 645649221, "title": "Combating fake news by empowering fact-checked news spread via topology-based interventions.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Ke Wang", "id-internal": "181/2613", "id-external": ""}, {"name": "Waheeb Yaqub", "id-internal": "167/7643", "id-external": ""}, {"name": "Abdallah Lakhdari", "id-internal": "189/1450", "id-external": ""}, {"name": "Basem Suleiman", "id-internal": "32/2656", "id-external": ""}], "url": {"full": "URL#230983", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4102665006, "title": "DEAP-FAKED - Knowledge Graph based Approach for Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Mohit Mayank", "id-internal": "280/0024", "id-external": ""}, {"name": "Shakshi Sharma", "id-internal": "276/6386", "id-external": ""}, {"name": "Rajesh Sharma", "id-internal": "16/7691", "id-external": ""}], "url": {"full": "URL#233269", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 809697859, "title": "Is it Fake? News Disinformation Detection on South African News Websites.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Harm de Wet", "id-internal": "299/1421", "id-external": ""}, {"name": "Vukosi Marivate", "id-internal": "73/1303", "id-external": ""}], "url": {"full": "URL#236113", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4034455628, "title": "The bad news game - a defense against fake news.", "abstract": "", "doi": "10.1145/3416065", "date": "2020", "authors": {"name": "Diane Golay", "id-internal": "211/4966", "id-external": ""}, "url": {"full": "URL#287767", "pdf": ""}, "publisher-venue": "XRDS", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2676502267, "title": "Fake news propagates differently from real news even at early stages of spreading.", "abstract": "", "doi": "10.1140/epjds/s13688-020-00224-z", "date": "2020", "authors": [{"name": "Zilong Zhao 0002", "id-internal": "199/3744-2", "id-external": ""}, {"name": "Jichang Zhao", "id-internal": "27/3251", "id-external": ""}, {"name": "Yukie Sano", "id-internal": "53/9891", "id-external": ""}, {"name": "Orr Levy", "id-internal": "217/3594", "id-external": ""}, {"name": "Hideki Takayasu", "id-internal": "83/6784", "id-external": ""}, {"name": "Misako Takayasu", "id-internal": "75/5926", "id-external": ""}, {"name": "Daqing Li", "id-internal": "04/10220", "id-external": ""}, {"name": "Junjie Wu 0002", "id-internal": "35/118-2", "id-external": ""}, {"name": "Shlomo Havlin", "id-internal": "04/5624", "id-external": ""}], "url": {"full": "URL#297321", "pdf": ""}, "publisher-venue": "EPJ Data Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2641139339, "title": "Study and analysis of unreliable news based on content acquired using ensemble learning (prevalence of fake news on social media).", "abstract": "", "doi": "10.1007/s13198-020-01016-4", "date": "2020", "authors": [{"name": "Mohammad Zubair Khan", "id-internal": "65/10402", "id-external": ""}, {"name": "Omar Hussain Alhazmi", "id-internal": "272/5786", "id-external": ""}], "url": {"full": "URL#371648", "pdf": ""}, "publisher-venue": "Int. J. Syst. Assur. Eng. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1799238930, "title": "NewsBag - A Benchmark Multimodal Dataset for Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Sarthak Jindal", "id-internal": "259/5966", "id-external": ""}, {"name": "Raghav Sood", "id-internal": "216/5035", "id-external": ""}, {"name": "Richa Singh 0001", "id-internal": "75/3512", "id-external": ""}, {"name": "Mayank Vatsa", "id-internal": "58/323", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}], "url": {"full": "URL#420596", "pdf": ""}, "publisher-venue": "SafeAI@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2070274096, "title": "Investigating Users' Perceived Credibility of Real and Fake News Posts in Facebook's News Feed - UK Case Study.", "abstract": "", "doi": "10.1007/978-3-030-51328-3_25", "date": "2020", "authors": [{"name": "Neil Bates", "id-internal": "300/2495", "id-external": ""}, {"name": "Sonia C. Sousa 0001", "id-internal": "98/10768", "id-external": ""}], "url": {"full": "URL#425101", "pdf": ""}, "publisher-venue": "AHFE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 492861013, "title": "Understanding How Readers Determine the Legitimacy of Online News Articles in the Era of Fake News.", "abstract": "", "doi": "10.1109/asonam49781.2020.9381451", "date": "2020", "authors": [{"name": "Srihaasa Pidikiti", "id-internal": "289/2424", "id-external": ""}, {"name": "Jason Shuo Zhang", "id-internal": "227/2185", "id-external": ""}, {"name": "Richard Han", "id-internal": "74/2447", "id-external": ""}, {"name": "Tamara Lehman", "id-internal": "271/7824", "id-external": ""}, {"name": "Qin Lv", "id-internal": "11/808", "id-external": ""}, {"name": "Shivakant Mishra", "id-internal": "37/3475", "id-external": ""}], "url": {"full": "URL#432673", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1755053380, "title": "Developing more Reliable News Sources by utilizing the Blockchain technology to combat Fake News.", "abstract": "", "doi": "10.1109/bcca50787.2020.9274460", "date": "2020", "authors": [{"name": "Panayiotis Christodoulou", "id-internal": "134/0205", "id-external": ""}, {"name": "Klitos Christodoulou", "id-internal": "117/6069", "id-external": ""}], "url": {"full": "URL#434074", "pdf": ""}, "publisher-venue": "BCCA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 915404012, "title": "Early Detection of Fake News by Utilizing the Credibility of News, Publishers, and Users based on Weakly Supervised Learning.", "abstract": "", "doi": "10.18653/v1/2020.coling-main.475", "date": "2020", "authors": [{"name": "Chunyuan Yuan", "id-internal": "248/8262", "id-external": ""}, {"name": "Qianwen Ma", "id-internal": "248/8201", "id-external": ""}, {"name": "Wei Zhou 0019", "id-internal": "69/5011-19", "id-external": ""}, {"name": "Jizhong Han", "id-internal": "72/6837", "id-external": ""}, {"name": "Songlin Hu", "id-internal": "67/4108", "id-external": ""}], "url": {"full": "URL#449292", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1612159990, "title": "NITP-AI-NLP@UrduFake-FIRE2020 - Multi-layer Dense Neural Network for Fake News Detection in Urdu News Articles.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Abhinav Kumar", "id-internal": "115/6458", "id-external": ""}, {"name": "Sunil Saumya", "id-internal": "184/6325", "id-external": ""}, {"name": "Jyoti Prakash Singh", "id-internal": "13/8817", "id-external": ""}], "url": {"full": "URL#471997", "pdf": ""}, "publisher-venue": "FIRE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1444540545, "title": "The Effects of Thinking Styles and News Domain on Fake News Recognition by Social Media Users - Evidence from Russia.", "abstract": "", "doi": "10.1007/978-3-030-49570-1_21", "date": "2020", "authors": [{"name": "Alexander Porshnev", "id-internal": "142/7071", "id-external": ""}, {"name": "Alexandre Miltsov", "id-internal": "269/6356", "id-external": ""}], "url": {"full": "URL#478472", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3060163108, "title": "Approaching Fake News at the Expense of Truth - A Psychophysiological Study of News on Social Media.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Lauren Kirkwood", "id-internal": "263/2962", "id-external": ""}, {"name": "Randall Minas", "id-internal": "263/3060", "id-external": ""}], "url": {"full": "URL#479685", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2105935407, "title": "DeepNet - An Efficient Neural Network for Fake News Detection using News-User Engagements.", "abstract": "", "doi": "10.1109/icccs49678.2020.9277353", "date": "2020", "authors": [{"name": "Rohit Kumar Kaliyar", "id-internal": "261/1345", "id-external": ""}, {"name": "Pawan Kumar", "id-internal": "53/773", "id-external": ""}, {"name": "Manish Kumar", "id-internal": "35/4332", "id-external": ""}, {"name": "Meenal Narkhede", "id-internal": "280/6923", "id-external": ""}, {"name": "Sreyas Namboodiri", "id-internal": "280/7126", "id-external": ""}, {"name": "Sneha Mishra", "id-internal": "280/6721", "id-external": ""}], "url": {"full": "URL#489860", "pdf": ""}, "publisher-venue": "ICCCS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2022571493, "title": "FakeDetector - Effective Fake News Detection with Deep Diffusive Neural Network.", "abstract": "", "doi": "10.1109/icde48307.2020.00180", "date": "2020", "authors": [{"name": "Jiawei Zhang 0001", "id-internal": "10/239-1", "id-external": ""}, {"name": "Bowen Dong", "id-internal": "173/4607", "id-external": ""}, {"name": "Philip S. Yu", "id-internal": "y/PhilipSYu", "id-external": ""}], "url": {"full": "URL#492895", "pdf": ""}, "publisher-venue": "ICDE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2086043518, "title": "Fakeddit - A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kai Nakamura", "id-internal": "232/2717", "id-external": ""}, {"name": "Sharon Levy", "id-internal": "92/7341", "id-external": ""}, {"name": "William Yang Wang", "id-internal": "08/9282", "id-external": ""}], "url": {"full": "URL#536078", "pdf": ""}, "publisher-venue": "LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 251198680, "title": "Detecting Fake News in Tweets from Text and Propagation Graph - IRISA's Paritcipation to the FakeNews Task at MediaEval 2020.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Vincent Claveau", "id-internal": "35/6385", "id-external": ""}, "url": {"full": "URL#537390", "pdf": ""}, "publisher-venue": "MediaEval", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2252349379, "title": "FakeYou! - A Gamified Approach for Building and Evaluating Resilience Against Fake News.", "abstract": "", "doi": "10.1007/978-3-030-61841-4_15", "date": "2020", "authors": [{"name": "Lena Clever", "id-internal": "202/2572", "id-external": ""}, {"name": "Dennis Assenmacher", "id-internal": "201/1363", "id-external": ""}, {"name": "Kilian M\u00fcller", "id-internal": "261/2759", "id-external": ""}, {"name": "Moritz Vinzent Seiler", "id-internal": "261/3628", "id-external": ""}, {"name": "Dennis M. Riehle", "id-internal": "180/3776", "id-external": ""}, {"name": "Mike Preuss", "id-internal": "p/MikePreuss", "id-external": ""}, {"name": "Christian Grimme", "id-internal": "94/3183", "id-external": ""}], "url": {"full": "URL#540776", "pdf": ""}, "publisher-venue": "MISDOOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 606244336, "title": "How Fake News Affect Trust in the Output of a Machine Learning System for News Curation.", "abstract": "", "doi": "10.1007/978-3-030-61841-4_2", "date": "2020", "authors": [{"name": "Hendrik Heuer", "id-internal": "117/6741", "id-external": ""}, {"name": "Andreas Breiter", "id-internal": "95/1082", "id-external": ""}], "url": {"full": "URL#540778", "pdf": ""}, "publisher-venue": "MISDOOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1875994873, "title": "Fake News Detection on Fake.Br Using Hierarchical Attention Networks.", "abstract": "", "doi": "10.1007/978-3-030-41505-1_14", "date": "2020", "authors": [{"name": "Emerson Yoshiaki Okano", "id-internal": "258/8490", "id-external": ""}, {"name": "Zebin Liu", "id-internal": "258/8523", "id-external": ""}, {"name": "Donghong Ji", "id-internal": "43/42", "id-external": ""}, {"name": "Evandro Eduardo Seron Ruiz", "id-internal": "54/9273", "id-external": ""}], "url": {"full": "URL#552289", "pdf": ""}, "publisher-venue": "PROPOR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3287223249, "title": "FakeNewsSetGen - a Process to Build Datasets that Support Comparison Among Fake News Detection Methods.", "abstract": "", "doi": "10.1145/3428658.3430965", "date": "2020", "authors": [{"name": "Fl\u00e1vio Roberto Matias da Silva", "id-internal": "279/5622", "id-external": ""}, {"name": "Paulo M\u00e1rcio Souza Freire", "id-internal": "250/3519", "id-external": ""}, {"name": "Marcelo Pereira de Souza", "id-internal": "279/5500", "id-external": ""}, {"name": "Gustavo de A. B. Plenamente", "id-internal": "279/5514", "id-external": ""}, {"name": "Ronaldo Ribeiro Goldschmidt", "id-internal": "45/881", "id-external": ""}], "url": {"full": "URL#574522", "pdf": ""}, "publisher-venue": "WebMedia", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 233102617, "title": "FakeFinder - Twitter Fake News Detection on Mobile.", "abstract": "", "doi": "10.1145/3366424.3382706", "date": "2020", "authors": [{"name": "Lin Tian", "id-internal": "90/2236", "id-external": ""}, {"name": "Xiuzhen Zhang", "id-internal": "20/2941", "id-external": ""}, {"name": "Min Peng", "id-internal": "57/495", "id-external": ""}], "url": {"full": "URL#577246", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3974583535, "title": "FakeYou! - A Gamified Approach for Building and Evaluating Resilience Against Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Lena Clever", "id-internal": "202/2572", "id-external": ""}, {"name": "Dennis Assenmacher", "id-internal": "201/1363", "id-external": ""}, {"name": "Kilian M\u00fcller", "id-internal": "261/2759", "id-external": ""}, {"name": "Moritz Vinzent Seiler", "id-internal": "261/3628", "id-external": ""}, {"name": "Dennis M. Riehle", "id-internal": "180/3776", "id-external": ""}, {"name": "Mike Preuss", "id-internal": "p/MikePreuss", "id-external": ""}, {"name": "Christian Grimme", "id-internal": "94/3183", "id-external": ""}], "url": {"full": "URL#594872", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 788983027, "title": "How Fake News Affect Trust in the Output of a Machine Learning System for News Curation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Hendrik Heuer", "id-internal": "117/6741", "id-external": ""}, {"name": "Andreas Breiter", "id-internal": "95/1082", "id-external": ""}], "url": {"full": "URL#623535", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2213582803, "title": "Perceptions of News Sharing and Fake News in Singapore.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Gionnieve Lim", "id-internal": "276/7277", "id-external": ""}, {"name": "Simon T. Perrault", "id-internal": "90/9545", "id-external": ""}], "url": {"full": "URL#637088", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2943478647, "title": "Fake or Real? A Study of Arabic Satirical Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Hadeel Saadany", "id-internal": "256/4248", "id-external": ""}, {"name": "Emad Mohamed", "id-internal": "68/8156", "id-external": ""}, {"name": "Constantin Orasan", "id-internal": "83/316", "id-external": ""}], "url": {"full": "URL#641272", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2356440967, "title": "Early Detection of Fake News by Utilizing the Credibility of News, Publishers, and Users Based on Weakly Supervised Learning.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Chunyuan Yuan", "id-internal": "248/8262", "id-external": ""}, {"name": "Qianwen Ma", "id-internal": "248/8201", "id-external": ""}, {"name": "Wei Zhou 0019", "id-internal": "69/5011-19", "id-external": ""}, {"name": "Jizhong Han", "id-internal": "72/6837", "id-external": ""}, {"name": "Songlin Hu", "id-internal": "67/4108", "id-external": ""}], "url": {"full": "URL#649150", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3937428436, "title": "FakeNewsTracker - a tool for fake news collection, detection, and visualization.", "abstract": "", "doi": "10.1007/s10588-018-09280-3", "date": "2019", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Deepak Mahudeswaran", "id-internal": "227/2536", "id-external": ""}, {"name": "Huanyu Liu", "id-internal": "168/0916", "id-external": ""}], "url": {"full": "URL#694807", "pdf": ""}, "publisher-venue": "Comput. Math. Organ. Theory", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2854199359, "title": "A Novel Approach for Selecting Hybrid Features from Online News Textual Metadata for Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-33509-0_86", "date": "2019", "authors": [{"name": "Mohamed K. Elhadad", "id-internal": "202/5078", "id-external": ""}, {"name": "Kin Fun Li", "id-internal": "33/2872", "id-external": ""}, {"name": "Fayez Gebali", "id-internal": "69/4864", "id-external": ""}], "url": {"full": "URL#817844", "pdf": ""}, "publisher-venue": "3PGCIC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2160456079, "title": "Factitious - Large Scale Computer Game to Fight Fake News and Improve News Literacy.", "abstract": "", "doi": "10.1145/3290607.3299046", "date": "2019", "authors": [{"name": "Lindsay Grace", "id-internal": "09/3123", "id-external": ""}, {"name": "Bob Hone", "id-internal": "239/9258", "id-external": ""}], "url": {"full": "URL#845746", "pdf": ""}, "publisher-venue": "CHI Extended Abstracts", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1922109894, "title": "A Trusting News Ecosystem Against Fake News from Humanity and Technology Perspectives.", "abstract": "", "doi": "10.1109/iccsa.2019.00011", "date": "2019", "authors": [{"name": "Chi-Ying Chen", "id-internal": "179/6665", "id-external": ""}, {"name": "Zon-Ying Shae", "id-internal": "250/0211", "id-external": ""}, {"name": "Chien-Jen Chang", "id-internal": "250/0245", "id-external": ""}, {"name": "Kuan-Yuh Lin", "id-internal": "250/0288", "id-external": ""}, {"name": "Shu-Mei Tan", "id-internal": "250/0215", "id-external": ""}, {"name": "Shao-Liang Chang", "id-internal": "116/6936", "id-external": ""}], "url": {"full": "URL#896088", "pdf": ""}, "publisher-venue": "ICCSA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2159997118, "title": "The Diffusion of Fake News through the \"Middle Media\" - Contaminated Online Sphere in Japan.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Hirotaka Kawashima", "id-internal": "88/9927", "id-external": ""}, {"name": "Hiroyuki Fujishiro", "id-internal": "169/1775", "id-external": ""}], "url": {"full": "URL#975738", "pdf": ""}, "publisher-venue": "NewsIR@SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 468643128, "title": "Fake News and Social Networks - How Users Interact with Fake Content.", "abstract": "", "doi": "10.1007/978-3-030-16181-1_19", "date": "2019", "authors": [{"name": "Manuel Au-Yong-Oliveira", "id-internal": "117/6034", "id-external": ""}, {"name": "Carlota P. A. Carlos", "id-internal": "238/3175", "id-external": ""}, {"name": "Hugo Pintor", "id-internal": "238/3086", "id-external": ""}, {"name": "Jo\u00e3o Caires", "id-internal": "238/3181", "id-external": ""}, {"name": "Julia Zanoni", "id-internal": "238/3156", "id-external": ""}], "url": {"full": "URL#994116", "pdf": ""}, "publisher-venue": "WorldCIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1587425305, "title": "Beyond News Contents - The Role of Social Context for Fake News Detection.", "abstract": "", "doi": "10.1145/3289600.3290994", "date": "2019", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#995038", "pdf": ""}, "publisher-venue": "WSDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 18881822, "title": "Fake or Fact? Theoretical and Practical Aspects of Fake News.", "abstract": "", "doi": "10.1007/978-3-030-03643-0_9", "date": "2019", "authors": [{"name": "George Bara", "id-internal": "240/3597", "id-external": ""}, {"name": "Gerhard Backfried", "id-internal": "62/4134", "id-external": ""}, {"name": "Dorothea Thomas-Aniola", "id-internal": "240/3484", "id-external": ""}], "url": {"full": "URL#996506", "pdf": ""}, "publisher-venue": "Information Quality in Information Fusion and Decision Making", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1884280599, "title": "Video Verification in the Newsroom.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_11", "date": "2019", "authors": [{"name": "Rolf Fricke", "id-internal": "48/1515", "id-external": ""}, {"name": "Jan Thomsen", "id-internal": "50/8012", "id-external": ""}], "url": {"full": "URL#996717", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2713583008, "title": "r/Fakeddit - A New Multimodal Benchmark Dataset for Fine-grained Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Kai Nakamura", "id-internal": "232/2717", "id-external": ""}, {"name": "Sharon Levy", "id-internal": "92/7341", "id-external": ""}, {"name": "William Yang Wang", "id-internal": "08/9282", "id-external": ""}], "url": {"full": "URL#1048800", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2869417321, "title": "Falling for Fake News - Investigating the Consumption of News via Social Media.", "abstract": "", "doi": "10.1145/3173574.3173950", "date": "2018", "authors": [{"name": "Martin Flintham", "id-internal": "01/1311", "id-external": ""}, {"name": "Christian Karner", "id-internal": "217/9403", "id-external": ""}, {"name": "Khaled Bachour", "id-internal": "04/427", "id-external": ""}, {"name": "Helen Creswick", "id-internal": "217/9614", "id-external": ""}, {"name": "Neha Gupta", "id-internal": "09/6861", "id-external": ""}, {"name": "Stuart Moran", "id-internal": "86/7501", "id-external": ""}], "url": {"full": "URL#1229571", "pdf": ""}, "publisher-venue": "CHI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1335467584, "title": "Is It Really Fake? - Towards an Understanding of Fake News in Social Media Communication.", "abstract": "", "doi": "10.1007/978-3-319-91521-0_35", "date": "2018", "authors": [{"name": "Judith Meinert", "id-internal": "143/4332", "id-external": ""}, {"name": "Milad Mirbabaie", "id-internal": "155/7706", "id-external": ""}, {"name": "Sebastian Dungs", "id-internal": "134/2150", "id-external": ""}, {"name": "Ahmet Aker", "id-internal": "67/7965", "id-external": ""}], "url": {"full": "URL#1264994", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3664712235, "title": "Are you the Reason Fake News exists? Investigating News Sharing Attitude on Twitter.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Maximilian Haug", "id-internal": "221/0683", "id-external": ""}, {"name": "Heiko Gewald", "id-internal": "44/3807", "id-external": ""}], "url": {"full": "URL#1284662", "pdf": ""}, "publisher-venue": "ICIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4153073130, "title": "Identifying Fake News and Fake Users on Twitter.", "abstract": "", "doi": "10.1016/j.procs.2018.07.279", "date": "2018", "authors": [{"name": "Costel-Sergiu Atodiresei", "id-internal": "231/5494", "id-external": ""}, {"name": "Alexandru Tanaselea", "id-internal": "231/5511", "id-external": ""}, {"name": "Adrian Iftene", "id-internal": "71/3415", "id-external": ""}], "url": {"full": "URL#1323309", "pdf": ""}, "publisher-venue": "KES", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4087471446, "title": "NewsVallum - Semantics-Aware Text and Image Processing for Fake News Detection system.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Giuliano Armano", "id-internal": "48/3252", "id-external": ""}, {"name": "Sebastiano Battiato", "id-internal": "b/SBattiato", "id-external": ""}, {"name": "Davide Bennato", "id-internal": "225/1790", "id-external": ""}, {"name": "Ludovico Boratto", "id-internal": "50/7423", "id-external": ""}, {"name": "Salvatore M. Carta", "id-internal": "07/5975", "id-external": ""}, {"name": "Tommaso Di Noia", "id-internal": "58/5192", "id-external": ""}, {"name": "Eugenio Di Sciascio", "id-internal": "s/EugenioDiSciascio", "id-external": ""}, {"name": "Alessandro Ortis", "id-internal": "133/9339", "id-external": ""}, {"name": "Diego Reforgiato Recupero", "id-internal": "r/DiegoReforgiatoRecupero", "id-external": ""}], "url": {"full": "URL#1349397", "pdf": ""}, "publisher-venue": "SEBD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1204803608, "title": "Fake news propagate differently from real news even at early stages of spreading.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Zilong Zhao 0002", "id-internal": "199/3744-2", "id-external": ""}, {"name": "Jichang Zhao", "id-internal": "27/3251", "id-external": ""}, {"name": "Yukie Sano", "id-internal": "53/9891", "id-external": ""}, {"name": "Orr Levy", "id-internal": "217/3594", "id-external": ""}, {"name": "Hideki Takayasu", "id-internal": "83/6784", "id-external": ""}, {"name": "Misako Takayasu", "id-internal": "75/5926", "id-external": ""}, {"name": "Daqing Li", "id-internal": "04/10220", "id-external": ""}, {"name": "Shlomo Havlin", "id-internal": "04/5624", "id-external": ""}], "url": {"full": "URL#1388051", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2121794021, "title": "Combating Fake News with Interpretable News Feed Algorithm.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Sina Mohseni", "id-internal": "155/4739", "id-external": ""}, {"name": "Eric D. Ragan", "id-internal": "69/7691", "id-external": ""}], "url": {"full": "URL#1418850", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1378022579, "title": "Alt-News and Post-Truths in the \"Fake News\" Era.", "abstract": "", "doi": "10.1109/mc.2017.104", "date": "2017", "authors": {"name": "Hal Berghel", "id-internal": "b/HalBerghel", "id-external": ""}, "url": {"full": "URL#1450533", "pdf": ""}, "publisher-venue": "Computer", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3652385279, "title": "News Feature - The genuine problem of fake news.", "abstract": "", "doi": "10.1073/pnas.1719005114", "date": "2017", "authors": {"name": "M. Mitchell Waldrop", "id-internal": "69/673", "id-external": ""}, "url": {"full": "URL#1516540", "pdf": ""}, "publisher-venue": "Proc. Natl. Acad. Sci. USA", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4286413809, "title": "News, Fake News, and Critical Authority.", "abstract": "", "doi": "10.1007/978-3-319-74334-9_24", "date": "2017", "authors": [{"name": "John M. Budd", "id-internal": "57/3003", "id-external": ""}, {"name": "Kristine N. Stewart", "id-internal": "150/3027", "id-external": ""}], "url": {"full": "URL#1595314", "pdf": ""}, "publisher-venue": "ECIL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 395466465, "title": "This Just In - Fake News Packs a Lot in Title, Uses Simpler, Repetitive Content in Text Body, More Similar to Satire than Real News.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Benjamin D. Horne", "id-internal": "166/8102", "id-external": ""}, {"name": "Sibel Adali", "id-internal": "a/SAdali", "id-external": ""}], "url": {"full": "URL#1730521", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1129552074, "title": "Fake tweet buster - a webtool to identify users promoting fake news ontwitter.", "abstract": "", "doi": "10.1145/2631775.2631786", "date": "2014", "authors": {"name": "Diego S\u00e1ez-Trumper", "id-internal": "66/9962", "id-external": ""}, "url": {"full": "URL#2528943", "pdf": ""}, "publisher-venue": "HT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1601013872, "title": "Data Science for Fake News - Surveys and Perspectives", "abstract": "", "doi": "10.1007/978-3-030-62696-9", "date": "2021", "authors": [{"name": "Deepak P 0001", "id-internal": "33/1882", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}, {"name": "Cheng Long", "id-internal": "58/10813", "id-external": ""}, {"name": "Santhosh Kumar G", "id-internal": "291/3179", "id-external": ""}], "url": {"full": "URL#1336", "pdf": ""}, "publisher-venue": "The Information Retrieval Series", "type": "Books and Theses", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 306294280, "title": "A Novel Stacking Approach for Accurate Detection of Fake News.", "abstract": "", "doi": "10.1109/access.2021.3056079", "date": "2021", "authors": [{"name": "Tao Jiang", "id-internal": "181/2813", "id-external": ""}, {"name": "Jian Ping Li 0002", "id-internal": "10/1708-2", "id-external": ""}, {"name": "Amin Ul Haq", "id-internal": "231/9206", "id-external": ""}, {"name": "Abdus Saboor", "id-internal": "118/7430", "id-external": ""}, {"name": "Amjad Ali 0004", "id-internal": "28/9766-4", "id-external": ""}], "url": {"full": "URL#4811", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2994170424, "title": "Unsupervised Fake News Detection Based on Autoencoder.", "abstract": "", "doi": "10.1109/access.2021.3058809", "date": "2021", "authors": [{"name": "Dun Li", "id-internal": "93/7773", "id-external": ""}, {"name": "Haimei Guo", "id-internal": "286/6376", "id-external": ""}, {"name": "Zhenfei Wang", "id-internal": "91/10516", "id-external": ""}, {"name": "Zhiyun Zheng", "id-internal": "18/3391", "id-external": ""}], "url": {"full": "URL#5688", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4143872408, "title": "MVAN - Multi-View Attention Networks for Fake News Detection on Social Media.", "abstract": "", "doi": "10.1109/access.2021.3100245", "date": "2021", "authors": [{"name": "Shiwen Ni", "id-internal": "279/5319", "id-external": ""}, {"name": "Jiawen Li", "id-internal": "78/11207", "id-external": ""}, {"name": "Hung-Yu Kao", "id-internal": "64/5833", "id-external": ""}], "url": {"full": "URL#6940", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 280511899, "title": "Advanced Machine Learning techniques for fake news (online disinformation) detection - A systematic mapping study.", "abstract": "", "doi": "10.1016/j.asoc.2020.107050", "date": "2021", "authors": [{"name": "Michal Choras", "id-internal": "06/2936", "id-external": ""}, {"name": "Konstantinos P. Demestichas", "id-internal": "37/872", "id-external": ""}, {"name": "Agata Gielczyk", "id-internal": "226/5062", "id-external": ""}, {"name": "\u00c1lvaro Herrero", "id-internal": "92/2688", "id-external": ""}, {"name": "Pawel Ksieniewicz", "id-internal": "145/6756", "id-external": ""}, {"name": "Konstantina Remoundou", "id-internal": "263/9694", "id-external": ""}, {"name": "Daniel Urda", "id-internal": "92/9053", "id-external": ""}, {"name": "Michal Wozniak 0001", "id-internal": "37/5714-1", "id-external": ""}], "url": {"full": "URL#14654", "pdf": ""}, "publisher-venue": "Appl. Soft Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1472824560, "title": "Detecting fake news with capsule neural networks.", "abstract": "", "doi": "10.1016/j.asoc.2020.106991", "date": "2021", "authors": [{"name": "Mohammad Hadi Goldani", "id-internal": "258/1041", "id-external": ""}, {"name": "Saeedeh Momtazi", "id-internal": "51/3441", "id-external": ""}, {"name": "Reza Safabakhsh", "id-internal": "44/839", "id-external": ""}], "url": {"full": "URL#14726", "pdf": ""}, "publisher-venue": "Appl. Soft Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2918590199, "title": "Cross-SEAN - A cross-stitch semi-supervised neural attention model for COVID-19 fake news detection.", "abstract": "", "doi": "10.1016/j.asoc.2021.107393", "date": "2021", "authors": [{"name": "William Scott Paka", "id-internal": "23/4401-1", "id-external": ""}, {"name": "Rachit Bansal", "id-internal": "228/6038", "id-external": ""}, {"name": "Abhay Kaushik", "id-internal": "285/6219", "id-external": ""}, {"name": "Shubhashis Sengupta", "id-internal": "33/5030", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}], "url": {"full": "URL#14920", "pdf": ""}, "publisher-venue": "Appl. Soft Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1809324704, "title": "Multiple features based approach for automatic fake news detection on social networks using deep learning.", "abstract": "", "doi": "10.1016/j.asoc.2020.106983", "date": "2021", "authors": [{"name": "Somya Ranjan Sahoo", "id-internal": "242/1772", "id-external": ""}, {"name": "Brij B. Gupta", "id-internal": "185/9576", "id-external": ""}], "url": {"full": "URL#14964", "pdf": ""}, "publisher-venue": "Appl. Soft Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3186556466, "title": "Would you notice if fake news changed your behavior? An experiment on the unconscious effects of disinformation.", "abstract": "", "doi": "10.1016/j.chb.2020.106633", "date": "2021", "authors": {"name": "Zach Bastick", "id-internal": "217/2209", "id-external": ""}, "url": {"full": "URL#21750", "pdf": ""}, "publisher-venue": "Comput. Hum. Behav.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2034776041, "title": "Designing for fake news literacy training - A problem-based undergraduate online-course.", "abstract": "", "doi": "10.1016/j.chb.2021.106796", "date": "2021", "authors": [{"name": "Christian Scheibenzuber", "id-internal": "248/5118", "id-external": ""}, {"name": "Sarah Hofer", "id-internal": "272/1358", "id-external": ""}, {"name": "Nicolae Nistor", "id-internal": "14/2140", "id-external": ""}], "url": {"full": "URL#21986", "pdf": ""}, "publisher-venue": "Comput. Hum. Behav.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4044786375, "title": "Struggling to strike the right balance between interests at stake - The 'Yarovaya', 'Fake news' and 'Disrespect' laws as examples of ill-conceived legislation in the age of modern technology.", "abstract": "", "doi": "10.1016/j.clsr.2020.105512", "date": "2021", "authors": [{"name": "E. Moyakine", "id-internal": "292/6277", "id-external": ""}, {"name": "A. Tabachnik", "id-internal": "292/6238", "id-external": ""}], "url": {"full": "URL#22591", "pdf": ""}, "publisher-venue": "Comput. Law Secur. Rev.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1434880878, "title": "Arabic Fake News Detection - Comparative Study of Neural Networks and Transformer-Based Approaches.", "abstract": "", "doi": "10.1155/2021/5516945", "date": "2021", "authors": [{"name": "Maha Al-Yahya", "id-internal": "231/4754", "id-external": ""}, {"name": "Hend S. Al-Khalifa", "id-internal": "23/2615", "id-external": ""}, {"name": "Heyam H. Al-Baity", "id-internal": "245/7911", "id-external": ""}, {"name": "Duaa H. AlSaeed", "id-internal": "120/4490", "id-external": ""}, {"name": "Amr Essam", "id-internal": "292/9411", "id-external": ""}], "url": {"full": "URL#25418", "pdf": ""}, "publisher-venue": "Complex.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2732454566, "title": "Deep Learning for Fake News Detection in a Pairwise Textual Input Schema.", "abstract": "", "doi": "10.3390/computation9020020", "date": "2021", "authors": [{"name": "Despoina Mouratidis", "id-internal": "219/6351", "id-external": ""}, {"name": "Maria Nefeli Nikiforos", "id-internal": "266/0688", "id-external": ""}, {"name": "Katia Lida Kermanidis", "id-internal": "23/4683", "id-external": ""}], "url": {"full": "URL#26775", "pdf": ""}, "publisher-venue": "Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1788937208, "title": "Controlling Fake News by Collective Tagging - A Branching Process Analysis.", "abstract": "", "doi": "10.1109/lcsys.2020.3045299", "date": "2021", "authors": [{"name": "Suyog Kapsikar", "id-internal": "274/1238", "id-external": ""}, {"name": "Indrajit Saha", "id-internal": "39/3217", "id-external": ""}, {"name": "Khushboo Agarwal", "id-internal": "05/7496", "id-external": ""}, {"name": "Veeraruna Kavitha", "id-internal": "20/7822", "id-external": ""}, {"name": "Quanyan Zhu", "id-internal": "03/6207", "id-external": ""}], "url": {"full": "URL#29680", "pdf": ""}, "publisher-venue": "IEEE Control. Syst. Lett.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1510879509, "title": "Combating COVID-19 fake news on social media through fact checking - antecedents and consequences.", "abstract": "", "doi": "10.1080/0960085x.2021.1895682", "date": "2021", "authors": [{"name": "Sebastian Walter Schuetz", "id-internal": "130/7764", "id-external": ""}, {"name": "Tracy Ann Sykes", "id-internal": "09/9108", "id-external": ""}, {"name": "Viswanath Venkatesh", "id-internal": "23/515", "id-external": ""}], "url": {"full": "URL#33320", "pdf": ""}, "publisher-venue": "Eur. J. Inf. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1837720798, "title": "Impact of mobile connectivity and freedom on fake news propensity during the COVID-19 pandemic - a cross-country empirical examination.", "abstract": "", "doi": "10.1080/0960085x.2021.1886614", "date": "2021", "authors": [{"name": "Anuragini Shirish", "id-internal": "131/3688", "id-external": ""}, {"name": "Shirish C. Srivastava", "id-internal": "96/6730", "id-external": ""}, {"name": "Shalini Chandra", "id-internal": "72/7554", "id-external": ""}], "url": {"full": "URL#33321", "pdf": ""}, "publisher-venue": "Eur. J. Inf. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1999993867, "title": "Exploiting discourse structure of traditional digital media to enhance automatic fake news detection.", "abstract": "", "doi": "10.1016/j.eswa.2020.114340", "date": "2021", "authors": [{"name": "Alba Bonet-Jover", "id-internal": "286/0124", "id-external": ""}, {"name": "Alejandro Piad-Morffis", "id-internal": "134/0974", "id-external": ""}, {"name": "Estela Saquete", "id-internal": "s/EstelaSaqueteBoro", "id-external": ""}, {"name": "Patricio Mart\u00ednez-Barco", "id-internal": "44/4292", "id-external": ""}, {"name": "Miguel \u00c1ngel Garc\u00eda Cumbreras", "id-internal": "75/5573", "id-external": ""}], "url": {"full": "URL#36025", "pdf": ""}, "publisher-venue": "Expert Syst. Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 852751147, "title": "Linguistic feature based learning model for fake news detection and classification.", "abstract": "", "doi": "10.1016/j.eswa.2020.114171", "date": "2021", "authors": [{"name": "Anshika Choudhary", "id-internal": "286/0335", "id-external": ""}, {"name": "Anuja Arora", "id-internal": "39/10193", "id-external": ""}], "url": {"full": "URL#36102", "pdf": ""}, "publisher-venue": "Expert Syst. Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3557655919, "title": "A temporal ensembling based semi-supervised ConvNet for the detection of fake news articles.", "abstract": "", "doi": "10.1016/j.eswa.2021.115002", "date": "2021", "authors": [{"name": "Priyanka Meel", "id-internal": "166/0645", "id-external": ""}, {"name": "Dinesh Kumar Vishwakarma", "id-internal": "214/0803", "id-external": ""}], "url": {"full": "URL#36474", "pdf": ""}, "publisher-venue": "Expert Syst. Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4251875465, "title": "SemSeq4FD - Integrating global semantic relationship and local sequential order to enhance text representation for fake news detection.", "abstract": "", "doi": "10.1016/j.eswa.2020.114090", "date": "2021", "authors": [{"name": "Yuhang Wang", "id-internal": "50/1242", "id-external": ""}, {"name": "Li Wang", "id-internal": "58/6810", "id-external": ""}, {"name": "Yanjie Yang", "id-internal": "174/6352", "id-external": ""}, {"name": "Tao Lian", "id-internal": "121/4324", "id-external": ""}], "url": {"full": "URL#36794", "pdf": ""}, "publisher-venue": "Expert Syst. Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3638757546, "title": "The mass, fake news, and cognition security.", "abstract": "", "doi": "10.1007/s11704-020-9256-0", "date": "2021", "authors": [{"name": "Bin Guo 0001", "id-internal": "86/2663-1", "id-external": ""}, {"name": "Yasan Ding", "id-internal": "245/2848", "id-external": ""}, {"name": "Yueheng Sun", "id-internal": "83/6984", "id-external": ""}, {"name": "Shuai Ma 0001", "id-internal": "35/6569", "id-external": ""}, {"name": "Ke Li", "id-internal": "75/6627", "id-external": ""}, {"name": "Zhiwen Yu 0001", "id-internal": "z/YuZhiwen", "id-external": ""}], "url": {"full": "URL#37527", "pdf": ""}, "publisher-venue": "Frontiers Comput. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3020781724, "title": "An ensemble machine learning approach through effective feature extraction to classify fake news.", "abstract": "", "doi": "10.1016/j.future.2020.11.022", "date": "2021", "authors": [{"name": "Saqib Hakak", "id-internal": "201/0779", "id-external": ""}, {"name": "Mamoun Alazab", "id-internal": "16/7566", "id-external": ""}, {"name": "Suleman Khan", "id-internal": "27/10474", "id-external": ""}, {"name": "Thippa Reddy Gadekallu", "id-internal": "192/9289", "id-external": ""}, {"name": "Praveen Kumar Reddy Maddikunta", "id-internal": "209/7666", "id-external": ""}, {"name": "Wazir Zada Khan", "id-internal": "13/9286", "id-external": ""}], "url": {"full": "URL#37936", "pdf": ""}, "publisher-venue": "Future Gener. Comput. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2995491305, "title": "Learning How to Separate Fake from Real News - Scalable Digital Tutorials Promoting Students' Civic Online Reasoning.", "abstract": "", "doi": "10.3390/fi13030060", "date": "2021", "authors": [{"name": "Carl-Anton Werner Axelsson", "id-internal": "131/2945", "id-external": ""}, {"name": "Mona Guath", "id-internal": "42/10597", "id-external": ""}, {"name": "Thomas Nygren", "id-internal": "276/8624", "id-external": ""}], "url": {"full": "URL#38274", "pdf": ""}, "publisher-venue": "Future Internet", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 103197687, "title": "Collecting a Large Scale Dataset for Classifying Fake News Tweets Using Weak Supervision.", "abstract": "", "doi": "10.3390/fi13050114", "date": "2021", "authors": [{"name": "Stefan Helmstetter", "id-internal": "228/7260", "id-external": ""}, {"name": "Heiko Paulheim", "id-internal": "39/4064", "id-external": ""}], "url": {"full": "URL#38325", "pdf": ""}, "publisher-venue": "Future Internet", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1138291948, "title": "Realistic Aspects of Simulation Models for Fake News Epidemics over Social Networks.", "abstract": "", "doi": "10.3390/fi13030076", "date": "2021", "authors": [{"name": "Quintino Francesco Lotito", "id-internal": "230/3472", "id-external": ""}, {"name": "Davide Zanella", "id-internal": "248/7512", "id-external": ""}, {"name": "Paolo Casari", "id-internal": "10/363", "id-external": ""}], "url": {"full": "URL#38357", "pdf": ""}, "publisher-venue": "Future Internet", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4178606059, "title": "Protection from 'Fake News' - The Need for Descriptive Factual Labeling for Online Content.", "abstract": "", "doi": "10.3390/fi13060142", "date": "2021", "authors": [{"name": "Matthew Spradling", "id-internal": "137/4946", "id-external": ""}, {"name": "Jeremy Straub", "id-internal": "131/6361", "id-external": ""}, {"name": "Jay Strong", "id-internal": "270/6132", "id-external": ""}], "url": {"full": "URL#38404", "pdf": ""}, "publisher-venue": "Future Internet", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 296974468, "title": "Social media affordances and information abundance - Enabling fake news sharing during the COVID-19 health crisis.", "abstract": "", "doi": "10.1177/14604582211021470", "date": "2021", "authors": [{"name": "Oberiri Destiny Apuke", "id-internal": "282/6130", "id-external": ""}, {"name": "Bahiyah Omar", "id-internal": "266/6880", "id-external": ""}], "url": {"full": "URL#40206", "pdf": ""}, "publisher-venue": "Health Informatics J.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3909985275, "title": "FaD-CODS Fake News Detection on COVID-19 Using Description Logics and Semantic Reasoning.", "abstract": "", "doi": "10.4018/ijitwe.2021070101", "date": "2021", "authors": [{"name": "Kartik Goel", "id-internal": "298/8990", "id-external": ""}, {"name": "Charu Gupta", "id-internal": "128/8045", "id-external": ""}, {"name": "Ria Rawal", "id-internal": "298/8905", "id-external": ""}, {"name": "Prateek Agrawal", "id-internal": "174/2840", "id-external": ""}, {"name": "Vishu Madaan", "id-internal": "174/2906", "id-external": ""}], "url": {"full": "URL#46608", "pdf": ""}, "publisher-venue": "Int. J. Inf. Technol. Web Eng.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1108995271, "title": "Automated Classification of Fake News Spreaders to Break the Misinformation Chain.", "abstract": "", "doi": "10.3390/info12060248", "date": "2021", "authors": [{"name": "Simone Leonardi", "id-internal": "52/1862", "id-external": ""}, {"name": "Giuseppe Rizzo 0002", "id-internal": "89/8577-2", "id-external": ""}, {"name": "Maurizio Morisio", "id-internal": "m/MaurizioMorisio", "id-external": ""}], "url": {"full": "URL#50795", "pdf": ""}, "publisher-venue": "Inf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3862986286, "title": "Combatting Visual Fake News with a Professional Fact-Checking Tool in Education in France, Romania, Spain and Sweden.", "abstract": "", "doi": "10.3390/info12050201", "date": "2021", "authors": [{"name": "Thomas Nygren", "id-internal": "276/8624", "id-external": ""}, {"name": "Mona Guath", "id-internal": "42/10597", "id-external": ""}, {"name": "Carl-Anton Werner Axelsson", "id-internal": "131/2945", "id-external": ""}, {"name": "Divina Frau-Meigs", "id-internal": "130/4577", "id-external": ""}], "url": {"full": "URL#50840", "pdf": ""}, "publisher-venue": "Inf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4032892607, "title": "Identifying Fake News on Social Networks Based on Natural Language Processing - Trends and Challenges.", "abstract": "", "doi": "10.3390/info12010038", "date": "2021", "authors": [{"name": "Nicollas R. de Oliveira", "id-internal": "267/4985", "id-external": ""}, {"name": "Pedro S. Pisa", "id-internal": "284/0301", "id-external": ""}, {"name": "Martin Andreoni Lopez", "id-internal": "167/9022", "id-external": ""}, {"name": "Dianne Scherly Varela de Medeiros", "id-internal": "193/1420", "id-external": ""}, {"name": "Diogo M. F. Mattos", "id-internal": "144/8416", "id-external": ""}], "url": {"full": "URL#50843", "pdf": ""}, "publisher-venue": "Inf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4217038714, "title": "Convolutional neural network with margin loss for fake news detection.", "abstract": "", "doi": "10.1016/j.ipm.2020.102418", "date": "2021", "authors": [{"name": "Mohammad Hadi Goldani", "id-internal": "258/1041", "id-external": ""}, {"name": "Reza Safabakhsh", "id-internal": "44/839", "id-external": ""}, {"name": "Saeedeh Momtazi", "id-internal": "51/3441", "id-external": ""}], "url": {"full": "URL#52806", "pdf": ""}, "publisher-venue": "Inf. Process. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2460641582, "title": "Propagation2Vec - Embedding partial propagation networks for explainable fake news early detection.", "abstract": "", "doi": "10.1016/j.ipm.2021.102618", "date": "2021", "authors": [{"name": "Amila Silva", "id-internal": "220/0876", "id-external": ""}, {"name": "Yi Han 0003", "id-internal": "27/4390-3", "id-external": ""}, {"name": "Ling Luo 0002", "id-internal": "00/1811-2", "id-external": ""}, {"name": "Shanika Karunasekera", "id-internal": "47/5584", "id-external": ""}, {"name": "Christopher Leckie", "id-internal": "73/1139", "id-external": ""}], "url": {"full": "URL#52898", "pdf": ""}, "publisher-venue": "Inf. Process. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4007063122, "title": "A multimodal fake news detection model based on crossmodal attention residual and multichannel convolutional neural networks.", "abstract": "", "doi": "10.1016/j.ipm.2020.102437", "date": "2021", "authors": [{"name": "Chenguang Song", "id-internal": "243/4021", "id-external": ""}, {"name": "Nianwen Ning", "id-internal": "225/1421", "id-external": ""}, {"name": "Yunlei Zhang", "id-internal": "173/9377", "id-external": ""}, {"name": "Bin Wu 0001", "id-internal": "98/4432-1", "id-external": ""}], "url": {"full": "URL#52901", "pdf": ""}, "publisher-venue": "Inf. Process. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1718396739, "title": "Detecting fake news by exploring the consistency of multimodal data.", "abstract": "", "doi": "10.1016/j.ipm.2021.102610", "date": "2021", "authors": [{"name": "Junxiao Xue", "id-internal": "38/1915", "id-external": ""}, {"name": "Yabo Wang", "id-internal": "87/2161", "id-external": ""}, {"name": "Yichen Tian", "id-internal": "51/9949", "id-external": ""}, {"name": "Yafei Li", "id-internal": "32/8087", "id-external": ""}, {"name": "Lei Shi", "id-internal": "29/563", "id-external": ""}, {"name": "Lin Wei", "id-internal": "99/5898", "id-external": ""}], "url": {"full": "URL#52927", "pdf": ""}, "publisher-venue": "Inf. Process. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1788203124, "title": "HAN, image captioning, and forensics ensemble multimodal fake news detection.", "abstract": "", "doi": "10.1016/j.ins.2021.03.037", "date": "2021", "authors": [{"name": "Priyanka Meel", "id-internal": "166/0645", "id-external": ""}, {"name": "Dinesh Kumar Vishwakarma", "id-internal": "214/0803", "id-external": ""}], "url": {"full": "URL#53566", "pdf": ""}, "publisher-venue": "Inf. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1716812864, "title": "Fake News, Investor Attention, and Market Reaction.", "abstract": "", "doi": "10.1287/isre.2019.0910", "date": "2021", "authors": [{"name": "Jonathan Clarke", "id-internal": "67/10656", "id-external": ""}, {"name": "Hailiang Chen", "id-internal": "00/8051", "id-external": ""}, {"name": "Ding Du", "id-internal": "40/2264", "id-external": ""}, {"name": "Yu (Jeffrey) Hu", "id-internal": "94/7877", "id-external": ""}], "url": {"full": "URL#54224", "pdf": ""}, "publisher-venue": "Inf. Syst. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2970613358, "title": "Affelt, Amy. All that's not fit to print - Fake news and the call to action for librarians and information professionals. London, UK - Emerald, 2019, 176 pp. \u00a339.99 (paperback) (ISBN 9781789733648).", "abstract": "", "doi": "10.1002/asi.24356", "date": "2021", "authors": {"name": "Thomas J. Froehlich", "id-internal": "67/3562", "id-external": ""}, "url": {"full": "URL#56313", "pdf": ""}, "publisher-venue": "J. Assoc. Inf. Sci. Technol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2847162113, "title": "The information manifold - Why computers cannot solve algorithmic bias and fake news. Badia, Antonio Cambridge, UK - The MIT press, 2019.", "abstract": "", "doi": "10.1002/asi.24365", "date": "2021", "authors": {"name": "Marc Kosciejew", "id-internal": "169/8229", "id-external": ""}, "url": {"full": "URL#56315", "pdf": ""}, "publisher-venue": "J. Assoc. Inf. Sci. Technol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4005632071, "title": "Detecting fake news stories via multimodal analysis.", "abstract": "", "doi": "10.1002/asi.24359", "date": "2021", "authors": [{"name": "Vivek K. Singh", "id-internal": "96/3854", "id-external": ""}, {"name": "Isha Ghosh", "id-internal": "179/2353", "id-external": ""}, {"name": "Darshan Sonagara", "id-internal": "282/3063", "id-external": ""}], "url": {"full": "URL#56330", "pdf": ""}, "publisher-venue": "J. Assoc. Inf. Sci. Technol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3174965045, "title": "Trends in combating fake news on social media - a survey.", "abstract": "", "doi": "10.1080/24751839.2020.1847379", "date": "2021", "authors": [{"name": "Botambu Collins", "id-internal": "256/4806", "id-external": ""}, {"name": "Dinh Tuyen Hoang", "id-internal": "194/3689", "id-external": ""}, {"name": "Ngoc Thanh Nguyen", "id-internal": "n/NgocThanhNguyen", "id-external": ""}, {"name": "Dosam Hwang", "id-internal": "91/6746", "id-external": ""}], "url": {"full": "URL#60636", "pdf": ""}, "publisher-venue": "J. Inf. Telecommun.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2997242767, "title": "The Effectiveness of Social Norms in Fighting Fake News on Social Media.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Henner Gimpel", "id-internal": "41/4552", "id-external": ""}, {"name": "Sebastian Heger", "id-internal": "152/9129", "id-external": ""}, {"name": "Christian Olenberger", "id-internal": "236/7970", "id-external": ""}, {"name": "Lena Utz", "id-internal": "220/4574", "id-external": ""}], "url": {"full": "URL#62754", "pdf": ""}, "publisher-venue": "J. Manag. Inf. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 183026482, "title": "EchoFakeD - improving fake news detection in social media with an efficient deep neural network.", "abstract": "", "doi": "10.1007/s00521-020-05611-1", "date": "2021", "authors": [{"name": "Rohit Kumar Kaliyar", "id-internal": "261/1345", "id-external": ""}, {"name": "Anurag Goswami", "id-internal": "139/3865", "id-external": ""}, {"name": "Pratik Narang", "id-internal": "132/9397", "id-external": ""}], "url": {"full": "URL#73821", "pdf": ""}, "publisher-venue": "Neural Comput. Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3029571188, "title": "On fake news, gatekeepers and LIS professionals - the finger or the moon?", "abstract": "", "doi": "10.1108/dlp-09-2020-0097", "date": "2021", "authors": {"name": "Matilde Fontanin", "id-internal": "233/4859", "id-external": ""}, "url": {"full": "URL#76190", "pdf": ""}, "publisher-venue": "Digit. Libr. Perspect.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3261782241, "title": "User motivation in fake news sharing during the COVID-19 pandemic - an application of the uses and gratification theory.", "abstract": "", "doi": "10.1108/oir-03-2020-0116", "date": "2021", "authors": [{"name": "Oberiri Destiny Apuke", "id-internal": "282/6130", "id-external": ""}, {"name": "Bahiyah Omar", "id-internal": "266/6880", "id-external": ""}], "url": {"full": "URL#76200", "pdf": ""}, "publisher-venue": "Online Inf. Rev.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3902126022, "title": "Supervised ensemble learning methods towards automatically filtering Urdu fake news within social media.", "abstract": "", "doi": "10.7717/peerj-cs.425", "date": "2021", "authors": [{"name": "Muhammad Pervez Akhter", "id-internal": "261/4493", "id-external": ""}, {"name": "Jiangbin Zheng", "id-internal": "49/1013", "id-external": ""}, {"name": "Farkhanda Afzal", "id-internal": "264/0824", "id-external": ""}, {"name": "Hui Lin", "id-internal": "37/3545", "id-external": ""}, {"name": "Saleem Riaz", "id-internal": "289/6783", "id-external": ""}, {"name": "Atif Mehmood", "id-internal": "08/808", "id-external": ""}], "url": {"full": "URL#77662", "pdf": ""}, "publisher-venue": "PeerJ Comput. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1417940364, "title": "Fake news detection - a survey of evaluation datasets.", "abstract": "", "doi": "10.7717/peerj-cs.518", "date": "2021", "authors": [{"name": "Arianna D'Ulizia", "id-internal": "97/3762", "id-external": ""}, {"name": "Maria Chiara Caschera", "id-internal": "74/6091", "id-external": ""}, {"name": "Fernando Ferri", "id-internal": "16/4746", "id-external": ""}, {"name": "Patrizia Grifoni", "id-internal": "85/1960", "id-external": ""}], "url": {"full": "URL#77733", "pdf": ""}, "publisher-venue": "PeerJ Comput. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3466773585, "title": "Using of n-grams from morphological tags for fake news classification.", "abstract": "", "doi": "10.7717/peerj-cs.624", "date": "2021", "authors": [{"name": "Jozef Kapusta", "id-internal": "97/4528", "id-external": ""}, {"name": "Martin Drl\u00edk", "id-internal": "37/9478", "id-external": ""}, {"name": "Michal Munk", "id-internal": "75/6508", "id-external": ""}], "url": {"full": "URL#77796", "pdf": ""}, "publisher-venue": "PeerJ Comput. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 939263573, "title": "The Influence of Political Ideology on Fake News Belief - The Portuguese Case.", "abstract": "", "doi": "10.3390/publications9020023", "date": "2021", "authors": [{"name": "Jo\u00e3o Pedro Baptista", "id-internal": "292/3211", "id-external": ""}, {"name": "Elisete Correia", "id-internal": "295/9349", "id-external": ""}, {"name": "Anabela Gradim", "id-internal": "292/2535", "id-external": ""}, {"name": "Valeriano Pi\u00f1eiro-Naval", "id-internal": "152/8847", "id-external": ""}], "url": {"full": "URL#79393", "pdf": ""}, "publisher-venue": "Publ.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1366535842, "title": "Young Spanish Adults and Disinformation - Do They Identify and Spread Fake News and Are They Literate in It?", "abstract": "", "doi": "10.3390/publications9010002", "date": "2021", "authors": [{"name": "Aida Mar\u00eda de Vicente Dom\u00ednguez", "id-internal": "290/7056", "id-external": ""}, {"name": "Ana Beriain Ba\u00f1ares", "id-internal": "290/7060", "id-external": ""}, {"name": "Javier Sierra S\u00e1nchez", "id-internal": "290/7061", "id-external": ""}], "url": {"full": "URL#79398", "pdf": ""}, "publisher-venue": "Publ.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3800060241, "title": "Fake News Reaching Young People on Social Networks - Distrust Challenging Media Literacy.", "abstract": "", "doi": "10.3390/publications9020024", "date": "2021", "authors": [{"name": "Ana P\u00e9rez-Escoda", "id-internal": "137/9065", "id-external": ""}, {"name": "Luis Miguel Pedrero Esteban", "id-internal": "191/8703", "id-external": ""}, {"name": "Juana Rubio-Romero", "id-internal": "295/9860", "id-external": ""}, {"name": "Carlos Jim\u00e9nez-Narros", "id-internal": "295/9159", "id-external": ""}], "url": {"full": "URL#79408", "pdf": ""}, "publisher-venue": "Publ.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3448773231, "title": "COVID-19 fake news diffusion across Latin America.", "abstract": "", "doi": "10.1007/s13278-021-00753-z", "date": "2021", "authors": [{"name": "Wilson Ceron", "id-internal": "278/0576", "id-external": ""}, {"name": "Gabriela Gruszynski Sanseverino", "id-internal": "294/0723", "id-external": ""}, {"name": "Mathias-Felipe de-Lima-Santos", "id-internal": "281/7708", "id-external": ""}, {"name": "Marcos G. Quiles", "id-internal": "70/1985", "id-external": ""}], "url": {"full": "URL#94961", "pdf": ""}, "publisher-venue": "Soc. Netw. Anal. Min.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3702084284, "title": "A transformer-based architecture for fake news classification.", "abstract": "", "doi": "10.1007/s13278-021-00738-y", "date": "2021", "authors": [{"name": "Divyam Mehta", "id-internal": "292/4714", "id-external": ""}, {"name": "Aniket Dwivedi", "id-internal": "255/1963", "id-external": ""}, {"name": "Arunabha Patra", "id-internal": "292/4647", "id-external": ""}, {"name": "M. Anand Kumar", "id-internal": "186/7709", "id-external": ""}], "url": {"full": "URL#94994", "pdf": ""}, "publisher-venue": "Soc. Netw. Anal. Min.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 738761879, "title": "CHECKED - Chinese COVID-19 fake news dataset.", "abstract": "", "doi": "10.1007/s13278-021-00766-8", "date": "2021", "authors": [{"name": "Chen Yang", "id-internal": "01/2478", "id-external": ""}, {"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}], "url": {"full": "URL#95021", "pdf": ""}, "publisher-venue": "Soc. Netw. Anal. Min.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3091493391, "title": "Detection of Online Fake News Using Blending Ensemble Learning.", "abstract": "", "doi": "10.1155/2021/3434458", "date": "2021", "authors": [{"name": "Arvin Hansrajh", "id-internal": "299/0360", "id-external": ""}, {"name": "Timothy T. Adeliyi", "id-internal": "225/9561", "id-external": ""}, {"name": "Jeanette W. Wing", "id-internal": "172/7433", "id-external": ""}], "url": {"full": "URL#96493", "pdf": ""}, "publisher-venue": "Sci. Program.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3243027561, "title": "An Evolutionary Fake News Detection Method for COVID-19 Pandemic Information.", "abstract": "", "doi": "10.3390/sym13061091", "date": "2021", "authors": [{"name": "Bilal Al-Ahmad", "id-internal": "231/6820", "id-external": ""}, {"name": "Ala' M. Al-Zoubi", "id-internal": "210/0901", "id-external": ""}, {"name": "Ruba Abu Khurma", "id-internal": "263/0132", "id-external": ""}, {"name": "Ibrahim Aljarah", "id-internal": "61/10168", "id-external": ""}], "url": {"full": "URL#98310", "pdf": ""}, "publisher-venue": "Symmetry", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3825733419, "title": "Fighting Fake News - Two Stream Network for Deepfake Detection via Learnable SRM.", "abstract": "", "doi": "10.1109/tbiom.2021.3065735", "date": "2021", "authors": [{"name": "Bing Han", "id-internal": "74/2721", "id-external": ""}, {"name": "Xiaoguang Han", "id-internal": "60/8294", "id-external": ""}, {"name": "Hua Zhang 0008", "id-internal": "69/2745-8", "id-external": ""}, {"name": "Jingzhi Li", "id-internal": "17/1271", "id-external": ""}, {"name": "Xiaochun Cao", "id-internal": "39/3695", "id-external": ""}], "url": {"full": "URL#101538", "pdf": ""}, "publisher-venue": "IEEE Trans. Biom. Behav. Identity Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 327962531, "title": "WELFake - Word Embedding Over Linguistic Features for Fake News Detection.", "abstract": "", "doi": "10.1109/tcss.2021.3068519", "date": "2021", "authors": [{"name": "Pawan Kumar Verma", "id-internal": "17/1321", "id-external": ""}, {"name": "Prateek Agrawal", "id-internal": "174/2840", "id-external": ""}, {"name": "Ivone Amorim", "id-internal": "118/5957", "id-external": ""}, {"name": "Radu Prodan", "id-internal": "43/1754", "id-external": ""}], "url": {"full": "URL#104595", "pdf": ""}, "publisher-venue": "IEEE Trans. Comput. Soc. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1367937252, "title": "DeepFakE - improving fake news detection using tensor decomposition-based deep neural network.", "abstract": "", "doi": "10.1007/s11227-020-03294-y", "date": "2021", "authors": [{"name": "Rohit Kumar Kaliyar", "id-internal": "261/1345", "id-external": ""}, {"name": "Anurag Goswami", "id-internal": "139/3865", "id-external": ""}, {"name": "Pratik Narang", "id-internal": "132/9397", "id-external": ""}], "url": {"full": "URL#113155", "pdf": ""}, "publisher-venue": "J. Supercomput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2529017576, "title": "FADE - Detecting Fake News Articles on the Web.", "abstract": "", "doi": "10.1145/3465481.3465751", "date": "2021", "authors": [{"name": "Bahruz Jabiyev", "id-internal": "291/2820", "id-external": ""}, {"name": "Sinan Pehlivanoglu", "id-internal": "299/5892", "id-external": ""}, {"name": "Kaan Onarlioglu", "id-internal": "77/8031", "id-external": ""}, {"name": "Engin Kirda", "id-internal": "k/EnginKirda", "id-external": ""}], "url": {"full": "URL#122681", "pdf": ""}, "publisher-venue": "ARES", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3980051063, "title": "DISSIMILAR - Towards fake news detection using information hiding, signal processing and machine learning.", "abstract": "", "doi": "10.1145/3465481.3470088", "date": "2021", "authors": [{"name": "David Meg\u00edas", "id-internal": "68/4929", "id-external": ""}, {"name": "Minoru Kuribayashi", "id-internal": "04/2360", "id-external": ""}, {"name": "Andrea Rosales", "id-internal": "36/8329", "id-external": ""}, {"name": "Wojciech Mazurczyk", "id-internal": "91/874", "id-external": ""}], "url": {"full": "URL#122709", "pdf": ""}, "publisher-venue": "ARES", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2769800985, "title": "Model Generalization on COVID-19 Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_13", "date": "2021", "authors": [{"name": "Yejin Bang", "id-internal": "261/2805", "id-external": ""}, {"name": "Etsuko Ishii", "id-internal": "261/2881", "id-external": ""}, {"name": "Samuel Cahyawijaya", "id-internal": "235/2988", "id-external": ""}, {"name": "Ziwei Ji", "id-internal": "176/4574", "id-external": ""}, {"name": "Pascale Fung", "id-internal": "29/4187", "id-external": ""}], "url": {"full": "URL#123189", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 669554478, "title": "Transformer-Based Language Model Fine-Tuning Methods for COVID-19 Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_9", "date": "2021", "authors": [{"name": "Ben Chen", "id-internal": "94/4500", "id-external": ""}, {"name": "Bin Chen", "id-internal": "22/5523", "id-external": ""}, {"name": "Dehong Gao", "id-internal": "59/9911", "id-external": ""}, {"name": "Qijin Chen", "id-internal": "193/2124", "id-external": ""}, {"name": "Chengfu Huo", "id-internal": "81/8757", "id-external": ""}, {"name": "Xiaonan Meng", "id-internal": "200/8976", "id-external": ""}, {"name": "Weijun Ren", "id-internal": "214/8201", "id-external": ""}, {"name": "Yang Zhou", "id-internal": "07/4580", "id-external": ""}], "url": {"full": "URL#123314", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 617486867, "title": "A Heuristic-Driven Ensemble Framework for COVID-19 Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_16", "date": "2021", "authors": [{"name": "Sourya Dipta Das", "id-internal": "217/1530", "id-external": ""}, {"name": "Ayan Basak", "id-internal": "256/4299", "id-external": ""}, {"name": "Saikat Dutta", "id-internal": "260/3198", "id-external": ""}], "url": {"full": "URL#123421", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1911223155, "title": "KAN - Knowledge-aware Attention Network for Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Yaqian Dun", "id-internal": "294/0019", "id-external": ""}, {"name": "Kefei Tu", "id-internal": "290/3569", "id-external": ""}, {"name": "Chen Chen", "id-internal": "65/4423", "id-external": ""}, {"name": "Chunyan Hou", "id-internal": "66/3541", "id-external": ""}, {"name": "Xiaojie Yuan", "id-internal": "79/2280", "id-external": ""}], "url": {"full": "URL#123481", "pdf": ""}, "publisher-venue": "AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2797282495, "title": "Fake News Detection System Using XLNet Model with Topic Distributions - CONSTRAINT@AAAI2021 Shared Task.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_18", "date": "2021", "authors": [{"name": "Akansha Gautam", "id-internal": "272/8689", "id-external": ""}, {"name": "Venktesh V", "id-internal": "274/2996", "id-external": ""}, {"name": "Sarah Masud", "id-internal": "115/9011", "id-external": ""}], "url": {"full": "URL#123586", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2986733326, "title": "Exploring Text-Transformers in AAAI 2021 Shared Task - COVID-19 Fake News Detection in English.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_11", "date": "2021", "authors": [{"name": "Xiangyang Li", "id-internal": "80/4579", "id-external": ""}, {"name": "Yu Xia", "id-internal": "28/4326", "id-external": ""}, {"name": "Xiang Long", "id-internal": "64/6328", "id-external": ""}, {"name": "Zheng Li", "id-internal": "10/1143", "id-external": ""}, {"name": "Sujian Li", "id-internal": "05/4288", "id-external": ""}], "url": {"full": "URL#123997", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2977816430, "title": "Overview of CONSTRAINT 2021 Shared Tasks - Detecting English COVID-19 Fake News and Hindi Hostile Posts.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_5", "date": "2021", "authors": [{"name": "Parth Patwa", "id-internal": "260/9345", "id-external": ""}, {"name": "Mohit Bhardwaj", "id-internal": "276/5843", "id-external": ""}, {"name": "Vineeth Guptha", "id-internal": "266/0781", "id-external": ""}, {"name": "Gitanjali Kumari", "id-internal": "278/2631", "id-external": ""}, {"name": "Shivam Sharma", "id-internal": "146/2381", "id-external": ""}, {"name": "Srinivas PYKL", "id-internal": "168/6642", "id-external": ""}, {"name": "Amitava Das", "id-internal": "75/5002", "id-external": ""}, {"name": "Asif Ekbal", "id-internal": "11/3590", "id-external": ""}, {"name": "Md. Shad Akhtar", "id-internal": "184/8579", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}], "url": {"full": "URL#124303", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4294267140, "title": "Fake News and Hostile Posts Detection Using an Ensemble Learning Model.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_8", "date": "2021", "authors": [{"name": "Siyao Zhou", "id-internal": "236/7749", "id-external": ""}, {"name": "Jie Li", "id-internal": "17/2703", "id-external": ""}, {"name": "Haiyan Ding", "id-internal": "49/751", "id-external": ""}], "url": {"full": "URL#125022", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3690667562, "title": "LUX (Linguistic aspects Under eXamination) - Discourse Analysis for Automatic Fake News Classification.", "abstract": "", "doi": "10.18653/v1/2021.findings-acl.4", "date": "2021", "authors": [{"name": "Lucas Azevedo", "id-internal": "215/3319", "id-external": ""}, {"name": "Mathieu d'Aquin", "id-internal": "55/4776", "id-external": ""}, {"name": "Brian Davis 0001", "id-internal": "04/285-1", "id-external": ""}, {"name": "Manel Zarrouk", "id-internal": "116/2848", "id-external": ""}], "url": {"full": "URL#125332", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3616208120, "title": "Cross-lingual Evidence Improves Monolingual Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Daryna Dementieva", "id-internal": "279/2369", "id-external": ""}, {"name": "Alexander Panchenko", "id-internal": "60/9162", "id-external": ""}], "url": {"full": "URL#125471", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 556053115, "title": "InfoSurgeon - Cross-Media Fine-grained Information Consistency Checking for Fake News Detection.", "abstract": "", "doi": "10.18653/v1/2021.acl-long.133", "date": "2021", "authors": [{"name": "Yi Fung", "id-internal": "295/4422", "id-external": ""}, {"name": "Christopher Thomas", "id-internal": "21/4235", "id-external": ""}, {"name": "Revanth Gangi Reddy", "id-internal": "276/5899", "id-external": ""}, {"name": "Sandeep Polisetty", "id-internal": "274/2983", "id-external": ""}, {"name": "Heng Ji", "id-internal": "61/2408", "id-external": ""}, {"name": "Shih-Fu Chang", "id-internal": "c/ShihFuChang", "id-external": ""}, {"name": "Kathleen R. McKeown", "id-internal": "m/KathleenMcKeown", "id-external": ""}, {"name": "Mohit Bansal", "id-internal": "32/5243", "id-external": ""}, {"name": "Avi Sil", "id-internal": "07/10489", "id-external": ""}], "url": {"full": "URL#125527", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3326916783, "title": "Automatic Fake News Detection - Are Models Learning to Reason?", "abstract": "", "doi": "10.18653/v1/2021.acl-short.12", "date": "2021", "authors": [{"name": "Casper Hansen", "id-internal": "205/2958", "id-external": ""}, {"name": "Christian Hansen 0004", "id-internal": "57/2217-4", "id-external": ""}, {"name": "Lucas Chaves Lima", "id-internal": "238/0439", "id-external": ""}], "url": {"full": "URL#125597", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2869397234, "title": "Compare to The Knowledge - Graph Neural Fake News Detection with External Knowledge.", "abstract": "", "doi": "10.18653/v1/2021.acl-long.62", "date": "2021", "authors": [{"name": "Linmei Hu", "id-internal": "141/4440", "id-external": ""}, {"name": "Tianchi Yang", "id-internal": "20/2167", "id-external": ""}, {"name": "Luhao Zhang", "id-internal": "254/8164", "id-external": ""}, {"name": "Wanjun Zhong", "id-internal": "227/2128", "id-external": ""}, {"name": "Duyu Tang", "id-internal": "135/6318", "id-external": ""}, {"name": "Chuan Shi", "id-internal": "64/3041", "id-external": ""}, {"name": "Nan Duan", "id-internal": "30/8160", "id-external": ""}, {"name": "Ming Zhou 0001", "id-internal": "16/1161-1", "id-external": ""}], "url": {"full": "URL#125632", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1095244579, "title": "Multimodal Fusion with Co-Attention Networks for Fake News Detection.", "abstract": "", "doi": "10.18653/v1/2021.findings-acl.226", "date": "2021", "authors": [{"name": "Yang Wu", "id-internal": "56/1428", "id-external": ""}, {"name": "Pengwei Zhan", "id-internal": "284/1181", "id-external": ""}, {"name": "Yunjian Zhang", "id-internal": "166/4074", "id-external": ""}, {"name": "LiMing Wang", "id-internal": "51/8", "id-external": ""}, {"name": "Zhen Xu", "id-internal": "02/6332", "id-external": ""}], "url": {"full": "URL#126283", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3608344236, "title": "Controlling Fake News by Collective Tagging - A Branching Process Analysis.", "abstract": "", "doi": "10.23919/acc50511.2021.9483257", "date": "2021", "authors": [{"name": "Suyog Kapsikar", "id-internal": "274/1238", "id-external": ""}, {"name": "Indrajit Saha", "id-internal": "39/3217", "id-external": ""}, {"name": "Khushboo Agarwal", "id-internal": "05/7496", "id-external": ""}, {"name": "Veeraruna Kavitha", "id-internal": "20/7822", "id-external": ""}, {"name": "Quanyan Zhu", "id-internal": "03/6207", "id-external": ""}], "url": {"full": "URL#129851", "pdf": ""}, "publisher-venue": "ACC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1630752012, "title": "Combating the spread of fake news on social media through a blockchain-led intervention.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sudarshan Narayanan", "id-internal": "121/8352", "id-external": ""}, {"name": "V S. Prakash Attili", "id-internal": "300/5442", "id-external": ""}], "url": {"full": "URL#130537", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 196444348, "title": "Fake News Detection on the Web - An LSTM-based Approach.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Piyush Vyas", "id-internal": "270/7757", "id-external": ""}, {"name": "Jun Liu 0028", "id-internal": "95/3736-28", "id-external": ""}, {"name": "Omar F. El-Gayar", "id-internal": "16/304", "id-external": ""}], "url": {"full": "URL#130633", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3527866035, "title": "Mitigating Attacks on Fake News Detection Systems using Genetic-Based Adversarial Training.", "abstract": "", "doi": "10.1109/cec45853.2021.9504723", "date": "2021", "authors": [{"name": "Marcellus Smith", "id-internal": "282/8110", "id-external": ""}, {"name": "Brandon Brown", "id-internal": "90/1016", "id-external": ""}, {"name": "Gerry V. Dozier", "id-internal": "88/3850", "id-external": ""}, {"name": "Michael C. King", "id-internal": "214/3280", "id-external": ""}], "url": {"full": "URL#134797", "pdf": ""}, "publisher-venue": "CEC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2959354635, "title": "M82B at CheckThat!\u00a02021 - Multiclass Fake News Detection Using BiLSTM.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sohel Siddique Ashik", "id-internal": "300/1642", "id-external": ""}, {"name": "Abdur Rahman Apu", "id-internal": "300/1219", "id-external": ""}, {"name": "Nusrat Jahan Marjana", "id-internal": "300/1881", "id-external": ""}, {"name": "Md. Sanzidul Islam", "id-internal": "253/0826", "id-external": ""}, {"name": "Md. Arid Hassan", "id-internal": "300/1346", "id-external": ""}], "url": {"full": "URL#137392", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 704829727, "title": "CIC at CheckThat!\u00a02021 - Fake News detection Using Machine Learning And Data Augmentation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Noman Ashraf", "id-internal": "264/2913", "id-external": ""}, {"name": "Sabur Butt", "id-internal": "215/8815", "id-external": ""}, {"name": "Grigori Sidorov", "id-internal": "68/4195", "id-external": ""}, {"name": "Alexander F. Gelbukh", "id-internal": "g/AlexanderFGelbukh", "id-external": ""}], "url": {"full": "URL#137393", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1508375237, "title": "MUCIC at CheckThat!\u00a02021 - FaDo-Fake News Detection and Domain Identification using Transformers Ensembling.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Fazlourrahman Balouchzahi", "id-internal": "277/0925", "id-external": ""}, {"name": "Hosahalli Lakshmaiah Shashirekha", "id-internal": "183/4155", "id-external": ""}, {"name": "Grigori Sidorov", "id-internal": "68/4195", "id-external": ""}], "url": {"full": "URL#137397", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2939954972, "title": "UAICS at CheckThat!\u00a02021 - Fake news detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Ciprian-Gabriel Cusmuliuc", "id-internal": "245/4434", "id-external": ""}, {"name": "Matei Alexandru Amarandei", "id-internal": "300/0804", "id-external": ""}, {"name": "Ioana Pelin", "id-internal": "300/1578", "id-external": ""}, {"name": "Vlad-Iulian Cociorva", "id-internal": "300/0911", "id-external": ""}, {"name": "Adrian Iftene", "id-internal": "71/3415", "id-external": ""}], "url": {"full": "URL#137426", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 923547090, "title": "University of Regensburg at CheckThat!\u00a02021 - Exploring Text Summarization for Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Philipp Hartl", "id-internal": "248/7389", "id-external": ""}, {"name": "Udo Kruschwitz", "id-internal": "07/1751", "id-external": ""}], "url": {"full": "URL#137457", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1801694245, "title": "Nkovachevich at CheckThat!\u00a02021 - BERT fine-tuning approach to fake news detection.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Ninko Kovachevich", "id-internal": "300/1110", "id-external": ""}, "url": {"full": "URL#137476", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 704084997, "title": "NITK_NLP at CheckThat!\u00a02021 - Ensemble Transformer Model for Fake News Classification.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Hariharan RamakrishnaIyer LekshmiAmmal", "id-internal": "300/1442", "id-external": ""}, {"name": "Anand Kumar Madasamy", "id-internal": "186/7709", "id-external": ""}], "url": {"full": "URL#137481", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3563680670, "title": "NLP&IR@UNED at CheckThat!\u00a02021 - Check-worthiness estimation and fake news detection using transformer models.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Juan R. Martinez-Rico", "id-internal": "232/7912", "id-external": ""}, {"name": "Juan Mart\u00ednez-Romo", "id-internal": "128/1735", "id-external": ""}, {"name": "Lourdes Araujo", "id-internal": "24/6640", "id-external": ""}], "url": {"full": "URL#137498", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3290931003, "title": "Team Sigmoid at CheckThat!2021 Task 3a - Multiclass fake news detection with Machine Learning.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Abdullah Al Mamun Sardar", "id-internal": "300/1724", "id-external": ""}, {"name": "Shahalu Akter Salma", "id-internal": "300/1523", "id-external": ""}, {"name": "Md. Sanzidul Islam", "id-internal": "253/0826", "id-external": ""}, {"name": "Md. Arid Hasan", "id-internal": "272/9694", "id-external": ""}, {"name": "Touhid Bhuiyan", "id-internal": "36/4026", "id-external": ""}], "url": {"full": "URL#137539", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2445946049, "title": "Overview of the CLEF-2021 CheckThat! Lab - Task 3 on Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Gautam Kishore Shahi", "id-internal": "178/1872", "id-external": ""}, {"name": "Julia Maria Stru\u00df", "id-internal": "154/2466", "id-external": ""}, {"name": "Thomas Mandl 0001", "id-internal": "m/ThomasMandl", "id-external": ""}], "url": {"full": "URL#137551", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3913301931, "title": "Qword at CheckThat!\u00a02021 - An Extreme Gradient Boosting Approach for Multiclass Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Rudra Sarker Utsha", "id-internal": "300/1387", "id-external": ""}, {"name": "Mumenunnessa Keya", "id-internal": "276/9179", "id-external": ""}, {"name": "Md. Arid Hasan", "id-internal": "272/9694", "id-external": ""}, {"name": "Md. Sanzidul Islam", "id-internal": "253/0826", "id-external": ""}], "url": {"full": "URL#137569", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4136284996, "title": "Challenges for Automatic Detection of Fake News Related to Migration - Invited paper.", "abstract": "", "doi": "10.1109/cogsima51574.2021.9475929", "date": "2021", "authors": [{"name": "Werner Bailer", "id-internal": "58/3746", "id-external": ""}, {"name": "Georg Thallinger", "id-internal": "39/5547", "id-external": ""}, {"name": "Gerhard Backfried", "id-internal": "62/4134", "id-external": ""}, {"name": "Dorothea Thomas-Aniola", "id-internal": "240/3484", "id-external": ""}], "url": {"full": "URL#137855", "pdf": ""}, "publisher-venue": "CogSIMA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3467756213, "title": "Building A Dynamic Corpus Of Fake News Using Commercially Available Machine Translation and NLP Software.", "abstract": "", "doi": "10.1109/cogsima51574.2021.9475934", "date": "2021", "authors": {"name": "George Antoniu Bara", "id-internal": "296/9040", "id-external": ""}, "url": {"full": "URL#137856", "pdf": ""}, "publisher-venue": "CogSIMA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 838689672, "title": "Fake News in European History.", "abstract": "", "doi": "10.1109/cogsima51574.2021.9475936", "date": "2021", "authors": {"name": "Bettina Biron", "id-internal": "296/8280", "id-external": ""}, "url": {"full": "URL#137858", "pdf": ""}, "publisher-venue": "CogSIMA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 309811844, "title": "Modus Operandi in Fake News - Invited Paper.", "abstract": "", "doi": "10.1109/cogsima51574.2021.9475926", "date": "2021", "authors": [{"name": "Edith Huber", "id-internal": "169/6512", "id-external": ""}, {"name": "Bettina Pospisil", "id-internal": "191/8044", "id-external": ""}, {"name": "Wolfgang Haidegger", "id-internal": "53/7277", "id-external": ""}], "url": {"full": "URL#137865", "pdf": ""}, "publisher-venue": "CogSIMA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 41624259, "title": "MCNNet - Generalizing Fake News Detection with a Multichannel Convolutional Neural Network using a Novel COVID-19 Dataset.", "abstract": "", "doi": "10.1145/3430984.3431064", "date": "2021", "authors": [{"name": "Rohit Kumar Kaliyar", "id-internal": "261/1345", "id-external": ""}, {"name": "Anurag Goswami", "id-internal": "139/3865", "id-external": ""}, {"name": "Pratik Narang", "id-internal": "132/9397", "id-external": ""}], "url": {"full": "URL#138200", "pdf": ""}, "publisher-venue": "COMAD/CODS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 952344070, "title": "On the detection of fake news and conspiracy theories.", "abstract": "", "doi": "10.24348/coria.2021.keynote_1", "date": "2021", "authors": {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}, "url": {"full": "URL#138821", "pdf": ""}, "publisher-venue": "CORIA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2392737984, "title": "Comparison of Fake News Detection using Machine Learning and Deep Learning Techniques.", "abstract": "", "doi": "10.1109/crc50527.2021.9392458", "date": "2021", "authors": [{"name": "Saeed Amer Alameri", "id-internal": "290/4289", "id-external": ""}, {"name": "Masnizah Mohd", "id-internal": "62/3687", "id-external": ""}], "url": {"full": "URL#138953", "pdf": ""}, "publisher-venue": "CRC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 640234723, "title": "A Novel Method for Detecting Fake news - Deep Learning Based on Propagation Path Concept.", "abstract": "", "doi": "10.1109/csicc52343.2021.9420601", "date": "2021", "authors": [{"name": "Fatemeh Torgheh", "id-internal": "163/7589", "id-external": ""}, {"name": "Mohammad Reza Keyvanpour", "id-internal": "88/5924", "id-external": ""}, {"name": "Behrooz Masoumi", "id-internal": "22/9344", "id-external": ""}, {"name": "Seyed Vahab Shojaedini", "id-internal": "231/3640", "id-external": ""}], "url": {"full": "URL#140075", "pdf": ""}, "publisher-venue": "CSICC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2210906759, "title": "Fake News Detection Using Machine Learning Methods.", "abstract": "", "doi": "10.1145/3460620.3460753", "date": "2021", "authors": [{"name": "Arun Nagaraja", "id-internal": "166/0280", "id-external": ""}, {"name": "Soumya K. N", "id-internal": "297/8921", "id-external": ""}, {"name": "Anubhav Sinha", "id-internal": "180/6643", "id-external": ""}, {"name": "Jain Vinay Rajendra Kumar", "id-internal": "297/8883", "id-external": ""}, {"name": "Prajwal Nayak", "id-internal": "297/9043", "id-external": ""}], "url": {"full": "URL#142761", "pdf": ""}, "publisher-venue": "DATA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2527811755, "title": "Machine Learning Approach to Detect Fake News, Misinformation in COVID-19 Pandemic.", "abstract": "", "doi": "10.1145/3463677.3463762", "date": "2021", "authors": [{"name": "Sirisha Bojjireddy", "id-internal": "294/7117", "id-external": ""}, {"name": "Soon Ae Chun", "id-internal": "c/SoonAeChun", "id-external": ""}, {"name": "James Geller", "id-internal": "g/JamesGeller", "id-external": ""}], "url": {"full": "URL#143554", "pdf": ""}, "publisher-venue": "DG.O", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 520785020, "title": "Graph-based Fake News Detection using a Summarization Technique.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Gihwan Kim", "id-internal": "247/7806", "id-external": ""}, {"name": "Youngjoong Ko", "id-internal": "29/1445", "id-external": ""}], "url": {"full": "URL#144107", "pdf": ""}, "publisher-venue": "EACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2803082040, "title": "Hierarchical Multi-head Attentive Network for Evidence-aware Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Nguyen Vo", "id-internal": "167/0323", "id-external": ""}, {"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}], "url": {"full": "URL#144294", "pdf": ""}, "publisher-venue": "EACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 561708894, "title": "The CLEF-2021 CheckThat! Lab on Detecting Check-Worthy Claims, Previously Fact-Checked Claims, and Fake News.", "abstract": "", "doi": "10.1007/978-3-030-72240-1_75", "date": "2021", "authors": [{"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Giovanni Da San Martino", "id-internal": "25/3236", "id-external": ""}, {"name": "Tamer Elsayed", "id-internal": "99/5856", "id-external": ""}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o", "id-internal": "40/3383", "id-external": ""}, {"name": "Rub\u00e9n M\u00edguez", "id-internal": "288/7773", "id-external": ""}, {"name": "Shaden Shaar", "id-internal": "234/1620", "id-external": ""}, {"name": "Firoj Alam", "id-internal": "126/2083", "id-external": ""}, {"name": "Fatima Haouari", "id-internal": "243/2755", "id-external": ""}, {"name": "Maram Hasanain", "id-internal": "151/5519", "id-external": ""}, {"name": "Nikolay Babulkov", "id-internal": "264/9922", "id-external": ""}, {"name": "Alex Nikolov", "id-internal": "242/4800", "id-external": ""}, {"name": "Gautam Kishore Shahi", "id-internal": "178/1872", "id-external": ""}, {"name": "Julia Maria Stru\u00df", "id-internal": "154/2466", "id-external": ""}, {"name": "Thomas Mandl 0001", "id-internal": "m/ThomasMandl", "id-external": ""}], "url": {"full": "URL#144618", "pdf": ""}, "publisher-venue": "ECIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4269658450, "title": "Human Experts or Artificial Intelligence? Algorithm Aversion in Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Samuel Kie\u00dfling", "id-internal": "254/7207", "id-external": ""}, {"name": "Kathrin Figl", "id-internal": "13/1231", "id-external": ""}, {"name": "Ulrich Remus", "id-internal": "70/4915", "id-external": ""}], "url": {"full": "URL#144771", "pdf": ""}, "publisher-venue": "ECIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3375239827, "title": "Tracking the Impact of Fake News on US Election Cycles.", "abstract": "", "doi": "10.1145/3462203.3475920", "date": "2021", "authors": [{"name": "Omar Alkhalili", "id-internal": "299/8847", "id-external": ""}, {"name": "Stefan A. Robila", "id-internal": "83/2644", "id-external": ""}], "url": {"full": "URL#148245", "pdf": ""}, "publisher-venue": "GoodIT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2479609418, "title": "Effects of Conspiracy Thinking Style, Framing and Political Interest on Accuracy of Fake News Recognition by Social Media Users - Evidence from Russia, Kazakhstan and Ukraine.", "abstract": "", "doi": "10.1007/978-3-030-77626-8_23", "date": "2021", "authors": [{"name": "Alexander Porshnev", "id-internal": "142/7071", "id-external": ""}, {"name": "Alexandre Miltsov", "id-internal": "269/6356", "id-external": ""}, {"name": "Tetyana Lokot", "id-internal": "188/6751", "id-external": ""}, {"name": "Olessia Koltsova", "id-internal": "137/4921", "id-external": ""}], "url": {"full": "URL#149609", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2886360381, "title": "Fake News Detection via English-to-Spanish Translation - Is It Really Useful?", "abstract": "", "doi": "10.1007/978-3-030-77626-8_9", "date": "2021", "authors": [{"name": "Sebasti\u00e1n Ru\u00edz", "id-internal": "296/5206", "id-external": ""}, {"name": "Eliana Providel", "id-internal": "35/11440", "id-external": ""}, {"name": "Marcelo Mendoza", "id-internal": "21/3488", "id-external": ""}], "url": {"full": "URL#149689", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1493536907, "title": "Testing Users' Ability to Recognize Fake News in Three Countries. An Experimental Perspective.", "abstract": "", "doi": "10.1007/978-3-030-77626-8_25", "date": "2021", "authors": [{"name": "Victoria Vziatysheva", "id-internal": "296/5591", "id-external": ""}, {"name": "Yadviga Sinyavskaya", "id-internal": "205/3275", "id-external": ""}, {"name": "Alexander Porshnev", "id-internal": "142/7071", "id-external": ""}, {"name": "Maxim Terpilovskii", "id-internal": "269/6367", "id-external": ""}, {"name": "Sergei Koltcov", "id-internal": "137/4841", "id-external": ""}, {"name": "Kirill Bryanov", "id-internal": "296/5260", "id-external": ""}], "url": {"full": "URL#149912", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3696965364, "title": "Developing Machine Learning Model for Predicting Social Media Induced Fake News.", "abstract": "", "doi": "10.1007/978-3-030-85447-8_54", "date": "2021", "authors": [{"name": "David Langley", "id-internal": "75/3169", "id-external": ""}, {"name": "Caoimhe Reidy", "id-internal": "300/3187", "id-external": ""}, {"name": "Mark Towey", "id-internal": "300/3587", "id-external": ""}, {"name": "Manisha", "id-internal": "46/9741", "id-external": ""}, {"name": "Denis Dennehy", "id-internal": "143/9987", "id-external": ""}], "url": {"full": "URL#151946", "pdf": ""}, "publisher-venue": "I3E", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1015808865, "title": "Modeling Malicious Behaviors and Fake News Dissemination on Social Networks.", "abstract": "", "doi": "10.1007/978-3-030-85447-8_53", "date": "2021", "authors": [{"name": "Kento Yoshikawa", "id-internal": "284/3270", "id-external": ""}, {"name": "Masatsugu Ichino", "id-internal": "33/6896", "id-external": ""}, {"name": "Hiroshi Yoshiura", "id-internal": "11/1899", "id-external": ""}], "url": {"full": "URL#151980", "pdf": ""}, "publisher-venue": "I3E", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2094237377, "title": "A Hybrid Model for Effective Fake News Detection with a Novel COVID-19 Dataset.", "abstract": "", "doi": "10.5220/0010316010661072", "date": "2021", "authors": [{"name": "Rohit Kumar Kaliyar", "id-internal": "261/1345", "id-external": ""}, {"name": "Anurag Goswami", "id-internal": "139/3865", "id-external": ""}, {"name": "Pratik Narang", "id-internal": "132/9397", "id-external": ""}], "url": {"full": "URL#152194", "pdf": ""}, "publisher-venue": "ICAART", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2343185655, "title": "SERN - Stance Extraction and Reasoning Network for Fake News Detection.", "abstract": "", "doi": "10.1109/icassp39728.2021.9414787", "date": "2021", "authors": [{"name": "Jianhui Xie", "id-internal": "184/0896", "id-external": ""}, {"name": "Song Liu", "id-internal": "80/1141", "id-external": ""}, {"name": "Ruixin Liu", "id-internal": "27/704", "id-external": ""}, {"name": "Yinghong Zhang", "id-internal": "270/1740", "id-external": ""}, {"name": "Yuesheng Zhu", "id-internal": "35/8757", "id-external": ""}], "url": {"full": "URL#154455", "pdf": ""}, "publisher-venue": "ICASSP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3848108140, "title": "Evaluating Fake News Detection Models from Explainable Machine Learning Perspectives.", "abstract": "", "doi": "10.1109/icc42927.2021.9500467", "date": "2021", "authors": [{"name": "Raed Alharbi", "id-internal": "194/5768", "id-external": ""}, {"name": "Minh N. Vu", "id-internal": "234/1850", "id-external": ""}, {"name": "My T. Thai", "id-internal": "63/4711", "id-external": ""}], "url": {"full": "URL#154984", "pdf": ""}, "publisher-venue": "ICC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1029182206, "title": "Transformer Based Models in Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-77970-2_3", "date": "2021", "authors": [{"name": "Sebastian Kula", "id-internal": "73/7452", "id-external": ""}, {"name": "Rafal Kozik", "id-internal": "80/2851", "id-external": ""}, {"name": "Michal Choras", "id-internal": "06/2936", "id-external": ""}, {"name": "Michal Wozniak 0001", "id-internal": "37/5714-1", "id-external": ""}], "url": {"full": "URL#156182", "pdf": ""}, "publisher-venue": "ICCS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 833885115, "title": "Market Forces - Quantifying the Role of Top Credible Ad Servers in the Fake News Ecosystem.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Lia Bozarth", "id-internal": "200/0112", "id-external": ""}, {"name": "Ceren Budak", "id-internal": "66/8462", "id-external": ""}], "url": {"full": "URL#162995", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1865165943, "title": "Machine Learning Explanations to Prevent Overtrust in Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sina Mohseni", "id-internal": "155/4739", "id-external": ""}, {"name": "Fan Yang 0023", "id-internal": "29/3081-23", "id-external": ""}, {"name": "Shiva K. Pentyala", "id-internal": "240/9336", "id-external": ""}, {"name": "Mengnan Du", "id-internal": "183/5606", "id-external": ""}, {"name": "Yi Liu", "id-internal": "97/4626", "id-external": ""}, {"name": "Nic Lupfer", "id-internal": "53/8700", "id-external": ""}, {"name": "Xia Hu", "id-internal": "24/7536", "id-external": ""}, {"name": "Shuiwang Ji", "id-internal": "84/6405", "id-external": ""}, {"name": "Eric D. Ragan", "id-internal": "69/7691", "id-external": ""}], "url": {"full": "URL#163035", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 210160222, "title": "Network Inference from a Mixture of Diffusion Models for Fake News Mitigation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Karishma Sharma", "id-internal": "222/7902", "id-external": ""}, {"name": "Xinran He", "id-internal": "57/10359", "id-external": ""}, {"name": "Sungyong Seo", "id-internal": "178/3209", "id-external": ""}, {"name": "Yan Liu 0002", "id-internal": "l/YanLiu2", "id-external": ""}], "url": {"full": "URL#163063", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 603780086, "title": "An Approach Utilizing Linguistic Features for Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-79150-6_51", "date": "2021", "authors": [{"name": "Dimitrios Panagiotis Kasseropoulos", "id-internal": "295/5259", "id-external": ""}, {"name": "Christos Tjortjis", "id-internal": "65/6096", "id-external": ""}], "url": {"full": "URL#163325", "pdf": ""}, "publisher-venue": "AIAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2663330104, "title": "Checking Method for Fake News to Avoid the Twitter Effect.", "abstract": "", "doi": "10.1007/978-3-030-80421-3_8", "date": "2021", "authors": [{"name": "T\u00e9o Orthlieb", "id-internal": "234/6024", "id-external": ""}, {"name": "Hamdi Ben Abdessalem", "id-internal": "201/5226", "id-external": ""}, {"name": "Claude Frasson", "id-internal": "96/5521", "id-external": ""}], "url": {"full": "URL#168970", "pdf": ""}, "publisher-venue": "ITS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1896499446, "title": "Fake News, Disinformation, Propaganda, Media Bias, and Flattening the Curve of the COVID-19 Infodemic.", "abstract": "", "doi": "10.1145/3447548.3470790", "date": "2021", "authors": [{"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Giovanni Da San Martino", "id-internal": "25/3236", "id-external": ""}], "url": {"full": "URL#170366", "pdf": ""}, "publisher-venue": "KDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 617125063, "title": "Machine Learning to Identify Fake News for COVID-19.", "abstract": "", "doi": "10.3233/shti210130", "date": "2021", "authors": [{"name": "Marianna Isaakidou", "id-internal": "298/2561", "id-external": ""}, {"name": "Emmanouil Zoulias", "id-internal": "51/7941", "id-external": ""}, {"name": "Marianna Diomidous", "id-internal": "99/2715", "id-external": ""}], "url": {"full": "URL#172520", "pdf": ""}, "publisher-venue": "MIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4094144267, "title": "Fake News and Disinformation in Health Care- Challenges and Technology Tools.", "abstract": "", "doi": "10.3233/shti210172", "date": "2021", "authors": {"name": "Maria Tsirintani", "id-internal": "152/3204", "id-external": ""}, "url": {"full": "URL#172660", "pdf": ""}, "publisher-venue": "MIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2336410184, "title": "Profiling Fake News Spreaders - Personality and Visual Information Matter.", "abstract": "", "doi": "10.1007/978-3-030-80599-9_31", "date": "2021", "authors": [{"name": "Riccardo Cervero", "id-internal": "295/4685", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}, {"name": "Gabriella Pasi", "id-internal": "26/4672", "id-external": ""}], "url": {"full": "URL#174925", "pdf": ""}, "publisher-venue": "NLDB", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 867880656, "title": "Fake News Detection with Heterogenous Deep Graph Convolutional Network.", "abstract": "", "doi": "10.1007/978-3-030-75762-5_33", "date": "2021", "authors": [{"name": "Zhezhou Kang", "id-internal": "227/1648", "id-external": ""}, {"name": "Yanan Cao", "id-internal": "97/5152", "id-external": ""}, {"name": "Yanmin Shang", "id-internal": "54/7648", "id-external": ""}, {"name": "Tao Liang", "id-internal": "00/4393", "id-external": ""}, {"name": "Hengzhu Tang", "id-internal": "261/9705", "id-external": ""}, {"name": "Lingling Tong", "id-internal": "92/8692", "id-external": ""}], "url": {"full": "URL#176218", "pdf": ""}, "publisher-venue": "PAKDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2638242557, "title": "SCARLET - Explainable Attention Based Graph Neural Network for Fake News Spreader Prediction.", "abstract": "", "doi": "10.1007/978-3-030-75762-5_56", "date": "2021", "authors": [{"name": "Bhavtosh Rath", "id-internal": "208/4861", "id-external": ""}, {"name": "Xavier Morales", "id-internal": "147/4421", "id-external": ""}, {"name": "Jaideep Srivastava", "id-internal": "s/JaideepSrivastava", "id-external": ""}], "url": {"full": "URL#176271", "pdf": ""}, "publisher-venue": "PAKDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1676270624, "title": "Incorporating Relational Knowledge in Explainable Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-75768-7_32", "date": "2021", "authors": [{"name": "Kun Wu", "id-internal": "60/1724", "id-external": ""}, {"name": "Xu Yuan", "id-internal": "24/6114", "id-external": ""}, {"name": "Yue Ning", "id-internal": "74/9990", "id-external": ""}], "url": {"full": "URL#176307", "pdf": ""}, "publisher-venue": "PAKDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1521812344, "title": "User Preference-aware Fake News Detection.", "abstract": "", "doi": "10.1145/3404835.3462990", "date": "2021", "authors": [{"name": "Yingtong Dou", "id-internal": "193/5689", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Congying Xia", "id-internal": "210/2265", "id-external": ""}, {"name": "Philip S. Yu", "id-internal": "y/PhilipSYu", "id-external": ""}, {"name": "Lichao Sun", "id-internal": "121/0780", "id-external": ""}], "url": {"full": "URL#180473", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1231038863, "title": "Hierarchical Multi-modal Contextual Attention Network for Fake News Detection.", "abstract": "", "doi": "10.1145/3404835.3462871", "date": "2021", "authors": [{"name": "Shengsheng Qian", "id-internal": "138/4249", "id-external": ""}, {"name": "Jinguang Wang", "id-internal": "21/11182", "id-external": ""}, {"name": "Jun Hu", "id-internal": "28/441", "id-external": ""}, {"name": "Quan Fang", "id-internal": "119/0328", "id-external": ""}, {"name": "Changsheng Xu", "id-internal": "85/1301", "id-external": ""}], "url": {"full": "URL#180642", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 172781945, "title": "To Intervene or Not To Intervene - Cost based Intervention for Combating Fake News.", "abstract": "", "doi": "10.1145/3448016.3452778", "date": "2021", "authors": [{"name": "Saravanan Thirumuruganathan", "id-internal": "57/10514", "id-external": ""}, {"name": "Michael Simpson", "id-internal": "150/6218", "id-external": ""}, {"name": "Laks V. S. Lakshmanan", "id-internal": "l/LVSLakshmanan", "id-external": ""}], "url": {"full": "URL#181093", "pdf": ""}, "publisher-venue": "SIGMOD Conference", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2542676844, "title": "What Are the Latest Fake News in Romanian Politics? An Automated Analysis Based on BERT Language Models.", "abstract": "", "doi": "10.1007/978-981-16-3930-2_16", "date": "2021", "authors": [{"name": "Costin Busioc", "id-internal": "300/8725", "id-external": ""}, {"name": "Vlad Dumitru", "id-internal": "300/8606", "id-external": ""}, {"name": "Stefan Ruseti", "id-internal": "118/3624", "id-external": ""}, {"name": "Simina Terian-Dan", "id-internal": "300/8723", "id-external": ""}, {"name": "Mihai Dascalu", "id-internal": "67/2120", "id-external": ""}, {"name": "Traian Rebedea", "id-internal": "16/856", "id-external": ""}], "url": {"full": "URL#181942", "pdf": ""}, "publisher-venue": "SLERD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 892730916, "title": "Discovering and Measuring Malicious URL Redirection Campaigns from Fake News Domains.", "abstract": "", "doi": "10.1109/spw53761.2021.00008", "date": "2021", "authors": [{"name": "Zhouhan Chen", "id-internal": "170/8182", "id-external": ""}, {"name": "Juliana Freire", "id-internal": "f/JulianaFreire", "id-external": ""}], "url": {"full": "URL#182532", "pdf": ""}, "publisher-venue": "SP Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2022581116, "title": "The Rise and Fall of Fake News sites - A Traffic Analysis.", "abstract": "", "doi": "10.1145/3447535.3462510", "date": "2021", "authors": [{"name": "Manolis Chalkiadakis", "id-internal": "288/0421", "id-external": ""}, {"name": "Alexandros Kornilakis", "id-internal": "234/5887", "id-external": ""}, {"name": "Panagiotis Papadopoulos", "id-internal": "130/2934", "id-external": ""}, {"name": "Evangelos P. Markatos", "id-internal": "m/EvangelosPMarkatos", "id-external": ""}, {"name": "Nicolas Kourtellis", "id-internal": "96/8779", "id-external": ""}], "url": {"full": "URL#186464", "pdf": ""}, "publisher-venue": "WebSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 444040586, "title": "All the Wiser - Fake News Intervention Using User Reading Preferences.", "abstract": "", "doi": "10.1145/3437963.3441696", "date": "2021", "authors": [{"name": "Kuan-Chieh Lo", "id-internal": "289/1974", "id-external": ""}, {"name": "Shih-Chieh Dai", "id-internal": "179/8789", "id-external": ""}, {"name": "Aiping Xiong", "id-internal": "162/1393", "id-external": ""}, {"name": "Jing Jiang", "id-internal": "68/1974", "id-external": ""}, {"name": "Lun-Wei Ku", "id-internal": "82/2054", "id-external": ""}], "url": {"full": "URL#187307", "pdf": ""}, "publisher-venue": "WSDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2179412077, "title": "Transformer based Automatic COVID-19 Fake News Detection System.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sunil Gundapu", "id-internal": "256/3591", "id-external": ""}, {"name": "Radhika Mamidi", "id-internal": "134/6779", "id-external": ""}], "url": {"full": "URL#189868", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3373672949, "title": "Advanced Machine Learning Techniques for Fake News (Online Disinformation) Detection - A Systematic Mapping Study.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Michal Choras", "id-internal": "06/2936", "id-external": ""}, {"name": "Konstantinos P. Demestichas", "id-internal": "37/872", "id-external": ""}, {"name": "Agata Gielczyk", "id-internal": "226/5062", "id-external": ""}, {"name": "\u00c1lvaro Herrero", "id-internal": "92/2688", "id-external": ""}, {"name": "Pawel Ksieniewicz", "id-internal": "145/6756", "id-external": ""}, {"name": "Konstantina Remoundou", "id-internal": "263/9694", "id-external": ""}, {"name": "Daniel Urda", "id-internal": "92/9053", "id-external": ""}, {"name": "Michal Wozniak 0001", "id-internal": "37/5714-1", "id-external": ""}], "url": {"full": "URL#190262", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 723809273, "title": "Exploring Text-transformers in AAAI 2021 Shared Task - COVID-19 Fake News Detection in English.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Xiangyang Li", "id-internal": "80/4579", "id-external": ""}, {"name": "Yu Xia", "id-internal": "28/4326", "id-external": ""}, {"name": "Xiang Long", "id-internal": "64/6328", "id-external": ""}, {"name": "Zheng Li", "id-internal": "10/1143", "id-external": ""}, {"name": "Sujian Li", "id-internal": "05/4288", "id-external": ""}], "url": {"full": "URL#190703", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2553346594, "title": "Combating Hostility - Covid-19 Fake News and Hostile Post Detection in Social Media.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Omar Sharif", "id-internal": "270/0002", "id-external": ""}, {"name": "Eftekhar Hossain", "id-internal": "270/0025", "id-external": ""}, {"name": "Mohammed Moshiul Hoque", "id-internal": "14/10110", "id-external": ""}], "url": {"full": "URL#191065", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2454862852, "title": "TIB's Visual Analytics Group at MediaEval '20 - Detecting Fake News on Corona Virus and 5G Conspiracy.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Gullal S. Cheema", "id-internal": "211/5762", "id-external": ""}, {"name": "Sherzod Hakimov", "id-internal": "117/6023", "id-external": ""}, {"name": "Ralph Ewerth", "id-internal": "45/52", "id-external": ""}], "url": {"full": "URL#191141", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4277677232, "title": "A Heuristic-driven Ensemble Framework for COVID-19 Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sourya Dipta Das", "id-internal": "217/1530", "id-external": ""}, {"name": "Ayan Basak", "id-internal": "256/4299", "id-external": ""}, {"name": "Saikat Dutta", "id-internal": "260/3198", "id-external": ""}], "url": {"full": "URL#191147", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 391005551, "title": "Constraint 2021 - Machine Learning Models for COVID-19 Fake News Detection Shared Task.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Thomas Felber", "id-internal": "209/6858", "id-external": ""}, "url": {"full": "URL#191214", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3525667139, "title": "Model Generalization on COVID-19 Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Yejin Bang", "id-internal": "261/2805", "id-external": ""}, {"name": "Etsuko Ishii", "id-internal": "261/2881", "id-external": ""}, {"name": "Samuel Cahyawijaya", "id-internal": "235/2988", "id-external": ""}, {"name": "Ziwei Ji", "id-internal": "176/4574", "id-external": ""}, {"name": "Pascale Fung", "id-internal": "29/4187", "id-external": ""}], "url": {"full": "URL#191256", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1532767447, "title": "Identification of COVID-19 related Fake News via Neural Stacking.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Boshko Koloski", "id-internal": "277/0961", "id-external": ""}, {"name": "Timen Stepisnik Perdih", "id-internal": "283/4592", "id-external": ""}, {"name": "Senja Pollak", "id-internal": "75/8154", "id-external": ""}, {"name": "Blaz Skrlj", "id-internal": "190/6972", "id-external": ""}], "url": {"full": "URL#191303", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 562000127, "title": "Evaluating Deep Learning Approaches for Covid19 Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Apurva Wani", "id-internal": "283/4456", "id-external": ""}, {"name": "Isha Joshi", "id-internal": "283/4336", "id-external": ""}, {"name": "Snehal Khandve", "id-internal": "283/4273", "id-external": ""}, {"name": "Vedangi Wagh", "id-internal": "283/4277", "id-external": ""}, {"name": "Raviraj Joshi", "id-internal": "229/7269", "id-external": ""}], "url": {"full": "URL#191309", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2641222427, "title": "Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Ben Chen", "id-internal": "94/4500", "id-external": ""}, {"name": "Bin Chen", "id-internal": "22/5523", "id-external": ""}, {"name": "Dehong Gao", "id-internal": "59/9911", "id-external": ""}, {"name": "Qijin Chen", "id-internal": "193/2124", "id-external": ""}, {"name": "Chengfu Huo", "id-internal": "81/8757", "id-external": ""}, {"name": "Xiaonan Meng", "id-internal": "200/8976", "id-external": ""}, {"name": "Weijun Ren", "id-internal": "214/8201", "id-external": ""}, {"name": "Yang Zhou", "id-internal": "07/4580", "id-external": ""}], "url": {"full": "URL#191830", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2739752653, "title": "TUDublin team at Constraint@AAAI2021 - COVID19 Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Elena Shushkevich", "id-internal": "224/1902", "id-external": ""}, {"name": "John Cardiff", "id-internal": "35/220", "id-external": ""}], "url": {"full": "URL#191906", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 334213279, "title": "Hostility Detection and Covid-19 Fake News Detection in Social Media.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Ayush Gupta", "id-internal": "12/10634", "id-external": ""}, {"name": "Rohan Sukumaran", "id-internal": "280/0377", "id-external": ""}, {"name": "Kevin John", "id-internal": "283/5527", "id-external": ""}, {"name": "Sundeep Teki", "id-internal": "157/5630", "id-external": ""}], "url": {"full": "URL#191986", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3360719413, "title": "Adversarial Active Learning based Heterogeneous Graph Neural Network for Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Yuxiang Ren", "id-internal": "236/5117", "id-external": ""}, {"name": "Bo Wang", "id-internal": "72/6811", "id-external": ""}, {"name": "Jiawei Zhang 0001", "id-internal": "10/239-1", "id-external": ""}, {"name": "Yi Chang 0001", "id-internal": "02/5438", "id-external": ""}], "url": {"full": "URL#194135", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 698932512, "title": "Fake News Detection System using XLNet model with Topic Distributions - CONSTRAINT@AAAI2021 Shared Task.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Akansha Gautam", "id-internal": "272/8689", "id-external": ""}, {"name": "Venktesh V", "id-internal": "274/2996", "id-external": ""}, {"name": "Sarah Masud", "id-internal": "115/9011", "id-external": ""}], "url": {"full": "URL#194231", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2367181177, "title": "Identifying COVID-19 Fake News in Social Media.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Tathagata Raha", "id-internal": "271/4295", "id-external": ""}, {"name": "Vijayasaradhi Indurthi", "id-internal": "190/1681", "id-external": ""}, {"name": "Aayush Upadhyaya", "id-internal": "284/0997", "id-external": ""}, {"name": "Jeevesh Kataria", "id-internal": "284/1235", "id-external": ""}, {"name": "Pramud Bommakanti", "id-internal": "284/0975", "id-external": ""}, {"name": "Vikram Keswani", "id-internal": "284/0937", "id-external": ""}, {"name": "Vasudeva Varma", "id-internal": "03/4045", "id-external": ""}], "url": {"full": "URL#194442", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 265750508, "title": "A transformer based approach for fighting COVID-19 fake news.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "S. M. Sadiq-Ur-Rahman Shifath", "id-internal": "284/1176", "id-external": ""}, {"name": "Mohammad Faiyaz Khan", "id-internal": "284/0963", "id-external": ""}, {"name": "Md. Saiful Islam", "id-internal": "04/3572", "id-external": ""}], "url": {"full": "URL#194471", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2761875182, "title": "TruthBot - An Automated Conversational Tool for Intent Learning, Curated Information Presenting, and Fake News Alerting.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Ankur Gupta", "id-internal": "90/2678", "id-external": ""}, {"name": "Yash Varun", "id-internal": "284/8330", "id-external": ""}, {"name": "Prarthana Das", "id-internal": "248/1733", "id-external": ""}, {"name": "Nithya Muttineni", "id-internal": "284/8480", "id-external": ""}, {"name": "Parth Srivastava", "id-internal": "152/3847", "id-external": ""}, {"name": "Hamim Zafar", "id-internal": "31/8830", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}, {"name": "Swaprava Nath", "id-internal": "70/9376", "id-external": ""}], "url": {"full": "URL#194940", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3243743833, "title": "Assessing Individual and Community Vulnerability to Fake News in Social Networks.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Bhavtosh Rath", "id-internal": "208/4861", "id-external": ""}, {"name": "Wei Gao 0001", "id-internal": "28/2073-1", "id-external": ""}, {"name": "Jaideep Srivastava", "id-internal": "s/JaideepSrivastava", "id-external": ""}], "url": {"full": "URL#195714", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 876699556, "title": "Hierarchical Multi-head Attentive Network for Evidence-aware Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Nguyen Vo", "id-internal": "167/0323", "id-external": ""}, {"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}], "url": {"full": "URL#195822", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 744984776, "title": "Detecting Fake News Using Machine Learning - A Systematic Literature Review.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Alim Al Ayub Ahmed", "id-internal": "285/5177", "id-external": ""}, {"name": "Ayman Aljabouh", "id-internal": "285/5030", "id-external": ""}, {"name": "Praveen Kumar Donepudi", "id-internal": "285/5448", "id-external": ""}, {"name": "Myung Suh Choi", "id-internal": "285/4781", "id-external": ""}], "url": {"full": "URL#196628", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1306674145, "title": "SCARLET - Explainable Attention based Graph Neural Network for Fake News spreader prediction.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Bhavtosh Rath", "id-internal": "208/4861", "id-external": ""}, {"name": "Xavier Morales", "id-internal": "147/4421", "id-external": ""}, {"name": "Jaideep Srivastava", "id-internal": "s/JaideepSrivastava", "id-external": ""}], "url": {"full": "URL#196694", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1369128179, "title": "Cross-SEAN - A Cross-Stitch Semi-Supervised Neural Attention Model for COVID-19 Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "William Scott Paka", "id-internal": "23/4401-1", "id-external": ""}, {"name": "Rachit Bansal", "id-internal": "228/6038", "id-external": ""}, {"name": "Abhay Kaushik", "id-internal": "285/6219", "id-external": ""}, {"name": "Shubhashis Sengupta", "id-internal": "33/5030", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}], "url": {"full": "URL#198637", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1813659501, "title": "Fake News Detection - a comparison between available Deep Learning techniques in vector space.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Lovedeep Singh", "id-internal": "286/1388", "id-external": ""}, "url": {"full": "URL#198881", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 69426237, "title": "An organized review of key factors for fake news detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Nuno Guimar\u00e3es", "id-internal": "39/1045", "id-external": ""}, {"name": "\u00c1lvaro Figueira 0001", "id-internal": "77/4827", "id-external": ""}, {"name": "Lu\u00eds Torgo", "id-internal": "60/1153", "id-external": ""}], "url": {"full": "URL#200573", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 835002688, "title": "The Rise and Fall of Fake News sites - A Traffic Analysis.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Manolis Chalkiadakis", "id-internal": "288/0421", "id-external": ""}, {"name": "Alexandros Kornilakis", "id-internal": "234/5887", "id-external": ""}, {"name": "Panagiotis Papadopoulos", "id-internal": "130/2934", "id-external": ""}, {"name": "Evangelos P. Markatos", "id-internal": "m/EvangelosPMarkatos", "id-external": ""}, {"name": "Nicolas Kourtellis", "id-internal": "96/8779", "id-external": ""}], "url": {"full": "URL#204612", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3088576411, "title": "Detection of fake news on CoViD-19 on Web Search Engines.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "V. Mazzeo", "id-internal": "288/2173", "id-external": ""}, {"name": "A. Rapisarda", "id-internal": "288/0870", "id-external": ""}, {"name": "G. Giuffrida", "id-internal": "288/2537", "id-external": ""}], "url": {"full": "URL#205720", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3073632359, "title": "Multimodal Fusion with BERT and Attention Mechanism for Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Nguyen Manh Duc Tuan", "id-internal": "281/8209", "id-external": ""}, {"name": "Pham Quang Nhat Minh", "id-internal": "217/1467", "id-external": ""}], "url": {"full": "URL#213270", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 848958422, "title": "User Preference-aware Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Yingtong Dou", "id-internal": "193/5689", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Congying Xia", "id-internal": "210/2265", "id-external": ""}, {"name": "Philip S. Yu", "id-internal": "y/PhilipSYu", "id-external": ""}, {"name": "Lichao Sun", "id-internal": "121/0780", "id-external": ""}], "url": {"full": "URL#213577", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2249398816, "title": "AraCOVID19-MFH - Arabic COVID-19 Multi-label Fake News and Hate Speech Detection Dataset.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Mohamed Seghir Hadj Ameur", "id-internal": "162/8834", "id-external": ""}, {"name": "Hassina Aliane", "id-internal": "43/8157", "id-external": ""}], "url": {"full": "URL#216170", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2060697694, "title": "Automatic Fake News Detection - Are Models Learning to Reason?", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Casper Hansen", "id-internal": "205/2958", "id-external": ""}, {"name": "Christian Hansen 0004", "id-internal": "57/2217-4", "id-external": ""}, {"name": "Lucas Chaves Lima", "id-internal": "238/0439", "id-external": ""}], "url": {"full": "URL#218086", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1835145998, "title": "Three prophylactic interventions to counter fake news on social media.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "David A. Eccles", "id-internal": "293/6890", "id-external": ""}, {"name": "Tilman Dingler", "id-internal": "79/8692", "id-external": ""}], "url": {"full": "URL#218603", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3214066498, "title": "Explainable Tsetlin Machine framework for fake news detection with credibility score assessment.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Bimal Bhattarai", "id-internal": "238/4886", "id-external": ""}, {"name": "Ole-Christoffer Granmo", "id-internal": "10/5522", "id-external": ""}, {"name": "Lei Jiao", "id-internal": "47/91", "id-external": ""}], "url": {"full": "URL#218684", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1470460280, "title": "SOK - Fake News Outbreak 2021 - Can We Stop the Viral Spread?", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Tanveer Khan", "id-internal": "180/2997", "id-external": ""}, {"name": "Antonis Michalas", "id-internal": "28/9590", "id-external": ""}, {"name": "Adnan Akhunzada", "id-internal": "156/6018", "id-external": ""}], "url": {"full": "URL#219345", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4041850924, "title": "Prevalence and Propagation of Fake News.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Banafsheh Behzad", "id-internal": "118/6435", "id-external": ""}, {"name": "Bhavana Bheem", "id-internal": "295/8578", "id-external": ""}, {"name": "Daniela Elizondo", "id-internal": "295/8533", "id-external": ""}, {"name": "Deyana Marsh", "id-internal": "295/8611", "id-external": ""}, {"name": "Susan Martonosi", "id-internal": "295/8577", "id-external": ""}], "url": {"full": "URL#225908", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 250807722, "title": "MetaDetector - Meta Event Knowledge Transfer for Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Yasan Ding", "id-internal": "245/2848", "id-external": ""}, {"name": "Bin Guo 0001", "id-internal": "86/2663-1", "id-external": ""}, {"name": "Yan Liu 0045", "id-internal": "150/4295-45", "id-external": ""}, {"name": "Yunji Liang", "id-internal": "22/10796", "id-external": ""}, {"name": "Haocheng Shen", "id-internal": "160/3613", "id-external": ""}, {"name": "Zhiwen Yu 0001", "id-internal": "z/YuZhiwen", "id-external": ""}], "url": {"full": "URL#226645", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 544383817, "title": "Multimodal Emergent Fake News Detection via Meta Neural Process Networks.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Yaqing Wang", "id-internal": "147/1393", "id-external": ""}, {"name": "Fenglong Ma", "id-internal": "85/10856", "id-external": ""}, {"name": "Haoyu Wang", "id-internal": "50/8499", "id-external": ""}, {"name": "Kishlay Jha", "id-internal": "177/7445", "id-external": ""}, {"name": "Jing Gao", "id-internal": "67/4834", "id-external": ""}], "url": {"full": "URL#227725", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3630748358, "title": "Cognitive Contagion - How to model (and potentially counter) the spread of fake news.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Nicholas Rabb", "id-internal": "289/4142", "id-external": ""}, {"name": "Lenore Cowen", "id-internal": "c/LenoreCowen", "id-external": ""}, {"name": "Jan P. de Ruiter", "id-internal": "14/4421", "id-external": ""}, {"name": "Matthias Scheutz", "id-internal": "00/2197", "id-external": ""}], "url": {"full": "URL#230057", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3548499728, "title": "Indonesia's Fake News Detection using Transformer Network.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Aisyah Awalina", "id-internal": "297/4259", "id-external": ""}, {"name": "Jibran Fawaid", "id-internal": "297/4901", "id-external": ""}, {"name": "Rifky Yunus Krisnabayu", "id-internal": "297/4177", "id-external": ""}, {"name": "Novanto Yudistira", "id-internal": "174/3609", "id-external": ""}], "url": {"full": "URL#231739", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 931865400, "title": "How Vulnerable Are Automatic Fake News Detection Methods to Adversarial Attacks?", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Camille Koenders", "id-internal": "297/4425", "id-external": ""}, {"name": "Johannes Filla", "id-internal": "297/4591", "id-external": ""}, {"name": "Nicolai Schneider", "id-internal": "118/9676", "id-external": ""}, {"name": "Vinicius Woloszyn", "id-internal": "204/3806", "id-external": ""}], "url": {"full": "URL#232245", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2578824781, "title": "'No, auntie, that's false' - Female baby boomers develop critical skills to confront fake news with guidance from relatives.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Andrea Pecho-Ninapaytan", "id-internal": "298/1922", "id-external": ""}, {"name": "Stefany Zambrano-Zuta", "id-internal": "298/2168", "id-external": ""}, {"name": "Lizardo Vargas-Bianchi", "id-internal": "298/2051", "id-external": ""}], "url": {"full": "URL#233923", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1218838772, "title": "Estudo Abordando o Contexto de Not\u00edcias Falsas em Pa\u00edses de L\u00edngua Portuguesa (Fake News).", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Carolina Duarte", "id-internal": "298/1936", "id-external": ""}, {"name": "Valderi R. Q. Leithardt", "id-internal": "75/11123", "id-external": ""}], "url": {"full": "URL#234138", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2906868951, "title": "Knowledge Enhanced Multi-modal Fake News Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Yi Han 0003", "id-internal": "27/4390-3", "id-external": ""}, {"name": "Amila Silva", "id-internal": "220/0876", "id-external": ""}, {"name": "Ling Luo 0002", "id-internal": "00/1811-2", "id-external": ""}, {"name": "Shanika Karunasekera", "id-internal": "47/5584", "id-external": ""}, {"name": "Christopher Leckie", "id-internal": "73/1139", "id-external": ""}], "url": {"full": "URL#236763", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 283025232, "title": "NoFake at CheckThat!2021 - Fake News Detection Using BERT.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Sushma Kumari", "id-internal": "193/3065", "id-external": ""}, "url": {"full": "URL#237160", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1216329363, "title": "Fake News and Phishing Detection Using a Machine Learning Trained Expert System.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Benjamin Fitzpatrick", "id-internal": "299/9419", "id-external": ""}, {"name": "Xinyu \"Sherwin\" Liang", "id-internal": "299/9458", "id-external": ""}, {"name": "Jeremy Straub", "id-internal": "131/6361", "id-external": ""}], "url": {"full": "URL#238332", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3691626573, "title": "Improving Fake News Detection by Using an Entity-enhanced Framework to Fuse Diverse Multimodal Clues.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Peng Qi 0005", "id-internal": "59/9474-5", "id-external": ""}, {"name": "Juan Cao", "id-internal": "75/2820", "id-external": ""}, {"name": "Xirong Li", "id-internal": "58/5856", "id-external": ""}, {"name": "Huan Liu", "id-internal": "92/309", "id-external": ""}, {"name": "Qiang Sheng", "id-internal": "199/7557", "id-external": ""}, {"name": "Xiaoyue Mi", "id-internal": "289/0689", "id-external": ""}, {"name": "Qin He", "id-internal": "02/479", "id-external": ""}, {"name": "Yongbiao Lv", "id-internal": "206/5908", "id-external": ""}, {"name": "Chenyang Guo", "id-internal": "205/7877", "id-external": ""}, {"name": "Yingchao Yu", "id-internal": "226/4999", "id-external": ""}], "url": {"full": "URL#239310", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 466814583, "title": "Profiling Fake News Spreaders on Social Media through Psychological and Motivational Factors.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Mansooreh Karami", "id-internal": "243/0884", "id-external": ""}, {"name": "Tahora H. Nazer", "id-internal": "190/5215", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#239484", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3500288164, "title": "Mitigation of Diachronic Bias in Fake News Detection Dataset.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Taichi Murayama", "id-internal": "263/7010", "id-external": ""}, {"name": "Shoko Wakamiya", "id-internal": "94/7622", "id-external": ""}, {"name": "Eiji Aramaki", "id-internal": "02/2649", "id-external": ""}], "url": {"full": "URL#240105", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1499788416, "title": "Fake News Stance Detection Using Deep Learning Architecture (CNN-LSTM).", "abstract": "", "doi": "10.1109/access.2020.3019735", "date": "2020", "authors": [{"name": "Muhammad Umer", "id-internal": "49/2776", "id-external": ""}, {"name": "Zainab Imtiaz", "id-internal": "258/5598", "id-external": ""}, {"name": "Saleem Ullah", "id-internal": "88/9934", "id-external": ""}, {"name": "Arif Mehmood", "id-internal": "185/3015", "id-external": ""}, {"name": "Gyu Sang Choi", "id-internal": "09/886", "id-external": ""}, {"name": "Byung-Won On", "id-internal": "49/5514", "id-external": ""}], "url": {"full": "URL#258327", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 656212796, "title": "Testing and unpacking the effects of digital fake news - on presidential candidate evaluations and voter support.", "abstract": "", "doi": "10.1007/s00146-020-00980-6", "date": "2020", "authors": [{"name": "Rodolfo Leyva", "id-internal": "277/8861", "id-external": ""}, {"name": "Charlie Beckett", "id-internal": "277/8981", "id-external": ""}], "url": {"full": "URL#264785", "pdf": ""}, "publisher-venue": "AI Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4208075093, "title": "Fake News Case Study during the Australian 2019 General Election.", "abstract": "", "doi": "10.3127/ajis.v24i0.2803", "date": "2020", "authors": {"name": "Matthew J. Warren", "id-internal": "10/2372", "id-external": ""}, "url": {"full": "URL#264954", "pdf": ""}, "publisher-venue": "Australas. J. Inf. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3075719206, "title": "Detecting fake news in social media - an Asia-Pacific perspective.", "abstract": "", "doi": "10.1145/3378422", "date": "2020", "authors": [{"name": "Meeyoung Cha", "id-internal": "57/4924", "id-external": ""}, {"name": "Wei Gao", "id-internal": "28/2073", "id-external": ""}, {"name": "Cheng-Te Li", "id-internal": "90/5961", "id-external": ""}], "url": {"full": "URL#273789", "pdf": ""}, "publisher-venue": "Commun. ACM", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4029436377, "title": "Reason-checking fake news.", "abstract": "", "doi": "10.1145/3397189", "date": "2020", "authors": [{"name": "Jacky Visser", "id-internal": "209/5497", "id-external": ""}, {"name": "John Lawrence", "id-internal": "77/5317", "id-external": ""}, {"name": "Chris Reed", "id-internal": "12/4444", "id-external": ""}], "url": {"full": "URL#274025", "pdf": ""}, "publisher-venue": "Commun. ACM", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 695037705, "title": "Analyzing and distinguishing fake and real news to mitigate the problem of disinformation.", "abstract": "", "doi": "10.1007/s10588-020-09307-8", "date": "2020", "authors": [{"name": "Alina Vereshchaka", "id-internal": "234/3045", "id-external": ""}, {"name": "Seth Cosimini", "id-internal": "276/3700", "id-external": ""}, {"name": "Wen Dong 0001", "id-internal": "84/3520-1", "id-external": ""}], "url": {"full": "URL#281429", "pdf": ""}, "publisher-venue": "Comput. Math. Organ. Theory", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1933102482, "title": "FNDNet - A deep convolutional neural network for fake news detection.", "abstract": "", "doi": "10.1016/j.cogsys.2019.12.005", "date": "2020", "authors": [{"name": "Rohit Kumar Kaliyar", "id-internal": "261/1345", "id-external": ""}, {"name": "Anurag Goswami", "id-internal": "139/3865", "id-external": ""}, {"name": "Pratik Narang", "id-internal": "132/9397", "id-external": ""}, {"name": "Soumendu Sinha", "id-internal": "185/6140", "id-external": ""}], "url": {"full": "URL#283099", "pdf": ""}, "publisher-venue": "Cogn. Syst. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3300779939, "title": "The Limitations of Stylometry for Detecting Machine-Generated Fake News.", "abstract": "", "doi": "10.1162/coli_a_00380", "date": "2020", "authors": [{"name": "Tal Schuster", "id-internal": "190/7491", "id-external": ""}, {"name": "Roei Schuster", "id-internal": "180/8190", "id-external": ""}, {"name": "Darsh J. Shah", "id-internal": "227/2738", "id-external": ""}, {"name": "Regina Barzilay", "id-internal": "b/ReginaBarzilay", "id-external": ""}], "url": {"full": "URL#283161", "pdf": ""}, "publisher-venue": "Comput. Linguistics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3663899443, "title": "Fake News Detection Using Machine Learning Ensemble Methods.", "abstract": "", "doi": "10.1155/2020/8885861", "date": "2020", "authors": [{"name": "Iftikhar Ahmad 0004", "id-internal": "85/7432-4", "id-external": ""}, {"name": "Muhammad Yousaf", "id-internal": "46/8275", "id-external": ""}, {"name": "Suhail Yousaf", "id-internal": "119/4939", "id-external": ""}, {"name": "Muhammad Ovais Ahmad", "id-internal": "143/1116", "id-external": ""}], "url": {"full": "URL#284174", "pdf": ""}, "publisher-venue": "Complex.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2700905530, "title": "Entangled in a web of fake news.", "abstract": "", "doi": "10.1145/3416027", "date": "2020", "authors": {"name": "Diane Golay", "id-internal": "211/4966", "id-external": ""}, "url": {"full": "URL#287766", "pdf": ""}, "publisher-venue": "XRDS", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1442771833, "title": "Python - the Sherlock Holmes of fake news.", "abstract": "", "doi": "10.1145/3418555", "date": "2020", "authors": {"name": "Manandeep", "id-internal": "274/4172", "id-external": ""}, "url": {"full": "URL#287786", "pdf": ""}, "publisher-venue": "XRDS", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3645008411, "title": "The Value of Information Searching against Fake News.", "abstract": "", "doi": "10.3390/e22121368", "date": "2020", "authors": [{"name": "Jos\u00e9 Martins", "id-internal": "97/5724", "id-external": ""}, {"name": "Alberto A. Pinto", "id-internal": "142/8850", "id-external": ""}], "url": {"full": "URL#295780", "pdf": ""}, "publisher-venue": "Entropy", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 920533192, "title": "Fake news detection in multiple platforms and languages.", "abstract": "", "doi": "10.1016/j.eswa.2020.113503", "date": "2020", "authors": [{"name": "Pedro Henrique Arruda Faustini", "id-internal": "273/9876", "id-external": ""}, {"name": "Thiago Ferreira Cov\u00f5es", "id-internal": "202/6212", "id-external": ""}], "url": {"full": "URL#297973", "pdf": ""}, "publisher-venue": "Expert Syst. Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4262521441, "title": "Fake news detection using an ensemble learning model based on Self-Adaptive Harmony Search algorithms.", "abstract": "", "doi": "10.1016/j.eswa.2020.113584", "date": "2020", "authors": [{"name": "Yin-Fu Huang", "id-internal": "62/6070", "id-external": ""}, {"name": "Po-Hong Chen", "id-internal": "276/7952", "id-external": ""}], "url": {"full": "URL#298049", "pdf": ""}, "publisher-venue": "Expert Syst. Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4179781500, "title": "Fake news, rumor, information pollution in social media and web - A contemporary survey of state-of-the-arts, challenges and opportunities.", "abstract": "", "doi": "10.1016/j.eswa.2019.112986", "date": "2020", "authors": [{"name": "Priyanka Meel", "id-internal": "166/0645", "id-external": ""}, {"name": "Dinesh Kumar Vishwakarma", "id-internal": "214/0803", "id-external": ""}], "url": {"full": "URL#298212", "pdf": ""}, "publisher-venue": "Expert Syst. Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1873143925, "title": "Towards automatically filtering fake news in Portuguese.", "abstract": "", "doi": "10.1016/j.eswa.2020.113199", "date": "2020", "authors": [{"name": "Renato Moraes Silva", "id-internal": "27/8461", "id-external": ""}, {"name": "Roney L. S. Santos", "id-internal": "189/4600", "id-external": ""}, {"name": "Tiago A. Almeida", "id-internal": "04/2243", "id-external": ""}, {"name": "Thiago A. S. Pardo", "id-internal": "31/4118", "id-external": ""}], "url": {"full": "URL#298380", "pdf": ""}, "publisher-venue": "Expert Syst. Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 149696351, "title": "Fake news detection using deep learning models - A novel approach.", "abstract": "", "doi": "10.1002/ett.3767", "date": "2020", "authors": [{"name": "Sachin Kumar 0002", "id-internal": "31/4484-2", "id-external": ""}, {"name": "Rohan Asthana", "id-internal": "260/8008", "id-external": ""}, {"name": "Shashwat Upadhyay", "id-internal": "260/8056", "id-external": ""}, {"name": "Nidhi Upreti", "id-internal": "260/8176", "id-external": ""}, {"name": "Mohammad Akbar", "id-internal": "26/1861", "id-external": ""}], "url": {"full": "URL#298767", "pdf": ""}, "publisher-venue": "Trans. Emerg. Telecommun. Technol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3697157496, "title": "Language-Independent Fake News Detection - English, Portuguese, and Spanish Mutual Features.", "abstract": "", "doi": "10.3390/fi12050087", "date": "2020", "authors": [{"name": "Hugo Queiroz Abonizio", "id-internal": "246/8435", "id-external": ""}, {"name": "Jana\u00edna Ign\u00e1cio de Morais", "id-internal": "246/7986", "id-external": ""}, {"name": "Gabriel Marques Tavares", "id-internal": "210/6317", "id-external": ""}, {"name": "Sylvio Barbon Junior", "id-internal": "66/5992", "id-external": ""}], "url": {"full": "URL#300542", "pdf": ""}, "publisher-venue": "Future Internet", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4263811335, "title": "Fake News and Aggregated Credibility - Conceptualizing a Co-Creative Medium for Evaluation of Sources Online.", "abstract": "", "doi": "10.4018/ijaci.20201001.oa1", "date": "2020", "authors": [{"name": "Montathar Faraon", "id-internal": "159/4432", "id-external": ""}, {"name": "Agnieszka Jaff", "id-internal": "267/1694", "id-external": ""}, {"name": "Liegi Paschoalini Nepomuceno", "id-internal": "267/2002", "id-external": ""}, {"name": "Victor Villavicencio", "id-internal": "267/1512", "id-external": ""}], "url": {"full": "URL#308265", "pdf": ""}, "publisher-venue": "Int. J. Ambient Comput. Intell.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4281820105, "title": "Text-mining-based Fake News Detection Using Ensemble Methods.", "abstract": "", "doi": "10.1007/s11633-019-1216-5", "date": "2020", "authors": [{"name": "Harita Reddy", "id-internal": "248/8309", "id-external": ""}, {"name": "Namratha Raj", "id-internal": "271/3489", "id-external": ""}, {"name": "Manali Gala", "id-internal": "271/3480", "id-external": ""}, {"name": "Annappa Basava", "id-internal": "01/9555", "id-external": ""}], "url": {"full": "URL#308933", "pdf": ""}, "publisher-venue": "Int. J. Autom. Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1317590947, "title": "Student Perceptions of Fake News - A Matter of Information Literacy Awareness.", "abstract": "", "doi": "10.4018/ijdldc.2020040103", "date": "2020", "authors": [{"name": "Corrado Petrucco", "id-internal": "44/4662", "id-external": ""}, {"name": "Daniele Agostini", "id-internal": "243/2745", "id-external": ""}], "url": {"full": "URL#311956", "pdf": ""}, "publisher-venue": "Int. J. Digit. Lit. Digit. Competence", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3265334487, "title": "Understanding Perceived Fakeness of Online Health News in Hong Kong.", "abstract": "", "doi": "10.4018/ijdldc.2020040101", "date": "2020", "authors": {"name": "Stephanie Jean Tsang", "id-internal": "295/5708", "id-external": ""}, "url": {"full": "URL#311959", "pdf": ""}, "publisher-venue": "Int. J. Digit. Lit. Digit. Competence", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 325896480, "title": "Improvement of Misleading and Fake News Classification for Flective Languages by Morphological Group Analysis.", "abstract": "", "doi": "10.3390/informatics7010004", "date": "2020", "authors": [{"name": "Jozef Kapusta", "id-internal": "97/4528", "id-external": ""}, {"name": "Juraj Obonya", "id-internal": "242/0545", "id-external": ""}], "url": {"full": "URL#322852", "pdf": ""}, "publisher-venue": "Informatics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3392947758, "title": "A Reliable Weighting Scheme for the Aggregation of Crowd Intelligence to Detect Fake News.", "abstract": "", "doi": "10.3390/info11060319", "date": "2020", "authors": [{"name": "Franklin Tchakount\u00e9", "id-internal": "178/9050", "id-external": ""}, {"name": "Ahmadou Faissal", "id-internal": "271/2823", "id-external": ""}, {"name": "Marcellin Atemkeng", "id-internal": "262/8132", "id-external": ""}, {"name": "Achille Ntyam", "id-internal": "271/1756", "id-external": ""}], "url": {"full": "URL#323380", "pdf": ""}, "publisher-venue": "Inf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 363958175, "title": "An overview of online fake news - Characterization, detection, and discussion.", "abstract": "", "doi": "10.1016/j.ipm.2019.03.004", "date": "2020", "authors": [{"name": "Xichen Zhang", "id-internal": "204/5159", "id-external": ""}, {"name": "Ali A. Ghorbani 0001", "id-internal": "g/AliAGhorbani", "id-external": ""}], "url": {"full": "URL#325812", "pdf": ""}, "publisher-venue": "Inf. Process. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4030247351, "title": "Appealing to Sense and Sensibility - System 1 and System 2 Interventions for Fake News on Social Media.", "abstract": "", "doi": "10.1287/isre.2020.0927", "date": "2020", "authors": [{"name": "Patricia L. Moravec", "id-internal": "231/0732", "id-external": ""}, {"name": "Antino Kim", "id-internal": "117/0007", "id-external": ""}, {"name": "Alan R. Dennis", "id-internal": "28/6832", "id-external": ""}], "url": {"full": "URL#327434", "pdf": ""}, "publisher-venue": "Inf. Syst. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2208546371, "title": "On the probabilistic modeling of fake news (hoax) persistency in online social networks and the role of debunking and filtering.", "abstract": "", "doi": "10.1002/itl2.204", "date": "2020", "authors": {"name": "Angelo Coluccia", "id-internal": "34/7911", "id-external": ""}, "url": {"full": "URL#327922", "pdf": ""}, "publisher-venue": "Internet Technol. Lett.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1066544942, "title": "Food for Thought - Fighting Fake News and Online Disinformation.", "abstract": "", "doi": "10.1109/mitp.2020.2978043", "date": "2020", "authors": [{"name": "Konstantinos P. Demestichas", "id-internal": "37/872", "id-external": ""}, {"name": "Konstantina Remoundou", "id-internal": "263/9694", "id-external": ""}, {"name": "Evgenia F. Adamopoulou", "id-internal": "97/2870", "id-external": ""}], "url": {"full": "URL#328216", "pdf": ""}, "publisher-venue": "IT Prof.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3221774900, "title": "Fake News, Disinformation, and Deepfakes - Leveraging Distributed Ledger Technologies and Blockchain to Combat Digital Deception and Counterfeit Reality.", "abstract": "", "doi": "10.1109/mitp.2020.2977589", "date": "2020", "authors": [{"name": "Paula Fraga-Lamas", "id-internal": "138/4366", "id-external": ""}, {"name": "Tiago M. Fern\u00e1ndez-Caram\u00e9s", "id-internal": "66/2481", "id-external": ""}], "url": {"full": "URL#328222", "pdf": ""}, "publisher-venue": "IT Prof.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3116505942, "title": "A model for the spreading of fake news.", "abstract": "", "doi": "10.1017/jpr.2019.103", "date": "2020", "authors": {"name": "Hosam Mahmoud", "id-internal": "266/3180", "id-external": ""}, "url": {"full": "URL#329927", "pdf": ""}, "publisher-venue": "J. Appl. Probab.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3050361056, "title": "Fake News Detection by Image Montage Recognition.", "abstract": "", "doi": "10.13052/jcsm2245-1439.921", "date": "2020", "authors": [{"name": "Martin Steinebach", "id-internal": "s/MartinSteinebach", "id-external": ""}, {"name": "Huajian Liu", "id-internal": "63/568", "id-external": ""}, {"name": "Karol Gotkowski", "id-internal": "246/5696", "id-external": ""}], "url": {"full": "URL#334348", "pdf": ""}, "publisher-venue": "J. Cyber Secur. Mobil.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2268643474, "title": "Fighting fake news - exploring George Orwell's relationship to information literacy.", "abstract": "", "doi": "10.1108/jd-11-2019-0223", "date": "2020", "authors": {"name": "Ellen Haggar", "id-internal": "273/5191", "id-external": ""}, "url": {"full": "URL#334738", "pdf": ""}, "publisher-venue": "J. Documentation", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3020596825, "title": "\"Bend the truth\" - Benchmark dataset for fake news detection in Urdu language and its evaluation.", "abstract": "", "doi": "10.3233/jifs-179905", "date": "2020", "authors": [{"name": "Maaz Amjad", "id-internal": "220/4234", "id-external": ""}, {"name": "Grigori Sidorov", "id-internal": "68/4195", "id-external": ""}, {"name": "Alisa Zhila", "id-internal": "136/9257", "id-external": ""}, {"name": "Helena G\u00f3mez-Adorno", "id-internal": "117/2917", "id-external": ""}, {"name": "Ilia Voronkov", "id-internal": "190/7188", "id-external": ""}, {"name": "Alexander F. Gelbukh", "id-internal": "g/AlexanderFGelbukh", "id-external": ""}], "url": {"full": "URL#336899", "pdf": ""}, "publisher-venue": "J. Intell. Fuzzy Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1101712278, "title": "Book review - Johan Farkas and Jannick Schou, Post-truth, fake news, and democracy - Mapping the politics of falsehood.", "abstract": "", "doi": "10.1177/0961000620927834", "date": "2020", "authors": {"name": "Kate Hinnant", "id-internal": "132/7274", "id-external": ""}, "url": {"full": "URL#341916", "pdf": ""}, "publisher-venue": "J. Libr. Inf. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3074989310, "title": "Fake News Propagation and Detection - A Sequential Model.", "abstract": "", "doi": "10.1287/mnsc.2019.3295", "date": "2020", "authors": {"name": "Yiangos Papanastasiou", "id-internal": "198/5835", "id-external": ""}, "url": {"full": "URL#348871", "pdf": ""}, "publisher-venue": "Manag. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 932843286, "title": "The Implied Truth Effect - Attaching Warnings to a Subset of Fake News Headlines Increases Perceived Accuracy of Headlines Without Warnings.", "abstract": "", "doi": "10.1287/mnsc.2019.3478", "date": "2020", "authors": [{"name": "Gordon Pennycook", "id-internal": "161/4730", "id-external": ""}, {"name": "Adam Bear", "id-internal": "176/0302", "id-external": ""}, {"name": "Evan T. Collins", "id-internal": "278/3697", "id-external": ""}, {"name": "David G. Rand", "id-internal": "57/8036", "id-external": ""}], "url": {"full": "URL#348874", "pdf": ""}, "publisher-venue": "Manag. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3905810293, "title": "Uncritical polarized groups - The impact of spreading fake news as fact in social networks.", "abstract": "", "doi": "10.1016/j.matcom.2020.06.013", "date": "2020", "authors": [{"name": "Jes\u00fas San Mart\u00edn", "id-internal": "118/7281", "id-external": ""}, {"name": "F\u00e1tima Drubi", "id-internal": "58/4916", "id-external": ""}, {"name": "Daniel Rodr\u00edguez-P\u00e9rez", "id-internal": "57/4234", "id-external": ""}], "url": {"full": "URL#349321", "pdf": ""}, "publisher-venue": "Math. Comput. Simul.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 407290056, "title": "'Fake news' as infrastructural uncanny.", "abstract": "", "doi": "10.1177/1461444819856912", "date": "2020", "authors": [{"name": "Jonathan Gray", "id-internal": "47/1786", "id-external": ""}, {"name": "Liliana Bounegru", "id-internal": "213/7444", "id-external": ""}, {"name": "Tommaso Venturini", "id-internal": "159/6150", "id-external": ""}], "url": {"full": "URL#357442", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1746988647, "title": "Countering Fake News - A Comparison of Possible Solutions Regarding User Acceptance and Effectiveness.", "abstract": "", "doi": "10.1145/3415211", "date": "2020", "authors": [{"name": "Jan Kirchner", "id-internal": "203/1852", "id-external": ""}, {"name": "Christian Reuter 0001", "id-internal": "79/3736", "id-external": ""}], "url": {"full": "URL#359471", "pdf": ""}, "publisher-venue": "Proc. ACM Hum. Comput. Interact.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3968600350, "title": "Multi-level word features based on CNN for fake news detection in cultural communication.", "abstract": "", "doi": "10.1007/s00779-019-01289-y", "date": "2020", "authors": [{"name": "Qian Li 0024", "id-internal": "69/5902-24", "id-external": ""}, {"name": "Qingyuan Hu", "id-internal": "73/11210", "id-external": ""}, {"name": "Youshui Lu", "id-internal": "261/5636", "id-external": ""}, {"name": "Yue Yang", "id-internal": "54/6179", "id-external": ""}, {"name": "Jingxian Cheng", "id-internal": "261/5717", "id-external": ""}], "url": {"full": "URL#363070", "pdf": ""}, "publisher-venue": "Pers. Ubiquitous Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 218115229, "title": "Edge Computing and Blockchain for Quick Fake News Detection in IoV.", "abstract": "", "doi": "10.3390/s20164360", "date": "2020", "authors": [{"name": "Yonggang Xiao", "id-internal": "224/6576", "id-external": ""}, {"name": "Yanbing Liu", "id-internal": "84/4048", "id-external": ""}, {"name": "Tun Li", "id-internal": "08/5261", "id-external": ""}], "url": {"full": "URL#379676", "pdf": ""}, "publisher-venue": "Sensors", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3666550056, "title": "Classification of Fake News by Fine-tuning Deep Bidirectional Transformers based Language Model.", "abstract": "", "doi": "10.4108/eai.13-7-2018.163973", "date": "2020", "authors": [{"name": "Akshay Aggarwal", "id-internal": "12/6850", "id-external": ""}, {"name": "Aniruddha Chauhan", "id-internal": "270/1123", "id-external": ""}, {"name": "Deepika Kumar", "id-internal": "250/2133", "id-external": ""}, {"name": "Mamta Mittal", "id-internal": "220/0742", "id-external": ""}, {"name": "Sharad Verma", "id-internal": "50/7444", "id-external": ""}], "url": {"full": "URL#383143", "pdf": ""}, "publisher-venue": "EAI Endorsed Trans. Scalable Inf. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1677787089, "title": "A systematic mapping on automatic classification of fake news in social media.", "abstract": "", "doi": "10.1007/s13278-020-00659-2", "date": "2020", "authors": [{"name": "Jo\u00e3o Victor de Souza", "id-internal": "269/3657", "id-external": ""}, {"name": "Jor\u00e3o Gomes Jr.", "id-internal": "246/8313", "id-external": ""}, {"name": "Fernando Marques de Souza Filho", "id-internal": "269/3782", "id-external": ""}, {"name": "Alessandreia Marta de Oliveira Julio", "id-internal": "269/3307", "id-external": ""}, {"name": "Jairo Francisco de Souza", "id-internal": "99/6877", "id-external": ""}], "url": {"full": "URL#384083", "pdf": ""}, "publisher-venue": "Soc. Netw. Anal. Min.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3157239357, "title": "Fake News Detection Using a Blend of Neural Networks - An Application of Deep Learning.", "abstract": "", "doi": "10.1007/s42979-020-00165-4", "date": "2020", "authors": [{"name": "Aman Agarwal", "id-internal": "25/8468", "id-external": ""}, {"name": "Mamta Mittal", "id-internal": "220/0742", "id-external": ""}, {"name": "Akshat Pathak", "id-internal": "270/7266", "id-external": ""}, {"name": "Lalit Mohan Goyal", "id-internal": "219/8907", "id-external": ""}], "url": {"full": "URL#384099", "pdf": ""}, "publisher-venue": "SN Comput. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2746487127, "title": "Automating fake news detection system using multi-level voting model.", "abstract": "", "doi": "10.1007/s00500-019-04436-y", "date": "2020", "authors": [{"name": "Sawinder Kaur", "id-internal": "214/6987", "id-external": ""}, {"name": "Parteek Kumar", "id-internal": "127/3040", "id-external": ""}, {"name": "Ponnurangam Kumaraguru", "id-internal": "97/5147", "id-external": ""}], "url": {"full": "URL#385010", "pdf": ""}, "publisher-venue": "Soft Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1190538379, "title": "A Sensitive Stylistic Approach to Identify Fake News on Social Networking.", "abstract": "", "doi": "10.1109/lsp.2020.3008087", "date": "2020", "authors": [{"name": "Nicollas R. de Oliveira", "id-internal": "267/4985", "id-external": ""}, {"name": "Dianne S. V. Medeiros", "id-internal": "193/1420", "id-external": ""}, {"name": "Diogo M. F. Mattos", "id-internal": "144/8416", "id-external": ""}], "url": {"full": "URL#386637", "pdf": ""}, "publisher-venue": "IEEE Signal Process. Lett.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1472281273, "title": "Two-Path Deep Semisupervised Learning for Timely Fake News Detection.", "abstract": "", "doi": "10.1109/tcss.2020.3027639", "date": "2020", "authors": [{"name": "Xishuang Dong", "id-internal": "62/7701", "id-external": ""}, {"name": "Uboho Victor", "id-internal": "243/2843", "id-external": ""}, {"name": "Lijun Qian", "id-internal": "48/536", "id-external": ""}], "url": {"full": "URL#396835", "pdf": ""}, "publisher-venue": "IEEE Trans. Comput. Soc. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 856930640, "title": "Defensive Modeling of Fake News Through Online Social Networks.", "abstract": "", "doi": "10.1109/tcss.2020.3014135", "date": "2020", "authors": [{"name": "Gulshan Shrivastava", "id-internal": "206/5293", "id-external": ""}, {"name": "Prabhat Kumar", "id-internal": "66/831", "id-external": ""}, {"name": "Rudra Pratap Ojha", "id-internal": "132/0104", "id-external": ""}, {"name": "Pramod Kumar Srivastava", "id-internal": "206/5603", "id-external": ""}, {"name": "Senthilkumar Mohan", "id-internal": "244/0946", "id-external": ""}, {"name": "Gautam Srivastava", "id-internal": "57/9993", "id-external": ""}], "url": {"full": "URL#396891", "pdf": ""}, "publisher-venue": "IEEE Trans. Comput. Soc. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4293151978, "title": "Robust Fake News Detection Over Time and Attack.", "abstract": "", "doi": "10.1145/3363818", "date": "2020", "authors": [{"name": "Benjamin D. Horne", "id-internal": "166/8102", "id-external": ""}, {"name": "Jeppe N\u00f8rregaard", "id-internal": "239/4071", "id-external": ""}, {"name": "Sibel Adali", "id-internal": "a/SAdali", "id-external": ""}], "url": {"full": "URL#404368", "pdf": ""}, "publisher-venue": "ACM Trans. Intell. Syst. Technol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2323281175, "title": "FNED - A Deep Network for Fake News Early Detection on Social Media.", "abstract": "", "doi": "10.1145/3386253", "date": "2020", "authors": [{"name": "Yang Liu", "id-internal": "51/3710", "id-external": ""}, {"name": "Yi-fang Brook Wu", "id-internal": "75/1418", "id-external": ""}], "url": {"full": "URL#409109", "pdf": ""}, "publisher-venue": "ACM Trans. Inf. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 914142689, "title": "Capturing the Style of Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Piotr Przybyla", "id-internal": "130/9765", "id-external": ""}, "url": {"full": "URL#421075", "pdf": ""}, "publisher-venue": "AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1851734060, "title": "SpotFake+ - A Multimodal Framework for Fake News Detection via Transfer Learning (Student Abstract).", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Shivangi Singhal", "id-internal": "218/0755", "id-external": ""}, {"name": "Anubha Kabra", "id-internal": "266/2823", "id-external": ""}, {"name": "Mohit Sharma", "id-internal": "04/3916", "id-external": ""}, {"name": "Rajiv Ratn Shah", "id-internal": "134/3502", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}, {"name": "Ponnurangam Kumaraguru", "id-internal": "97/5147", "id-external": ""}], "url": {"full": "URL#421210", "pdf": ""}, "publisher-venue": "AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2505935894, "title": "Weak Supervision for Fake News Detection via Reinforcement Learning.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Yaqing Wang", "id-internal": "147/1393", "id-external": ""}, {"name": "Weifeng Yang", "id-internal": "27/7344", "id-external": ""}, {"name": "Fenglong Ma", "id-internal": "85/10856", "id-external": ""}, {"name": "Jin Xu", "id-internal": "97/3265", "id-external": ""}, {"name": "Bin Zhong", "id-internal": "79/10179", "id-external": ""}, {"name": "Qiang Deng", "id-internal": "68/10452", "id-external": ""}, {"name": "Jing Gao 0004", "id-internal": "67/4834-4", "id-external": ""}], "url": {"full": "URL#421431", "pdf": ""}, "publisher-venue": "AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3103112871, "title": "Protecting Data Privacy and Prevent Fake News and Deepfakes in Social Media via Blockchain Technology.", "abstract": "", "doi": "10.1007/978-981-33-6835-4_44", "date": "2020", "authors": [{"name": "Tee Wee Jing", "id-internal": "169/2935", "id-external": ""}, {"name": "Raja Kumar Murugesan", "id-internal": "71/9568", "id-external": ""}], "url": {"full": "URL#422263", "pdf": ""}, "publisher-venue": "ACeS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3191053458, "title": "Fake News Types and Detection Models on Social Media A State-of-the-Art Survey.", "abstract": "", "doi": "10.1007/978-981-15-3380-8_49", "date": "2020", "authors": [{"name": "Botambu Collins", "id-internal": "256/4806", "id-external": ""}, {"name": "Dinh Tuyen Hoang", "id-internal": "194/3689", "id-external": ""}, {"name": "Ngoc Thanh Nguyen", "id-internal": "n/NgocThanhNguyen", "id-external": ""}, {"name": "Dosam Hwang", "id-internal": "91/6746", "id-external": ""}], "url": {"full": "URL#422314", "pdf": ""}, "publisher-venue": "ACIIDS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4014097191, "title": "How Effectively Can Machines Defend Against Machine-Generated Fake News? An Empirical Study.", "abstract": "", "doi": "10.18653/v1/2020.insights-1.7", "date": "2020", "authors": [{"name": "Meghana Moorthy Bhat", "id-internal": "234/8670", "id-external": ""}, {"name": "Srinivasan Parthasarathy 0001", "id-internal": "p/SParathasarathy", "id-external": ""}], "url": {"full": "URL#422680", "pdf": ""}, "publisher-venue": "Insights", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 535196146, "title": "GCAN - Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media.", "abstract": "", "doi": "10.18653/v1/2020.acl-main.48", "date": "2020", "authors": [{"name": "Yi-Ju Lu", "id-internal": "263/6834", "id-external": ""}, {"name": "Cheng-Te Li", "id-internal": "90/5961", "id-external": ""}], "url": {"full": "URL#423211", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3471945926, "title": "Fake News Detection Based on Subjective Opinions.", "abstract": "", "doi": "10.1007/978-3-030-54832-2_10", "date": "2020", "authors": [{"name": "Danchen Zhang", "id-internal": "118/3760", "id-external": ""}, {"name": "Vladimir I. Zadorozhny", "id-internal": "64/4494", "id-external": ""}], "url": {"full": "URL#424746", "pdf": ""}, "publisher-venue": "ADBIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1522896801, "title": "The Impact of Fake News on the African-American Community.", "abstract": "", "doi": "10.1007/978-3-030-52581-1_5", "date": "2020", "authors": [{"name": "Wayne Patterson", "id-internal": "19/5971", "id-external": ""}, {"name": "Augustine Orgah", "id-internal": "286/6832", "id-external": ""}, {"name": "Suryadip Chakraborty", "id-internal": "132/1089", "id-external": ""}, {"name": "Cynthia E. Winston-Proctor", "id-internal": "300/5184", "id-external": ""}], "url": {"full": "URL#425724", "pdf": ""}, "publisher-venue": "AHFE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1247572582, "title": "A Semantic Model for Context-Based Fake News Detection on Social Media.", "abstract": "", "doi": "10.1109/aiccsa50499.2020.9316504", "date": "2020", "authors": [{"name": "Anoud Bani-Hani", "id-internal": "206/1611", "id-external": ""}, {"name": "Oluwasegun A. Adedugbe", "id-internal": "156/2549", "id-external": ""}, {"name": "Elhadj Benkhelifa", "id-internal": "29/5366", "id-external": ""}, {"name": "Munir Majdalawieh", "id-internal": "98/9045", "id-external": ""}, {"name": "Feras N. Al-Obeidat", "id-internal": "82/8092", "id-external": ""}], "url": {"full": "URL#426448", "pdf": ""}, "publisher-venue": "AICCSA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3607094825, "title": "Sifting the Arguments in Fake News to Boost a Disinformation Analysis Tool.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "J\u00e9r\u00f4me Delobelle", "id-internal": "141/2105", "id-external": ""}, {"name": "Amaury Delamaire", "id-internal": "205/7842", "id-external": ""}, {"name": "Elena Cabrio", "id-internal": "35/7561", "id-external": ""}, {"name": "Rom\u00f3n Ruti", "id-internal": "278/5339", "id-external": ""}, {"name": "Serena Villata", "id-internal": "84/5009", "id-external": ""}], "url": {"full": "URL#426878", "pdf": ""}, "publisher-venue": "NL4AI@AI*IA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4176776687, "title": "Automatic Differentiation Between Legitimate and Fake News Using Named Entity Recognition.", "abstract": "", "doi": "10.1145/3430199.3430220", "date": "2020", "authors": [{"name": "Bo Sen Xu", "id-internal": "283/3825", "id-external": ""}, {"name": "Chih Ming Tsai", "id-internal": "71/7299", "id-external": ""}], "url": {"full": "URL#427679", "pdf": ""}, "publisher-venue": "AIPR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1801568796, "title": "Something Real about Fake News - The Role of Polarization and Mindfulness.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Gaurav Bansal", "id-internal": "59/6932", "id-external": ""}, {"name": "Aaron Weinschenk", "id-internal": "270/7592", "id-external": ""}], "url": {"full": "URL#429467", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3613442324, "title": "Foundations of Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Jordana J. George", "id-internal": "189/0352", "id-external": ""}, {"name": "Russell Torres", "id-internal": "125/0542", "id-external": ""}, {"name": "Natalie Gerhart", "id-internal": "160/5824", "id-external": ""}], "url": {"full": "URL#429565", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1587419545, "title": "Simultaneous Fake News and Topic Classification via Auxiliary Task Learning.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Tsun-hin Cheung", "id-internal": "285/0595", "id-external": ""}, {"name": "Kin-Man Lam 0001", "id-internal": "16/1994", "id-external": ""}], "url": {"full": "URL#431410", "pdf": ""}, "publisher-venue": "APSIPA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3031716388, "title": "Truth or Lie - Pre-emptive Detection of Fake News in Different Languages Through Entropy-based Active Learning and Multi-model Neural Ensemble.", "abstract": "", "doi": "10.1109/asonam49781.2020.9381422", "date": "2020", "authors": [{"name": "Md. Saqib Hasan", "id-internal": "289/2411", "id-external": ""}, {"name": "Rukshar Alam", "id-internal": "289/2459", "id-external": ""}, {"name": "Muhammad Abdullah Adnan", "id-internal": "90/5533", "id-external": ""}], "url": {"full": "URL#432626", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 479855446, "title": "Detecting Fake News Spreaders in Social Networks using Inductive Representation Learning.", "abstract": "", "doi": "10.1109/asonam49781.2020.9381466", "date": "2020", "authors": [{"name": "Bhavtosh Rath", "id-internal": "208/4861", "id-external": ""}, {"name": "Aadesh Salecha", "id-internal": "277/5089", "id-external": ""}, {"name": "Jaideep Srivastava", "id-internal": "s/JaideepSrivastava", "id-external": ""}], "url": {"full": "URL#432675", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2240016688, "title": "On Sentiment of Online Fake News.", "abstract": "", "doi": "10.1109/asonam49781.2020.9381323", "date": "2020", "authors": [{"name": "Razieh Nokhbeh Zaeem", "id-internal": "99/7855", "id-external": ""}, {"name": "Chengjing Li", "id-internal": "233/7667", "id-external": ""}, {"name": "K. Suzanne Barber", "id-internal": "b/KSuzanneBarber", "id-external": ""}], "url": {"full": "URL#432722", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3567298888, "title": "A Deep Learning Model for Early Detection of Fake News on Social Media*.", "abstract": "", "doi": "10.1109/besc51023.2020.9348311", "date": "2020", "authors": [{"name": "Pakindessama M. Konkobo", "id-internal": "286/2531", "id-external": ""}, {"name": "Rui Zhang", "id-internal": "60/2536", "id-external": ""}, {"name": "Siyuan Huang", "id-internal": "62/885", "id-external": ""}, {"name": "Toussida T. Minoungou", "id-internal": "286/2008", "id-external": ""}, {"name": "Jose A. Ouedraogo", "id-internal": "286/2444", "id-external": ""}, {"name": "Lin Li 0001", "id-internal": "73/2252-1", "id-external": ""}], "url": {"full": "URL#434251", "pdf": ""}, "publisher-venue": "BESC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2401964939, "title": "Fake News Classification of Social Media Through Sentiment Analysis.", "abstract": "", "doi": "10.1007/978-3-030-59612-5_5", "date": "2020", "authors": [{"name": "Lixuan Ding", "id-internal": "274/6607", "id-external": ""}, {"name": "Lanting Ding", "id-internal": "274/6642", "id-external": ""}, {"name": "Richard O. Sinnott", "id-internal": "99/6289", "id-external": ""}], "url": {"full": "URL#435257", "pdf": ""}, "publisher-venue": "BigData Congress", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2398089998, "title": "SGG - Spinbot, Grammarly and GloVe based Fake News Detection.", "abstract": "", "doi": "10.1109/bigmm50055.2020.00033", "date": "2020", "authors": [{"name": "Akansha Gautam", "id-internal": "272/8689", "id-external": ""}, {"name": "Koteswar Rao Jerripothula", "id-internal": "158/9790", "id-external": ""}], "url": {"full": "URL#436155", "pdf": ""}, "publisher-venue": "BigMM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2019950198, "title": "Attributional analysis of Multi-Modal Fake News Detection Models (Grand Challenge).", "abstract": "", "doi": "10.1109/bigmm50055.2020.00074", "date": "2020", "authors": [{"name": "Shashank Madhusudhan", "id-internal": "277/2164", "id-external": ""}, {"name": "Siddhant Mahurkar", "id-internal": "266/8270", "id-external": ""}, {"name": "Suresh Kumar Nagarajan", "id-internal": "277/2221", "id-external": ""}], "url": {"full": "URL#436178", "pdf": ""}, "publisher-venue": "BigMM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1255012091, "title": "WhistleBlower - Towards A Decentralized and Open Platform for Spotting Fake News.", "abstract": "", "doi": "10.1109/blockchain50366.2020.00026", "date": "2020", "authors": [{"name": "Gowri Sankar Ramachandran", "id-internal": "125/2771", "id-external": ""}, {"name": "Daniel Nemeth", "id-internal": "217/1684", "id-external": ""}, {"name": "David Neville", "id-internal": "47/10724", "id-external": ""}, {"name": "Dimitrii Zhelezov", "id-internal": "282/9593", "id-external": ""}, {"name": "Ahmet Yal\u00e7in", "id-internal": "282/8761", "id-external": ""}, {"name": "Oliver Fohrmann", "id-internal": "282/9604", "id-external": ""}, {"name": "Bhaskar Krishnamachari", "id-internal": "87/2250", "id-external": ""}], "url": {"full": "URL#437231", "pdf": ""}, "publisher-venue": "Blockchain", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 666458668, "title": "Multimodal fake news detection using a Cultural Algorithm with situational and normative knowledge.", "abstract": "", "doi": "10.1109/cec48606.2020.9185643", "date": "2020", "authors": [{"name": "Priyanshi Shah", "id-internal": "273/8520", "id-external": ""}, {"name": "Ziad Kobti", "id-internal": "36/167", "id-external": ""}], "url": {"full": "URL#442074", "pdf": ""}, "publisher-venue": "CEC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 375352670, "title": "Fake News on Facebook and Twitter - Investigating How People (Don't) Investigate.", "abstract": "", "doi": "10.1145/3313831.3376784", "date": "2020", "authors": [{"name": "Christine Geeng", "id-internal": "239/7899", "id-external": ""}, {"name": "Savanna Yee", "id-internal": "264/7302", "id-external": ""}, {"name": "Franziska Roesner", "id-internal": "23/2758", "id-external": ""}], "url": {"full": "URL#442731", "pdf": ""}, "publisher-venue": "CHI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1196926595, "title": "Pilot Case Study in Games as Polling Systems, Generating Knowledge about Fake News.", "abstract": "", "doi": "10.1145/3334480.3375230", "date": "2020", "authors": {"name": "Lindsay Grace", "id-internal": "09/3123", "id-external": ""}, "url": {"full": "URL#442756", "pdf": ""}, "publisher-venue": "CHI Extended Abstracts", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2845993144, "title": "Beyond Cognitive Ability - Susceptibility to Fake News Is Also Explained by Associative Inference.", "abstract": "", "doi": "10.1145/3334480.3383077", "date": "2020", "authors": [{"name": "Sian Lee", "id-internal": "264/7747", "id-external": ""}, {"name": "Joshua P. Forrest", "id-internal": "264/7679", "id-external": ""}, {"name": "Jessica Strait", "id-internal": "264/7598", "id-external": ""}, {"name": "Haeseung Seo", "id-internal": "244/0106", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}, {"name": "Aiping Xiong", "id-internal": "162/1393", "id-external": ""}], "url": {"full": "URL#442993", "pdf": ""}, "publisher-venue": "CHI Extended Abstracts", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3441507124, "title": "Joint Estimation of User And Publisher Credibility for Fake News Detection.", "abstract": "", "doi": "10.1145/3340531.3412066", "date": "2020", "authors": [{"name": "Rajdipa Chowdhury", "id-internal": "276/5102", "id-external": ""}, {"name": "Sriram Srinivasan 0004", "id-internal": "74/3399-4", "id-external": ""}, {"name": "Lise Getoor", "id-internal": "g/LiseGetoor", "id-external": ""}], "url": {"full": "URL#444645", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 176276236, "title": "The Battle Against Online Harmful Information - The Cases of Fake News and Hate Speech.", "abstract": "", "doi": "10.1145/3340531.3412169", "date": "2020", "authors": [{"name": "Anastasia Giachanou", "id-internal": "118/3830", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}], "url": {"full": "URL#444699", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 90425401, "title": "Epidemiology Inspired Framework for Fake News Mitigationin Social Networks.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Bhavtosh Rath", "id-internal": "208/4861", "id-external": ""}, {"name": "Jaideep Srivastava", "id-internal": "s/JaideepSrivastava", "id-external": ""}], "url": {"full": "URL#444926", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2845831643, "title": "Truth be Told - Fake News Detection Using User Reactions on Reddit.", "abstract": "", "doi": "10.1145/3340531.3417463", "date": "2020", "authors": [{"name": "Vinay Setty", "id-internal": "36/8510", "id-external": ""}, {"name": "Erlend Rekve", "id-internal": "276/5114", "id-external": ""}], "url": {"full": "URL#444953", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4276870140, "title": "Embedding Partial Propagation Network for Fake News Early Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Amila Silva", "id-internal": "220/0876", "id-external": ""}, {"name": "Yi Han 0003", "id-internal": "27/4390-3", "id-external": ""}, {"name": "Ling Luo 0002", "id-internal": "00/1811-2", "id-external": ""}, {"name": "Shanika Karunasekera", "id-internal": "47/5584", "id-external": ""}, {"name": "Christopher Leckie", "id-internal": "73/1139", "id-external": ""}], "url": {"full": "URL#444965", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1845957763, "title": "Distributed Architecture for Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-57805-3_20", "date": "2020", "authors": [{"name": "Rafal Kozik", "id-internal": "80/2851", "id-external": ""}, {"name": "Michal Choras", "id-internal": "06/2936", "id-external": ""}, {"name": "Sebastian Kula", "id-internal": "73/7452", "id-external": ""}, {"name": "Marek Pawlicki", "id-internal": "224/4630", "id-external": ""}], "url": {"full": "URL#445769", "pdf": ""}, "publisher-venue": "CISIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3010704756, "title": "Application of the BERT-Based Architecture in Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-57805-3_23", "date": "2020", "authors": [{"name": "Sebastian Kula", "id-internal": "73/7452", "id-external": ""}, {"name": "Michal Choras", "id-internal": "06/2936", "id-external": ""}, {"name": "Rafal Kozik", "id-internal": "80/2851", "id-external": ""}], "url": {"full": "URL#445772", "pdf": ""}, "publisher-venue": "CISIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1344728328, "title": "Fake News Detection - Do Complex Problems Need Complex Solutions?", "abstract": "", "doi": "10.1007/978-3-030-57805-3_22", "date": "2020", "authors": [{"name": "Ignacio Palacio Mar\u00edn", "id-internal": "277/8020", "id-external": ""}, {"name": "David Arroyo", "id-internal": "72/4580", "id-external": ""}], "url": {"full": "URL#445776", "pdf": ""}, "publisher-venue": "CISIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2718188973, "title": "KU-CST at the Profiling Fake News spreaders Shared Task.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Manex Agirrezabal", "id-internal": "140/3023", "id-external": ""}, "url": {"full": "URL#446058", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1433854214, "title": "Fake News Spreader Detection using Neural Tweet Aggregation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Oleg Bakhteev", "id-internal": "277/0581", "id-external": ""}, {"name": "Aleksandr Ogaltsov", "id-internal": "224/2058", "id-external": ""}, {"name": "Petr Ostroukhov", "id-internal": "258/3462", "id-external": ""}], "url": {"full": "URL#446073", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2649662937, "title": "Automatic Detection of Fake News Spreaders Using BERT.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Arup Baruah", "id-internal": "149/2397", "id-external": ""}, {"name": "Kaushik Amar Das", "id-internal": "256/4279", "id-external": ""}, {"name": "Ferdous A. Barbhuiya", "id-internal": "78/8343", "id-external": ""}, {"name": "Kuntal Dey", "id-internal": "82/1315", "id-external": ""}], "url": {"full": "URL#446076", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3858267195, "title": "Detecting Fake News Spreaders with Behavioural, Lexical and Psycholinguistic Features.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "H\u00e9ctor Ricardo Murrieta Bello", "id-internal": "277/0896", "id-external": ""}, {"name": "Lukas Heilmann", "id-internal": "239/8161", "id-external": ""}, {"name": "Esben Ronan", "id-internal": "277/0856", "id-external": ""}], "url": {"full": "URL#446078", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4175203913, "title": "Overview of PAN 2020 - Authorship Verification, Celebrity Profiling, Profiling Fake News Spreaders on Twitter, and Style Change Detection.", "abstract": "", "doi": "10.1007/978-3-030-58219-7_25", "date": "2020", "authors": [{"name": "Janek Bevendorff", "id-internal": "195/5852", "id-external": ""}, {"name": "Bilal Ghanem", "id-internal": "219/8408", "id-external": ""}, {"name": "Anastasia Giachanou", "id-internal": "118/3830", "id-external": ""}, {"name": "Mike Kestemont", "id-internal": "42/10071", "id-external": ""}, {"name": "Enrique Manjavacas", "id-internal": "205/2772", "id-external": ""}, {"name": "Ilia Markov", "id-internal": "146/9620", "id-external": ""}, {"name": "Maximilian Mayerl", "id-internal": "208/4329", "id-external": ""}, {"name": "Martin Potthast", "id-internal": "87/6573", "id-external": ""}, {"name": "Francisco M. Rangel Pardo", "id-internal": "63/8242", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}, {"name": "G\u00fcnther Specht", "id-internal": "s/GuntherSpecht", "id-external": ""}, {"name": "Efstathios Stamatatos", "id-internal": "16/2424", "id-external": ""}, {"name": "Benno Stein 0001", "id-internal": "69/4806-1", "id-external": ""}, {"name": "Matti Wiegmann", "id-internal": "167/7939", "id-external": ""}, {"name": "Eva Zangerle", "id-internal": "31/8199", "id-external": ""}], "url": {"full": "URL#446079", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2424805610, "title": "An Ensemble Model Using N-grams and Statistical Features to Identify Fake News Spreaders on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Jakab Buda", "id-internal": "245/4311", "id-external": ""}, {"name": "Flora Bolonyai", "id-internal": "245/4360", "id-external": ""}], "url": {"full": "URL#446088", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3557607839, "title": "Fake News Spreaders Profiling Through Behavioural Analysis.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Matteo Cardaioli", "id-internal": "205/3630", "id-external": ""}, {"name": "Stefano Cecconello", "id-internal": "202/9073", "id-external": ""}, {"name": "Mauro Conti", "id-internal": "82/4386", "id-external": ""}, {"name": "Luca Pajola", "id-internal": "225/7722", "id-external": ""}, {"name": "Federico Turrin", "id-internal": "247/4992", "id-external": ""}], "url": {"full": "URL#446090", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3029846587, "title": "Ensemble of ELECTRA for Profiling Fake News Spreaders.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kaushik Amar Das", "id-internal": "256/4279", "id-external": ""}, {"name": "Arup Baruah", "id-internal": "149/2397", "id-external": ""}, {"name": "Ferdous Ahmed Barbhuiya", "id-internal": "78/8343", "id-external": ""}, {"name": "Kuntal Dey", "id-internal": "82/1315", "id-external": ""}], "url": {"full": "URL#446107", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3239236221, "title": "RMIT at PAN-CLEF 2020 - Profiling Fake News Spreaders on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Xinhuan Duan", "id-internal": "277/0942", "id-external": ""}, {"name": "Elham Naghizade", "id-internal": "147/2957", "id-external": ""}, {"name": "Damiano Spina", "id-internal": "74/2824", "id-external": ""}, {"name": "Xiuzhen Zhang", "id-internal": "20/2941", "id-external": ""}], "url": {"full": "URL#446113", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3889445558, "title": "Analyzing User Profiles for Detection of Fake News Spreaders on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Mar\u00eda S. Espinosa", "id-internal": "277/0759", "id-external": ""}, {"name": "Roberto Centeno", "id-internal": "26/6078", "id-external": ""}, {"name": "\u00c1lvaro Rodrigo", "id-internal": "57/1853", "id-external": ""}], "url": {"full": "URL#446120", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2258899804, "title": "Profiling Fake News Spreaders using Character and Words N-grams.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Daniel Yacob Espinosa", "id-internal": "245/4465", "id-external": ""}, {"name": "Helena G\u00f3mez-Adorno", "id-internal": "117/2917", "id-external": ""}, {"name": "Grigori Sidorov", "id-internal": "68/4195", "id-external": ""}], "url": {"full": "URL#446121", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3278318470, "title": "Approaches to the Profiling Fake News Spreaders on Twitter Task in English and Spanish.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Jacobo L\u00f3pez Fern\u00e1ndez", "id-internal": "277/0854", "id-external": ""}, {"name": "Juan Antonio L\u00f3pez Ram\u00edrez", "id-internal": "277/0606", "id-external": ""}], "url": {"full": "URL#446122", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1990327471, "title": "Profiling Fake News Spreaders - Stylometry, Personality, Emotions and Embeddings.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Elisabetta Fersini", "id-internal": "00/3705", "id-external": ""}, {"name": "Justin Armanini", "id-internal": "277/0628", "id-external": ""}, {"name": "Michael D'Intorni", "id-internal": "277/0904", "id-external": ""}], "url": {"full": "URL#446124", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3846464203, "title": "LSACoNet - A Combination of Lexical and Conceptual Features for Analysis of Fake News Spreaders on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Hamed Babaei Giglou", "id-internal": "224/2067", "id-external": ""}, {"name": "Jafar Razmara", "id-internal": "09/6381", "id-external": ""}, {"name": "Mostafa Rahgouy", "id-internal": "224/2051", "id-external": ""}, {"name": "Mahsa Sanaei", "id-internal": "277/0887", "id-external": ""}], "url": {"full": "URL#446129", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3841529708, "title": "Fake News Spreader Identification in Twitter using Ensemble Modeling. Notebook for PAN at CLEF 2020.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Ahmad Hashemi", "id-internal": "162/9296", "id-external": ""}, {"name": "Mohammad Reza Zarei", "id-internal": "255/5786", "id-external": ""}, {"name": "Mohammad Reza Moosavi", "id-internal": "83/9475", "id-external": ""}, {"name": "Mohammad Taheri", "id-internal": "72/4993", "id-external": ""}], "url": {"full": "URL#446140", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3005146904, "title": "A Multi-Aspect Classification Ensemble Approach for Profiling Fake News Spreaders on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Clemens H\u00f6rtenhuemer", "id-internal": "277/0544", "id-external": ""}, {"name": "Eva Zangerle", "id-internal": "31/8199", "id-external": ""}], "url": {"full": "URL#446144", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3022689917, "title": "UniNE at PAN-CLEF 2020 - Profiling Fake News Spreaders on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Catherine Ikae", "id-internal": "245/4232", "id-external": ""}, {"name": "Jacques Savoy", "id-internal": "s/JacquesSavoy", "id-external": ""}], "url": {"full": "URL#446150", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3672041604, "title": "Multilingual Detection of Fake News Spreaders via Sparse Matrix Factorization.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Boshko Koloski", "id-internal": "277/0961", "id-external": ""}, {"name": "Senja Pollak", "id-internal": "75/8154", "id-external": ""}, {"name": "Blaz Skrlj", "id-internal": "190/6972", "id-external": ""}], "url": {"full": "URL#446165", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1867328353, "title": "Fusing Stylistic Features with Deep-learning Methods for Profiling Fake News Spreader.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Roberto Labadie", "id-internal": "277/0694", "id-external": ""}, {"name": "Daniel Castro-Castro", "id-internal": "10/4317", "id-external": ""}, {"name": "Reynier Ortega Bueno", "id-internal": "151/0066", "id-external": ""}], "url": {"full": "URL#446174", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 111234652, "title": "Profiling Fake News Spreaders on Twitter based on TFIDF Features and Morphological Process. Notebook for PAN at CLEF 2020.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Mohamed Lichouri", "id-internal": "226/8991", "id-external": ""}, {"name": "Mourad Abbas", "id-internal": "01/11346", "id-external": ""}, {"name": "Besma Benaziz", "id-internal": "187/8289", "id-external": ""}], "url": {"full": "URL#446181", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 178855985, "title": "Profiling Fake News Spreaders on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "\u00c1lvaro L\u00f3pez", "id-internal": "277/0571", "id-external": ""}, {"name": "Pasqual Mart\u00ed", "id-internal": "268/8940", "id-external": ""}], "url": {"full": "URL#446184", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3084478929, "title": "Detecting Fake News Spreaders on Twitter Using Universal Sentence Encoder.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Soumayan Bandhu Majumder", "id-internal": "277/0852", "id-external": ""}, {"name": "Dipankar Das", "id-internal": "48/3180", "id-external": ""}], "url": {"full": "URL#446193", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 822145896, "title": "Profiling Fake News spreaders through Stylometry and Lexical Features. UniOR NLP @PAN2020.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Raffaele Manna", "id-internal": "231/9227", "id-external": ""}, {"name": "Antonio Pascucci", "id-internal": "231/8127", "id-external": ""}, {"name": "Johanna Monti", "id-internal": "33/9656", "id-external": ""}], "url": {"full": "URL#446195", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3846251100, "title": "Overview of the 8th Author Profiling Task at PAN 2020 - Profiling Fake News Spreaders on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Francisco M. Rangel Pardo", "id-internal": "63/8242", "id-external": ""}, {"name": "Anastasia Giachanou", "id-internal": "118/3830", "id-external": ""}, {"name": "Bilal Ghanem", "id-internal": "219/8408", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}], "url": {"full": "URL#446225", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3014577536, "title": "Identifying Fake News Spreaders in Social Media.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Nikhil Pinnaparaju", "id-internal": "264/2789", "id-external": ""}, {"name": "Vijayasaradhi Indurthi", "id-internal": "190/1681", "id-external": ""}, {"name": "Vasudeva Varma", "id-internal": "03/4045", "id-external": ""}], "url": {"full": "URL#446233", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4225056965, "title": "Using N-grams to detect Fake News Spreaders on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Juan Pizarro", "id-internal": "245/4143", "id-external": ""}, "url": {"full": "URL#446234", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2649920342, "title": "Sadness and Fear - Classification of Fake NewsSpreaders Content on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Irene Russo", "id-internal": "22/8155", "id-external": ""}, "url": {"full": "URL#446244", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 855977494, "title": "Profiling Fake News Spreaders on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Usman Saeed", "id-internal": "03/3899", "id-external": ""}, {"name": "Hammad Fahim", "id-internal": "277/0843", "id-external": ""}, {"name": "Farid Shirazi", "id-internal": "79/3336", "id-external": ""}], "url": {"full": "URL#446245", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1764853766, "title": "Ensemble Model for Profiling Fake News Spreaders on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "H. L. Shashirekha", "id-internal": "183/4155", "id-external": ""}, {"name": "M. D. Anusha", "id-internal": "277/0655", "id-external": ""}, {"name": "Nitin S. Prakash", "id-internal": "277/0757", "id-external": ""}], "url": {"full": "URL#446257", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1782045285, "title": "ULMFiT for Twitter Fake News Spreader Profiling.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "H. L. Shashirekha", "id-internal": "183/4155", "id-external": ""}, {"name": "Fazlourrahman Balouchzahi", "id-internal": "277/0925", "id-external": ""}], "url": {"full": "URL#446258", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2035812486, "title": "Detecting Fake News Spreaders in Social Networks via Linguistic and Personality Features.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Anu Shrestha", "id-internal": "225/5383", "id-external": ""}, {"name": "Francesca Spezzano", "id-internal": "81/7907", "id-external": ""}, {"name": "Abishai Joy", "id-internal": "277/0629", "id-external": ""}], "url": {"full": "URL#446259", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 140001239, "title": "EvolutionTeam at CLEF2020 - CheckThat! lab - Integration of Linguistic and Sentimental Features in a Fake News Detection Approach.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Ibtissam Touahri", "id-internal": "232/8525", "id-external": ""}, {"name": "Azzeddine Mazroui", "id-internal": "91/8972", "id-external": ""}], "url": {"full": "URL#446269", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1923739438, "title": "Fake News Spreader Detection on Twitter using Character N-Grams.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Inna Vogel", "id-internal": "216/7232", "id-external": ""}, {"name": "Meghana Meghana", "id-internal": "275/3443", "id-external": ""}], "url": {"full": "URL#446280", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2918882796, "title": "A BERT based Two-stage Fake News Spreader Profiling System.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Shih-Hung Wu", "id-internal": "83/4512", "id-external": ""}, {"name": "Sheng-Lun Chien", "id-internal": "266/0709", "id-external": ""}], "url": {"full": "URL#446286", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 608215343, "title": "Evaluating Unsupervised Representation Learning for Detecting Stances of Fake News.", "abstract": "", "doi": "10.18653/v1/2020.coling-main.558", "date": "2020", "authors": [{"name": "Maike Guderlei", "id-internal": "280/0697", "id-external": ""}, {"name": "Matthias A\u00dfenmacher", "id-internal": "256/0948", "id-external": ""}], "url": {"full": "URL#448838", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 153731690, "title": "Connecting the Dots Between Fact Verification and Fake News Detection.", "abstract": "", "doi": "10.18653/v1/2020.coling-main.165", "date": "2020", "authors": [{"name": "Qifei Li", "id-internal": "266/6211", "id-external": ""}, {"name": "Wangchunshu Zhou", "id-internal": "245/8640", "id-external": ""}], "url": {"full": "URL#448990", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3153201494, "title": "Words are the Window to the Soul - Language-based User Representations for Fake News Detection.", "abstract": "", "doi": "10.18653/v1/2020.coling-main.477", "date": "2020", "authors": [{"name": "Marco Del Tredici", "id-internal": "184/8927", "id-external": ""}, {"name": "Raquel Fern\u00e1ndez", "id-internal": "02/5384", "id-external": ""}], "url": {"full": "URL#449201", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1132948039, "title": "The Kauwa-Kaate Fake News Detection System - Demo.", "abstract": "", "doi": "10.1145/3371158.3371402", "date": "2020", "authors": [{"name": "Abhishek Bagade", "id-internal": "256/7966", "id-external": ""}, {"name": "Ashwini Pale", "id-internal": "256/8002", "id-external": ""}, {"name": "Shreyans Sheth", "id-internal": "256/8067", "id-external": ""}, {"name": "Megha Agarwal", "id-internal": "119/8606", "id-external": ""}, {"name": "Soumen Chakrabarti", "id-internal": "c/SChakrabarti", "id-external": ""}, {"name": "Kameswari Chebrolu", "id-internal": "17/792", "id-external": ""}, {"name": "S. Sudarshan 0001", "id-internal": "s/SSudarshan1", "id-external": ""}], "url": {"full": "URL#449556", "pdf": ""}, "publisher-venue": "COMAD/CODS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3762651965, "title": "Opinion Dynamic Modeling of Fake News Perception.", "abstract": "", "doi": "10.1007/978-3-030-65347-7_31", "date": "2020", "authors": [{"name": "Cecilia Toccaceli", "id-internal": "288/4630", "id-external": ""}, {"name": "Letizia Milli", "id-internal": "140/9523", "id-external": ""}, {"name": "Giulio Rossetti", "id-internal": "27/10814", "id-external": ""}], "url": {"full": "URL#450005", "pdf": ""}, "publisher-venue": "COMPLEX NETWORKS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2189012571, "title": "Keystroke Biometrics in Response to Fake News Propagation in a Global Pandemic.", "abstract": "", "doi": "10.1109/compsac48688.2020.00-26", "date": "2020", "authors": [{"name": "Aythami Morales", "id-internal": "91/7421", "id-external": ""}, {"name": "Alejandro Acien", "id-internal": "176/2890", "id-external": ""}, {"name": "Julian Fi\u00e9rrez", "id-internal": "97/4330", "id-external": ""}, {"name": "John V. Monaco", "id-internal": "119/2077", "id-external": ""}, {"name": "Rub\u00e9n Tolosana", "id-internal": "164/9111", "id-external": ""}, {"name": "Rub\u00e9n Vera-Rodr\u00edguez", "id-internal": "62/5209", "id-external": ""}, {"name": "Javier Ortega-Garcia", "id-internal": "95/893", "id-external": ""}], "url": {"full": "URL#450190", "pdf": ""}, "publisher-venue": "COMPSAC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 909017705, "title": "A Multi-feature Bayesian Approach for Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-66046-8_27", "date": "2020", "authors": [{"name": "Mario Casillo", "id-internal": "183/2551", "id-external": ""}, {"name": "Francesco Colace", "id-internal": "62/291", "id-external": ""}, {"name": "Dajana Conte", "id-internal": "25/10106", "id-external": ""}, {"name": "Massimo De Santo", "id-internal": "58/2824", "id-external": ""}, {"name": "Marco Lombardi", "id-internal": "161/0391", "id-external": ""}, {"name": "Serena Mottola", "id-internal": "282/1831", "id-external": ""}, {"name": "Domenico Santaniello", "id-internal": "207/6795", "id-external": ""}], "url": {"full": "URL#452554", "pdf": ""}, "publisher-venue": "CSoNet", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3640414554, "title": "A Novel Approach for Fake News Detection in Vehicular Ad-Hoc Network (VANET).", "abstract": "", "doi": "10.1007/978-3-030-66046-8_32", "date": "2020", "authors": [{"name": "Akshat Gaurav", "id-internal": "282/1748", "id-external": ""}, {"name": "Brij B. Gupta", "id-internal": "185/9576", "id-external": ""}, {"name": "Arcangelo Castiglione", "id-internal": "117/9048", "id-external": ""}, {"name": "Kostas E. Psannis", "id-internal": "53/6109", "id-external": ""}, {"name": "Chang Choi", "id-internal": "61/7024", "id-external": ""}], "url": {"full": "URL#452562", "pdf": ""}, "publisher-venue": "CSoNet", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1773870141, "title": "Propagation of Fake News on Social Media - Challenges and Opportunities.", "abstract": "", "doi": "10.1007/978-3-030-66046-8_28", "date": "2020", "authors": [{"name": "Saqib Hakak", "id-internal": "201/0779", "id-external": ""}, {"name": "Wazir Zada Khan", "id-internal": "13/9286", "id-external": ""}, {"name": "Sweta Bhattacharya", "id-internal": "238/5879", "id-external": ""}, {"name": "G. Thippa Reddy", "id-internal": "192/9289", "id-external": ""}, {"name": "Kim-Kwang Raymond Choo", "id-internal": "c/KimKwangRaymondChoo", "id-external": ""}], "url": {"full": "URL#452563", "pdf": ""}, "publisher-venue": "CSoNet", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3027030581, "title": "BNnet - A Deep Neural Network for the Identification of Satire and Fake Bangla News.", "abstract": "", "doi": "10.1007/978-3-030-66046-8_38", "date": "2020", "authors": [{"name": "Abdullah Al Imran", "id-internal": "248/5104", "id-external": ""}, {"name": "Zaman Wahid", "id-internal": "280/4263", "id-external": ""}, {"name": "Tanvir Ahmed", "id-internal": "73/1017", "id-external": ""}], "url": {"full": "URL#452570", "pdf": ""}, "publisher-venue": "CSoNet", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2512959530, "title": "k-TruthScore - Fake News Mitigation in the Presence of Strong User Bias.", "abstract": "", "doi": "10.1007/978-3-030-66046-8_10", "date": "2020", "authors": [{"name": "Akrati Saxena", "id-internal": "163/1823", "id-external": ""}, {"name": "Harsh Saxena", "id-internal": "261/1156", "id-external": ""}, {"name": "Ralucca Gera", "id-internal": "45/5825", "id-external": ""}], "url": {"full": "URL#452584", "pdf": ""}, "publisher-venue": "CSoNet", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1735540465, "title": "Multidimensional Analysis of Fake News Spreaders on Twitter.", "abstract": "", "doi": "10.1007/978-3-030-66046-8_29", "date": "2020", "authors": [{"name": "Maneet Singh", "id-internal": "142/1568", "id-external": ""}, {"name": "Rishemjit Kaur", "id-internal": "142/3858", "id-external": ""}, {"name": "S. R. S. Iyengar", "id-internal": "90/10042", "id-external": ""}], "url": {"full": "URL#452587", "pdf": ""}, "publisher-venue": "CSoNet", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1028121637, "title": "Fake News Detection using Higher-order User to User Mutual-attention Progression in Propagation Paths.", "abstract": "", "doi": "10.1109/cvprw50498.2020.00334", "date": "2020", "authors": {"name": "Rahul Mishra", "id-internal": "66/9553", "id-external": ""}, "url": {"full": "URL#454029", "pdf": ""}, "publisher-venue": "CVPR Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1306399378, "title": "Leveraging Machine Learning for Fake News Detection.", "abstract": "", "doi": "10.5220/0009767401510157", "date": "2020", "authors": [{"name": "Elio Masciari", "id-internal": "28/168", "id-external": ""}, {"name": "Vincenzo Moscato", "id-internal": "97/4042", "id-external": ""}, {"name": "Antonio Picariello", "id-internal": "62/431", "id-external": ""}, {"name": "Giancarlo Sperl\u00ec", "id-internal": "121/0078", "id-external": ""}], "url": {"full": "URL#455842", "pdf": ""}, "publisher-venue": "DATA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3305809484, "title": "Policy & Regulation Against Fake News - Case of Russia.", "abstract": "", "doi": "10.1145/3396956.3397866", "date": "2020", "authors": [{"name": "Aleksey Martynov", "id-internal": "159/0471", "id-external": ""}, {"name": "Mikhail Bundin", "id-internal": "159/0504", "id-external": ""}], "url": {"full": "URL#457197", "pdf": ""}, "publisher-venue": "DG.O", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3268574420, "title": "Fake News Detection using Multilingual Evidence.", "abstract": "", "doi": "10.1109/dsaa49011.2020.00111", "date": "2020", "authors": [{"name": "Daryna Dementieva", "id-internal": "279/2369", "id-external": ""}, {"name": "Alexander Panchenko", "id-internal": "60/9162", "id-external": ""}], "url": {"full": "URL#458465", "pdf": ""}, "publisher-venue": "DSAA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1713687677, "title": "Multimodal Multi-image Fake News Detection.", "abstract": "", "doi": "10.1109/dsaa49011.2020.00091", "date": "2020", "authors": [{"name": "Anastasia Giachanou", "id-internal": "118/3830", "id-external": ""}, {"name": "Guobiao Zhang", "id-internal": "246/4658", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}], "url": {"full": "URL#458473", "pdf": ""}, "publisher-venue": "DSAA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4212483992, "title": "Detecting Fake News Spreaders on Twitter from a Multilingual Perspective.", "abstract": "", "doi": "10.1109/dsaa49011.2020.00084", "date": "2020", "authors": [{"name": "Inna Vogel", "id-internal": "216/7232", "id-external": ""}, {"name": "Meghana Meghana", "id-internal": "275/3443", "id-external": ""}], "url": {"full": "URL#458537", "pdf": ""}, "publisher-venue": "DSAA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2261921395, "title": "Credulous Users and Fake News - a Real Case Study on the Propagation in Twitter.", "abstract": "", "doi": "10.1109/eais48028.2020.9122764", "date": "2020", "authors": [{"name": "Alessandro Balestrucci", "id-internal": "148/2763", "id-external": ""}, {"name": "Rocco De Nicola", "id-internal": "n/RDNicola", "id-external": ""}], "url": {"full": "URL#459005", "pdf": ""}, "publisher-venue": "EAIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3469563647, "title": "Adaptive Interaction Fusion Networks for Fake News Detection.", "abstract": "", "doi": "10.3233/faia200348", "date": "2020", "authors": [{"name": "Lianwei Wu", "id-internal": "214/2499", "id-external": ""}, {"name": "Yuan Rao", "id-internal": "73/4103", "id-external": ""}], "url": {"full": "URL#459782", "pdf": ""}, "publisher-venue": "ECAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3326760952, "title": "Fact-Checking, Fake News, Propaganda, and Media Bias - Truth Seeking in the Post-Truth Era.", "abstract": "", "doi": "10.18653/v1/2020.emnlp-tutorials.2", "date": "2020", "authors": [{"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Giovanni Da San Martino", "id-internal": "25/3236", "id-external": ""}], "url": {"full": "URL#466168", "pdf": ""}, "publisher-venue": "EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 607542655, "title": "Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News.", "abstract": "", "doi": "10.18653/v1/2020.emnlp-main.163", "date": "2020", "authors": [{"name": "Reuben Tan", "id-internal": "247/5782", "id-external": ""}, {"name": "Bryan A. Plummer", "id-internal": "163/2330", "id-external": ""}, {"name": "Kate Saenko", "id-internal": "88/2754", "id-external": ""}], "url": {"full": "URL#466414", "pdf": ""}, "publisher-venue": "EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 971928368, "title": "Where Are the Facts? Searching for Fact-checked Information to Alleviate the Spread of Fake News.", "abstract": "", "doi": "10.18653/v1/2020.emnlp-main.621", "date": "2020", "authors": [{"name": "Nguyen Vo", "id-internal": "167/0323", "id-external": ""}, {"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}], "url": {"full": "URL#466458", "pdf": ""}, "publisher-venue": "EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1193119819, "title": "Fake News Detection Using Time Series and User Features Classification.", "abstract": "", "doi": "10.1007/978-3-030-43722-0_22", "date": "2020", "authors": [{"name": "Maria Laura Previti", "id-internal": "209/8794", "id-external": ""}, {"name": "V\u00edctor Rodr\u00edguez-Fern\u00e1ndez", "id-internal": "164/7997", "id-external": ""}, {"name": "David Camacho", "id-internal": "64/1881", "id-external": ""}, {"name": "Vincenza Carchiolo", "id-internal": "71/250", "id-external": ""}, {"name": "Michele Malgeri", "id-internal": "25/971", "id-external": ""}], "url": {"full": "URL#470287", "pdf": ""}, "publisher-venue": "EvoApplications", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 229490560, "title": "Text-Convolutional Neural Networks for Fake News Detection in Tweets.", "abstract": "", "doi": "10.1007/978-981-15-5788-0_8", "date": "2020", "authors": [{"name": "Harsh Sinha", "id-internal": "228/0638", "id-external": ""}, {"name": "Sakshi", "id-internal": "218/6462", "id-external": ""}, {"name": "Yashvardhan Sharma", "id-internal": "92/2489", "id-external": ""}], "url": {"full": "URL#471491", "pdf": ""}, "publisher-venue": "FICTA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1250479204, "title": "UrduFake@FIRE2020 - Shared Track on Fake News Identification in Urdu.", "abstract": "", "doi": "10.1145/3441501.3441541", "date": "2020", "authors": [{"name": "Maaz Amjad", "id-internal": "220/4234", "id-external": ""}, {"name": "Grigori Sidorov", "id-internal": "68/4195", "id-external": ""}, {"name": "Alisa Zhila", "id-internal": "136/9257", "id-external": ""}, {"name": "Alexander F. Gelbukh", "id-internal": "g/AlexanderFGelbukh", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}], "url": {"full": "URL#471938", "pdf": ""}, "publisher-venue": "FIRE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2271649042, "title": "Overview of the Shared Task on Fake News Detection in Urdu at FIRE 2020.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Maaz Amjad", "id-internal": "220/4234", "id-external": ""}, {"name": "Grigori Sidorov", "id-internal": "68/4195", "id-external": ""}, {"name": "Alisa Zhila", "id-internal": "136/9257", "id-external": ""}, {"name": "Alexander F. Gelbukh", "id-internal": "g/AlexanderFGelbukh", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}], "url": {"full": "URL#471939", "pdf": ""}, "publisher-venue": "FIRE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3054624778, "title": "SSNCSE_NLP@Fake news detection in the Urdu language (UrduFake) 2020.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Nitin Nikamanth Appiah Balaji", "id-internal": "277/0807", "id-external": ""}, {"name": "B. Bharathi", "id-internal": "176/3054", "id-external": ""}], "url": {"full": "URL#471949", "pdf": ""}, "publisher-venue": "FIRE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3744650671, "title": "Learning Models for Urdu Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Fazlourrahman Balouchzahi", "id-internal": "277/0925", "id-external": ""}, {"name": "H. L. Shashirekha", "id-internal": "183/4155", "id-external": ""}], "url": {"full": "URL#471954", "pdf": ""}, "publisher-venue": "FIRE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3173767082, "title": "Urdu Fake News Detection using Generalized Autoregressors.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Abdullah Faiz Ur Rahman Khilji", "id-internal": "267/9510", "id-external": ""}, {"name": "Sahinur Rahman Laskar", "id-internal": "247/6547", "id-external": ""}, {"name": "Partha Pakray", "id-internal": "27/7928", "id-external": ""}, {"name": "Sivaji Bandyopadhyay", "id-internal": "04/2897", "id-external": ""}], "url": {"full": "URL#471992", "pdf": ""}, "publisher-venue": "FIRE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3278220964, "title": "Fake News Detection in the Urdu Language using CharCNN-RoBERTa.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Nankai Lin", "id-internal": "235/2956", "id-external": ""}, {"name": "Sihui Fu", "id-internal": "210/8466", "id-external": ""}, {"name": "Shengyi Jiang", "id-internal": "67/3929", "id-external": ""}], "url": {"full": "URL#472005", "pdf": ""}, "publisher-venue": "FIRE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 699730296, "title": "A GRU-based Fake News Prediction System - Working Notes for UrduFake-FIRE 2020.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Saichethan Miriyala Reddy", "id-internal": "268/5359", "id-external": ""}, {"name": "Chanchal Suman", "id-internal": "241/6114", "id-external": ""}, {"name": "Sriparna Saha 0001", "id-internal": "27/1664-1", "id-external": ""}, {"name": "Pushpak Bhattacharyya", "id-internal": "p/PushpakBhattacharyya", "id-external": ""}], "url": {"full": "URL#472028", "pdf": ""}, "publisher-venue": "FIRE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2758573518, "title": "A Board Game to Fight Against Misinformation and Fake News.", "abstract": "", "doi": "10.1007/978-3-030-63464-3_31", "date": "2020", "authors": [{"name": "Christophe Maze", "id-internal": "279/8914", "id-external": ""}, {"name": "Arthur Haye", "id-internal": "279/8855", "id-external": ""}, {"name": "Joshua Sarre", "id-internal": "279/8801", "id-external": ""}, {"name": "Michel Galaup", "id-internal": "159/2127", "id-external": ""}, {"name": "Pierre Lagarrigue", "id-internal": "159/1706", "id-external": ""}, {"name": "Catherine Pons-Lelardeux", "id-internal": "159/2151", "id-external": ""}], "url": {"full": "URL#473556", "pdf": ""}, "publisher-venue": "GALA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 752168455, "title": "Fake News Detection by Means of Uncertainty Weighted Causal Graphs.", "abstract": "", "doi": "10.1007/978-3-030-61705-9_2", "date": "2020", "authors": [{"name": "Eduardo C. Garrido-Merch\u00e1n", "id-internal": "200/9425", "id-external": ""}, {"name": "Cristina Puente", "id-internal": "00/4391", "id-external": ""}, {"name": "Rafael Palacios", "id-internal": "22/1223", "id-external": ""}], "url": {"full": "URL#476856", "pdf": ""}, "publisher-venue": "HAIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 430025130, "title": "Designing an Experiment on Recognition of Political Fake News by Social Media Users - Factors of Dropout.", "abstract": "", "doi": "10.1007/978-3-030-49570-1_18", "date": "2020", "authors": [{"name": "Olessia Koltsova", "id-internal": "137/4921", "id-external": ""}, {"name": "Yadviga Sinyavskaya", "id-internal": "205/3275", "id-external": ""}, {"name": "Maxim Terpilovskii", "id-internal": "269/6367", "id-external": ""}], "url": {"full": "URL#477963", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3668958042, "title": "The Influence of Traits Associated with Autism Spectrum Disorder (ASD) on the Detection of Fake News.", "abstract": "", "doi": "10.1007/978-3-030-60152-2_35", "date": "2020", "authors": [{"name": "Jacqui Taylor-Jackson", "id-internal": "36/7192", "id-external": ""}, {"name": "Sophie Matthews", "id-internal": "275/0063", "id-external": ""}], "url": {"full": "URL#478811", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1272097474, "title": "The Power of Related Articles - Improving Fake News Detection on Social Media Platforms.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Henner Gimpel", "id-internal": "41/4552", "id-external": ""}, {"name": "Sebastian Heger", "id-internal": "152/9129", "id-external": ""}, {"name": "Julia Kasper", "id-internal": "263/2989", "id-external": ""}, {"name": "Ricarda Sch\u00e4fer", "id-internal": "263/2984", "id-external": ""}], "url": {"full": "URL#479545", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 523467085, "title": "Context Map Analysis of Fake News in Social Media - A Contextualized Visualization Approach.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Onur Seref", "id-internal": "97/262", "id-external": ""}, {"name": "Michelle M. H. Seref", "id-internal": "50/9721", "id-external": ""}, {"name": "Sukhwa Hong", "id-internal": "247/3250", "id-external": ""}], "url": {"full": "URL#479952", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 938542466, "title": "How does Information Spread? An Exploratory Study of True and Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Sandeep Suntwal", "id-internal": "232/5613", "id-external": ""}, {"name": "Susan A. Brown", "id-internal": "64/3781", "id-external": ""}, {"name": "Mark Patton", "id-internal": "36/4686", "id-external": ""}], "url": {"full": "URL#479999", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3091005702, "title": "Detection of Fake News Based on Domain Analysis and Social Network Psychology.", "abstract": "", "doi": "10.1007/978-3-030-73050-5_44", "date": "2020", "authors": [{"name": "Dipayan Deb", "id-internal": "290/4020", "id-external": ""}, {"name": "Ratti Sai Pavan", "id-internal": "290/3958", "id-external": ""}, {"name": "Azad Nautiyal", "id-internal": "290/4093", "id-external": ""}, {"name": "Ameya Phadnis", "id-internal": "290/4054", "id-external": ""}, {"name": "Hemant Rathore", "id-internal": "224/4545", "id-external": ""}], "url": {"full": "URL#480187", "pdf": ""}, "publisher-venue": "HIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1080591828, "title": "Unsupervised Fake News Detection - A Graph-based Approach.", "abstract": "", "doi": "10.1145/3372923.3404783", "date": "2020", "authors": [{"name": "Siva Charan Reddy Gangireddy", "id-internal": "175/5573", "id-external": ""}, {"name": "Deepak P 0001", "id-internal": "33/1882", "id-external": ""}, {"name": "Cheng Long", "id-internal": "58/10813", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}], "url": {"full": "URL#481317", "pdf": ""}, "publisher-venue": "HT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3560415743, "title": "A Systematic Review on Fake News Themes Reported in Literature.", "abstract": "", "doi": "10.1007/978-3-030-45002-1_19", "date": "2020", "authors": [{"name": "Marlie Celliers", "id-internal": "262/4871", "id-external": ""}, {"name": "Marie Hattingh", "id-internal": "120/5795", "id-external": ""}], "url": {"full": "URL#481982", "pdf": ""}, "publisher-venue": "I3E", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1941941748, "title": "The Use of Critical Thinking to Identify Fake News - A Systematic Literature Review.", "abstract": "", "doi": "10.1007/978-3-030-45002-1_20", "date": "2020", "authors": [{"name": "Paul Machete", "id-internal": "262/4990", "id-external": ""}, {"name": "Marita Turpin", "id-internal": "31/10500", "id-external": ""}], "url": {"full": "URL#482010", "pdf": ""}, "publisher-venue": "I3E", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1591677752, "title": "Supervised Classification Methods for Fake News Identification.", "abstract": "", "doi": "10.1007/978-3-030-61534-5_40", "date": "2020", "authors": [{"name": "Thanh Cong Truong", "id-internal": "255/8212", "id-external": ""}, {"name": "Quoc Bao Diep", "id-internal": "241/5538", "id-external": ""}, {"name": "Ivan Zelinka", "id-internal": "82/2538", "id-external": ""}, {"name": "Roman Senkerik", "id-internal": "43/5090", "id-external": ""}], "url": {"full": "URL#483504", "pdf": ""}, "publisher-venue": "ICAISC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3420689546, "title": "EMET - Embeddings from Multilingual-Encoder Transformer for Fake News Detection.", "abstract": "", "doi": "10.1109/icassp40776.2020.9054673", "date": "2020", "authors": [{"name": "Stephane Schwarz", "id-internal": "270/4361", "id-external": ""}, {"name": "Ant\u00f4nio The\u00f3philo", "id-internal": "190/3379", "id-external": ""}, {"name": "Anderson Rocha 0001", "id-internal": "81/2446", "id-external": ""}], "url": {"full": "URL#485668", "pdf": ""}, "publisher-venue": "ICASSP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 55568133, "title": "A Fake News Dissemination Model Based on Updating Reliability and Doubt among Individuals.", "abstract": "", "doi": "10.1109/icast51195.2020.9319485", "date": "2020", "authors": [{"name": "Kento Yoshikawa", "id-internal": "284/3270", "id-external": ""}, {"name": "Takumi Awa", "id-internal": "284/3247", "id-external": ""}, {"name": "Risa Kusano", "id-internal": "284/2884", "id-external": ""}, {"name": "Hiroyuki Sato", "id-internal": "68/5837", "id-external": ""}, {"name": "Masatsugu Ichino", "id-internal": "33/6896", "id-external": ""}, {"name": "Hiroshi Yoshiura", "id-internal": "11/1899", "id-external": ""}], "url": {"full": "URL#486233", "pdf": ""}, "publisher-venue": "iCAST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4185650819, "title": "Trust-based Ecosystem to Combat Fake News.", "abstract": "", "doi": "10.1109/icbc48266.2020.9169435", "date": "2020", "authors": [{"name": "Zakwan Jaroucheh", "id-internal": "39/7568", "id-external": ""}, {"name": "Mohamad Alissa", "id-internal": "244/0110", "id-external": ""}, {"name": "William J. Buchanan", "id-internal": "04/5266", "id-external": ""}], "url": {"full": "URL#486364", "pdf": ""}, "publisher-venue": "IEEE ICBC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1164181421, "title": "Sentiment Analysis for Fake News Detection by Means of Neural Networks.", "abstract": "", "doi": "10.1007/978-3-030-50423-6_49", "date": "2020", "authors": [{"name": "Sebastian Kula", "id-internal": "73/7452", "id-external": ""}, {"name": "Michal Choras", "id-internal": "06/2936", "id-external": ""}, {"name": "Rafal Kozik", "id-internal": "80/2851", "id-external": ""}, {"name": "Pawel Ksieniewicz", "id-internal": "145/6756", "id-external": ""}, {"name": "Michal Wozniak 0001", "id-internal": "37/5714-1", "id-external": ""}], "url": {"full": "URL#487917", "pdf": ""}, "publisher-venue": "ICCS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2202287620, "title": "BERT-Based Mental Model, a Better Fake News Detector.", "abstract": "", "doi": "10.1145/3404555.3404607", "date": "2020", "authors": [{"name": "Jia Ding", "id-internal": "25/10869", "id-external": ""}, {"name": "Yongjun Hu", "id-internal": "201/3143", "id-external": ""}, {"name": "Huiyou Chang", "id-internal": "30/6058", "id-external": ""}], "url": {"full": "URL#488668", "pdf": ""}, "publisher-venue": "ICCAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3228114859, "title": "Fake news detector in the medical domain by reasoning with description logics.", "abstract": "", "doi": "10.1109/iccp51029.2020.9266270", "date": "2020", "authors": [{"name": "Adrian Groza", "id-internal": "96/2182", "id-external": ""}, {"name": "Ana-Diana Pop", "id-internal": "280/1912", "id-external": ""}], "url": {"full": "URL#491071", "pdf": ""}, "publisher-venue": "ICCP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2448391709, "title": "A Hybrid Approach for Fake News Detection in Twitter Based on User Features and Graph Embedding.", "abstract": "", "doi": "10.1007/978-3-030-36987-3_17", "date": "2020", "authors": [{"name": "Tarek Hamdi", "id-internal": "255/9985", "id-external": ""}, {"name": "Hamda Slimi", "id-internal": "234/5975", "id-external": ""}, {"name": "Ibrahim Bounhas", "id-internal": "27/7872", "id-external": ""}, {"name": "Yahya Slimani", "id-internal": "81/5328", "id-external": ""}], "url": {"full": "URL#492399", "pdf": ""}, "publisher-venue": "ICDCIT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1939742535, "title": "MALCOM - Generating Malicious Comments to Attack Neural Fake News Detection Models.", "abstract": "", "doi": "10.1109/icdm50108.2020.00037", "date": "2020", "authors": [{"name": "Thai Le", "id-internal": "03/9889", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}], "url": {"full": "URL#493097", "pdf": ""}, "publisher-venue": "ICDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1321260782, "title": "An Experimental Evaluation of Data Classification Models for Credibility Based Fake News Detection.", "abstract": "", "doi": "10.1109/icdmw51313.2020.00022", "date": "2020", "authors": [{"name": "Amit Neil Ramkissoon", "id-internal": "285/7027", "id-external": ""}, {"name": "Shareeda Mohammed", "id-internal": "130/4048", "id-external": ""}], "url": {"full": "URL#493180", "pdf": ""}, "publisher-venue": "ICDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1318415777, "title": "Adversarial Active Learning based Heterogeneous Graph Neural Network for Fake News Detection.", "abstract": "", "doi": "10.1109/icdm50108.2020.00054", "date": "2020", "authors": [{"name": "Yuxiang Ren", "id-internal": "236/5117", "id-external": ""}, {"name": "Bo Wang", "id-internal": "72/6811", "id-external": ""}, {"name": "Jiawei Zhang 0001", "id-internal": "10/239-1", "id-external": ""}, {"name": "Yi Chang 0001", "id-internal": "02/5438", "id-external": ""}], "url": {"full": "URL#493181", "pdf": ""}, "publisher-venue": "ICDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1673170153, "title": "State of the Art Models for Fake News Detection Tasks.", "abstract": "", "doi": "10.1109/iciot48696.2020.9089487", "date": "2020", "authors": [{"name": "Wissam Antoun", "id-internal": "246/0438", "id-external": ""}, {"name": "Fady Baly", "id-internal": "190/3497", "id-external": ""}, {"name": "Rim Achour", "id-internal": "265/7760", "id-external": ""}, {"name": "Amir Hussein", "id-internal": "134/9208", "id-external": ""}, {"name": "Hazem M. Hajj", "id-internal": "84/8237", "id-external": ""}], "url": {"full": "URL#495736", "pdf": ""}, "publisher-venue": "ICIoT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 765247401, "title": "An Explainable Machine Learning Framework for Fake Financial News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Xiaohui Zhang", "id-internal": "55/1332", "id-external": ""}, {"name": "Qianzhou Du", "id-internal": "172/7187", "id-external": ""}, {"name": "Zhongju Zhang", "id-internal": "92/1805", "id-external": ""}], "url": {"full": "URL#496862", "pdf": ""}, "publisher-venue": "ICIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 877334358, "title": "Nudging Users to Slow Down the Spread of Fake News in Social Media.", "abstract": "", "doi": "10.1109/icmew46912.2020.9106003", "date": "2020", "authors": [{"name": "Christian von der Weth", "id-internal": "18/2883", "id-external": ""}, {"name": "Jithin Vachery", "id-internal": "14/10827", "id-external": ""}, {"name": "Mohan S. Kankanhalli", "id-internal": "09/3613", "id-external": ""}], "url": {"full": "URL#499589", "pdf": ""}, "publisher-venue": "ICME Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1456967757, "title": "Towards Machine Learning Explainability in Text Classification for Fake News Detection.", "abstract": "", "doi": "10.1109/icmla51294.2020.00127", "date": "2020", "authors": [{"name": "Lukas Kurasinski", "id-internal": "286/6977", "id-external": ""}, {"name": "Radu-Casian Mihailescu", "id-internal": "10/10270", "id-external": ""}], "url": {"full": "URL#501093", "pdf": ""}, "publisher-venue": "ICMLA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1475959036, "title": "Automatic Fake News Detection with Pre-trained Transformer Models.", "abstract": "", "doi": "10.1007/978-3-030-68787-8_45", "date": "2020", "authors": [{"name": "Mina Sch\u00fctz", "id-internal": "285/9811", "id-external": ""}, {"name": "Alexander Schindler", "id-internal": "68/10703", "id-external": ""}, {"name": "Melanie Siegel", "id-internal": "84/2538", "id-external": ""}, {"name": "Kawa Nazemi", "id-internal": "43/160", "id-external": ""}], "url": {"full": "URL#504338", "pdf": ""}, "publisher-venue": "ICPR Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 147474605, "title": "Multi-Modal Component Embedding for Fake News Detection.", "abstract": "", "doi": "10.1109/imcom48794.2020.9001800", "date": "2020", "authors": [{"name": "SeongKu Kang", "id-internal": "251/9613", "id-external": ""}, {"name": "Junyoung Hwang", "id-internal": "246/3153", "id-external": ""}, {"name": "Hwanjo Yu", "id-internal": "80/6889", "id-external": ""}], "url": {"full": "URL#509657", "pdf": ""}, "publisher-venue": "IMCOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 221104464, "title": "Toward a Better Performance Evaluation Framework for Fake News Classification.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Lia Bozarth", "id-internal": "200/0112", "id-external": ""}, {"name": "Ceren Budak", "id-internal": "66/8462", "id-external": ""}], "url": {"full": "URL#510016", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 762366050, "title": "Higher Ground? How Groundtruth Labeling Impacts Our Understanding of Fake News about the 2016 U.S. Presidential Nominees.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Lia Bozarth", "id-internal": "200/0112", "id-external": ""}, {"name": "Aparajita Saraf", "id-internal": "266/9867", "id-external": ""}, {"name": "Ceren Budak", "id-internal": "66/8462", "id-external": ""}], "url": {"full": "URL#510017", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 374842908, "title": "Ginger Cannot Cure Cancer - Battling Fake Health News with a Comprehensive Data Repository.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Enyan Dai", "id-internal": "250/2886", "id-external": ""}, {"name": "Yiwei Sun", "id-internal": "20/8149", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}], "url": {"full": "URL#510026", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 273800122, "title": "Hierarchical Propagation Networks for Fake News Detection - Investigation and Exploitation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Deepak Mahudeswaran", "id-internal": "227/2536", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#510085", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2901662585, "title": "Emotion cognizance improves health fake news identification.", "abstract": "", "doi": "10.1145/3410566.3410595", "date": "2020", "authors": [{"name": "Anoop K.", "id-internal": "284/3968", "id-external": ""}, {"name": "Deepak P 0001", "id-internal": "33/1882", "id-external": ""}, {"name": "Lajish V. L", "id-internal": "243/5899", "id-external": ""}], "url": {"full": "URL#510463", "pdf": ""}, "publisher-venue": "IDEAS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1784138831, "title": "Detecting fake news by image analysis.", "abstract": "", "doi": "10.1145/3410566.3410599", "date": "2020", "authors": [{"name": "Elio Masciari", "id-internal": "28/168", "id-external": ""}, {"name": "Vincenzo Moscato", "id-internal": "97/4042", "id-external": ""}, {"name": "Antonio Picariello", "id-internal": "62/431", "id-external": ""}, {"name": "Giancarlo Sperl\u00ec", "id-internal": "121/0078", "id-external": ""}], "url": {"full": "URL#510468", "pdf": ""}, "publisher-venue": "IDEAS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3701595791, "title": "Automatic Fake News Detection by Exploiting User's Assessments on Social Networks - A Case Study of Twitter.", "abstract": "", "doi": "10.1007/978-3-030-55789-8_33", "date": "2020", "authors": [{"name": "Van Cuong Tran", "id-internal": "187/5407", "id-external": ""}, {"name": "Van Du Nguyen 0001", "id-internal": "129/3482", "id-external": ""}, {"name": "Ngoc Thanh Nguyen", "id-internal": "n/NgocThanhNguyen", "id-external": ""}], "url": {"full": "URL#510539", "pdf": ""}, "publisher-venue": "IEA/AIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2557829967, "title": "Fake News Detection Regarding the Hong Kong Events from Tweets.", "abstract": "", "doi": "10.1007/978-3-030-49190-1_16", "date": "2020", "authors": [{"name": "Maria Nefeli Nikiforos", "id-internal": "266/0688", "id-external": ""}, {"name": "Spiridon Vergis", "id-internal": "253/9769", "id-external": ""}, {"name": "Andreana Stylidou", "id-internal": "266/3381", "id-external": ""}, {"name": "Nikolaos Augoustis", "id-internal": "266/3372", "id-external": ""}, {"name": "Katia Lida Kermanidis", "id-internal": "23/4683", "id-external": ""}, {"name": "Manolis Maragoudakis", "id-internal": "89/1731", "id-external": ""}], "url": {"full": "URL#512077", "pdf": ""}, "publisher-venue": "AIAI Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4113086772, "title": "Hong Kong Protests - Using Natural Language Processing for Fake News Detection on Twitter.", "abstract": "", "doi": "10.1007/978-3-030-49186-4_34", "date": "2020", "authors": [{"name": "Alexandros Dimitrios Zervopoulos", "id-internal": "240/9186", "id-external": ""}, {"name": "Aikaterini Georgia Alvanou", "id-internal": "253/1475", "id-external": ""}, {"name": "Konstantinos Bezas", "id-internal": "253/9534", "id-external": ""}, {"name": "Asterios Papamichail", "id-internal": "240/9173", "id-external": ""}, {"name": "Manolis Maragoudakis", "id-internal": "89/1731", "id-external": ""}, {"name": "Katia Kermanidis", "id-internal": "23/4683", "id-external": ""}], "url": {"full": "URL#512109", "pdf": ""}, "publisher-venue": "AIAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3123628368, "title": "Fake News Detection from Data Streams.", "abstract": "", "doi": "10.1109/ijcnn48605.2020.9207498", "date": "2020", "authors": [{"name": "Pawel Ksieniewicz", "id-internal": "145/6756", "id-external": ""}, {"name": "Pawel Zyblewski", "id-internal": "241/5551", "id-external": ""}, {"name": "Michal Choras", "id-internal": "06/2936", "id-external": ""}, {"name": "Rafal Kozik", "id-internal": "80/2851", "id-external": ""}, {"name": "Agata Gielczyk", "id-internal": "226/5062", "id-external": ""}, {"name": "Michal Wozniak 0001", "id-internal": "37/5714-1", "id-external": ""}], "url": {"full": "URL#516665", "pdf": ""}, "publisher-venue": "IJCNN", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2101275037, "title": "A Deep Transfer Learning Approach for Fake News Detection.", "abstract": "", "doi": "10.1109/ijcnn48605.2020.9207477", "date": "2020", "authors": [{"name": "Tanik Saikh", "id-internal": "00/9019", "id-external": ""}, {"name": "Haripriya B.", "id-internal": "275/7840", "id-external": ""}, {"name": "Asif Ekbal", "id-internal": "11/3590", "id-external": ""}, {"name": "Pushpak Bhattacharyya", "id-internal": "p/PushpakBhattacharyya", "id-external": ""}], "url": {"full": "URL#517015", "pdf": ""}, "publisher-venue": "IJCNN", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3463286867, "title": "IARNet - An Information Aggregating and Reasoning Network over Heterogeneous Graph for Fake News Detection.", "abstract": "", "doi": "10.1109/ijcnn48605.2020.9207406", "date": "2020", "authors": [{"name": "Junshuai Yu", "id-internal": "261/6831", "id-external": ""}, {"name": "Qi Huang", "id-internal": "46/4397", "id-external": ""}, {"name": "Xiaofei Zhou", "id-internal": "58/1065", "id-external": ""}, {"name": "Ying Sha", "id-internal": "80/4686", "id-external": ""}], "url": {"full": "URL#517242", "pdf": ""}, "publisher-venue": "IJCNN", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3774504670, "title": "BDANN - BERT-Based Domain Adaptation Neural Network for Multi-Modal Fake News Detection.", "abstract": "", "doi": "10.1109/ijcnn48605.2020.9206973", "date": "2020", "authors": [{"name": "Tong Zhang", "id-internal": "07/4227", "id-external": ""}, {"name": "Di Wang 0004", "id-internal": "18/5410-4", "id-external": ""}, {"name": "Huanhuan Chen", "id-internal": "72/5816", "id-external": ""}, {"name": "Zhiwei Zeng", "id-internal": "149/8306", "id-external": ""}, {"name": "Wei Guo", "id-internal": "71/6601", "id-external": ""}, {"name": "Chunyan Miao", "id-internal": "m/ChunyanMiao", "id-external": ""}, {"name": "Lizhen Cui", "id-internal": "82/5713", "id-external": ""}], "url": {"full": "URL#517277", "pdf": ""}, "publisher-venue": "IJCNN", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1409926989, "title": "Bengali Fake News Detection.", "abstract": "", "doi": "10.1109/is48319.2020.9199931", "date": "2020", "authors": [{"name": "Farzana Islam", "id-internal": "158/6099", "id-external": ""}, {"name": "Mohammad Minhazul Alam", "id-internal": "274/9178", "id-external": ""}, {"name": "S. M. Shahadat Hossain", "id-internal": "274/9292", "id-external": ""}, {"name": "Abdul Motaleb", "id-internal": "274/9664", "id-external": ""}, {"name": "Sabrina Yeasmin", "id-internal": "274/9345", "id-external": ""}, {"name": "Mehedi Hasan", "id-internal": "168/4641", "id-external": ""}, {"name": "Rashedur M. Rahman", "id-internal": "69/6511", "id-external": ""}], "url": {"full": "URL#522553", "pdf": ""}, "publisher-venue": "IEEE Conf. on Intelligent Systems", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1315146174, "title": "Untangling between fake-news and truth in social media to understand the Covid-19 Coronavirus.", "abstract": "", "doi": "10.1109/iscc50000.2020.9219663", "date": "2020", "authors": [{"name": "Marco Furini", "id-internal": "35/4324", "id-external": ""}, {"name": "Silvia Mirri", "id-internal": "83/4258", "id-external": ""}, {"name": "Manuela Montangero", "id-internal": "46/3976", "id-external": ""}, {"name": "Catia Prandi", "id-internal": "31/9459", "id-external": ""}], "url": {"full": "URL#524530", "pdf": ""}, "publisher-venue": "ISCC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1803028096, "title": "Evaluating Preprocessing Techniques in Identifying Fake News.", "abstract": "", "doi": "10.1007/978-3-030-71187-0_46", "date": "2020", "authors": [{"name": "Matheus Marinho", "id-internal": "232/6658", "id-external": ""}, {"name": "Carmelo J. A. Bastos Filho", "id-internal": "72/164", "id-external": ""}, {"name": "Anthony Lins", "id-internal": "117/2937", "id-external": ""}], "url": {"full": "URL#524884", "pdf": ""}, "publisher-venue": "ISDA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2113446857, "title": "Using NER + ML to Automatically Detect Fake News.", "abstract": "", "doi": "10.1007/978-3-030-71187-0_109", "date": "2020", "authors": [{"name": "Marcos A. Spalenza", "id-internal": "246/2228", "id-external": ""}, {"name": "Elias de Oliveira", "id-internal": "09/5072", "id-external": ""}, {"name": "Leopoldo Lusquino Filho", "id-internal": "229/5575", "id-external": ""}, {"name": "Priscila M. V. Lima", "id-internal": "75/6119", "id-external": ""}, {"name": "Felipe M. G. Fran\u00e7a", "id-internal": "f/FelipeMaiaGalvaoFranca", "id-external": ""}], "url": {"full": "URL#524919", "pdf": ""}, "publisher-venue": "ISDA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2098639916, "title": "A Deep Learning Approach to Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-59491-6_11", "date": "2020", "authors": [{"name": "Elio Masciari", "id-internal": "28/168", "id-external": ""}, {"name": "Vincenzo Moscato", "id-internal": "97/4042", "id-external": ""}, {"name": "Antonio Picariello", "id-internal": "62/431", "id-external": ""}, {"name": "Giancarlo Sperl\u00ec", "id-internal": "121/0078", "id-external": ""}], "url": {"full": "URL#527075", "pdf": ""}, "publisher-venue": "ISMIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1394720303, "title": "An interpretable model to measure fakeness and emotion in news.", "abstract": "", "doi": "10.1016/j.procs.2020.08.009", "date": "2020", "authors": [{"name": "Guillaume Gadek", "id-internal": "199/9463", "id-external": ""}, {"name": "Paul Gu\u00e9lorget", "id-internal": "277/2180", "id-external": ""}], "url": {"full": "URL#533433", "pdf": ""}, "publisher-venue": "KES", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 139978052, "title": "Data Augmentation using Machine Translation for Fake News Detection in the Urdu Language.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Maaz Amjad", "id-internal": "220/4234", "id-external": ""}, {"name": "Grigori Sidorov", "id-internal": "68/4195", "id-external": ""}, {"name": "Alisa Zhila", "id-internal": "136/9257", "id-external": ""}], "url": {"full": "URL#535474", "pdf": ""}, "publisher-venue": "LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1816144649, "title": "Localization of Fake News Detection via Multitask Transfer Learning.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Jan Christian Blaise Cruz", "id-internal": "244/2362", "id-external": ""}, {"name": "Julianne Agatha Tan", "id-internal": "251/2993", "id-external": ""}, {"name": "Charibeth Cheng", "id-internal": "97/8063", "id-external": ""}], "url": {"full": "URL#535651", "pdf": ""}, "publisher-venue": "LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2191056570, "title": "BanFakeNews - A Dataset for Detecting Fake News in Bangla.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Md Zobaer Hossain", "id-internal": "263/3594", "id-external": ""}, {"name": "Md Ashraful Rahman", "id-internal": "263/3044", "id-external": ""}, {"name": "Md. Saiful Islam", "id-internal": "04/3572", "id-external": ""}, {"name": "Sudipta Kar", "id-internal": "186/7220", "id-external": ""}], "url": {"full": "URL#535820", "pdf": ""}, "publisher-venue": "LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1030630498, "title": "CLFD - A Novel Vectorization Technique and Its Application in Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Michail Mersinias", "id-internal": "266/1077", "id-external": ""}, {"name": "Stergos D. Afantenos", "id-internal": "34/3281", "id-external": ""}, {"name": "Georgios Chalkiadakis", "id-internal": "92/2998", "id-external": ""}], "url": {"full": "URL#536028", "pdf": ""}, "publisher-venue": "LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3499023198, "title": "A Survey on Natural Language Processing for Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Ray Oshikawa", "id-internal": "230/3700", "id-external": ""}, {"name": "Jing Qian", "id-internal": "71/944", "id-external": ""}, {"name": "William Yang Wang", "id-internal": "08/9282", "id-external": ""}], "url": {"full": "URL#536120", "pdf": ""}, "publisher-venue": "LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2613666667, "title": "Profiling Bots, Fake News Spreaders and Haters.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}, "url": {"full": "URL#536203", "pdf": ""}, "publisher-venue": "ResTUP@LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3579921541, "title": "Measuring the Impact of Readability Features in Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Roney L. S. Santos", "id-internal": "189/4600", "id-external": ""}, {"name": "Gabriela Wick-Pedro", "id-internal": "258/8786", "id-external": ""}, {"name": "Sidney Leal", "id-internal": "266/1093", "id-external": ""}, {"name": "Oto A. Vale", "id-internal": "31/1655", "id-external": ""}, {"name": "Thiago A. S. Pardo", "id-internal": "31/4118", "id-external": ""}, {"name": "Kalina Bontcheva", "id-internal": "b/KalinaBontcheva", "id-external": ""}, {"name": "Carolina Scarton", "id-internal": "23/8672", "id-external": ""}], "url": {"full": "URL#536225", "pdf": ""}, "publisher-venue": "LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1936157264, "title": "Transfer Learning from Transformers to Fake News Challenge Stance Detection (FNC-1) Task.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Valeriya Slovikovskaya", "id-internal": "251/9597", "id-external": ""}, {"name": "Giuseppe Attardi", "id-internal": "a/GAttardi", "id-external": ""}], "url": {"full": "URL#536269", "pdf": ""}, "publisher-venue": "LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3286283173, "title": "Tracing the Source of Fake News using a Scalable Blockchain Distributed Network.", "abstract": "", "doi": "10.1109/mass50613.2020.00015", "date": "2020", "authors": [{"name": "Ashutosh Dhar Dwivedi", "id-internal": "191/5979", "id-external": ""}, {"name": "Rajani Singh", "id-internal": "223/5388", "id-external": ""}, {"name": "Sakshi Dhall", "id-internal": "55/8142", "id-external": ""}, {"name": "Gautam Srivastava", "id-internal": "57/9993", "id-external": ""}, {"name": "Saibal K. Pal", "id-internal": "66/8143", "id-external": ""}], "url": {"full": "URL#536582", "pdf": ""}, "publisher-venue": "MASS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2989502649, "title": "TIB's Visual Analytics Group at MediaEval '20 - Detecting Fake News on Corona Virus and 5G Conspiracy.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Gullal Singh Cheema", "id-internal": "211/5762", "id-external": ""}, {"name": "Sherzod Hakimov", "id-internal": "117/6023", "id-external": ""}, {"name": "Ralph Ewerth", "id-internal": "45/52", "id-external": ""}], "url": {"full": "URL#537389", "pdf": ""}, "publisher-venue": "MediaEval", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2668750672, "title": "Fake News Detection in Social Media Using Graph Neural Networks and NLP Techniques - A COVID-19 Use-Case.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Abdullah Hamid", "id-internal": "155/8835", "id-external": ""}, {"name": "Nasrullah Sheikh", "id-internal": "211/3450", "id-external": ""}, {"name": "Naina Said", "id-internal": "232/1560", "id-external": ""}, {"name": "Kashif Ahmad", "id-internal": "150/4698", "id-external": ""}, {"name": "Asma Gul", "id-internal": "150/0164", "id-external": ""}, {"name": "Laiq Hasan", "id-internal": "37/6219", "id-external": ""}, {"name": "Ala I. Al-Fuqaha", "id-internal": "22/2131", "id-external": ""}], "url": {"full": "URL#537396", "pdf": ""}, "publisher-venue": "MediaEval", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 156227836, "title": "Fake News Classification with BERT.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Andrey Malakhov", "id-internal": "295/2470", "id-external": ""}, {"name": "Alessandro Patruno", "id-internal": "295/2517", "id-external": ""}, {"name": "Stefano Bocconi", "id-internal": "78/5363", "id-external": ""}], "url": {"full": "URL#537414", "pdf": ""}, "publisher-venue": "MediaEval", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3894021684, "title": "On the pursuit of Fake News - From Graph Convolutional Networks to Time Series.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Zeynep Pehlivan", "id-internal": "11/8342", "id-external": ""}, "url": {"full": "URL#537426", "pdf": ""}, "publisher-venue": "MediaEval", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1070318441, "title": "The Perception of the Fake News Phenomenon on the Internet by Members of Generation Z.", "abstract": "", "doi": "10.23919/mipro48935.2020.9245169", "date": "2020", "authors": [{"name": "Lordan Prelog", "id-internal": "278/6675", "id-external": ""}, {"name": "Ljubica Bakic-Tomic", "id-internal": "278/7170", "id-external": ""}], "url": {"full": "URL#540517", "pdf": ""}, "publisher-venue": "MIPRO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2463481808, "title": "Fake News Detection via Knowledge-driven Multimodal Graph Convolutional Networks.", "abstract": "", "doi": "10.1145/3372278.3390713", "date": "2020", "authors": [{"name": "Youze Wang", "id-internal": "267/2608", "id-external": ""}, {"name": "Shengsheng Qian", "id-internal": "138/4249", "id-external": ""}, {"name": "Jun Hu", "id-internal": "28/441", "id-external": ""}, {"name": "Quan Fang", "id-internal": "119/0328", "id-external": ""}, {"name": "Changsheng Xu", "id-internal": "85/1301", "id-external": ""}], "url": {"full": "URL#540734", "pdf": ""}, "publisher-venue": "ICMR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1665991779, "title": "Fake News Detection on Twitter Using Propagation Structures.", "abstract": "", "doi": "10.1007/978-3-030-61841-4_10", "date": "2020", "authors": [{"name": "Marion Meyers", "id-internal": "276/8086", "id-external": ""}, {"name": "Gerhard Weiss", "id-internal": "07/2055", "id-external": ""}, {"name": "Gerasimos Spanakis", "id-internal": "43/7739", "id-external": ""}], "url": {"full": "URL#540782", "pdf": ""}, "publisher-venue": "MISDOOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1050121278, "title": "The Role of Personality and Linguistic Patterns in Discriminating Between Fake News Spreaders and Fact Checkers.", "abstract": "", "doi": "10.1007/978-3-030-51310-8_17", "date": "2020", "authors": [{"name": "Anastasia Giachanou", "id-internal": "118/3830", "id-external": ""}, {"name": "Esteban A. R\u00edssola", "id-internal": "229/3158", "id-external": ""}, {"name": "Bilal Ghanem", "id-internal": "219/8408", "id-external": ""}, {"name": "Fabio Crestani", "id-internal": "c/FabioCrestani", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}], "url": {"full": "URL#547209", "pdf": ""}, "publisher-venue": "NLDB", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2538434242, "title": "SAFE - Similarity-Aware Multi-modal Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-47436-2_27", "date": "2020", "authors": [{"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Jindi Wu", "id-internal": "184/2336", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}], "url": {"full": "URL#549832", "pdf": ""}, "publisher-venue": "PAKDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3264081998, "title": "Exploring Thematic Coherence in Fake News.", "abstract": "", "doi": "10.1007/978-3-030-65965-3_40", "date": "2020", "authors": [{"name": "Martins Samuel Dogo", "id-internal": "281/7011", "id-external": ""}, {"name": "Deepak P 0001", "id-internal": "33/1882", "id-external": ""}, {"name": "Anna Jurek-Loughrey", "id-internal": "45/8120", "id-external": ""}], "url": {"full": "URL#551121", "pdf": ""}, "publisher-venue": "PKDD/ECML Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1608491925, "title": "Early Detection of Fake News with Multi-source Weak Social Supervision.", "abstract": "", "doi": "10.1007/978-3-030-67664-3_39", "date": "2020", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Guoqing Zheng", "id-internal": "12/4932", "id-external": ""}, {"name": "Yichuan Li", "id-internal": "216/7478", "id-external": ""}, {"name": "Subhabrata Mukherjee", "id-internal": "37/11030", "id-external": ""}, {"name": "Ahmed Hassan Awadallah", "id-internal": "147/9148", "id-external": ""}, {"name": "Scott Ruston", "id-internal": "72/9034", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#551287", "pdf": ""}, "publisher-venue": "ECML/PKDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2920452028, "title": "On the Coherence of Fake News Articles.", "abstract": "", "doi": "10.1007/978-3-030-65965-3_42", "date": "2020", "authors": [{"name": "Iknoor Singh", "id-internal": "243/5708", "id-external": ""}, {"name": "Deepak P 0001", "id-internal": "33/1882", "id-external": ""}, {"name": "Anoop K.", "id-internal": "284/3968", "id-external": ""}], "url": {"full": "URL#551289", "pdf": ""}, "publisher-venue": "PKDD/ECML Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1966858406, "title": "Fake News Detection in Social Media - A Systematic Review.", "abstract": "", "doi": "10.1145/3411564.3411648", "date": "2020", "authors": [{"name": "Francisco D. C. Medeiros", "id-internal": "276/7326", "id-external": ""}, {"name": "Reinaldo Bezerra Braga", "id-internal": "36/10735", "id-external": ""}], "url": {"full": "URL#555945", "pdf": ""}, "publisher-venue": "SBSI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 644012579, "title": "A Brazilian Portuguese Moral Foundations Dictionary for Fake News classification.", "abstract": "", "doi": "10.1109/sccc51225.2020.9281258", "date": "2020", "authors": [{"name": "Flavio Carvalho", "id-internal": "207/7000", "id-external": ""}, {"name": "Helder Yukio Okuno", "id-internal": "225/1891", "id-external": ""}, {"name": "Lais Baroni", "id-internal": "238/1303", "id-external": ""}, {"name": "Gustavo Paiva Guedes", "id-internal": "165/3747", "id-external": ""}], "url": {"full": "URL#556292", "pdf": ""}, "publisher-venue": "SCCC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3834138291, "title": "Some experiments on Deep Learning for Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Angelo Chianese", "id-internal": "79/2429", "id-external": ""}, {"name": "Elio Masciari", "id-internal": "28/168", "id-external": ""}, {"name": "Vincenzo Moscato", "id-internal": "97/4042", "id-external": ""}, {"name": "Antonio Picariello", "id-internal": "62/431", "id-external": ""}, {"name": "Giancarlo Sperl\u00ec", "id-internal": "121/0078", "id-external": ""}], "url": {"full": "URL#556815", "pdf": ""}, "publisher-venue": "SEBD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3754458748, "title": "Overview of MEX-A3T at IberLEF 2020 - Fake News and Aggressiveness Analysis in Mexican Spanish.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Mario Ezra Arag\u00f3n", "id-internal": "224/1915", "id-external": ""}, {"name": "Horacio Jes\u00fas Jarqu\u00edn-V\u00e1squez", "id-internal": "267/6376", "id-external": ""}, {"name": "Manuel Montes-y-G\u00f3mez", "id-internal": "56/2154", "id-external": ""}, {"name": "Hugo Jair Escalante", "id-internal": "86/2693", "id-external": ""}, {"name": "Luis Villase\u00f1or Pineda", "id-internal": "53/5047", "id-external": ""}, {"name": "Helena G\u00f3mez-Adorno", "id-internal": "117/2917", "id-external": ""}, {"name": "Juan Pablo Posadas-Dur\u00e1n", "id-internal": "83/10505", "id-external": ""}, {"name": "Gemma Bel-Enguix", "id-internal": "65/1331", "id-external": ""}], "url": {"full": "URL#558244", "pdf": ""}, "publisher-venue": "IberLEF@SEPLN", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2382735741, "title": "TecNM at MEX-A3T 2020 - Fake News and Aggressiveness Analysis in Mexican Spanish.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Samuel Arce-Cardenas", "id-internal": "277/0451", "id-external": ""}, {"name": "Daniel Fajardo-Delgado", "id-internal": "03/5545", "id-external": ""}, {"name": "Miguel \u00c1ngel \u00c1lvarez Carmona", "id-internal": "167/4659", "id-external": ""}], "url": {"full": "URL#558245", "pdf": ""}, "publisher-venue": "IberLEF@SEPLN", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3030734070, "title": "ITCG's Participation at MEX-A3T 2020 - Aggressive Identification and Fake News Detection Based on Textual Features for Mexican Spanish.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Diego Zaizar-Guti\u00e9rrez", "id-internal": "277/0506", "id-external": ""}, {"name": "Daniel Fajardo-Delgado", "id-internal": "03/5545", "id-external": ""}, {"name": "Miguel \u00c1ngel \u00c1lvarez Carmona", "id-internal": "167/4659", "id-external": ""}], "url": {"full": "URL#558289", "pdf": ""}, "publisher-venue": "IberLEF@SEPLN", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3046972034, "title": "Mass Communication on Social Media - The Case of Fake News.", "abstract": "", "doi": "10.1145/3378539.3393852", "date": "2020", "authors": {"name": "Maximilian Haug", "id-internal": "221/0683", "id-external": ""}, "url": {"full": "URL#558919", "pdf": ""}, "publisher-venue": "SIGMIS-CPR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2183977114, "title": "Towards the Identification of Fake News in Portuguese.", "abstract": "", "doi": "10.4230/oasics.slate.2020.7", "date": "2020", "authors": [{"name": "Jo\u00e3o Rodrigues", "id-internal": "91/6627", "id-external": ""}, {"name": "Ricardo Ribeiro 0001", "id-internal": "23/20-1", "id-external": ""}, {"name": "Fernando Batista", "id-internal": "07/6052", "id-external": ""}], "url": {"full": "URL#561998", "pdf": ""}, "publisher-venue": "SLATE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 249080817, "title": "FacTweet - Profiling Fake News Twitter Accounts.", "abstract": "", "doi": "10.1007/978-3-030-59430-5_3", "date": "2020", "authors": [{"name": "Bilal Ghanem", "id-internal": "219/8408", "id-external": ""}, {"name": "Simone Paolo Ponzetto", "id-internal": "04/2532", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}], "url": {"full": "URL#562041", "pdf": ""}, "publisher-venue": "SLSP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1417193509, "title": "Fane-KG - A Semantic Knowledge Graph for Context-Based Fake News Detection on Social Media.", "abstract": "", "doi": "10.1109/snams52053.2020.9336542", "date": "2020", "authors": [{"name": "Anoud Bani-Hani", "id-internal": "206/1611", "id-external": ""}, {"name": "Oluwasegun A. Adedugbe", "id-internal": "156/2549", "id-external": ""}, {"name": "Feras N. Al-Obeidat", "id-internal": "82/8092", "id-external": ""}, {"name": "Elhadj Benkhelifa", "id-internal": "29/5366", "id-external": ""}, {"name": "Munir Majdalawieh", "id-internal": "98/9045", "id-external": ""}], "url": {"full": "URL#563274", "pdf": ""}, "publisher-venue": "SNAMS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1288789946, "title": "The Adversarial UFP/UFN Attack - A New Threat to ML-based Fake News Detection Systems?", "abstract": "", "doi": "10.1109/ssci47803.2020.9308298", "date": "2020", "authors": [{"name": "Brandon Brown", "id-internal": "90/1016", "id-external": ""}, {"name": "Alexicia Richardson", "id-internal": "282/3156", "id-external": ""}, {"name": "Marcellus Smith", "id-internal": "282/8110", "id-external": ""}, {"name": "Gerry V. Dozier", "id-internal": "88/3850", "id-external": ""}, {"name": "Michael C. King", "id-internal": "214/3280", "id-external": ""}], "url": {"full": "URL#565213", "pdf": ""}, "publisher-venue": "SSCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 32757382, "title": "A Study of the Impact of Evolutionary-Based Feature Selection for Fake News Detection.", "abstract": "", "doi": "10.1109/ssci47803.2020.9308613", "date": "2020", "authors": [{"name": "Marcellus Smith", "id-internal": "282/8110", "id-external": ""}, {"name": "Alexicia Richardson", "id-internal": "282/3156", "id-external": ""}, {"name": "Brandon Brown", "id-internal": "90/1016", "id-external": ""}, {"name": "Gerry V. Dozier", "id-internal": "88/3850", "id-external": ""}, {"name": "Michael C. King", "id-internal": "214/3280", "id-external": ""}, {"name": "Joshua Morris", "id-internal": "241/8370", "id-external": ""}], "url": {"full": "URL#565497", "pdf": ""}, "publisher-venue": "SSCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 772009861, "title": "The (Un)Invited in Collective Action on Social Media - A Socio-Technical Perspective of Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Alessio Maria Braccini", "id-internal": "14/2943", "id-external": ""}, "url": {"full": "URL#566059", "pdf": ""}, "publisher-venue": "STPIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2392245325, "title": "Automatic Detection of Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Pontus Nordberg", "id-internal": "293/2668", "id-external": ""}, {"name": "Joakim K\u00e4vrestad", "id-internal": "174/8288", "id-external": ""}, {"name": "Marcus Nohlberg", "id-internal": "06/7463", "id-external": ""}], "url": {"full": "URL#566073", "pdf": ""}, "publisher-venue": "STPIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1032527478, "title": "Multimodal Fake News Detection with Textual, Visual and Semantic Information.", "abstract": "", "doi": "10.1007/978-3-030-58323-1_3", "date": "2020", "authors": [{"name": "Anastasia Giachanou", "id-internal": "118/3830", "id-external": ""}, {"name": "Guobiao Zhang", "id-internal": "246/4658", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}], "url": {"full": "URL#568471", "pdf": ""}, "publisher-venue": "TDS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 991077275, "title": "Detecting fake news in social media content (abstract).", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Charles Huot", "id-internal": "23/4278", "id-external": ""}, {"name": "Sonia Collada", "id-internal": "281/4760", "id-external": ""}], "url": {"full": "URL#568713", "pdf": ""}, "publisher-venue": "TWSDetection", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4153045833, "title": "Fake News Classification and Topic Modeling in Brazilian Portuguese.", "abstract": "", "doi": "10.1109/wiiat50758.2020.00063", "date": "2020", "authors": [{"name": "Maik Paix\u00e3o", "id-internal": "295/8065", "id-external": ""}, {"name": "Rinaldo Lima", "id-internal": "23/8009", "id-external": ""}, {"name": "Bernard Espinasse", "id-internal": "95/2326", "id-external": ""}], "url": {"full": "URL#574381", "pdf": ""}, "publisher-venue": "WI/IAT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 907001568, "title": "Debunking Fake News by Leveraging Speaker Credibility and BERT Based Model.", "abstract": "", "doi": "10.1109/wiiat50758.2020.00147", "date": "2020", "authors": [{"name": "Thoudam Doren Singh", "id-internal": "115/5882", "id-external": ""}, {"name": "Divyansha", "id-internal": "267/9678", "id-external": ""}, {"name": "Apoorva Vikram Singh", "id-internal": "267/9647", "id-external": ""}, {"name": "Anubhav Sachan", "id-internal": "241/0537", "id-external": ""}, {"name": "Abdullah Faiz Ur Rahman Khilji", "id-internal": "267/9510", "id-external": ""}], "url": {"full": "URL#574404", "pdf": ""}, "publisher-venue": "WI/IAT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1881311804, "title": "A Linguistic-Based Method that Combines Polarity, Emotion and Grammatical Characteristics to Detect Fake News in Portuguese.", "abstract": "", "doi": "10.1145/3428658.3430975", "date": "2020", "authors": [{"name": "Marcelo Pereira de Souza", "id-internal": "279/5500", "id-external": ""}, {"name": "Fl\u00e1vio Roberto Matias da Silva", "id-internal": "279/5622", "id-external": ""}, {"name": "Paulo M\u00e1rcio Souza Freire", "id-internal": "250/3519", "id-external": ""}, {"name": "Ronaldo Ribeiro Goldschmidt", "id-internal": "45/881", "id-external": ""}], "url": {"full": "URL#574529", "pdf": ""}, "publisher-venue": "WebMedia", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 590109013, "title": "Analysis of the Subjectivity Level in Fake News Fragments.", "abstract": "", "doi": "10.1145/3428658.3430978", "date": "2020", "authors": [{"name": "Lucas Lima Vieira", "id-internal": "279/5478", "id-external": ""}, {"name": "Caio Lib\u00e2nio Melo Jer\u00f4nimo", "id-internal": "172/7675", "id-external": ""}, {"name": "Cl\u00e1udio E. C. Campelo", "id-internal": "77/3901", "id-external": ""}, {"name": "Leandro Balby Marinho", "id-internal": "59/4973", "id-external": ""}], "url": {"full": "URL#574534", "pdf": ""}, "publisher-venue": "WebMedia", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3921524296, "title": "ACT - Automatic Fake News Classification Through Self-Attention.", "abstract": "", "doi": "10.1145/3394231.3397901", "date": "2020", "authors": {"name": "Nujud Aloshban", "id-internal": "268/0872", "id-external": ""}, "url": {"full": "URL#574541", "pdf": ""}, "publisher-venue": "WebSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4017175207, "title": "Proactive Discovery of Fake News Domains from Real-Time Social Media Feeds.", "abstract": "", "doi": "10.1145/3366424.3385772", "date": "2020", "authors": [{"name": "Zhouhan Chen", "id-internal": "170/8182", "id-external": ""}, {"name": "Juliana Freire", "id-internal": "f/JulianaFreire", "id-external": ""}], "url": {"full": "URL#576943", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1229919640, "title": "Explainable Detection of Fake News and Cyberbullying on Social Media.", "abstract": "", "doi": "10.1145/3366424.3384366", "date": "2020", "authors": {"name": "Cheng-Te Li", "id-internal": "90/5961", "id-external": ""}, "url": {"full": "URL#577083", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 144087761, "title": "Mining Disinformation and Fake News - Concepts, Methods, and Recent Advancements.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#582634", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3803341330, "title": "Two-path Deep Semi-supervised Learning for Timely Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Xishuang Dong", "id-internal": "62/7701", "id-external": ""}, {"name": "Uboho Victor", "id-internal": "243/2843", "id-external": ""}, {"name": "Lijun Qian", "id-internal": "48/536", "id-external": ""}], "url": {"full": "URL#586960", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2207477346, "title": "Ginger Cannot Cure Cancer - Battling Fake Health News with a Comprehensive Data Repository.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Enyan Dai", "id-internal": "250/2886", "id-external": ""}, {"name": "Yiwei Sun", "id-internal": "20/8149", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}], "url": {"full": "URL#586999", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 764745310, "title": "Improving Generalizability of Fake News Detection Methods using Propensity Score Matching.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Bo Ni", "id-internal": "91/9937", "id-external": ""}, {"name": "Zhichun Guo", "id-internal": "254/0545", "id-external": ""}, {"name": "Jianing Li", "id-internal": "72/6658", "id-external": ""}, {"name": "Meng Jiang 0001", "id-internal": "69/339-1", "id-external": ""}], "url": {"full": "URL#587000", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2560736503, "title": "Detecting Fake News with Capsule Neural Networks.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Mohammad Hadi Goldani", "id-internal": "258/1041", "id-external": ""}, {"name": "Saeedeh Momtazi", "id-internal": "51/3441", "id-external": ""}, {"name": "Reza Safabakhsh", "id-internal": "44/839", "id-external": ""}], "url": {"full": "URL#587067", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2594955629, "title": "Fake News Detection by means of Uncertainty Weighted Causal Graphs.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Eduardo C. Garrido-Merch\u00e1n", "id-internal": "200/9425", "id-external": ""}, {"name": "Cristina Puente", "id-internal": "00/4391", "id-external": ""}, {"name": "Rafael Palacios", "id-internal": "22/1223", "id-external": ""}], "url": {"full": "URL#587083", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2606900594, "title": "HGAT - Hierarchical Graph Attention Network for Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Yuxiang Ren", "id-internal": "236/5117", "id-external": ""}, {"name": "Jiawei Zhang 0001", "id-internal": "10/239-1", "id-external": ""}], "url": {"full": "URL#588437", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3509213921, "title": "Untrue.News - A New Search Engine For Fake Stories.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Vinicius Woloszyn", "id-internal": "204/3806", "id-external": ""}, {"name": "Felipe Schaeffer", "id-internal": "259/1656", "id-external": ""}, {"name": "Beliza Boniatti", "id-internal": "259/1256", "id-external": ""}, {"name": "Eduardo G. Cortes", "id-internal": "226/3865", "id-external": ""}, {"name": "Salar Mohtaj", "id-internal": "167/4836", "id-external": ""}, {"name": "Sebastian M\u00f6ller 0001", "id-internal": "37/5849", "id-external": ""}], "url": {"full": "URL#589324", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2604838599, "title": "Fake News Detection with Different Models.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Sairamvinay Vijayaraghavan", "id-internal": "260/7086", "id-external": ""}, {"name": "Ye Wang", "id-internal": "44/6292", "id-external": ""}, {"name": "Zhiyuan Guo", "id-internal": "26/10808", "id-external": ""}, {"name": "John Voong", "id-internal": "260/6674", "id-external": ""}, {"name": "Wenda Xu", "id-internal": "52/9964", "id-external": ""}, {"name": "Armand Nasseri", "id-internal": "260/6688", "id-external": ""}, {"name": "Jiaru Cai", "id-internal": "260/6900", "id-external": ""}, {"name": "Linda Li", "id-internal": "252/1350", "id-external": ""}, {"name": "Kevin Vuong", "id-internal": "260/6696", "id-external": ""}, {"name": "Eshan Wadhwa", "id-internal": "260/6862", "id-external": ""}], "url": {"full": "URL#593890", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1935525952, "title": "SAFE - Similarity-Aware Multi-Modal Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Jindi Wu", "id-internal": "184/2336", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}], "url": {"full": "URL#593892", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2389228728, "title": "Exploring the Role of Visual Content in Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Juan Cao", "id-internal": "75/2820", "id-external": ""}, {"name": "Peng Qi 0005", "id-internal": "59/9474-5", "id-external": ""}, {"name": "Qiang Sheng", "id-internal": "199/7557", "id-external": ""}, {"name": "Tianyun Yang", "id-internal": "189/3221", "id-external": ""}, {"name": "Junbo Guo", "id-internal": "33/4618", "id-external": ""}, {"name": "Jintao Li 0001", "id-internal": "l/JintaoLi-1", "id-external": ""}], "url": {"full": "URL#593945", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2401160946, "title": "Leveraging Multi-Source Weak Social Supervision for Early Detection of Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Guoqing Zheng", "id-internal": "12/4932", "id-external": ""}, {"name": "Yichuan Li", "id-internal": "216/7478", "id-external": ""}, {"name": "Subhabrata Mukherjee", "id-internal": "37/11030", "id-external": ""}, {"name": "Ahmed Hassan Awadallah", "id-internal": "147/9148", "id-external": ""}, {"name": "Scott Ruston", "id-internal": "72/9034", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#598123", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 865340134, "title": "BanFakeNews - A Dataset for Detecting Fake News in Bangla.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Md Zobaer Hossain", "id-internal": "263/3594", "id-external": ""}, {"name": "Md Ashraful Rahman", "id-internal": "263/3044", "id-external": ""}, {"name": "Md. Saiful Islam", "id-internal": "04/3572", "id-external": ""}, {"name": "Sudipta Kar", "id-internal": "186/7220", "id-external": ""}], "url": {"full": "URL#600939", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1825879303, "title": "Adaptive Interaction Fusion Networks for Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Lianwei Wu", "id-internal": "214/2499", "id-external": ""}, {"name": "Yuan Rao", "id-internal": "73/4103", "id-external": ""}], "url": {"full": "URL#601418", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2763372137, "title": "Anger makes fake news viral online.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Yuwei Chuai", "id-internal": "263/7105", "id-external": ""}, {"name": "Jichang Zhao", "id-internal": "27/3251", "id-external": ""}], "url": {"full": "URL#601569", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3293592153, "title": "GCAN - Graph-aware Co-Attention Networks for Explainable Fake News Detection on Social Media.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Yi-Ju Lu", "id-internal": "263/6834", "id-external": ""}, {"name": "Cheng-Te Li", "id-internal": "90/5961", "id-external": ""}], "url": {"full": "URL#602030", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2017775066, "title": "Detecting fake news for the new coronavirus by reasoning on the Covid-19 ontology.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Adrian Groza", "id-internal": "96/2182", "id-external": ""}, "url": {"full": "URL#602338", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3286157523, "title": "Credulous Users and Fake News - a Real Case Study on the Propagation in Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Alessandro Balestrucci", "id-internal": "148/2763", "id-external": ""}, {"name": "Rocco De Nicola", "id-internal": "n/RDNicola", "id-external": ""}], "url": {"full": "URL#604876", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 668851583, "title": "A Deep Learning Approach for Automatic Detection of Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Tanik Saikh", "id-internal": "00/9019", "id-external": ""}, {"name": "Arkadipta De", "id-internal": "256/4289", "id-external": ""}, {"name": "Asif Ekbal", "id-internal": "11/3590", "id-external": ""}, {"name": "Pushpak Bhattacharyya", "id-internal": "p/PushpakBhattacharyya", "id-external": ""}], "url": {"full": "URL#605424", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3474365580, "title": "Keystroke Biometrics in Response to Fake News Propagation in a Global Pandemic.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Aythami Morales", "id-internal": "91/7421", "id-external": ""}, {"name": "Alejandro Acien", "id-internal": "176/2890", "id-external": ""}, {"name": "Julian Fi\u00e9rrez", "id-internal": "97/4330", "id-external": ""}, {"name": "John V. Monaco", "id-internal": "119/2077", "id-external": ""}, {"name": "Rub\u00e9n Tolosana", "id-internal": "164/9111", "id-external": ""}, {"name": "Rub\u00e9n Vera-Rodr\u00edguez", "id-internal": "62/5209", "id-external": ""}, {"name": "Javier Ortega-Garcia", "id-internal": "95/893", "id-external": ""}], "url": {"full": "URL#606487", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2498102547, "title": "BRENDA - Browser Extension for Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Bjarte Botnevik", "id-internal": "266/1405", "id-external": ""}, {"name": "Eirik Sakariassen", "id-internal": "266/1444", "id-external": ""}, {"name": "Vinay Setty", "id-internal": "36/8510", "id-external": ""}], "url": {"full": "URL#608650", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2410949193, "title": "Detection of Bangla Fake News using MNB and SVM Classifier.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Md Gulzar Hussain", "id-internal": "266/3247", "id-external": ""}, {"name": "Md Rashidul Hasan", "id-internal": "254/2810", "id-external": ""}, {"name": "Mahmuda Rahman", "id-internal": "124/7137", "id-external": ""}, {"name": "Joy Protim", "id-internal": "266/3065", "id-external": ""}, {"name": "Sakib Al Hasan", "id-internal": "266/3023", "id-external": ""}], "url": {"full": "URL#609133", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1324745470, "title": "FakeCovid - A Multilingual Cross-domain Fact Check News Dataset for COVID-19.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Gautam Kishore Shahi", "id-internal": "178/1872", "id-external": ""}, {"name": "Durgesh Nandini", "id-internal": "178/1755", "id-external": ""}], "url": {"full": "URL#613943", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1346913911, "title": "Graph Neural Networks with Continual Learning for Fake News Detection from Social Media.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Yi Han 0003", "id-internal": "27/4390-3", "id-external": ""}, {"name": "Shanika Karunasekera", "id-internal": "47/5584", "id-external": ""}, {"name": "Christopher Leckie", "id-internal": "73/1139", "id-external": ""}], "url": {"full": "URL#617578", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2698564425, "title": "Machine Learning Explanations to Prevent Overtrust in Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Sina Mohseni", "id-internal": "155/4739", "id-external": ""}, {"name": "Fan Yang 0023", "id-internal": "29/3081-23", "id-external": ""}, {"name": "Shiva K. Pentyala", "id-internal": "240/9336", "id-external": ""}, {"name": "Mengnan Du", "id-internal": "183/5606", "id-external": ""}, {"name": "Yi Liu", "id-internal": "97/4626", "id-external": ""}, {"name": "Nic Lupfer", "id-internal": "53/8700", "id-external": ""}, {"name": "Xia Hu", "id-internal": "24/7536", "id-external": ""}, {"name": "Shuiwang Ji", "id-internal": "84/6405", "id-external": ""}, {"name": "Eric D. Ragan", "id-internal": "69/7691", "id-external": ""}], "url": {"full": "URL#621271", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3706803313, "title": "Fake News Detection using Temporal Features Extracted via Point Process.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Taichi Murayama", "id-internal": "263/7010", "id-external": ""}, {"name": "Shoko Wakamiya", "id-internal": "94/7622", "id-external": ""}, {"name": "Eiji Aramaki", "id-internal": "02/2649", "id-external": ""}], "url": {"full": "URL#621921", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1231528523, "title": "Modeling and Predicting Fake News Spreading on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Taichi Murayama", "id-internal": "263/7010", "id-external": ""}, {"name": "Shoko Wakamiya", "id-internal": "94/7622", "id-external": ""}, {"name": "Eiji Aramaki", "id-internal": "02/2649", "id-external": ""}, {"name": "Ryota Kobayashi", "id-internal": "39/1202", "id-external": ""}], "url": {"full": "URL#621937", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 960106654, "title": "Universal Fake News Collection System using Debunking Tweets.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Taichi Murayama", "id-internal": "263/7010", "id-external": ""}, {"name": "Shoko Wakamiya", "id-internal": "94/7622", "id-external": ""}, {"name": "Eiji Aramaki", "id-internal": "02/2649", "id-external": ""}], "url": {"full": "URL#621947", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 874878675, "title": "Weighted Accuracy Algorithmic Approach In Counteracting Fake News And Disinformation.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Kwadwo Osei Bonsu", "id-internal": "268/6958", "id-external": ""}, "url": {"full": "URL#623353", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4061481890, "title": "Network Inference from a Mixture of Diffusion Models for Fake News Mitigation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Karishma Sharma", "id-internal": "222/7902", "id-external": ""}, {"name": "Xinran He", "id-internal": "57/10359", "id-external": ""}, {"name": "Sungyong Seo", "id-internal": "178/3209", "id-external": ""}, {"name": "Yan Liu 0002", "id-internal": "l/YanLiu2", "id-external": ""}], "url": {"full": "URL#624103", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 896364564, "title": "Can We Spot the \"Fake News\" Before It Was Even Written?", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, "url": {"full": "URL#624483", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1141397335, "title": "Graph-based Modeling of Online Communities for Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Shantanu Chandra", "id-internal": "272/9083", "id-external": ""}, {"name": "Pushkar Mishra", "id-internal": "137/8258", "id-external": ""}, {"name": "Helen Yannakoudakis", "id-internal": "60/9768", "id-external": ""}, {"name": "Madhav Nimishakavi", "id-internal": "180/5919", "id-external": ""}, {"name": "Marzieh Saeidi", "id-internal": "136/9320", "id-external": ""}, {"name": "Ekaterina Shutova", "id-internal": "33/8156", "id-external": ""}], "url": {"full": "URL#625236", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 289184242, "title": "SGG - Spinbot, Grammarly and GloVe based Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Akansha Gautam", "id-internal": "272/8689", "id-external": ""}, {"name": "Koteswar Rao Jerripothula", "id-internal": "158/9790", "id-external": ""}], "url": {"full": "URL#625451", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3378194700, "title": "FANG - Leveraging Social Context for Fake News Detection Using Graph Representation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Van-Hoang Nguyen", "id-internal": "272/9171", "id-external": ""}, {"name": "Kazunari Sugiyama", "id-internal": "50/7001", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Min-Yen Kan", "id-internal": "k/MinYenKan", "id-external": ""}], "url": {"full": "URL#625910", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2460770853, "title": "MALCOM - Generating Malicious Comments to Attack Neural Fake News Detection Models.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Thai Le", "id-internal": "03/9889", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}], "url": {"full": "URL#628525", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1950426535, "title": "Controlling Fake News by Tagging - A Branching Process Analysis.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Suyog Kapsikar", "id-internal": "274/1238", "id-external": ""}, {"name": "Indrajit Saha", "id-internal": "39/3217", "id-external": ""}, {"name": "Khushboo Agarwal", "id-internal": "05/7496", "id-external": ""}, {"name": "Veeraruna Kavitha", "id-internal": "20/7822", "id-external": ""}, {"name": "Quanyan Zhu", "id-internal": "03/6207", "id-external": ""}], "url": {"full": "URL#628963", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1091897976, "title": "Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Reuben Tan", "id-internal": "247/5782", "id-external": ""}, {"name": "Bryan A. Plummer", "id-internal": "163/2330", "id-external": ""}, {"name": "Kate Saenko", "id-internal": "88/2754", "id-external": ""}], "url": {"full": "URL#630932", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3165432329, "title": "Similarity Detection Pipeline for Crawling a Topic Related Fake News Corpus.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Inna Vogel", "id-internal": "216/7232", "id-external": ""}, {"name": "Jeong-Eun Choi", "id-internal": "275/3672", "id-external": ""}, {"name": "Meghana Meghana", "id-internal": "275/3443", "id-external": ""}], "url": {"full": "URL#633118", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3767116378, "title": "Fake News Spreader Detection on Twitter using Character N-Grams. Notebook for PAN at CLEF 2020.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Inna Vogel", "id-internal": "216/7232", "id-external": ""}, {"name": "Meghana Meghana", "id-internal": "275/3443", "id-external": ""}], "url": {"full": "URL#633302", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1297199072, "title": "FaNDS - Fake News Detection System Using Energy Flow.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Jiawei Xu", "id-internal": "79/8798", "id-external": ""}, {"name": "Vladimir Zadorozhny", "id-internal": "64/4494", "id-external": ""}, {"name": "Danchen Zhang", "id-internal": "118/3760", "id-external": ""}, {"name": "John Grant", "id-internal": "85/4920", "id-external": ""}], "url": {"full": "URL#634630", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1475763924, "title": "Where Are the Facts? Searching for Fact-checked Information to Alleviate the Spread of Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Nguyen Vo", "id-internal": "167/0323", "id-external": ""}, {"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}], "url": {"full": "URL#635100", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2446150969, "title": "Connecting the Dots Between Fact Verification and Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Qifei Li", "id-internal": "266/6211", "id-external": ""}, {"name": "Wangchunshu Zhou", "id-internal": "245/8640", "id-external": ""}], "url": {"full": "URL#636008", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1288613645, "title": "Feature Extraction of Text for Deep Learning Algorithms - Application on Fake News Dectection.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "HyeonJun Kim", "id-internal": "276/5343", "id-external": ""}, "url": {"full": "URL#636155", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 132585767, "title": "DeHiDe - Deep Learning-based Hybrid Model to Detect Fake News using Blockchain.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Prashansa Agrawal", "id-internal": "276/6775", "id-external": ""}, {"name": "Parwat Singh Anjana", "id-internal": "207/5234", "id-external": ""}, {"name": "Sathya Peri", "id-internal": "41/5564", "id-external": ""}], "url": {"full": "URL#637616", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 651207044, "title": "CHECKED - Chinese COVID-19 Fake News Dataset.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Chen Yang", "id-internal": "01/2478", "id-external": ""}, {"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}], "url": {"full": "URL#637730", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3110356323, "title": "Towards Causal Understanding of Fake News Dissemination.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Lu Cheng", "id-internal": "17/4969", "id-external": ""}, {"name": "Ruocheng Guo", "id-internal": "167/4378", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#638409", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1533618027, "title": "Lexicon generation for detecting fake news.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Ugur Mertoglu Burkay Gen\u00e7", "id-internal": "277/0979", "id-external": ""}, "url": {"full": "URL#638651", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 880875385, "title": "Incorporating User-Comment Graph for Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Hao Liao", "id-internal": "74/1078", "id-external": ""}, {"name": "Qi-xin Liu", "id-internal": "254/2692", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Xing Xie", "id-internal": "08/6809", "id-external": ""}], "url": {"full": "URL#641788", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1620357638, "title": "Machine Generation and Detection of Arabic Manipulated and Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "El Moatez Billah Nagoudi", "id-internal": "201/3889", "id-external": ""}, {"name": "AbdelRahim A. Elmadany", "id-internal": "163/2207", "id-external": ""}, {"name": "Muhammad Abdul-Mageed", "id-internal": "49/9389", "id-external": ""}, {"name": "Tariq Alhindi", "id-internal": "165/6971", "id-external": ""}, {"name": "Hasan Cavusoglu", "id-internal": "72/899", "id-external": ""}], "url": {"full": "URL#642419", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2369458302, "title": "Fighting an Infodemic - COVID-19 Fake News Dataset.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Parth Patwa", "id-internal": "260/9345", "id-external": ""}, {"name": "Shivam Sharma", "id-internal": "146/2381", "id-external": ""}, {"name": "Srinivas PYKL", "id-internal": "168/6642", "id-external": ""}, {"name": "Vineeth Guptha", "id-internal": "266/0781", "id-external": ""}, {"name": "Gitanjali Kumari", "id-internal": "278/2631", "id-external": ""}, {"name": "Md. Shad Akhtar", "id-internal": "184/8579", "id-external": ""}, {"name": "Asif Ekbal", "id-internal": "11/3590", "id-external": ""}, {"name": "Amitava Das", "id-internal": "75/5002", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}], "url": {"full": "URL#642531", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2307350196, "title": "Competitive Influence Propagation and Fake News Mitigation in the Presence of Strong User Bias.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Akrati Saxena", "id-internal": "163/1823", "id-external": ""}, {"name": "Harsh Saxena", "id-internal": "261/1156", "id-external": ""}, {"name": "Ralucca Gera", "id-internal": "45/5825", "id-external": ""}], "url": {"full": "URL#643174", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1117728765, "title": "Words are the Window to the Soul - Language-based User Representations for Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Marco Del Tredici", "id-internal": "184/8927", "id-external": ""}, {"name": "Raquel Fern\u00e1ndez", "id-internal": "02/5384", "id-external": ""}], "url": {"full": "URL#644230", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 899289138, "title": "Detecting Fake News Spreaders in Social Networks using Inductive Representation Learning.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Bhavtosh Rath", "id-internal": "208/4861", "id-external": ""}, {"name": "Aadesh Salecha", "id-internal": "277/5089", "id-external": ""}, {"name": "Jaideep Srivastava", "id-internal": "s/JaideepSrivastava", "id-external": ""}], "url": {"full": "URL#645635", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1951346607, "title": "Two Stage Transformer Model for COVID-19 Fake News Detection and Fact Checking.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Rutvik Vijjali", "id-internal": "279/6203", "id-external": ""}, {"name": "Prathyush Potluri", "id-internal": "279/6254", "id-external": ""}, {"name": "Siddharth Kumar", "id-internal": "248/7787", "id-external": ""}, {"name": "Sundeep Teki", "id-internal": "157/5630", "id-external": ""}], "url": {"full": "URL#646629", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 869698894, "title": "An Event Correlation Filtering Method for Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Hao Li", "id-internal": "17/5705", "id-external": ""}, {"name": "Huan Wang", "id-internal": "70/6155", "id-external": ""}, {"name": "Guanghua Liu", "id-internal": "69/7813", "id-external": ""}], "url": {"full": "URL#649649", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3639570195, "title": "Fake News Detection in Social Media using Graph Neural Networks and NLP Techniques - A COVID-19 Use-case.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Abdullah Hamid", "id-internal": "155/8835", "id-external": ""}, {"name": "Nasrullah Sheikh", "id-internal": "211/3450", "id-external": ""}, {"name": "Naina Said", "id-internal": "232/1560", "id-external": ""}, {"name": "Kashif Ahmad", "id-internal": "150/4698", "id-external": ""}, {"name": "Asma Gul", "id-internal": "150/0164", "id-external": ""}, {"name": "Laiq Hassan", "id-internal": "252/6562", "id-external": ""}, {"name": "Ala I. Al-Fuqaha", "id-internal": "22/2131", "id-external": ""}], "url": {"full": "URL#650477", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3527442788, "title": "Exploring Thematic Coherence in Fake News.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Martins Samuel Dogo", "id-internal": "281/7011", "id-external": ""}, {"name": "Deepak P 0001", "id-internal": "33/1882", "id-external": ""}, {"name": "Anna Jurek-Loughrey", "id-internal": "45/8120", "id-external": ""}], "url": {"full": "URL#651089", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4007709638, "title": "Fake news agenda in the era of COVID-19 - Identifying trends through fact-checking content.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Wilson Ceron", "id-internal": "278/0576", "id-external": ""}, {"name": "Mathias-Felipe de-Lima-Santos", "id-internal": "281/7708", "id-external": ""}, {"name": "Marcos G. Quiles", "id-internal": "70/1985", "id-external": ""}], "url": {"full": "URL#651783", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2063986737, "title": "g2tmn at Constraint@AAAI2021 - Exploiting CT-BERT and Ensembling Learning for COVID-19 Fake News Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Anna Glazkova", "id-internal": "229/8527", "id-external": ""}, {"name": "Maksim Glazkov", "id-internal": "275/3767", "id-external": ""}, {"name": "Timofey Trifonov", "id-internal": "282/0099", "id-external": ""}], "url": {"full": "URL#652129", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1122867288, "title": "Fake News Data Collection and Classification - Iterative Query Selection for Opaque Search Engines with Pseudo Relevance Feedback.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Aviad Elyashar", "id-internal": "127/7256", "id-external": ""}, {"name": "Maor Reuben", "id-internal": "223/6115", "id-external": ""}, {"name": "Rami Puzis", "id-internal": "13/3098", "id-external": ""}], "url": {"full": "URL#652339", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2574691129, "title": "Detecting Fake News on Social Media", "abstract": "", "doi": "10.2200/s00926ed1v01y201906dmk018", "date": "2019", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#659405", "pdf": ""}, "publisher-venue": "Synthesis Lectures on Data Mining and Knowledge Discovery", "type": "Books and Theses", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1019210262, "title": "Fake News Identification and Classification Using DSSM and Improved Recurrent Neural Network Classifier.", "abstract": "", "doi": "10.1080/08839514.2019.1661579", "date": "2019", "authors": [{"name": "Shrutika S. Jadhav", "id-internal": "251/8674", "id-external": ""}, {"name": "Sudeep D. Thepade", "id-internal": "74/8327", "id-external": ""}], "url": {"full": "URL#659530", "pdf": ""}, "publisher-venue": "Appl. Artif. Intell.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2618944282, "title": "AI education matters - building a fake news detector.", "abstract": "", "doi": "10.1145/3362077.3362082", "date": "2019", "authors": [{"name": "Michael Guerzhoy", "id-internal": "64/7696", "id-external": ""}, {"name": "Lisa Zhang", "id-internal": "z/LisaZhang", "id-external": ""}, {"name": "Georgy Noarov", "id-internal": "229/4286", "id-external": ""}], "url": {"full": "URL#676904", "pdf": ""}, "publisher-venue": "AI Matters", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 147819483, "title": "Optimal structure of groups under exposure to fake news.", "abstract": "", "doi": "10.1007/s41109-019-0227-z", "date": "2019", "authors": [{"name": "Evelin Berekm\u00e9ri", "id-internal": "253/1401", "id-external": ""}, {"name": "Imre Der\u00e9nyi", "id-internal": "45/6033", "id-external": ""}, {"name": "Anna Zafeiris", "id-internal": "132/9324", "id-external": ""}], "url": {"full": "URL#679409", "pdf": ""}, "publisher-venue": "Appl. Netw. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3433179415, "title": "A response to fake news as a response to Citizens United.", "abstract": "", "doi": "10.1145/3341223", "date": "2019", "authors": {"name": "Marshall W. Van Alstyne", "id-internal": "31/2169", "id-external": ""}, "url": {"full": "URL#685995", "pdf": ""}, "publisher-venue": "Commun. ACM", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 859945483, "title": "About velocity and dealing with \"fake\" scientific news.", "abstract": "", "doi": "10.1145/3371934.3371945", "date": "2019", "authors": {"name": "Christophe Diot", "id-internal": "98/739", "id-external": ""}, "url": {"full": "URL#688949", "pdf": ""}, "publisher-venue": "Comput. Commun. Rev.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 291273436, "title": "\"This is fake news\" - Investigating the role of conformity to other users' views when commenting on and spreading disinformation in social media.", "abstract": "", "doi": "10.1016/j.chb.2019.03.032", "date": "2019", "authors": {"name": "Jonas Colliander", "id-internal": "201/4537", "id-external": ""}, "url": {"full": "URL#690864", "pdf": ""}, "publisher-venue": "Comput. Hum. Behav.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 565631838, "title": "Human-machine interaction - A case study on fake news detection using a backtracking based on a cognitive system.", "abstract": "", "doi": "10.1016/j.cogsys.2018.12.018", "date": "2019", "authors": [{"name": "Hoon Ko", "id-internal": "86/3832", "id-external": ""}, {"name": "Jong Youl Hong", "id-internal": "238/4705", "id-external": ""}, {"name": "Sangheon Kim", "id-internal": "28/6446", "id-external": ""}, {"name": "Libor Mesicek", "id-internal": "222/4669", "id-external": ""}, {"name": "In Seop Na", "id-internal": "35/11117", "id-external": ""}], "url": {"full": "URL#696113", "pdf": ""}, "publisher-venue": "Cogn. Syst. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1351393201, "title": "Detection and veracity analysis of fake news via scrapping and authenticating the web search.", "abstract": "", "doi": "10.1016/j.cogsys.2019.07.004", "date": "2019", "authors": [{"name": "Dinesh Kumar Vishwakarma", "id-internal": "214/0803", "id-external": ""}, {"name": "Deepika Varshney", "id-internal": "252/5523", "id-external": ""}, {"name": "Ashima Yadav", "id-internal": "252/4454", "id-external": ""}], "url": {"full": "URL#696174", "pdf": ""}, "publisher-venue": "Cogn. Syst. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1453729322, "title": "Cross-Domain Failures of Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Maria Janicka", "id-internal": "242/4672", "id-external": ""}, {"name": "Maria Pszona", "id-internal": "242/4612", "id-external": ""}, {"name": "Aleksander Wawer", "id-internal": "62/3540", "id-external": ""}], "url": {"full": "URL#701669", "pdf": ""}, "publisher-venue": "Computaci\u00f3n y Sistemas", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 826366534, "title": "Detecting fake news for reducing misinformation risks using analytics approaches.", "abstract": "", "doi": "10.1016/j.ejor.2019.06.022", "date": "2019", "authors": [{"name": "Chaowei Zhang", "id-internal": "188/1352", "id-external": ""}, {"name": "Ashish Gupta 0004", "id-internal": "27/4744-4", "id-external": ""}, {"name": "Christian Kauten", "id-internal": "246/4452", "id-external": ""}, {"name": "Amit V. Deokar", "id-internal": "35/4218", "id-external": ""}, {"name": "Xiao Qin 0001", "id-internal": "q/XiaoQin", "id-external": ""}], "url": {"full": "URL#708895", "pdf": ""}, "publisher-venue": "Eur. J. Oper. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3887141783, "title": "Behind the cues - A benchmarking study for fake news detection.", "abstract": "", "doi": "10.1016/j.eswa.2019.03.036", "date": "2019", "authors": [{"name": "Georgios Gravanis", "id-internal": "242/7112", "id-external": ""}, {"name": "Athena Vakali", "id-internal": "v/AthenaVakali", "id-external": ""}, {"name": "Konstantinos I. Diamantaras", "id-internal": "74/4220", "id-external": ""}, {"name": "Panagiotis Karadais", "id-internal": "242/7536", "id-external": ""}], "url": {"full": "URL#709535", "pdf": ""}, "publisher-venue": "Expert Syst. Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 81147540, "title": "Supervised Learning for Fake News Detection.", "abstract": "", "doi": "10.1109/mis.2019.2899143", "date": "2019", "authors": [{"name": "Julio C. S. Reis", "id-internal": "223/4293", "id-external": ""}, {"name": "Andr\u00e9 Correia", "id-internal": "60/4085", "id-external": ""}, {"name": "Fabricio Murai", "id-internal": "30/9221", "id-external": ""}, {"name": "Adriano Veloso", "id-internal": "12/919", "id-external": ""}, {"name": "Fabr\u00edcio Benevenuto", "id-internal": "90/2878", "id-external": ""}, {"name": "Erik Cambria", "id-internal": "80/7421", "id-external": ""}], "url": {"full": "URL#710621", "pdf": ""}, "publisher-venue": "IEEE Intell. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 467671408, "title": "Introduction to Series - Informing Science Perspectives on Fake News.", "abstract": "", "doi": "10.28945/4485", "date": "2019", "authors": {"name": "Eli Cohen", "id-internal": "13/4483", "id-external": ""}, "url": {"full": "URL#733059", "pdf": ""}, "publisher-venue": "Informing Sci. Int. J. an Emerg. Transdiscipl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4242992393, "title": "Building an Informing Science Model in Light of Fake News.", "abstract": "", "doi": "10.28945/4486", "date": "2019", "authors": {"name": "Eli Cohen", "id-internal": "13/4483", "id-external": ""}, "url": {"full": "URL#733060", "pdf": ""}, "publisher-venue": "Informing Sci. Int. J. an Emerg. Transdiscipl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1662235835, "title": "Fake News and Informing Science.", "abstract": "", "doi": "10.28945/4265", "date": "2019", "authors": {"name": "Grandon Gill", "id-internal": "31/5401", "id-external": ""}, "url": {"full": "URL#733063", "pdf": ""}, "publisher-venue": "Informing Sci. Int. J. an Emerg. Transdiscipl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 736887795, "title": "A survey on fake news and rumour detection techniques.", "abstract": "", "doi": "10.1016/j.ins.2019.05.035", "date": "2019", "authors": [{"name": "Alessandro Bondielli", "id-internal": "191/4078", "id-external": ""}, {"name": "Francesco Marcelloni", "id-internal": "38/2999", "id-external": ""}], "url": {"full": "URL#735760", "pdf": ""}, "publisher-venue": "Inf. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3075734682, "title": "FAGON - Fake News Detection Model Using Grammatical Transformation on Deep Neural Network.", "abstract": "", "doi": "10.3837/tiis.2019.10.008", "date": "2019", "authors": [{"name": "Youngkyung Seo", "id-internal": "245/6951", "id-external": ""}, {"name": "Seong-Soo Han", "id-internal": "252/8311", "id-external": ""}, {"name": "You-Boo Jeon", "id-internal": "145/4294", "id-external": ""}, {"name": "Chang-Sung Jeong", "id-internal": "58/1148", "id-external": ""}], "url": {"full": "URL#737523", "pdf": ""}, "publisher-venue": "KSII Trans. Internet Inf. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3264732228, "title": "Using Blockchain to Rein in the New Post-Truth World and Check the Spread of Fake News.", "abstract": "", "doi": "10.1109/mitp.2019.2910503", "date": "2019", "authors": [{"name": "Adnan Qayyum", "id-internal": "198/1509", "id-external": ""}, {"name": "Junaid Qadir 0001", "id-internal": "74/2204", "id-external": ""}, {"name": "Muhammad Umar Janjua", "id-internal": "63/5600", "id-external": ""}, {"name": "Falak Sher", "id-internal": "45/9126", "id-external": ""}], "url": {"full": "URL#737930", "pdf": ""}, "publisher-venue": "IT Prof.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3483936990, "title": "Scottish citizens' perceptions of the credibility of online political \"facts\" in the \"fake news\" era.", "abstract": "", "doi": "10.1108/jd-10-2018-0161", "date": "2019", "authors": [{"name": "Graeme Baxter", "id-internal": "72/10921", "id-external": ""}, {"name": "Rita Marcella", "id-internal": "49/4460", "id-external": ""}, {"name": "Agnieszka Walicka", "id-internal": "251/2933", "id-external": ""}], "url": {"full": "URL#744230", "pdf": ""}, "publisher-venue": "J. Documentation", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4246793512, "title": "User engagement with political \"facts\" in the context of the fake news phenomenon.", "abstract": "", "doi": "10.1108/jd-11-2018-0180", "date": "2019", "authors": [{"name": "Rita Marcella", "id-internal": "49/4460", "id-external": ""}, {"name": "Graeme Baxter", "id-internal": "72/10921", "id-external": ""}, {"name": "Agnieszka Walicka", "id-internal": "251/2933", "id-external": ""}], "url": {"full": "URL#744269", "pdf": ""}, "publisher-venue": "J. Documentation", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4073374095, "title": "Combining Similarity Features and Deep Representation Learning for Stance Detection in the Context of Checking Fake News.", "abstract": "", "doi": "10.1145/3287763", "date": "2019", "authors": [{"name": "Lu\u00eds Borges", "id-internal": "230/3717", "id-external": ""}, {"name": "Bruno Martins 0001", "id-internal": "m/BrunoMartins", "id-external": ""}, {"name": "P\u00e1vel Calado", "id-internal": "72/6044", "id-external": ""}], "url": {"full": "URL#744457", "pdf": ""}, "publisher-venue": "ACM J. Data Inf. Qual.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3797313045, "title": "Detection of fake news in a new corpus for the Spanish language.", "abstract": "", "doi": "10.3233/jifs-179034", "date": "2019", "authors": [{"name": "Juan Pablo Posadas-Dur\u00e1n", "id-internal": "83/10505", "id-external": ""}, {"name": "Helena G\u00f3mez-Adorno", "id-internal": "117/2917", "id-external": ""}, {"name": "Grigori Sidorov", "id-internal": "68/4195", "id-external": ""}, {"name": "Jes\u00fas Jaime Moreno Escobar", "id-internal": "37/792", "id-external": ""}], "url": {"full": "URL#747048", "pdf": ""}, "publisher-venue": "J. Intell. Fuzzy Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 366227665, "title": "Fake News Detection Using Deep Learning.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Dong-Ho Lee", "id-internal": "69/3962", "id-external": ""}, {"name": "Yu-Ri Kim", "id-internal": "253/5762", "id-external": ""}, {"name": "Hyeong-Jun Kim", "id-internal": "10/6506", "id-external": ""}, {"name": "Seung-Myun Park", "id-internal": "253/5626", "id-external": ""}, {"name": "Yu-Jun Yang", "id-internal": "253/5415", "id-external": ""}], "url": {"full": "URL#748174", "pdf": ""}, "publisher-venue": "J. Inf. Process. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1720123425, "title": "Combating Fake News on Social Media with Source Ratings - The Effects of User and Expert Reputation Ratings.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Antino Kim", "id-internal": "117/0007", "id-external": ""}, {"name": "Patricia L. Moravec", "id-internal": "231/0732", "id-external": ""}, {"name": "Alan R. Dennis", "id-internal": "28/6832", "id-external": ""}], "url": {"full": "URL#749491", "pdf": ""}, "publisher-venue": "J. Manag. Inf. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1302899262, "title": "Why librarians can't fight fake news.", "abstract": "", "doi": "10.1177/0961000618764258", "date": "2019", "authors": {"name": "M. Connor Sullivan", "id-internal": "251/7348", "id-external": ""}, "url": {"full": "URL#751276", "pdf": ""}, "publisher-venue": "J. Libr. Inf. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1439925318, "title": "Says Who? The Effects of Presentation Format and Source Rating on Fake News in Social Media.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Antino Kim", "id-internal": "117/0007", "id-external": ""}, {"name": "Alan R. Dennis", "id-internal": "28/6832", "id-external": ""}], "url": {"full": "URL#760076", "pdf": ""}, "publisher-venue": "MIS Q.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2934673113, "title": "Fake News on Social Media - People Believe What They Want to Believe When it Makes No Sense At All.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Patricia L. Moravec", "id-internal": "231/0732", "id-external": ""}, {"name": "Randall K. Minas", "id-internal": "91/11057", "id-external": ""}, {"name": "Alan R. Dennis", "id-internal": "28/6832", "id-external": ""}], "url": {"full": "URL#760091", "pdf": ""}, "publisher-venue": "MIS Q.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4121051239, "title": "\"Thank god for Deadspin\" - Interlopers, metajournalistic commentary, and fake news through the lens of \"journalistic realization\".", "abstract": "", "doi": "10.1177/1461444818809461", "date": "2019", "authors": {"name": "Scott A. Eldridge II", "id-internal": "239/6335", "id-external": ""}, "url": {"full": "URL#766737", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1037562355, "title": "\"Lots of Questions about 'Fake News'\" - How Public Libraries Have Addressed Media Literacy, 2016-2018.", "abstract": "", "doi": "10.1080/01616846.2019.1600391", "date": "2019", "authors": [{"name": "Suzanne S. Lapierre", "id-internal": "260/2400", "id-external": ""}, {"name": "Vanessa Kitzie", "id-internal": "119/5797", "id-external": ""}], "url": {"full": "URL#770534", "pdf": ""}, "publisher-venue": "Public Libr. Q.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1774608281, "title": "Combating Fake News - A Data Management and Mining Perspective.", "abstract": "", "doi": "10.14778/3352063.3352117", "date": "2019", "authors": [{"name": "Laks V. S. Lakshmanan", "id-internal": "l/LVSLakshmanan", "id-external": ""}, {"name": "Michael Simpson", "id-internal": "150/6218", "id-external": ""}, {"name": "Saravanan Thirumuruganathan", "id-internal": "57/10514", "id-external": ""}], "url": {"full": "URL#772122", "pdf": ""}, "publisher-venue": "Proc. VLDB Endow.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3449228782, "title": "Network-based Fake News Detection - A Pattern-driven Approach.", "abstract": "", "doi": "10.1145/3373464.3373473", "date": "2019", "authors": [{"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}], "url": {"full": "URL#787061", "pdf": ""}, "publisher-venue": "SIGKDD Explor.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2933210263, "title": "Understanding archetypes of fake news via fine-grained classification.", "abstract": "", "doi": "10.1007/s13278-019-0580-z", "date": "2019", "authors": [{"name": "Liqiang Wang", "id-internal": "02/3331", "id-external": ""}, {"name": "Yafang Wang", "id-internal": "68/6229", "id-external": ""}, {"name": "Gerard de Melo", "id-internal": "86/1747", "id-external": ""}, {"name": "Gerhard Weikum", "id-internal": "w/GerhardWeikum", "id-external": ""}], "url": {"full": "URL#788696", "pdf": ""}, "publisher-venue": "Soc. Netw. Anal. Min.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1371525759, "title": "Combating Fake News - A Survey on Identification and Mitigation Techniques.", "abstract": "", "doi": "10.1145/3305260", "date": "2019", "authors": [{"name": "Karishma Sharma", "id-internal": "222/7902", "id-external": ""}, {"name": "Feng Qian", "id-internal": "54/476", "id-external": ""}, {"name": "He Jiang", "id-internal": "30/3790", "id-external": ""}, {"name": "Natali Ruchansky", "id-internal": "12/9876", "id-external": ""}, {"name": "Ming Zhang 0004", "id-internal": "73/1844-4", "id-external": ""}, {"name": "Yan Liu 0002", "id-internal": "l/YanLiu2", "id-external": ""}], "url": {"full": "URL#805555", "pdf": ""}, "publisher-venue": "ACM Trans. Intell. Syst. Technol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2649939272, "title": "Polarization and Fake News - Early Warning of Potential Misinformation Targets.", "abstract": "", "doi": "10.1145/3316809", "date": "2019", "authors": [{"name": "Michela Del Vicario", "id-internal": "151/6677", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}, {"name": "Antonio Scala", "id-internal": "92/9669", "id-external": ""}, {"name": "Fabiana Zollo", "id-internal": "60/9927", "id-external": ""}], "url": {"full": "URL#814448", "pdf": ""}, "publisher-venue": "ACM Trans. Web", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 547440902, "title": "SocialTruth Project Approach to Online Disinformation (Fake News) Detection and Mitigation.", "abstract": "", "doi": "10.1145/3339252.3341497", "date": "2019", "authors": [{"name": "Michal Choras", "id-internal": "06/2936", "id-external": ""}, {"name": "Marek Pawlicki", "id-internal": "224/4630", "id-external": ""}, {"name": "Rafal Kozik", "id-internal": "80/2851", "id-external": ""}, {"name": "Konstantinos P. Demestichas", "id-internal": "37/872", "id-external": ""}, {"name": "Pavlos Kosmides", "id-internal": "68/11261", "id-external": ""}, {"name": "Manik Gupta", "id-internal": "22/10701", "id-external": ""}], "url": {"full": "URL#818634", "pdf": ""}, "publisher-venue": "ARES", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1746567682, "title": "Fake News Detection by Image Montage Recognition.", "abstract": "", "doi": "10.1145/3339252.3341487", "date": "2019", "authors": [{"name": "Martin Steinebach", "id-internal": "s/MartinSteinebach", "id-external": ""}, {"name": "Karol Gotkowski", "id-internal": "246/5696", "id-external": ""}, {"name": "Hujian Liu", "id-internal": "246/5718", "id-external": ""}], "url": {"full": "URL#818698", "pdf": ""}, "publisher-venue": "ARES", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 476692461, "title": "Unsupervised Fake News Detection on Social Media - A Generative Approach.", "abstract": "", "doi": "10.1609/aaai.v33i01.33015644", "date": "2019", "authors": [{"name": "Shuo Yang 0001", "id-internal": "78/1102-1", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Renjie Gu", "id-internal": "245/3316", "id-external": ""}, {"name": "Fan Wu 0006", "id-internal": "07/6378-6", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#820442", "pdf": ""}, "publisher-venue": "AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1784736587, "title": "Combining Machine Learning with Knowledge Engineering to detect Fake News in Social Networks - A Survey.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Knut Hinkelmann", "id-internal": "50/1728", "id-external": ""}, {"name": "Sajjad Ahmed", "id-internal": "239/6712", "id-external": ""}, {"name": "Flavio Corradini", "id-internal": "00/6390", "id-external": ""}], "url": {"full": "URL#820630", "pdf": ""}, "publisher-venue": "AAAI Spring Symposium - Combining Machine Learning with Knowledge Engineering", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1320802986, "title": "BREAKING! Presenting Fake News Corpus for Automated Fact Checking.", "abstract": "", "doi": "10.18653/v1/p19-2050", "date": "2019", "authors": [{"name": "Archita Pathak", "id-internal": "245/8637", "id-external": ""}, {"name": "Rohini K. Srihari", "id-internal": "59/6877", "id-external": ""}], "url": {"full": "URL#821948", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2286576406, "title": "Rhetoric Mining for Fake News - Identifying Moves of Persuasion and Disinformation.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Michelle M. H. Seref", "id-internal": "50/9721", "id-external": ""}, {"name": "Onur Seref", "id-internal": "97/262", "id-external": ""}], "url": {"full": "URL#828510", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1035141438, "title": "Smart and Blissful? Exploring the Characteristics of Individuals That Share Fake News on Social Networking Sites.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Eric Villafranca", "id-internal": "228/2250", "id-external": ""}, {"name": "Uchenna Peters", "id-internal": "200/1619", "id-external": ""}], "url": {"full": "URL#828576", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3684485276, "title": "Gradual Argumentation Evaluation for Stance Aggregation in Automated Fake News Detection.", "abstract": "", "doi": "10.18653/v1/w19-4518", "date": "2019", "authors": [{"name": "Neema Kotonya", "id-internal": "218/5785", "id-external": ""}, {"name": "Francesca Toni", "id-internal": "t/FrancescaToni", "id-external": ""}], "url": {"full": "URL#831110", "pdf": ""}, "publisher-venue": "ArgMining@ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3687506755, "title": "Semi-supervised learning and graph neural networks for fake news detection.", "abstract": "", "doi": "10.1145/3341161.3342958", "date": "2019", "authors": [{"name": "Adrien Benamira", "id-internal": "256/6147", "id-external": ""}, {"name": "Benjamin Devillers", "id-internal": "256/6134", "id-external": ""}, {"name": "Etienne Lesot", "id-internal": "256/6159", "id-external": ""}, {"name": "Ayush K. Ray", "id-internal": "256/6183", "id-external": ""}, {"name": "Manal Saadi", "id-internal": "256/6172", "id-external": ""}, {"name": "Fragkiskos D. Malliaros", "id-internal": "22/9458", "id-external": ""}], "url": {"full": "URL#832728", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1356058729, "title": "SAME - sentiment-aware multi-modal embedding for detecting fake news.", "abstract": "", "doi": "10.1145/3341161.3342894", "date": "2019", "authors": [{"name": "Limeng Cui", "id-internal": "147/6826", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}], "url": {"full": "URL#832752", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3743955672, "title": "Evaluating vulnerability to fake news in social networks - a community health assessment model.", "abstract": "", "doi": "10.1145/3341161.3342920", "date": "2019", "authors": [{"name": "Bhavtosh Rath", "id-internal": "208/4861", "id-external": ""}, {"name": "Wei Gao 0001", "id-internal": "28/2073-1", "id-external": ""}, {"name": "Jaideep Srivastava", "id-internal": "s/JaideepSrivastava", "id-external": ""}], "url": {"full": "URL#832849", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1450132906, "title": "The role of user profiles for fake news detection.", "abstract": "", "doi": "10.1145/3341161.3342927", "date": "2019", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#832861", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 304766716, "title": "How Does Fake News Spread - Raising Awareness & Educating the Public with a Simulation Tool.", "abstract": "", "doi": "10.1109/bigdata47090.2019.9005953", "date": "2019", "authors": [{"name": "Cheng L. Lee", "id-internal": "259/7055", "id-external": ""}, {"name": "Joel-David J. J. Wong", "id-internal": "259/7331", "id-external": ""}, {"name": "Zi Y. Lim", "id-internal": "259/6906", "id-external": ""}, {"name": "Belinda S. T. Tho", "id-internal": "259/6164", "id-external": ""}, {"name": "Sean S. W. Kwek", "id-internal": "259/6570", "id-external": ""}, {"name": "Kyong Jin Shim", "id-internal": "91/1390", "id-external": ""}], "url": {"full": "URL#836307", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1658961636, "title": "Detecting Fake News Articles.", "abstract": "", "doi": "10.1109/bigdata47090.2019.9005980", "date": "2019", "authors": [{"name": "Jun Lin", "id-internal": "55/1226", "id-external": ""}, {"name": "Glenna Tremblay-Taylor", "id-internal": "259/6432", "id-external": ""}, {"name": "Guanyi Mou", "id-internal": "259/7191", "id-external": ""}, {"name": "Di You", "id-internal": "83/8652", "id-external": ""}, {"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}], "url": {"full": "URL#836332", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2754159923, "title": "A Location Independent Machine Learning Approach for Early Fake News Detection.", "abstract": "", "doi": "10.1109/bigdata47090.2019.9005962", "date": "2019", "authors": {"name": "Haohui Liu", "id-internal": "259/7348", "id-external": ""}, "url": {"full": "URL#836335", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 502910547, "title": "RecANt - Network-based Recruitment for Active Fake News Correction.", "abstract": "", "doi": "10.1109/bigdata47090.2019.9005592", "date": "2019", "authors": [{"name": "Ajitesh Srivastava", "id-internal": "77/9528", "id-external": ""}, {"name": "Rajgopal Kannan", "id-internal": "66/2538", "id-external": ""}, {"name": "Charalampos Chelmis", "id-internal": "72/7698", "id-external": ""}, {"name": "Viktor K. Prasanna", "id-internal": "p/ViktorKPrasanna", "id-external": ""}], "url": {"full": "URL#836563", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1971085459, "title": "Deep Diffusive Neural Network based Fake News Detection from Heterogeneous Social Networks.", "abstract": "", "doi": "10.1109/bigdata47090.2019.9005556", "date": "2019", "authors": [{"name": "Jiawei Zhang 0001", "id-internal": "10/239-1", "id-external": ""}, {"name": "Bowen Dong", "id-internal": "173/4607", "id-external": ""}, {"name": "Philip S. Yu", "id-internal": "y/PhilipSYu", "id-external": ""}], "url": {"full": "URL#836721", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1978153395, "title": "SpotFake - A Multi-modal Framework for Fake News Detection.", "abstract": "", "doi": "10.1109/bigmm.2019.00-44", "date": "2019", "authors": [{"name": "Shivangi Singhal", "id-internal": "218/0755", "id-external": ""}, {"name": "Rajiv Ratn Shah", "id-internal": "134/3502", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}, {"name": "Ponnurangam Kumaraguru", "id-internal": "97/5147", "id-external": ""}, {"name": "Shin'ichi Satoh 0001", "id-internal": "50/290", "id-external": ""}], "url": {"full": "URL#836903", "pdf": ""}, "publisher-venue": "BigMM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3731881239, "title": "Fake News Detection Using One-Class Classification.", "abstract": "", "doi": "10.1109/bracis.2019.00109", "date": "2019", "authors": [{"name": "Pedro Faustini", "id-internal": "155/4367", "id-external": ""}, {"name": "Thiago Ferreira Cov\u00f5es", "id-internal": "202/6212", "id-external": ""}], "url": {"full": "URL#839169", "pdf": ""}, "publisher-venue": "BRACIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 60744899, "title": "Brazilian Presidential Elections in the Era of Misinformation - A Machine Learning Approach to Analyse Fake News.", "abstract": "", "doi": "10.1007/978-3-030-33904-3_7", "date": "2019", "authors": [{"name": "Jairo L. Alves", "id-internal": "251/6194", "id-external": ""}, {"name": "Leila Weitzel", "id-internal": "19/11233", "id-external": ""}, {"name": "Paulo Quaresma", "id-internal": "73/4272", "id-external": ""}, {"name": "Carlos E. Cardoso", "id-internal": "251/6165", "id-external": ""}, {"name": "Luan Cunha", "id-internal": "251/6073", "id-external": ""}], "url": {"full": "URL#847091", "pdf": ""}, "publisher-venue": "CIARP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1106958719, "title": "dEFEND - A System for Explainable Fake News Detection.", "abstract": "", "doi": "10.1145/3357384.3357862", "date": "2019", "authors": [{"name": "Limeng Cui", "id-internal": "147/6826", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#847774", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 11123544, "title": "Evaluation of the Existing Tools for Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-28957-7_13", "date": "2019", "authors": [{"name": "Agata Gielczyk", "id-internal": "226/5062", "id-external": ""}, {"name": "Rafal Wawrzyniak", "id-internal": "200/6330", "id-external": ""}, {"name": "Michal Choras", "id-internal": "06/2936", "id-external": ""}], "url": {"full": "URL#848585", "pdf": ""}, "publisher-venue": "CISIM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3329849204, "title": "Fighting Fake News Propagation with Blockchains.", "abstract": "", "doi": "10.1109/cns.2019.8802670", "date": "2019", "authors": [{"name": "Muhammad Saad", "id-internal": "181/5807", "id-external": ""}, {"name": "Ashar Ahmad", "id-internal": "209/7462", "id-external": ""}, {"name": "Aziz Mohaisen", "id-internal": "70/2832", "id-external": ""}], "url": {"full": "URL#850192", "pdf": ""}, "publisher-venue": "CNS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1838214562, "title": "Media Literacy Training Against Fake News in Online Media.", "abstract": "", "doi": "10.1007/978-3-030-29736-7_67", "date": "2019", "authors": [{"name": "Christian Scheibenzuber", "id-internal": "248/5118", "id-external": ""}, {"name": "Nicolae Nistor", "id-internal": "14/2140", "id-external": ""}], "url": {"full": "URL#864454", "pdf": ""}, "publisher-venue": "EC-TEL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1951424989, "title": "Can EU Data Protection Legislation Help to Counter \"Fake News\" and Other Threats to Democracy?", "abstract": "", "doi": "10.1007/978-3-030-37545-4_15", "date": "2019", "authors": {"name": "Yordanka Ivanova", "id-internal": "242/5056", "id-external": ""}, "url": {"full": "URL#864651", "pdf": ""}, "publisher-venue": "e-Democracy", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3438515318, "title": "Different Absorption from the Same Sharing - Sifted Multi-task Learning for Fake News Detection.", "abstract": "", "doi": "10.18653/v1/d19-1471", "date": "2019", "authors": [{"name": "Lianwei Wu", "id-internal": "214/2499", "id-external": ""}, {"name": "Yuan Rao", "id-internal": "73/4103", "id-external": ""}, {"name": "Haolin Jin", "id-internal": "207/8891", "id-external": ""}, {"name": "Ambreen Nazir", "id-internal": "226/6984", "id-external": ""}, {"name": "Ling Sun 0004", "id-internal": "08/6547-4", "id-external": ""}], "url": {"full": "URL#868521", "pdf": ""}, "publisher-venue": "EMNLP/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3578386835, "title": "Fake News Detection with the New German Dataset \"GermanFakeNC\".", "abstract": "", "doi": "10.1007/978-3-030-30760-8_25", "date": "2019", "authors": [{"name": "Inna Vogel", "id-internal": "216/7232", "id-external": ""}, {"name": "Peter Jiang", "id-internal": "245/4393", "id-external": ""}], "url": {"full": "URL#869299", "pdf": ""}, "publisher-venue": "TPDL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1848899075, "title": "From Belief in Conspiracy Theories to Trust in Others - Which Factors Influence Exposure, Believing and Sharing Fake News.", "abstract": "", "doi": "10.1007/978-3-030-21902-4_16", "date": "2019", "authors": [{"name": "Daniel Halpern 0001", "id-internal": "83/5135-1", "id-external": ""}, {"name": "Sebasti\u00e1n Valenzuela", "id-internal": "36/8834", "id-external": ""}, {"name": "James E. Katz", "id-internal": "83/4073", "id-external": ""}, {"name": "Juan Pablo Miranda", "id-internal": "244/6192", "id-external": ""}], "url": {"full": "URL#881834", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3479048063, "title": "Toward Automatic Fake News Classification.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Souvick Ghosh", "id-internal": "167/4892", "id-external": ""}, {"name": "Chirag Shah", "id-internal": "04/4087", "id-external": ""}], "url": {"full": "URL#883374", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2781278153, "title": "Do You Really Know If It's True? How Asking Users to Rate Stories Affects Belief in Fake News on Social Media.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Patricia L. Moravec", "id-internal": "231/0732", "id-external": ""}, {"name": "Antino Kim", "id-internal": "117/0007", "id-external": ""}, {"name": "Alan R. Dennis", "id-internal": "28/6832", "id-external": ""}, {"name": "Randall K. Minas", "id-internal": "91/11057", "id-external": ""}], "url": {"full": "URL#883644", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3505516569, "title": "Creating Task-Generic Features for Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Alex C. Olivieri", "id-internal": "129/2358", "id-external": ""}, {"name": "Shaban Shabani", "id-internal": "185/3554", "id-external": ""}, {"name": "Maria Sokhn", "id-internal": "52/7093", "id-external": ""}, {"name": "Philippe Cudr\u00e9-Mauroux", "id-internal": "71/5578", "id-external": ""}], "url": {"full": "URL#883677", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3199915426, "title": "Can Machines Learn to Detect Fake News? A Survey Focused on Social Media.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Fernando Cardoso Durier da Silva", "id-internal": "238/5022", "id-external": ""}, {"name": "Rafael Vieira", "id-internal": "146/9095", "id-external": ""}, {"name": "Ana Cristina Bicharra Garcia", "id-internal": "45/6671", "id-external": ""}], "url": {"full": "URL#883836", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4189083945, "title": "Stacking-Based Ensemble Learning on Low Dimensional Features for Fake News Detection.", "abstract": "", "doi": "10.1109/hpcc/smartcity/dss.2019.00383", "date": "2019", "authors": [{"name": "Songqian Li", "id-internal": "246/8800", "id-external": ""}, {"name": "Kun Ma", "id-internal": "97/143", "id-external": ""}, {"name": "Xuewei Niu", "id-internal": "221/8163", "id-external": ""}, {"name": "Yufeng Wang", "id-internal": "90/6339", "id-external": ""}, {"name": "Ke Ji", "id-internal": "145/1166", "id-external": ""}, {"name": "Ziqiang Yu", "id-internal": "50/10486", "id-external": ""}, {"name": "Zhenxiang Chen", "id-internal": "36/6342", "id-external": ""}], "url": {"full": "URL#884671", "pdf": ""}, "publisher-venue": "HPCC/SmartCity/DSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3896260300, "title": "How Dependable are \"First Impressions\" to Distinguish between Real and Fake NewsWebsites?", "abstract": "", "doi": "10.1145/3342220.3343670", "date": "2019", "authors": [{"name": "Dongchen Huang", "id-internal": "248/8821", "id-external": ""}, {"name": "Yige Zhu", "id-internal": "248/8827", "id-external": ""}, {"name": "Eni Mustafaraj", "id-internal": "97/592", "id-external": ""}], "url": {"full": "URL#885403", "pdf": ""}, "publisher-venue": "HT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1735706644, "title": "Fake News Reading on Social Media - An Eye-tracking Study.", "abstract": "", "doi": "10.1145/3342220.3343642", "date": "2019", "authors": [{"name": "Jakub Simko", "id-internal": "09/8578", "id-external": ""}, {"name": "Martina Hanakova", "id-internal": "248/8866", "id-external": ""}, {"name": "Patrik Racsko", "id-internal": "248/8799", "id-external": ""}, {"name": "Mat\u00fas Tomlein", "id-internal": "148/1345", "id-external": ""}, {"name": "R\u00f3bert M\u00f3ro", "id-internal": "13/10717", "id-external": ""}, {"name": "M\u00e1ria Bielikov\u00e1", "id-internal": "b/MariaBielikova", "id-external": ""}], "url": {"full": "URL#885439", "pdf": ""}, "publisher-venue": "HT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 358347309, "title": "Fake News Detection Using Sentiment Analysis.", "abstract": "", "doi": "10.1109/ic3.2019.8844880", "date": "2019", "authors": [{"name": "Bhavika Bhutani", "id-internal": "249/4450", "id-external": ""}, {"name": "Neha Rastogi", "id-internal": "209/2084", "id-external": ""}, {"name": "Priyanshu Sehgal", "id-internal": "249/4630", "id-external": ""}, {"name": "Archana Purwar", "id-internal": "22/7797", "id-external": ""}], "url": {"full": "URL#887096", "pdf": ""}, "publisher-venue": "IC3", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1102730312, "title": "FIND - Fake Information and News Detections using Deep Learning.", "abstract": "", "doi": "10.1109/ic3.2019.8844892", "date": "2019", "authors": [{"name": "Abhishek Verma", "id-internal": "54/3512", "id-external": ""}, {"name": "Vanshika Mittal", "id-internal": "249/4751", "id-external": ""}, {"name": "Suma Dawn", "id-internal": "86/8237", "id-external": ""}], "url": {"full": "URL#887149", "pdf": ""}, "publisher-venue": "IC3", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 765577614, "title": "A Closer Look at Fake News Detection - A Deep Learning Perspective.", "abstract": "", "doi": "10.1145/3369114.3369149", "date": "2019", "authors": [{"name": "Ayat Abedalla", "id-internal": "255/2960", "id-external": ""}, {"name": "Aisha Al-Sadi", "id-internal": "228/7981", "id-external": ""}, {"name": "Malak Abdullah", "id-internal": "32/9695", "id-external": ""}], "url": {"full": "URL#887525", "pdf": ""}, "publisher-venue": "ICAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1804985250, "title": "An Arabic Corpus of Fake News - Collection, Analysis and Classification.", "abstract": "", "doi": "10.1007/978-3-030-32959-4_21", "date": "2019", "authors": [{"name": "Maysoon Alkhair", "id-internal": "250/0121", "id-external": ""}, {"name": "Karima Meftouh", "id-internal": "34/1861", "id-external": ""}, {"name": "Kamel Sma\u00efli", "id-internal": "79/4349", "id-external": ""}, {"name": "Nouha Othman", "id-internal": "174/6756", "id-external": ""}], "url": {"full": "URL#888508", "pdf": ""}, "publisher-venue": "ICALP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1336015726, "title": "Sentiment Aware Fake News Detection on Online Social Networks.", "abstract": "", "doi": "10.1109/icassp.2019.8683170", "date": "2019", "authors": [{"name": "Oluwaseun Ajao", "id-internal": "173/0924", "id-external": ""}, {"name": "Deepayan Bhowmik", "id-internal": "44/7616", "id-external": ""}, {"name": "Shahrzad Zargari", "id-internal": "122/8657", "id-external": ""}], "url": {"full": "URL#889375", "pdf": ""}, "publisher-venue": "ICASSP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1226276693, "title": "Learning Contextual Features with Multi-head Self-attention for Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-23407-2_11", "date": "2019", "authors": [{"name": "Yangqian Wang", "id-internal": "243/1942", "id-external": ""}, {"name": "Hao Han", "id-internal": "73/1570", "id-external": ""}, {"name": "Ye Ding", "id-internal": "17/4099", "id-external": ""}, {"name": "Xuan Wang 0002", "id-internal": "34/4799-2", "id-external": ""}, {"name": "Qing Liao 0001", "id-internal": "09/8600-1", "id-external": ""}], "url": {"full": "URL#893746", "pdf": ""}, "publisher-venue": "ICCC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2242597331, "title": "Bidirectional LSTM Based on POS tags and CNN Architecture for Fake News Detection.", "abstract": "", "doi": "10.1109/icccnt45670.2019.8944460", "date": "2019", "authors": {"name": "Manoj Kumar Balwant", "id-internal": "217/4997", "id-external": ""}, "url": {"full": "URL#894237", "pdf": ""}, "publisher-venue": "ICCCNT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2505748471, "title": "Exploiting Multi-domain Visual Information for Fake News Detection.", "abstract": "", "doi": "10.1109/icdm.2019.00062", "date": "2019", "authors": [{"name": "Peng Qi 0005", "id-internal": "59/9474-5", "id-external": ""}, {"name": "Juan Cao", "id-internal": "75/2820", "id-external": ""}, {"name": "Tianyun Yang", "id-internal": "189/3221", "id-external": ""}, {"name": "Junbo Guo", "id-internal": "33/4618", "id-external": ""}, {"name": "Jintao Li 0001", "id-internal": "l/JintaoLi-1", "id-external": ""}], "url": {"full": "URL#900135", "pdf": ""}, "publisher-venue": "ICDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4080614463, "title": "Fake News Detection in Social Networks Using Machine Learning and Deep Learning - Performance Evaluation.", "abstract": "", "doi": "10.1109/icii.2019.00070", "date": "2019", "authors": [{"name": "Wenlin Han", "id-internal": "07/9818", "id-external": ""}, {"name": "Varshil Mehta", "id-internal": "266/0044", "id-external": ""}], "url": {"full": "URL#903141", "pdf": ""}, "publisher-venue": "ICII", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1018900962, "title": "The Tangled Web - Studying Online Fake News.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Jean-Gregoire Bernard", "id-internal": "56/10952", "id-external": ""}, {"name": "Alan R. Dennis", "id-internal": "28/6832", "id-external": ""}, {"name": "Dennis F. Galletta", "id-internal": "g/DennisFGalletta", "id-external": ""}, {"name": "Ali Khan", "id-internal": "29/4613", "id-external": ""}, {"name": "Jane Webster", "id-internal": "42/4852", "id-external": ""}], "url": {"full": "URL#905024", "pdf": ""}, "publisher-venue": "ICIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1229215330, "title": "Fake News Flags, Cognitive Dissonance, and the Believability of Social Media Posts.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Kathrin Figl", "id-internal": "13/1231", "id-external": ""}, {"name": "Samuel Kie\u00dfling", "id-internal": "254/7207", "id-external": ""}, {"name": "Christiane Rank", "id-internal": "254/7126", "id-external": ""}, {"name": "Svitlana Vakulenko", "id-internal": "132/4990", "id-external": ""}], "url": {"full": "URL#905083", "pdf": ""}, "publisher-venue": "ICIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3127483010, "title": "Analysis of Fake News and the Level of Cognitive Perception of Undergraduate Students in the University in Thailand.", "abstract": "", "doi": "10.1007/978-3-030-35343-8_80", "date": "2019", "authors": {"name": "Chantana Viriyavejakul", "id-internal": "203/0597", "id-external": ""}, "url": {"full": "URL#906459", "pdf": ""}, "publisher-venue": "ICITL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 423394677, "title": "SADHAN - Hierarchical Attention Networks to Learn Latent Aspect Embeddings for Fake News Detection.", "abstract": "", "doi": "10.1145/3341981.3344229", "date": "2019", "authors": [{"name": "Rahul Mishra", "id-internal": "66/9553", "id-external": ""}, {"name": "Vinay Setty", "id-internal": "36/8510", "id-external": ""}], "url": {"full": "URL#916285", "pdf": ""}, "publisher-venue": "ICTIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4089713031, "title": "FA-KES - A Fake News Dataset around the Syrian War.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Fatima K. Abu Salem", "id-internal": "68/2576", "id-external": ""}, {"name": "Roaa Al Feel", "id-internal": "242/9510", "id-external": ""}, {"name": "Shady Elbassuoni", "id-internal": "82/4089", "id-external": ""}, {"name": "Mohamad Jaber 0001", "id-internal": "j/MohamadJaber", "id-external": ""}, {"name": "May Farah", "id-internal": "242/9512", "id-external": ""}], "url": {"full": "URL#917626", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3721592173, "title": "Automatic Ground Truth Dataset Creation for Fake News Detection in Social Media.", "abstract": "", "doi": "10.1007/978-3-030-33607-3_46", "date": "2019", "authors": [{"name": "Danae Pla Karidi", "id-internal": "181/9145", "id-external": ""}, {"name": "Harry Nakos", "id-internal": "252/2228", "id-external": ""}, {"name": "Yannis Stavrakas", "id-internal": "62/1193", "id-external": ""}], "url": {"full": "URL#918141", "pdf": ""}, "publisher-venue": "IDEAL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 276716294, "title": "Machine Learning Methods for Fake News Classification.", "abstract": "", "doi": "10.1007/978-3-030-33617-2_34", "date": "2019", "authors": [{"name": "Pawel Ksieniewicz", "id-internal": "145/6756", "id-external": ""}, {"name": "Michal Choras", "id-internal": "06/2936", "id-external": ""}, {"name": "Rafal Kozik", "id-internal": "80/2851", "id-external": ""}, {"name": "Michal Wozniak 0001", "id-internal": "37/5714-1", "id-external": ""}], "url": {"full": "URL#918146", "pdf": ""}, "publisher-venue": "IDEAL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3725485498, "title": "Authenticating Fake News - An Empirical Study in India.", "abstract": "", "doi": "10.1007/978-3-030-20671-0_23", "date": "2019", "authors": [{"name": "Gautam Prakash", "id-internal": "242/6326", "id-external": ""}, {"name": "Ravinder Kumar Verma", "id-internal": "217/4911", "id-external": ""}, {"name": "P. Vigneswara Ilavarasan", "id-internal": "86/1216", "id-external": ""}, {"name": "Arpan Kumar Kar", "id-internal": "96/9189", "id-external": ""}], "url": {"full": "URL#920547", "pdf": ""}, "publisher-venue": "TDIT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1688399049, "title": "Huge Oil Spill in the Desert - Fake News or Reality? The Remote Sensing Perspective.", "abstract": "", "doi": "10.1109/igarss.2019.8899028", "date": "2019", "authors": {"name": "Dominique Dubucq", "id-internal": "171/0235", "id-external": ""}, "url": {"full": "URL#921214", "pdf": ""}, "publisher-venue": "IGARSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3840901007, "title": "Fake News Classification Based on Subjective Language.", "abstract": "", "doi": "10.1145/3366030.3366039", "date": "2019", "authors": [{"name": "Caio Lib\u00e2nio Melo Jer\u00f4nimo", "id-internal": "172/7675", "id-external": ""}, {"name": "Leandro Balby Marinho", "id-internal": "59/4973", "id-external": ""}, {"name": "Cl\u00e1udio E. C. Campelo", "id-internal": "77/3901", "id-external": ""}, {"name": "Adriano Veloso", "id-internal": "12/919", "id-external": ""}, {"name": "Allan Sales da Costa Melo", "id-internal": "207/6979", "id-external": ""}], "url": {"full": "URL#924061", "pdf": ""}, "publisher-venue": "iiWAS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 725872607, "title": "Content Based Fake News Detection Using N-Gram Models.", "abstract": "", "doi": "10.1145/3366030.3366116", "date": "2019", "authors": [{"name": "Hnin Ei Wynne", "id-internal": "259/0518", "id-external": ""}, {"name": "Zar Zar Wint", "id-internal": "211/9414", "id-external": ""}], "url": {"full": "URL#924118", "pdf": ""}, "publisher-venue": "iiWAS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1725064197, "title": "A Machine Learning Approach to Fake News Detection Using Knowledge Verification and Natural Language Processing.", "abstract": "", "doi": "10.1007/978-3-030-29035-1_22", "date": "2019", "authors": [{"name": "Marina Danchovsky Ibrishimova", "id-internal": "230/2358", "id-external": ""}, {"name": "Kin Fun Li", "id-internal": "33/2872", "id-external": ""}], "url": {"full": "URL#926685", "pdf": ""}, "publisher-venue": "INCoS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3476904594, "title": "Fake News Detection Using Bayesian Inference.", "abstract": "", "doi": "10.1109/iri.2019.00066", "date": "2019", "authors": [{"name": "Fatma Najar", "id-internal": "216/4170", "id-external": ""}, {"name": "Nuha Zamzami", "id-internal": "175/4795", "id-external": ""}, {"name": "Nizar Bouguila", "id-internal": "43/2204", "id-external": ""}], "url": {"full": "URL#930939", "pdf": ""}, "publisher-venue": "IRI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4142572404, "title": "If You Could Believe Your Eyes - Images and Fake News.", "abstract": "", "doi": "10.1109/iv-2.2019.00034", "date": "2019", "authors": [{"name": "Mark William McKenzie Bannatyne", "id-internal": "40/4780", "id-external": ""}, {"name": "Agnieszka Katarzyna Piekarzewska", "id-internal": "247/7642", "id-external": ""}, {"name": "Clinton Theodore Koch", "id-internal": "247/7745", "id-external": ""}], "url": {"full": "URL#942154", "pdf": ""}, "publisher-venue": "IV", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 273104220, "title": "Semantic Fake News Detection - A Machine Learning Perspective.", "abstract": "", "doi": "10.1007/978-3-030-20521-8_54", "date": "2019", "authors": [{"name": "Adrian M. P. Brasoveanu", "id-internal": "32/1077-2", "id-external": ""}, {"name": "Razvan Andonie", "id-internal": "73/98", "id-external": ""}], "url": {"full": "URL#942838", "pdf": ""}, "publisher-venue": "IWANN", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2727770781, "title": "Natural Language Contents Evaluation System for Detecting Fake News using Deep Learning.", "abstract": "", "doi": "10.1109/jcsse.2019.8864171", "date": "2019", "authors": [{"name": "Ye-Chan Ahn", "id-internal": "297/9853", "id-external": ""}, {"name": "Chang-Sung Jeong", "id-internal": "58/1148", "id-external": ""}], "url": {"full": "URL#944432", "pdf": ""}, "publisher-venue": "JCSSE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1656148171, "title": "Fake News Detection System using Article Abstraction.", "abstract": "", "doi": "10.1109/jcsse.2019.8864154", "date": "2019", "authors": [{"name": "Kyeong-Hwan Kim", "id-internal": "298/0091", "id-external": ""}, {"name": "Chang-Sung Jeong", "id-internal": "58/1148", "id-external": ""}], "url": {"full": "URL#944458", "pdf": ""}, "publisher-venue": "JCSSE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2598209395, "title": "dEFEND - Explainable Fake News Detection.", "abstract": "", "doi": "10.1145/3292500.3330935", "date": "2019", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Limeng Cui", "id-internal": "147/6826", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#945413", "pdf": ""}, "publisher-venue": "KDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2050584589, "title": "Fake News Research - Theories, Detection Strategies, and Open Problems.", "abstract": "", "doi": "10.1145/3292500.3332287", "date": "2019", "authors": [{"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}, {"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#945521", "pdf": ""}, "publisher-venue": "KDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 700796215, "title": "A Two-Stage Model Based on BERT for Short Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-29563-9_17", "date": "2019", "authors": [{"name": "Chao Liu 0020", "id-internal": "15/5923-20", "id-external": ""}, {"name": "Xinghua Wu", "id-internal": "54/7811", "id-external": ""}, {"name": "Min Yu", "id-internal": "23/1425", "id-external": ""}, {"name": "Gang Li 0009", "id-internal": "62/2655-9", "id-external": ""}, {"name": "Jianguo Jiang", "id-internal": "20/1871", "id-external": ""}, {"name": "Weiqing Huang", "id-internal": "42/3576", "id-external": ""}, {"name": "Xiang Lu", "id-internal": "05/5990", "id-external": ""}], "url": {"full": "URL#946315", "pdf": ""}, "publisher-venue": "KSEM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2640923872, "title": "Fake News Detection in Microblogging Through Quantifier-Guided Aggregation.", "abstract": "", "doi": "10.1007/978-3-030-26773-5_6", "date": "2019", "authors": [{"name": "Marco De Grandis", "id-internal": "247/6510", "id-external": ""}, {"name": "Gabriella Pasi", "id-internal": "26/4672", "id-external": ""}, {"name": "Marco Viviani", "id-internal": "33/2831", "id-external": ""}], "url": {"full": "URL#948424", "pdf": ""}, "publisher-venue": "MDAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2927570302, "title": "On the Origin, Proliferation and Tone of Fake News.", "abstract": "", "doi": "10.1109/mipr.2019.00031", "date": "2019", "authors": [{"name": "Shivam B. Parikh", "id-internal": "211/3838", "id-external": ""}, {"name": "Vikram Patil", "id-internal": "37/9786", "id-external": ""}, {"name": "Pradeep K. Atrey", "id-internal": "81/478", "id-external": ""}], "url": {"full": "URL#952413", "pdf": ""}, "publisher-venue": "MIPR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 215892944, "title": "Towards Impact Scoring of Fake News.", "abstract": "", "doi": "10.1109/mipr.2019.00107", "date": "2019", "authors": [{"name": "Shivam B. Parikh", "id-internal": "211/3838", "id-external": ""}, {"name": "Vikram Patil", "id-internal": "37/9786", "id-external": ""}, {"name": "Ravi Makawana", "id-internal": "239/7412", "id-external": ""}, {"name": "Pradeep K. Atrey", "id-internal": "81/478", "id-external": ""}], "url": {"full": "URL#952414", "pdf": ""}, "publisher-venue": "MIPR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1314530633, "title": "High Dimensional Latent Space Variational AutoEncoders for Fake News Detection.", "abstract": "", "doi": "10.1109/mipr.2019.00088", "date": "2019", "authors": [{"name": "Saad Sadiq", "id-internal": "191/9452", "id-external": ""}, {"name": "Nicolas Wagner", "id-internal": "72/364", "id-external": ""}, {"name": "Mei-Ling Shyu", "id-internal": "93/6593", "id-external": ""}, {"name": "Daniel Feaster", "id-internal": "208/6933", "id-external": ""}], "url": {"full": "URL#952419", "pdf": ""}, "publisher-venue": "MIPR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 183666405, "title": "Learning Hierarchical Discourse-level Structure for Fake News Detection.", "abstract": "", "doi": "10.18653/v1/n19-1347", "date": "2019", "authors": [{"name": "Hamid Karimi", "id-internal": "00/8953", "id-external": ""}, {"name": "Jiliang Tang", "id-internal": "64/10812", "id-external": ""}], "url": {"full": "URL#956817", "pdf": ""}, "publisher-venue": "NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3914434347, "title": "Fake News Detection using Deep Markov Random Fields.", "abstract": "", "doi": "10.18653/v1/n19-1141", "date": "2019", "authors": [{"name": "Duc Minh Nguyen", "id-internal": "89/4455", "id-external": ""}, {"name": "Tien Huu Do", "id-internal": "182/6906", "id-external": ""}, {"name": "A. Robert Calderbank", "id-internal": "c/ARobertCalderbank", "id-external": ""}, {"name": "Nikos Deligiannis", "id-internal": "90/5258", "id-external": ""}], "url": {"full": "URL#956919", "pdf": ""}, "publisher-venue": "NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1533597084, "title": "Defending Against Neural Fake News.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Rowan Zellers", "id-internal": "182/2175", "id-external": ""}, {"name": "Ari Holtzman", "id-internal": "205/9029", "id-external": ""}, {"name": "Hannah Rashkin", "id-internal": "164/6090", "id-external": ""}, {"name": "Yonatan Bisk", "id-internal": "38/9282", "id-external": ""}, {"name": "Ali Farhadi", "id-internal": "37/5826", "id-external": ""}, {"name": "Franziska Roesner", "id-internal": "23/2758", "id-external": ""}, {"name": "Yejin Choi", "id-internal": "89/579", "id-external": ""}], "url": {"full": "URL#959984", "pdf": ""}, "publisher-venue": "NeurIPS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1291197997, "title": "A Novel Approach Towards Fake News Detection - Deep Learning Augmented with Textual Entailment Features.", "abstract": "", "doi": "10.1007/978-3-030-23281-8_30", "date": "2019", "authors": [{"name": "Tanik Saikh", "id-internal": "00/9019", "id-external": ""}, {"name": "Amit Anand", "id-internal": "178/1931", "id-external": ""}, {"name": "Asif Ekbal", "id-internal": "11/3590", "id-external": ""}, {"name": "Pushpak Bhattacharyya", "id-internal": "p/PushpakBhattacharyya", "id-external": ""}], "url": {"full": "URL#960166", "pdf": ""}, "publisher-venue": "NLDB", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2822558966, "title": "Multi-depth Graph Convolutional Networks for Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-32233-5_54", "date": "2019", "authors": [{"name": "Guoyong Hu", "id-internal": "249/8984", "id-external": ""}, {"name": "Ye Ding", "id-internal": "17/4099", "id-external": ""}, {"name": "Shuhan Qi", "id-internal": "38/10422", "id-external": ""}, {"name": "Xuan Wang 0002", "id-internal": "34/4799-2", "id-external": ""}, {"name": "Qing Liao 0001", "id-internal": "09/8600-1", "id-external": ""}], "url": {"full": "URL#960204", "pdf": ""}, "publisher-venue": "NLPCC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 290065449, "title": "User-Characteristic Enhanced Model for Fake News Detection in Social Media.", "abstract": "", "doi": "10.1007/978-3-030-32233-5_49", "date": "2019", "authors": [{"name": "Shengyi Jiang", "id-internal": "67/3929", "id-external": ""}, {"name": "Xiaoting Chen", "id-internal": "124/6226", "id-external": ""}, {"name": "Liming Zhang", "id-internal": "66/6011", "id-external": ""}, {"name": "Sutong Chen", "id-internal": "249/9144", "id-external": ""}, {"name": "Haonan Liu", "id-internal": "26/8513", "id-external": ""}], "url": {"full": "URL#960213", "pdf": ""}, "publisher-venue": "NLPCC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2768495048, "title": "Fake News Detection on Social Media - A Systematic Survey.", "abstract": "", "doi": "10.1109/pacrim47961.2019.8985062", "date": "2019", "authors": [{"name": "Mohamed K. Elhadad", "id-internal": "202/5078", "id-external": ""}, {"name": "Kin Fun Li", "id-internal": "33/2872", "id-external": ""}, {"name": "Fayez Gebali", "id-internal": "69/4864", "id-external": ""}], "url": {"full": "URL#962491", "pdf": ""}, "publisher-venue": "PACRIM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1386351144, "title": "Fake and Hyper-partisan News Identification.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Vlad Cristian Dumitru", "id-internal": "253/9056", "id-external": ""}, {"name": "Traian Rebedea", "id-internal": "16/856", "id-external": ""}], "url": {"full": "URL#969511", "pdf": ""}, "publisher-venue": "RoCHI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2739104519, "title": "Fake News and Brazilian politics - temporal investigation based on semantic annotations and graph analysis.", "abstract": "", "doi": "10.5753/sbbd.2019.8818", "date": "2019", "authors": [{"name": "Luiz Celso Gomes Jr.", "id-internal": "68/6898", "id-external": ""}, {"name": "Gabriel Frizzon", "id-internal": "258/3803", "id-external": ""}], "url": {"full": "URL#971258", "pdf": ""}, "publisher-venue": "SBBD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4273568884, "title": "Deciding among Fake, Satirical, Objective and Legitimate news - A multi-label classification system.", "abstract": "", "doi": "10.1145/3330204.3330231", "date": "2019", "authors": [{"name": "Jana\u00edna Ign\u00e1cio de Morais", "id-internal": "246/7986", "id-external": ""}, {"name": "Hugo Queiroz Abonizio", "id-internal": "246/8435", "id-external": ""}, {"name": "Gabriel Marques Tavares", "id-internal": "210/6317", "id-external": ""}, {"name": "Andr\u00e9 Azevedo da Fonseca", "id-internal": "222/4417", "id-external": ""}, {"name": "Sylvio Barbon Jr.", "id-internal": "66/5992", "id-external": ""}], "url": {"full": "URL#971637", "pdf": ""}, "publisher-venue": "SBSI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3251402875, "title": "Classifying Fake News Articles Using Natural Language Processing to Identify In-Article Attribution as a Supervised Learning Estimator.", "abstract": "", "doi": "10.1109/icosc.2019.8665593", "date": "2019", "authors": [{"name": "Terry Traylor", "id-internal": "237/9042", "id-external": ""}, {"name": "Jerey Straub", "id-internal": "237/9089", "id-external": ""}, {"name": "Gurmeet", "id-internal": "237/9090", "id-external": ""}, {"name": "Nicholas Snell", "id-internal": "237/9045", "id-external": ""}], "url": {"full": "URL#973304", "pdf": ""}, "publisher-venue": "ICSC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4060345323, "title": "Ensembles of Recurrent Networks for Classifying the Relationship of Fake News Titles.", "abstract": "", "doi": "10.1145/3331184.3331305", "date": "2019", "authors": [{"name": "Ting Su 0003", "id-internal": "42/6896-3", "id-external": ""}, {"name": "Craig Macdonald", "id-internal": "02/2224", "id-external": ""}, {"name": "Iadh Ounis", "id-internal": "21/141", "id-external": ""}], "url": {"full": "URL#975847", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1686688938, "title": "Fake News in Spanish - Towards the Building of a Corpus Based on Twitter.", "abstract": "", "doi": "10.1007/978-3-030-46140-9_32", "date": "2019", "authors": [{"name": "Braulio Andres Soncco Pimentel", "id-internal": "271/4791", "id-external": ""}, {"name": "Roxana L. Q. Portugal", "id-internal": "172/3916", "id-external": ""}], "url": {"full": "URL#976722", "pdf": ""}, "publisher-venue": "SIMBig", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1444924959, "title": "Automatic Identification of Fake News Using Deep Learning.", "abstract": "", "doi": "10.1109/snams.2019.8931873", "date": "2019", "authors": [{"name": "Ethar Qawasmeh", "id-internal": "255/2972", "id-external": ""}, {"name": "Mais Tawalbeh", "id-internal": "255/2952", "id-external": ""}, {"name": "Malak Abdullah", "id-internal": "32/9695", "id-external": ""}], "url": {"full": "URL#978966", "pdf": ""}, "publisher-venue": "SNAMS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3302805098, "title": "Spread and reception of fake news promoting hate speech against migrants and refugees in social media - Research Plan for the Doctoral Programme Education in the Knowledge Society.", "abstract": "", "doi": "10.1145/3362789.3362842", "date": "2019", "authors": [{"name": "David Blanco-Herrero", "id-internal": "284/7492", "id-external": ""}, {"name": "Carlos Arcila Calder\u00f3n", "id-internal": "230/0148", "id-external": ""}], "url": {"full": "URL#983764", "pdf": ""}, "publisher-venue": "TEEM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3287804120, "title": "Do Sentence Interactions Matter? Leveraging Sentence Level Representations for Fake News Classification.", "abstract": "", "doi": "10.18653/v1/d19-5316", "date": "2019", "authors": [{"name": "Vaibhav Vaibhav", "id-internal": "251/1226", "id-external": ""}, {"name": "Raghuram Mandyam Annasamy", "id-internal": "222/1568", "id-external": ""}, {"name": "Eduard H. Hovy", "id-internal": "47/2454", "id-external": ""}], "url": {"full": "URL#984580", "pdf": ""}, "publisher-venue": "TextGraphs@EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3739575612, "title": "Social Reinforcement Learning to Combat Fake News Spread.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Mahak Goindani", "id-internal": "203/9509", "id-external": ""}, {"name": "Jennifer Neville", "id-internal": "n/JenniferNeville", "id-external": ""}], "url": {"full": "URL#985341", "pdf": ""}, "publisher-venue": "UAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2111947252, "title": "Who Shares Fake News in Online Social Networks?", "abstract": "", "doi": "10.1145/3320435.3320456", "date": "2019", "authors": [{"name": "Laura Burbach", "id-internal": "222/8637", "id-external": ""}, {"name": "Patrick Halbach", "id-internal": "223/0606", "id-external": ""}, {"name": "Martina Ziefle", "id-internal": "90/6913", "id-external": ""}, {"name": "Andr\u00e9 Calero Valdez", "id-internal": "77/7521", "id-external": ""}], "url": {"full": "URL#986389", "pdf": ""}, "publisher-venue": "UMAP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3584671872, "title": "Which machine learning paradigm for fake news detection?", "abstract": "", "doi": "10.1145/3350546.3352552", "date": "2019", "authors": [{"name": "Dimitrios Katsaros 0001", "id-internal": "k/DimitriosKatsaros", "id-external": ""}, {"name": "George Stavropoulos", "id-internal": "251/0704", "id-external": ""}, {"name": "Dimitrios Papakostas", "id-internal": "149/5819", "id-external": ""}], "url": {"full": "URL#991901", "pdf": ""}, "publisher-venue": "WI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2332678823, "title": "Check-It - A plugin for Detecting and Reducing the Spread of Fake News and Misinformation on the Web.", "abstract": "", "doi": "10.1145/3350546.3352534", "date": "2019", "authors": [{"name": "Demetris Paschalides", "id-internal": "190/1302", "id-external": ""}, {"name": "Alexandros Kornilakis", "id-internal": "234/5887", "id-external": ""}, {"name": "Chrysovalantis Christodoulou", "id-internal": "241/5290", "id-external": ""}, {"name": "Rafael Andreou", "id-internal": "241/5489", "id-external": ""}, {"name": "George Pallis 0001", "id-internal": "21/4460", "id-external": ""}, {"name": "Marios D. Dikaiakos", "id-internal": "06/1702", "id-external": ""}, {"name": "Evangelos P. Markatos", "id-internal": "m/EvangelosPMarkatos", "id-external": ""}], "url": {"full": "URL#991990", "pdf": ""}, "publisher-venue": "WI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3395654040, "title": "Fake news detection on social media via implicit crowd signals.", "abstract": "", "doi": "10.1145/3323503.3360626", "date": "2019", "authors": [{"name": "Paulo M\u00e1rcio Souza Freire", "id-internal": "250/3519", "id-external": ""}, {"name": "Ronaldo Ribeiro Goldschmidt", "id-internal": "45/881", "id-external": ""}], "url": {"full": "URL#992140", "pdf": ""}, "publisher-venue": "WebMedia", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2008638710, "title": "Data mining applied in fake news classification through textual patterns.", "abstract": "", "doi": "10.1145/3323503.3360648", "date": "2019", "authors": [{"name": "Marcos Paulo Moraes", "id-internal": "250/3764", "id-external": ""}, {"name": "Jonice de Oliveira Sampaio", "id-internal": "o/JoniceOliveira", "id-external": ""}, {"name": "Anderson Cordeiro Charles", "id-internal": "250/3617", "id-external": ""}], "url": {"full": "URL#992158", "pdf": ""}, "publisher-venue": "WebMedia", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2899782969, "title": "FACTCK.BR - a new dataset to study fake news.", "abstract": "", "doi": "10.1145/3323503.3361698", "date": "2019", "authors": [{"name": "Jo\u00e3o Moreno", "id-internal": "250/3409", "id-external": ""}, {"name": "Gra\u00e7a Bressan", "id-internal": "50/3947", "id-external": ""}], "url": {"full": "URL#992159", "pdf": ""}, "publisher-venue": "WebMedia", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1757173276, "title": "Explainable Machine Learning for Fake News Detection.", "abstract": "", "doi": "10.1145/3292522.3326027", "date": "2019", "authors": [{"name": "Julio C. S. Reis", "id-internal": "223/4293", "id-external": ""}, {"name": "Andr\u00e9 Correia", "id-internal": "60/4085", "id-external": ""}, {"name": "Fabricio Murai", "id-internal": "30/9221", "id-external": ""}, {"name": "Adriano Veloso", "id-internal": "12/919", "id-external": ""}, {"name": "Fabr\u00edcio Benevenuto", "id-internal": "90/2878", "id-external": ""}], "url": {"full": "URL#992230", "pdf": ""}, "publisher-venue": "WebSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3220898110, "title": "How Gullible Are You? - Predicting Susceptibility to Fake News.", "abstract": "", "doi": "10.1145/3292522.3326055", "date": "2019", "authors": [{"name": "Tracy Jia Shen", "id-internal": "244/0146", "id-external": ""}, {"name": "Robert Cowell", "id-internal": "244/0456", "id-external": ""}, {"name": "Aditi Gupta", "id-internal": "223/9382", "id-external": ""}, {"name": "Thai Le", "id-internal": "03/9889", "id-external": ""}, {"name": "Amulya Yadav", "id-internal": "121/3511", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}], "url": {"full": "URL#992239", "pdf": ""}, "publisher-venue": "WebSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4240070310, "title": "Computing the Linguistic-Based Cues of Fake News in the Philippines Towards its Detection.", "abstract": "", "doi": "10.1145/3326467.3326490", "date": "2019", "authors": [{"name": "Aaron Carl T. Fernandez", "id-internal": "241/6420", "id-external": ""}, {"name": "Madhavi Devaraj", "id-internal": "139/5357", "id-external": ""}], "url": {"full": "URL#992978", "pdf": ""}, "publisher-venue": "WIMS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 927113179, "title": "Fake News Perception in Germany - A Representative Study of People's Attitudes and Approaches to Counteract Disinformation.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Christian Reuter 0001", "id-internal": "79/3736", "id-external": ""}, {"name": "Katrin Hartwig", "id-internal": "247/3542", "id-external": ""}, {"name": "Jan Kirchner", "id-internal": "203/1852", "id-external": ""}, {"name": "Noah Schlegel", "id-internal": "247/3501", "id-external": ""}], "url": {"full": "URL#993168", "pdf": ""}, "publisher-venue": "Wirtschaftsinformatik", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3373267338, "title": "TrustyTweet - An Indicator-based Browser-Plugin to Assist Users in Dealing with Fake News on Twitter.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Katrin Hartwig", "id-internal": "247/3542", "id-external": ""}, {"name": "Christian Reuter 0001", "id-internal": "79/3736", "id-external": ""}], "url": {"full": "URL#993224", "pdf": ""}, "publisher-venue": "Wirtschaftsinformatik", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 656931252, "title": "Fake News - Fundamental Theories, Detection Strategies and Challenges.", "abstract": "", "doi": "10.1145/3289600.3291382", "date": "2019", "authors": [{"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#995075", "pdf": ""}, "publisher-venue": "WSDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 55589842, "title": "What happened? The Spread of Fake News Publisher Content During the 2016 U.S. Presidential Election.", "abstract": "", "doi": "10.1145/3308558.3313721", "date": "2019", "authors": {"name": "Ceren Budak", "id-internal": "66/8462", "id-external": ""}, "url": {"full": "URL#995269", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 431677854, "title": "MVAE - Multimodal Variational Autoencoder for Fake News Detection.", "abstract": "", "doi": "10.1145/3308558.3313552", "date": "2019", "authors": [{"name": "Dhruv Khattar", "id-internal": "204/2682", "id-external": ""}, {"name": "Jaipal Singh Goud", "id-internal": "240/9397", "id-external": ""}, {"name": "Manish Gupta 0001", "id-internal": "g/ManishGupta1", "id-external": ""}, {"name": "Vasudeva Varma", "id-internal": "03/4045", "id-external": ""}], "url": {"full": "URL#995461", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1383419796, "title": "Fake News Detection - An Interdisciplinary Research.", "abstract": "", "doi": "10.1145/3308560.3316476", "date": "2019", "authors": [{"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}], "url": {"full": "URL#995821", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4288240151, "title": "Copyright Management of User-Generated Video for Journalistic Reuse.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_8", "date": "2019", "authors": [{"name": "Roberto Garc\u00eda 0001", "id-internal": "57/7467", "id-external": ""}, {"name": "Maria Teixidor", "id-internal": "249/1485", "id-external": ""}, {"name": "Paloma de Barr\u00f3n", "id-internal": "249/1486", "id-external": ""}, {"name": "Denis Teyssou", "id-internal": "215/2284", "id-external": ""}, {"name": "Rosa Gil", "id-internal": "17/4905", "id-external": ""}, {"name": "Albert Berga", "id-internal": "249/1487", "id-external": ""}, {"name": "Gerard Rovira", "id-internal": "249/1484", "id-external": ""}], "url": {"full": "URL#996428", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3766645601, "title": "Video Fragmentation and Reverse Search on the Web.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_3", "date": "2019", "authors": [{"name": "Evlampios E. Apostolidis", "id-internal": "138/0884", "id-external": ""}, {"name": "Konstantinos Apostolidis", "id-internal": "152/9368", "id-external": ""}, {"name": "Ioannis Patras", "id-internal": "18/1556", "id-external": ""}, {"name": "Vasileios Mezaris", "id-internal": "80/6216", "id-external": ""}], "url": {"full": "URL#996484", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 958135451, "title": "Finding Near-Duplicate Videos in Large-Scale Collections.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_4", "date": "2019", "authors": [{"name": "Giorgos Kordopatis-Zilos", "id-internal": "138/0862", "id-external": ""}, {"name": "Symeon Papadopoulos", "id-internal": "38/3754", "id-external": ""}, {"name": "Ioannis Patras", "id-internal": "18/1556", "id-external": ""}, {"name": "Ioannis Kompatsiaris", "id-internal": "k/YiannisKompatsiaris", "id-external": ""}], "url": {"full": "URL#996915", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3996391054, "title": "Finding Semantically Related Videos in Closed Collections.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_5", "date": "2019", "authors": [{"name": "Foteini Markatopoulou", "id-internal": "34/8875", "id-external": ""}, {"name": "Markos Zampoglou", "id-internal": "84/8696", "id-external": ""}, {"name": "Evlampios E. Apostolidis", "id-internal": "138/0884", "id-external": ""}, {"name": "Symeon Papadopoulos", "id-internal": "38/3754", "id-external": ""}, {"name": "Vasileios Mezaris", "id-internal": "80/6216", "id-external": ""}, {"name": "Ioannis Patras", "id-internal": "18/1556", "id-external": ""}, {"name": "Ioannis Kompatsiaris", "id-internal": "k/YiannisKompatsiaris", "id-external": ""}], "url": {"full": "URL#997002", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1173080367, "title": "Detecting Manipulations in Video.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_6", "date": "2019", "authors": [{"name": "Gr\u00e9goire Mercier", "id-internal": "13/6452", "id-external": ""}, {"name": "Foteini Markatopoulou", "id-internal": "34/8875", "id-external": ""}, {"name": "Roger Cozien", "id-internal": "213/5429", "id-external": ""}, {"name": "Markos Zampoglou", "id-internal": "84/8696", "id-external": ""}, {"name": "Evlampios E. Apostolidis", "id-internal": "138/0884", "id-external": ""}, {"name": "Alexandros I. Metsai", "id-internal": "249/1483", "id-external": ""}, {"name": "Symeon Papadopoulos", "id-internal": "38/3754", "id-external": ""}, {"name": "Vasileios Mezaris", "id-internal": "80/6216", "id-external": ""}, {"name": "Ioannis Patras", "id-internal": "18/1556", "id-external": ""}, {"name": "Ioannis Kompatsiaris", "id-internal": "k/YiannisKompatsiaris", "id-external": ""}], "url": {"full": "URL#997030", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2820728431, "title": "Real-Time Story Detection and Video Retrieval from Social Media Streams.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_2", "date": "2019", "authors": [{"name": "Lyndon J. B. Nixon", "id-internal": "n/LyndonJBNixon", "id-external": ""}, {"name": "Daniel Fischl", "id-internal": "151/3265", "id-external": ""}, {"name": "Arno Scharl", "id-internal": "23/121", "id-external": ""}], "url": {"full": "URL#997080", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2180679917, "title": "Verification of Web Videos Through Analysis of Their Online Context.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_7", "date": "2019", "authors": [{"name": "Olga Papadopoulou", "id-internal": "156/0678", "id-external": ""}, {"name": "Markos Zampoglou", "id-internal": "84/8696", "id-external": ""}, {"name": "Symeon Papadopoulos", "id-internal": "38/3754", "id-external": ""}, {"name": "Ioannis Kompatsiaris", "id-internal": "k/YiannisKompatsiaris", "id-external": ""}], "url": {"full": "URL#997095", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1060345043, "title": "Multimodal Analytics Dashboard for Story Detection and Visualization.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_10", "date": "2019", "authors": [{"name": "Arno Scharl", "id-internal": "23/121", "id-external": ""}, {"name": "Alexander Hubmann-Haidvogel", "id-internal": "17/4899", "id-external": ""}, {"name": "Max C. G\u00f6bel", "id-internal": "99/8023", "id-external": ""}, {"name": "Tobi Sch\u00e4fer", "id-internal": "249/1488", "id-external": ""}, {"name": "Daniel Fischl", "id-internal": "151/3265", "id-external": ""}, {"name": "Lyndon J. B. Nixon", "id-internal": "n/LyndonJBNixon", "id-external": ""}], "url": {"full": "URL#997210", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3626897040, "title": "Applying Design Thinking Methodology - The InVID Verification Plugin.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_9", "date": "2019", "authors": {"name": "Denis Teyssou", "id-internal": "215/2284", "id-external": ""}, "url": {"full": "URL#997309", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2839088156, "title": "Disinformation - The Force of Falsity.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_12", "date": "2019", "authors": {"name": "Denis Teyssou", "id-internal": "215/2284", "id-external": ""}, "url": {"full": "URL#997310", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3923466189, "title": "Video Verification - Motivation and Requirements.", "abstract": "", "doi": "10.1007/978-3-030-26752-0_1", "date": "2019", "authors": [{"name": "Denis Teyssou", "id-internal": "215/2284", "id-external": ""}, {"name": "Jochen Spangenberg", "id-internal": "07/2959", "id-external": ""}], "url": {"full": "URL#997311", "pdf": ""}, "publisher-venue": "Video Verification in the Fake News Era", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2187815698, "title": "Video Verification in the Fake News Era.", "abstract": "", "doi": "10.1007/978-3-030-26752-0", "date": "2019", "authors": [{"name": "Vasileios Mezaris", "id-internal": "80/6216", "id-external": ""}, {"name": "Lyndon J. B. Nixon", "id-internal": "n/LyndonJBNixon", "id-external": ""}, {"name": "Symeon Papadopoulos", "id-internal": "38/3754", "id-external": ""}, {"name": "Denis Teyssou", "id-internal": "215/2284", "id-external": ""}], "url": {"full": "URL#998139", "pdf": ""}, "publisher-venue": "", "type": "Editorship", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4269760788, "title": "Combating Fake News - A Survey on Identification and Mitigation Techniques.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Karishma Sharma", "id-internal": "222/7902", "id-external": ""}, {"name": "Feng Qian", "id-internal": "54/476", "id-external": ""}, {"name": "He Jiang", "id-internal": "30/3790", "id-external": ""}, {"name": "Natali Ruchansky", "id-internal": "12/9876", "id-external": ""}, {"name": "Ming Zhang 0004", "id-internal": "73/1844-4", "id-external": ""}, {"name": "Yan Liu 0002", "id-internal": "l/YanLiu2", "id-external": ""}], "url": {"full": "URL#1004359", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4276634136, "title": "Fake News Detection via NLP is Vulnerable to Adversarial Attacks.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Zhixuan Zhou", "id-internal": "228/6035", "id-external": ""}, {"name": "Huankang Guan", "id-internal": "234/8472", "id-external": ""}, {"name": "Meghana Moorthy Bhat", "id-internal": "234/8670", "id-external": ""}, {"name": "Justin Hsu", "id-internal": "35/10964", "id-external": ""}], "url": {"full": "URL#1005397", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 29844117, "title": "Fake News Detection on Social Media using Geometric Deep Learning.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Federico Monti", "id-internal": "170/0002", "id-external": ""}, {"name": "Fabrizio Frasca", "id-internal": "228/1840", "id-external": ""}, {"name": "Davide Eynard", "id-internal": "30/5672", "id-external": ""}, {"name": "Damon Mannion", "id-internal": "236/5073", "id-external": ""}, {"name": "Michael M. Bronstein", "id-internal": "07/2668", "id-external": ""}], "url": {"full": "URL#1008102", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 172232543, "title": "Identifying Fake News from Twitter Sharing Data - A Large-Scale Study.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Rakshit Agrawal", "id-internal": "11/11304", "id-external": ""}, {"name": "Luca de Alfaro", "id-internal": "d/LucadeAlfaro", "id-external": ""}, {"name": "Gabriele Ballarin", "id-internal": "199/2238", "id-external": ""}, {"name": "Stefano Moret", "id-internal": "189/8761", "id-external": ""}, {"name": "Massimo Di Pierro", "id-internal": "90/17", "id-external": ""}, {"name": "Eugenio Tacchini", "id-internal": "32/10636", "id-external": ""}, {"name": "Marco L. Della Vedova", "id-internal": "93/7704", "id-external": ""}], "url": {"full": "URL#1008282", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2953376968, "title": "Exploiting Emotions for Fake News Detection on Social Media.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Chuan Guo", "id-internal": "147/5346", "id-external": ""}, {"name": "Juan Cao", "id-internal": "75/2820", "id-external": ""}, {"name": "Xueyao Zhang", "id-internal": "237/9484", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Miao Yu", "id-internal": "49/1749", "id-external": ""}], "url": {"full": "URL#1010120", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2530006821, "title": "Learning Hierarchical Discourse-level Structure for Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Hamid Karimi", "id-internal": "00/8953", "id-external": ""}, {"name": "Jiliang Tang", "id-internal": "64/10812", "id-external": ""}], "url": {"full": "URL#1011824", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3940145288, "title": "Hierarchical Propagation Networks for Fake News Detection - Investigation and Exploitation.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Deepak Mahudeswaran", "id-internal": "227/2536", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#1012335", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2979772385, "title": "Using Blockchain to Rein in The New Post-Truth World and Check The Spread of Fake News.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Adnan Qayyum", "id-internal": "198/1509", "id-external": ""}, {"name": "Junaid Qadir 0001", "id-internal": "74/2204", "id-external": ""}, {"name": "Muhammad Umar Janjua", "id-internal": "63/5600", "id-external": ""}, {"name": "Falak Sher", "id-internal": "45/9126", "id-external": ""}], "url": {"full": "URL#1013139", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2647687644, "title": "Neural Abstractive Text Summarization and Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Soheil Esmaeilzadeh", "id-internal": "222/1559", "id-external": ""}, {"name": "Gao Xian Peh", "id-internal": "214/8876", "id-external": ""}, {"name": "Angela Xu", "id-internal": "239/4358", "id-external": ""}], "url": {"full": "URL#1013654", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3571909570, "title": "Open Issues in Combating Fake News - Interpretability as an Opportunity.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Sina Mohseni", "id-internal": "155/4739", "id-external": ""}, {"name": "Eric D. Ragan", "id-internal": "69/7691", "id-external": ""}, {"name": "Xia Hu", "id-internal": "24/7536", "id-external": ""}], "url": {"full": "URL#1014438", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 498463901, "title": "A Classification Algorithm to Recognize Fake News Websites.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Davide Bennato", "id-internal": "225/1790", "id-external": ""}, {"name": "Giuseppe Pernagallo", "id-internal": "239/5032", "id-external": ""}, {"name": "Benedetto Torrisi", "id-internal": "124/6560", "id-external": ""}], "url": {"full": "URL#1015316", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4150872207, "title": "Leveraging Distributed Ledger Technologies and Blockchain to Combat Fake News.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Paula Fraga-Lamas", "id-internal": "138/4366", "id-external": ""}, {"name": "Tiago M. Fern\u00e1ndez-Caram\u00e9s", "id-internal": "66/2481", "id-external": ""}], "url": {"full": "URL#1015348", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 505545257, "title": "Fake News Early Detection - A Theory-driven Model.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Atishay Jain", "id-internal": "18/5534", "id-external": ""}, {"name": "Vir V. Phoha", "id-internal": "18/5695", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}], "url": {"full": "URL#1017496", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2172183479, "title": "The Role of User Profile for Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#1018082", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 386028938, "title": "A Topic-Agnostic Approach for Identifying Fake News Pages.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Sonia Castelo", "id-internal": "240/9112", "id-external": ""}, {"name": "Thais G. Almeida", "id-internal": "190/1391", "id-external": ""}, {"name": "Anas Elghafari", "id-internal": "53/8158", "id-external": ""}, {"name": "A\u00e9cio S. R. Santos", "id-internal": "135/2637", "id-external": ""}, {"name": "Kien Pham", "id-internal": "52/7031", "id-external": ""}, {"name": "Eduardo Freire Nakamura", "id-internal": "86/0", "id-external": ""}, {"name": "Juliana Freire", "id-internal": "f/JulianaFreire", "id-external": ""}], "url": {"full": "URL#1018410", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3583430379, "title": "Check-It - A Plugin for Detecting and Reducing the Spread of Fake News and Misinformation on the Web.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Demetris Paschalides", "id-internal": "190/1302", "id-external": ""}, {"name": "Alexandros Kornilakis", "id-internal": "234/5887", "id-external": ""}, {"name": "Chrysovalantis Christodoulou", "id-internal": "241/5290", "id-external": ""}, {"name": "Rafael Andreou", "id-internal": "241/5489", "id-external": ""}, {"name": "George Pallis 0001", "id-internal": "21/4460", "id-external": ""}, {"name": "Marios D. Dikaiakos", "id-internal": "06/1702", "id-external": ""}, {"name": "Evangelos P. Markatos", "id-internal": "m/EvangelosPMarkatos", "id-external": ""}], "url": {"full": "URL#1019486", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2676769076, "title": "A Benchmark Study on Machine Learning Methods for Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Junaed Younus Khan", "id-internal": "241/5884", "id-external": ""}, {"name": "Md. Tawkat Islam Khondaker", "id-internal": "241/5971", "id-external": ""}, {"name": "Anindya Iqbal", "id-internal": "98/7632", "id-external": ""}, {"name": "Sadia Afroz", "id-internal": "29/7562", "id-external": ""}], "url": {"full": "URL#1019676", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2718066229, "title": "Fake news and rumors - a trigger for proliferation or fading away.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Ahad N. Zehmakan", "id-internal": "167/4131", "id-external": ""}, {"name": "Serge Galam", "id-internal": "86/4836", "id-external": ""}], "url": {"full": "URL#1020403", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3747449218, "title": "Defending Against Neural Fake News.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Rowan Zellers", "id-internal": "182/2175", "id-external": ""}, {"name": "Ari Holtzman", "id-internal": "205/9029", "id-external": ""}, {"name": "Hannah Rashkin", "id-internal": "164/6090", "id-external": ""}, {"name": "Yonatan Bisk", "id-internal": "38/9282", "id-external": ""}, {"name": "Ali Farhadi", "id-internal": "37/5826", "id-external": ""}, {"name": "Franziska Roesner", "id-internal": "23/2758", "id-external": ""}, {"name": "Yejin Choi", "id-internal": "89/579", "id-external": ""}], "url": {"full": "URL#1022552", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3703089945, "title": "News Labeling as Early as Possible - Real or Fake?", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Maryam Ramezani", "id-internal": "79/542", "id-external": ""}, {"name": "Mina Rafiei", "id-internal": "242/9107", "id-external": ""}, {"name": "Soroush Omranpour", "id-internal": "242/8864", "id-external": ""}, {"name": "Hamid R. Rabiee", "id-internal": "01/4547", "id-external": ""}], "url": {"full": "URL#1024442", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 114748309, "title": "Network-based Fake News Detection - A Pattern-driven Approach.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}], "url": {"full": "URL#1024758", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2863834901, "title": "Deep Two-path Semi-supervised Learning for Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Xishuang Dong", "id-internal": "62/7701", "id-external": ""}, {"name": "Uboho Victor", "id-internal": "243/2843", "id-external": ""}, {"name": "Shanta Chowdhury", "id-internal": "211/4889", "id-external": ""}, {"name": "Lijun Qian", "id-internal": "48/536", "id-external": ""}], "url": {"full": "URL#1025321", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 563763529, "title": "Emotion Cognizance Improves Fake News Identification.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Anoop K.", "id-internal": "284/3968", "id-external": ""}, {"name": "Deepak P 0001", "id-internal": "33/1882", "id-external": ""}, {"name": "Lajish V. L", "id-internal": "243/5899", "id-external": ""}], "url": {"full": "URL#1027084", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2224966096, "title": "On the Coherence of Fake News Articles.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Iknoor Singh", "id-internal": "243/5708", "id-external": ""}, {"name": "Deepak P 0001", "id-internal": "33/1882", "id-external": ""}, {"name": "Anoop K.", "id-internal": "284/3968", "id-external": ""}], "url": {"full": "URL#1027364", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1068390178, "title": "Fake News Detection using Stance Classification - A Survey.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Anders Edelbo Lillie", "id-internal": "206/1201", "id-external": ""}, {"name": "Emil Refsgaard Middelboe", "id-internal": "244/2206", "id-external": ""}], "url": {"full": "URL#1027856", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 283901017, "title": "Fake News Detection as Natural Language Inference.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Kai-Chou Yang", "id-internal": "245/2857", "id-external": ""}, {"name": "Timothy Niven", "id-internal": "218/6540", "id-external": ""}, {"name": "Hung-Yu Kao", "id-internal": "64/5833", "id-external": ""}], "url": {"full": "URL#1030494", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 758465725, "title": "XFake - Explainable Fake News Detector with Visualizations.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Fan Yang 0023", "id-internal": "29/3081-23", "id-external": ""}, {"name": "Shiva K. Pentyala", "id-internal": "240/9336", "id-external": ""}, {"name": "Sina Mohseni", "id-internal": "155/4739", "id-external": ""}, {"name": "Mengnan Du", "id-internal": "183/5606", "id-external": ""}, {"name": "Hao Yuan", "id-internal": "92/867", "id-external": ""}, {"name": "Rhema Linder", "id-internal": "132/1528", "id-external": ""}, {"name": "Eric D. Ragan", "id-internal": "69/7691", "id-external": ""}, {"name": "Shuiwang Ji", "id-internal": "84/6405", "id-external": ""}, {"name": "Xia (Ben) Hu", "id-internal": "240/9062", "id-external": ""}], "url": {"full": "URL#1030627", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3930179550, "title": "The Mass, Fake News, and Cognition Security.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Bin Guo 0001", "id-internal": "86/2663-1", "id-external": ""}, {"name": "Yasan Ding", "id-internal": "245/2848", "id-external": ""}, {"name": "Yueheng Sun", "id-internal": "83/6984", "id-external": ""}, {"name": "Shuai Ma 0001", "id-internal": "35/6569", "id-external": ""}, {"name": "Ke Li", "id-internal": "75/6627", "id-external": ""}], "url": {"full": "URL#1030629", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2495968510, "title": "The Myths of Our Time - Fake News.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "V\u00edt Ruzicka", "id-internal": "223/4125", "id-external": ""}, {"name": "Eunsu Kang", "id-internal": "90/1093", "id-external": ""}, {"name": "David Gordon", "id-internal": "35/2929", "id-external": ""}, {"name": "Ankita Patel", "id-internal": "246/4878", "id-external": ""}, {"name": "Jacqui Fashimpaur", "id-internal": "246/4677", "id-external": ""}, {"name": "Manzil Zaheer", "id-internal": "40/10701", "id-external": ""}], "url": {"full": "URL#1033233", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3126730387, "title": "Tensor Factorization with Label Information for Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Frosso Papanastasiou", "id-internal": "247/1065", "id-external": ""}, {"name": "Georgios Katsimpras", "id-internal": "118/3452", "id-external": ""}, {"name": "Georgios Paliouras", "id-internal": "55/2039", "id-external": ""}], "url": {"full": "URL#1033977", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 525289490, "title": "Exploiting Multi-domain Visual Information for Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Peng Qi 0005", "id-internal": "59/9474-5", "id-external": ""}, {"name": "Juan Cao", "id-internal": "75/2820", "id-external": ""}, {"name": "Tianyun Yang", "id-internal": "189/3221", "id-external": ""}, {"name": "Junbo Guo", "id-internal": "33/4618", "id-external": ""}, {"name": "Jintao Li 0001", "id-internal": "l/JintaoLi-1", "id-external": ""}], "url": {"full": "URL#1034150", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2909478480, "title": "Are We Safe Yet? The Limitations of Distributional Features for Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Tal Schuster", "id-internal": "190/7491", "id-external": ""}, {"name": "Roei Schuster", "id-internal": "180/8190", "id-external": ""}, {"name": "Darsh J. Shah", "id-internal": "227/2738", "id-external": ""}, {"name": "Regina Barzilay", "id-internal": "b/ReginaBarzilay", "id-external": ""}], "url": {"full": "URL#1036066", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2232959690, "title": "Different Absorption from the Same Sharing - Sifted Multi-task Learning for Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Lianwei Wu", "id-internal": "214/2499", "id-external": ""}, {"name": "Yuan Rao", "id-internal": "73/4103", "id-external": ""}, {"name": "Haolin Jin", "id-internal": "207/8891", "id-external": ""}, {"name": "Ambreen Nazir", "id-internal": "226/6984", "id-external": ""}, {"name": "Ling Sun 0004", "id-internal": "08/6547-4", "id-external": ""}], "url": {"full": "URL#1037424", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 624935623, "title": "Identifying Nuances in Fake News vs. Satire - Using Semantic and Linguistic Cues.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Or Levi", "id-internal": "188/3799", "id-external": ""}, {"name": "Pedram Hosseini", "id-internal": "198/9907", "id-external": ""}, {"name": "Mona T. Diab", "id-internal": "15/4305", "id-external": ""}, {"name": "David A. Broniatowski", "id-internal": "03/8878", "id-external": ""}], "url": {"full": "URL#1042375", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3204436719, "title": "Fake news detection using Deep Learning.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "\u00c1lvaro Ibrain Rodr\u00edguez", "id-internal": "250/8898", "id-external": ""}, {"name": "Lara Lloret Iglesias", "id-internal": "205/2363", "id-external": ""}], "url": {"full": "URL#1043253", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3799965755, "title": "FacTweet - Profiling Fake News Twitter Accounts.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Bilal Ghanem", "id-internal": "219/8408", "id-external": ""}, {"name": "Simone Paolo Ponzetto", "id-internal": "04/2532", "id-external": ""}, {"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}], "url": {"full": "URL#1044396", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2790129341, "title": "Uncritical polarized groups - The impact of spreading fake news as fact in social networks.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Jes\u00fas San Mart\u00edn", "id-internal": "118/7281", "id-external": ""}, {"name": "F\u00e1tima Drubi", "id-internal": "58/4916", "id-external": ""}, {"name": "Daniel Rodr\u00edguez-P\u00e9rez", "id-internal": "57/4234", "id-external": ""}], "url": {"full": "URL#1044875", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3669024424, "title": "Localization of Fake News Detection via Multitask Transfer Learning.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Jan Christian Blaise Cruz", "id-internal": "244/2362", "id-external": ""}, {"name": "Julianne Agatha Tan", "id-internal": "251/2993", "id-external": ""}, {"name": "Charibeth Cheng", "id-internal": "97/8063", "id-external": ""}], "url": {"full": "URL#1045367", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2155727877, "title": "Detecting Fake News with Weak Social Supervision.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Ahmed Hassan Awadallah", "id-internal": "147/9148", "id-external": ""}, {"name": "Susan T. Dumais", "id-internal": "d/SusanTDumais", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#1046168", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2527075554, "title": "Do Sentence Interactions Matter? Leveraging Sentence Level Representations for Fake News Classification.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Vaibhav Vaibhav", "id-internal": "251/1226", "id-external": ""}, {"name": "Raghuram Mandyam Annasamy", "id-internal": "222/1568", "id-external": ""}, {"name": "Eduard H. Hovy", "id-internal": "47/2454", "id-external": ""}], "url": {"full": "URL#1046481", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1549766110, "title": "Transfer Learning from Transformers to Fake News Challenge Stance Detection (FNC-1) Task.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Valeriya Slovikovskaya", "id-internal": "251/9597", "id-external": ""}, "url": {"full": "URL#1047263", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 132921318, "title": "Credibility-based Fake News Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Niraj Sitaula", "id-internal": "216/5810", "id-external": ""}, {"name": "Chilukuri K. Mohan", "id-internal": "m/CKMohan", "id-external": ""}, {"name": "Jennifer Grygiel", "id-internal": "180/8041", "id-external": ""}, {"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}], "url": {"full": "URL#1047590", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1882314204, "title": "Sieving Fake News From Genuine - A Synopsis.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Shahid Alam", "id-internal": "99/4251", "id-external": ""}, {"name": "Abdulaziz Ravshanbekov", "id-internal": "254/2158", "id-external": ""}], "url": {"full": "URL#1050600", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 520712077, "title": "Taking a Stance on Fake News - Towards Automatic Disinformation Assessment via Deep Bidirectional Transformer Language Models for Stance Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Chris Dulhanty", "id-internal": "238/0500", "id-external": ""}, {"name": "Jason L. Deglint", "id-internal": "173/5341", "id-external": ""}, {"name": "Ibrahim Ben Daya", "id-internal": "172/9470", "id-external": ""}, {"name": "Alexander Wong", "id-internal": "52/4401", "id-external": ""}], "url": {"full": "URL#1051932", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3710496127, "title": "The Limited Reach of Fake News on Twitter during 2019 European Elections.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Matteo Cinelli", "id-internal": "186/8303", "id-external": ""}, {"name": "Stefano Cresci", "id-internal": "150/6331", "id-external": ""}, {"name": "Alessandro Galeazzi", "id-internal": "213/0898", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}, {"name": "Maurizio Tesconi", "id-internal": "53/3857", "id-external": ""}], "url": {"full": "URL#1051970", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2388723802, "title": "Weak Supervision for Fake News Detection via Reinforcement Learning.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Yaqing Wang", "id-internal": "147/1393", "id-external": ""}, {"name": "Weifeng Yang", "id-internal": "27/7344", "id-external": ""}, {"name": "Fenglong Ma", "id-internal": "85/10856", "id-external": ""}, {"name": "Jin Xu", "id-internal": "97/3265", "id-external": ""}, {"name": "Bin Zhong", "id-internal": "79/10179", "id-external": ""}, {"name": "Qiang Deng", "id-internal": "68/10452", "id-external": ""}, {"name": "Jing Gao 0004", "id-internal": "67/4834-4", "id-external": ""}], "url": {"full": "URL#1056631", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1937968229, "title": "A computational approach for examining the roots and spreading patterns of fake news - Evolution tree analysis.", "abstract": "", "doi": "10.1016/j.chb.2018.02.032", "date": "2018", "authors": [{"name": "S. Mo Jang", "id-internal": "41/11483", "id-external": ""}, {"name": "Tieming Geng", "id-internal": "218/0502", "id-external": ""}, {"name": "Jo-Yun Queenie Li", "id-internal": "218/0655", "id-external": ""}, {"name": "Ruofan Xia", "id-internal": "149/1512", "id-external": ""}, {"name": "Chin-Tser Huang", "id-internal": "89/331", "id-external": ""}, {"name": "Hwalbin Kim", "id-internal": "218/0159", "id-external": ""}, {"name": "Jijun Tang", "id-internal": "21/234", "id-external": ""}], "url": {"full": "URL#1085784", "pdf": ""}, "publisher-venue": "Comput. Hum. Behav.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 229342222, "title": "Epistemology in the Era of Fake News - An Exploration of Information Verification Behaviors among Social Networking Site Users.", "abstract": "", "doi": "10.1145/3242734.3242740", "date": "2018", "authors": [{"name": "Russell Torres", "id-internal": "125/0542", "id-external": ""}, {"name": "Natalie Gerhart", "id-internal": "160/5824", "id-external": ""}, {"name": "Arash Negahban", "id-internal": "125/0756", "id-external": ""}], "url": {"full": "URL#1096099", "pdf": ""}, "publisher-venue": "Data Base", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 602607541, "title": "AI and Fake News.", "abstract": "", "doi": "10.1109/mis.2018.2877280", "date": "2018", "authors": [{"name": "Anne K. Cybenko", "id-internal": "233/1617", "id-external": ""}, {"name": "George Cybenko", "id-internal": "c/GCybenko", "id-external": ""}], "url": {"full": "URL#1104022", "pdf": ""}, "publisher-venue": "IEEE Intell. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1774949365, "title": "Audiences' acts of authentication in the age of fake news - A conceptual framework.", "abstract": "", "doi": "10.1177/1461444817731756", "date": "2018", "authors": [{"name": "Edson C. Tandoc Jr.", "id-internal": "146/1082", "id-external": ""}, {"name": "Richard Ling", "id-internal": "150/0888", "id-external": ""}, {"name": "Oscar Westlund", "id-internal": "21/9957", "id-external": ""}, {"name": "Andrew Duffy", "id-internal": "224/7826", "id-external": ""}, {"name": "Debbie Goh", "id-internal": "141/3882", "id-external": ""}, {"name": "Lim Zheng Wei", "id-internal": "224/7667", "id-external": ""}], "url": {"full": "URL#1157451", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 35658386, "title": "The agenda-setting power of fake news - A big data analysis of the online media landscape from 2014 to 2016.", "abstract": "", "doi": "10.1177/1461444817712086", "date": "2018", "authors": [{"name": "Chris J. Vargo", "id-internal": "192/8367", "id-external": ""}, {"name": "Lei Guo", "id-internal": "64/1967", "id-external": ""}, {"name": "Michelle A. Amazeen", "id-internal": "219/3137", "id-external": ""}], "url": {"full": "URL#1157468", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1151556462, "title": "Detecting opinion spams and fake news using text classification.", "abstract": "", "doi": "10.1002/spy2.9", "date": "2018", "authors": [{"name": "Hadeer Ahmed", "id-internal": "204/9079", "id-external": ""}, {"name": "Issa Traor\u00e9", "id-internal": "10/1711", "id-external": ""}, {"name": "Sherif Saad", "id-internal": "40/9034", "id-external": ""}], "url": {"full": "URL#1167376", "pdf": ""}, "publisher-venue": "Secur. Priv.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 64638025, "title": "Fake news and indifference to scientific fact - President Trump's confused tweets on global warming, climate change and weather.", "abstract": "", "doi": "10.1007/s11192-018-2847-y", "date": "2018", "authors": [{"name": "David E. Allen", "id-internal": "40/7576", "id-external": ""}, {"name": "Michael McAleer", "id-internal": "35/3858", "id-external": ""}], "url": {"full": "URL#1167489", "pdf": ""}, "publisher-venue": "Scientometrics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2698787143, "title": "Early Detection of Fake News on Social Media Through Propagation Path Classification with Recurrent and Convolutional Networks.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Yang Liu", "id-internal": "51/3710", "id-external": ""}, {"name": "Yi-fang Brook Wu", "id-internal": "75/1418", "id-external": ""}], "url": {"full": "URL#1206322", "pdf": ""}, "publisher-venue": "AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2833050915, "title": "A Stylometric Inquiry into Hyperpartisan and Fake News.", "abstract": "", "doi": "10.18653/v1/p18-1022", "date": "2018", "authors": [{"name": "Martin Potthast", "id-internal": "87/6573", "id-external": ""}, {"name": "Johannes Kiesel", "id-internal": "118/3606", "id-external": ""}, {"name": "Kevin Reinartz", "id-internal": "190/5328", "id-external": ""}, {"name": "Janek Bevendorff", "id-internal": "195/5852", "id-external": ""}, {"name": "Benno Stein 0001", "id-internal": "69/4806-1", "id-external": ""}], "url": {"full": "URL#1208275", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4026701111, "title": "Beyond Facts - A New Spin on Fake News in the Age of Social Media.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "David M. Murungi", "id-internal": "25/10689", "id-external": ""}, {"name": "Sandeep Purao", "id-internal": "09/6014", "id-external": ""}, {"name": "David J. Yates", "id-internal": "y/DavidJYates", "id-external": ""}], "url": {"full": "URL#1213852", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2277855789, "title": "Negotiating the Changing Digital Health Information Ecosystem in the Era of Fake Health News.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "David R. Kaufman", "id-internal": "85/1198", "id-external": ""}, {"name": "Catherine S. Smith", "id-internal": "239/0706", "id-external": ""}, {"name": "Alla Keselman", "id-internal": "03/502", "id-external": ""}, {"name": "Anita C. Murcko", "id-internal": "18/9252", "id-external": ""}], "url": {"full": "URL#1214430", "pdf": ""}, "publisher-venue": "AMIA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1705361421, "title": "Is it Fake News? The Accuracy of Medical Reports in Popular Media Compared to their Original Sources in PubMed.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Tobenna Nwankwo", "id-internal": "239/0830", "id-external": ""}, {"name": "Paul A. Fontelo", "id-internal": "12/3495", "id-external": ""}], "url": {"full": "URL#1214569", "pdf": ""}, "publisher-venue": "AMIA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1722795975, "title": "CIMTDetect - A Community Infused Matrix-Tensor Coupled Factorization Based Method for Fake News Detection.", "abstract": "", "doi": "10.1109/asonam.2018.8508408", "date": "2018", "authors": [{"name": "Shashank Gupta 0006", "id-internal": "89/5046-6", "id-external": ""}, {"name": "Raghuveer Thirukovalluru", "id-internal": "205/0092", "id-external": ""}, {"name": "Manjira Sinha", "id-internal": "127/0162", "id-external": ""}, {"name": "Sandya Mannarswamy", "id-internal": "73/3305", "id-external": ""}], "url": {"full": "URL#1217688", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3427183500, "title": "Weakly Supervised Learning for Fake News Detection on Twitter.", "abstract": "", "doi": "10.1109/asonam.2018.8508520", "date": "2018", "authors": [{"name": "Stefan Helmstetter", "id-internal": "228/7260", "id-external": ""}, {"name": "Heiko Paulheim", "id-internal": "39/4064", "id-external": ""}], "url": {"full": "URL#1217695", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 104504123, "title": "Five Shades of Untruth - Finer-Grained Classification of Fake News.", "abstract": "", "doi": "10.1109/asonam.2018.8508256", "date": "2018", "authors": [{"name": "Liqiang Wang", "id-internal": "02/3331", "id-external": ""}, {"name": "Yafang Wang", "id-internal": "68/6229", "id-external": ""}, {"name": "Gerard de Melo", "id-internal": "86/1747", "id-external": ""}, {"name": "Gerhard Weikum", "id-internal": "w/GerhardWeikum", "id-external": ""}], "url": {"full": "URL#1217815", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1841375240, "title": "FActCheck - Keeping Activation of Fake News at Check.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Ajitesh Srivastava", "id-internal": "77/9528", "id-external": ""}, {"name": "Rajgopal Kannan", "id-internal": "66/2538", "id-external": ""}, {"name": "Charalampos Chelmis", "id-internal": "72/7698", "id-external": ""}, {"name": "Viktor K. Prasanna", "id-internal": "p/ViktorKPrasanna", "id-external": ""}], "url": {"full": "URL#1218227", "pdf": ""}, "publisher-venue": "AAMAS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1592637554, "title": "Fake News - A Method to Measure Distance from Fact.", "abstract": "", "doi": "10.1109/bigdata.2018.8621951", "date": "2018", "authors": [{"name": "Char Sample", "id-internal": "126/2572", "id-external": ""}, {"name": "Connie Justice", "id-internal": "193/5329", "id-external": ""}, {"name": "Emily Darraj", "id-internal": "234/2758", "id-external": ""}], "url": {"full": "URL#1221704", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4066749392, "title": "Modeling the Fake News Challenge as a Cross-Level Stance Detection Task.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Costanza Conforti", "id-internal": "201/5204", "id-external": ""}, {"name": "Mohammad Taher Pilehvar", "id-internal": "136/8704", "id-external": ""}, {"name": "Nigel Collier", "id-internal": "90/2619", "id-external": ""}], "url": {"full": "URL#1231438", "pdf": ""}, "publisher-venue": "CIKM Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2099849783, "title": "Pattern Recognition Solutions for Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-319-99954-8_12", "date": "2018", "authors": [{"name": "Michal Choras", "id-internal": "06/2936", "id-external": ""}, {"name": "Agata Gielczyk", "id-internal": "226/5062", "id-external": ""}, {"name": "Konstantinos P. Demestichas", "id-internal": "37/872", "id-external": ""}, {"name": "Damian Puchalski", "id-internal": "124/9991", "id-external": ""}, {"name": "Rafal Kozik", "id-internal": "80/2851", "id-external": ""}], "url": {"full": "URL#1232228", "pdf": ""}, "publisher-venue": "CISIM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1576763465, "title": "(Fake News Subtheme) More than just new evidence - How category learning fosters belief revision.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Micah B. Goldwater", "id-internal": "88/9201", "id-external": ""}, {"name": "Monica Bollen", "id-internal": "239/0284", "id-external": ""}, {"name": "Josue Giron", "id-internal": "212/4291", "id-external": ""}], "url": {"full": "URL#1234474", "pdf": ""}, "publisher-venue": "CogSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4055972479, "title": "Hybrid Machine-Crowd Approach for Fake News Detection.", "abstract": "", "doi": "10.1109/cic.2018.00048", "date": "2018", "authors": [{"name": "Shaban Shabani", "id-internal": "185/3554", "id-external": ""}, {"name": "Maria Sokhn", "id-internal": "52/7093", "id-external": ""}], "url": {"full": "URL#1235059", "pdf": ""}, "publisher-venue": "CIC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2796735490, "title": "A Retrospective Analysis of the Fake News Challenge Stance-Detection Task.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Andreas Hanselowski", "id-internal": "215/6859", "id-external": ""}, {"name": "Avinesh P. V. S.", "id-internal": "70/8153", "id-external": ""}, {"name": "Benjamin Schiller", "id-internal": "55/8733", "id-external": ""}, {"name": "Felix Caspelherr", "id-internal": "222/1846", "id-external": ""}, {"name": "Debanjan Chaudhuri", "id-internal": "213/7337", "id-external": ""}, {"name": "Christian M. Meyer", "id-internal": "18/7930", "id-external": ""}, {"name": "Iryna Gurevych", "id-internal": "85/6201", "id-external": ""}], "url": {"full": "URL#1235242", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1974503965, "title": "Multi-Source Multi-Class Fake News Detection.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Hamid Karimi", "id-internal": "00/8953", "id-external": ""}, {"name": "Proteek Roy", "id-internal": "224/5972", "id-external": ""}, {"name": "Sari Saba-Sadiya", "id-internal": "188/8999", "id-external": ""}, {"name": "Jiliang Tang", "id-internal": "64/10812", "id-external": ""}], "url": {"full": "URL#1235277", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 126557503, "title": "Automatic Detection of Fake News.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Ver\u00f3nica P\u00e9rez-Rosas", "id-internal": "53/9684", "id-external": ""}, {"name": "Bennett Kleinberg", "id-internal": "205/3085", "id-external": ""}, {"name": "Alexandra Lefevre", "id-internal": "205/2468", "id-external": ""}, {"name": "Rada Mihalcea", "id-internal": "m/RadaMihalcea", "id-external": ""}], "url": {"full": "URL#1235394", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 902565149, "title": "Attending Sentences to detect Satirical Fake News.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Sohan De Sarkar", "id-internal": "224/5980", "id-external": ""}, {"name": "Fan Yang 0075", "id-internal": "29/3081-75", "id-external": ""}, {"name": "Arjun Mukherjee", "id-internal": "31/9013", "id-external": ""}], "url": {"full": "URL#1235424", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2487736803, "title": "Fake news, (dis)information and principle of non-intervention.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Annachiara Rotondo", "id-internal": "194/5925", "id-external": ""}, {"name": "Pierluigi Salvati", "id-internal": "244/4893", "id-external": ""}], "url": {"full": "URL#1241054", "pdf": ""}, "publisher-venue": "CyCon U.S.", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3824951673, "title": "A Model for Evaluating Fake News.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Char Sample", "id-internal": "126/2572", "id-external": ""}, {"name": "Connie Justice", "id-internal": "193/5329", "id-external": ""}, {"name": "Emily Darraj", "id-internal": "234/2758", "id-external": ""}], "url": {"full": "URL#1241055", "pdf": ""}, "publisher-venue": "CyCon U.S.", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3685888250, "title": "Fake News Detection Enhancement with Data Imputation.", "abstract": "", "doi": "10.1109/dasc/picom/datacom/cyberscitec.2018.00042", "date": "2018", "authors": [{"name": "Chandra Mouli Madhav Kotteti", "id-internal": "228/8975", "id-external": ""}, {"name": "Xishuang Dong", "id-internal": "62/7701", "id-external": ""}, {"name": "Na Li", "id-internal": "18/3173", "id-external": ""}, {"name": "Lijun Qian", "id-internal": "48/536", "id-external": ""}], "url": {"full": "URL#1241519", "pdf": ""}, "publisher-venue": "DASC/PiCom/DataCom/CyberSciTech", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1091403388, "title": "Fighting Fake News - Image Splice Detection via Learned Self-Consistency.", "abstract": "", "doi": "10.1007/978-3-030-01252-6_7", "date": "2018", "authors": [{"name": "Minyoung Huh", "id-internal": "220/3360", "id-external": ""}, {"name": "Andrew Liu", "id-internal": "21/501", "id-external": ""}, {"name": "Andrew Owens", "id-internal": "85/2697", "id-external": ""}, {"name": "Alexei A. Efros", "id-internal": "40/6158", "id-external": ""}], "url": {"full": "URL#1245920", "pdf": ""}, "publisher-venue": "ECCV", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2296292966, "title": "DeClarE - Debunking Fake News and False Claims using Evidence-Aware Deep Learning.", "abstract": "", "doi": "10.18653/v1/d18-1003", "date": "2018", "authors": [{"name": "Kashyap Popat", "id-internal": "136/8735", "id-external": ""}, {"name": "Subhabrata Mukherjee", "id-internal": "37/11030", "id-external": ""}, {"name": "Andrew Yates", "id-internal": "49/7109", "id-external": ""}, {"name": "Gerhard Weikum", "id-internal": "w/GerhardWeikum", "id-external": ""}], "url": {"full": "URL#1251869", "pdf": ""}, "publisher-venue": "EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3487875197, "title": "Detecting Fake News in Social Media Networks.", "abstract": "", "doi": "10.1016/j.procs.2018.10.171", "date": "2018", "authors": [{"name": "Monther Aldwairi", "id-internal": "38/5057", "id-external": ""}, {"name": "Ali Alwahedi", "id-internal": "233/1201", "id-external": ""}], "url": {"full": "URL#1255654", "pdf": ""}, "publisher-venue": "EUSPN/ICTH", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1987297457, "title": "Automatic Online Fake News Detection Combining Content and Social Signals.", "abstract": "", "doi": "10.23919/fruct.2018.8468301", "date": "2018", "authors": [{"name": "Marco L. Della Vedova", "id-internal": "93/7704", "id-external": ""}, {"name": "Eugenio Tacchini", "id-internal": "32/10636", "id-external": ""}, {"name": "Stefano Moret", "id-internal": "189/8761", "id-external": ""}, {"name": "Gabriele Ballarin", "id-internal": "199/2238", "id-external": ""}, {"name": "Massimo Di Pierro", "id-internal": "90/17", "id-external": ""}, {"name": "Luca de Alfaro", "id-internal": "d/LucadeAlfaro", "id-external": ""}], "url": {"full": "URL#1258905", "pdf": ""}, "publisher-venue": "FRUCT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2360740571, "title": "Exploring the Propagation of Fake Cyber News - An Experimental Approach.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Michele Maasberg", "id-internal": "160/9347", "id-external": ""}, {"name": "Emmanuel Ayaburi", "id-internal": "172/6923", "id-external": ""}, {"name": "Charles Liu", "id-internal": "91/4301", "id-external": ""}, {"name": "Yoris Au", "id-internal": "20/2567", "id-external": ""}], "url": {"full": "URL#1266210", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1184663184, "title": "A Tale of Two Internet News Platforms-Real vs. Fake - An Elaboration Likelihood Model Perspective.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Babajide Osatuyi", "id-internal": "24/8822", "id-external": ""}, {"name": "Jerald Hughes", "id-internal": "30/2263", "id-external": ""}], "url": {"full": "URL#1266283", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1789926876, "title": "Combating Fake News - An Investigation of Information Verification Behaviors on Social Networking Sites.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Russell Torres", "id-internal": "125/0542", "id-external": ""}, {"name": "Natalie Gerhart", "id-internal": "160/5824", "id-external": ""}, {"name": "Arash Negahban", "id-internal": "125/0756", "id-external": ""}], "url": {"full": "URL#1266441", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 99067622, "title": "Raising a Model for Fake News Detection Using Machine Learning in Python.", "abstract": "", "doi": "10.1007/978-3-030-02131-3_52", "date": "2018", "authors": [{"name": "Gerardo Ernesto Rolong Agudelo", "id-internal": "228/4037", "id-external": ""}, {"name": "Octavio Jos\u00e9 Salcedo Parra", "id-internal": "30/8275", "id-external": ""}, {"name": "Julio Bar\u00f3n Velandia", "id-internal": "228/4087", "id-external": ""}], "url": {"full": "URL#1268925", "pdf": ""}, "publisher-venue": "I3E", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4084677603, "title": "Evaluating Deep Neural Networks for Automatic Fake News Detection in Political Domain.", "abstract": "", "doi": "10.1007/978-3-030-03928-8_17", "date": "2018", "authors": [{"name": "Francis C. Fern\u00e1ndez-Reyes", "id-internal": "95/11423", "id-external": ""}, {"name": "Suraj Shinde", "id-internal": "229/5730", "id-external": ""}], "url": {"full": "URL#1269361", "pdf": ""}, "publisher-venue": "IBERAMIA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1269826008, "title": "The Fake News Challenge - Stance Detection using Traditional Machine Learning Approaches.", "abstract": "", "doi": "10.5220/0006898801260133", "date": "2018", "authors": [{"name": "Razan Masood", "id-internal": "227/0811", "id-external": ""}, {"name": "Ahmet Aker", "id-internal": "67/7965", "id-external": ""}], "url": {"full": "URL#1269812", "pdf": ""}, "publisher-venue": "KMIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4100084633, "title": "Flagging Fake News - System 1 vs. System 2.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Patricia L. Moravec", "id-internal": "231/0732", "id-external": ""}, {"name": "Antino Kim", "id-internal": "117/0007", "id-external": ""}, {"name": "Alan R. Dennis", "id-internal": "28/6832", "id-external": ""}], "url": {"full": "URL#1284764", "pdf": ""}, "publisher-venue": "ICIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3377082897, "title": "Fake News on Social Media - The (In)Effectiveness of Warning Messages.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Bj\u00f6rn Ross", "id-internal": "194/2453", "id-external": ""}, {"name": "Anna Jung", "id-internal": "231/0762", "id-external": ""}, {"name": "Jennifer Heisel", "id-internal": "231/0652", "id-external": ""}, {"name": "Stefan Stieglitz", "id-internal": "80/3271", "id-external": ""}], "url": {"full": "URL#1284803", "pdf": ""}, "publisher-venue": "ICIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3130524720, "title": "Neural User Response Generator - Fake News Detection with Collective User Intelligence.", "abstract": "", "doi": "10.24963/ijcai.2018/533", "date": "2018", "authors": [{"name": "Feng Qian", "id-internal": "54/476", "id-external": ""}, {"name": "ChengYue Gong", "id-internal": "209/4862", "id-external": ""}, {"name": "Karishma Sharma", "id-internal": "222/7902", "id-external": ""}, {"name": "Yan Liu 0002", "id-internal": "l/YanLiu2", "id-external": ""}], "url": {"full": "URL#1304225", "pdf": ""}, "publisher-venue": "IJCAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 418844408, "title": "Design Exploration of Fake News - A Transdisciplinary Methodological Approach to Understanding Content Sharing and Trust on Social Media.", "abstract": "", "doi": "10.1109/procomm.2018.00008", "date": "2018", "authors": [{"name": "Jaigris Hodson", "id-internal": "136/4629", "id-external": ""}, {"name": "Brian Traynor", "id-internal": "39/6596", "id-external": ""}], "url": {"full": "URL#1308622", "pdf": ""}, "publisher-venue": "ProComm", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 523620863, "title": "Identifying Tweets with Fake News.", "abstract": "", "doi": "10.1109/iri.2018.00073", "date": "2018", "authors": [{"name": "Saranya Krishnan", "id-internal": "224/0994", "id-external": ""}, {"name": "Min Chen 0009", "id-internal": "50/6996-9", "id-external": ""}], "url": {"full": "URL#1309655", "pdf": ""}, "publisher-venue": "IRI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3899708381, "title": "EANN - Event Adversarial Neural Networks for Multi-Modal Fake News Detection.", "abstract": "", "doi": "10.1145/3219819.3219903", "date": "2018", "authors": [{"name": "Yaqing Wang", "id-internal": "147/1393", "id-external": ""}, {"name": "Fenglong Ma", "id-internal": "85/10856", "id-external": ""}, {"name": "Zhiwei Jin", "id-internal": "136/1091", "id-external": ""}, {"name": "Ye Yuan 0006", "id-internal": "33/6315-6", "id-external": ""}, {"name": "Guangxu Xun", "id-internal": "127/0253", "id-external": ""}, {"name": "Kishlay Jha", "id-internal": "177/7445", "id-external": ""}, {"name": "Lu Su", "id-internal": "63/4152", "id-external": ""}, {"name": "Jing Gao 0004", "id-internal": "67/4834-4", "id-external": ""}], "url": {"full": "URL#1323227", "pdf": ""}, "publisher-venue": "KDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2917362826, "title": "Fake News and its Credibility Evaluation by Dynamic Relational Networks - A Bottom up Approach.", "abstract": "", "doi": "10.1016/j.procs.2018.07.226", "date": "2018", "authors": [{"name": "Yoshiteru Ishida", "id-internal": "70/1023", "id-external": ""}, {"name": "Sanae Kuraya", "id-internal": "231/5826", "id-external": ""}], "url": {"full": "URL#1323379", "pdf": ""}, "publisher-venue": "KES", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1747674392, "title": "Why do people believe in fake news over the Internet? An understanding from the perspective of existence of the habit of eating and drinking.", "abstract": "", "doi": "10.1016/j.procs.2018.08.107", "date": "2018", "authors": {"name": "Hiroko Kanoh", "id-internal": "137/6854", "id-external": ""}, "url": {"full": "URL#1323395", "pdf": ""}, "publisher-venue": "KES", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3944959050, "title": "Automatic and Manual Web Annotations in an Infrastructure to handle Fake News and other Online Media Phenomena.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Georg Rehm", "id-internal": "89/1527", "id-external": ""}, {"name": "Juli\u00e1n Moreno Schneider", "id-internal": "64/8420", "id-external": ""}, {"name": "Peter Bourgonje", "id-internal": "187/7470", "id-external": ""}], "url": {"full": "URL#1325825", "pdf": ""}, "publisher-venue": "LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3834687694, "title": "Media-Rich Fake News Detection - A Survey.", "abstract": "", "doi": "10.1109/mipr.2018.00093", "date": "2018", "authors": [{"name": "Shivam B. Parikh", "id-internal": "211/3838", "id-external": ""}, {"name": "Pradeep K. Atrey", "id-internal": "81/478", "id-external": ""}], "url": {"full": "URL#1330326", "pdf": ""}, "publisher-venue": "MIPR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 921713118, "title": "Understanding User Profiles on Social Media for Fake News Detection.", "abstract": "", "doi": "10.1109/mipr.2018.00092", "date": "2018", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#1330338", "pdf": ""}, "publisher-venue": "MIPR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2081160330, "title": "Contributions to the Study of Fake News in Portuguese - New Corpus and Automatic Detection Results.", "abstract": "", "doi": "10.1007/978-3-319-99722-3_33", "date": "2018", "authors": [{"name": "Rafael A. Monteiro", "id-internal": "226/3927", "id-external": ""}, {"name": "Roney L. S. Santos", "id-internal": "189/4600", "id-external": ""}, {"name": "Thiago A. S. Pardo", "id-internal": "31/4118", "id-external": ""}, {"name": "Tiago A. de Almeida", "id-internal": "04/2243", "id-external": ""}, {"name": "Evandro Eduardo Seron Ruiz", "id-internal": "54/9273", "id-external": ""}, {"name": "Oto A. Vale", "id-internal": "31/1655", "id-external": ""}], "url": {"full": "URL#1343300", "pdf": ""}, "publisher-venue": "PROPOR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3543047991, "title": "Beaten Up on Twitter? Exploring Fake News and Satirical Responses During the Black Panther Movie Event.", "abstract": "", "doi": "10.1007/978-3-319-93372-6_12", "date": "2018", "authors": [{"name": "Matthew Babcock", "id-internal": "222/4084", "id-external": ""}, {"name": "David M. Beskow", "id-internal": "222/3992", "id-external": ""}, {"name": "Kathleen M. Carley", "id-internal": "72/6492", "id-external": ""}], "url": {"full": "URL#1348281", "pdf": ""}, "publisher-venue": "SBP-BRiMS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3991625873, "title": "Content Based Fake News Detection Using Knowledge Graphs.", "abstract": "", "doi": "10.1007/978-3-030-00671-6_39", "date": "2018", "authors": [{"name": "Jeff Z. Pan", "id-internal": "59/6490", "id-external": ""}, {"name": "Siyana Pavlova", "id-internal": "227/0970", "id-external": ""}, {"name": "Chenxi Li", "id-internal": "90/7767", "id-external": ""}, {"name": "Ningxi Li", "id-internal": "150/0300", "id-external": ""}, {"name": "Yangmei Li", "id-internal": "53/7948", "id-external": ""}, {"name": "Jinshuo Liu", "id-internal": "83/6089", "id-external": ""}], "url": {"full": "URL#1350414", "pdf": ""}, "publisher-venue": "International Semantic Web Conference", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 881852986, "title": "Epistemology in the Cloud - On Fake News and Digital Sovereignty.", "abstract": "", "doi": "", "date": "2018", "authors": {"name": "Henry Joseph Story", "id-internal": "225/2141", "id-external": ""}, "url": {"full": "URL#1350492", "pdf": ""}, "publisher-venue": "DeSemWeb@ISWC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1481429868, "title": "The Rise of Guardians - Fact-checking URL Recommendation to Combat Fake News.", "abstract": "", "doi": "10.1145/3209978.3210037", "date": "2018", "authors": [{"name": "Nguyen Vo", "id-internal": "167/0323", "id-external": ""}, {"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}], "url": {"full": "URL#1352675", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 545984962, "title": "Research on Text Classification for Identifying Fake News.", "abstract": "", "doi": "10.1109/spac46244.2018.8965536", "date": "2018", "authors": [{"name": "Shenhao Zhang", "id-internal": "257/9767", "id-external": ""}, {"name": "Yihui Wang", "id-internal": "30/7591", "id-external": ""}, {"name": "Chengxiang Tan", "id-internal": "11/2755", "id-external": ""}], "url": {"full": "URL#1357833", "pdf": ""}, "publisher-venue": "SPAC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2280527983, "title": "A Tool for Fake News Detection.", "abstract": "", "doi": "10.1109/synasc.2018.00064", "date": "2018", "authors": [{"name": "Bashar Al Asaad", "id-internal": "244/0525", "id-external": ""}, {"name": "Madalina Erascu", "id-internal": "16/9868", "id-external": ""}], "url": {"full": "URL#1360128", "pdf": ""}, "publisher-venue": "SYNASC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2750265154, "title": "'Let's Fake News'.", "abstract": "", "doi": "10.1145/3173225.3173318", "date": "2018", "authors": {"name": "L\u00e9on McCarthy", "id-internal": "216/3267", "id-external": ""}, "url": {"full": "URL#1361368", "pdf": ""}, "publisher-venue": "Tangible and Embedded Interaction", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 367754944, "title": "FaNDeR - Fake News Detection Model Using Media Reliability.", "abstract": "", "doi": "10.1109/tencon.2018.8650350", "date": "2018", "authors": [{"name": "Youngkyung Seo", "id-internal": "245/6951", "id-external": ""}, {"name": "Deokjin Seo", "id-internal": "245/6985", "id-external": ""}, {"name": "Chang-Sung Jeong", "id-internal": "58/1148", "id-external": ""}], "url": {"full": "URL#1361824", "pdf": ""}, "publisher-venue": "TENCON", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3377832291, "title": "Checking Fake News on Web Browsers - An Approach Using Collaborative Datasets.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Anderson Cordeiro", "id-internal": "230/1405", "id-external": ""}, {"name": "Jonice Oliveira", "id-internal": "o/JoniceOliveira", "id-external": ""}], "url": {"full": "URL#1365303", "pdf": ""}, "publisher-venue": "BiDu-Posters@VLDB", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3824710358, "title": "A First Step Towards Combating Fake News over Online Social Media.", "abstract": "", "doi": "10.1007/978-3-319-94268-1_43", "date": "2018", "authors": [{"name": "Kuai Xu", "id-internal": "x/KuaiXu", "id-external": ""}, {"name": "Feng Wang 0002", "id-internal": "w/FengWang2", "id-external": ""}, {"name": "Haiyan Wang", "id-internal": "27/59", "id-external": ""}, {"name": "Bo Yang", "id-internal": "46/999", "id-external": ""}], "url": {"full": "URL#1368046", "pdf": ""}, "publisher-venue": "WASA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2671648120, "title": "Current State of the Art to Detect Fake News in Social Media - Global Trendings and Next Challenges.", "abstract": "", "doi": "10.5220/0007188503320339", "date": "2018", "authors": [{"name": "\u00c1lvaro Figueira 0001", "id-internal": "77/4827", "id-external": ""}, {"name": "Nuno Guimar\u00e3es", "id-internal": "39/1045", "id-external": ""}, {"name": "Lu\u00eds Torgo", "id-internal": "60/1153", "id-external": ""}], "url": {"full": "URL#1369536", "pdf": ""}, "publisher-venue": "WEBIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3405045323, "title": "Fake News vs Satire - A Dataset and Analysis.", "abstract": "", "doi": "10.1145/3201064.3201100", "date": "2018", "authors": [{"name": "Jennifer Golbeck", "id-internal": "48/2412", "id-external": ""}, {"name": "Matthew Louis Mauriello", "id-internal": "14/11456", "id-external": ""}, {"name": "Brooke Auxier", "id-internal": "205/3282", "id-external": ""}, {"name": "Keval H. Bhanushali", "id-internal": "219/5428", "id-external": ""}, {"name": "Christopher Bonk", "id-internal": "219/5260", "id-external": ""}, {"name": "Mohamed Amine Bouzaghrane", "id-internal": "219/5322", "id-external": ""}, {"name": "Cody Buntain", "id-internal": "34/7214", "id-external": ""}, {"name": "Riya Chanduka", "id-internal": "219/5306", "id-external": ""}, {"name": "Paul Cheakalos", "id-internal": "203/0208", "id-external": ""}, {"name": "Jennine B. Everett", "id-internal": "219/5517", "id-external": ""}, {"name": "Waleed Falak", "id-internal": "213/1440", "id-external": ""}, {"name": "Carl Gieringer", "id-internal": "219/5512", "id-external": ""}, {"name": "Jack Graney", "id-internal": "219/5533", "id-external": ""}, {"name": "Kelly M. Hoffman", "id-internal": "203/0232", "id-external": ""}, {"name": "Lindsay Huth", "id-internal": "219/5408", "id-external": ""}, {"name": "Zhenya Ma", "id-internal": "219/5547", "id-external": ""}, {"name": "Mayanka Jha", "id-internal": "213/1507", "id-external": ""}, {"name": "Misbah Khan", "id-internal": "219/5635", "id-external": ""}, {"name": "Varsha Kori", "id-internal": "219/5689", "id-external": ""}, {"name": "Elo Lewis", "id-internal": "219/5699", "id-external": ""}, {"name": "George Mirano", "id-internal": "219/5382", "id-external": ""}, {"name": "William T. Mohn IV", "id-internal": "219/5369", "id-external": ""}, {"name": "Sean Mussenden", "id-internal": "219/5299", "id-external": ""}, {"name": "Tammie M. Nelson", "id-internal": "219/5579", "id-external": ""}, {"name": "Sean Mcwillie", "id-internal": "219/5509", "id-external": ""}, {"name": "Akshat Pant", "id-internal": "219/5383", "id-external": ""}, {"name": "Priya Shetye", "id-internal": "219/5653", "id-external": ""}, {"name": "Rusha Shrestha", "id-internal": "219/5447", "id-external": ""}, {"name": "Alexandra Steinheimer", "id-internal": "219/5265", "id-external": ""}, {"name": "Aditya Subramanian", "id-internal": "217/3188", "id-external": ""}, {"name": "Gina Visnansky", "id-internal": "219/5600", "id-external": ""}], "url": {"full": "URL#1369660", "pdf": ""}, "publisher-venue": "WebSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1746198004, "title": "DUAL - A Deep Unified Attention Model with Latent Relation Representations for Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-02922-7_14", "date": "2018", "authors": [{"name": "Manqing Dong", "id-internal": "220/3088", "id-external": ""}, {"name": "Lina Yao", "id-internal": "56/6651", "id-external": ""}, {"name": "Xianzhi Wang 0001", "id-internal": "51/8330", "id-external": ""}, {"name": "Boualem Benatallah", "id-internal": "b/BoualemBenatallah", "id-external": ""}, {"name": "Quan Z. Sheng", "id-internal": "s/QuanZSheng", "id-external": ""}, {"name": "Hao Huang", "id-internal": "04/5616", "id-external": ""}], "url": {"full": "URL#1370797", "pdf": ""}, "publisher-venue": "WISE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2281635868, "title": "Social Context-Aware Trust Prediction - Methods for Identifying Fake News.", "abstract": "", "doi": "10.1007/978-3-030-02922-7_11", "date": "2018", "authors": [{"name": "Seyed Mohssen Ghafari", "id-internal": "138/0067", "id-external": ""}, {"name": "Shahpar Yakhchi", "id-internal": "204/2461", "id-external": ""}, {"name": "Amin Beheshti", "id-internal": "90/10041", "id-external": ""}, {"name": "Mehmet A. Orgun", "id-internal": "o/MehmetAOrgun", "id-external": ""}], "url": {"full": "URL#1370802", "pdf": ""}, "publisher-venue": "WISE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 422180469, "title": "Leveraging the Crowd to Detect and Reduce the Spread of Fake News and Misinformation.", "abstract": "", "doi": "10.1145/3159652.3159734", "date": "2018", "authors": [{"name": "Jooyeon Kim", "id-internal": "64/9560", "id-external": ""}, {"name": "Behzad Tabibian", "id-internal": "70/9714", "id-external": ""}, {"name": "Alice Oh", "id-internal": "50/7562", "id-external": ""}, {"name": "Bernhard Sch\u00f6lkopf", "id-internal": "97/119", "id-external": ""}, {"name": "Manuel Gomez-Rodriguez", "id-internal": "73/8260", "id-external": ""}], "url": {"full": "URL#1372544", "pdf": ""}, "publisher-venue": "WSDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 131069863, "title": "Tracing Fake-News Footprints - Characterizing Social Media Messages by How They Propagate.", "abstract": "", "doi": "10.1145/3159652.3159677", "date": "2018", "authors": [{"name": "Liang Wu 0006", "id-internal": "20/5233-6", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#1372597", "pdf": ""}, "publisher-venue": "WSDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 263361987, "title": "Satire or Fake News - Social Media Consumers' Socio-Demographics Decide.", "abstract": "", "doi": "10.1145/3184558.3188732", "date": "2018", "authors": [{"name": "Michele Bedard", "id-internal": "218/0483", "id-external": ""}, {"name": "Chianna Schoenthaler", "id-internal": "218/0130", "id-external": ""}], "url": {"full": "URL#1372770", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4289108797, "title": "Combining Neural, Statistical and External Features for Fake News Stance Identification.", "abstract": "", "doi": "10.1145/3184558.3191577", "date": "2018", "authors": [{"name": "Gaurav Bhatt", "id-internal": "173/8402", "id-external": ""}, {"name": "Aman Sharma", "id-internal": "211/6908", "id-external": ""}, {"name": "Shivam Sharma", "id-internal": "146/2381", "id-external": ""}, {"name": "Ankush Nagpal", "id-internal": "211/7004", "id-external": ""}, {"name": "Balasubramanian Raman", "id-internal": "57/6641", "id-external": ""}, {"name": "Ankush Mittal", "id-internal": "78/6048", "id-external": ""}], "url": {"full": "URL#1372779", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1276245151, "title": "Fake News Detection in Social Networks via Crowd Signals.", "abstract": "", "doi": "10.1145/3184558.3188722", "date": "2018", "authors": [{"name": "Sebastian Tschiatschek", "id-internal": "33/10810", "id-external": ""}, {"name": "Adish Singla", "id-internal": "58/657", "id-external": ""}, {"name": "Manuel Gomez-Rodriguez", "id-internal": "73/8260", "id-external": ""}, {"name": "Arpit Merchant", "id-internal": "178/3551", "id-external": ""}, {"name": "Andreas Krause 0001", "id-internal": "87/1831-1", "id-external": ""}], "url": {"full": "URL#1373225", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2359737311, "title": "Is this the Era of Misinformation yet - Combining Social Bots and Fake News to Deceive the Masses.", "abstract": "", "doi": "10.1145/3184558.3191610", "date": "2018", "authors": [{"name": "Patrick Wang 0002", "id-internal": "36/4574-2", "id-external": ""}, {"name": "Rafael Angarita", "id-internal": "117/5074", "id-external": ""}, {"name": "Ilaria Renna", "id-internal": "28/7627", "id-external": ""}], "url": {"full": "URL#1373240", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3106711353, "title": "Polarization and Fake News - Early Warning of Potential Misinformation Targets.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Michela Del Vicario", "id-internal": "151/6677", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}, {"name": "Antonio Scala", "id-internal": "92/9669", "id-external": ""}, {"name": "Fabiana Zollo", "id-internal": "60/9927", "id-external": ""}], "url": {"full": "URL#1384393", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2801812731, "title": "We Built a Fake News & Click-bait Filter - What Happened Next Will Blow Your Mind!", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Georgi Karadzhov", "id-internal": "205/1966", "id-external": ""}, {"name": "Pepa Gencheva", "id-internal": "184/2024", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Ivan Koychev", "id-internal": "88/2617", "id-external": ""}], "url": {"full": "URL#1388163", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1278198895, "title": "Influence of fake news in Twitter during the 2016 US presidential election.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Alexandre Bovet", "id-internal": "188/6446", "id-external": ""}, {"name": "Hern\u00e1n A. Makse", "id-internal": "65/1138", "id-external": ""}], "url": {"full": "URL#1389503", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3408319053, "title": "A Bayesian Model for False Information Belief Impact, Optimal Design, and Fake News Containment.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Amin Khajehnejad", "id-internal": "217/1835", "id-external": ""}, {"name": "Shima Hajimirza", "id-internal": "217/1817", "id-external": ""}], "url": {"full": "URL#1390817", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 914521351, "title": "Incentivizing the Dissemination of Truth Versus Fake News in Social Networks.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Abbas Ehsanfar", "id-internal": "185/0973", "id-external": ""}, {"name": "Mo Mansouri", "id-internal": "46/8093", "id-external": ""}], "url": {"full": "URL#1391080", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 501209515, "title": "The Web of False Information - Rumors, Fake News, Hoaxes, Clickbait, and Various Other Shenanigans.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Savvas Zannettou", "id-internal": "184/5969", "id-external": ""}, {"name": "Michael Sirivianos", "id-internal": "92/5463", "id-external": ""}, {"name": "Jeremy Blackburn", "id-internal": "12/8780", "id-external": ""}, {"name": "Nicolas Kourtellis", "id-internal": "96/8779", "id-external": ""}], "url": {"full": "URL#1391393", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2134723172, "title": "Seeing Through Misinformation - A Framework for Identifying Fake Online News.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Murphy Choy", "id-internal": "19/10045", "id-external": ""}, {"name": "Mark Chong", "id-internal": "218/5161", "id-external": ""}], "url": {"full": "URL#1391405", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2457868301, "title": "Studying Fake News via Network Analysis - Detection and Mitigation.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "H. Russell Bernard", "id-internal": "135/4233", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#1393443", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1289079058, "title": "Fighting Fake News - Image Splice Detection via Learned Self-Consistency.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Minyoung Huh", "id-internal": "220/3360", "id-external": ""}, {"name": "Andrew Liu", "id-internal": "21/501", "id-external": ""}, {"name": "Andrew Owens", "id-internal": "85/2697", "id-external": ""}, {"name": "Alexei A. Efros", "id-internal": "40/6158", "id-external": ""}], "url": {"full": "URL#1394958", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3277828447, "title": "Fake News Detection with Deep Diffusive Network Model.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Jiawei Zhang 0001", "id-internal": "10/239-1", "id-external": ""}, {"name": "Limeng Cui", "id-internal": "147/6826", "id-external": ""}, {"name": "Yanjie Fu", "id-internal": "134/3987", "id-external": ""}, {"name": "Fisher B. Gouza", "id-internal": "217/2172", "id-external": ""}], "url": {"full": "URL#1396425", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2788098938, "title": "TI-CNN - Convolutional Neural Networks for Fake News Detection.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Yang Yang", "id-internal": "48/450", "id-external": ""}, {"name": "Lei Zheng 0001", "id-internal": "86/5344-1", "id-external": ""}, {"name": "Jiawei Zhang 0001", "id-internal": "10/239-1", "id-external": ""}, {"name": "Qingcai Cui", "id-internal": "222/1845", "id-external": ""}, {"name": "Zhoujun Li 0001", "id-internal": "76/2866-1", "id-external": ""}, {"name": "Philip S. Yu", "id-internal": "y/PhilipSYu", "id-external": ""}], "url": {"full": "URL#1397878", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1347584674, "title": "A Retrospective Analysis of the Fake News Challenge Stance Detection Task.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Andreas Hanselowski", "id-internal": "215/6859", "id-external": ""}, {"name": "Avinesh P. V. S.", "id-internal": "70/8153", "id-external": ""}, {"name": "Benjamin Schiller", "id-internal": "55/8733", "id-external": ""}, {"name": "Felix Caspelherr", "id-internal": "222/1846", "id-external": ""}, {"name": "Debanjan Chaudhuri", "id-internal": "213/7337", "id-external": ""}, {"name": "Christian M. Meyer", "id-internal": "18/7930", "id-external": ""}, {"name": "Iryna Gurevych", "id-internal": "85/6201", "id-external": ""}], "url": {"full": "URL#1399245", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2533801606, "title": "The Rise of Guardians - Fact-checking URL Recommendation to Combat Fake News.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Nguyen Vo", "id-internal": "167/0323", "id-external": ""}, {"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}], "url": {"full": "URL#1399958", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 352369760, "title": "Fake News Identification on Twitter with Hybrid CNN and RNN Models.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Oluwaseun Ajao", "id-internal": "173/0924", "id-external": ""}, {"name": "Deepayan Bhowmik", "id-internal": "44/7616", "id-external": ""}, {"name": "Shahrzad Zargari", "id-internal": "122/8657", "id-external": ""}], "url": {"full": "URL#1400961", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1916630441, "title": "Debunking Fake News One Feature at a Time.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Melanie Tosik", "id-internal": "185/5611", "id-external": ""}, {"name": "Antonio Mallia", "id-internal": "204/0179", "id-external": ""}, {"name": "Kedar Gangopadhyay", "id-internal": "222/8341", "id-external": ""}], "url": {"full": "URL#1405370", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1512550653, "title": "Limiting the Spread of Fake News on Social Media Platforms by Evaluating Users' Trustworthiness.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Oana Balmau", "id-internal": "157/1134", "id-external": ""}, {"name": "Rachid Guerraoui", "id-internal": "g/RachidGuerraoui", "id-external": ""}, {"name": "Anne-Marie Kermarrec", "id-internal": "86/676", "id-external": ""}, {"name": "Alexandre Maurer", "id-internal": "01/10825", "id-external": ""}, {"name": "Matej Pavlovic", "id-internal": "178/5515", "id-external": ""}, {"name": "Willy Zwaenepoel", "id-internal": "z/WZwaenepoel", "id-external": ""}], "url": {"full": "URL#1407375", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2883675691, "title": "Belittling the Source - Trustworthiness Indicators to Obfuscate Fake News on the Web.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Diego Esteves", "id-internal": "168/1466", "id-external": ""}, {"name": "Aniketh Janardhan Reddy", "id-internal": "216/9333", "id-external": ""}, {"name": "Piyush Chawla", "id-internal": "227/3228", "id-external": ""}, {"name": "Jens Lehmann 0001", "id-internal": "71/4882", "id-external": ""}], "url": {"full": "URL#1407784", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1392822005, "title": "How to model fake news.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Dorje C. Brody", "id-internal": "29/3790", "id-external": ""}, {"name": "David M. Meier", "id-internal": "118/8030", "id-external": ""}], "url": {"full": "URL#1407940", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4027236904, "title": "CIMTDetect - A Community Infused Matrix-Tensor Coupled Factorization Based Method for Fake News Detection.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Shashank Gupta 0006", "id-internal": "89/5046-6", "id-external": ""}, {"name": "Raghuveer Thirukovalluru", "id-internal": "205/0092", "id-external": ""}, {"name": "Manjira Sinha", "id-internal": "127/0162", "id-external": ""}, {"name": "Sandya Mannarswamy", "id-internal": "73/3305", "id-external": ""}], "url": {"full": "URL#1409263", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2154480272, "title": "DeClarE - Debunking Fake News and False Claims using Evidence-Aware Deep Learning.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Kashyap Popat", "id-internal": "136/8735", "id-external": ""}, {"name": "Subhabrata Mukherjee", "id-internal": "37/11030", "id-external": ""}, {"name": "Andrew Yates", "id-internal": "49/7109", "id-external": ""}, {"name": "Gerhard Weikum", "id-internal": "w/GerhardWeikum", "id-external": ""}], "url": {"full": "URL#1409646", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1343610013, "title": "Combining Similarity Features and Deep Representation Learning for Stance Detection in the Context of Checking Fake News.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Lu\u00eds Borges", "id-internal": "230/3717", "id-external": ""}, {"name": "Bruno Martins 0001", "id-internal": "m/BrunoMartins", "id-external": ""}, {"name": "P\u00e1vel Calado", "id-internal": "72/6044", "id-external": ""}], "url": {"full": "URL#1415129", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1508581111, "title": "A Survey on Natural Language Processing for Fake News Detection.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Ray Oshikawa", "id-internal": "230/3700", "id-external": ""}, {"name": "Jing Qian", "id-internal": "71/944", "id-external": ""}, {"name": "William Yang Wang", "id-internal": "08/9282", "id-external": ""}], "url": {"full": "URL#1415153", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1269378490, "title": "A Deep Ensemble Framework for Fake News Detection and Classification.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Arjun Roy", "id-internal": "42/9448", "id-external": ""}, {"name": "Kingshuk Basak", "id-internal": "230/3932", "id-external": ""}, {"name": "Asif Ekbal", "id-internal": "11/3590", "id-external": ""}, {"name": "Pushpak Bhattacharyya", "id-internal": "p/PushpakBhattacharyya", "id-external": ""}], "url": {"full": "URL#1416484", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3116757925, "title": "Fake News - A Survey of Research, Detection Methods, and Opportunities.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}], "url": {"full": "URL#1419153", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3521802670, "title": "Fake News - A Technological Approach to Proving the Origins of Content, Using Blockchains.", "abstract": "", "doi": "10.1089/big.2017.0071", "date": "2017", "authors": [{"name": "Steve Huckle", "id-internal": "191/9120", "id-external": ""}, {"name": "Martin White", "id-internal": "56/1682", "id-external": ""}], "url": {"full": "URL#1438538", "pdf": ""}, "publisher-venue": "Big Data", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1566052899, "title": "Lies, Damn Lies, and Fake News.", "abstract": "", "doi": "10.1109/mc.2017.56", "date": "2017", "authors": {"name": "Hal Berghel", "id-internal": "b/HalBerghel", "id-external": ""}, "url": {"full": "URL#1450531", "pdf": ""}, "publisher-venue": "Computer", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2661673680, "title": "Oh, What a Tangled Web - Russian Hacking, Fake News, and the 2016 US Presidential Election.", "abstract": "", "doi": "10.1109/mc.2017.3571054", "date": "2017", "authors": {"name": "Hal Berghel", "id-internal": "b/HalBerghel", "id-external": ""}, "url": {"full": "URL#1450536", "pdf": ""}, "publisher-venue": "Computer", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3079308933, "title": "Fake News und Providerhaftung.", "abstract": "", "doi": "10.9785/cr-2017-1209", "date": "2017", "authors": {"name": "Karl-Nikolaus Peifer", "id-internal": "221/5308", "id-external": ""}, "url": {"full": "URL#1452156", "pdf": ""}, "publisher-venue": "Comput. und Recht", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2897525555, "title": "Filter bubbles and fake news.", "abstract": "", "doi": "10.1145/3055153", "date": "2017", "authors": [{"name": "Dominic DiFranzo", "id-internal": "04/8024", "id-external": ""}, {"name": "Marie Joan Kristine Gloria", "id-internal": "130/0484", "id-external": ""}], "url": {"full": "URL#1452314", "pdf": ""}, "publisher-venue": "XRDS", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 785832270, "title": "Navigating an Immersive Narratology - Factors to Explain the Reception of Fake News.", "abstract": "", "doi": "10.4018/ijep.2017070102", "date": "2017", "authors": {"name": "Bradley E. Wiggins", "id-internal": "171/4276", "id-external": ""}, "url": {"full": "URL#1474907", "pdf": ""}, "publisher-venue": "Int. J. E Politics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3072811046, "title": "Information Re-Sharing on Social Network Sites in the Age of Fake News.", "abstract": "", "doi": "10.28945/3871", "date": "2017", "authors": [{"name": "Mehrdad Koohikamali", "id-internal": "160/5821", "id-external": ""}, {"name": "Anna Sidorova", "id-internal": "89/8215", "id-external": ""}], "url": {"full": "URL#1483611", "pdf": ""}, "publisher-venue": "Informing Sci. Int. J. an Emerg. Transdiscipl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 639828079, "title": "Fake-News - K\u00f6nnen Algorithmen Menschen manipulieren?", "abstract": "", "doi": "10.1007/s00287-017-1060-3", "date": "2017", "authors": [{"name": "Agata Kr\u00f3likowski", "id-internal": "118/9910", "id-external": ""}, {"name": "Jens-Martin Loebel", "id-internal": "58/916", "id-external": ""}], "url": {"full": "URL#1483895", "pdf": ""}, "publisher-venue": "Inform. Spektrum", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4079380988, "title": "The medium is the fake news.", "abstract": "", "doi": "10.1145/3064776", "date": "2017", "authors": {"name": "Jonathan Bean", "id-internal": "18/5368", "id-external": ""}, "url": {"full": "URL#1484137", "pdf": ""}, "publisher-venue": "Interactions", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1124448721, "title": "The Economics of \"Fake News\".", "abstract": "", "doi": "10.1109/mitp.2017.4241459", "date": "2017", "authors": [{"name": "Nir Kshetri", "id-internal": "76/526", "id-external": ""}, {"name": "Jeffrey M. Voas", "id-internal": "27/5522", "id-external": ""}], "url": {"full": "URL#1487131", "pdf": ""}, "publisher-venue": "IT Prof.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3175616432, "title": "Fake news - belief in post-truth.", "abstract": "", "doi": "10.1108/lht-03-2017-0062", "date": "2017", "authors": {"name": "Nick Rochlin", "id-internal": "206/3616", "id-external": ""}, "url": {"full": "URL#1505086", "pdf": ""}, "publisher-venue": "Libr. Hi Tech", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3748107809, "title": "Fake News Detection on Social Media - A Data Mining Perspective.", "abstract": "", "doi": "10.1145/3137597.3137600", "date": "2017", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Amy Sliva", "id-internal": "67/3213", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Jiliang Tang", "id-internal": "64/10812", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#1528050", "pdf": ""}, "publisher-venue": "SIGKDD Explor.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2944309586, "title": "\"Liar, Liar Pants on Fire\" - A New Benchmark Dataset for Fake News Detection.", "abstract": "", "doi": "10.18653/v1/p17-2067", "date": "2017", "authors": {"name": "William Yang Wang", "id-internal": "08/9282", "id-external": ""}, "url": {"full": "URL#1557742", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1854537977, "title": "Combatting Fake News - An Investigation of Individuals' Information Verification Behaviors on Social Networking Sites.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Natalie Gerhart", "id-internal": "160/5824", "id-external": ""}, {"name": "Russell Torres", "id-internal": "125/0542", "id-external": ""}, {"name": "Arash Negahban", "id-internal": "125/0756", "id-external": ""}], "url": {"full": "URL#1563024", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1863863020, "title": "Digital literacy in the era of fake news - Key roles for information professionals.", "abstract": "", "doi": "10.1002/pra2.2017.14505401070", "date": "2017", "authors": [{"name": "Lynn Silipigni Connaway", "id-internal": "57/3056", "id-external": ""}, {"name": "Heidi E. Julien", "id-internal": "87/1100", "id-external": ""}, {"name": "Michael Seadle", "id-internal": "73/7470", "id-external": ""}, {"name": "Alex Kasprak", "id-internal": "224/3132", "id-external": ""}], "url": {"full": "URL#1566696", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3520888538, "title": "Human values and trust in scientific journals, the mainstream media and fake news.", "abstract": "", "doi": "10.1002/pra2.2017.14505401046", "date": "2017", "authors": [{"name": "Nitin Verma", "id-internal": "131/4174", "id-external": ""}, {"name": "Kenneth R. Fleischmann", "id-internal": "87/6899", "id-external": ""}, {"name": "Kolina Koltai", "id-internal": "144/5709", "id-external": ""}], "url": {"full": "URL#1566829", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1778760363, "title": "Fighting fake news spread in online social networks - Actual trends and future research directions.", "abstract": "", "doi": "10.1109/bigdata.2017.8258484", "date": "2017", "authors": [{"name": "Alina Campan", "id-internal": "63/4876", "id-external": ""}, {"name": "Alfredo Cuzzocrea", "id-internal": "c/AlfredoCuzzocrea", "id-external": ""}, {"name": "Traian Marius Truta", "id-internal": "26/3228", "id-external": ""}], "url": {"full": "URL#1570462", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 159150291, "title": "Geographic and Temporal Trends in Fake News Consumption During the 2016 US Presidential Election.", "abstract": "", "doi": "10.1145/3132847.3133147", "date": "2017", "authors": [{"name": "Adam Fourney", "id-internal": "60/863", "id-external": ""}, {"name": "Mikl\u00f3s Z. R\u00e1cz", "id-internal": "33/10360", "id-external": ""}, {"name": "Gireeja Ranade", "id-internal": "60/11151", "id-external": ""}, {"name": "Markus Mobius", "id-internal": "86/8355", "id-external": ""}, {"name": "Eric Horvitz", "id-internal": "h/EricHorvitz", "id-external": ""}], "url": {"full": "URL#1581137", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2317383862, "title": "Fake News and False Corroboration - Interactivity in Rumor Networks.", "abstract": "", "doi": "", "date": "2017", "authors": {"name": "Michael J. Spivey", "id-internal": "35/578", "id-external": ""}, "url": {"full": "URL#1584736", "pdf": ""}, "publisher-venue": "CogSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3541981091, "title": "From Clickbait to Fake News Detection - An Approach based on Detecting the Stance of Headlines to Articles.", "abstract": "", "doi": "10.18653/v1/w17-4215", "date": "2017", "authors": [{"name": "Peter Bourgonje", "id-internal": "187/7470", "id-external": ""}, {"name": "Juli\u00e1n Moreno Schneider", "id-internal": "64/8420", "id-external": ""}, {"name": "Georg Rehm", "id-internal": "89/1527", "id-external": ""}], "url": {"full": "URL#1599314", "pdf": ""}, "publisher-venue": "NLPmJ@EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3521917773, "title": "Truth of Varying Shades - Analyzing Language in Fake News and Political Fact-Checking.", "abstract": "", "doi": "10.18653/v1/d17-1317", "date": "2017", "authors": [{"name": "Hannah Rashkin", "id-internal": "164/6090", "id-external": ""}, {"name": "Eunsol Choi", "id-internal": "116/2765", "id-external": ""}, {"name": "Jin Yea Jang", "id-internal": "161/3212", "id-external": ""}, {"name": "Svitlana Volkova", "id-internal": "19/8609", "id-external": ""}, {"name": "Yejin Choi", "id-internal": "89/579", "id-external": ""}], "url": {"full": "URL#1599557", "pdf": ""}, "publisher-venue": "EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1479750834, "title": "Fake news stance detection using stacked ensemble of classifiers.", "abstract": "", "doi": "10.18653/v1/w17-4214", "date": "2017", "authors": [{"name": "James Thorne", "id-internal": "204/1380", "id-external": ""}, {"name": "Mingjie Chen", "id-internal": "87/7674", "id-external": ""}, {"name": "Giorgos Myrianthous", "id-internal": "205/9161", "id-external": ""}, {"name": "Jiashu Pu", "id-internal": "205/9148", "id-external": ""}, {"name": "Xiaoxuan Wang", "id-internal": "76/8875", "id-external": ""}, {"name": "Andreas Vlachos 0001", "id-internal": "18/1071-1", "id-external": ""}], "url": {"full": "URL#1599618", "pdf": ""}, "publisher-venue": "NLPmJ@EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 687896559, "title": "An Infrastructure for Empowering Internet Users to Handle Fake News and Other Online Media Phenomena.", "abstract": "", "doi": "10.1007/978-3-319-73706-5_19", "date": "2017", "authors": {"name": "Georg Rehm", "id-internal": "89/1527", "id-external": ""}, "url": {"full": "URL#1609420", "pdf": ""}, "publisher-venue": "GSCL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2016011631, "title": "Crowdsourcing the Verification of Fake News and Alternative Facts.", "abstract": "", "doi": "10.1145/3078714.3078746", "date": "2017", "authors": {"name": "Ricky J. Sethi", "id-internal": "69/8616", "id-external": ""}, "url": {"full": "URL#1615598", "pdf": ""}, "publisher-venue": "HT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 865958429, "title": "Is Fake News Profitable? The Effect of Distorting Pre-IPO Financing on IPO Performance of Internet Firms.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Ya hui Sun", "id-internal": "211/0832", "id-external": ""}, {"name": "Jin Zhou", "id-internal": "98/2691", "id-external": ""}, {"name": "Zhe Qu", "id-internal": "48/2774", "id-external": ""}, {"name": "Cheng Zhang 0001", "id-internal": "82/6384-1", "id-external": ""}], "url": {"full": "URL#1632555", "pdf": ""}, "publisher-venue": "ICIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3791297062, "title": "Fake News Mitigation via Point Process Based Intervention.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Mehrdad Farajtabar", "id-internal": "21/9988", "id-external": ""}, {"name": "Jiachen Yang", "id-internal": "120/3255", "id-external": ""}, {"name": "Xiaojing Ye", "id-internal": "01/2390", "id-external": ""}, {"name": "Huan Xu", "id-internal": "35/2843", "id-external": ""}, {"name": "Rakshit Trivedi", "id-internal": "184/0005", "id-external": ""}, {"name": "Elias B. Khalil", "id-internal": "151/3240", "id-external": ""}, {"name": "Shuang Li 0002", "id-internal": "43/6294-2", "id-external": ""}, {"name": "Le Song", "id-internal": "94/3481", "id-external": ""}, {"name": "Hongyuan Zha", "id-internal": "z/HongyuanZha", "id-external": ""}], "url": {"full": "URL#1634657", "pdf": ""}, "publisher-venue": "ICML", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 500260241, "title": "3HAN - A Deep Neural Network for Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-319-70096-0_59", "date": "2017", "authors": [{"name": "Sneha Singhania", "id-internal": "208/4715", "id-external": ""}, {"name": "Nigel Fernandez", "id-internal": "208/4804", "id-external": ""}, {"name": "Shrisha Rao", "id-internal": "88/3599", "id-external": ""}], "url": {"full": "URL#1637124", "pdf": ""}, "publisher-venue": "ICONIP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2767340121, "title": "Spotting Fake News - A Social Argumentation Framework for Scrutinizing Alternative Facts.", "abstract": "", "doi": "10.1109/icws.2017.108", "date": "2017", "authors": {"name": "Ricky J. Sethi", "id-internal": "69/8616", "id-external": ""}, "url": {"full": "URL#1643605", "pdf": ""}, "publisher-venue": "ICWS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3237661488, "title": "Fake News Detection Through Multi-Perspective Speaker Profiles.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Yunfei Long", "id-internal": "168/4623", "id-external": ""}, {"name": "Qin Lu 0001", "id-internal": "29/766-1", "id-external": ""}, {"name": "Rong Xiang", "id-internal": "05/7808", "id-external": ""}, {"name": "Minglei Li 0001", "id-internal": "136/7341-1", "id-external": ""}, {"name": "Chu-Ren Huang", "id-internal": "49/1619", "id-external": ""}], "url": {"full": "URL#1650538", "pdf": ""}, "publisher-venue": "IJCNLP(2)", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4073723879, "title": "Tidal wave of fake news ruins thousands of student projects! - Navigating technical and professional writing in the misinformation age.", "abstract": "", "doi": "10.1109/ipcc.2017.8013972", "date": "2017", "authors": [{"name": "Sarah Summers", "id-internal": "167/5744", "id-external": ""}, {"name": "Bill Riley", "id-internal": "190/0070", "id-external": ""}], "url": {"full": "URL#1654959", "pdf": ""}, "publisher-venue": "ProComm", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1501407109, "title": "Rumors, Fake News and Social Bots in Conflicts and Emergencies - Towards a Model for Believability in Social Media.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Christian Reuter 0001", "id-internal": "79/3736", "id-external": ""}, {"name": "Marc-Andr\u00e9 Kaufhold", "id-internal": "160/3032", "id-external": ""}, {"name": "Ren\u00e9 Steinfort", "id-internal": "227/4616", "id-external": ""}], "url": {"full": "URL#1659005", "pdf": ""}, "publisher-venue": "ISCRAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3504475975, "title": "Detection of Online Fake News Using N-Gram Analysis and Machine Learning Techniques.", "abstract": "", "doi": "10.1007/978-3-319-69155-8_9", "date": "2017", "authors": [{"name": "Hadeer Ahmed", "id-internal": "204/9079", "id-external": ""}, {"name": "Issa Traor\u00e9", "id-internal": "10/1711", "id-external": ""}, {"name": "Sherif Saad", "id-internal": "40/9034", "id-external": ""}], "url": {"full": "URL#1659131", "pdf": ""}, "publisher-venue": "ISDDC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2509971643, "title": "Automatic Detection of Fake News on Social Media Platforms.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Christian Janze", "id-internal": "172/6956", "id-external": ""}, {"name": "Marten Risius", "id-internal": "142/8188", "id-external": ""}], "url": {"full": "URL#1684072", "pdf": ""}, "publisher-venue": "PACIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3026285691, "title": "Incentivizing the dissemination of truth versus fake news in social networks.", "abstract": "", "doi": "10.1109/sysose.2017.7994981", "date": "2017", "authors": [{"name": "Abbas Ehsanfar", "id-internal": "185/0973", "id-external": ""}, {"name": "Mo Mansouri", "id-internal": "46/8093", "id-external": ""}], "url": {"full": "URL#1704346", "pdf": ""}, "publisher-venue": "SoSE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2822241233, "title": "Addressing fake news - Open standards & easy identification.", "abstract": "", "doi": "10.1109/uemcon.2017.8248986", "date": "2017", "authors": {"name": "Joshua Hyman", "id-internal": "213/2612", "id-external": ""}, "url": {"full": "URL#1706437", "pdf": ""}, "publisher-venue": "UEMCON", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3186174242, "title": "Fake News - Simply Agile.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Jil Kl\u00fcnder", "id-internal": "184/6405", "id-external": ""}, {"name": "Anna Schmitt 0001", "id-internal": "167/2320-1", "id-external": ""}, {"name": "Philipp Hohl", "id-internal": "189/6667", "id-external": ""}, {"name": "Kurt Schneider", "id-internal": "s/KurtSchneider", "id-external": ""}], "url": {"full": "URL#1708999", "pdf": ""}, "publisher-venue": "Vorgehensmodelle", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4044207753, "title": "The Fake News Spreading Plague - Was it Preventable?", "abstract": "", "doi": "10.1145/3091478.3091523", "date": "2017", "authors": [{"name": "Eni Mustafaraj", "id-internal": "97/592", "id-external": ""}, {"name": "Panagiotis Takis Metaxas", "id-internal": "m/PTMetaxas", "id-external": ""}], "url": {"full": "URL#1712799", "pdf": ""}, "publisher-venue": "WebSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 479224159, "title": "Fake News Mitigation via Point Process Based Intervention.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Mehrdad Farajtabar", "id-internal": "21/9988", "id-external": ""}, {"name": "Jiachen Yang", "id-internal": "120/3255", "id-external": ""}, {"name": "Xiaojing Ye", "id-internal": "01/2390", "id-external": ""}, {"name": "Huan Xu", "id-internal": "35/2843", "id-external": ""}, {"name": "Rakshit Trivedi", "id-internal": "184/0005", "id-external": ""}, {"name": "Elias Boutros Khalil", "id-internal": "151/3240", "id-external": ""}, {"name": "Shuang Li 0002", "id-internal": "43/6294-2", "id-external": ""}, {"name": "Le Song", "id-internal": "94/3481", "id-external": ""}, {"name": "Hongyuan Zha", "id-internal": "z/HongyuanZha", "id-external": ""}], "url": {"full": "URL#1728531", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1092105950, "title": "The Fake News Spreading Plague - Was it Preventable?", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Eni Mustafaraj", "id-internal": "97/592", "id-external": ""}, {"name": "Panagiotis Takis Metaxas", "id-internal": "m/PTMetaxas", "id-external": ""}], "url": {"full": "URL#1734641", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2928406244, "title": "A Stylometric Inquiry into Hyperpartisan and Fake News.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Martin Potthast", "id-internal": "87/6573", "id-external": ""}, {"name": "Johannes Kiesel", "id-internal": "118/3606", "id-external": ""}, {"name": "Kevin Reinartz", "id-internal": "190/5328", "id-external": ""}, {"name": "Janek Bevendorff", "id-internal": "195/5852", "id-external": ""}, {"name": "Benno Stein 0001", "id-internal": "69/4806-1", "id-external": ""}], "url": {"full": "URL#1735811", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3250156405, "title": "A simple but tough-to-beat baseline for the Fake News Challenge stance detection task.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Benjamin Riedel 0001", "id-internal": "208/4275", "id-external": ""}, {"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}, {"name": "Georgios P. Spithourakis", "id-internal": "129/7511", "id-external": ""}, {"name": "Sebastian Riedel 0001", "id-internal": "18/3348-1", "id-external": ""}], "url": {"full": "URL#1736325", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2432564114, "title": "CSI - A Hybrid Deep Model for Fake News.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Natali Ruchansky", "id-internal": "12/9876", "id-external": ""}, {"name": "Sungyong Seo", "id-internal": "178/3209", "id-external": ""}, {"name": "Yan Liu 0002", "id-internal": "l/YanLiu2", "id-external": ""}], "url": {"full": "URL#1736528", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3092204865, "title": "The spread of fake news by social bots.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Chengcheng Shao", "id-internal": "150/7597", "id-external": ""}, {"name": "Giovanni Luca Ciampaglia", "id-internal": "07/8400", "id-external": ""}, {"name": "Onur Varol", "id-internal": "135/8835", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}], "url": {"full": "URL#1737184", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 831212520, "title": "Some Like it Hoax - Automated Fake News Detection in Social Networks.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Eugenio Tacchini", "id-internal": "32/10636", "id-external": ""}, {"name": "Gabriele Ballarin", "id-internal": "199/2238", "id-external": ""}, {"name": "Marco L. Della Vedova", "id-internal": "93/7704", "id-external": ""}, {"name": "Stefano Moret", "id-internal": "189/8761", "id-external": ""}, {"name": "Luca de Alfaro", "id-internal": "d/LucadeAlfaro", "id-external": ""}], "url": {"full": "URL#1738020", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1529457843, "title": "\"Liar, Liar Pants on Fire\" - A New Benchmark Dataset for Fake News Detection.", "abstract": "", "doi": "", "date": "2017", "authors": {"name": "William Yang Wang", "id-internal": "08/9282", "id-external": ""}, "url": {"full": "URL#1738892", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2641199894, "title": "Fake News Detection on Social Media - A Data Mining Perspective.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Amy Sliva", "id-internal": "67/3213", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Jiliang Tang", "id-internal": "64/10812", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#1741274", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3857900972, "title": "Fake News in Social Networks.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Christoph Aymanns", "id-internal": "205/2688", "id-external": ""}, {"name": "Jakob N. Foerster", "id-internal": "176/5095", "id-external": ""}, {"name": "Co-Pierre Georg", "id-internal": "205/3032", "id-external": ""}], "url": {"full": "URL#1742363", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2131990249, "title": "Automatic Detection of Fake News.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Ver\u00f3nica P\u00e9rez-Rosas", "id-internal": "53/9684", "id-external": ""}, {"name": "Bennett Kleinberg", "id-internal": "205/3085", "id-external": ""}, {"name": "Alexandra Lefevre", "id-internal": "205/2468", "id-external": ""}, {"name": "Rada Mihalcea", "id-internal": "m/RadaMihalcea", "id-external": ""}], "url": {"full": "URL#1742578", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1761471757, "title": "Related Fact Checks - a tool for combating fake news.", "abstract": "", "doi": "", "date": "2017", "authors": {"name": "Sreya Guha", "id-internal": "208/2221", "id-external": ""}, "url": {"full": "URL#1748758", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1160561473, "title": "Detecting Fake News in Social Networks via Crowdsourcing.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Sebastian Tschiatschek", "id-internal": "33/10810", "id-external": ""}, {"name": "Adish Singla", "id-internal": "58/657", "id-external": ""}, {"name": "Manuel Gomez-Rodriguez", "id-internal": "73/8260", "id-external": ""}, {"name": "Arpit Merchant", "id-internal": "178/3551", "id-external": ""}, {"name": "Andreas Krause 0001", "id-internal": "87/1831-1", "id-external": ""}], "url": {"full": "URL#1750907", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 459374875, "title": "Leveraging the Crowd to Detect and Reduce the Spread of Fake News and Misinformation.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Jooyeon Kim", "id-internal": "64/9560", "id-external": ""}, {"name": "Behzad Tabibian", "id-internal": "70/9714", "id-external": ""}, {"name": "Alice Oh", "id-internal": "50/7562", "id-external": ""}, {"name": "Bernhard Sch\u00f6lkopf", "id-internal": "97/119", "id-external": ""}, {"name": "Manuel Gomez-Rodriguez", "id-internal": "73/8260", "id-external": ""}], "url": {"full": "URL#1751152", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 482667342, "title": "On the Benefit of Combining Neural, Statistical and External Features for Fake News Identification.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Gaurav Bhatt", "id-internal": "173/8402", "id-external": ""}, {"name": "Aman Sharma", "id-internal": "211/6908", "id-external": ""}, {"name": "Shivam Sharma", "id-internal": "146/2381", "id-external": ""}, {"name": "Ankush Nagpal", "id-internal": "211/7004", "id-external": ""}, {"name": "Balasubramanian Raman", "id-internal": "57/6641", "id-external": ""}, {"name": "Ankush Mittal", "id-internal": "78/6048", "id-external": ""}], "url": {"full": "URL#1752557", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 383380589, "title": "Characterizing Political Fake News in Twitter by its Meta-Data.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Julio Amador D\u00edaz L\u00f3pez", "id-internal": "204/9865", "id-external": ""}, {"name": "Axel Oehmichen", "id-internal": "153/6999", "id-external": ""}, {"name": "Miguel Molina-Solana", "id-internal": "92/7407", "id-external": ""}], "url": {"full": "URL#1753016", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3556711831, "title": "Exploiting Tri-Relationship for Fake News Detection.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#1753392", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1037078203, "title": "Automatic deception detection - Methods for finding fake news.", "abstract": "", "doi": "10.1002/pra2.2015.145052010082", "date": "2015", "authors": [{"name": "Niall J. Conroy", "id-internal": "90/11137", "id-external": ""}, {"name": "Victoria L. Rubin", "id-internal": "36/6480", "id-external": ""}, {"name": "Yimin Chen 0002", "id-internal": "38/1020-2", "id-external": ""}], "url": {"full": "URL#2189938", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 113700, "title": "Deception detection for news - Three types of fakes.", "abstract": "", "doi": "10.1002/pra2.2015.145052010083", "date": "2015", "authors": [{"name": "Victoria L. Rubin", "id-internal": "36/6480", "id-external": ""}, {"name": "Yimin Chen 0002", "id-internal": "38/1020-2", "id-external": ""}, {"name": "Niall J. Conroy", "id-internal": "90/11137", "id-external": ""}], "url": {"full": "URL#2190019", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 361982, "title": "When Fake News Becomes Real.", "abstract": "", "doi": "10.1177/0093650212453600", "date": "2014", "authors": {"name": "Meital Balmas", "id-internal": "196/7427", "id-external": ""}, "url": {"full": "URL#2382260", "pdf": ""}, "publisher-venue": "Commun. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2450360048, "title": "The Mass, Fake News, and Cognition Security", "abstract": "The wide spread of fake news in social networks is posing threats to social\nstability, economic development and political democracy etc. Numerous studies\nhave explored the effective detection approaches of online fake news, while few\nworks study the intrinsic propagation and cognition mechanisms of fake news.\nSince the development of cognitive science paves a promising way for the\nprevention of fake news, we present a new research area called Cognition\nSecurity (CogSec), which studies the potential impacts of fake news to human\ncognition, ranging from misperception, untrusted knowledge acquisition,\ntargeted opinion/attitude formation, to biased decision making, and\ninvestigates the effective ways for fake news debunking. CogSec is a\nmultidisciplinary research field that leverages knowledge from social science,\npsychology, cognition science, neuroscience, AI and computer science. We first\npropose related definitions to characterize CogSec and review the literature\nhistory. We further investigate the key research challenges and techniques of\nCogSec, including human-content cognition mechanism, social influence and\nopinion diffusion, fake news detection and malicious bot detection. Finally, we\nsummarize the open issues and future research directions, such as early\ndetection of fake news, explainable fake news debunking, social contagion and\ndiffusion models of fake news, and so on.", "doi": "", "date": "2019-07-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.07759v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3030343750, "title": "Credibility-based Fake News Detection", "abstract": "Fake news can significantly misinform people who often rely on online sources\nand social media for their information. Current research on fake news detection\nhas mostly focused on analyzing fake news content and how it propagates on a\nnetwork of users. In this paper, we emphasize the detection of fake news by\nassessing its credibility. By analyzing public fake news data, we show that\ninformation on news sources (and authors) can be a strong indicator of\ncredibility. Our findings suggest that an author's history of association with\nfake news, and the number of authors of a news article, can play a significant\nrole in detecting fake news. Our approach can help improve traditional fake\nnews detection methods, wherein content features are often used to detect fake\nnews.", "doi": "", "date": "2019-11-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.00643v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1025762333, "title": "Is it Fake? News Disinformation Detection on South African News Websites", "abstract": "Disinformation through fake news is an ongoing problem in our society and has\nbecome easily spread through social media. The most cost and time effective way\nto filter these large amounts of data is to use a combination of human and\ntechnical interventions to identify it. From a technical perspective, Natural\nLanguage Processing (NLP) is widely used in detecting fake news. Social media\ncompanies use NLP techniques to identify the fake news and warn their users,\nbut fake news may still slip through undetected. It is especially a problem in\nmore localised contexts (outside the United States of America). How do we\nadjust fake news detection systems to work better for local contexts such as in\nSouth Africa. In this work we investigate fake news detection on South African\nwebsites. We curate a dataset of South African fake news and then train\ndetection models. We contrast this with using widely available fake news\ndatasets (from mostly USA website). We also explore making the datasets more\ndiverse by combining them and observe the differences in behaviour in writing\nbetween nations' fake news using interpretable machine learning.", "doi": "", "date": "2021-08-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.02941v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3447788486, "title": "Fake News Early Detection: An Interdisciplinary Study", "abstract": "Massive dissemination of fake news and its potential to erode democracy has\nincreased the demand for accurate fake news detection. Recent advancements in\nthis area have proposed novel techniques that aim to detect fake news by\nexploring how it propagates on social networks. Nevertheless, to detect fake\nnews at an early stage, i.e., when it is published on a news outlet but not yet\nspread on social media, one cannot rely on news propagation information as it\ndoes not exist. Hence, there is a strong need to develop approaches that can\ndetect fake news by focusing on news content. In this paper, a theory-driven\nmodel is proposed for fake news detection. The method investigates news content\nat various levels: lexicon-level, syntax-level, semantic-level and\ndiscourse-level. We represent news at each level, relying on well-established\ntheories in social and forensic psychology. Fake news detection is then\nconducted within a supervised machine learning framework. As an\ninterdisciplinary research, our work explores potential fake news patterns,\nenhances the interpretability in fake news feature engineering, and studies the\nrelationships among fake news, deception/disinformation, and clickbaits.\nExperiments conducted on two real-world datasets indicate the proposed method\ncan outperform the state-of-the-art and enable fake news early detection when\nthere is limited content information.", "doi": "", "date": "2019-04-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.11679v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3924709606, "title": "Exploiting Multi-domain Visual Information for Fake News Detection", "abstract": "The increasing popularity of social media promotes the proliferation of fake\nnews. With the development of multimedia technology, fake news attempts to\nutilize multimedia contents with images or videos to attract and mislead\nreaders for rapid dissemination, which makes visual contents an important part\nof fake news. Fake-news images, images attached in fake news posts,include not\nonly fake images which are maliciously tampered but also real images which are\nwrongly used to represent irrelevant events. Hence, how to fully exploit the\ninherent characteristics of fake-news images is an important but challenging\nproblem for fake news detection. In the real world, fake-news images may have\nsignificantly different characteristics from real-news images at both physical\nand semantic levels, which can be clearly reflected in the frequency and pixel\ndomain, respectively. Therefore, we propose a novel framework Multi-domain\nVisual Neural Network (MVNN) to fuse the visual information of frequency and\npixel domains for detecting fake news. Specifically, we design a CNN-based\nnetwork to automatically capture the complex patterns of fake-news images in\nthe frequency domain; and utilize a multi-branch CNN-RNN model to extract\nvisual features from different semantic levels in the pixel domain. An\nattention mechanism is utilized to fuse the feature representations of\nfrequency and pixel domains dynamically. Extensive experiments conducted on a\nreal-world dataset demonstrate that MVNN outperforms existing methods with at\nleast 9.2% in accuracy, and can help improve the performance of multimodal fake\nnews detection by over 5.2%.", "doi": "", "date": "2019-08-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.04472v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1229093304, "title": "Exploring the Role of Visual Content in Fake News Detection", "abstract": "The increasing popularity of social media promotes the proliferation of fake\nnews, which has caused significant negative societal effects. Therefore, fake\nnews detection on social media has recently become an emerging research area of\ngreat concern. With the development of multimedia technology, fake news\nattempts to utilize multimedia content with images or videos to attract and\nmislead consumers for rapid dissemination, which makes visual content an\nimportant part of fake news. Despite the importance of visual content, our\nunderstanding of the role of visual content in fake news detection is still\nlimited. This chapter presents a comprehensive review of the visual content in\nfake news, including the basic concepts, effective visual features,\nrepresentative detection methods and challenging issues of multimedia fake news\ndetection. This chapter can help readers to understand the role of visual\ncontent in fake news detection, and effectively utilize visual content to\nassist in detecting multimedia fake news.", "doi": "10.1007/978-3-030-42699-6", "date": "2020-03-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.05096v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2578283900, "title": "Network-based Fake News Detection: A Pattern-driven Approach", "abstract": "Fake news gains has gained significant momentum, strongly motivating the need\nfor fake news research. Many fake news detection approaches have thus been\nproposed, where most of them heavily rely on news content. However,\nnetwork-based clues revealed when analyzing news propagation on social networks\nis an information that has hardly been comprehensively explored or used for\nfake news detection. We bridge this gap by proposing a network-based\npattern-driven fake news detection approach. We aim to study the patterns of\nfake news in social networks, which refer to the news being spread, spreaders\nof the news and relationships among the spreaders. Empirical evidence and\ninterpretations on the existence of such patterns are provided based on social\npsychological theories. These patterns are then represented at various network\nlevels (i.e., node-level, ego-level, triad-level, community-level and the\noverall network) for being further utilized to detect fake news. The proposed\napproach enhances the explainability in fake news feature engineering.\nExperiments conducted on real-world data demonstrate that the proposed approach\ncan outperform the state of the arts.", "doi": "", "date": "2019-06-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.04210v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3153451907, "title": "Fake News Detection using Temporal Features Extracted via Point Process", "abstract": "Many people use social networking services (SNSs) to easily access various\nnews. There are numerous ways to obtain and share ``fake news,'' which are news\ncarrying false information. To address fake news, several studies have been\nconducted for detecting fake news by using SNS-extracted features. In this\nstudy, we attempt to use temporal features generated from SNS posts by using a\npoint process algorithm to identify fake news from real news. Temporal features\nin fake news detection have the advantage of robustness over existing features\nbecause it has minimal dependence on fake news propagators. Further, we propose\na novel multi-modal attention-based method, which includes linguistic and user\nfeatures alongside temporal features, for detecting fake news from SNS posts.\nResults obtained from three public datasets indicate that the proposed model\nachieves better performance compared to existing methods and demonstrate the\neffectiveness of temporal features for fake news detection.", "doi": "10.36190/2020.13", "date": "2020-07-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.14013v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2428216165, "title": "How does Truth Evolve into Fake News? An Empirical Study of Fake News\n  Evolution", "abstract": "Automatically identifying fake news from the Internet is a challenging\nproblem in deception detection tasks. Online news is modified constantly during\nits propagation, e.g., malicious users distort the original truth and make up\nfake news. However, the continuous evolution process would generate\nunprecedented fake news and cheat the original model. We present the Fake News\nEvolution (FNE) dataset: a new dataset tracking the fake news evolution\nprocess. Our dataset is composed of 950 paired data, each of which consists of\narticles representing the three significant phases of the evolution process,\nwhich are the truth, the fake news, and the evolved fake news. We observe the\nfeatures during the evolution and they are the disinformation techniques, text\nsimilarity, top 10 keywords, classification accuracy, parts of speech, and\nsentiment properties.", "doi": "", "date": "2021-03-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.05944v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1879302044, "title": "Hierarchical Propagation Networks for Fake News Detection: Investigation\n  and Exploitation", "abstract": "Consuming news from social media is becoming increasingly popular. However,\nsocial media also enables the widespread of fake news. Because of its\ndetrimental effects brought by social media, fake news detection has attracted\nincreasing attention. However, the performance of detecting fake news only from\nnews content is generally limited as fake news pieces are written to mimic true\nnews. In the real world, news pieces spread through propagation networks on\nsocial media. The news propagation networks usually involve multi-levels. In\nthis paper, we study the challenging problem of investigating and exploiting\nnews hierarchical propagation network on social media for fake news detection.\n  In an attempt to understand the correlations between news propagation\nnetworks and fake news, first, we build a hierarchical propagation network from\nmacro-level and micro-level of fake news and true news; second, we perform a\ncomparative analysis of the propagation network features of linguistic,\nstructural and temporal perspectives between fake and real news, which\ndemonstrates the potential of utilizing these features to detect fake news;\nthird, we show the effectiveness of these propagation network features for fake\nnews detection. We further validate the effectiveness of these features from\nfeature important analysis. Altogether, this work presents a data-driven view\nof hierarchical propagation network and fake news and paves the way towards a\nhealthier online news ecosystem.", "doi": "", "date": "2019-03-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.09196v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 816131305, "title": "The Role of User Profile for Fake News Detection", "abstract": "Consuming news from social media is becoming increasingly popular. Social\nmedia appeals to users due to its fast dissemination of information, low cost,\nand easy access. However, social media also enables the widespread of fake\nnews. Because of the detrimental societal effects of fake news, detecting fake\nnews has attracted increasing attention. However, the detection performance\nonly using news contents is generally not satisfactory as fake news is written\nto mimic true news. Thus, there is a need for an in-depth understanding on the\nrelationship between user profiles on social media and fake news. In this\npaper, we study the challenging problem of understanding and exploiting user\nprofiles on social media for fake news detection. In an attempt to understand\nconnections between user profiles and fake news, first, we measure users'\nsharing behaviors on social media and group representative users who are more\nlikely to share fake and real news; then, we perform a comparative analysis of\nexplicit and implicit profile features between these user groups, which reveals\ntheir potential to help differentiate fake news from real news. To exploit user\nprofile features, we demonstrate the usefulness of these user profile features\nin a fake news classification task. We further validate the effectiveness of\nthese features through feature importance analysis. The findings of this work\nlay the foundation for deeper exploration of user profile features of social\nmedia and enhance the capabilities for fake news detection.", "doi": "", "date": "2019-04-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.13355v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1296304628, "title": "How to model fake news", "abstract": "Over the past three years it has become evident that fake news is a danger to\ndemocracy. However, until now there has been no clear understanding of how to\ndefine fake news, much less how to model it. This paper addresses both these\nissues. A definition of fake news is given, and two approaches for the\nmodelling of fake news and its impact in elections and referendums are\nintroduced. The first approach, based on the idea of a representative voter, is\nshown to be suitable to obtain a qualitative understanding of phenomena\nassociated with fake news at a macroscopic level. The second approach, based on\nthe idea of an election microstructure, describes the collective behaviour of\nthe electorate by modelling the preferences of individual voters. It is shown\nthrough a simulation study that the mere knowledge that pieces of fake news may\nbe in circulation goes a long way towards mitigating the impact of fake news.", "doi": "", "date": "2018-09-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.00964v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4146059019, "title": "Open Issues in Combating Fake News: Interpretability as an Opportunity", "abstract": "Combating fake news needs a variety of defense methods. Although rumor\ndetection and various linguistic analysis techniques are common methods to\ndetect false content in social media, there are other feasible mitigation\napproaches that could be explored in the machine learning community. In this\npaper, we present open issues and opportunities in fake news research that need\nfurther attention. We first review different stages of the news life cycle in\nsocial media and discuss core vulnerability issues for news feed algorithms in\npropagating fake news content with three examples. We then discuss how\ncomplexity and unclarity of the fake news problem limit the advancements in\nthis field. Lastly, we present research opportunities from interpretable\nmachine learning to mitigate fake news problems with 1) interpretable fake news\ndetection and 2) transparent news feed algorithms. We propose three dimensions\nof interpretability consisting of algorithmic interpretability, human\ninterpretability, and the inclusion of supporting evidence that can benefit\nfake news mitigation methods in different ways.", "doi": "", "date": "2019-04-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.03016v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3624637741, "title": "Indonesia's Fake News Detection using Transformer Network", "abstract": "Fake news is a problem faced by society in this era. It is not rare for fake\nnews to cause provocation and problem for the people. Indonesia, as a country\nwith the 4th largest population, has a problem in dealing with fake news. More\nthan 30% of rural and urban population are deceived by this fake news problem.\nAs we have been studying, there is only few literatures on preventing the\nspread of fake news in Bahasa Indonesia. So, this research is conducted to\nprevent these problems. The dataset used in this research was obtained from a\nnews portal that identifies fake news, turnbackhoax.id. Using Web Scrapping on\nthis page, we got 1116 data consisting of valid news and fake news. The dataset\ncan be accessed at https://github.com/JibranFawaid/turnbackhoax-dataset. This\ndataset will be combined with other available datasets. The methods used are\nCNN, BiLSTM, Hybrid CNN-BiLSTM, and BERT with Transformer Network. This\nresearch shows that the BERT method with Transformer Network has the best\nresults with an accuracy of up to 90%.", "doi": "", "date": "2021-07-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.06796v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 528975522, "title": "How Vulnerable Are Automatic Fake News Detection Methods to Adversarial\n  Attacks?", "abstract": "As the spread of false information on the internet has increased dramatically\nin recent years, more and more attention is being paid to automated fake news\ndetection. Some fake news detection methods are already quite successful.\nNevertheless, there are still many vulnerabilities in the detection algorithms.\nThe reason for this is that fake news publishers can structure and formulate\ntheir texts in such a way that a detection algorithm does not expose this text\nas fake news. This paper shows that it is possible to automatically attack\nstate-of-the-art models that have been trained to detect Fake News, making\nthese vulnerable. For this purpose, corresponding models were first trained\nbased on a dataset. Then, using Text-Attack, an attempt was made to manipulate\nthe trained models in such a way that previously correctly identified fake news\nwas classified as true news. The results show that it is possible to\nautomatically bypass Fake News detection mechanisms, leading to implications\nconcerning existing policy initiatives.", "doi": "", "date": "2021-07-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.07970v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4201400514, "title": "TI-CNN: Convolutional Neural Networks for Fake News Detection", "abstract": "With the development of social networks, fake news for various commercial and\npolitical purposes has been appearing in large numbers and gotten widespread in\nthe online world. With deceptive words, people can get infected by the fake\nnews very easily and will share them without any fact-checking. For instance,\nduring the 2016 US president election, various kinds of fake news about the\ncandidates widely spread through both official news media and the online social\nnetworks. These fake news is usually released to either smear the opponents or\nsupport the candidate on their side. The erroneous information in the fake news\nis usually written to motivate the voters' irrational emotion and enthusiasm.\nSuch kinds of fake news sometimes can bring about devastating effects, and an\nimportant goal in improving the credibility of online social networks is to\nidentify the fake news timely. In this paper, we propose to study the fake news\ndetection problem. Automatic fake news identification is extremely hard, since\npure model based fact-checking for news is still an open problem, and few\nexisting models can be applied to solve the problem. With a thorough\ninvestigation of a fake news data, lots of useful explicit features are\nidentified from both the text words and images used in the fake news. Besides\nthe explicit features, there also exist some hidden patterns in the words and\nimages used in fake news, which can be captured with a set of latent features\nextracted via the multiple convolutional layers in our model. A model named as\nTI-CNN (Text and Image information based Convolutinal Neural Network) is\nproposed in this paper. By projecting the explicit and latent features into a\nunified feature space, TI-CNN is trained with both the text and image\ninformation simultaneously. Extensive experiments carried on the real-world\nfake news datasets have demonstrate the effectiveness of TI-CNN.", "doi": "", "date": "2018-06-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.00749v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2083249169, "title": "FakeNewsNet: A Data Repository with News Content, Social Context and\n  Spatialtemporal Information for Studying Fake News on Social Media", "abstract": "Social media has become a popular means for people to consume news.\nMeanwhile, it also enables the wide dissemination of fake news, i.e., news with\nintentionally false information, which brings significant negative effects to\nthe society. Thus, fake news detection is attracting increasing attention.\nHowever, fake news detection is a non-trivial task, which requires multi-source\ninformation such as news content, social context, and dynamic information.\nFirst, fake news is written to fool people, which makes it difficult to detect\nfake news simply based on news contents. In addition to news contents, we need\nto explore social contexts such as user engagements and social behaviors. For\nexample, a credible user's comment that \"this is a fake news\" is a strong\nsignal for detecting fake news. Second, dynamic information such as how fake\nnews and true news propagate and how users' opinions toward news pieces are\nvery important for extracting useful patterns for (early) fake news detection\nand intervention. Thus, comprehensive datasets which contain news content,\nsocial context, and dynamic information could facilitate fake news propagation,\ndetection, and mitigation; while to the best of our knowledge, existing\ndatasets only contains one or two aspects. Therefore, in this paper, to\nfacilitate fake news related researches, we provide a fake news data repository\nFakeNewsNet, which contains two comprehensive datasets that includes news\ncontent, social context, and dynamic information. We present a comprehensive\ndescription of datasets collection, demonstrate an exploratory analysis of this\ndata repository from different perspectives, and discuss the benefits of\nFakeNewsNet for potential applications on fake news study on social media.", "doi": "", "date": "2018-09-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.01286v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3394159348, "title": "Beyond News Contents: The Role of Social Context for Fake News Detection", "abstract": "Social media is becoming popular for news consumption due to its fast\ndissemination, easy access, and low cost. However, it also enables the wide\npropagation of fake news, i.e., news with intentionally false information.\nDetecting fake news is an important task, which not only ensures users to\nreceive authentic information but also help maintain a trustworthy news\necosystem. The majority of existing detection algorithms focus on finding clues\nfrom news contents, which are generally not effective because fake news is\noften intentionally written to mislead users by mimicking true news. Therefore,\nwe need to explore auxiliary information to improve detection. The social\ncontext during news dissemination process on social media forms the inherent\ntri-relationship, the relationship among publishers, news pieces, and users,\nwhich has potential to improve fake news detection. For example,\npartisan-biased publishers are more likely to publish fake news, and\nlow-credible users are more likely to share fake news. In this paper, we study\nthe novel problem of exploiting social context for fake news detection. We\npropose a tri-relationship embedding framework TriFN, which models\npublisher-news relations and user-news interactions simultaneously for fake\nnews classification. We conduct experiments on two real-world datasets, which\ndemonstrate that the proposed approach significantly outperforms other baseline\nmethods for fake news detection.", "doi": "", "date": "2017-12-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1712.07709v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3845094203, "title": "Modeling the spread of fake news on Twitter", "abstract": "Fake news can have a significant negative impact on society because of the\ngrowing use of mobile devices and the worldwide increase in Internet access. It\nis therefore essential to develop a simple mathematical model to understand the\nonline dissemination of fake news. In this study, we propose a point process\nmodel of the spread of fake news on Twitter. The proposed model describes the\nspread of a fake news item as a two-stage process: initially, fake news spreads\nas a piece of ordinary news; then, when most users start recognizing the\nfalsity of the news item, that itself spreads as another news story. We\nvalidate this model using two datasets of fake news items spread on Twitter. We\nshow that the proposed model is superior to the current state-of-the-art\nmethods in accurately predicting the evolution of the spread of a fake news\nitem. Moreover, a text analysis suggests that our model appropriately infers\nthe correction time, i.e., the moment when Twitter users start realizing the\nfalsity of the news item. The proposed model contributes to understanding the\ndynamics of the spread of fake news on social media. Its ability to extract a\ncompact representation of the spreading pattern could be useful in the\ndetection and mitigation of fake news.", "doi": "10.1371/journal.pone.0250419", "date": "2020-07-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.14059v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3397888797, "title": "User Preference-aware Fake News Detection", "abstract": "Disinformation and fake news have posed detrimental effects on individuals\nand society in recent years, attracting broad attention to fake news detection.\nThe majority of existing fake news detection algorithms focus on mining news\ncontent and/or the surrounding exogenous context for discovering deceptive\nsignals; while the endogenous preference of a user when he/she decides to\nspread a piece of fake news or not is ignored. The confirmation bias theory has\nindicated that a user is more likely to spread a piece of fake news when it\nconfirms his/her existing beliefs/preferences. Users' historical, social\nengagements such as posts provide rich information about users' preferences\ntoward news and have great potential to advance fake news detection. However,\nthe work on exploring user preference for fake news detection is somewhat\nlimited. Therefore, in this paper, we study the novel problem of exploiting\nuser preference for fake news detection. We propose a new framework, UPFD,\nwhich simultaneously captures various signals from user preferences by joint\ncontent and graph modeling. Experimental results on real-world datasets\ndemonstrate the effectiveness of the proposed framework. We release our code\nand data as a benchmark for GNN-based fake news detection:\nhttps://github.com/safe-graph/GNN-FakeNews.", "doi": "", "date": "2021-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.12259v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 672524840, "title": "r/Fakeddit: A New Multimodal Benchmark Dataset for Fine-grained Fake\n  News Detection", "abstract": "Fake news has altered society in negative ways in politics and culture. It\nhas adversely affected both online social network systems as well as offline\ncommunities and conversations. Using automatic machine learning classification\nmodels is an efficient way to combat the widespread dissemination of fake news.\nHowever, a lack of effective, comprehensive datasets has been a problem for\nfake news research and detection model development. Prior fake news datasets do\nnot provide multimodal text and image data, metadata, comment data, and\nfine-grained fake news categorization at the scale and breadth of our dataset.\nWe present Fakeddit, a novel multimodal dataset consisting of over 1 million\nsamples from multiple categories of fake news. After being processed through\nseveral stages of review, the samples are labeled according to 2-way, 3-way,\nand 6-way classification categories through distant supervision. We construct\nhybrid text+image models and perform extensive experiments for multiple\nvariations of classification, demonstrating the importance of the novel aspect\nof multimodality and fine-grained classification unique to Fakeddit.", "doi": "", "date": "2019-11-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.03854v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 596326877, "title": "Fake News Detection on News-Oriented Heterogeneous Information Networks\n  through Hierarchical Graph Attention", "abstract": "The viral spread of fake news has caused great social harm, making fake news\ndetection an urgent task. Current fake news detection methods rely heavily on\ntext information by learning the extracted news content or writing style of\ninternal knowledge. However, deliberate rumors can mask writing style,\nbypassing language models and invalidating simple text-based models. In fact,\nnews articles and other related components (such as news creators and news\ntopics) can be modeled as a heterogeneous information network (HIN for short).\nIn this paper, we propose a novel fake news detection framework, namely\nHierarchical Graph Attention Network(HGAT), which uses a novel hierarchical\nattention mechanism to perform node representation learning in HIN, and then\ndetects fake news by classifying news article nodes. Experiments on two\nreal-world fake news datasets show that HGAT can outperform text-based models\nand other network-based models. In addition, the experiment proved the\nexpandability and generalizability of our for graph representation learning and\nother node classification related applications in heterogeneous graphs.", "doi": "", "date": "2020-02-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.04397v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2971666228, "title": "Detection of Bangla Fake News using MNB and SVM Classifier", "abstract": "Fake news has been coming into sight in significant numbers for numerous\nbusiness and political reasons and has become frequent in the online world.\nPeople can get contaminated easily by these fake news for its fabricated words\nwhich have enormous effects on the offline community. Thus, interest in\nresearch in this area has risen. Significant research has been conducted on the\ndetection of fake news from English texts and other languages but a few in\nBangla Language. Our work reflects the experimental analysis on the detection\nof Bangla fake news from social media as this field still requires much focus.\nIn this research work, we have used two supervised machine learning algorithms,\nMultinomial Naive Bayes (MNB) and Support Vector Machine (SVM) classifiers to\ndetect Bangla fake news with CountVectorizer and Term Frequency - Inverse\nDocument Frequency Vectorizer as feature extraction. Our proposed framework\ndetects fake news depending on the polarity of the corresponding article.\nFinally, our analysis shows SVM with the linear kernel with an accuracy of\n96.64% outperform MNB with an accuracy of 93.32%.", "doi": "", "date": "2020-05-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.14627v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3793918784, "title": "Connecting the Dots Between Fact Verification and Fake News Detection", "abstract": "Fact verification models have enjoyed a fast advancement in the last two\nyears with the development of pre-trained language models like BERT and the\nrelease of large scale datasets such as FEVER. However, the challenging problem\nof fake news detection has not benefited from the improvement of fact\nverification models, which is closely related to fake news detection. In this\npaper, we propose a simple yet effective approach to connect the dots between\nfact verification and fake news detection. Our approach first employs a text\nsummarization model pre-trained on news corpora to summarize the long news\narticle into a short claim. Then we use a fact verification model pre-trained\non the FEVER dataset to detect whether the input news article is real or fake.\nOur approach makes use of the recent success of fact verification models and\nenables zero-shot fake news detection, alleviating the need of large-scale\ntraining data to train fake news detection models. Experimental results on\nFakenewsNet, a benchmark dataset for fake news detection, demonstrate the\neffectiveness of our proposed approach.", "doi": "", "date": "2020-10-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.05202v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2378022230, "title": "MM-COVID: A Multilingual and Multimodal Data Repository for Combating\n  COVID-19 Disinformation", "abstract": "The COVID-19 epidemic is considered as the global health crisis of the whole\nsociety and the greatest challenge mankind faced since World War Two.\nUnfortunately, the fake news about COVID-19 is spreading as fast as the virus\nitself. The incorrect health measurements, anxiety, and hate speeches will have\nbad consequences on people's physical health, as well as their mental health in\nthe whole world. To help better combat the COVID-19 fake news, we propose a new\nfake news detection dataset MM-COVID(Multilingual and Multidimensional COVID-19\nFake News Data Repository). This dataset provides the multilingual fake news\nand the relevant social context. We collect 3981 pieces of fake news content\nand 7192 trustworthy information from English, Spanish, Portuguese, Hindi,\nFrench and Italian, 6 different languages. We present a detailed and\nexploratory analysis of MM-COVID from different perspectives and demonstrate\nthe utility of MM-COVID in several potential applications of COVID-19 fake news\nstudy on multilingual and social media.", "doi": "", "date": "2020-11-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.04088v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2842107163, "title": "A Survey on Natural Language Processing for Fake News Detection", "abstract": "Fake news detection is a critical yet challenging problem in Natural Language\nProcessing (NLP). The rapid rise of social networking platforms has not only\nyielded a vast increase in information accessibility but has also accelerated\nthe spread of fake news. Thus, the effect of fake news has been growing,\nsometimes extending to the offline world and threatening public safety. Given\nthe massive amount of Web content, automatic fake news detection is a practical\nNLP problem useful to all online content providers, in order to reduce the\nhuman time and effort to detect and prevent the spread of fake news. In this\npaper, we describe the challenges involved in fake news detection and also\ndescribe related tasks. We systematically review and compare the task\nformulations, datasets and NLP solutions that have been developed for this\ntask, and also discuss the potentials and limitations of them. Based on our\ninsights, we outline promising research directions, including more\nfine-grained, detailed, fair, and practical detection models. We also highlight\nthe difference between fake news detection and other related tasks, and the\nimportance of NLP solutions for fake news detection.", "doi": "", "date": "2018-11-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.00770v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3319721919, "title": "Debunking Fake News One Feature at a Time", "abstract": "Identifying the stance of a news article body with respect to a certain\nheadline is the first step to automated fake news detection. In this paper, we\nintroduce a 2-stage ensemble model to solve the stance detection task. By using\nonly hand-crafted features as input to a gradient boosting classifier, we are\nable to achieve a score of 9161.5 out of 11651.25 (78.63%) on the official Fake\nNews Challenge (Stage 1) dataset. We identify the most useful features for\ndetecting fake news and discuss how sampling techniques can be used to improve\nrecall accuracy on a highly imbalanced dataset.", "doi": "", "date": "2018-08-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.02831v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2326095633, "title": "Weighted Accuracy Algorithmic Approach In Counteracting Fake News And\n  Disinformation", "abstract": "As the world is becoming more dependent on the internet for information\nexchange, some overzealous journalists, hackers, bloggers, individuals and\norganizations tend to abuse the gift of free information environment by\npolluting it with fake news, disinformation and pretentious content for their\nown agenda. Hence, there is the need to address the issue of fake news and\ndisinformation with utmost seriousness. This paper proposes a methodology for\nfake news detection and reporting through a constraint mechanism that utilizes\nthe combined weighted accuracies of four machine learning algorithms.", "doi": "10.2478/ers-2021-0007", "date": "2020-07-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.01535v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1742319037, "title": "An organized review of key factors for fake news detection", "abstract": "Fake news in social media has quickly become one of the most discussed topics\nin today's society. With false information proliferating and causing a\nsignificant impact in the political, economical, and social domains, research\nefforts to analyze and automatically identify this type of content have being\nconducted in the past few years. In this paper, we attempt to summarize the\nprincipal findings on the topic of fake news in social media, highlighting the\nmain research path taken and giving a particular focus on the detection of fake\nnews and bot accounts.", "doi": "", "date": "2021-02-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.13433v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1463677582, "title": "Fake News Detection on Social Media: A Data Mining Perspective", "abstract": "Social media for news consumption is a double-edged sword. On the one hand,\nits low cost, easy access, and rapid dissemination of information lead people\nto seek out and consume news from social media. On the other hand, it enables\nthe wide spread of \"fake news\", i.e., low quality news with intentionally false\ninformation. The extensive spread of fake news has the potential for extremely\nnegative impacts on individuals and society. Therefore, fake news detection on\nsocial media has recently become an emerging research that is attracting\ntremendous attention. Fake news detection on social media presents unique\ncharacteristics and challenges that make existing detection algorithms from\ntraditional news media ineffective or not applicable. First, fake news is\nintentionally written to mislead readers to believe false information, which\nmakes it difficult and nontrivial to detect based on news content; therefore,\nwe need to include auxiliary information, such as user social engagements on\nsocial media, to help make a determination. Second, exploiting this auxiliary\ninformation is challenging in and of itself as users' social engagements with\nfake news produce data that is big, incomplete, unstructured, and noisy.\nBecause the issue of fake news detection on social media is both challenging\nand relevant, we conducted this survey to further facilitate research on the\nproblem. In this survey, we present a comprehensive review of detecting fake\nnews on social media, including fake news characterizations on psychology and\nsocial theories, existing algorithms from a data mining perspective, evaluation\nmetrics and representative datasets. We also discuss related research areas,\nopen problems, and future research directions for fake news detection on social\nmedia.", "doi": "", "date": "2017-08-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1708.01967v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4032679529, "title": "Localization of Fake News Detection via Multitask Transfer Learning", "abstract": "The use of the internet as a fast medium of spreading fake news reinforces\nthe need for computational tools that combat it. Techniques that train fake\nnews classifiers exist, but they all assume an abundance of resources including\nlarge labeled datasets and expert-curated corpora, which low-resource languages\nmay not have. In this work, we make two main contributions: First, we alleviate\nresource scarcity by constructing the first expertly-curated benchmark dataset\nfor fake news detection in Filipino, which we call \"Fake News Filipino.\"\nSecond, we benchmark Transfer Learning (TL) techniques and show that they can\nbe used to train robust fake news classifiers from little data, achieving 91%\naccuracy on our fake news dataset, reducing the error by 14% compared to\nestablished few-shot baselines. Furthermore, lifting ideas from multitask\nlearning, we show that augmenting transformer-based transfer techniques with\nauxiliary language modeling losses improves their performance by adapting to\nwriting style. Using this, we improve TL performance by 4-6%, achieving an\naccuracy of 96% on our best model. Lastly, we show that our method generalizes\nwell to different types of news articles, including political news,\nentertainment news, and opinion articles.", "doi": "10.13140/rg.2.2.23028.40322", "date": "2019-10-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.09295v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1846946059, "title": "FAKEDETECTOR: Effective Fake News Detection with Deep Diffusive Neural\n  Network", "abstract": "In recent years, due to the booming development of online social networks,\nfake news for various commercial and political purposes has been appearing in\nlarge numbers and widespread in the online world. With deceptive words, online\nsocial network users can get infected by these online fake news easily, which\nhas brought about tremendous effects on the offline society already. An\nimportant goal in improving the trustworthiness of information in online social\nnetworks is to identify the fake news timely. This paper aims at investigating\nthe principles, methodologies and algorithms for detecting fake news articles,\ncreators and subjects from online social networks and evaluating the\ncorresponding performance. This paper addresses the challenges introduced by\nthe unknown characteristics of fake news and diverse connections among news\narticles, creators and subjects. This paper introduces a novel automatic fake\nnews credibility inference model, namely FAKEDETECTOR. Based on a set of\nexplicit and latent features extracted from the textual information,\nFAKEDETECTOR builds a deep diffusive network model to learn the representations\nof news articles, creators and subjects simultaneously. Extensive experiments\nhave been done on a real-world fake news dataset to compare FAKEDETECTOR with\nseveral state-of-the-art models, and the experimental results have demonstrated\nthe effectiveness of the proposed model.", "doi": "", "date": "2018-05-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1805.08751v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1276295434, "title": "Learning Hierarchical Discourse-level Structure for Fake News Detection", "abstract": "On the one hand, nowadays, fake news articles are easily propagated through\nvarious online media platforms and have become a grand threat to the\ntrustworthiness of information. On the other hand, our understanding of the\nlanguage of fake news is still minimal. Incorporating hierarchical\ndiscourse-level structure of fake and real news articles is one crucial step\ntoward a better understanding of how these articles are structured.\nNevertheless, this has rarely been investigated in the fake news detection\ndomain and faces tremendous challenges. First, existing methods for capturing\ndiscourse-level structure rely on annotated corpora which are not available for\nfake news datasets. Second, how to extract out useful information from such\ndiscovered structures is another challenge. To address these challenges, we\npropose Hierarchical Discourse-level Structure for Fake news detection. HDSF\nlearns and constructs a discourse-level structure for fake/real news articles\nin an automated and data-driven manner. Moreover, we identify insightful\nstructure-related properties, which can explain the discovered structures and\nboost our understating of fake news. Conducted experiments show the\neffectiveness of the proposed approach. Further structural analysis suggests\nthat real and fake news present substantial differences in the hierarchical\ndiscourse-level structures.", "doi": "", "date": "2019-02-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.07389v6", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1270754625, "title": "Fake News Spreader Detection on Twitter using Character N-Grams.\n  Notebook for PAN at CLEF 2020", "abstract": "The authors of fake news often use facts from verified news sources and mix\nthem with misinformation to create confusion and provoke unrest among the\nreaders. The spread of fake news can thereby have serious implications on our\nsociety. They can sway political elections, push down the stock price or crush\nreputations of corporations or public figures. Several websites have taken on\nthe mission of checking rumors and allegations, but are often not fast enough\nto check the content of all the news being disseminated. Especially social\nmedia websites have offered an easy platform for the fast propagation of\ninformation. Towards limiting fake news from being propagated among social\nmedia users, the task of this year's PAN 2020 challenge lays the focus on the\nfake news spreaders. The aim of the task is to determine whether it is possible\nto discriminate authors that have shared fake news in the past from those that\nhave never done it. In this notebook, we describe our profiling system for the\nfake news detection task on Twitter. For this, we conduct different feature\nextraction techniques and learning experiments from a multilingual perspective,\nnamely English and Spanish. Our final submitted systems use character n-grams\nas features in combination with a linear SVM for English and Logistic\nRegression for the Spanish language. Our submitted models achieve an overall\naccuracy of 73% and 79% on the English and Spanish official test set,\nrespectively. Our experiments show that it is difficult to differentiate\nsolidly fake news spreaders on Twitter from users who share credible\ninformation leaving room for further investigations. Our model ranked 3rd out\nof 72 competitors.", "doi": "", "date": "2020-09-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.13859v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2673205057, "title": "FaNDS: Fake News Detection System Using Energy Flow", "abstract": "Recently, the term \"fake news\" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.", "doi": "", "date": "2020-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.02097v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 976903589, "title": "Early Detection of Fake News by Utilizing the Credibility of News,\n  Publishers, and Users Based on Weakly Supervised Learning", "abstract": "The dissemination of fake news significantly affects personal reputation and\npublic trust. Recently, fake news detection has attracted tremendous attention,\nand previous studies mainly focused on finding clues from news content or\ndiffusion path. However, the required features of previous models are often\nunavailable or insufficient in early detection scenarios, resulting in poor\nperformance. Thus, early fake news detection remains a tough challenge.\nIntuitively, the news from trusted and authoritative sources or shared by many\nusers with a good reputation is more reliable than other news. Using the\ncredibility of publishers and users as prior weakly supervised information, we\ncan quickly locate fake news in massive news and detect them in the early\nstages of dissemination.\n  In this paper, we propose a novel Structure-aware Multi-head Attention\nNetwork (SMAN), which combines the news content, publishing, and reposting\nrelations of publishers and users, to jointly optimize the fake news detection\nand credibility prediction tasks. In this way, we can explicitly exploit the\ncredibility of publishers and users for early fake news detection. We conducted\nexperiments on three real-world datasets, and the results show that SMAN can\ndetect fake news in 4 hours with an accuracy of over 91%, which is much faster\nthan the state-of-the-art models.", "doi": "", "date": "2020-12-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.04233v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2609128878, "title": "Adversarial Active Learning based Heterogeneous Graph Neural Network for\n  Fake News Detection", "abstract": "The explosive growth of fake news along with destructive effects on politics,\neconomy, and public safety has increased the demand for fake news detection.\nFake news on social media does not exist independently in the form of an\narticle. Many other entities, such as news creators, news subjects, and so on,\nexist on social media and have relationships with news articles. Different\nentities and relationships can be modeled as a heterogeneous information\nnetwork (HIN). In this paper, we attempt to solve the fake news detection\nproblem with the support of a news-oriented HIN. We propose a novel fake news\ndetection framework, namely Adversarial Active Learning-based Heterogeneous\nGraph Neural Network (AA-HGNN) which employs a novel hierarchical attention\nmechanism to perform node representation learning in the HIN. AA-HGNN utilizes\nan active learning framework to enhance learning performance, especially when\nfacing the paucity of labeled data. An adversarial selector will be trained to\nquery high-value candidates for the active learning framework. When the\nadversarial active learning is completed, AA-HGNN detects fake news by\nclassifying news article nodes. Experiments with two real-world fake news\ndatasets show that our model can outperform text-based models and other\ngraph-based models when using less labeled data benefiting from the adversarial\nactive learning. As a model with generalizability, AA-HGNN also has the ability\nto be widely used in other node classification-related applications on\nheterogeneous graphs.", "doi": "", "date": "2021-01-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.11206v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 791555225, "title": "Embracing Domain Differences in Fake News: Cross-domain Fake News\n  Detection using Multi-modal Data", "abstract": "With the rapid evolution of social media, fake news has become a significant\nsocial problem, which cannot be addressed in a timely manner using manual\ninvestigation. This has motivated numerous studies on automating fake news\ndetection. Most studies explore supervised training models with different\nmodalities (e.g., text, images, and propagation networks) of news records to\nidentify fake news. However, the performance of such techniques generally drops\nif news records are coming from different domains (e.g., politics,\nentertainment), especially for domains that are unseen or rarely-seen during\ntraining. As motivation, we empirically show that news records from different\ndomains have significantly different word usage and propagation patterns.\nFurthermore, due to the sheer volume of unlabelled news records, it is\nchallenging to select news records for manual labelling so that the\ndomain-coverage of the labelled dataset is maximized. Hence, this work: (1)\nproposes a novel framework that jointly preserves domain-specific and\ncross-domain knowledge in news records to detect fake news from different\ndomains; and (2) introduces an unsupervised technique to select a set of\nunlabelled informative news records for manual labelling, which can be\nultimately used to train a fake news detection model that performs well for\nmany domains while minimizing the labelling cost. Our experiments show that the\nintegration of the proposed fake news model and the selective annotation\napproach achieves state-of-the-art performance for cross-domain news datasets,\nwhile yielding notable improvements for rarely-appearing domains in news\ndatasets.", "doi": "", "date": "2021-02-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.06314v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 145601388, "title": "Fake news as we feel it: perception and conceptualization of the term\n  \"fake news\" in the media", "abstract": "In this article, we quantitatively analyze how the term \"fake news\" is being\nshaped in news media in recent years. We study the perception and the\nconceptualization of this term in the traditional media using eight years of\ndata collected from news outlets based in 20 countries. Our results not only\ncorroborate previous indications of a high increase in the usage of the\nexpression \"fake news\", but also show contextual changes around this expression\nafter the United States presidential election of 2016. Among other results, we\nfound changes in the related vocabulary, in the mentioned entities, in the\nsurrounding topics and in the contextual polarity around the term \"fake news\",\nsuggesting that this expression underwent a change in perception and\nconceptualization after 2016. These outcomes expand the understandings on the\nusage of the term \"fake news\", helping to comprehend and more accurately\ncharacterize this relevant social phenomenon linked to misinformation and\nmanipulation.", "doi": "", "date": "2018-07-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1807.06926v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4107886392, "title": "\"Liar, Liar Pants on Fire\": A New Benchmark Dataset for Fake News\n  Detection", "abstract": "Automatic fake news detection is a challenging problem in deception\ndetection, and it has tremendous real-world political and social impacts.\nHowever, statistical approaches to combating fake news has been dramatically\nlimited by the lack of labeled benchmark datasets. In this paper, we present\nliar: a new, publicly available dataset for fake news detection. We collected a\ndecade-long, 12.8K manually labeled short statements in various contexts from\nPolitiFact.com, which provides detailed analysis report and links to source\ndocuments for each case. This dataset can be used for fact-checking research as\nwell. Notably, this new dataset is an order of magnitude larger than previously\nlargest public fake news datasets of similar type. Empirically, we investigate\nautomatic fake news detection based on surface-level linguistic patterns. We\nhave designed a novel, hybrid convolutional neural network to integrate\nmeta-data with text. We show that this hybrid approach can improve a text-only\ndeep learning model.", "doi": "", "date": "2017-05-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1705.00648v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3222842257, "title": "Studying Fake News via Network Analysis: Detection and Mitigation", "abstract": "Social media for news consumption is becoming increasingly popular due to its\neasy access, fast dissemination, and low cost. However, social media also\nenable the wide propagation of \"fake news\", i.e., news with intentionally false\ninformation. Fake news on social media poses significant negative societal\neffects, and also presents unique challenges. To tackle the challenges, many\nexisting works exploit various features, from a network perspective, to detect\nand mitigate fake news. In essence, news dissemination ecosystem involves three\ndimensions on social media, i.e., a content dimension, a social dimension, and\na temporal dimension. In this chapter, we will review network properties for\nstudying fake news, introduce popular network types and how these networks can\nbe used to detect and mitigation fake news on social media.", "doi": "", "date": "2018-04-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.10233v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2635155362, "title": "The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake\n  News", "abstract": "A large body of research work and efforts have been focused on detecting fake\nnews and building online fact-check systems in order to debunk fake news as\nsoon as possible. Despite the existence of these systems, fake news is still\nwildly shared by online users. It indicates that these systems may not be fully\nutilized. After detecting fake news, what is the next step to stop people from\nsharing it? How can we improve the utilization of these fact-check systems? To\nfill this gap, in this paper, we (i) collect and analyze online users called\nguardians, who correct misinformation and fake news in online discussions by\nreferring fact-checking URLs; and (ii) propose a novel fact-checking URL\nrecommendation model to encourage the guardians to engage more in fact-checking\nactivities. We found that the guardians usually took less than one day to reply\nto claims in online conversations and took another day to spread verified\ninformation to hundreds of millions of followers. Our proposed recommendation\nmodel outperformed four state-of-the-art models by 11%~33%. Our source code and\ndataset are available at https://github.com/nguyenvo09/CombatingFakeNews.", "doi": "", "date": "2018-06-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.07516v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4166411935, "title": "Tensor Factorization with Label Information for Fake News Detection", "abstract": "The buzz over the so-called \"fake news\" has created concerns about a\ndegenerated media environment and led to the need for technological solutions.\nAs the detection of fake news is increasingly considered a technological\nproblem, it has attracted considerable research. Most of these studies\nprimarily focus on utilizing information extracted from textual news content.\nIn contrast, we focus on detecting fake news solely based on structural\ninformation of social networks. We suggest that the underlying network\nconnections of users that share fake news are discriminative enough to support\nthe detection of fake news. Thereupon, we model each post as a network of\nfriendship interactions and represent a collection of posts as a\nmultidimensional tensor. Taking into account the available labeled data, we\npropose a tensor factorization method which associates the class labels of data\nsamples with their latent representations. Specifically, we combine a\nclassification error term with the standard factorization in a unified\noptimization process. Results on real-world datasets demonstrate that our\nproposed method is competitive against state-of-the-art methods by implementing\nan arguably simpler approach.", "doi": "", "date": "2019-08-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.03957v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3453839486, "title": "Sieving Fake News From Genuine: A Synopsis", "abstract": "With the rise of social media, it has become easier to disseminate fake news\nfaster and cheaper, compared to traditional news media, such as television and\nnewspapers. Recently this phenomenon has attracted lot of public attention,\nbecause it is causing significant social and financial impacts on their lives\nand businesses. Fake news are responsible for creating false, deceptive,\nmisleading, and suspicious information that can greatly effect the outcome of\nan event. This paper presents a synopsis that explains what are fake news with\nexamples and also discusses some of the current machine learning techniques,\nspecifically natural language processing (NLP) and deep learning, for\nautomatically predicting and detecting fake news. Based on this synopsis, we\nrecommend that there is a potential of using NLP and deep learning to improve\nautomatic detection of fake news, but with the right set of data and features.", "doi": "", "date": "2019-11-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.08516v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1984862441, "title": "BanFakeNews: A Dataset for Detecting Fake News in Bangla", "abstract": "Observing the damages that can be done by the rapid propagation of fake news\nin various sectors like politics and finance, automatic identification of fake\nnews using linguistic analysis has drawn the attention of the research\ncommunity. However, such methods are largely being developed for English where\nlow resource languages remain out of the focus. But the risks spawned by fake\nand manipulative news are not confined by languages. In this work, we propose\nan annotated dataset of ~50K news that can be used for building automated fake\nnews detection systems for a low resource language like Bangla. Additionally,\nwe provide an analysis of the dataset and develop a benchmark system with state\nof the art NLP techniques to identify Bangla fake news. To create this system,\nwe explore traditional linguistic features and neural network based methods. We\nexpect this dataset will be a valuable resource for building technologies to\nprevent the spreading of fake news and contribute in research with low resource\nlanguages.", "doi": "", "date": "2020-04-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.08789v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1507020360, "title": "Where Are the Facts? Searching for Fact-checked Information to Alleviate\n  the Spread of Fake News", "abstract": "Although many fact-checking systems have been developed in academia and\nindustry, fake news is still proliferating on social media. These systems\nmostly focus on fact-checking but usually neglect online users who are the main\ndrivers of the spread of misinformation. How can we use fact-checked\ninformation to improve users' consciousness of fake news to which they are\nexposed? How can we stop users from spreading fake news? To tackle these\nquestions, we propose a novel framework to search for fact-checking articles,\nwhich address the content of an original tweet (that may contain\nmisinformation) posted by online users. The search can directly warn fake news\nposters and online users (e.g. the posters' followers) about misinformation,\ndiscourage them from spreading fake news, and scale up verified content on\nsocial media. Our framework uses both text and images to search for\nfact-checking articles, and achieves promising results on real-world datasets.\nOur code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.", "doi": "", "date": "2020-10-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.03159v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 972653879, "title": "Perceptions of News Sharing and Fake News in Singapore", "abstract": "Fake news is a prevalent problem that can undermine citizen engagement and\nbecome an obstacle to the goals of civic tech. To understand consumers'\nreactions and actions towards fake news, and their trust in various news media,\nwe conducted a survey in Singapore. We found that fake news stem largely from\ninstant messaging apps and social media, and that the problem of fake news was\nattributed more to its sharing than to its creation. Verification of news was\ndone mainly by using a search engine to check and cross-reference the news.\nAmongst the top three sources to obtain news, there was low trust reported in\nsocial media, high trust in local news channels, and highest trust in\ngovernment communication platforms. The strong trust in government\ncommunication platforms suggests that top-down civic tech initiatives may have\ngreat potential to effectively manage fake news and promote citizen engagement\nin Singapore.", "doi": "", "date": "2020-10-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.07607v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1219903128, "title": "Lexicon generation for detecting fake news", "abstract": "With the digitization of media, an immense amount of news data has been\ngenerated by online sources, including mainstream media outlets as well as\nsocial networks. However, the ease of production and distribution resulted in\ncirculation of fake news as well as credible, authentic news. The pervasive\ndissemination of fake news has extreme negative impacts on individuals and\nsociety. Therefore, fake news detection has recently become an emerging topic\nas an interdisciplinary research field that is attracting significant attention\nfrom many research disciplines, including social sciences and linguistics. In\nthis study, we propose a method primarily based on lexicons including a scoring\nsystem to facilitate the detection of the fake news in Turkish. We contribute\nto the literature by collecting a novel, large scale, and credible dataset of\nTurkish news, and by constructing the first fake news detection lexicon for\nTurkish.", "doi": "", "date": "2020-10-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.11089v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 320828744, "title": "The Rise and Fall of Fake News sites: A Traffic Analysis", "abstract": "Over the past decade, we have witnessed the rise of misinformation on the\nInternet, with online users constantly falling victims of fake news. A\nmultitude of past studies have analyzed fake news diffusion mechanics and\ndetection and mitigation techniques. However, there are still open questions\nabout their operational behavior such as: How old are fake news websites? Do\nthey typically stay online for long periods of time? Do such websites\nsynchronize with each other their up and down time? Do they share similar\ncontent through time? Which third-parties support their operations? How much\nuser traffic do they attract, in comparison to mainstream or real news\nwebsites? In this paper, we perform a first of its kind investigation to answer\nsuch questions regarding the online presence of fake news websites and\ncharacterize their behavior in comparison to real news websites. Based on our\nfindings, we build a content-agnostic ML classifier for automatic detection of\nfake news websites (i.e. accuracy) that are not yet included in manually\ncurated blacklists.", "doi": "", "date": "2021-03-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.09258v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2853478407, "title": "'No, auntie, that's false': Female baby boomers develop critical skills\n  to confront fake news with guidance from relatives", "abstract": "The spread of fake news has been increasing, which gives rise to a special\ninterest in the development of identification and coping skills among news\nconsumers so that they can filter out misleading information. Studies suggest\nthat older people share more fake news from social media. There is scarce\nliterature that analyse how baby boomers behave in the face of fake news. The\npurpose of this study is to examine how female baby boomers deal with fake news\non Facebook and their available resources to learn how to identify and handle\ndubious information. A qualitative study and thematic analysis were conducted\nusing information obtained from interviewing female baby boomers. Four themes\nemerge from the analysis, revealing that participants recognise that they can\nidentify fake news but may not always be able to do so due to limitations in\ntheir understanding of an issue or uncertainty about its source. Participants\nshow participants empirically develop critical identification and filtering\nskills with the assistance from close family members.", "doi": "", "date": "2021-07-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.12312v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4190644249, "title": "Mitigation of Diachronic Bias in Fake News Detection Dataset", "abstract": "Fake news causes significant damage to society.To deal with these fake news,\nseveral studies on building detection models and arranging datasets have been\nconducted. Most of the fake news datasets depend on a specific time period.\nConsequently, the detection models trained on such a dataset have difficulty\ndetecting novel fake news generated by political changes and social changes;\nthey may possibly result in biased output from the input, including specific\nperson names and organizational names. We refer to this problem as\n\\textbf{Diachronic Bias} because it is caused by the creation date of news in\neach dataset. In this study, we confirm the bias, especially proper nouns\nincluding person names, from the deviation of phrase appearances in each\ndataset. Based on these findings, we propose masking methods using Wikidata to\nmitigate the influence of person names and validate whether they make fake news\ndetection models robust through experiments with in-domain and out-of-domain\ndata.", "doi": "", "date": "2021-08-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12601v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2361353377, "title": "Weak Supervision for Fake News Detection via Reinforcement Learning", "abstract": "Today social media has become the primary source for news. Via social media\nplatforms, fake news travel at unprecedented speeds, reach global audiences and\nput users and communities at great risk. Therefore, it is extremely important\nto detect fake news as early as possible. Recently, deep learning based\napproaches have shown improved performance in fake news detection. However, the\ntraining of such models requires a large amount of labeled data, but manual\nannotation is time-consuming and expensive. Moreover, due to the dynamic nature\nof news, annotated samples may become outdated quickly and cannot represent the\nnews articles on newly emerged events. Therefore, how to obtain fresh and\nhigh-quality labeled samples is the major challenge in employing deep learning\nmodels for fake news detection. In order to tackle this challenge, we propose a\nreinforced weakly-supervised fake news detection framework, i.e., WeFEND, which\ncan leverage users' reports as weak supervision to enlarge the amount of\ntraining data for fake news detection. The proposed framework consists of three\nmain components: the annotator, the reinforced selector and the fake news\ndetector. The annotator can automatically assign weak labels for unlabeled news\nbased on users' reports. The reinforced selector using reinforcement learning\ntechniques chooses high-quality samples from the weakly labeled data and\nfilters out those low-quality ones that may degrade the detector's prediction\nperformance. The fake news detector aims to identify fake news based on the\nnews content. We tested the proposed framework on a large collection of news\narticles published via WeChat official accounts and associated user reports.\nExtensive experiments on this dataset show that the proposed WeFEND model\nachieves the best performance compared with the state-of-the-art methods.", "doi": "", "date": "2019-12-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.12520v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1880915272, "title": "Fake News Detection in Social Networks via Crowd Signals", "abstract": "Our work considers leveraging crowd signals for detecting fake news and is\nmotivated by tools recently introduced by Facebook that enable users to flag\nfake news. By aggregating users' flags, our goal is to select a small subset of\nnews every day, send them to an expert (e.g., via a third-party fact-checking\norganization), and stop the spread of news identified as fake by an expert. The\nmain objective of our work is to minimize the spread of misinformation by\nstopping the propagation of fake news in the network. It is especially\nchallenging to achieve this objective as it requires detecting fake news with\nhigh-confidence as quickly as possible. We show that in order to leverage\nusers' flags efficiently, it is crucial to learn about users' flagging\naccuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian\ninference for detecting fake news and jointly learns about users' flagging\naccuracy over time. Our algorithm employs posterior sampling to actively trade\noff exploitation (selecting news that maximize the objective value at a given\nepoch) and exploration (selecting news that maximize the value of information\ntowards learning about users' flagging accuracy). We demonstrate the\neffectiveness of our approach via extensive experiments and show the power of\nleveraging community signals for fake news detection.", "doi": "", "date": "2017-11-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.09025v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2271397016, "title": "This Just In: Fake News Packs a Lot in Title, Uses Simpler, Repetitive\n  Content in Text Body, More Similar to Satire than Real News", "abstract": "The problem of fake news has gained a lot of attention as it is claimed to\nhave had a significant impact on 2016 US Presidential Elections. Fake news is\nnot a new problem and its spread in social networks is well-studied. Often an\nunderlying assumption in fake news discussion is that it is written to look\nlike real news, fooling the reader who does not check for reliability of the\nsources or the arguments in its content. Through a unique study of three data\nsets and features that capture the style and the language of articles, we show\nthat this assumption is not true. Fake news in most cases is more similar to\nsatire than to real news, leading us to conclude that persuasion in fake news\nis achieved through heuristics rather than the strength of arguments. We show\noverall title structure and the use of proper nouns in titles are very\nsignificant in differentiating fake from real. This leads us to conclude that\nfake news is targeted for audiences who are not likely to read beyond titles\nand is aimed at creating mental associations between entities and claims.", "doi": "", "date": "2017-03-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1703.09398v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2732850406, "title": "Identifying Nuances in Fake News vs. Satire: Using Semantic and\n  Linguistic Cues", "abstract": "The blurry line between nefarious fake news and protected-speech satire has\nbeen a notorious struggle for social media platforms. Further to the efforts of\nreducing exposure to misinformation on social media, purveyors of fake news\nhave begun to masquerade as satire sites to avoid being demoted. In this work,\nwe address the challenge of automatically classifying fake news versus satire.\nPrevious work have studied whether fake news and satire can be distinguished\nbased on language differences. Contrary to fake news, satire stories are\nusually humorous and carry some political or social message. We hypothesize\nthat these nuances could be identified using semantic and linguistic cues.\nConsequently, we train a machine learning method using semantic representation,\nwith a state-of-the-art contextual language model, and with linguistic features\nbased on textual coherence metrics. Empirical evaluation attests to the merits\nof our approach compared to the language-based baseline and sheds light on the\nnuances between fake news and satire. As avenues for future work, we consider\nstudying additional linguistic features related to the humor aspect, and\nenriching the data with current news events, to help identify a political or\nsocial message.", "doi": "10.18653/v1/d19-5004", "date": "2019-10-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.01160v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 31859008, "title": "Fake news propagate differently from real news even at early stages of\n  spreading", "abstract": "Social media can be a double-edged sword for society, either as a convenient\nchannel exchanging ideas or as an unexpected conduit circulating fake news\nthrough a large population. While existing studies of fake news focus on\ntheoretical modeling of propagation or identification methods based on machine\nlearning, it is important to understand the realistic mechanisms between\ntheoretical models and black-box methods. Here we track large databases of fake\nnews and real news in both, Weibo in China and Twitter in Japan from different\nculture, which include their complete traces of re-postings. We find in both\nonline social networks that fake news spreads distinctively from real news even\nat early stages of propagation, e.g. five hours after the first re-postings.\nOur finding demonstrates collective structural signals that help to understand\nthe different propagation evolution of fake news and real news. Different from\nearlier studies, identifying the topological properties of the information\npropagation at early stages may offer novel features for early detection of\nfake news in social media.", "doi": "", "date": "2018-03-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1803.03443v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1536271918, "title": "MALCOM: Generating Malicious Comments to Attack Neural Fake News\n  Detection Models", "abstract": "In recent years, the proliferation of so-called \"fake news\" has caused much\ndisruptions in society and weakened the news ecosystem. Therefore, to mitigate\nsuch problems, researchers have developed state-of-the-art models to\nauto-detect fake news on social media using sophisticated data science and\nmachine learning techniques. In this work, then, we ask \"what if adversaries\nattempt to attack such detection models?\" and investigate related issues by (i)\nproposing a novel threat model against fake news detectors, in which\nadversaries can post malicious comments toward news articles to mislead fake\nnews detectors, and (ii) developing MALCOM, an end-to-end adversarial comment\ngeneration framework to achieve such an attack. Through a comprehensive\nevaluation, we demonstrate that about 94% and 93.5% of the time on average\nMALCOM can successfully mislead five of the latest neural detection models to\nalways output targeted real and fake news labels. Furthermore, MALCOM can also\nfool black box fake news detectors to always output real news labels 90% of the\ntime on average. We also compare our attack model with four baselines across\ntwo real-world datasets, not only on attack performance but also on generated\nquality, coherency, transferability, and robustness.", "doi": "", "date": "2020-09-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.01048v2", "pdf": ""}, "publisher-venue": "the 20th IEEE International Conference on Data Mining\\n  (ICDM 2020)", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3228249976, "title": "Fake News Detection through Graph Comment Advanced Learning", "abstract": "Disinformation has long been regarded as a severe social problem, where fake\nnews is one of the most representative issues. What is worse, today's highly\ndeveloped social media makes fake news widely spread at incredible speed,\nbringing in substantial harm to various aspects of human life. Yet, the\npopularity of social media also provides opportunities to better detect fake\nnews. Unlike conventional means which merely focus on either content or user\ncomments, effective collaboration of heterogeneous social media information,\nincluding content and context factors of news, users' comments and the\nengagement of social media with users, will hopefully give rise to better\ndetection of fake news.\n  Motivated by the above observations, a novel detection framework, namely\ngraph comment-user advanced learning framework (GCAL) is proposed in this\npaper. User-comment information is crucial but not well studied in fake news\ndetection. Thus, we model user-comment context through network representation\nlearning based on heterogeneous graph neural network. We conduct experiments on\ntwo real-world datasets, which demonstrate that the proposed joint model\noutperforms 8 state-of-the-art baseline methods for fake news detection (at\nleast 4% in Accuracy, 7% in Recall and 5% in F1). Moreover, the proposed method\nis also explainable.", "doi": "", "date": "2020-11-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.01579v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2803771738, "title": "Cross-SEAN: A Cross-Stitch Semi-Supervised Neural Attention Model for\n  COVID-19 Fake News Detection", "abstract": "As the COVID-19 pandemic sweeps across the world, it has been accompanied by\na tsunami of fake news and misinformation on social media. At the time when\nreliable information is vital for public health and safety, COVID-19 related\nfake news has been spreading even faster than the facts. During times such as\nthe COVID-19 pandemic, fake news can not only cause intellectual confusion but\ncan also place lives of people at risk. This calls for an immediate need to\ncontain the spread of such misinformation on social media. We introduce CTF,\nthe first COVID-19 Twitter fake news dataset with labeled genuine and fake\ntweets. Additionally, we propose Cross-SEAN, a cross-stitch based\nsemi-supervised end-to-end neural attention model, which leverages the large\namount of unlabelled data. Cross-SEAN partially generalises to emerging fake\nnews as it learns from relevant external knowledge. We compare Cross-SEAN with\nseven state-of-the-art fake news detection methods. We observe that it achieves\n$0.95$ F1 Score on CTF, outperforming the best baseline by $9\\%$. We also\ndevelop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time\ndetection of fake tweets.", "doi": "", "date": "2021-02-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.08924v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1302673835, "title": "Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment", "abstract": "The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations.", "doi": "", "date": "2021-05-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.09114v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1730281125, "title": "Credulous Users and Fake News: a Real Case Study on the Propagation in\n  Twitter", "abstract": "Recent studies have confirmed a growing trend, especially among youngsters,\nof using Online Social Media as favourite information platform at the expense\nof traditional mass media. Indeed, they can easily reach a wide audience at a\nhigh speed; but exactly because of this they are the preferred medium for\ninfluencing public opinion via so-called fake news. Moreover, there is a\ngeneral agreement that the main vehicle of fakes news are malicious software\nrobots (bots) that automatically interact with human users. In previous work we\nhave considered the problem of tagging human users in Online Social Networks as\ncredulous users. Specifically, we have considered credulous those users with\nrelatively high number of bot friends when compared to total number of their\nsocial friends. We consider this group of users worth of attention because they\nmight have a higher exposure to malicious activities and they may contribute to\nthe spreading of fake information by sharing dubious content. In this work,\nstarting from a dataset of fake news, we investigate the behaviour and the\ndegree of involvement of credulous users in fake news diffusion. The study aims\nto: (i) fight fake news by considering the content diffused by credulous users;\n(ii) highlight the relationship between credulous users and fake news\nspreading; (iii) target fake news detection by focusing on the analysis of\nspecific accounts more exposed to malicious activities of bots. Our first\nresults demonstrate a strong involvement of credulous users in fake news\ndiffusion. This findings are calling for tools that, by performing data\nstreaming on credulous' users actions, enables us to perform targeted\nfact-checking.", "doi": "", "date": "2020-05-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.03550v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 502767384, "title": "A Stylometric Inquiry into Hyperpartisan and Fake News", "abstract": "This paper reports on a writing style analysis of hyperpartisan (i.e.,\nextremely one-sided) news in connection to fake news. It presents a large\ncorpus of 1,627 articles that were manually fact-checked by professional\njournalists from BuzzFeed. The articles originated from 9 well-known political\npublishers, 3 each from the mainstream, the hyperpartisan left-wing, and the\nhyperpartisan right-wing. In sum, the corpus contains 299 fake news, 97% of\nwhich originated from hyperpartisan publishers.\n  We propose and demonstrate a new way of assessing style similarity between\ntext categories via Unmasking---a meta-learning approach originally devised for\nauthorship verification---, revealing that the style of left-wing and\nright-wing news have a lot more in common than any of the two have with the\nmainstream. Furthermore, we show that hyperpartisan news can be discriminated\nwell by its style from the mainstream (F1=0.78), as can be satire from both\n(F1=0.81). Unsurprisingly, style-based fake news detection does not live up to\nscratch (F1=0.46). Nevertheless, the former results are important to implement\npre-screening for fake news detectors.", "doi": "", "date": "2017-02-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1702.05638v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3763437055, "title": "Fake News Mitigation via Point Process Based Intervention", "abstract": "We propose the first multistage intervention framework that tackles fake news\nin social networks by combining reinforcement learning with a point process\nnetwork activity model. The spread of fake news and mitigation events within\nthe network is modeled by a multivariate Hawkes process with additional\nexogenous control terms. By choosing a feature representation of states,\ndefining mitigation actions and constructing reward functions to measure the\neffectiveness of mitigation activities, we map the problem of fake news\nmitigation into the reinforcement learning framework. We develop a policy\niteration method unique to the multivariate networked point process, with the\ngoal of optimizing the actions for maximal total reward under budget\nconstraints. Our method shows promising performance in real-time intervention\nexperiments on a Twitter network to mitigate a surrogate fake news campaign,\nand outperforms alternatives on synthetic datasets.", "doi": "", "date": "2017-03-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1703.07823v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2867829449, "title": "A Deep Ensemble Framework for Fake News Detection and Classification", "abstract": "Fake news, rumor, incorrect information, and misinformation detection are\nnowadays crucial issues as these might have serious consequences for our social\nfabrics. The rate of such information is increasing rapidly due to the\navailability of enormous web information sources including social media feeds,\nnews blogs, online newspapers etc.\n  In this paper, we develop various deep learning models for detecting fake\nnews and classifying them into the pre-defined fine-grained categories.\n  At first, we develop models based on Convolutional Neural Network (CNN) and\nBi-directional Long Short Term Memory (Bi-LSTM) networks. The representations\nobtained from these two models are fed into a Multi-layer Perceptron Model\n(MLP) for the final classification. Our experiments on a benchmark dataset show\npromising results with an overall accuracy of 44.87\\%, which outperforms the\ncurrent state of the art.", "doi": "", "date": "2018-11-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.04670v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3730932614, "title": "Influence of fake news in Twitter during the 2016 US presidential\n  election", "abstract": "The dynamics and influence of fake news on Twitter during the 2016 US\npresidential election remains to be clarified. Here, we use a dataset of 171\nmillion tweets in the five months preceding the election day to identify 30\nmillion tweets, from 2.2 million users, which contain a link to news outlets.\nBased on a classification of news outlets curated by www.opensources.co, we\nfind that 25% of these tweets spread either fake or extremely biased news. We\ncharacterize the networks of information flow to find the most influential\nspreaders of fake and traditional news and use causal modeling to uncover how\nfake news influenced the presidential election. We find that, while top\ninfluencers spreading traditional center and left leaning news largely\ninfluence the activity of Clinton supporters, this causality is reversed for\nthe fake news: the activity of Trump supporters influences the dynamics of the\ntop fake news spreaders.", "doi": "10.1038/s41467-018-07761-2", "date": "2018-03-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1803.08491v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4100158350, "title": "Combating Fake News: A Survey on Identification and Mitigation\n  Techniques", "abstract": "The proliferation of fake news on social media has opened up new directions\nof research for timely identification and containment of fake news, and\nmitigation of its widespread impact on public opinion. While much of the\nearlier research was focused on identification of fake news based on its\ncontents or by exploiting users' engagements with the news on social media,\nthere has been a rising interest in proactive intervention strategies to\ncounter the spread of misinformation and its impact on society. In this survey,\nwe describe the modern-day problem of fake news and, in particular, highlight\nthe technical challenges associated with it. We discuss existing methods and\ntechniques applicable to both identification and mitigation, with a focus on\nthe significant advances in each method and their advantages and limitations.\nIn addition, research has often been limited by the quality of existing\ndatasets and their specific application contexts. To alleviate this problem, we\ncomprehensively compile and summarize characteristic features of available\ndatasets. Furthermore, we outline new directions of research to facilitate\nfuture development of effective and interdisciplinary solutions.", "doi": "", "date": "2019-01-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.06437v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2719518042, "title": "Using Blockchain to Rein in The New Post-Truth World and Check The\n  Spread of Fake News", "abstract": "In recent years, `fake news' has become a global issue that raises\nunprecedented challenges for human society and democracy. This problem has\narisen due to the emergence of various concomitant phenomena such as (1) the\ndigitization of human life and the ease of disseminating news through social\nnetworking applications (such as Facebook and WhatsApp); (2) the availability\nof `big data' that allows customization of news feeds and the creation of\npolarized so-called `filter-bubbles'; and (3) the rapid progress made by\ngenerative machine learning (ML) and deep learning (DL) algorithms in creating\nrealistic-looking yet fake digital content (such as text, images, and videos).\nThere is a crucial need to combat the rampant rise of fake news and\ndisinformation. In this paper, we propose a high-level overview of a\nblockchain-based framework for fake news prevention and highlight the various\ndesign issues and consideration of such a blockchain-based framework for\ntackling fake news.", "doi": "", "date": "2019-03-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.11899v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1530765210, "title": "Check-It: A Plugin for Detecting and Reducing the Spread of Fake News\n  and Misinformation on the Web", "abstract": "Over the past few years, we have been witnessing the rise of misinformation\non the Web. People fall victims of fake news during their daily lives and\nassist their further propagation knowingly and inadvertently. There have been\nmany initiatives that are trying to mitigate the damage caused by fake news,\nfocusing on signals from either domain flag-lists, online social networks or\nartificial intelligence. In this work, we present Check-It, a system that\ncombines, in an intelligent way, a variety of signals into a pipeline for fake\nnews identification. Check-It is developed as a web browser plugin with the\nobjective of efficient and timely fake news detection, respecting the user's\nprivacy. Experimental results show that Check-It is able to outperform the\nstate-of-the-art methods. On a dataset, consisting of 9 millions of articles\nlabeled as fake and real, Check-It obtains classification accuracies that\nexceed 99%.", "doi": "", "date": "2019-05-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.04260v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1383883383, "title": "On the Coherence of Fake News Articles", "abstract": "The generation and spread of fake news within new and online media sources is\nemerging as a phenomenon of high societal significance. Combating them using\ndata-driven analytics has been attracting much recent scholarly interest. In\nthis study, we analyze the textual coherence of fake news articles vis-a-vis\nlegitimate ones. We develop three computational formulations of textual\ncoherence drawing upon the state-of-the-art methods in natural language\nprocessing and data science. Two real-world datasets from widely different\ndomains which have fake/legitimate article labellings are then analyzed with\nrespect to textual coherence. We observe apparent differences in textual\ncoherence across fake and legitimate news articles, with fake news articles\nconsistently scoring lower on coherence as compared to legitimate news ones.\nWhile the relative coherence shortfall of fake news articles as compared to\nlegitimate ones form the main observation from our study, we analyze several\naspects of the differences and outline potential avenues of further inquiry.", "doi": "", "date": "2019-06-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.11126v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1529029191, "title": "Attributed Multi-Relational Attention Network for Fact-checking URL\n  Recommendation", "abstract": "To combat fake news, researchers mostly focused on detecting fake news and\njournalists built and maintained fact-checking sites (e.g., Snopes.com and\nPolitifact.com). However, fake news dissemination has been greatly promoted via\nsocial media sites, and these fact-checking sites have not been fully utilized.\nTo overcome these problems and complement existing methods against fake news,\nin this paper we propose a deep-learning based fact-checking URL recommender\nsystem to mitigate impact of fake news in social media sites such as Twitter\nand Facebook. In particular, our proposed framework consists of a\nmulti-relational attentive module and a heterogeneous graph attention network\nto learn complex/semantic relationship between user-URL pairs, user-user pairs,\nand URL-URL pairs. Extensive experiments on a real-world dataset show that our\nproposed framework outperforms eight state-of-the-art recommendation models,\nachieving at least 3~5.3% improvement.", "doi": "", "date": "2020-01-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.02214v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2972708789, "title": "Improving Generalizability of Fake News Detection Methods using\n  Propensity Score Matching", "abstract": "Recently, due to the booming influence of online social networks, detecting\nfake news is drawing significant attention from both academic communities and\ngeneral public. In this paper, we consider the existence of confounding\nvariables in the features of fake news and use Propensity Score Matching (PSM)\nto select generalizable features in order to reduce the effects of the\nconfounding variables. Experimental results show that the generalizability of\nfake news method is significantly better by using PSM than using raw frequency\nto select features. We investigate multiple types of fake news methods\n(classifiers) such as logistic regression, random forests, and support vector\nmachines. We have consistent observations of performance improvement.", "doi": "", "date": "2020-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.00838v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1118429353, "title": "SAFE: Similarity-Aware Multi-Modal Fake News Detection", "abstract": "Effective detection of fake news has recently attracted significant\nattention. Current studies have made significant contributions to predicting\nfake news with less focus on exploiting the relationship (similarity) between\nthe textual and visual information in news articles. Attaching importance to\nsuch similarity helps identify fake news stories that, for example, attempt to\nuse irrelevant images to attract readers' attention. In this work, we propose a\n$\\mathsf{S}$imilarity-$\\mathsf{A}$ware $\\mathsf{F}$ak$\\mathsf{E}$ news\ndetection method ($\\mathsf{SAFE}$) which investigates multi-modal (textual and\nvisual) information of news articles. First, neural networks are adopted to\nseparately extract textual and visual features for news representation. We\nfurther investigate the relationship between the extracted features across\nmodalities. Such representations of news textual and visual information along\nwith their relationship are jointly learned and used to predict fake news. The\nproposed method facilitates recognizing the falsity of news articles based on\ntheir text, images, or their \"mismatches.\" We conduct extensive experiments on\nlarge-scale real-world data, which demonstrate the effectiveness of the\nproposed method.", "doi": "", "date": "2020-02-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.04981v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2211332909, "title": "Anger makes fake news viral online", "abstract": "Fake news that manipulates political elections, strikes financial systems,\nand even incites riots is more viral than real news online, resulting in\nunstable societies and buffeted democracy. The easier contagion of fake news\nonline can be causally explained by the greater anger it carries. The same\nresults in Twitter and Weibo indicate that this mechanism is independent of the\nplatform. Moreover, mutations in emotions like increasing anger will\nprogressively speed up the information spread. Specifically, increasing the\noccupation of anger by 0.1 and reducing that of joy by 0.1 will produce nearly\n6 more retweets in the Weibo dataset. Offline questionnaires reveal that anger\nleads to more incentivized audiences in terms of anxiety management and\ninformation sharing and accordingly makes fake news more contagious than real\nnews online. Cures such as tagging anger in social media could be implemented\nto slow or prevent the contagion of fake news at the source.", "doi": "", "date": "2020-04-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.10399v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3705376194, "title": "Universal Fake News Collection System using Debunking Tweets", "abstract": "Large numbers of people use Social Networking Services (SNS) for easy access\nto various news, but they have more opportunities to obtain and share ``fake\nnews'' carrying false information. Partially to combat fake news, several\nfact-checking sites such as Snopes and PolitiFact have been founded.\nNevertheless, these sites rely on time-consuming and labor-intensive tasks.\nMoreover, their available languages are not extensive. To address these\ndifficulties, we propose a new fake news collection system based on rule-based\n(unsupervised) frameworks that can be extended easily for various languages.\nThe system collects news with high probability of being fake by debunking\ntweets by users and presents event clusters gathering higher attention. Our\nsystem currently functions in two languages: English and Japanese. It shows\nevent clusters, 65\\% of which are actually fake. In future studies, it will be\napplied to other languages and will be published with a large fake news\ndataset.", "doi": "", "date": "2020-07-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.14083v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3909730531, "title": "Similarity Detection Pipeline for Crawling a Topic Related Fake News\n  Corpus", "abstract": "Fake news detection is a challenging task aiming to reduce human time and\neffort to check the truthfulness of news. Automated approaches to combat fake\nnews, however, are limited by the lack of labeled benchmark datasets,\nespecially in languages other than English. Moreover, many publicly available\ncorpora have specific limitations that make them difficult to use. To address\nthis problem, our contribution is threefold. First, we propose a new, publicly\navailable German topic related corpus for fake news detection. To the best of\nour knowledge, this is the first corpus of its kind. In this regard, we\ndeveloped a pipeline for crawling similar news articles. As our third\ncontribution, we conduct different learning experiments to detect fake news.\nThe best performance was achieved using sentence level embeddings from SBERT in\ncombination with a Bi-LSTM (k=0.88).", "doi": "", "date": "2020-09-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.13367v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3943095341, "title": "Fake or Real? A Study of Arabic Satirical Fake News", "abstract": "One very common type of fake news is satire which comes in a form of a news\nwebsite or an online platform that parodies reputable real news agencies to\ncreate a sarcastic version of reality. This type of fake news is often\ndisseminated by individuals on their online platforms as it has a much stronger\neffect in delivering criticism than through a straightforward message. However,\nwhen the satirical text is disseminated via social media without mention of its\nsource, it can be mistaken for real news. This study conducts several\nexploratory analyses to identify the linguistic properties of Arabic fake news\nwith satirical content. We exploit these features to build a number of machine\nlearning models capable of identifying satirical fake news with an accuracy of\nup to 98.6%.", "doi": "", "date": "2020-11-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.00452v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1727363081, "title": "Transformer based Automatic COVID-19 Fake News Detection System", "abstract": "Recent rapid technological advancements in online social networks such as\nTwitter have led to a great incline in spreading false information and fake\nnews. Misinformation is especially prevalent in the ongoing coronavirus disease\n(COVID-19) pandemic, leading to individuals accepting bogus and potentially\ndeleterious claims and articles. Quick detection of fake news can reduce the\nspread of panic and confusion among the public. For our analysis in this paper,\nwe report a methodology to analyze the reliability of information shared on\nsocial media pertaining to the COVID-19 pandemic. Our best approach is based on\nan ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting\nfake news. This model was trained and evaluated in the context of the\nConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our\nsystem obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.", "doi": "", "date": "2021-01-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.00180v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2530913045, "title": "TUDublin team at Constraint@AAAI2021 -- COVID19 Fake News Detection", "abstract": "The paper is devoted to the participation of the TUDublin team in\nConstraint@AAAI2021 - COVID19 Fake News Detection Challenge. Today, the problem\nof fake news detection is more acute than ever in connection with the pandemic.\nThe number of fake news is increasing rapidly and it is necessary to create AI\ntools that allow us to identify and prevent the spread of false information\nabout COVID-19 urgently. The main goal of the work was to create a model that\nwould carry out a binary classification of messages from social media as real\nor fake news in the context of COVID-19. Our team constructed the ensemble\nconsisting of Bidirectional Long Short Term Memory, Support Vector Machine,\nLogistic Regression, Naive Bayes and a combination of Logistic Regression and\nNaive Bayes. The model allowed us to achieve 0.94 F1-score, which is within 5\\%\nof the best result.", "doi": "", "date": "2021-01-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.05701v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 753598587, "title": "Detecting Fake News Using Machine Learning : A Systematic Literature\n  Review", "abstract": "Internet is one of the important inventions and a large number of persons are\nits users. These persons use this for different purposes. There are different\nsocial media platforms that are accessible to these users. Any user can make a\npost or spread the news through the online platforms. These platforms do not\nverify the users or their posts. So some of the users try to spread fake news\nthrough these platforms. These news can be propaganda against an individual,\nsociety, organization or political party. A human being is unable to detect all\nthese fake news. So there is a need for machine learning classifiers that can\ndetect these fake news automatically. Use of machine learning classifiers for\ndetecting fake news is described in this systematic literature review.", "doi": "", "date": "2021-02-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.04458v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 315976787, "title": "Multimodal Fusion with BERT and Attention Mechanism for Fake News\n  Detection", "abstract": "Fake news detection is an important task for increasing the credibility of\ninformation on the media since fake news is constantly spreading on social\nmedia every day and it is a very serious concern in our society. Fake news is\nusually created by manipulating images, texts, and videos. In this paper, we\npresent a novel method for detecting fake news by fusing multimodal features\nderived from textual and visual data. Specifically, we used a pre-trained BERT\nmodel to learn text features and a VGG-19 model pre-trained on the ImageNet\ndataset to extract image features. We proposed a scale-dot product attention\nmechanism to capture the relationship between text features and visual\nfeatures. Experimental results showed that our approach performs better than\nthe current state-of-the-art method on a public Twitter dataset by 3.1%\naccuracy.", "doi": "", "date": "2021-04-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.11476v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1387651510, "title": "Three prophylactic interventions to counter fake news on social media", "abstract": "Fake news on Social Media undermines democratic institutions and processes.\nEspecially since 2016, researchers from many disciplines have focussed on ways\nto address the phenomenon. Much of the research focus to date has been on\nidentification and understanding the nature of the phenomenon in and between\nsocial networks and of a rather reactive nature. We propose interventions that\nfocus on individual user empowerment, and social media structural change that\nis prophylactic (pre exposure), rather than therapeutic (post exposure) with\nthe goal of reducing the population exposed to fake news. We investigate\ninterventions that result in greater user elaboration (cognitive effort) before\nexposure to fake news. We propose three interventions i) psychological\ninoculation, ii) fostering digital and media literacy and iii) imposition of\nuser transaction costs. Each intervention promises to illicit greater cognitive\neffort in message evaluation and reduce the likelihood of creating, sharing,\nliking and consuming 'fake news'.", "doi": "", "date": "2021-05-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.08929v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3692062525, "title": "SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?", "abstract": "Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges.", "doi": "", "date": "2021-05-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.10671v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2206823614, "title": "DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection", "abstract": "Fake News on social media platforms has attracted a lot of attention in\nrecent times, primarily for events related to politics (2016 US Presidential\nelections), healthcare (infodemic during COVID-19), to name a few. Various\nmethods have been proposed for detecting Fake News. The approaches span from\nexploiting techniques related to network analysis, Natural Language Processing\n(NLP), and the usage of Graph Neural Networks (GNNs). In this work, we propose\nDEAP-FAKED, a knowleDgE grAPh FAKe nEws Detection framework for identifying\nFake News. Our approach is a combination of the NLP -- where we encode the news\ncontent, and the GNN technique -- where we encode the Knowledge Graph (KG). A\nvariety of these encodings provides a complementary advantage to our detector.\nWe evaluate our framework using two publicly available datasets containing\narticles from domains such as politics, business, technology, and healthcare.\nAs part of dataset pre-processing, we also remove the bias, such as the source\nof the articles, which could impact the performance of the models. DEAP-FAKED\nobtains an F1-score of 88% and 78% for the two datasets, which is an\nimprovement of 21%, and 3% respectively, which shows the effectiveness of the\napproach.", "doi": "", "date": "2021-07-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.10648v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 53146396, "title": "Seeing Through Misinformation: A Framework for Identifying Fake Online\n  News", "abstract": "The fake news epidemic makes it imperative to develop a diagnostic framework\nthat is both parsimonious and valid to guide present and future efforts in fake\nnews detection. This paper represents one of the very first attempts to fill a\nvoid in the research on this topic. The LeSiE (Lexical Structure, Simplicity,\nEmotion) framework we created and validated allows lay people to identify\npotential fake news without the use of calculators or complex statistics by\nlooking out for three simple cues.", "doi": "", "date": "2018-03-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.03508v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1589378714, "title": "Exploring Thematic Coherence in Fake News", "abstract": "The spread of fake news remains a serious global issue; understanding and\ncurtailing it is paramount. One way of differentiating between deceptive and\ntruthful stories is by analyzing their coherence. This study explores the use\nof topic models to analyze the coherence of cross-domain news shared online.\nExperimental results on seven cross-domain datasets demonstrate that fake news\nshows a greater thematic deviation between its opening sentences and its\nremainder.", "doi": "", "date": "2020-12-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.09118v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 317670071, "title": "\"Everything I Disagree With is #FakeNews\": Correlating Political\n  Polarization and Spread of Misinformation", "abstract": "An important challenge in the process of tracking and detecting the\ndissemination of misinformation is to understand the political gap between\npeople that engage with the so called \"fake news\". A possible factor\nresponsible for this gap is opinion polarization, which may prompt the general\npublic to classify content that they disagree or want to discredit as fake. In\nthis work, we study the relationship between political polarization and content\nreported by Twitter users as related to \"fake news\". We investigate how\npolarization may create distinct narratives on what misinformation actually is.\nWe perform our study based on two datasets collected from Twitter. The first\ndataset contains tweets about US politics in general, from which we compute the\ndegree of polarization of each user towards the Republican and Democratic\nParty. In the second dataset, we collect tweets and URLs that co-occurred with\n\"fake news\" related keywords and hashtags, such as #FakeNews and\n#AlternativeFact, as well as reactions towards such tweets and URLs. We then\nanalyze the relationship between polarization and what is perceived as\nmisinformation, and whether users are designating information that they\ndisagree as fake. Our results show an increase in the polarization of users and\nURLs associated with fake-news keywords and hashtags, when compared to\ninformation not labeled as \"fake news\". We discuss the impact of our findings\non the challenges of tracking \"fake news\" in the ongoing battle against\nmisinformation.", "doi": "", "date": "2017-06-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1706.05924v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1507900154, "title": "Limiting the Spread of Fake News on Social Media Platforms by Evaluating\n  Users' Trustworthiness", "abstract": "Today's social media platforms enable to spread both authentic and fake news\nvery quickly. Some approaches have been proposed to automatically detect such\n\"fake\" news based on their content, but it is difficult to agree on universal\ncriteria of authenticity (which can be bypassed by adversaries once known).\nBesides, it is obviously impossible to have each news item checked by a human.\n  In this paper, we a mechanism to limit the spread of fake news which is not\nbased on content. It can be implemented as a plugin on a social media platform.\nThe principle is as follows: a team of fact-checkers reviews a small number of\nnews items (the most popular ones), which enables to have an estimation of each\nuser's inclination to share fake news items. Then, using a Bayesian approach,\nwe estimate the trustworthiness of future news items, and treat accordingly\nthose of them that pass a certain \"untrustworthiness\" threshold.\n  We then evaluate the effectiveness and overhead of this technique on a large\nTwitter graph. We show that having a few thousands users exposed to one given\nnews item enables to reach a very precise estimation of its reliability. We\nthus identify more than 99% of fake news items with no false positives. The\nperformance impact is very small: the induced overhead on the 90th percentile\nlatency is less than 3%, and less than 8% on the throughput of user operations.", "doi": "", "date": "2018-08-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.09922v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2157135728, "title": "A Benchmark Study of Machine Learning Models for Online Fake News\n  Detection", "abstract": "The proliferation of fake news and its propagation on social media has become\na major concern due to its ability to create devastating impacts. Different\nmachine learning approaches have been suggested to detect fake news. However,\nmost of those focused on a specific type of news (such as political) which\nleads us to the question of dataset-bias of the models used. In this research,\nwe conducted a benchmark study to assess the performance of different\napplicable machine learning approaches on three different datasets where we\naccumulated the largest and most diversified one. We explored a number of\nadvanced pre-trained language models for fake news detection along with the\ntraditional and deep learning ones and compared their performances from\ndifferent aspects for the first time to the best of our knowledge. We find that\nBERT and similar pre-trained models perform the best for fake news detection,\nespecially with very small dataset. Hence, these models are significantly\nbetter option for languages with limited electronic contents, i.e., training\ndata. We also carried out several analysis based on the models' performance,\narticle's topic, article's length, and discussed different lessons learned from\nthem. We believe that this benchmark study will help the research community to\nexplore further and news sites/blogs to select the most appropriate fake news\ndetection method.", "doi": "10.1016/j.mlwa.2021.100032", "date": "2019-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.04749v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2408576026, "title": "FakeYou! -- A Gamified Approach for Building and Evaluating Resilience\n  Against Fake News", "abstract": "Nowadays fake news are heavily discussed in public and political debates.\nEven though the phenomenon of intended false information is rather old,\nmisinformation reaches a new level with the rise of the internet and\nparticipatory platforms. Due to Facebook and Co., purposeful false information\n- often called fake news - can be easily spread by everyone. Because of a high\ndata volatility and variety in content types (text, images,...) debunking of\nfake news is a complex challenge. This is especially true for automated\napproaches, which are prone to fail validating the veracity of the information.\nThis work focuses on an a gamified approach to strengthen the resilience of\nconsumers towards fake news. The game FakeYou motivates its players to\ncritically analyze headlines regarding their trustworthiness. Further, the game\nfollows a \"learning by doing strategy\": by generating own fake headlines, users\nshould experience the concepts of convincing fake headline formulations. We\nintroduce the game itself, as well as the underlying technical infrastructure.\nA first evaluation study shows, that users tend to use specific stylistic\ndevices to generate fake news. Further, the results indicate, that creating\ngood fakes and identifying correct headlines are challenging and hard to learn.", "doi": "", "date": "2020-03-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.07595v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1797343896, "title": "Network Inference from a Mixture of Diffusion Models for Fake News\n  Mitigation", "abstract": "The dissemination of fake news intended to deceive people, influence public\nopinion and manipulate social outcomes, has become a pressing problem on social\nmedia. Moreover, information sharing on social media facilitates diffusion of\nviral information cascades. In this work, we focus on understanding and\nleveraging diffusion dynamics of false and legitimate contents in order to\nfacilitate network interventions for fake news mitigation. We analyze\nreal-world Twitter datasets comprising fake and true news cascades, to\nunderstand differences in diffusion dynamics and user behaviours with regards\nto fake and true contents. Based on the analysis, we model the diffusion as a\nmixture of Independent Cascade models (MIC) with parameters $\\theta_T,\n\\theta_F$ over the social network graph; and derive unsupervised inference\ntechniques for parameter estimation of the diffusion mixture model from\nobserved, unlabeled cascades. Users influential in the propagation of true and\nfake contents are identified using the inferred diffusion dynamics.\nCharacteristics of the identified influential users reveal positive correlation\nbetween influential users identified for fake news and their relative\nappearance in fake news cascades. Identified influential users tend to be\nrelated to topics of more viral information cascades than less viral ones; and\nidentified fake news influential users have relatively fewer counts of direct\nfollowers, compared to the true news influential users. Intervention analysis\non nodes and edges demonstrates capacity of the inferred diffusion dynamics in\nsupporting network interventions for mitigation.", "doi": "", "date": "2020-08-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.03450v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1142263014, "title": "Transformer-based Language Model Fine-tuning Methods for COVID-19 Fake\n  News Detection", "abstract": "With the pandemic of COVID-19, relevant fake news is spreading all over the\nsky throughout the social media. Believing in them without discrimination can\ncause great trouble to people's life. However, universal language models may\nperform weakly in these fake news detection for lack of large-scale annotated\ndata and sufficient semantic understanding of domain-specific knowledge. While\nthe model trained on corresponding corpora is also mediocre for insufficient\nlearning. In this paper, we propose a novel transformer-based language model\nfine-tuning approach for these fake news detection. First, the token vocabulary\nof individual model is expanded for the actual semantics of professional\nphrases. Second, we adapt the heated-up softmax loss to distinguish the\nhard-mining samples, which are common for fake news because of the\ndisambiguation of short text. Then, we involve adversarial training to improve\nthe model's robustness. Last, the predicted features extracted by universal\nlanguage model RoBERTa and domain-specific model CT-BERT are fused by one\nmultiple layer perception to integrate fine-grained and high-level specific\nrepresentations. Quantitative experimental results evaluated on existing\nCOVID-19 fake news dataset show its superior performances compared to the\nstate-of-the-art methods among various evaluation metrics. Furthermore, the\nbest weighted average F1 score achieves 99.02%.", "doi": "", "date": "2021-01-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.05509v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3498784732, "title": "A Heuristic-driven Uncertainty based Ensemble Framework for Fake News\n  Detection in Tweets and News Articles", "abstract": "The significance of social media has increased manifold in the past few\ndecades as it helps people from even the most remote corners of the world to\nstay connected. With the advent of technology, digital media has become more\nrelevant and widely used than ever before and along with this, there has been a\nresurgence in the circulation of fake news and tweets that demand immediate\nattention. In this paper, we describe a novel Fake News Detection system that\nautomatically identifies whether a news item is \"real\" or \"fake\", as an\nextension of our work in the CONSTRAINT COVID-19 Fake News Detection in English\nchallenge. We have used an ensemble model consisting of pre-trained models\nfollowed by a statistical feature fusion network , along with a novel heuristic\nalgorithm by incorporating various attributes present in news items or tweets\nlike source, username handles, URL domains and authors as statistical feature.\nOur proposed framework have also quantified reliable predictive uncertainty\nalong with proper class output confidence level for the classification task. We\nhave evaluated our results on the COVID-19 Fake News dataset and FakeNewsNet\ndataset to show the effectiveness of the proposed algorithm on detecting fake\nnews in short news content as well as in news articles. We obtained a best\nF1-score of 0.9892 on the COVID-19 dataset, and an F1-score of 0.9073 on the\nFakeNewsNet dataset.", "doi": "", "date": "2021-04-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.01791v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2678195068, "title": "Stance Detection with BERT Embeddings for Credibility Analysis of\n  Information on Social Media", "abstract": "The evolution of electronic media is a mixed blessing. Due to the easy\naccess, low cost, and faster reach of the information, people search out and\ndevour news from online social networks. In contrast, the increasing acceptance\nof social media reporting leads to the spread of fake news. This is a minacious\nproblem that causes disputes and endangers societal stability and harmony. Fake\nnews spread has gained attention from researchers due to its vicious nature.\nproliferation of misinformation in all media, from the internet to cable news,\npaid advertising and local news outlets, has made it essential for people to\nidentify the misinformation and sort through the facts. Researchers are trying\nto analyze the credibility of information and curtail false information on such\nplatforms. Credibility is the believability of the piece of information at\nhand. Analyzing the credibility of fake news is challenging due to the intent\nof its creation and the polychromatic nature of the news. In this work, we\npropose a model for detecting fake news. Our method investigates the content of\nthe news at the early stage i.e. when the news is published but is yet to be\ndisseminated through social media. Our work interprets the content with\nautomatic feature extraction and the relevance of the text pieces. In summary,\nwe introduce stance as one of the features along with the content of the\narticle and employ the pre-trained contextualized word embeddings BERT to\nobtain the state-of-art results for fake news detection. The experiment\nconducted on the real-world dataset indicates that our model outperforms the\nprevious work and enables fake news detection with an accuracy of 95.32%.", "doi": "10.7717/peerj-cs.467", "date": "2021-05-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.10272v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1647934753, "title": "Knowledge Enhanced Multi-modal Fake News Detection", "abstract": "Recent years have witnessed the significant damage caused by various types of\nfake news. Although considerable effort has been applied to address this issue\nand much progress has been made on detecting fake news, most existing\napproaches mainly rely on the textual content and/or social context, while\nknowledge-level information---entities extracted from the news content and the\nrelations between them---is much less explored. Within the limited work on\nknowledge-based fake news detection, an external knowledge graph is often\nrequired, which may introduce additional problems: it is quite common for\nentities and relations, especially with respect to new concepts, to be missing\nin existing knowledge graphs, and both entity prediction and link prediction\nare open research questions themselves. Therefore, in this work, we investigate\n\\textbf{knowledge-based fake news detection that does not require any external\nknowledge graph.} Specifically, our contributions include: (1) transforming the\nproblem of detecting fake news into a subgraph classification task---entities\nand relations are extracted from each news item to form a single knowledge\ngraph, where a news item is represented by a subgraph. Then a graph neural\nnetwork (GNN) model is trained to classify each subgraph/news item. (2) Further\nimproving the performance of this model through a simple but effective\nmulti-modal technique that combines extracted knowledge, textual content and\nsocial context. Experiments on multiple datasets with thousands of labelled\nnews items demonstrate that our knowledge-based algorithm outperforms existing\ncounterpart methods, and its performance can be further boosted by the\nmulti-modal approach.", "doi": "", "date": "2021-08-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.04418v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4275449079, "title": "Improving Fake News Detection by Using an Entity-enhanced Framework to\n  Fuse Diverse Multimodal Clues", "abstract": "Recently, fake news with text and images have achieved more effective\ndiffusion than text-only fake news, raising a severe issue of multimodal fake\nnews detection. Current studies on this issue have made significant\ncontributions to developing multimodal models, but they are defective in\nmodeling the multimodal content sufficiently. Most of them only preliminarily\nmodel the basic semantics of the images as a supplement to the text, which\nlimits their performance on detection. In this paper, we find three valuable\ntext-image correlations in multimodal fake news: entity inconsistency, mutual\nenhancement, and text complementation. To effectively capture these multimodal\nclues, we innovatively extract visual entities (such as celebrities and\nlandmarks) to understand the news-related high-level semantics of images, and\nthen model the multimodal entity inconsistency and mutual enhancement with the\nhelp of visual entities. Moreover, we extract the embedded text in images as\nthe complementation of the original text. All things considered, we propose a\nnovel entity-enhanced multimodal fusion framework, which simultaneously models\nthree cross-modal correlations to detect diverse multimodal fake news.\nExtensive experiments demonstrate the superiority of our model compared to the\nstate of the art.", "doi": "10.1145/3474085.3481548", "date": "2021-08-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.10509v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3531339235, "title": "Fake News Detection on Social Media using Geometric Deep Learning", "abstract": "Social media are nowadays one of the main news sources for millions of people\naround the globe due to their low cost, easy access and rapid dissemination.\nThis however comes at the cost of dubious trustworthiness and significant risk\nof exposure to 'fake news', intentionally written to mislead the readers.\nAutomatically detecting fake news poses challenges that defy existing\ncontent-based analysis approaches. One of the main reasons is that often the\ninterpretation of the news requires the knowledge of political or social\ncontext or 'common sense', which current NLP algorithms are still missing.\nRecent studies have shown that fake and real news spread differently on social\nmedia, forming propagation patterns that could be harnessed for the automatic\nfake news detection. Propagation-based approaches have multiple advantages\ncompared to their content-based counterparts, among which is language\nindependence and better resilience to adversarial attacks. In this paper we\nshow a novel automatic fake news detection model based on geometric deep\nlearning. The underlying core algorithms are a generalization of classical CNNs\nto graphs, allowing the fusion of heterogeneous data such as content, user\nprofile and activity, social graph, and news propagation. Our model was trained\nand tested on news stories, verified by professional fact-checking\norganizations, that were spread on Twitter. Our experiments indicate that\nsocial network structure and propagation are important features allowing highly\naccurate (92.7% ROC AUC) fake news detection. Second, we observe that fake news\ncan be reliably detected at an early stage, after just a few hours of\npropagation. Third, we test the aging of our model on training and testing data\nseparated in time. Our results point to the promise of propagation-based\napproaches for fake news detection as an alternative or complementary strategy\nto content-based approaches.", "doi": "", "date": "2019-02-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.06673v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1120384349, "title": "An Event Correlation Filtering Method for Fake News Detection", "abstract": "Nowadays, social network platforms have been the prime source for people to\nexperience news and events due to their capacities to spread information\nrapidly, which inevitably provides a fertile ground for the dissemination of\nfake news. Thus, it is significant to detect fake news otherwise it could cause\npublic misleading and panic. Existing deep learning models have achieved great\nprogress to tackle the problem of fake news detection. However, training an\neffective deep learning model usually requires a large amount of labeled news,\nwhile it is expensive and time-consuming to provide sufficient labeled news in\nactual applications. To improve the detection performance of fake news, we take\nadvantage of the event correlations of news and propose an event correlation\nfiltering method (ECFM) for fake news detection, mainly consisting of the news\ncharacterizer, the pseudo label annotator, the event credibility updater, and\nthe news entropy selector. The news characterizer is responsible for extracting\ntextual features from news, which cooperates with the pseudo label annotator to\nassign pseudo labels for unlabeled news by fully exploiting the event\ncorrelations of news. In addition, the event credibility updater employs\nadaptive Kalman filter to weaken the credibility fluctuations of events. To\nfurther improve the detection performance, the news entropy selector\nautomatically discovers high-quality samples from pseudo labeled news by\nquantifying their news entropy. Finally, ECFM is proposed to integrate them to\ndetect fake news in an event correlation filtering manner. Extensive\nexperiments prove that the explainable introduction of the event correlations\nof news is beneficial to improve the detection performance of fake news.", "doi": "", "date": "2020-12-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.05491v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2617200188, "title": "Polarization and Fake News: Early Warning of Potential Misinformation\n  Targets", "abstract": "Users polarization and confirmation bias play a key role in misinformation\nspreading on online social media. Our aim is to use this information to\ndetermine in advance potential targets for hoaxes and fake news. In this paper,\nwe introduce a general framework for promptly identifying polarizing content on\nsocial media and, thus, \"predicting\" future fake news topics. We validate the\nperformances of the proposed methodology on a massive Italian Facebook dataset,\nshowing that we are able to identify topics that are susceptible to\nmisinformation with 77% accuracy. Moreover, such information may be embedded as\na new feature in an additional classifier able to recognize fake news with 91%\naccuracy. The novelty of our approach consists in taking into account a series\nof characteristics related to users behavior on online social media, making a\nfirst, important step towards the smoothing of polarization and the mitigation\nof misinformation phenomena.", "doi": "", "date": "2018-02-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1802.01400v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2524550582, "title": "Combating Fake News with Interpretable News Feed Algorithms", "abstract": "Nowadays, artificial intelligence algorithms are used for targeted and\npersonalized content distribution in the large scale as part of the intense\ncompetition for attention in the digital media environment. Unfortunately,\ntargeted information dissemination may result in intellectual isolation and\ndiscrimination. Further, as demonstrated in recent political events in the US\nand EU, malicious bots and social media users can create and propagate targeted\n`fake news' content in different forms for political gains. From the other\ndirection, fake news detection algorithms attempt to combat such problems by\nidentifying misinformation and fraudulent user profiles. This paper reviews\ncommon news feed algorithms as well as methods for fake news detection, and we\ndiscuss how news feed algorithms could be misused to promote falsified content,\naffect news diversity, or impact credibility. We review how news feed\nalgorithms and recommender engines can enable confirmation bias to isolate\nusers to certain news sources and affecting the perception of reality. As a\npotential solution for increasing user awareness of how content is selected or\nsorted, we argue for the use of interpretable and explainable news feed\nalgorithms. We discuss how improved user awareness and system transparency\ncould mitigate unwanted outcomes of echo chambers and bubble filters in social\nmedia.", "doi": "", "date": "2018-11-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.12349v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2068336266, "title": "Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language", "abstract": "In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.", "doi": "", "date": "2019-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.02202v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1892167155, "title": "Fake news detection using Deep Learning", "abstract": "The evolution of the information and communication technologies has\ndramatically increased the number of people with access to the Internet, which\nhas changed the way the information is consumed. As a consequence of the above,\nfake news have become one of the major concerns because its potential to\ndestabilize governments, which makes them a potential danger to modern society.\nAn example of this can be found in the US. electoral campaign, where the term\n\"fake news\" gained great notoriety due to the influence of the hoaxes in the\nfinal result of these. In this work the feasibility of applying deep learning\ntechniques to discriminate fake news on the Internet using only their text is\nstudied. In order to accomplish that, three different neural network\narchitectures are proposed, one of them based on BERT, a modern language model\ncreated by Google which achieves state-of-the-art results.", "doi": "", "date": "2019-09-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.03496v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2000292185, "title": "Automatic Detection of Fake News", "abstract": "The proliferation of misleading information in everyday access media outlets\nsuch as social media feeds, news blogs, and online newspapers have made it\nchallenging to identify trustworthy news sources, thus increasing the need for\ncomputational tools able to provide insights into the reliability of online\ncontent. In this paper, we focus on the automatic identification of fake\ncontent in online news. Our contribution is twofold. First, we introduce two\nnovel datasets for the task of fake news detection, covering seven different\nnews domains. We describe the collection, annotation, and validation process in\ndetail and present several exploratory analysis on the identification of\nlinguistic differences in fake and legitimate news content. Second, we conduct\na set of learning experiments to build accurate fake news detectors. In\naddition, we provide comparative analyses of the automatic and manual\nidentification of fake news.", "doi": "", "date": "2017-08-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1708.07104v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2340198398, "title": "Characterizing Political Fake News in Twitter by its Meta-Data", "abstract": "This article presents a preliminary approach towards characterizing political\nfake news on Twitter through the analysis of their meta-data. In particular, we\nfocus on more than 1.5M tweets collected on the day of the election of Donald\nTrump as 45th president of the United States of America. We use the meta-data\nembedded within those tweets in order to look for differences between tweets\ncontaining fake news and tweets not containing them. Specifically, we perform\nour analysis only on tweets that went viral, by studying proxies for users'\nexposure to the tweets, by characterizing accounts spreading fake news, and by\nlooking at their polarization. We found significant differences on the\ndistribution of followers, the number of URLs on tweets, and the verification\nof the users.", "doi": "", "date": "2017-12-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1712.05999v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 229855135, "title": "A Classification Algorithm to Recognize Fake News Websites", "abstract": "'Fake news' is information that generally spreads on the web, which only\nmimics the form of reliable news media content. The phenomenon has assumed\nuncontrolled proportions in recent years rising the concern of authorities and\ncitizens. In this paper we present a classifier able to distinguish a reliable\nsource from a fake news website. We have prepared a dataset made of 200 fake\nnews websites and 200 reliable websites from all over the world and used as\npredictors information potentially available on websites, such as the presence\nof a 'contact us' section or a secured connection. The algorithm is based on\nlogistic regression, whereas further analyses were carried out using\ntetrachoric correlation coefficients for dichotomous variables and chi-square\ntests. This framework offers a concrete solution to attribute a 'reliability\nscore' to news website, defined as the probability that a source is reliable or\nnot, and on this probability a user can decide if the news is worth sharing or\nnot.", "doi": "10.1007/978-3-030-51222-4_25", "date": "2019-04-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.05305v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1648063459, "title": "Detecting Fake News with Capsule Neural Networks", "abstract": "Fake news is dramatically increased in social media in recent years. This has\nprompted the need for effective fake news detection algorithms. Capsule neural\nnetworks have been successful in computer vision and are receiving attention\nfor use in Natural Language Processing (NLP). This paper aims to use capsule\nneural networks in the fake news detection task. We use different embedding\nmodels for news items of different lengths. Static word embedding is used for\nshort news items, whereas non-static word embeddings that allow incremental\nup-training and updating in the training phase are used for medium length or\nlarge news statements. Moreover, we apply different levels of n-grams for\nfeature extraction. Our proposed architectures are evaluated on two recent\nwell-known datasets in the field, namely ISOT and LIAR. The results show\nencouraging performance, outperforming the state-of-the-art methods by 7.8% on\nISOT and 3.1% on the validation set, and 1% on the test set of the LIAR\ndataset.", "doi": "", "date": "2020-02-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.01030v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1375916427, "title": "Adaptive Interaction Fusion Networks for Fake News Detection", "abstract": "The majority of existing methods for fake news detection universally focus on\nlearning and fusing various features for detection. However, the learning of\nvarious features is independent, which leads to a lack of cross-interaction\nfusion between features on social media, especially between posts and comments.\nGenerally, in fake news, there are emotional associations and semantic\nconflicts between posts and comments. How to represent and fuse the\ncross-interaction between both is a key challenge. In this paper, we propose\nAdaptive Interaction Fusion Networks (AIFN) to fulfill cross-interaction fusion\namong features for fake news detection. In AIFN, to discover semantic\nconflicts, we design gated adaptive interaction networks (GAIN) to capture\nadaptively similar semantics and conflicting semantics between posts and\ncomments. To establish feature associations, we devise semantic-level fusion\nself-attention networks (SFSN) to enhance semantic correlations and fusion\namong features. Extensive experiments on two real-world datasets, i.e.,\nRumourEval and PHEME, demonstrate that AIFN achieves the state-of-the-art\nperformance and boosts accuracy by more than 2.05% and 1.90%, respectively.", "doi": "", "date": "2020-04-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.10009v1", "pdf": ""}, "publisher-venue": "the 24th European Conference on Artificial Intelligence\\n  (ECAI 2020)", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4030136082, "title": "A Deep Learning Approach for Automatic Detection of Fake News", "abstract": "Fake news detection is a very prominent and essential task in the field of\njournalism. This challenging problem is seen so far in the field of politics,\nbut it could be even more challenging when it is to be determined in the\nmulti-domain platform. In this paper, we propose two effective models based on\ndeep learning for solving fake news detection problem in online news contents\nof multiple domains. We evaluate our techniques on the two recently released\ndatasets, namely FakeNews AMT and Celebrity for fake news detection. The\nproposed systems yield encouraging performance, outperforming the current\nhandcrafted feature engineering based state-of-the-art system with a\nsignificant margin of 3.08% and 9.3% by the two models, respectively. In order\nto exploit the datasets, available for the related tasks, we perform\ncross-domain analysis (i.e. model trained on FakeNews AMT and tested on\nCelebrity and vice versa) to explore the applicability of our systems across\nthe domains.", "doi": "", "date": "2020-05-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.04938v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2023782828, "title": "Machine Learning Explanations to Prevent Overtrust in Fake News\n  Detection", "abstract": "Combating fake news and misinformation propagation is a challenging task in\nthe post-truth era. News feed and search algorithms could potentially lead to\nunintentional large-scale propagation of false and fabricated information with\nusers being exposed to algorithmically selected false content. Our research\ninvestigates the effects of an Explainable AI assistant embedded in news review\nplatforms for combating the propagation of fake news. We design a news\nreviewing and sharing interface, create a dataset of news stories, and train\nfour interpretable fake news detection algorithms to study the effects of\nalgorithmic transparency on end-users. We present evaluation results and\nanalysis from multiple controlled crowdsourced studies. For a deeper\nunderstanding of Explainable AI systems, we discuss interactions between user\nengagement, mental model, trust, and performance measures in the process of\nexplaining. The study results indicate that explanations helped participants to\nbuild appropriate mental models of the intelligent assistants in different\nconditions and adjust their trust accordingly for model limitations.", "doi": "", "date": "2020-07-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.12358v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3583010047, "title": "Words are the Window to the Soul: Language-based User Representations\n  for Fake News Detection", "abstract": "Cognitive and social traits of individuals are reflected in language use.\nMoreover, individuals who are prone to spread fake news online often share\ncommon traits. Building on these ideas, we introduce a model that creates\nrepresentations of individuals on social media based only on the language they\nproduce, and use them to detect fake news. We show that language-based user\nrepresentations are beneficial for this task. We also present an extended\nanalysis of the language of fake news spreaders, showing that its main features\nare mostly domain independent and consistent across two English datasets.\nFinally, we exploit the relation between language use and connections in the\nsocial graph to assess the presence of the Echo Chamber effect in our data.", "doi": "", "date": "2020-11-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.07389v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2241560252, "title": "Detecting Fake News Spreaders in Social Networks using Inductive\n  Representation Learning", "abstract": "An important aspect of preventing fake news dissemination is to proactively\ndetect the likelihood of its spreading. Research in the domain of fake news\nspreader detection has not been explored much from a network analysis\nperspective. In this paper, we propose a graph neural network based approach to\nidentify nodes that are likely to become spreaders of false information. Using\nthe community health assessment model and interpersonal trust we propose an\ninductive representation learning framework to predict nodes of\ndensely-connected community structures that are most likely to spread fake\nnews, thus making the entire community vulnerable to the infection. Using\ntopology and interaction based trust properties of nodes in real-world Twitter\nnetworks, we are able to predict false information spreaders with an accuracy\nof over 90%.", "doi": "", "date": "2020-11-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.10817v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3948721904, "title": "Fake News Data Collection and Classification: Iterative Query Selection\n  for Opaque Search Engines with Pseudo Relevance Feedback", "abstract": "Retrieving information from an online search engine, is the first and most\nimportant step in many data mining tasks. Most of the search engines currently\navailable on the web, including all social media platforms, are black-boxes\n(a.k.a opaque) supporting short keyword queries. In these settings, retrieving\nall posts and comments discussing a particular news item automatically and at\nlarge scales is a challenging task. In this paper, we propose a method for\ngenerating short keyword queries given a prototype document. The proposed\niterative query selection algorithm (IQS) interacts with the opaque search\nengine to iteratively improve the query. It is evaluated on the Twitter TREC\nMicroblog 2012 and TREC-COVID 2019 datasets showing superior performance\ncompared to state-of-the-art. IQS is applied to automatically collect a\nlarge-scale fake news dataset of about 70K true and fake news items. The\ndataset, publicly available for research, includes more than 22M accounts and\n61M tweets in Twitter approved format. We demonstrate the usefulness of the\ndataset for fake news detection task achieving state-of-the-art performance.", "doi": "", "date": "2020-12-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.12498v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1613528045, "title": "Exploring Text-transformers in AAAI 2021 Shared Task: COVID-19 Fake News\n  Detection in English", "abstract": "In this paper, we describe our system for the AAAI 2021 shared task of\nCOVID-19 Fake News Detection in English, where we achieved the 3rd position\nwith the weighted F1 score of 0.9859 on the test set. Specifically, we proposed\nan ensemble method of different pre-trained language models such as BERT,\nRoberta, Ernie, etc. with various training strategies including\nwarm-up,learning rate schedule and k-fold cross-validation. We also conduct an\nextensive analysis of the samples that are not correctly classified. The code\nis available\nat:https://github.com/archersama/3rd-solution-COVID19-Fake-News-Detection-in-English.", "doi": "", "date": "2021-01-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.02359v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2529203964, "title": "A Heuristic-driven Ensemble Framework for COVID-19 Fake News Detection", "abstract": "The significance of social media has increased manifold in the past few\ndecades as it helps people from even the most remote corners of the world stay\nconnected. With the COVID-19 pandemic raging, social media has become more\nrelevant and widely used than ever before, and along with this, there has been\na resurgence in the circulation of fake news and tweets that demand immediate\nattention. In this paper, we describe our Fake News Detection system that\nautomatically identifies whether a tweet related to COVID-19 is \"real\" or\n\"fake\", as a part of CONSTRAINT COVID19 Fake News Detection in English\nchallenge. We have used an ensemble model consisting of pre-trained models that\nhas helped us achieve a joint 8th position on the leader board. We have\nachieved an F1-score of 0.9831 against a top score of 0.9869. Post completion\nof the competition, we have been able to drastically improve our system by\nincorporating a novel heuristic algorithm based on username handles and link\ndomains in tweets fetching an F1-score of 0.9883 and achieving state-of-the art\nresults on the given dataset.", "doi": "", "date": "2021-01-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.03545v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3730225120, "title": "ECOL: Early Detection of COVID Lies Using Content, Prior Knowledge and\n  Source Information", "abstract": "Social media platforms are vulnerable to fake news dissemination, which\ncauses negative consequences such as panic and wrong medication in the\nhealthcare domain. Therefore, it is important to automatically detect fake news\nin an early stage before they get widely spread. This paper analyzes the impact\nof incorporating content information, prior knowledge, and credibility of\nsources into models for the early detection of fake news. We propose a\nframework modeling those features by using BERT language model and external\nsources, namely Simple English Wikipedia and source reliability tags. The\nconducted experiments on CONSTRAINT datasets demonstrated the benefit of\nintegrating these features for the early detection of fake news in the\nhealthcare domain.", "doi": "", "date": "2021-01-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.05499v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3404933619, "title": "Hostility Detection and Covid-19 Fake News Detection in Social Media", "abstract": "Withtheadventofsocialmedia,therehasbeenanextremely rapid increase in the\ncontent shared online. Consequently, the propagation of fake news and hostile\nmessages on social media platforms has also skyrocketed. In this paper, we\naddress the problem of detecting hostile and fake content in the Devanagari\n(Hindi) script as a multi-class, multi-label problem. Using NLP techniques, we\nbuild a model that makes use of an abusive language detector coupled with\nfeatures extracted via Hindi BERT and Hindi FastText models and metadata. Our\nmodel achieves a 0.97 F1 score on coarse grain evaluation on Hostility\ndetection task. Additionally, we built models to identify fake news related to\nCovid-19 in English tweets. We leverage entity information extracted from the\ntweets along with textual representations learned from word embeddings and\nachieve a 0.93 F1 score on the English fake news detection task.", "doi": "", "date": "2021-01-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.05953v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 527805116, "title": "Hierarchical Multi-head Attentive Network for Evidence-aware Fake News\n  Detection", "abstract": "The widespread of fake news and misinformation in various domains ranging\nfrom politics, economics to public health has posed an urgent need to\nautomatically fact-check information. A recent trend in fake news detection is\nto utilize evidence from external sources. However, existing evidence-aware\nfake news detection methods focused on either only word-level attention or\nevidence-level attention, which may result in suboptimal performance. In this\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\ntextual claims. Our model jointly combines multi-head word-level attention and\nmulti-head document-level attention, which aid explanation in both word-level\nand evidence-level. Experiments on two real-word datasets show that our model\noutperforms seven state-of-the-art baselines. Improvements over baselines are\nfrom 6\\% to 18\\%. Our source code and datasets are released at\n\\texttt{\\url{https://github.com/nguyenvo09/EACL2021}}.", "doi": "", "date": "2021-02-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.02680v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4123898066, "title": "AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News and Hate Speech\n  Detection Dataset", "abstract": "Along with the COVID-19 pandemic, an \"infodemic\" of false and misleading\ninformation has emerged and has complicated the COVID-19 response efforts.\nSocial networking sites such as Facebook and Twitter have contributed largely\nto the spread of rumors, conspiracy theories, hate, xenophobia, racism, and\nprejudice. To combat the spread of fake news, researchers around the world have\nand are still making considerable efforts to build and share COVID-19 related\nresearch articles, models, and datasets. This paper releases \"AraCOVID19-MFH\" a\nmanually annotated multi-label Arabic COVID-19 fake news and hate speech\ndetection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10\ndifferent labels. The labels have been designed to consider some aspects\nrelevant to the fact-checking task, such as the tweet's check worthiness,\npositivity/negativity, and factuality. To confirm our annotated dataset's\npractical utility, we used it to train and evaluate several classification\nmodels and reported the obtained results. Though the dataset is mainly designed\nfor fake news detection, it can also be used for hate speech detection,\nopinion/news classification, dialect identification, and many other tasks.", "doi": "", "date": "2021-05-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.03143v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2444011674, "title": "NoFake at CheckThat! 2021: Fake News Detection Using BERT", "abstract": "Much research has been done for debunking and analysing fake news. Many\nresearchers study fake news detection in the last year, but many are limited to\nsocial media data. Currently, multiples fact-checkers are publishing their\nresults in various formats. Also, multiple fact-checkers use different labels\nfor the fake news, making it difficult to make a generalisable classifier. With\nthe merge classes, the performance of the machine model can be enhanced. This\ndomain categorisation will help group the article, which will help save the\nmanual effort in assigning the claim verification. In this paper, we have\npresented BERT based classification model to predict the domain and\nclassification. We have also used additional data from fact-checked articles.\nWe have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B\nusing the additional training data.", "doi": "", "date": "2021-08-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.05419v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 721029154, "title": "Fake News and Phishing Detection Using a Machine Learning Trained Expert\n  System", "abstract": "Expert systems have been used to enable computers to make recommendations and\ndecisions. This paper presents the use of a machine learning trained expert\nsystem (MLES) for phishing site detection and fake news detection. Both topics\nshare a similar goal: to design a rule-fact network that allows a computer to\nmake explainable decisions like domain experts in each respective area. The\nphishing website detection study uses a MLES to detect potential phishing\nwebsites by analyzing site properties (like URL length and expiration time).\nThe fake news detection study uses a MLES rule-fact network to gauge news story\ntruthfulness based on factors such as emotion, the speaker's political\naffiliation status, and job. The two studies use different MLES network\nimplementations, which are presented and compared herein. The fake news study\nutilized a more linear design while the phishing project utilized a more\ncomplex connection structure. Both networks' inputs are based on commonly\navailable data sets.", "doi": "", "date": "2021-08-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.08264v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2144619053, "title": "Graph Neural Networks with Continual Learning for Fake News Detection\n  from Social Media", "abstract": "Although significant effort has been applied to fact-checking, the prevalence\nof fake news over social media, which has profound impact on justice, public\ntrust and our society, remains a serious problem. In this work, we focus on\npropagation-based fake news detection, as recent studies have demonstrated that\nfake news and real news spread differently online. Specifically, considering\nthe capability of graph neural networks (GNNs) in dealing with non-Euclidean\ndata, we use GNNs to differentiate between the propagation patterns of fake and\nreal news on social media. In particular, we concentrate on two questions: (1)\nWithout relying on any text information, e.g., tweet content, replies and user\ndescriptions, how accurately can GNNs identify fake news? Machine learning\nmodels are known to be vulnerable to adversarial attacks, and avoiding the\ndependence on text-based features can make the model less susceptible to the\nmanipulation of advanced fake news fabricators. (2) How to deal with new,\nunseen data? In other words, how does a GNN trained on a given dataset perform\non a new and potentially vastly different dataset? If it achieves\nunsatisfactory performance, how do we solve the problem without re-training the\nmodel on the entire data from scratch? We study the above questions on two\ndatasets with thousands of labelled news items, and our results show that: (1)\nGNNs can achieve comparable or superior performance without any text\ninformation to state-of-the-art methods. (2) GNNs trained on a given dataset\nmay perform poorly on new, unseen data, and direct incremental training cannot\nsolve the problem---this issue has not been addressed in the previous work that\napplies GNNs for fake news detection. In order to solve the problem, we propose\na method that achieves balanced performance on both existing and new datasets,\nby using techniques from continual learning to train GNNs incrementally.", "doi": "", "date": "2020-07-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.03316v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1902717369, "title": "Defending Against Neural Fake News", "abstract": "Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news.", "doi": "", "date": "2019-05-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.12616v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3368024342, "title": "Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements", "abstract": "In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.", "doi": "", "date": "2020-01-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.00623v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 615645819, "title": "Fake News Detection by means of Uncertainty Weighted Causal Graphs", "abstract": "Society is experimenting changes in information consumption, as new\ninformation channels such as social networks let people share news that do not\nnecessarily be trust worthy. Sometimes, these sources of information produce\nfake news deliberately with doubtful purposes and the consumers of that\ninformation share it to other users thinking that the information is accurate.\nThis transmission of information represents an issue in our society, as can\ninfluence negatively the opinion of people about certain figures, groups or\nideas. Hence, it is desirable to design a system that is able to detect and\nclassify information as fake and categorize a source of information as trust\nworthy or not. Current systems experiment difficulties performing this task, as\nit is complicated to design an automatic procedure that can classify this\ninformation independent on the context. In this work, we propose a mechanism to\ndetect fake news through a classifier based on weighted causal graphs. These\ngraphs are specific hybrid models that are built through causal relations\nretrieved from texts and consider the uncertainty of causal relations. We take\nadvantage of this representation to use the probability distributions of this\ngraph and built a fake news classifier based on the entropy and KL divergence\nof learned and new information. We believe that the problem of fake news is\naccurately tackled by this model due to its hybrid nature between a symbolic\nand quantitative methodology. We describe the methodology of this classifier\nand add empirical evidence of the usefulness of our proposed approach in the\nform of synthetic experiments and a real experiment involving lung cancer.", "doi": "", "date": "2020-02-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.01065v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3470568139, "title": "Leveraging Multi-Source Weak Social Supervision for Early Detection of\n  Fake News", "abstract": "Social media has greatly enabled people to participate in online activities\nat an unprecedented rate. However, this unrestricted access also exacerbates\nthe spread of misinformation and fake news online which might cause confusion\nand chaos unless being detected early for its mitigation. Given the rapidly\nevolving nature of news events and the limited amount of annotated data,\nstate-of-the-art systems on fake news detection face challenges due to the lack\nof large numbers of annotated training instances that are hard to come by for\nearly detection. In this work, we exploit multiple weak signals from different\nsources given by user and content engagements (referred to as weak social\nsupervision), and their complementary utilities to detect fake news. We jointly\nleverage the limited amount of clean data along with weak signals from social\nengagements to train deep neural networks in a meta-learning framework to\nestimate the quality of different weak instances. Experiments on realworld\ndatasets demonstrate that the proposed framework outperforms state-of-the-art\nbaselines for early detection of fake news without using any user engagements\nat prediction time.", "doi": "", "date": "2020-04-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.01732v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3438101993, "title": "Controlling Fake News by Tagging: A Branching Process Analysis", "abstract": "The spread of fake news, especially on online social networks, has become a\nmatter of concern in the last few years. These platforms are also used for\npropagating other important authentic information. Thus, there is a need for\nmitigating fake news without significantly influencing the spread of real news.\nWe leverage user's inherent capabilities of identifying fake news and propose a\nwarning-based control mechanism to curb this spread. Warnings are based on\nprevious users' responses that indicate the authenticity of the news.\n  We use population-size dependent continuous-time multi-type branching\nprocesses to describe the spreading under the warning mechanism. We also have\nnew results towards these branching processes. The (time) asymptotic\nproportions of the individual populations are derived. These results are\ninstrumental in deriving relevant type-1, type-2 performance measures, and\nformulating an optimization problem to design optimal warning parameters. The\nfraction of copies tagged as real (fake) are considered for the type-1 (type-2)\nperformance.\n  We derive structural properties of the performance, which help simplify the\noptimization problem. We finally demonstrate that the optimal warning mechanism\neffectively mitigates fake news, with negligible influences on the propagation\nof authentic news. We validate performance measures using Monte Carlo\nsimulations on ego-network database related to Twitter.", "doi": "", "date": "2020-09-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.02275v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3998758951, "title": "Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking", "abstract": "The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.", "doi": "", "date": "2020-11-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.13253v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4006462552, "title": "Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study", "abstract": "Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.", "doi": "", "date": "2020-12-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.01142v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1981337807, "title": "Model Generalization on COVID-19 Fake News Detection", "abstract": "Amid the pandemic COVID-19, the world is facing unprecedented infodemic with\nthe proliferation of both fake and real information. Considering the\nproblematic consequences that the COVID-19 fake-news have brought, the\nscientific community has put effort to tackle it. To contribute to this fight\nagainst the infodemic, we aim to achieve a robust model for the COVID-19\nfake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking\ntwo separate approaches: 1) fine-tuning transformers based language models with\nrobust loss functions and 2) removing harmful training instances through\ninfluence calculation. We further evaluate the robustness of our models by\nevaluating on different COVID-19 misinformation test set (Tweets-19) to\nunderstand model generalization ability. With the first approach, we achieve\n98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on\nthe Tweets-19 highest. On the contrary, by performing influence data cleansing,\nour model with 99% cleansing percentage can achieve 54.33% W-F1 score on\nTweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news\ntest sets, we suggest the importance of model generalization ability in this\ntask to step forward to tackle the COVID-19 fake-news problem in online social\nmedia platforms.", "doi": "", "date": "2021-01-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.03841v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 845690894, "title": "Investigating Misinformation Dissemination on Social Media in Pakistan", "abstract": "Fake news and misinformation are one of the most significant challenges\nbrought about by advances in communication technologies. We chose to research\nthe spread of fake news in Pakistan because of some unfortunate incidents that\ntook place during 2020. These included the downplaying of the severity of the\nCOVID-19 pandemic, and protests by right-wing political movements. We observed\nthat fake news and misinformation contributed significantly to these events and\nespecially affected low-literate and low-income populations. We conducted a\ncross-platform comparison of misinformation on WhatsApp, Twitter and YouTube\nwith a primary focus on messages shared in public WhatsApp groups, and analysed\nthe characteristics of misinformation, techniques used to make is believable,\nand how users respond to it. To the best of our knowledge, this is the first\nattempt to compare misinformation on all three platforms in Pakistan. Data\ncollected over a span of eight months helped us identify fake news and\nmisinformation related to politics, religion and health, among other\ncategories. Common elements which were used by fake news creators in Pakistan\nto make false content seem believable included: appeals to emotion, conspiracy\ntheories, political and religious polarization, incorrect facts and\nimpersonation of credible sources.", "doi": "", "date": "2021-06-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.09338v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2123959733, "title": "Related Fact Checks: a tool for combating fake news", "abstract": "The emergence of \"Fake News\" and misinformation via online news and social\nmedia has spurred an interest in computational tools to combat this phenomenon.\nIn this paper we present a new \"Related Fact Checks\" service, which can help a\nreader critically evaluate an article and make a judgment on its veracity by\nbringing up fact checks that are relevant to the article. We describe the core\ntechnical problems that need to be solved in building a \"Related Fact Checks\"\nservice, and present results from an evaluation of an implementation.", "doi": "", "date": "2017-10-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.00715v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2303593429, "title": "FacTweet: Profiling Fake News Twitter Accounts", "abstract": "We present an approach to detect fake news in Twitter at the account level\nusing a neural recurrent model and a variety of different semantic and\nstylistic features. Our method extracts a set of features from the timelines of\nnews Twitter accounts by reading their posts as chunks, rather than dealing\nwith each tweet independently. We show the experimental benefits of modeling\nlatent stylistic signatures of mixed fake and real news with a sequential model\nover a wide range of strong baselines.", "doi": "", "date": "2019-10-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.06592v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1987930993, "title": "Transfer Learning from Transformers to Fake News Challenge Stance\n  Detection (FNC-1) Task", "abstract": "In this paper, we report improved results of the Fake News Challenge Stage 1\n(FNC-1) stance detection task. This gain in performance is due to the\ngeneralization power of large language models based on Transformer\narchitecture, invented, trained and publicly released over the last two years.\nSpecifically (1) we improved the FNC-1 best performing model adding BERT\nsentence embedding of input sequences as a model feature, (2) we fine-tuned\nBERT, XLNet, and RoBERTa transformers on FNC-1 extended dataset and obtained\nstate-of-the-art results on FNC-1 task.", "doi": "", "date": "2019-10-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.14353v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2561371326, "title": "Fake News Detection as Natural Language Inference", "abstract": "This report describes the entry by the Intelligent Knowledge Management (IKM)\nLab in the WSDM 2019 Fake News Classification challenge. We treat the task as\nnatural language inference (NLI). We individually train a number of the\nstrongest NLI models as well as BERT. We ensemble these results and retrain\nwith noisy labels in two stages. We analyze transitivity relations in the train\nand test sets and determine a set of test cases that can be reliably classified\non this basis. The remainder of test cases are classified by our ensemble. Our\nentry achieves test set accuracy of 88.063% for 3rd place in the competition.", "doi": "", "date": "2019-07-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.07347v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 58253864, "title": "Fake News Detection with Different Models", "abstract": "This is a paper for exploring various different models aiming at developing\nfake news detection models and we had used certain machine learning algorithms\nand we had used pretrained algorithms such as TFIDF and CV and W2V as features\nfor processing textual data.", "doi": "", "date": "2020-02-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.04978v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4189176678, "title": "Identifying COVID-19 Fake News in Social Media", "abstract": "The evolution of social media platforms have empowered everyone to access\ninformation easily. Social media users can easily share information with the\nrest of the world. This may sometimes encourage spread of fake news, which can\nresult in undesirable consequences. In this work, we train models which can\nidentify health news related to COVID-19 pandemic as real or fake. Our models\nachieve a high F1-score of 98.64%. Our models achieve second place on the\nleaderboard, tailing the first position with a very narrow margin 0.05% points.", "doi": "", "date": "2021-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.11954v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4147291487, "title": "Hoaxy: A Platform for Tracking Online Misinformation", "abstract": "Massive amounts of misinformation have been observed to spread in\nuncontrolled fashion across social media. Examples include rumors, hoaxes, fake\nnews, and conspiracy theories. At the same time, several journalistic\norganizations devote significant efforts to high-quality fact checking of\nonline claims. The resulting information cascades contain instances of both\naccurate and inaccurate information, unfold over multiple time scales, and\noften reach audiences of considerable size. All these factors pose challenges\nfor the study of the social dynamics of online news sharing. Here we introduce\nHoaxy, a platform for the collection, detection, and analysis of online\nmisinformation and its related fact-checking efforts. We discuss the design of\nthe platform and present a preliminary analysis of a sample of public tweets\ncontaining both fake news and fact checking. We find that, in the aggregate,\nthe sharing of fact-checking content typically lags that of misinformation by\n10--20 hours. Moreover, fake news are dominated by very active users, while\nfact checking is a more grass-roots activity. With the increasing risks\nconnected to massive online misinformation, social news observatories have the\npotential to help researchers, journalists, and the general public understand\nthe dynamics of real and fake news sharing.", "doi": "10.1145/2872518.2890098", "date": "2016-03-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1603.01511v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3899178559, "title": "Fake News in Social Networks", "abstract": "We model the spread of news as a social learning game on a network. Agents\ncan either endorse or oppose a claim made in a piece of news, which itself may\nbe either true or false. Agents base their decision on a private signal and\ntheir neighbors' past actions. Given these inputs, agents follow strategies\nderived via multi-agent deep reinforcement learning and receive utility from\nacting in accordance with the veracity of claims. Our framework yields\nstrategies with agent utility close to a theoretical, Bayes optimal benchmark,\nwhile remaining flexible to model re-specification. Optimized strategies allow\nagents to correctly identify most false claims, when all agents receive\nunbiased private signals. However, an adversary's attempt to spread fake news\nby targeting a subset of agents with a biased private signal can be successful.\nEven more so when the adversary has information about agents' network position\nor private signal. When agents are aware of the presence of an adversary they\nre-optimize their strategies in the training stage and the adversary's attack\nis less effective. Hence, exposing agents to the possibility of fake news can\nbe an effective way to curtail the spread of fake news in social networks. Our\nresults also highlight that information about the users' private beliefs and\ntheir social network structure can be extremely valuable to adversaries and\nshould be well protected.", "doi": "", "date": "2017-08-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1708.06233v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 570912847, "title": "On the Benefit of Combining Neural, Statistical and External Features\n  for Fake News Identification", "abstract": "Identifying the veracity of a news article is an interesting problem while\nautomating this process can be a challenging task. Detection of a news article\nas fake is still an open question as it is contingent on many factors which the\ncurrent state-of-the-art models fail to incorporate. In this paper, we explore\na subtask to fake news identification, and that is stance detection. Given a\nnews article, the task is to determine the relevance of the body and its claim.\nWe present a novel idea that combines the neural, statistical and external\nfeatures to provide an efficient solution to this problem. We compute the\nneural embedding from the deep recurrent model, statistical features from the\nweighted n-gram bag-of-words model and handcrafted external features with the\nhelp of feature engineering heuristics. Finally, using deep neural layer all\nthe features are combined, thereby classifying the headline-body news pair as\nagree, disagree, discuss, or unrelated. We compare our proposed technique with\nthe current state-of-the-art models on the fake news challenge dataset. Through\nextensive experiments, we find that the proposed model outperforms all the\nstate-of-the-art techniques including the submissions to the fake news\nchallenge.", "doi": "", "date": "2017-12-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1712.03935v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2253085038, "title": "Graph-based Modeling of Online Communities for Fake News Detection", "abstract": "Over the past few years, there has been a substantial effort towards\nautomated detection of fake news on social media platforms. Existing research\nhas modeled the structure, style, content, and patterns in dissemination of\nonline posts, as well as the demographic traits of users who interact with\nthem. However, no attention has been directed towards modeling the properties\nof online communities that interact with the posts. In this work, we propose a\nnovel social context-aware fake news detection framework, SAFER, based on graph\nneural networks (GNNs). The proposed framework aggregates information with\nrespect to: 1) the nature of the content disseminated, 2) content-sharing\nbehavior of users, and 3) the social network of those users. We furthermore\nperform a systematic comparison of several GNN models for this task and\nintroduce novel methods based on relational and hyperbolic GNNs, which have not\nbeen previously used for user or community modeling within NLP. We empirically\ndemonstrate that our framework yields significant improvements over existing\ntext-based techniques and achieves state-of-the-art results on fake news\ndatasets from two different domains.", "doi": "", "date": "2020-08-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.06274v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2884521432, "title": "SGG: Spinbot, Grammarly and GloVe based Fake News Detection", "abstract": "Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.", "doi": "", "date": "2020-08-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.06854v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 180802821, "title": "Machine Generation and Detection of Arabic Manipulated and Fake News", "abstract": "Fake news and deceptive machine-generated text are serious problems\nthreatening modern societies, including in the Arab world. This motivates work\non detecting false and manipulated stories online. However, a bottleneck for\nthis research is lack of sufficient data to train detection models. We present\na novel method for automatically generating Arabic manipulated (and potentially\nfake) news stories. Our method is simple and only depends on availability of\ntrue stories, which are abundant online, and a part of speech tagger (POS). To\nfacilitate future work, we dispense with both of these requirements altogether\nby providing AraNews, a novel and large POS-tagged news dataset that can be\nused off-the-shelf. Using stories generated based on AraNews, we carry out a\nhuman annotation study that casts light on the effects of machine manipulation\non text veracity. The study also measures human ability to detect Arabic\nmachine manipulated text generated by our method. Finally, we develop the first\nmodels for detecting manipulated Arabic news and achieve state-of-the-art\nresults on Arabic fake news detection (macro F1=70.06). Our models and data are\npublicly available.", "doi": "", "date": "2020-11-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.03092v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 699097476, "title": "Assessing Individual and Community Vulnerability to Fake News in Social\n  Networks", "abstract": "The plague of false information, popularly called fake news has affected\nlives of news consumers ever since the prevalence of social media. Thus\nunderstanding the spread of false information in social networks has gained a\nlot of attention in the literature. While most proposed models do content\nanalysis of the information, no much work has been done by exploring the\ncommunity structures that also play an important role in determining how people\nget exposed to it. In this paper we base our idea on Computational Trust in\nsocial networks to propose a novel Community Health Assessment model against\nfake news. Based on the concepts of neighbor, boundary and core nodes of a\ncommunity, we propose novel evaluation metrics to quantify the vulnerability of\nnodes (individual-level) and communities (group-level) to spreading false\ninformation. Our model hypothesizes that if the boundary nodes trust the\nneighbor nodes of a community who are spreaders, the densely-connected core\nnodes of the community are highly likely to become spreaders. We test our model\nwith communities generated using three popular community detection algorithms\nbased on two new datasets of information spreading networks collected from\nTwitter. Our experimental results show that the proposed metrics perform\nclearly better on the networks spreading false information than on those\nspreading true ones, indicating our community health assessment model is\neffective.", "doi": "", "date": "2021-02-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.02434v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1362191316, "title": "Supporting verification of news articles with automated search for\n  semantically similar articles", "abstract": "Fake information poses one of the major threats for society in the 21st\ncentury. Identifying misinformation has become a key challenge due to the\namount of fake news that is published daily. Yet, no approach is established\nthat addresses the dynamics and versatility of fake news editorials. Instead of\nclassifying content, we propose an evidence retrieval approach to handle fake\nnews. The learning task is formulated as an unsupervised machine learning\nproblem. For validation purpose, we provide the user with a set of news\narticles from reliable news sources supporting the hypothesis of the news\narticle in query and the final decision is left to the user. Technically we\npropose a two-step process: (i) Aggregation-step: With information extracted\nfrom the given text we query for similar content from reliable news sources.\n(ii) Refining-step: We narrow the supporting evidence down by measuring the\nsemantic distance of the text with the collection from step (i). The distance\nis calculated based on Word2Vec and the Word Mover's Distance. In our\nexperiments, only content that is below a certain distance threshold is\nconsidered as supporting evidence. We find that our approach is agnostic to\nconcept drifts, i.e. the machine learning task is independent of the hypotheses\nin a text. This makes it highly adaptable in times where fake news is as\ndiverse as classical news is. Our pipeline offers the possibility for further\nanalysis in the future, such as investigating bias and differences in news\nreporting.", "doi": "", "date": "2021-03-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.15581v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2464109024, "title": "Prevalence and Propagation of Fake News", "abstract": "In recent years, scholars have raised concerns on the effects that unreliable\nnews, or \"fake news,\" has on our political sphere, and our democracy as a\nwhole. For example, the propagation of fake news on social media is widely\nbelieved to have influenced the outcome of national elections, including the\n2016 U.S. Presidential Election, and the 2020 COVID-19 pandemic. What drives\nthe propagation of fake news on an individual level, and which interventions\ncould effectively reduce the propagation rate? Our model disentangles bias from\ntruthfulness of an article and examines the relationship between these two\nparameters and a reader's own beliefs. Using the model, we create policy\nrecommendations for both social media platforms and individual social media\nusers to reduce the spread of untruthful or highly biased news. We recommend\nthat platforms sponsor unbiased truthful news, focus fact-checking efforts on\nmild to moderately biased news, recommend friend suggestions across the\npolitical spectrum, and provide users with reports about the political\nalignment of their feed. We recommend that individual social media users fact\ncheck news that strongly aligns with their political bias and read articles of\nopposing political bias.", "doi": "", "date": "2021-06-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.09586v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1598001025, "title": "MetaDetector: Meta Event Knowledge Transfer for Fake News Detection", "abstract": "The blooming of fake news on social networks has devastating impacts on\nsociety, economy, and public security. Although numerous studies are conducted\nfor the automatic detection of fake news, the majority tend to utilize deep\nneural networks to learn event-specific features for superior detection\nperformance on specific datasets. However, the trained models heavily rely on\nthe training datasets and are infeasible to apply to upcoming events due to the\ndiscrepancy between event distributions. Inspired by domain adaptation\ntheories, we propose an end-to-end adversarial adaptation network, dubbed as\nMetaDetector, to transfer meta knowledge (event-shared features) between\ndifferent events. Specifically, MetaDetector pushes the feature extractor and\nevent discriminator to eliminate event-specific features and preserve required\nevent-shared features by adversarial training. Furthermore, the pseudo-event\ndiscriminator is utilized to evaluate the importance of historical event posts\nto obtain partial shared features that are discriminative for detecting fake\nnews. Under the coordinated optimization among the four submodules,\nMetaDetector accurately transfers the meta-knowledge of historical events to\nthe upcoming event for fact checking. We conduct extensive experiments on two\nlarge-scale datasets collected from Weibo and Twitter. The experimental results\ndemonstrate that MetaDetector outperforms the state-of-the-art methods,\nespecially when the distribution shift between events is significant.\nFurthermore, we find that MetaDetector is able to learn the event-shared\nfeatures, and alleviate the negative transfer caused by the large distribution\nshift between events.", "doi": "", "date": "2021-06-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.11177v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1752406650, "title": "The coercive logic of fake news", "abstract": "The spread of misinformation and \"fake news\" continues to be a major focus of\npublic concern. A great deal of recent research has examined who falls for\nmisinformation and why, and what can be done to make people more discerning\nconsumers of news. Comparatively little work, however, has considered the\nchoices of those who produce misinformation, and how these choices interact\nwith the psychology of news consumers. Here we use game-theoretic models to\nstudy the strategic interaction between news publishers and news readers. We\nshow that publishers who seek to spread misinformation can generate high\nengagement with falsehoods by using strategies that mix true and false stories\nover time, in such a way that they serve more false stories to more loyal\nreaders. These coercive strategies cause false stories to receive higher reader\nengagement than true stories - even when readers strictly prefer truth over\nfalsehood. In contrast, publishers who seek to promote engagement with accurate\ninformation will use strategies that generate more engagement with true stories\nthan with false stories. We confirm these predictions empirically by examining\n1,000 headlines from 20 mainstream and 20 fake news sites, comparing Facebook\nengagement data with 20,000 perceived accuracy ratings collected in a survey\nexperiment. We then use our model to analyze possible ways to disincentivize\nfake news, finding that reducing the capacity of news sources to microtarget\nreaders, and increasing readers' level of attention, reduces the efficacy of\ncoercion. Finally, we show that if a publisher incorrectly assumes that readers\nprefer falsehoods, their resulting publication strategy can manufacture greater\nengagement with false news - leading to a self-reinforcing cycle of false news\npromotion.", "doi": "", "date": "2021-08-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.13687v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3037721946, "title": "Adversarial Classification on Social Networks", "abstract": "The spread of unwanted or malicious content through social media has become a\nmajor challenge. Traditional examples of this include social network spam, but\nan important new concern is the propagation of fake news through social media.\nA common approach for mitigating this problem is by using standard statistical\nclassification to distinguish malicious (e.g., fake news) instances from benign\n(e.g., actual news stories). However, such an approach ignores the fact that\nmalicious instances propagate through the network, which is consequential both\nin quantifying consequences (e.g., fake news diffusing through the network),\nand capturing detection redundancy (bad content can be detected at different\nnodes). An additional concern is evasion attacks, whereby the generators of\nmalicious instances modify the nature of these to escape detection. We model\nthis problem as a Stackelberg game between the defender who is choosing\nparameters of the detection model, and an attacker, who is choosing both the\nnode at which to initiate malicious spread, and the nature of malicious\nentities. We develop a novel bi-level programming approach for this problem, as\nwell as a novel solution approach based on implicit function gradients, and\nexperimentally demonstrate the advantage of our approach over alternatives\nwhich ignore network structure.", "doi": "", "date": "2018-01-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1801.08159v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4064464143, "title": "Reversible bootstrap percolation: Fake news and fact checking", "abstract": "Bootstrap percolation has been used to describe opinion formation in society\nand other social and natural phenomena. The formal equation of the bootstrap\npercolation may have more than one solution, corresponding to several stable\nfixed points of the corresponding iteration process. We construct a reversible\nbootstrap percolation process, which converges to these extra solutions\ndisplaying a hysteresis typical of discontinuous phase transitions. This\nprocess provides a reasonable model for fake news spreading and the\neffectiveness of fact checking. We show that sometimes it is not sufficient to\ndiscard all the sources of fake news in order to reverse the belief of a\npopulation that formed under the influence of these sources.", "doi": "10.1103/physreve.101.042307", "date": "2019-10-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.09516v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3219510195, "title": "Do Sentence Interactions Matter? Leveraging Sentence Level\n  Representations for Fake News Classification", "abstract": "The rising growth of fake news and misleading information through online\nmedia outlets demands an automatic method for detecting such news articles. Of\nthe few limited works which differentiate between trusted vs other types of\nnews article (satire, propaganda, hoax), none of them model sentence\ninteractions within a document. We observe an interesting pattern in the way\nsentences interact with each other across different kind of news articles. To\ncapture this kind of information for long news articles, we propose a graph\nneural network-based model which does away with the need of feature engineering\nfor fine grained fake news classification. Through experiments, we show that\nour proposed method beats strong neural baselines and achieves state-of-the-art\naccuracy on existing datasets. Moreover, we establish the generalizability of\nour model by evaluating its performance in out-of-domain scenarios. Code is\navailable at https://github.com/MysteryVaibhav/fake_news_semantics", "doi": "", "date": "2019-10-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.12203v1", "pdf": ""}, "publisher-venue": "TextGraphs - EMNLP 2019", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2224898318, "title": "A simple but tough-to-beat baseline for the Fake News Challenge stance\n  detection task", "abstract": "Identifying public misinformation is a complicated and challenging task. An\nimportant part of checking the veracity of a specific claim is to evaluate the\nstance different news sources take towards the assertion. Automatic stance\nevaluation, i.e. stance detection, would arguably facilitate the process of\nfact checking. In this paper, we present our stance detection system which\nclaimed third place in Stage 1 of the Fake News Challenge. Despite our\nstraightforward approach, our system performs at a competitive level with the\ncomplex ensembles of the top two winning teams. We therefore propose our system\nas the 'simple but tough-to-beat baseline' for the Fake News Challenge stance\ndetection task.", "doi": "", "date": "2017-07-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1707.03264v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1006921201, "title": "Incentivizing the Dissemination of Truth Versus Fake News in Social\n  Networks", "abstract": "The concept of truth, as a public good is the production of a collective\nunderstanding, which emerges from a complex network of social interactions. The\nrecent impact of social networks on shaping the perception of truth in\npolitical arena shows how such perception is corroborated and established by\nthe online users, collectively. However, investigative journalism for\ndiscovering truth is a costly option, given the vast spectrum of online\ninformation. In some cases, both journalist and online users choose not to\ninvestigate the authenticity of the news they receive, because they assume\nother actors of the network had carried the cost of validation. Therefore, the\nnew phenomenon of \"fake news\" has emerged within the context of social\nnetworks. The online social networks, similarly to System of Systems, cause\nemergent properties, which makes authentication processes difficult, given\navailability of multiple sources. In this study, we show how this conflict can\nbe modeled as a volunteer's dilemma. We also show how the public contribution\nthrough news subscription (shared rewards) can impact the dominance of truth\nover fake news in the network.", "doi": "", "date": "2018-04-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.02509v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1805871546, "title": "Neural Abstractive Text Summarization and Fake News Detection", "abstract": "In this work, we study abstractive text summarization by exploring different\nmodels such as LSTM-encoder-decoder with attention, pointer-generator networks,\ncoverage mechanisms, and transformers. Upon extensive and careful\nhyperparameter tuning we compare the proposed architectures against each other\nfor the abstractive text summarization task. Finally, as an extension of our\nwork, we apply our text summarization model as a feature extractor for a fake\nnews detection task where the news articles prior to classification will be\nsummarized and the results are compared against the classification using only\nthe original news text.\n  keywords: LSTM, encoder-deconder, abstractive text summarization,\npointer-generator, coverage mechanism, transformers, fake news detection", "doi": "", "date": "2019-03-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.00788v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 773594793, "title": "Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality", "abstract": "The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media.", "doi": "", "date": "2019-04-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.05386v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1752958581, "title": "Deep Two-path Semi-supervised Learning for Fake News Detection", "abstract": "News in social media such as Twitter has been generated in high volume and\nspeed. However, very few of them can be labeled (as fake or true news) in a\nshort time. In order to achieve timely detection of fake news in social media,\na novel deep two-path semi-supervised learning model is proposed, where one\npath is for supervised learning and the other is for unsupervised learning.\nThese two paths implemented with convolutional neural networks are jointly\noptimized to enhance detection performance. In addition, we build a shared\nconvolutional neural networks between these two paths to share the low level\nfeatures. Experimental results using Twitter datasets show that the proposed\nmodel can recognize fake news effectively with very few labeled data.", "doi": "", "date": "2019-06-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.05659v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1909343108, "title": "Fake News Detection using Stance Classification: A Survey", "abstract": "This paper surveys and presents recent academic work carried out within the\nfield of stance classification and fake news detection. Echo chambers and the\nmodel organism problem are examples that pose challenges to acquire data with\nhigh quality, due to opinions being polarised in microblogs. Nevertheless it is\nshown that several machine learning approaches achieve promising results in\nclassifying stance. Some use crowd stance for fake news detection, such as the\napproach in [Dungs et al., 2018] using Hidden Markov Models. Furthermore\nfeature engineering have significant importance in several approaches, which is\nshown in [Aker et al., 2017]. This paper additionally includes a proposal of a\nsystem implementation based on the presented survey.", "doi": "", "date": "2019-06-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.00181v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 206598265, "title": "The Myths of Our Time: Fake News", "abstract": "While the purpose of most fake news is misinformation and political\npropaganda, our team sees it as a new type of myth that is created by people in\nthe age of internet identities and artificial intelligence. Seeking insights on\nthe fear and desire hidden underneath these modified or generated stories, we\nuse machine learning methods to generate fake articles and present them in the\nform of an online news blog. This paper aims to share the details of our\npipeline and the techniques used for full generation of fake news, from dataset\ncollection to presentation as a media art project on the internet.", "doi": "", "date": "2019-08-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.01760v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2271000682, "title": "The Limitations of Stylometry for Detecting Machine-Generated Fake News", "abstract": "Recent developments in neural language models (LMs) have raised concerns\nabout their potential misuse for automatically spreading misinformation. In\nlight of these concerns, several studies have proposed to detect\nmachine-generated fake news by capturing their stylistic differences from\nhuman-written text. These approaches, broadly termed stylometry, have found\nsuccess in source attribution and misinformation detection in human-written\ntexts. However, in this work, we show that stylometry is limited against\nmachine-generated misinformation. While humans speak differently when trying to\ndeceive, LMs generate stylistically consistent text, regardless of underlying\nmotive. Thus, though stylometry can successfully prevent impersonation by\nidentifying text provenance, it fails to distinguish legitimate LM applications\nfrom those that introduce false information. We create two benchmarks\ndemonstrating the stylistic similarity between malicious and legitimate uses of\nLMs, employed in auto-completion and editing-assistance settings. Our findings\nhighlight the need for non-stylometry approaches in detecting machine-generated\nmisinformation, and open up the discussion on the desired evaluation\nbenchmarks.", "doi": "", "date": "2019-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.09805v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1004279946, "title": "Different Absorption from the Same Sharing: Sifted Multi-task Learning\n  for Fake News Detection", "abstract": "Recently, neural networks based on multi-task learning have achieved\npromising performance on fake news detection, which focus on learning shared\nfeatures among tasks as complementary features to serve different tasks.\nHowever, in most of the existing approaches, the shared features are completely\nassigned to different tasks without selection, which may lead to some useless\nand even adverse features integrated into specific tasks. In this paper, we\ndesign a sifted multi-task learning method with a selected sharing layer for\nfake news detection. The selected sharing layer adopts gate mechanism and\nattention mechanism to filter and select shared feature flows between tasks.\nExperiments on two public and widely used competition datasets, i.e. RumourEval\nand PHEME, demonstrate that our proposed method achieves the state-of-the-art\nperformance and boosts the F1-score by more than 0.87%, 1.31%, respectively.", "doi": "", "date": "2019-09-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.01720v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 257173426, "title": "In Search of Credible News", "abstract": "We study the problem of finding fake online news. This is an important\nproblem as news of questionable credibility have recently been proliferating in\nsocial media at an alarming scale. As this is an understudied problem,\nespecially for languages other than English, we first collect and release to\nthe research community three new balanced credible vs. fake news datasets\nderived from four online sources. We then propose a language-independent\napproach for automatically distinguishing credible from fake news, based on a\nrich feature set. In particular, we use linguistic (n-gram),\ncredibility-related (capitalization, punctuation, pronoun use, sentiment\npolarity), and semantic (embeddings and DBPedia data) features. Our experiments\non three different testsets show that our model can distinguish credible from\nfake news with very high accuracy.", "doi": "", "date": "2019-11-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.08125v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1947246133, "title": "Warning Signs in Communicating the Machine Learning Detection Results of\n  Misinformation with Individuals", "abstract": "With the prevalence of misinformation online, researchers have focused on\ndeveloping various machine learning algorithms to detect fake news. However,\nusers' perception of machine learning outcomes and related behaviors have been\nwidely ignored. Hence, this paper proposed to bridge this gap by studying how\nto pass the detection results of machine learning to the users, and aid their\ndecisions in handling misinformation. An online experiment was conducted, to\nevaluate the effect of the proposed machine learning warning sign against a\ncontrol condition. We examined participants' detection and sharing of news. The\ndata showed that warning sign's effects on participants' trust toward the fake\nnews were not significant. However, we found that people's uncertainty about\nthe authenticity of the news dropped with the presence of the machine learning\nwarning sign. We also found that social media experience had effects on users'\ntrust toward the fake news, and age and social media experience had effects on\nusers' sharing decision. Therefore, the results indicate that there are many\nfactors worth studying that affect people's trust in the news. Moreover, the\nwarning sign in communicating machine learning detection results is different\nfrom ordinary warnings and needs more detailed research and design. These\nfindings hold important implications for the design of machine learning\nwarnings.", "doi": "", "date": "2019-11-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.11920v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2111119505, "title": "Two-path Deep Semi-supervised Learning for Timely Fake News Detection", "abstract": "News in social media such as Twitter has been generated in high volume and\nspeed. However, very few of them are labeled (as fake or true news) by\nprofessionals in near real time. In order to achieve timely detection of fake\nnews in social media, a novel framework of two-path deep semi-supervised\nlearning is proposed where one path is for supervised learning and the other is\nfor unsupervised learning. The supervised learning path learns on the limited\namount of labeled data while the unsupervised learning path is able to learn on\na huge amount of unlabeled data. Furthermore, these two paths implemented with\nconvolutional neural networks (CNN) are jointly optimized to complete\nsemi-supervised learning. In addition, we build a shared CNN to extract the low\nlevel features on both labeled data and unlabeled data to feed them into these\ntwo paths. To verify this framework, we implement a Word CNN based\nsemi-supervised learning model and test it on two datasets, namely, LIAR and\nPHEME. Experimental results demonstrate that the model built on the proposed\nframework can recognize fake news effectively with very few labeled data.", "doi": "", "date": "2020-01-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.00763v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3493793141, "title": "Ginger Cannot Cure Cancer: Battling Fake Health News with a\n  Comprehensive Data Repository", "abstract": "Nowadays, Internet is a primary source of attaining health information.\nMassive fake health news which is spreading over the Internet, has become a\nsevere threat to public health. Numerous studies and research works have been\ndone in fake news detection domain, however, few of them are designed to cope\nwith the challenges in health news. For instance, the development of\nexplainable is required for fake health news detection. To mitigate these\nproblems, we construct a comprehensive repository, FakeHealth, which includes\nnews contents with rich features, news reviews with detailed explanations,\nsocial engagements and a user-user social network. Moreover, exploratory\nanalyses are conducted to understand the characteristics of the datasets,\nanalyze useful patterns and validate the quality of the datasets for health\nfake news detection. We also discuss the novel and potential future research\ndirections for the health fake news detection.", "doi": "", "date": "2020-01-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.00837v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2086619452, "title": "Can We Spot the \"Fake News\" Before It Was Even Written?", "abstract": "Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n\"fake news.\" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.", "doi": "", "date": "2020-08-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.04374v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2301381451, "title": "Feature Extraction of Text for Deep Learning Algorithms: Application on\n  Fake News Detection", "abstract": "Feature extraction is an important process of machine learning and deep\nlearning, as the process make algorithms function more efficiently, and also\naccurate. In natural language processing used in deception detection such as\nfake news detection, several ways of feature extraction in statistical aspect\nhad been introduced (e.g. N-gram). In this research, it will be shown that by\nusing deep learning algorithms and alphabet frequencies of the original text of\na news without any information about the sequence of the alphabet can actually\nbe used to classify fake news and trustworthy ones in high accuracy (85\\%). As\nthis pre-processing method makes the data notably compact but also include the\nfeature that is needed for the classifier, it seems that alphabet frequencies\ncontains some useful features for understanding complex context or meaning of\nthe original text.", "doi": "", "date": "2020-10-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.05496v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4142818178, "title": "Fake News Detection in Social Media using Graph Neural Networks and NLP\n  Techniques: A COVID-19 Use-case", "abstract": "The paper presents our solutions for the MediaEval 2020 task namely FakeNews:\nCorona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task\naims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect\nmisinformation spreaders. The task is composed of two sub-tasks namely (i)\ntext-based, and (ii) structure-based fake news detection. For the first task,\nwe propose six different solutions relying on Bag of Words (BoW) and BERT\nembedding. Three of the methods aim at binary classification task by\ndifferentiating in 5G conspiracy and the rest of the COVID-19 related tweets\nwhile the rest of them treat the task as ternary classification problem. In the\nternary classification task, our BoW and BERT based methods obtained an\nF1-score of .606% and .566% on the development set, respectively. On the binary\nclassification, the BoW and BERT based solutions obtained an average F1-score\nof .666% and .693%, respectively. On the other hand, for structure-based fake\nnews detection, we rely on Graph Neural Networks (GNNs) achieving an average\nROC of .95% on the development set.", "doi": "", "date": "2020-11-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.07517v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 701458016, "title": "TIB's Visual Analytics Group at MediaEval '20: Detecting Fake News on\n  Corona Virus and 5G Conspiracy", "abstract": "Fake news on social media has become a hot topic of research as it negatively\nimpacts the discourse of real news in the public. Specifically, the ongoing\nCOVID-19 pandemic has seen a rise of inaccurate and misleading information due\nto the surrounding controversies and unknown details at the beginning of the\npandemic. The FakeNews task at MediaEval 2020 tackles this problem by creating\na challenge to automatically detect tweets containing misinformation based on\ntext and structure from Twitter follower network. In this paper, we present a\nsimple approach that uses BERT embeddings and a shallow neural network for\nclassifying tweets using only text, and discuss our findings and limitations of\nthe approach in text-based misinformation detection.", "doi": "", "date": "2021-01-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.03529v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3569590926, "title": "LaDiff ULMFiT: A Layer Differentiated training approach for ULMFiT", "abstract": "In our paper, we present Deep Learning models with a layer differentiated\ntraining method which were used for the SHARED TASK@ CONSTRAINT 2021 sub-tasks\nCOVID19 Fake News Detection in English and Hostile Post Detection in Hindi. We\npropose a Layer Differentiated training procedure for training a pre-trained\nULMFiT arXiv:1801.06146 model. We used special tokens to annotate specific\nparts of the tweets to improve language understanding and gain insights on the\nmodel making the tweets more interpretable. The other two submissions included\na modified RoBERTa model and a simple Random Forest Classifier. The proposed\napproach scored a precision and f1 score of 0.96728972 and 0.967324832\nrespectively for sub-task \"COVID19 Fake News Detection in English\". Also,\nCoarse-Grained Hostility f1 Score and Weighted FineGrained f1 score of 0.908648\nand 0.533907 respectively for sub-task Hostile Post Detection in Hindi. The\nproposed approach ranked 61st out of 164 in the sub-task \"COVID19 Fake News\nDetection in English and 18th out of 45 in the sub-task Hostile Post Detection\nin Hindi\".", "doi": "", "date": "2021-01-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.04965v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2150331495, "title": "FakeFlow: Fake News Detection by Modeling the Flow of Affective\n  Information", "abstract": "Fake news articles often stir the readers' attention by means of emotional\nappeals that arouse their feelings. Unlike in short news texts, authors of\nlonger articles can exploit such affective factors to manipulate readers by\nadding exaggerations or fabricating events, in order to affect the readers'\nemotions. To capture this, we propose in this paper to model the flow of\naffective information in fake news articles using a neural architecture. The\nproposed model, FakeFlow, learns this flow by combining topic and affective\ninformation extracted from text. We evaluate the model's performance with\nseveral experiments on four real-world datasets. The results show that FakeFlow\nachieves superior results when compared against state-of-the-art methods, thus\nconfirming the importance of capturing the flow of the affective information in\nnews articles.", "doi": "", "date": "2021-01-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.09810v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3215789687, "title": "Fake News Detection System using XLNet model with Topic Distributions:\n  CONSTRAINT@AAAI2021 Shared Task", "abstract": "With the ease of access to information, and its rapid dissemination over the\ninternet (both velocity and volume), it has become challenging to filter out\ntruthful information from fake ones. The research community is now faced with\nthe task of automatic detection of fake news, which carries real-world\nsocio-political impact. One such research contribution came in the form of the\nConstraint@AAA12021 Shared Task on COVID19 Fake News Detection in English. In\nthis paper, we shed light on a novel method we proposed as a part of this\nshared task. Our team introduced an approach to combine topical distributions\nfrom Latent Dirichlet Allocation (LDA) with contextualized representations from\nXLNet. We also compared our method with existing baselines to show that XLNet +\nTopic Distributions outperforms other approaches by attaining an F1-score of\n0.967.", "doi": "", "date": "2021-01-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.11425v1", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI2021 Shared Task for the CONSTRAINT\\n  workshop, collocated with AAAI 2021", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 192390092, "title": "A transformer based approach for fighting COVID-19 fake news", "abstract": "The rapid outbreak of COVID-19 has caused humanity to come to a stand-still\nand brought with it a plethora of other problems. COVID-19 is the first\npandemic in history when humanity is the most technologically advanced and\nrelies heavily on social media platforms for connectivity and other benefits.\nUnfortunately, fake news and misinformation regarding this virus is also\navailable to people and causing some massive problems. So, fighting this\ninfodemic has become a significant challenge. We present our solution for the\n\"Constraint@AAAI2021 - COVID19 Fake News Detection in English\" challenge in\nthis work. After extensive experimentation with numerous architectures and\ntechniques, we use eight different transformer-based pre-trained models with\nadditional layers to construct a stacking ensemble classifier and fine-tuned\nthem for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,\n0.979906542 recall, and 0.979907901 f1-score on the test dataset of the\ncompetition.", "doi": "", "date": "2021-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.12027v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1893606484, "title": "Fake News Detection: a comparison between available Deep Learning\n  techniques in vector space", "abstract": "Fake News Detection is an essential problem in the field of Natural Language\nProcessing. The benefits of an effective solution in this area are manifold for\nthe goodwill of society. On a surface level, it broadly matches with the\ngeneral problem of text classification. Researchers have proposed various\napproaches to tackle fake news using simple as well as some complex techniques.\nIn this paper, we try to make a comparison between the present Deep Learning\ntechniques by representing the news instances in some vector space using a\ncombination of common mathematical operations with available vector space\nrepresentations. We do a number of experiments using various combinations and\npermutations. Finally, we conclude with a sound analysis of the results and\nevaluate the reasons for such results.", "doi": "10.1109/cict51604.2020.9312099", "date": "2021-02-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.09470v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1297211444, "title": "On the Role of Images for Analyzing Claims in Social Media", "abstract": "Fake news is a severe problem in social media. In this paper, we present an\nempirical study on visual, textual, and multimodal models for the tasks of\nclaim, claim check-worthiness, and conspiracy detection, all of which are\nrelated to fake news detection. Recent work suggests that images are more\ninfluential than text and often appear alongside fake text. To this end,\nseveral multimodal models have been proposed in recent years that use images\nalong with text to detect fake news on social media sites like Twitter.\nHowever, the role of images is not well understood for claim detection,\nspecifically using transformer-based textual and multimodal models. We\ninvestigate state-of-the-art models for images, text (Transformer-based), and\nmultimodal information for four different datasets across two languages to\nunderstand the role of images in the task of claim and conspiracy detection.", "doi": "", "date": "2021-03-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.09602v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2674506731, "title": "Automatic Fake News Detection: Are Models Learning to Reason?", "abstract": "Most fact checking models for automatic fake news detection are based on\nreasoning: given a claim with associated evidence, the models aim to estimate\nthe claim veracity based on the supporting or refuting content within the\nevidence. When these models perform well, it is generally assumed to be due to\nthe models having learned to reason over the evidence with regards to the\nclaim. In this paper, we investigate this assumption of reasoning, by exploring\nthe relationship and importance of both claim and evidence. Surprisingly, we\nfind on political fact checking datasets that most often the highest\neffectiveness is obtained by utilizing only the evidence, as the impact of\nincluding the claim is either negligible or harmful to the effectiveness. This\nhighlights an important problem in what constitutes evidence in existing\napproaches for automatic fake news detection.", "doi": "", "date": "2021-05-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.07698v1", "pdf": ""}, "publisher-venue": "ACL 2021", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2797437843, "title": "Both Rates of Fake News and Fact-based News on Twitter Negatively\n  Correlate with the State-level COVID-19 Vaccine Uptake", "abstract": "There is evidence of misinformation in the online discourses and discussions\nabout the COVID-19 vaccines. Using a sample of 1.6 million geotagged English\ntweets and the data from the CDC COVID Data Tracker, we conduct a quantitative\nstudy to understand the influence of both misinformation and fact-based news on\nTwitter on the COVID-19 vaccine uptake in the U.S. from April 19 when U.S.\nadults were vaccine eligible to May 7, 2021, after controlling state-level\nfactors such as demographics, education, and the pandemic severity. We identify\nthe tweets related to either misinformation or fact-based news by analyzing the\nURLs. By analyzing the content of the most frequent tweets of these two groups,\nwe find that their structures are similar, making it difficult for Twitter\nusers to distinguish one from another by reading the text alone. The users who\nspread both fake news and fact-based news tend to show a negative attitude\ntowards the vaccines. We further conduct the Fama-MacBeth regression with the\nNewey-West adjustment to examine the effect of fake-news-related and\nfact-related tweets on the vaccination rate, and find marginally negative\ncorrelations.", "doi": "", "date": "2021-06-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.07435v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3578061101, "title": "Countering Misinformation on Social Media Through Educational\n  Interventions: Evidence from a Randomized Experiment in Pakistan", "abstract": "Fake news is a growing problem in developing countries with potentially\nfar-reaching consequences. We conduct a randomized experiment in urban Pakistan\nto evaluate the effectiveness of two educational interventions to counter\nmisinformation among low-digital literacy populations. We do not find a\nsignificant effect of video-based general educational messages about\nmisinformation. However, when such messages are augmented with personalized\nfeedback based on individuals' past engagement with fake news, we find an\nimprovement of 0.14 standard deviations in identifying fake news. We also find\nnegative but insignificant effects on identifying true news, driven by female\nrespondents. Our results suggest that educational interventions can enable\ninformation discernment but their effectiveness critically depends on how well\ntheir features and delivery are customized for the population of interest.", "doi": "", "date": "2021-07-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.02775v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1044473384, "title": "CIMTDetect: A Community Infused Matrix-Tensor Coupled Factorization\n  Based Method for Fake News Detection", "abstract": "Detecting whether a news article is fake or genuine is a crucial task in\ntoday's digital world where it's easy to create and spread a misleading news\narticle. This is especially true of news stories shared on social media since\nthey don't undergo any stringent journalistic checking associated with main\nstream media. Given the inherent human tendency to share information with their\nsocial connections at a mouse-click, fake news articles masquerading as real\nones, tend to spread widely and virally. The presence of echo chambers (people\nsharing same beliefs) in social networks, only adds to this problem of\nwide-spread existence of fake news on social media. In this paper, we tackle\nthe problem of fake news detection from social media by exploiting the very\npresence of echo chambers that exist within the social network of users to\nobtain an efficient and informative latent representation of the news article.\nBy modeling the echo-chambers as closely-connected communities within the\nsocial network, we represent a news article as a 3-mode tensor of the structure\n- <News, User, Community> and propose a tensor factorization based method to\nencode the news article in a latent embedding space preserving the community\nstructure. We also propose an extension of the above method, which jointly\nmodels the community and content information of the news article through a\ncoupled matrix-tensor factorization framework. We empirically demonstrate the\nefficacy of our method for the task of Fake News Detection over two real-world\ndatasets. Further, we validate the generalization of the resulting embeddings\nover two other auxiliary tasks, namely: \\textbf{1)} News Cohort Analysis and\n\\textbf{2)} Collaborative News Recommendation. Our proposed method outperforms\nappropriate baselines for both the tasks, establishing its generalization.", "doi": "", "date": "2018-09-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.05252v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4070026767, "title": "Leveraging the Crowd to Detect and Reduce the Spread of Fake News and\n  Misinformation", "abstract": "Online social networking sites are experimenting with the following\ncrowd-powered procedure to reduce the spread of fake news and misinformation:\nwhenever a user is exposed to a story through her feed, she can flag the story\nas misinformation and, if the story receives enough flags, it is sent to a\ntrusted third party for fact checking. If this party identifies the story as\nmisinformation, it is marked as disputed. However, given the uncertain number\nof exposures, the high cost of fact checking, and the trade-off between flags\nand exposures, the above mentioned procedure requires careful reasoning and\nsmart algorithms which, to the best of our knowledge, do not exist to date.\n  In this paper, we first introduce a flexible representation of the above\nprocedure using the framework of marked temporal point processes. Then, we\ndevelop a scalable online algorithm, Curb, to select which stories to send for\nfact checking and when to do so to efficiently reduce the spread of\nmisinformation with provable guarantees. In doing so, we need to solve a novel\nstochastic optimal control problem for stochastic differential equations with\njumps, which is of independent interest. Experiments on two real-world datasets\ngathered from Twitter and Weibo show that our algorithm may be able to\neffectively reduce the spread of fake news and misinformation.", "doi": "", "date": "2017-11-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.09918v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 272996882, "title": "A Machine Learning Analysis of the Features in Deceptive and Credible\n  News", "abstract": "Fake news is a type of pervasive propaganda that spreads misinformation\nonline, taking advantage of social media's extensive reach to manipulate public\nperception. Over the past three years, fake news has become a focal discussion\npoint in the media due to its impact on the 2016 U.S. presidential election.\nFake news can have severe real-world implications: in 2016, a man walked into a\npizzeria carrying a rifle because he read that Hillary Clinton was harboring\nchildren as sex slaves. This project presents a high accuracy (87%) machine\nlearning classifier that determines the validity of news based on the word\ndistributions and specific linguistic and stylistic differences in the first\nfew sentences of an article. This can help readers identify the validity of an\narticle by looking for specific features in the opening lines aiding them in\nmaking informed decisions. Using a dataset of 2,107 articles from 30 different\nwebsites, this project establishes an understanding of the variations between\nfake and credible news by examining the model, dataset, and features. This\nclassifier appears to use the differences in word distribution, levels of tone\nauthenticity, and frequency of adverbs, adjectives, and nouns. The\ndifferentiation in the features of these articles can be used to improve future\nclassifiers. This classifier can also be further applied directly to browsers\nas a Google Chrome extension or as a filter for social media outlets or news\nwebsites to reduce the spread of misinformation.", "doi": "", "date": "2019-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.02223v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2160218133, "title": "Semi-supervised Content-based Detection of Misinformation via Tensor\n  Embeddings", "abstract": "Fake news may be intentionally created to promote economic, political and\nsocial interests, and can lead to negative impacts on humans beliefs and\ndecisions. Hence, detection of fake news is an emerging problem that has become\nextremely prevalent during the last few years. Most existing works on this\ntopic focus on manual feature extraction and supervised classification models\nleveraging a large number of labeled (fake or real) articles. In contrast, we\nfocus on content-based detection of fake news articles, while assuming that we\nhave a small amount of labels, made available by manual fact-checkers or\nautomated sources. We argue this is a more realistic setting in the presence of\nmassive amounts of content, most of which cannot be easily factchecked. To that\nend, we represent collections of news articles as multi-dimensional tensors,\nleverage tensor decomposition to derive concise article embeddings that capture\nspatial/contextual information about each news article, and use those\nembeddings to create an article-by-article graph on which we propagate limited\nlabels. Results on three real-world datasets show that our method performs on\npar or better than existing models that are fully supervised, in that we\nachieve better detection accuracy using fewer labels. In particular, our\nproposed method achieves 75.43% of accuracy using only 30% of labels of a\npublic dataset while an SVM-based classifier achieved 67.43%. Furthermore, our\nmethod achieves 70.92% of accuracy in a large dataset using only 2% of labels.", "doi": "", "date": "2018-04-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.09088v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2847476146, "title": "A Retrospective Analysis of the Fake News Challenge Stance Detection\n  Task", "abstract": "The 2017 Fake News Challenge Stage 1 (FNC-1) shared task addressed a stance\nclassification task as a crucial first step towards detecting fake news. To\ndate, there is no in-depth analysis paper to critically discuss FNC-1's\nexperimental setup, reproduce the results, and draw conclusions for\nnext-generation stance classification methods. In this paper, we provide such\nan in-depth analysis for the three top-performing systems. We first find that\nFNC-1's proposed evaluation metric favors the majority class, which can be\neasily classified, and thus overestimates the true discriminative power of the\nmethods. Therefore, we propose a new F1-based metric yielding a changed system\nranking. Next, we compare the features and architectures used, which leads to a\nnovel feature-rich stacked LSTM model that performs on par with the best\nsystems, but is superior in predicting minority classes. To understand the\nmethods' ability to generalize, we derive a new dataset and perform both\nin-domain and cross-domain experiments. Our qualitative and quantitative study\nhelps interpreting the original FNC-1 scores and understand which features help\nimproving performance and why. Our new dataset and all source code used during\nthe reproduction study are publicly available for future research.", "doi": "", "date": "2018-06-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.05180v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3270184397, "title": "Belittling the Source: Trustworthiness Indicators to Obfuscate Fake News\n  on the Web", "abstract": "With the growth of the internet, the number of fake-news online has been\nproliferating every year. The consequences of such phenomena are manifold,\nranging from lousy decision-making process to bullying and violence episodes.\nTherefore, fact-checking algorithms became a valuable asset. To this aim, an\nimportant step to detect fake-news is to have access to a credibility score for\na given information source. However, most of the widely used Web indicators\nhave either been shut-down to the public (e.g., Google PageRank) or are not\nfree for use (Alexa Rank). Further existing databases are short-manually\ncurated lists of online sources, which do not scale. Finally, most of the\nresearch on the topic is theoretical-based or explore confidential data in a\nrestricted simulation environment. In this paper we explore current research,\nhighlight the challenges and propose solutions to tackle the problem of\nclassifying websites into a credibility scale. The proposed model automatically\nextracts source reputation cues and computes a credibility factor, providing\nvaluable insights which can help in belittling dubious and confirming trustful\nunknown websites. Experimental results outperform state of the art in the\n2-classes and 5-classes setting.", "doi": "", "date": "2018-09-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.00494v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 336018592, "title": "Emotion Cognizance Improves Health Fake News Identification", "abstract": "Identifying misinformation is increasingly being recognized as an important\ncomputational task with high potential social impact. Misinformation and fake\ncontents are injected into almost every domain of news including politics,\nhealth, science, business, etc., among which, the fakeness in health domain\npose serious adverse effects to scare or harm the society. Misinformation\ncontains scientific claims or content from social media exaggerated with strong\nemotion content to attract eyeballs. In this paper, we consider the utility of\nthe affective character of news articles for fake news identification in the\nhealth domain and present evidence that emotion cognizant representations are\nsignificantly more suited for the task. We outline a technique to leverage\nemotion intensity lexicons to develop emotionized text representations, and\nevaluate the utility of such a representation for identifying fake news\nrelating to health in various supervised and unsupervised scenarios. The\nconsistent and significant empirical gains that we observe over a range of\ntechnique types and parameter settings establish the utility of the emotional\ninformation in news articles, an often overlooked aspect, for the task of\nmisinformation identification in the health domain.", "doi": "", "date": "2019-06-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.10365v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 686000257, "title": "A Data Set of Internet Claims and Comparison of their Sentiments with\n  Credibility", "abstract": "In this modern era, communication has become faster and easier. This means\nfallacious information can spread as fast as reality. Considering the damage\nthat fake news kindles on the psychology of people and the fact that such news\nproliferates faster than truth, we need to study the phenomenon that helps\nspread fake news. An unbiased data set that depends on reality for rating news\nis necessary to construct predictive models for its classification. This paper\ndescribes the methodology to create such a data set. We collect our data from\nsnopes.com which is a fact-checking organization. Furthermore, we intend to\ncreate this data set not only for classification of the news but also to find\npatterns that reason the intent behind misinformation. We also formally define\nan Internet Claim, its credibility, and the sentiment behind such a claim. We\ntry to realize the relationship between the sentiment of a claim with its\ncredibility. This relationship pours light on the bigger picture behind the\npropagation of misinformation. We pave the way for further research based on\nthe methodology described in this paper to create the data set and usage of\npredictive modeling along with research-based on psychology/mentality of people\nto understand why fake news spreads much faster than reality.", "doi": "", "date": "2019-11-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.10130v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2861542556, "title": "Keystroke Biometrics in Response to Fake News Propagation in a Global\n  Pandemic", "abstract": "This work proposes and analyzes the use of keystroke biometrics for content\nde-anonymization. Fake news have become a powerful tool to manipulate public\nopinion, especially during major events. In particular, the massive spread of\nfake news during the COVID-19 pandemic has forced governments and companies to\nfight against missinformation. In this context, the ability to link multiple\naccounts or profiles that spread such malicious content on the Internet while\nhiding in anonymity would enable proactive identification and blacklisting.\nBehavioral biometrics can be powerful tools in this fight. In this work, we\nhave analyzed how the latest advances in keystroke biometric recognition can\nhelp to link behavioral typing patterns in experiments involving 100,000 users\nand more than 1 million typed sequences. Our proposed system is based on\nRecurrent Neural Networks adapted to the context of content de-anonymization.\nAssuming the challenge to link the typed content of a target user in a pool of\ncandidate profiles, our results show that keystroke recognition can be used to\nreduce the list of candidate profiles by more than 90%. In addition, when\nkeystroke is combined with auxiliary data (such as location), our system\nachieves a Rank-1 identification performance equal to 52.6% and 10.9% for a\nbackground candidate list composed of 1K and 100K profiles, respectively.", "doi": "", "date": "2020-05-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.07688v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 554682666, "title": "Factorization of Fact-Checks for Low Resource Indian Languages", "abstract": "The advancement in technology and accessibility of internet to each\nindividual is revolutionizing the real time information. The liberty to express\nyour thoughts without passing through any credibility check is leading to\ndissemination of fake content in the ecosystem. It can have disastrous effects\non both individuals and society as a whole. The amplification of fake news is\nbecoming rampant in India too. Debunked information often gets republished with\na replacement description, claiming it to depict some different incidence. To\ncurb such fabricated stories, it is necessary to investigate such deduplicates\nand false claims made in public. The majority of studies on automatic\nfact-checking and fake news detection is restricted to English only. But for a\ncountry like India where only 10% of the literate population speak English,\nrole of regional languages in spreading falsity cannot be undermined. In this\npaper, we introduce FactDRIL: the first large scale multilingual Fact-checking\nDataset for Regional Indian Languages. We collect an exhaustive dataset across\n7 months covering 11 low-resource languages. Our propose dataset consists of\n9,058 samples belonging to English, 5,155 samples to Hindi and remaining 8,222\nsamples are distributed across various regional languages, i.e. Bangla,\nMarathi, Malayalam, Telugu, Tamil, Oriya, Assamese, Punjabi, Urdu, Sinhala and\nBurmese. We also present the detailed characterization of three M's\n(multi-lingual, multi-media, multi-domain) in the FactDRIL accompanied with the\ncomplete list of other varied attributes making it a unique dataset to study.\nLastly, we present some potential use cases of the dataset. We expect this\ndataset will be a valuable resource and serve as a starting point to fight\nproliferation of fake news in low resource languages.", "doi": "", "date": "2021-02-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.11276v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3213622108, "title": "A Web Infrastructure for Certifying Multimedia News Content for Fake\n  News Defense", "abstract": "In dealing with altered visual multimedia content, also referred to as fake\nnews, we present a ready-to-deploy extension of the current public key\ninfrastructure (PKI), to provide an endorsement and integrity check platform\nfor newsworthy visual multimedia content. PKI, which is primarily used for Web\ndomain authentication, can directly be utilized with any visual multimedia\nfile. Unlike many other fake news researches that focus on technical multimedia\ndata processing and verification, we enable various news organizations to use\nour developed program to certify/endorse a multimedia news content when they\nbelieve this news piece is truthiness and newsworthy. Our program digitally\nsigns the multimedia news content with the news organization's private key, and\nthe endorsed news content can be posted not only by the endorser, but also by\nany other websites. By installing a web browser extension developed by us, an\nend user can easily verify whether a multimedia news content has been endorsed\nand by which organization. During verification, our browser extension will\npresent to the end user a floating logo next to the image or video. This logo,\nin the shape of a shield, will show whether the image has been endorsed, by\nwhich news organization, and a few more pieces of essential text information of\nthe news multimedia content. The proposed system can be easily integrated to\nother closed-web system such as social media networks and easily applied to\nother non-visual multimedia files.", "doi": "", "date": "2021-04-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.04671v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2766363836, "title": "Combining Similarity Features and Deep Representation Learning for\n  Stance Detection in the Context of Checking Fake News", "abstract": "Fake news are nowadays an issue of pressing concern, given their recent rise\nas a potential threat to high-quality journalism and well-informed public\ndiscourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage\nthe development of machine learning-based classification systems for stance\ndetection (i.e., for identifying whether a particular news article agrees,\ndisagrees, discusses, or is unrelated to a particular news headline), thus\nhelping in the detection and analysis of possible instances of fake news. This\narticle presents a new approach to tackle this stance detection problem, based\non the combination of string similarity features with a deep neural\narchitecture that leverages ideas previously advanced in the context of\nlearning efficient text representations, document classification, and natural\nlanguage inference. Specifically, we use bi-directional Recurrent Neural\nNetworks, together with max-pooling over the temporal/sequential dimension and\nneural attention, for representing (i) the headline, (ii) the first two\nsentences of the news article, and (iii) the entire news article. These\nrepresentations are then combined/compared, complemented with similarity\nfeatures inspired on other FNC-1 approaches, and passed to a final layer that\npredicts the stance of the article towards the headline. We also explore the\nuse of external sources of information, specifically large datasets of sentence\npairs originally proposed for training and evaluating natural language\ninference methods, in order to pre-train specific components of the neural\nnetwork architecture (e.g., the RNNs used for encoding sentences). The obtained\nresults attest to the effectiveness of the proposed ideas and show that our\nmodel, particularly when considering pre-training and the combination of neural\nrepresentations together with similarity features, slightly outperforms the\nprevious state-of-the-art.", "doi": "", "date": "2018-11-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.00706v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 84152089, "title": "Detecting fake news for the new coronavirus by reasoning on the Covid-19\n  ontology", "abstract": "In the context of the Covid-19 pandemic, many were quick to spread deceptive\ninformation. I investigate here how reasoning in Description Logics (DLs) can\ndetect inconsistencies between trusted medical sources and not trusted ones.\nThe not-trusted information comes in natural language (e.g. \"Covid-19 affects\nonly the elderly\"). To automatically convert into DLs, I used the FRED\nconverter. Reasoning in Description Logics is then performed with the Racer\ntool.", "doi": "", "date": "2020-04-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.12330v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1455270257, "title": "The Great Division", "abstract": "When information flow fails, when Democrats and Republicans do not talk to\neach other, when Israelis and Palestinians do not talk to each other, and when\nNorth Koreans and South Koreans do not talk to each other, mis-perceptions,\nbiases and fake news arise. In this paper we present an in-depth study of\npolitical polarization and social division using Twitter data and Monte Carlo\nsimulations. First, we study at the aggregate level people's inclination to\nretweet within their own ideological circle. Introducing the concept of cocoon\nratio, we show that Donald Trump's followers are 2.56 more likely to retweet a\nfellow Trump follower than to retweet a Hillary Clinton follower. Second, going\ndown to the individual level, we show that the tendency of retweeting\nexclusively within one's ideological circle is stronger for women than for men\nand that such tendency weakens as one's social capital grows. Third, we use a\none-dimensional Ising model to simulate how a society with high cocoon ratios\ncould end up becoming completely divided. We conclude with a discussion of our\nfindings with respect to fake news.", "doi": "", "date": "2018-02-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1802.00156v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 752619022, "title": "Uncritical polarized groups: The impact of spreading fake news as fact\n  in social networks", "abstract": "The spread of ideas in online social networks is a crucial phenomenon to\nunderstand nowadays the proliferation of fake news and their impact in\ndemocracies. This makes necessary to use models that mimic the circulation of\nrumors. The law of large numbers as well as the probability distribution of\ncontact groups allow us to construct a model with a minimum number of\nhypotheses. Moreover, we can analyze with this model the presence of very\npolarized groups of individuals (humans or bots) who spread a rumor as soon as\nthey know about it. Given only the initial number of individuals who know any\nnews, in a population connected by an instant messaging application, we first\ndeduce from our model a simple function of time to study the rumor propagation.\nWe then prove that the polarized groups can be detected and quantified from\nempirical data. Finally, we also predict the time required by any rumor to\nreach a fixed percentage of the population.", "doi": "", "date": "2019-10-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.08010v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 97762651, "title": "Detecting Fake News with Weak Social Supervision", "abstract": "Limited labeled data is becoming the largest bottleneck for supervised\nlearning systems. This is especially the case for many real-world tasks where\nlarge scale annotated examples are either too expensive to acquire or\nunavailable due to privacy or data access constraints. Weak supervision has\nshown to be a good means to mitigate the scarcity of annotated data by\nleveraging weak labels or injecting constraints from heuristic rules and/or\nexternal knowledge sources. Social media has little labeled data but possesses\nunique characteristics that make it suitable for generating weak supervision,\nresulting in a new type of weak supervision, i.e., weak social supervision. In\nthis article, we illustrate how various aspects of social media can be used to\ngenerate weak social supervision. Specifically, we use the recent research on\nfake news detection as the use case, where social engagements are abundant but\nannotated examples are scarce, to show that weak social supervision is\neffective when facing the little labeled data problem. This article opens the\ndoor for learning with weak social supervision for other emerging tasks.", "doi": "", "date": "2019-10-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.11430v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1862227625, "title": "Defending Elections Against Malicious Spread of Misinformation", "abstract": "The integrity of democratic elections depends on voters' access to accurate\ninformation. However, modern media environments, which are dominated by social\nmedia, provide malicious actors with unprecedented ability to manipulate\nelections via misinformation, such as fake news. We study a zero-sum game\nbetween an attacker, who attempts to subvert an election by propagating a fake\nnew story or other misinformation over a set of advertising channels, and a\ndefender who attempts to limit the attacker's impact. Computing an equilibrium\nin this game is challenging as even the pure strategy sets of players are\nexponential. Nevertheless, we give provable polynomial-time approximation\nalgorithms for computing the defender's minimax optimal strategy across a range\nof settings, encompassing different population structures as well as models of\nthe information available to each player. Experimental results confirm that our\nalgorithms provide near-optimal defender strategies and showcase variations in\nthe difficulty of defending elections depending on the resources and knowledge\navailable to the defender.", "doi": "", "date": "2018-09-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.05521v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 652189244, "title": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning", "abstract": "Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.", "doi": "", "date": "2018-09-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.06416v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1033495016, "title": "Subleading BMS charges and fake news near null infinity", "abstract": "In this paper we establish a relation between the non-linearly conserved\nNewman-Penrose charges and certain subleading terms in a large-$r$ expansion of\nthe BMS charges in an asymptotically-flat spacetime. We define the subleading\nBMS charges by considering a $1/r$-expansion of the Barnich-Brandt prescription\nfor defining asymptotic charges in an asymptotically-flat spacetime. At the\nleading order, i.e. $1/r^0$, one obtains the standard BMS charges, which would\nbe integrable and conserved in the absence of a flux term at null infinity,\ncorresponding to gravitational radiation, or Bondi news. At subleading orders,\nanalogous terms in general provide obstructions to the integrability of the\ncorresponding charges. Since the subleading terms are defined close to null\ninfinity, but vanish actually at infinity, the analogous obstructions are not\nassociated with genuine Bondi news. One may instead describe them as\ncorresponding to \"fake news.\" At order $r^{-3}$, we find that a set of\nintegrable charges can be defined and that these are related to the ten\nnon-linearly conserved Newman-Penrose charges.", "doi": "10.1007/jhep01(2019)143", "date": "2018-09-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.09076v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 790730661, "title": "Fact-Checking Meets Fauxtography: Verifying Claims About Images", "abstract": "The recent explosion of false claims in social media and on the Web in\ngeneral has given rise to a lot of manual fact-checking initiatives.\nUnfortunately, the number of claims that need to be fact-checked is several\norders of magnitude larger than what humans can handle manually. Thus, there\nhas been a lot of research aiming at automating the process. Interestingly,\nprevious work has largely ignored the growing number of claims about images.\nThis is despite the fact that visual imagery is more influential than text and\nnaturally appears alongside fake news. Here we aim at bridging this gap. In\nparticular, we create a new dataset for this problem, and we explore a variety\nof features modeling the claim, the image, and the relationship between the\nclaim and the image. The evaluation results show sizable improvements over the\nbaseline. We release our dataset, hoping to enable further research on\nfact-checking claims about images.", "doi": "", "date": "2019-08-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.11722v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3720697472, "title": "GCAN: Graph-aware Co-Attention Networks for Explainable Fake News\n  Detection on Social Media", "abstract": "This paper solves the fake news detection problem under a more realistic\nscenario on social media. Given the source short-text tweet and the\ncorresponding sequence of retweet users without text comments, we aim at\npredicting whether the source tweet is fake or not, and generating explanation\nby highlighting the evidences on suspicious retweeters and the words they\nconcern. We develop a novel neural network-based model, Graph-aware\nCo-Attention Networks (GCAN), to achieve the goal. Extensive experiments\nconducted on real tweet datasets exhibit that GCAN can significantly outperform\nstate-of-the-art methods by 16% in accuracy on average. In addition, the case\nstudies also show that GCAN can produce reasonable explanations.", "doi": "", "date": "2020-04-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.11648v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1187277667, "title": "Disinformation and Misinformation on Twitter during the Novel\n  Coronavirus Outbreak", "abstract": "As the novel coronavirus spread globally, a growing public panic was\nexpressed over the internet. We examine the public discussion concerning\nCOVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million\nusers collected between January 29, 2020 and March 4, 2020. We categorize users\nbased on their home countries, social identities, and political orientation. We\nfind that news media, government officials, and individual news reporters\nposted a majority of influential tweets, while the most influential ones are\nstill written by regular users. Tweets mentioning \"fake news\" URLs and\ndisinformation story-lines are also more likely to be spread by regular users.\nUnlike real news and normal tweets, tweets containing URLs pointing to \"fake\nnews\" sites are most likely to be retweeted within the source country and so\nare less likely to spread internationally.", "doi": "", "date": "2020-06-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.04278v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 220797164, "title": "FakeCovid -- A Multilingual Cross-domain Fact Check News Dataset for\n  COVID-19", "abstract": "In this paper, we present a first multilingual cross-domain dataset of 5182\nfact-checked news articles for COVID-19, collected from 04/01/2020 to\n15/05/2020. We have collected the fact-checked articles from 92 different\nfact-checking websites after obtaining references from Poynter and Snopes. We\nhave manually annotated articles into 11 different categories of the\nfact-checked news according to their content. The dataset is in 40 languages\nfrom 105 countries. We have built a classifier to detect fake news and present\nresults for the automatic fake news detection and its class. Our model achieves\nan F1 score of 0.76 to detect the false class and other fact check articles.\nThe FakeCovid dataset is available at Github.", "doi": "10.36190/2020.14", "date": "2020-06-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.11343v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 208239091, "title": "How Fake News Affect Trust in the Output of a Machine Learning System\n  for News Curation", "abstract": "People are increasingly consuming news curated by machine learning (ML)\nsystems. Motivated by studies on algorithmic bias, this paper explores which\nrecommendations of an algorithmic news curation system users trust and how this\ntrust is affected by untrustworthy news stories like fake news. In a study with\n82 vocational school students with a background in IT, we found that users are\nable to provide trust ratings that distinguish trustworthy recommendations of\nquality news stories from untrustworthy recommendations. However, a single\nuntrustworthy news story combined with four trustworthy news stories is rated\nsimilarly as five trustworthy news stories. The results could be a first\nindication that untrustworthy news stories benefit from appearing in a\ntrustworthy context. The results also show the limitations of users' abilities\nto rate the recommendations of a news curation system. We discuss the\nimplications of this for the user experience of interactive machine learning\nsystems.", "doi": "", "date": "2020-08-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.01988v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 80340762, "title": "COVID-19: The Information Warfare Paradigm Shift", "abstract": "In Kuhn's The Structure of Scientific Revolutions, the critical term is\nparadigm-shift when it suddenly becomes evident that earlier assumptions no\nlonger are correct and the plurality of the scientific community that studies\nthis domain accepts the change. These types of events can be scientific\nfindings or as in social science system shock that creates a punctured\nequilibrium that sets the stage in the developments. In information warfare,\nrecent years studies and government lines of efforts have been to engage fake\nnews, electoral interference, and fight extremist social media as the primary\ncombat theater in the information space, and the tools to influence a targeted\naudience. The COVID-19 pandemic generates a rebuttal of these assumptions. Even\nif fake news and extremist social media content may exploit fault lines in our\nsociety and create a civil disturbance, tensions between federal and local\ngovernment, and massive protests, it is still effects that impact a part of the\npopulation. What we have seen with COVID-19, as an indicator, is that what is\nrelated to public health is far more powerful to swing public sentiment and\ncreate reactions within the citizenry that are trigger impact at a larger\nmagnitude that has rippled through society in multiple directions.", "doi": "", "date": "2020-09-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.01267v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 704972730, "title": "CHECKED: Chinese COVID-19 Fake News Dataset", "abstract": "COVID-19 has impacted all lives. To maintain social distancing and avoiding\nexposure, works and lives have gradually moved online. Under this trend, social\nmedia usage to obtain COVID-19 news has increased. Also, misinformation on\nCOVID-19 is frequently spread on social media. In this work, we develop\nCHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides\na total 2,104 verified microblogs related to COVID-19 from December 2019 to\nAugust 2020, identified by using a specific list of keywords. Correspondingly,\nCHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes\nthat reveal how these verified microblogs are spread and reacted on Weibo. The\ndataset contains a rich set of multimedia information for each microblog\nincluding ground-truth label, textual, visual, temporal, and network\ninformation. Extensive experiments have been conducted to analyze CHECKED data\nand to provide benchmark results for well-established methods when predicting\nfake news using CHECKED. We hope that CHECKED can facilitate studies that\ntarget misinformation on coronavirus. The dataset is available at\nhttps://github.com/cyang03/CHECKED.", "doi": "", "date": "2020-10-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.09029v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3029411988, "title": "Topic-Preserving Synthetic News Generation: An Adversarial Deep\n  Reinforcement Learning Approach", "abstract": "Nowadays, there exist powerful language models such as OpenAI's GPT-2 that\ncan generate readable text and can be fine-tuned to generate text for a\nspecific domain. Considering GPT-2, it cannot directly generate synthetic news\nwith respect to a given topic and the output of the language model cannot be\nexplicitly controlled. In this paper, we study the novel problem of\ntopic-preserving synthetic news generation. We propose a novel deep\nreinforcement learning-based method to control the output of GPT-2 with respect\nto a given news topic. When generating text using GPT-2, by default, the most\nprobable word is selected from the vocabulary. Instead of selecting the best\nword each time from GPT-2's output, an RL agent tries to select words that\noptimize the matching of a given topic. In addition, using a fake news detector\nas an adversary, we investigate generating realistic news using our proposed\nmethod. In this paper, we consider realistic news as news that cannot be easily\ndetected by a fake news classifier. Experimental results demonstrate the\neffectiveness of the proposed framework on generating topic-preserving news\ncontent than state-of-the-art baselines.", "doi": "", "date": "2020-10-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.16324v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2528965452, "title": "Competitive Influence Propagation and Fake News Mitigation in the\n  Presence of Strong User Bias", "abstract": "Due to the extensive role of social networks in social media, it is easy for\npeople to share the news, and it spreads faster than ever before. These\nplatforms also have been exploited to share the rumor or fake information,\nwhich is a threat to society. One method to reduce the impact of fake\ninformation is making people aware of the correct information based on hard\nproof. In this work, first, we propose a propagation model called Competitive\nIndependent Cascade Model with users' Bias (CICMB) that considers the presence\nof strong user bias towards different opinions, believes, or political parties.\nWe further propose a method, called $k-TruthScore$, to identify an optimal set\nof truth campaigners from a given set of prospective truth campaigners to\nminimize the influence of rumor spreaders on the network. We compare\n$k-TruthScore$ with state of the art methods, and we measure their performances\nas the percentage of the saved nodes (nodes that would have believed in the\nfake news in the absence of the truth campaigners). We present these results on\na few real-world networks, and the results show that $k-TruthScore$ method\noutperforms baseline methods.", "doi": "", "date": "2020-11-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.04857v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3415828838, "title": "Analysing Social Media Network Data with R: Semi-Automated Screening of\n  Users, Comments and Communication Patterns", "abstract": "Communication on social media platforms is not only culturally and\npolitically relevant, it is also increasingly widespread across societies.\nUsers not only communicate via social media platforms, but also search\nspecifically for information, disseminate it or post information themselves.\nHowever, fake news, hate speech and even radicalizing elements are part of this\nmodern form of communication: Sometimes with far-reaching effects on\nindividuals and societies. A basic understanding of these mechanisms and\ncommunication patterns could help to counteract negative forms of\ncommunication, e.g. bullying among children or extreme political points of\nview. To this end, a method will be presented in order to break down the\nunderlying communication patterns, to trace individual users and to inspect\ntheir comments and range on social media platforms; Or to contrast them later\non via qualitative research. This approeach can identify particularly active\nusers with an accuracy of 100 percent, if the framing social networks as well\nas the topics are taken into account. However, methodological as well as\ncounteracting approaches must be even more dynamic and flexible to ensure\nsensitivity and specifity regarding users who spread hate speech, fake news and\nradicalizing elements.", "doi": "", "date": "2020-11-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.13327v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1437532925, "title": "Combating Hostility: Covid-19 Fake News and Hostile Post Detection in\n  Social Media", "abstract": "This paper illustrates a detail description of the system and its results\nthat developed as a part of the participation at CONSTRAINT shared task in\nAAAI-2021. The shared task comprises two tasks: a) COVID19 fake news detection\nin English b) Hostile post detection in Hindi. Task-A is a binary\nclassification problem with fake and real class, while task-B is a multi-label\nmulti-class classification task with five hostile classes (i.e. defame, fake,\nhate, offense, non-hostile). Various techniques are used to perform the\nclassification task, including SVM, CNN, BiLSTM, and CNN+BiLSTM with tf-idf and\nWord2Vec embedding techniques. Results indicate that SVM with tf-idf features\nachieved the highest 94.39% weighted $f_1$ score on the test set in task-A.\nLabel powerset SVM with n-gram features obtained the maximum coarse-grained and\nfine-grained $f_1$ score of 86.03% and 50.98% on the task-B test set\nrespectively.", "doi": "", "date": "2021-01-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.03291v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1850908296, "title": "Constraint 2021: Machine Learning Models for COVID-19 Fake News\n  Detection Shared Task", "abstract": "In this system paper we present our contribution to the Constraint 2021\nCOVID-19 Fake News Detection Shared Task, which poses the challenge of\nclassifying COVID-19 related social media posts as either fake or real. In our\nsystem, we address this challenge by applying classical machine learning\nalgorithms together with several linguistic features, such as n-grams,\nreadability, emotional tone and punctuation. In terms of pre-processing, we\nexperiment with various steps like stop word removal, stemming/lemmatization,\nlink removal and more. We find our best performing system to be based on a\nlinear SVM, which obtains a weighted average F1 score of 95.19% on test data,\nwhich lands a place in the middle of the leaderboard (place 80 of 167).", "doi": "", "date": "2021-01-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.03717v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3261699375, "title": "Rating Facts under Coarse-to-fine Regimes", "abstract": "The rise of manipulating fake news as a political weapon has become a global\nconcern and highlighted the incapability of manually fact checking against\nrapidly produced fake news. Thus, statistical approaches are required if we are\nto address this problem efficiently. The shortage of publicly available\ndatasets is one major bottleneck of automated fact checking. To remedy this, we\ncollected 24K manually rated statements from PolitiFact. The class values\nexhibit a natural order with respect to truthfulness as shown in Table 1. Thus,\nour task represents a twist from standard classification, due to the various\ndegrees of similarity between classes. To investigate this, we defined\ncoarse-to-fine classification regimes, which presents new challenge for\nclassification. To address this, we propose BERT-based models. After training,\nclass similarity is sensible over the multi-class datasets, especially in the\nfine-grained one. Under all the regimes, BERT achieves state of the art, while\nthe additional layers provide insignificant improvement.", "doi": "", "date": "2021-07-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.06051v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4072799440, "title": "Deep Ensemble Learning for News Stance Detection", "abstract": "Stance detection in fake news is an important component in news veracity\nassessment because this process helps fact-checking by understanding stance to\na central claim from different information sources. The Fake News Challenge\nStage 1 (FNC-1) held in 2017 was setup for this purpose, which involves\nestimating the stance of a news article body relative to a given headline. This\nthesis starts from the error analysis for the three top-performing systems in\nFNC-1. Based on the analysis, a simple but tough-to-beat Multilayer Perceptron\nsystem is chosen as the baseline. Afterwards, three approaches are explored to\nimprove baseline.The first approach explores the possibility of improving the\nprediction accuracy by adding extra keywords features when training a model,\nwhere keywords are converted to an indicator vector and then concatenated to\nthe baseline features. A list of keywords is manually selected based on the\nerror analysis, which may best reflect some characteristics of fake news titles\nand bodies. To make this selection process automatically, three algorithms are\ncreated based on Mutual Information (MI) theory: keywords generator based on MI\nstance class, MI customised class, and Pointwise MI algorithm. The second\napproach is based on word embedding, where word2vec model is introduced and two\ndocument similarities calculation algorithms are implemented: wor2vec cosine\nsimilarity and WMD distance. The third approach is ensemble learning. Different\nmodels are configured together with two continuous outputs combining\nalgorithms. The 10-fold cross validation reveals that the ensemble of three\nneural network models trained from simple bag-of-words features gives the best\nperformance. It is therefore selected to compete in FNC-1. After\nhyperparameters fine tuning, the selected deep ensemble model beats the FNC-1\nwinner team by a remarkable 34.25 marks under FNC-1's evaluation metric.", "doi": "", "date": "2019-09-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.12233v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2288049345, "title": "Online Political Discourse in the Trump Era", "abstract": "We identify general trends in the (in)civility and complexity of political\ndiscussions occurring on Reddit between January 2007 and May 2017 -- a period\nspanning both terms of Barack Obama's presidency and the first 100 days of\nDonald Trump's presidency. We then investigate four factors that are frequently\nhypothesized as having contributed to the declining quality of American\npolitical discourse -- (1) the rising popularity of Donald Trump, (2)\nincreasing polarization and negative partisanship, (3) the democratization of\nnews media and the rise of fake news, and (4) merging of fringe groups into\nmainstream political discussions.", "doi": "", "date": "2017-11-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.05303v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3146530726, "title": "Simple Open Stance Classification for Rumour Analysis", "abstract": "Stance classification determines the attitude, or stance, in a (typically\nshort) text. The task has powerful applications, such as the detection of fake\nnews or the automatic extraction of attitudes toward entities or events in the\nmedia. This paper describes a surprisingly simple and efficient classification\napproach to open stance classification in Twitter, for rumour and veracity\nclassification. The approach profits from a novel set of automatically\nidentifiable problem-specific features, which significantly boost classifier\naccuracy and achieve above state-of-the-art results on recent benchmark\ndatasets. This calls into question the value of using complex sophisticated\nmodels for stance classification without first doing informed feature\nextraction.", "doi": "", "date": "2017-08-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1708.05286v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 572112858, "title": "360\u00b0 Stance Detection", "abstract": "The proliferation of fake news and filter bubbles makes it increasingly\ndifficult to form an unbiased, balanced opinion towards a topic. To ameliorate\nthis, we propose 360{\\deg} Stance Detection, a tool that aggregates news with\nmultiple perspectives on a topic. It presents them on a spectrum ranging from\nsupport to opposition, enabling the user to base their opinion on multiple\npieces of diverse evidence.", "doi": "", "date": "2018-04-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.00982v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1792751680, "title": "Automatic Stance Detection Using End-to-End Memory Networks", "abstract": "We present a novel end-to-end memory network for stance detection, which\njointly (i) predicts whether a document agrees, disagrees, discusses or is\nunrelated with respect to a given target claim, and also (ii) extracts snippets\nof evidence for that prediction. The network operates at the paragraph level\nand integrates convolutional and recurrent neural networks, as well as a\nsimilarity matrix as part of the overall architecture. The experimental\nevaluation on the Fake News Challenge dataset shows state-of-the-art\nperformance.", "doi": "", "date": "2018-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.07581v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1199221749, "title": "Stance Prediction for Russian: Data and Analysis", "abstract": "Stance detection is a critical component of rumour and fake news\nidentification. It involves the extraction of the stance a particular author\ntakes related to a given claim, both expressed in text. This paper investigates\nstance classification for Russian. It introduces a new dataset, RuStance, of\nRussian tweets and news comments from multiple sources, covering multiple\nstories, as well as text classification approaches to stance detection as\nbenchmarks over this data in this language. As well as presenting this\nopenly-available dataset, the first of its kind for Russian, the paper presents\na baseline for stance prediction in the language.", "doi": "10.13140/rg.2.2.15252.76161/1", "date": "2018-09-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.01574v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2287469081, "title": "Trust and Trustworthiness in Social Recommender Systems", "abstract": "The prevalence of misinformation on online social media has tangible\nempirical connections to increasing political polarization and partisan\nantipathy in the United States. Ranking algorithms for social recommendation\noften encode broad assumptions about network structure (like homophily) and\ngroup cognition (like, social action is largely imitative). Assumptions like\nthese can be na\\\"ive and exclusionary in the era of fake news and ideological\nuniformity towards the political poles. We examine these assumptions with aid\nfrom the user-centric framework of trustworthiness in social recommendation.\nThe constituent dimensions of trustworthiness (diversity, transparency,\nexplainability, disruption) highlight new opportunities for discouraging\ndogmatization and building decision-aware, transparent news recommender\nsystems.", "doi": "", "date": "2019-03-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.01780v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 422656898, "title": "An Emotional Analysis of False Information in Social Media and News\n  Articles", "abstract": "Fake news is risky since it has been created to manipulate the readers'\nopinions and beliefs. In this work, we compared the language of false news to\nthe real one of real news from an emotional perspective, considering a set of\nfalse information types (propaganda, hoax, clickbait, and satire) from social\nmedia and online news articles sources. Our experiments showed that false\ninformation has different emotional patterns in each of its types, and emotions\nplay a key role in deceiving the reader. Based on that, we proposed a LSTM\nneural network model that is emotionally-infused to detect false news.", "doi": "", "date": "2019-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.09951v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4277480656, "title": "Text Similarity Using Word Embeddings to Classify Misinformation", "abstract": "Fake news is a growing problem in the last years, especially during\nelections. It's hard work to identify what is true and what is false among all\nthe user generated content that circulates every day. Technology can help with\nthat work and optimize the fact-checking process. In this work, we address the\nchallenge of finding similar content in order to be able to suggest to a\nfact-checker articles that could have been verified before and thus avoid that\nthe same information is verified more than once. This is especially important\nin collaborative approaches to fact-checking where members of large teams will\nnot know what content others have already fact-checked.", "doi": "", "date": "2020-03-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.06634v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 109797050, "title": "You are right. I am ALARMED -- But by Climate Change Counter Movement", "abstract": "The world is facing the challenge of climate crisis. Despite the consensus in\nscientific community about anthropogenic global warming, the web is flooded\nwith articles spreading climate misinformation. These articles are carefully\nconstructed by climate change counter movement (cccm) organizations to\ninfluence the narrative around climate change. We revisit the literature on\nclimate misinformation in social sciences and repackage it to introduce in the\ncommunity of NLP. Despite considerable work in detection of fake news, there is\nno misinformation dataset available that is specific to the domain.of climate\nchange. We try to bridge this gap by scraping and releasing articles with known\nclimate change misinformation.", "doi": "", "date": "2020-04-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.14907v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3748966901, "title": "Getting Insights from a Large Corpus of Scientific Papers on\n  Specialisted Comprehensive Topics -- the Case of COVID-19", "abstract": "COVID-19 is one of the most important topic these days, specifically on\nsearch engines and news. While fake news are easily shared, scientific papers\nare reliable sources where information can be extracted. With about 24,000\nscientific publications on COVID-19 and related research on PUBMED, automatic\ncomputer-assisted analysis is required. In this paper, we develop two\nmethodologies to get insights on specific sub-topics of interest and latest\nresearch sub-topics. They rely on natural language processing and graph-based\nvisualizations. We run these methodologies on two cases: the virus origin and\nthe uses of existing drugs.", "doi": "", "date": "2020-04-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.00485v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3461052416, "title": "Hostility Detection Dataset in Hindi", "abstract": "In this paper, we present a novel hostility detection dataset in Hindi\nlanguage. We collect and manually annotate ~8200 online posts. The annotated\ndataset covers four hostility dimensions: fake news, hate speech, offensive,\nand defamation posts, along with a non-hostile label. The hostile posts are\nalso considered for multi-label tags due to a significant overlap among the\nhostile classes. We release this dataset as part of the CONSTRAINT-2021 shared\ntask on hostile post detection.", "doi": "", "date": "2020-11-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.03588v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 251705370, "title": "FinnSentiment -- A Finnish Social Media Corpus for Sentiment Polarity\n  Annotation", "abstract": "Sentiment analysis and opinion mining is an important task with obvious\napplication areas in social media, e.g. when indicating hate speech and fake\nnews. In our survey of previous work, we note that there is no large-scale\nsocial media data set with sentiment polarity annotations for Finnish. This\npublications aims to remedy this shortcoming by introducing a 27,000 sentence\ndata set annotated independently with sentiment polarity by three native\nannotators. We had the same three annotators for the whole data set, which\nprovides a unique opportunity for further studies of annotator behaviour over\ntime. We analyse their inter-annotator agreement and provide two baselines to\nvalidate the usefulness of the data set.", "doi": "", "date": "2020-12-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.02613v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3854541789, "title": "Self-Supervised Claim Identification for Automated Fact Checking", "abstract": "We propose a novel, attention-based self-supervised approach to identify\n\"claim-worthy\" sentences in a fake news article, an important first step in\nautomated fact-checking. We leverage \"aboutness\" of headline and content using\nattention mechanism for this task. The identified claims can be used for\ndownstream task of claim verification for which we are releasing a benchmark\ndataset of manually selected compelling articles with veracity labels and\nassociated evidence. This work goes beyond stylistic analysis to identifying\ncontent that influences reader belief. Experiments with three datasets show the\nstrength of our model. Data and code available at\nhttps://github.com/architapathak/Self-Supervised-ClaimIdentification", "doi": "", "date": "2021-02-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.02335v1", "pdf": ""}, "publisher-venue": "ICON 2020", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3094827259, "title": "On Unifying Misinformation Detection", "abstract": "In this paper, we introduce UnifiedM2, a general-purpose misinformation model\nthat jointly models multiple domains of misinformation with a single, unified\nsetup. The model is trained to handle four tasks: detecting news bias,\nclickbait, fake news, and verifying rumors. By grouping these tasks together,\nUnifiedM2learns a richer representation of misinformation, which leads to\nstate-of-the-art or comparable performance across all tasks. Furthermore, we\ndemonstrate that UnifiedM2's learned representation is helpful for few-shot\nlearning of unseen misinformation tasks/datasets and model's generalizability\nto unseen events.", "doi": "", "date": "2021-04-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.05243v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 595606034, "title": "The Fake News Spreading Plague: Was it Preventable?", "abstract": "In 2010, a paper entitled \"From Obscurity to Prominence in Minutes: Political\nSpeech and Real-time search\" won the Best Paper Prize of the Web Science 2010\nConference. Among its findings were the discovery and documentation of what was\ntermed a \"Twitter-bomb\", an organized effort to spread misinformation about the\ndemocratic candidate Martha Coakley through anonymous Twitter accounts. In this\npaper, after summarizing the details of that event, we outline the recipe of\nhow social networks are used to spread misinformation. One of the most\nimportant steps in such a recipe is the \"infiltration\" of a community of users\nwho are already engaged in conversations about a topic, to use them as organic\nspreaders of misinformation in their extended subnetworks. Then, we take this\nmisinformation spreading recipe and indicate how it was successfully used to\nspread fake news during the 2016 U.S. Presidential Election. The main\ndifferences between the scenarios are the use of Facebook instead of Twitter,\nand the respective motivations (in 2010: political influence; in 2016:\nfinancial benefit through online advertising). After situating these events in\nthe broader context of exploiting the Web, we seize this opportunity to address\nlimitations of the reach of research findings and to start a conversation about\nhow communities of researchers can increase their impact on real-world societal\nissues.", "doi": "", "date": "2017-03-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1703.06988v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4021668078, "title": "Fake news and rumors: a trigger for proliferation or fading away", "abstract": "The dynamics of fake news and rumor spreading is investigated using a model\nwith three kinds of agents who are respectively the Seeds, the Agnostics and\nthe Others. While Seeds are the ones who start spreading the rumor being\nadamantly convinced of its truth, Agnostics reject any kind of rumor and do not\nbelieve in conspiracy theories. In between, the Others constitute the main part\nof the community. While Seeds are always Believers and Agnostics are always\nIndifferents, Others can switch between being Believer and Indifferent\ndepending on who they are discussing with. The underlying driving dynamics is\nimplemented via local updates of randomly formed groups of agents. In each\ngroup, an Other turns into a Believer as soon as $m$ or more Believers are\npresent in the group. However, since some Believers may lose interest in the\nrumor as time passes by, we add a flipping fixed rate $0<d<1$ from Believers\ninto Indifferents. Rigorous analysis of the associated dynamics reveals that\nswitching from $m=1$ to $m\\ge2$ triggers a drastic qualitative change in the\nspreading process. When $m=1$ even a small group of Believers may manage to\nconvince a large part of the community very quickly. In contrast, for $m\\ge 2$,\neven a substantial fraction of Believers does not prevent the rumor dying out\nafter a few update rounds. Our results provide an explanation on why a given\nrumor spreads within a social group and not in another, and also why some\nrumors will not spread in neither groups.", "doi": "10.1063/5.0006984", "date": "2019-05-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.06894v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4140030382, "title": "Under the Conditions of Non-Agenda Ownership: Social Media Users in the\n  2019 Ukrainian Presidential Elections Campaign", "abstract": "Owing to its history and challenging circumstances, social networks community\nin Ukraine is a very interesting polygon for the study of communications in the\nconstantly changing environment, especially in the political discourse. This\nunique environment requires three dimensions to ascertain the political\nposition of its participant. But 2019 presidential elections made this object\neven more spectacular. The winner of elections comedian Volodymyr Zelenskyi\nreached 73% of votes without any issue ownership, with empty agenda, and this\ninfluenced the electoral content of social networks and their authors behavior.\nWe saw, that the issue ownership by other candidates succeeds in making their\nissues more salient in social networks. But the new phenomena, the non-agenda\nownership, overcome any ideological influence, especially under the conditions\nof punishment mechanism applied to old politicians. Analyzing social media\ncontent and users behavior in the period between two rounds of elections, we\nfound considerable overlaps between this campaign and the 2016 Trump campaign.\nWe approved the widespread of filter bubbles, negative campaign messages, fake\nnews and conspiracy theories. Active and powerful core of Ukrainian Facebook\nthat was responsible for the Revolution of dignity now became less significant\nand even turns into the huge filter bubble of active people. We also proved\nthat manipulations and fake news in the environment of private groups may be as\nmuch powerful as in a case of classical communication based around the opinion\nleaders.", "doi": "", "date": "2019-09-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.01681v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1856992348, "title": "The Limited Reach of Fake News on Twitter during 2019 European Elections", "abstract": "The advent of social media changed the way we consume content favoring a\ndisintermediated access and production. This scenario has been matter of\ncritical discussion about its impact on society. Magnified in the case of Arab\nSpring or heavily criticized in the Brexit and 2016 U.S. elections. In this\nwork we explore information consumption on Twitter during the last European\nelectoral campaign by analyzing the interaction patterns of official news\nsources, fake news sources, politicians, people from the showbiz and many\nothers. We extensively explore interactions among different classes of accounts\nin the months preceding the last European elections, held between 23rd and 26th\nof May, 2019. We collected almost 400,000 tweets posted by 863 accounts having\ndifferent roles in the public society. Through a thorough quantitative analysis\nwe investigate the information flow among them, also exploiting geolocalized\ninformation. Accounts show the tendency to confine their interaction within the\nsame class and the debate rarely crosses national borders. Moreover, we do not\nfind any evidence of an organized network of accounts aimed at spreading\ndisinformation. Instead, disinformation outlets are largely ignored by the\nother actors and hence play a peripheral role in online political discussions.", "doi": "10.1371/journal.pone.0234689", "date": "2019-11-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.12039v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2151645906, "title": "To Transfer or Not to Transfer: Misclassification Attacks Against\n  Transfer Learned Text Classifiers", "abstract": "Transfer learning --- transferring learned knowledge --- has brought a\nparadigm shift in the way models are trained. The lucrative benefits of\nimproved accuracy and reduced training time have shown promise in training\nmodels with constrained computational resources and fewer training samples.\nSpecifically, publicly available text-based models such as GloVe and BERT that\nare trained on large corpus of datasets have seen ubiquitous adoption in\npractice. In this paper, we ask, \"can transfer learning in text prediction\nmodels be exploited to perform misclassification attacks?\" As our main\ncontribution, we present novel attack techniques that utilize unintended\nfeatures learnt in the teacher (public) model to generate adversarial examples\nfor student (downstream) models. To the best of our knowledge, ours is the\nfirst work to show that transfer learning from state-of-the-art word-based and\nsentence-based teacher models increase the susceptibility of student models to\nmisclassification attacks. First, we propose a novel word-score based attack\nalgorithm for generating adversarial examples against student models trained\nusing context-free word-level embedding model. On binary classification tasks\ntrained using the GloVe teacher model, we achieve an average attack accuracy of\n97% for the IMDB Movie Reviews and 80% for the Fake News Detection. For\nmulti-class tasks, we divide the Newsgroup dataset into 6 and 20 classes and\nachieve an average attack accuracy of 75% and 41% respectively. Next, we\npresent length-based and sentence-based misclassification attacks for the Fake\nNews Detection task trained using a context-aware BERT model and achieve 78%\nand 39% attack accuracy respectively. Thus, our results motivate the need for\ndesigning training techniques that are robust to unintended feature learning,\nspecifically for transfer learned models.", "doi": "", "date": "2020-01-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.02438v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4182943922, "title": "Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News", "abstract": "Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 \"infodemic\", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n\"fake news\" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.05854v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 166740091, "title": "That is a Known Lie: Detecting Previously Fact-Checked Claims", "abstract": "The recent proliferation of \"fake news\" has triggered a number of responses,\nmost notably the emergence of several manual fact-checking initiatives. As a\nresult and over time, a large number of fact-checked claims have been\naccumulated, which increases the likelihood that a new claim in social media or\na new statement by a politician might have already been fact-checked by some\ntrusted fact-checking organization, as viral claims often come back after a\nwhile in social media, and politicians like to repeat their favorite\nstatements, true or false, over and over again. As manual fact-checking is very\ntime-consuming (and fully automatic fact-checking has credibility issues), it\nis important to try to save this effort and to avoid wasting time on claims\nthat have already been fact-checked. Interestingly, despite the importance of\nthe task, it has been largely ignored by the research community so far. Here,\nwe aim to bridge this gap. In particular, we formulate the task and we discuss\nhow it relates to, but also differs from, previous work. We further create a\nspecialized dataset, which we release to the research community. Finally, we\npresent learning-to-rank experiments that demonstrate sizable improvements over\nstate-of-the-art retrieval and textual similarity approaches.", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.06058v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1077276239, "title": "Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms", "abstract": "With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.", "doi": "", "date": "2020-07-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.07996v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 493443995, "title": "Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News", "abstract": "Large-scale dissemination of disinformation online intended to mislead or\ndeceive the general population is a major societal problem. Rapid progression\nin image, video, and natural language generative models has only exacerbated\nthis situation and intensified our need for an effective defense mechanism.\nWhile existing approaches have been proposed to defend against neural fake\nnews, they are generally constrained to the very limited setting where articles\nonly have text and metadata such as the title and authors. In this paper, we\nintroduce the more realistic and challenging task of defending against\nmachine-generated news that also includes images and captions. To identify the\npossible weaknesses that adversaries can exploit, we create a NeuralNews\ndataset composed of 4 different types of generated articles as well as conduct\na series of human user study experiments based on this dataset. In addition to\nthe valuable insights gleaned from our user study experiments, we provide a\nrelatively effective approach based on detecting visual-semantic\ninconsistencies, which will serve as an effective first line of defense and a\nuseful reference for future work in defending against machine-generated\ndisinformation.", "doi": "", "date": "2020-09-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.07698v5", "pdf": ""}, "publisher-venue": "EMNLP 2020", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1931478296, "title": "How to Deal with Fake News: Visualizing Disinformation", "abstract": "The current public sense of anxiety in dealing with disinformation as\nmanifested by so-called fake news is acutely displayed by the reaction to\nrecent events prompted by a belief in conspiracies among certain groups. A\nmodel to deal with disinformation is proposed; it is based on a demonstration\nof the analogous behavior of disinformation to that of wave phenomena. Two\ncriteria form the basis to combat the deleterious effects of disinformation:\nthe use of a refractive medium based on skepticism as the default mode, and\npolarization as a filter mechanism to analyze its merits based on evidence.\nCritical thinking is enhanced since the first one tackles the pernicious effect\nof the confirmation bias, and the second the tendency towards attribution, both\nof which undermine our efforts to think and act rationally. The benefits of\nsuch a strategy include an epistemic reformulation of disinformation as an\nindependently existing phenomenon, that removes its negative connotations when\nperceived as being possessed by groups or individuals.", "doi": "", "date": "2021-01-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.09251v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 680588163, "title": "Launchers and Targets in Social Networks", "abstract": "Influence propagation in social networks is a subject of growing interest. A\nrelevant issue in those networks involves the identification of key\ninfluencers. These players have an important role on viral marketing strategies\nand message propagation, including political propaganda and fake news. In\neffect, an important way to fight malicious usage on social networks is to\nunderstand their properties, their structure and the way messages propagate.\n  This paper proposes two new indices for analysing message propagation in\nsocial networks, based on the network topological nature and the power of the\nmessage. The first index involves the strength of each node as a launcher of\nthe message, dividing the nodes into launchers and non-launchers. The second\nindex addresses the potential of each member as a receiver (target) of the\nmessage, dividing the nodes into targets and non-targets. Launcher individuals\nshould indicate strong influencers and target individuals should identify the\nbest target consumers. These indices can assist other known metrics when used\nto select efficient influencers in a social network. For instance, instead of\nchoosing a strong and probably expensive member according to its degree in the\nnetwork (number of followers), we may previously select those belonging to the\nlaunchers group and look for the lowest degree members, which are probably\ncheaper but still guarantying almost the same influence effectiveness as the\nlargest degree members.\n  On a different direction, using the second index, the strong target members\nshould characterize relevant consumers of information in the network, which may\ninclude fake news' regular collectors.\n  We discuss these indices using small-world randomly generated graphs and a\nnumber of real-world social networks available in known datasets repositories.", "doi": "", "date": "2021-01-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.11337v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2854428532, "title": "Detection of fake news on CoViD-19 on Web Search Engines", "abstract": "In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.", "doi": "", "date": "2021-03-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.11804v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2315472439, "title": "A Survey on Predicting the Factuality and the Bias of News Media", "abstract": "The present level of proliferation of fake, biased, and propagandistic\ncontent online has made it impossible to fact-check every single suspicious\nclaim or article, either manually or automatically. Thus, many researchers are\nshifting their attention to higher granularity, aiming to profile entire news\noutlets, which makes it possible to detect likely \"fake news\" the moment it is\npublished, by simply checking the reliability of its source. Source factuality\nis also an important element of systems for automatic fact-checking and \"fake\nnews\" detection, as they need to assess the reliability of the evidence they\nretrieve online. Political bias detection, which in the Western political\nlandscape is about predicting left-center-right bias, is an equally important\ntopic, which has experienced a similar shift towards profiling entire news\noutlets. Moreover, there is a clear connection between the two, as highly\nbiased media are less likely to be factual; yet, the two problems have been\naddressed separately. In this survey, we review the state of the art on media\nprofiling for factuality and bias, arguing for the need to model them jointly.\nWe further discuss interesting recent advances in using different information\nsources and modalities, which go beyond the text of the articles the target\nnews outlet has published. Finally, we discuss current challenges and outline\nfuture research directions.", "doi": "", "date": "2021-03-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.12506v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 235588216, "title": "A Survey on Multimodal Disinformation Detection", "abstract": "Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.", "doi": "", "date": "2021-03-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.12541v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 973089933, "title": "Combining exogenous and endogenous signals with a semi-supervised\n  co-attention network for early detection of COVID-19 fake tweets", "abstract": "Fake tweets are observed to be ever-increasing, demanding immediate\ncountermeasures to combat their spread. During COVID-19, tweets with\nmisinformation should be flagged and neutralized in their early stages to\nmitigate the damages. Most of the existing methods for early detection of fake\nnews assume to have enough propagation information for large labeled tweets --\nwhich may not be an ideal setting for cases like COVID-19 where both aspects\nare largely absent. In this work, we present ENDEMIC, a novel early detection\nmodel which leverages exogenous and endogenous signals related to tweets, while\nlearning on limited labeled data. We first develop a novel dataset, called CTF\nfor early COVID-19 Twitter fake news, with additional behavioral test sets to\nvalidate early detection. We build a heterogeneous graph with\nfollower-followee, user-tweet, and tweet-retweet connections and train a graph\nembedding model to aggregate propagation information. Graph embeddings and\ncontextual features constitute endogenous, while time-relative web-scraped\ninformation constitutes exogenous signals. ENDEMIC is trained in a\nsemi-supervised fashion, overcoming the challenge of limited labeled data. We\npropose a co-attention mechanism to fuse signal representations optimally.\nExperimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is\nhighly reliable in detecting early fake tweets, outperforming nine\nstate-of-the-art methods significantly.", "doi": "", "date": "2021-04-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.05321v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3445855661, "title": "Assessing disinformation through the dynamics of supply and demand in\n  the news ecosystem", "abstract": "Social dialogue, the foundation of our democracies, is currently threatened\nby disinformation and partisanship, with their disrupting role on individual\nand collective awareness and detrimental effects on decision-making processes.\nDespite a great deal of attention to the news sphere itself, little is known\nabout the subtle interplay between the offer and the demand for information.\nStill, a broader perspective on the news ecosystem, including both the\nproducers and the consumers of information, is needed to build new tools to\nassess the health of the infosphere. Here, we combine in the same framework\nnews supply, as mirrored by a fairly complete Italian news database - partially\nannotated for fake news, and news demand, as captured through the Google Trends\ndata for Italy. Our investigation focuses on the temporal and semantic\ninterplay of news, fake news, and searches in several domains, including the\nvirus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is\nextremely reactive to people's interests and tends to thrive, especially when\nthere is a mismatch between what people are interested in and what news outlets\nprovide. Second, a suitably defined index can assess the level of\ndisinformation only based on the available volumes of news and searches.\nAlthough our results mainly concern the Coronavirus subject, we provide hints\nthat the same findings can have more general applications. We contend these\nresults can be a powerful asset in informing campaigns against disinformation\nand providing news outlets and institutions with potentially relevant\nstrategies.", "doi": "", "date": "2021-05-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.15172v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3102838672, "title": "NewsCompare - a novel application for detecting news influence in a\n  country", "abstract": "The concept of `fake news' has been referenced and thrown around in news\nreports so much in recent years that it has become a news topic in its own\nright. At its core, it poses a chilling question -- what do we do if our\nworldview is fundamentally wrong? Even if internally consistent, what if it\ndoes not match the real world? Are our beliefs justified, or could we become\nindoctrinated from living in a `bubble'? If the latter is true, how could we\neven test the limits of said bubble from within its confines? We propose a new\nmethod to augment the process of identifying fake news, by speeding up and\nautomating the more cumbersome and time-consuming tasks involved. Our\napplication, NewsCompare takes any list of target websites as input\n(news-related in our use case, but otherwise not restricted), visits them in\nparallel and retrieves any text content found within. Web pages are\nsubsequently compared to each other, and similarities are tentatively pointed\nout. These results can be manually verified in order to determine which\nwebsites tend to draw inspiration from one another. The data gathered on every\nintermediate step can be queried and analyzed separately, and most notably we\nalready use the set of hyperlinks to and from the various websites we encounter\nto paint a sort of `map' of that particular slice of the web. This map can then\nbe cross-referenced and further strengthen the conclusion that a particular\ngrouping of sites with strong links to each other, and posting similar content,\nare likely to share the same allegiance. We run our application on the Romanian\nnews websites and we draw several interesting observations.", "doi": "", "date": "2019-04-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.00712v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4228354606, "title": "Taking a Stance on Fake News: Towards Automatic Disinformation\n  Assessment via Deep Bidirectional Transformer Language Models for Stance\n  Detection", "abstract": "The exponential rise of social media and digital news in the past decade has\nhad the unfortunate consequence of escalating what the United Nations has\ncalled a global topic of concern: the growing prevalence of disinformation.\nGiven the complexity and time-consuming nature of combating disinformation\nthrough human assessment, one is motivated to explore harnessing AI solutions\nto automatically assess news articles for the presence of disinformation. A\nvaluable first step towards automatic identification of disinformation is\nstance detection, where given a claim and a news article, the aim is to predict\nif the article agrees, disagrees, takes no position, or is unrelated to the\nclaim. Existing approaches in literature have largely relied on hand-engineered\nfeatures or shallow learned representations (e.g., word embeddings) to encode\nthe claim-article pairs, which can limit the level of representational\nexpressiveness needed to tackle the high complexity of disinformation\nidentification. In this work, we explore the notion of harnessing large-scale\ndeep bidirectional transformer language models for encoding claim-article pairs\nin an effort to construct state-of-the-art stance detection geared for\nidentifying disinformation. Taking advantage of bidirectional cross-attention\nbetween claim-article pairs via pair encoding with self-attention, we construct\na large-scale language model for stance detection by performing transfer\nlearning on a RoBERTa deep bidirectional transformer language model, and were\nable to achieve state-of-the-art performance (weighted accuracy of 90.01%) on\nthe Fake News Challenge Stage 1 (FNC-I) benchmark. These promising results\nserve as motivation for harnessing such large-scale language models as powerful\nbuilding blocks for creating effective AI solutions to combat disinformation.", "doi": "", "date": "2019-11-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.11951v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 695329590, "title": "No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet\n  Detection", "abstract": "The sudden widespread menace created by the present global pandemic COVID-19\nhas had an unprecedented effect on our lives. Man-kind is going through\nhumongous fear and dependence on social media like never before. Fear\ninevitably leads to panic, speculations, and the spread of misinformation. Many\ngovernments have taken measures to curb the spread of such misinformation for\npublic well being. Besides global measures, to have effective outreach, systems\nfor demographically local languages have an important role to play in this\neffort. Towards this, we propose an approach to detect fake news about COVID-19\nearly on from social media, such as tweets, for multiple Indic-Languages\nbesides English. In addition, we also create an annotated dataset of Hindi and\nBengali tweet for fake news detection. We propose a BERT based model augmented\nwith additional relevant features extracted from Twitter to identify fake\ntweets. To expand our approach to multiple Indic languages, we resort to mBERT\nbased model which is fine-tuned over created dataset in Hindi and Bengali. We\nalso propose a zero-shot learning approach to alleviate the data scarcity issue\nfor such low resource languages. Through rigorous experiments, we show that our\napproach reaches around 89% F-Score in fake tweet detection which supercedes\nthe state-of-the-art (SOTA) results. Moreover, we establish the first benchmark\nfor two Indic-Languages, Hindi and Bengali. Using our annotated data, our model\nachieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our\nzero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali\nTweets without any annotated data, which clearly indicates the efficacy of our\napproach.", "doi": "", "date": "2020-10-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.06906v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2272749452, "title": "The Many Dimensions of Truthfulness: Crowdsourcing Misinformation\n  Assessments on a Multidimensional Scale", "abstract": "Recent work has demonstrated the viability of using crowdsourcing as a tool\nfor evaluating the truthfulness of public statements. Under certain conditions\nsuch as: (1) having a balanced set of workers with different backgrounds and\ncognitive abilities; (2) using an adequate set of mechanisms to control the\nquality of the collected data; and (3) using a coarse grained assessment scale,\nthe crowd can provide reliable identification of fake news. However, fake news\nare a subtle matter: statements can be just biased (\"cherrypicked\"), imprecise,\nwrong, etc. and the unidimensional truth scale used in existing work cannot\naccount for such differences. In this paper we propose a multidimensional\nnotion of truthfulness and we ask the crowd workers to assess seven different\ndimensions of truthfulness selected based on existing literature: Correctness,\nNeutrality, Comprehensibility, Precision, Completeness, Speaker's\nTrustworthiness, and Informativeness. We deploy a set of quality control\nmechanisms to ensure that the thousands of assessments collected on 180\npublicly available fact-checked statements distributed over two datasets are of\nadequate quality, including a custom search engine used by the crowd workers to\nfind web pages supporting their truthfulness assessments. A comprehensive\nanalysis of crowdsourced judgments shows that: (1) the crowdsourced assessments\nare reliable when compared to an expert-provided gold standard; (2) the\nproposed dimensions of truthfulness capture independent pieces of information;\n(3) the crowdsourcing task can be easily learned by the workers; and (4) the\nresulting assessments provide a useful basis for a more complete estimation of\nstatement truthfulness.", "doi": "10.1016/j.ipm.2021.102710", "date": "2021-08-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.01222v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1236651044, "title": "Electroweak corrections and anomalous triple gauge-boson couplings in WW\n  and WZ production at the LHC", "abstract": "We have analysed the production of WW and WZ vector-boson pairs at the LHC.\nThese processes give rise to four-fermion final states, and are particularly\nsensitive to possible non-standard trilinear gauge-boson couplings. We have\nstudied the interplay between the influence of these anomalous couplings and\nthe effect of the complete logarithmic electroweak O(\\alpha) corrections.\nRadiative corrections to the Standard Model processes in double-pole\napproximation and non-standard terms due to trilinear couplings are implemented\ninto a Monte Carlo program for p p -> 4f (+\\gamma) with final states involving\nfour or two charged leptons. We numerically investigate purely leptonic final\nstates and find that electroweak corrections can fake new-physics signals,\nmodifying the observables by the same amount and shape, in kinematical regions\nof statistical significance.", "doi": "10.1103/physrevd.73.093006", "date": "2005-11-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/hep-ph/0511088v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4276441154, "title": "Battling the Internet Water Army: Detection of Hidden Paid Posters", "abstract": "We initiate a systematic study to help distinguish a special group of online\nusers, called hidden paid posters, or termed \"Internet water army\" in China,\nfrom the legitimate ones. On the Internet, the paid posters represent a new\ntype of online job opportunity. They get paid for posting comments and new\nthreads or articles on different online communities and websites for some\nhidden purposes, e.g., to influence the opinion of other people towards certain\nsocial events or business markets. Though an interesting strategy in business\nmarketing, paid posters may create a significant negative effect on the online\ncommunities, since the information from paid posters is usually not\ntrustworthy. When two competitive companies hire paid posters to post fake news\nor negative comments about each other, normal online users may feel overwhelmed\nand find it difficult to put any trust in the information they acquire from the\nInternet. In this paper, we thoroughly investigate the behavioral pattern of\nonline paid posters based on real-world trace data. We design and validate a\nnew detection mechanism, using both non-semantic analysis and semantic\nanalysis, to identify potential online paid posters. Our test results with\nreal-world datasets show a very promising performance.", "doi": "", "date": "2011-11-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1111.4297v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2797911008, "title": "Controlling Elections through Social Influence", "abstract": "Election control considers the problem of an adversary who attempts to tamper\nwith a voting process, in order to either ensure that their favored candidate\nwins (constructive control) or another candidate loses (destructive control).\nAs online social networks have become significant sources of information for\npotential voters, a new tool in an attacker's arsenal is to effect control by\nharnessing social influence, for example, by spreading fake news and other\nforms of misinformation through online social media.\n  We consider the computational problem of election control via social\ninfluence, studying the conditions under which finding good adversarial\nstrategies is computationally feasible. We consider two objectives for the\nadversary in both the constructive and destructive control settings:\nprobability and margin of victory (POV and MOV, respectively). We present\nseveral strong negative results, showing, for example, that the problem of\nmaximizing POV is inapproximable for any constant factor. On the other hand, we\npresent approximation algorithms which provide somewhat weaker approximation\nguarantees, such as bicriteria approximations for the POV objective and\nconstant-factor approximations for MOV. Finally, we present mixed integer\nprogramming formulations for these problems. Experimental results show that our\napproximation algorithms often find near-optimal control strategies, indicating\nthat election control through social influence is a salient threat to election\nintegrity.", "doi": "", "date": "2017-11-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.08615v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3222497889, "title": "Organized Behavior Classification of Tweet Sets using Supervised\n  Learning Methods", "abstract": "During the 2016 US elections Twitter experienced unprecedented levels of\npropaganda and fake news through the collaboration of bots and hired persons,\nthe ramifications of which are still being debated. This work proposes an\napproach to identify the presence of organized behavior in tweets. The Random\nForest, Support Vector Machine, and Logistic Regression algorithms are each\nused to train a model with a data set of 850 records consisting of 299 features\nextracted from tweets gathered during the 2016 US presidential election. The\nfeatures represent user and temporal synchronization characteristics to capture\ncoordinated behavior. These models are trained to classify tweet sets among the\ncategories: organic vs organized, political vs non-political, and pro-Trump vs\npro-Hillary vs neither. The random forest algorithm performs better with\ngreater than 95% average accuracy and f-measure scores for each category. The\nmost valuable features for classification are identified as user based\nfeatures, with media use and marking tweets as favorite to be the most\ndominant.", "doi": "", "date": "2017-11-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.10720v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 229277006, "title": "The Politics of Attention", "abstract": "We develop an equilibrium theory of attention and politics. In a spatial\nmodel of electoral competition where candidates have varying policy\npreferences, we examine what kinds of political behaviors capture voters'\nlimited attention and how this concern affects the overall political outcomes.\nFollowing the seminal works of Downs (1957) and Sims (1998), we assume that\nvoters are rationally inattentive and can process information about the\npolicies at a cost proportional to entropy reduction. The main finding is an\nequilibrium phenomenon called attention- and media-driven extremism, namely as\nwe increase the attention cost or garble the news technology, a truncated set\nof the equilibria captures voters' attention through enlarging the policy\ndifferentials between the varying types of the candidates. We supplement our\nanalysis with historical accounts, and discuss its relevance in the new era\nfeatured with greater media choices and distractions, as well as the rise of\npartisan media and fake news.", "doi": "", "date": "2018-10-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1810.11449v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1990267243, "title": "Rebutting fake news on full spectral fitting", "abstract": "A recent paper by Ge et al. performs a series of experiments with two full\nspectral fitting codes, pPXF and starlight, finding that the two yield\nconsistent results when the input spectrum is not heavily reddened. For E(B-V)\n> 0.2, however, they claim starlight leads to severe biases in the derived\nproperties. Counterintuitively, and at odds with previous simulations, they\nfind that this behaviour worsens significantly as the signal-to-noise ratio of\nthe input spectrum increases. This communication shows that this is entirely\ndue to an A_V < 1 mag condition imposed while initializing the Markov chains in\nthe code. This choice is normally irrelevant in real-life galaxy work but can\nbecome critical in artificial experiments. Alleviating this usually harmless\ninitialization constraint changes the Ge et al. results completely, as was\nexplained to the authors before their publication. We replicate their spectral\nfitting experiments, finding much smaller biases. Furthermore both bias and\nscatter in the derived properties all converge as S/N increases, as one would\nexpect. We also show how the very output of the code provides ways of\ndiagnosing anomalies in the fits. The code behaviour has been documented in\ncareful and extensive experiments in the literature, but the biased analysis of\nGe et al. is just not representative of starlight at all.", "doi": "10.1093/mnras/sty2012", "date": "2018-07-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1807.10423v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2464997893, "title": "Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of\n  User Engagement and Challenges", "abstract": "Fake news and misinformation spread in developing countries as fast as they\ndo in developed countries with increasing penetration of the internet and\nsocial media. However, fighting misinformation is more difficult in developing\ncountries where resources and necessary technologies are scarce. This study\nprovides an understanding of the challenges various fact-checking initiatives\nface in three South Asian countries--Bangladesh, India, and Nepal. In-depth\ninterviews were conducted with senior editors of six fact-checking initiatives.\nChallenges identified include lack of resources, technologies, and political\npressure. An analysis of Facebook pages of these initiatives shows increasing\nuser engagement with their posts.", "doi": "", "date": "2018-11-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.01806v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2679227212, "title": "A Simulated Cyberattack on Twitter: Assessing Partisan Vulnerability to\n  Spear Phishing and Disinformation ahead of the 2018 U.S. Midterm Elections", "abstract": "State-sponsored \"bad actors\" increasingly weaponize social media platforms to\nlaunch cyberattacks and disinformation campaigns during elections. Social media\ncompanies, due to their rapid growth and scale, struggle to prevent the\nweaponization of their platforms. This study conducts an automated spear\nphishing and disinformation campaign on Twitter ahead of the 2018 United States\nMidterm Elections. A fake news bot account - the @DCNewsReport - was created\nand programmed to automatically send customized tweets with a \"breaking news\"\nlink to 138 Twitter users, before being restricted by Twitter.\n  Overall, one in five users clicked the link, which could have potentially led\nto the downloading of ransomware or the theft of private information. However,\nthe link in this experiment was non-malicious and redirected users to a Google\nForms survey. In predicting users' likelihood to click the link on Twitter, no\nstatistically significant differences were observed between right-wing and\nleft-wing partisans, or between Web users and mobile users. The findings signal\nthat politically expressive Americans on Twitter, regardless of their party\npreferences or the devices they use to access the platform, are at risk of\nbeing spear phishing on social media.", "doi": "10.5210/fm.v23i12.9540", "date": "2018-11-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.05900v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1989074410, "title": "Generate, Segment and Refine: Towards Generic Manipulation Segmentation", "abstract": "Detecting manipulated images has become a significant emerging challenge. The\nadvent of image sharing platforms and the easy availability of advanced photo\nediting software have resulted in a large quantities of manipulated images\nbeing shared on the internet. While the intent behind such manipulations varies\nwidely, concerns on the spread of fake news and misinformation is growing.\nCurrent state of the art methods for detecting these manipulated images suffers\nfrom the lack of training data due to the laborious labeling process. We\naddress this problem in this paper, for which we introduce a manipulated image\ngeneration process that creates true positives using currently available\ndatasets. Drawing from traditional work on image blending, we propose a novel\ngenerator for creating such examples. In addition, we also propose to further\ncreate examples that force the algorithm to focus on boundary artifacts during\ntraining. Strong experimental results validate our proposal.", "doi": "", "date": "2018-11-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.09729v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1399364541, "title": "Predicting the Leading Political Ideology of YouTube Channels Using\n  Acoustic, Textual, and Metadata Information", "abstract": "We address the problem of predicting the leading political ideology, i.e.,\nleft-center-right bias, for YouTube channels of news media. Previous work on\nthe problem has focused exclusively on text and on analysis of the language\nused, topics discussed, sentiment, and the like. In contrast, here we study\nvideos, which yields an interesting multimodal setup. Starting with gold\nannotations about the leading political ideology of major world news media from\nMedia Bias/Fact Check, we searched on YouTube to find their corresponding\nchannels, and we downloaded a recent sample of videos from each channel. We\ncrawled more than 1,000 YouTube hours along with the corresponding subtitles\nand metadata, thus producing a new multimodal dataset. We further developed a\nmultimodal deep-learning architecture for the task. Our analysis shows that the\nuse of acoustic signal helped to improve bias detection by more than 6%\nabsolute over using text and metadata only. We release the dataset to the\nresearch community, hoping to help advance the field of multi-modal political\nbias detection.", "doi": "", "date": "2019-10-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.08948v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2205795310, "title": "Findings of the NLP4IF-2019 Shared Task on Fine-Grained Propaganda\n  Detection", "abstract": "We present the shared task on Fine-Grained Propaganda Detection, which was\norganized as part of the NLP4IF workshop at EMNLP-IJCNLP 2019. There were two\nsubtasks. FLC is a fragment-level task that asks for the identification of\npropagandist text fragments in a news article and also for the prediction of\nthe specific propaganda technique used in each such fragment (18-way\nclassification task). SLC is a sentence-level binary classification task asking\nto detect the sentences that contain propaganda. A total of 12 teams submitted\nsystems for the FLC task, 25 teams did so for the SLC task, and 14 teams\neventually submitted a system description paper. For both subtasks, most\nsystems managed to beat the baseline by a sizable margin. The leaderboard and\nthe data from the competition are available at\nhttp://propaganda.qcri.org/nlp4if-shared-task/.", "doi": "", "date": "2019-10-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.09982v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2940031529, "title": "Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments", "abstract": "Over the past couple of years, the topic of \"fake news\" and its influence\nover people's opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to \"go viral.\" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.", "doi": "", "date": "2019-10-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.12073v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3241743179, "title": "A Two-Level Classification Approach for Detecting Clickbait Posts using\n  Text-Based Features", "abstract": "The emergence of social media as news sources has led to the rise of\nclickbait posts attempting to attract users to click on article links without\ninforming them on the actual article content. This paper presents our efforts\nto create a clickbait detector inspired by fake news detection algorithms, and\nour submission to the Clickbait Challenge 2017. The detector is based almost\nexclusively on text-based features taken from previous work on clickbait\ndetection, our own work on fake post detection, and features we designed\nspecifically for the challenge. We use a two-level classification approach,\ncombining the outputs of 65 first-level classifiers in a second-level feature\nvector. We present our exploratory results with individual features and their\ncombinations, taken from the post text and the target article title, as well as\nfeature selection. While our own blind tests with the dataset led to an F-score\nof 0.63, our final evaluation in the Challenge only achieved an F-score of\n0.43. We explore the possible causes of this, and lay out potential future\nsteps to achieve more successful results.", "doi": "", "date": "2017-10-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1710.08528v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1921267180, "title": "Polarization, Partisanship and Junk News Consumption over Social Media\n  in the US", "abstract": "What kinds of social media users read junk news? We examine the distribution\nof the most significant sources of junk news in the three months before\nPresident Donald Trump first State of the Union Address. Drawing on a list of\nsources that consistently publish political news and information that is\nextremist, sensationalist, conspiratorial, masked commentary, fake news and\nother forms of junk news, we find that the distribution of such content is\nunevenly spread across the ideological spectrum. We demonstrate that (1) on\nTwitter, a network of Trump supporters shares the widest range of known junk\nnews sources and circulates more junk news than all the other groups put\ntogether; (2) on Facebook, extreme hard right pages, distinct from Republican\npages, share the widest range of known junk news sources and circulate more\njunk news than all the other audiences put together; (3) on average, the\naudiences for junk news on Twitter share a wider range of known junk news\nsources than audiences on Facebook public pages.", "doi": "", "date": "2018-03-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1803.01845v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2770520532, "title": "A Bayesian Model for False Information Belief Impact, Optimal Design,\n  and Fake News Containment", "abstract": "This work is a technical approach to modeling false information nature,\ndesign, belief impact and containment in multi-agent networks. We present a\nBayesian mathematical model for source information and viewer's belief, and how\nthe former impacts the latter in a media (network) of broadcasters and viewers.\nGiven the proposed model, we study how a particular information (true or false)\ncan be optimally designed into a report, so that on average it conveys the most\namount of the original intended information to the viewers of the network.\nConsequently, the model allows us to study susceptibility of a particular group\nof viewers to false information, as a function of statistical metrics of the\ntheir prior beliefs (e.g. bias, hesitation, open-mindedness, credibility\nassessment etc.). In addition, based on the same model we can study false\ninformation \"containment\" strategies imposed by network administrators.\nSpecifically, we study a credibility assessment strategy, where every\ndisseminated report must be within a certain distance of the truth. We study\nthe trade-off between false and true information-belief convergence using this\nscheme which leads to ways for optimally deciding how truth sensitive an\ninformation dissemination network should operate.", "doi": "", "date": "2018-03-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.01576v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 860438082, "title": "Prevalence of web trackers on hospital websites in Illinois", "abstract": "Web tracking technologies are pervasive and operated by a few large\ntechnology companies. This technology, and the use of the collected data has\nbeen implicated in influencing elections, fake news, discrimination, and even\nhealth decisions. Little is known about how this technology is deployed on\nhospital or other health related websites. The websites of the 210 public\nhospitals in the state of Illinois, USA were evaluated with a web tracker\nidentification tool. Web trackers were identified on 94% of hospital webs\nsites, with an average of 3.5 trackers on the websites of general hospitals.\nThe websites of smaller critical access hospitals used an average of 2 web\ntrackers. The most common web tracker identified was Google Analytics, found on\n74% of Illinois hospital websites. Of the web trackers discovered, 88% were\noperated by Google and 26% by Facebook. In light of revelations about how web\nbrowsing profiles have been used and misused, search bubbles, and the potential\nfor algorithmic discrimination hospital leadership and policy makers must\ncarefully consider if it is appropriate to use third party tracking technology\non hospital web sites.", "doi": "", "date": "2018-05-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1805.01392v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3186498048, "title": "Fighting Fake News: Image Splice Detection via Learned Self-Consistency", "abstract": "Advances in photo editing and manipulation tools have made it significantly\neasier to create fake imagery. Learning to detect such manipulations, however,\nremains a challenging problem due to the lack of sufficient amounts of\nmanipulated training data. In this paper, we propose a learning algorithm for\ndetecting visual image manipulations that is trained only using a large dataset\nof real photographs. The algorithm uses the automatically recorded photo EXIF\nmetadata as supervisory signal for training a model to determine whether an\nimage is self-consistent -- that is, whether its content could have been\nproduced by a single imaging pipeline. We apply this self-consistency model to\nthe task of detecting and localizing image splices. The proposed method obtains\nstate-of-the-art performance on several image forensics benchmarks, despite\nnever seeing any manipulated images at training. That said, it is merely a step\nin the long quest for a truly general purpose visual forensics tool.", "doi": "", "date": "2018-05-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1805.04096v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3339133581, "title": "Technology, Propaganda, and the Limits of Human Intellect", "abstract": "\"Fake news\" is a recent phenomenon, but misinformation and propaganda are\nnot. Our new communication technologies make it easy for us to be exposed to\nhigh volumes of true, false, irrelevant, and unprovable information. Future AI\nis expected to amplify the problem even more. At the same time, our brains are\nreaching their limits in handling information. How should we respond to\npropaganda? Technology can help, but relying on it alone will not suffice in\nthe long term. We also need ethical policies, laws, regulations, and trusted\nauthorities, including fact-checkers. However, we will not solve the problem\nwithout the active engagement of the educated citizen. Epistemological\neducation, recognition of self biases and protection of our channels of\ncommunication and trusted networks are all needed to overcome the problem and\ncontinue our progress as democratic societies.", "doi": "", "date": "2018-06-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.09541v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1690247793, "title": "Neural Networks Assist Crowd Predictions in Discerning the Veracity of\n  Emotional Expressions", "abstract": "Crowd predictions have demonstrated powerful performance in predicting future\nevents. We aim to understand crowd prediction efficacy in ascertaining the\nveracity of human emotional expressions. We discover that collective\ndiscernment can increase the accuracy of detecting emotion veracity from 63%,\nwhich is the average individual performance, to 80%. Constraining data to best\nperformers can further increase the result up to 92%. Neural networks can\nachieve an accuracy to 99.69% by aggregating participants' answers. That is,\nassigning positive and negative weights to high and low human predictors,\nrespectively. Furthermore, neural networks that are trained with one emotion\ndata can also produce high accuracies on discerning the veracity of other\nemotion types: our crowdsourced transfer of emotion learning is novel. We find\nthat our neural networks do not require a large number of participants,\nparticularly, 30 randomly selected, to achieve high accuracy predictions,\nbetter than any individual participant. Our proposed method of assembling\npeoples' predictions with neural networks can provide insights for applications\nsuch as fake news prevention and lie detection.", "doi": "", "date": "2018-08-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.05359v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3728406577, "title": "Analysis of adversarial attacks against CNN-based image forgery\n  detectors", "abstract": "With the ubiquitous diffusion of social networks, images are becoming a\ndominant and powerful communication channel. Not surprisingly, they are also\nincreasingly subject to manipulations aimed at distorting information and\nspreading fake news. In recent years, the scientific community has devoted\nmajor efforts to contrast this menace, and many image forgery detectors have\nbeen proposed. Currently, due to the success of deep learning in many\nmultimedia processing tasks, there is high interest towards CNN-based\ndetectors, and early results are already very promising. Recent studies in\ncomputer vision, however, have shown CNNs to be highly vulnerable to\nadversarial attacks, small perturbations of the input data which drive the\nnetwork towards erroneous classification. In this paper we analyze the\nvulnerability of CNN-based image forensics methods to adversarial attacks,\nconsidering several detectors and several types of attack, and testing\nperformance on a wide range of common manipulations, both easily and hardly\ndetectable.", "doi": "", "date": "2018-08-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.08426v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2680183791, "title": "Framing and Agenda-setting in Russian News: a Computational Analysis of\n  Intricate Political Strategies", "abstract": "Amidst growing concern over media manipulation, NLP attention has focused on\novert strategies like censorship and \"fake news'\". Here, we draw on two\nconcepts from the political science literature to explore subtler strategies\nfor government media manipulation: agenda-setting (selecting what topics to\ncover) and framing (deciding how topics are covered). We analyze 13 years (100K\narticles) of the Russian newspaper Izvestia and identify a strategy of\ndistraction: articles mention the U.S. more frequently in the month directly\nfollowing an economic downturn in Russia. We introduce embedding-based methods\nfor cross-lingually projecting English frames to Russian, and discover that\nthese articles emphasize U.S. moral failings and threats to the U.S. Our work\noffers new ways to identify subtle media manipulation strategies at the\nintersection of agenda-setting and framing.", "doi": "", "date": "2018-08-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.09386v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2263327415, "title": "RumourEval 2019: Determining Rumour Veracity and Support for Rumours", "abstract": "This is the proposal for RumourEval-2019, which will run in early 2019 as\npart of that year's SemEval event. Since the first RumourEval shared task in\n2017, interest in automated claim validation has greatly increased, as the\ndangers of \"fake news\" have become a mainstream concern. Yet automated support\nfor rumour checking remains in its infancy. For this reason, it is important\nthat a shared task in this area continues to provide a focus for effort, which\nis likely to increase. We therefore propose a continuation in which the\nveracity of further rumours is determined, and as previously, supportive of\nthis goal, tweets discussing them are classified according to the stance they\ntake regarding the rumour. Scope is extended compared with the first\nRumourEval, in that the dataset is substantially expanded to include Reddit as\nwell as Twitter data, and additional languages are also included.", "doi": "", "date": "2018-09-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.06683v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4156559815, "title": "Identifying Fake News from Twitter Sharing Data: A Large-Scale Study", "abstract": "Social networks offer a ready channel for fake and misleading news to spread\nand exert influence. This paper examines the performance of different\nreputation algorithms when applied to a large and statistically significant\nportion of the news that are spread via Twitter. Our main result is that simple\ncrowdsourcing-based algorithms are able to identify a large portion of fake or\nmisleading news, while incurring only very low false positive rates for\nmainstream websites. We believe that these algorithms can be used as the basis\nof practical, large-scale systems for indicating to consumers which news sites\ndeserve careful scrutiny and skepticism.", "doi": "", "date": "2019-02-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.07207v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2039049931, "title": "TEEvil: Identity Lease via Trusted Execution Environments", "abstract": "We investigate identity lease, a new type of service in which users lease\ntheir identities to third parties by providing them with full or restricted\naccess to their online accounts or credentials. We discuss how identity lease\ncould be abused to subvert the digital society, facilitating the spread of fake\nnews and subverting electronic voting by enabling the sale of votes. We show\nthat the emergence of Trusted Execution Environments and anonymous\ncryptocurrencies, for the first time, allows the implementation of such a lease\nservice while guaranteeing fairness, plausible deniability and anonymity,\ntherefore shielding the users and account renters from prosecution. To show\nthat such a service can be practically implemented, we build an example service\nthat we call TEEvil leveraging Intel SGX and ZCash. Finally, we discuss defense\nmechanisms and challenges in the mitigation of identity lease services.", "doi": "", "date": "2019-03-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.00449v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3347911179, "title": "Lexical convergence and collective identities on Facebook", "abstract": "Recent studies, targeting Facebook, showed the tendency of users to interact\nwith information adhering to their preferred narrative and to ignore dissenting\ninformation. Primarily driven by confirmation bias, users tend to join\npolarized clusters where they cooperate to reinforce a like-minded system of\nbeliefs, thus facilitating fake news and misinformation cascades. To gain a\ndeeper understanding of these phenomena, in this work we analyze the lexicons\nused by the communities of users emerging on Facebook around verified and\nunverified contents. We show how the lexical approach provides important\ninsights about the kind of information processed by the two communities of\nusers and about their overall sentiment. Furthermore, by focusing on comment\nthreads, we observe a strong positive correlation between the lexical\nconvergence of co-commenters and their number of interactions, which in turns\nsuggests that such a trend could be a proxy for the emergence of collective\nidentities and polarization in opinion dynamics.", "doi": "", "date": "2019-03-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.11452v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3951325966, "title": "Multi-Task Ordinal Regression for Jointly Predicting the Trustworthiness\n  and the Leading Political Ideology of News Media", "abstract": "In the context of fake news, bias, and propaganda, we study two important but\nrelatively under-explored problems: (i) trustworthiness estimation (on a\n3-point scale) and (ii) political ideology detection (left/right bias on a\n7-point scale) of entire news outlets, as opposed to evaluating individual\narticles. In particular, we propose a multi-task ordinal regression framework\nthat models the two problems jointly. This is motivated by the observation that\nhyper-partisanship is often linked to low trustworthiness, e.g., appealing to\nemotions rather than sticking to the facts, while center media tend to be\ngenerally more impartial and trustworthy. We further use several auxiliary\ntasks, modeling centrality, hyperpartisanship, as well as left-vs.-right bias\non a coarse-grained scale. The evaluation results show sizable performance\ngains by the joint models over models that target the problems in isolation.", "doi": "", "date": "2019-04-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.00542v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1233017481, "title": "Second-order Inductive Inference: an axiomatic approach", "abstract": "Consider a predictor who ranks eventualities on the basis of past cases: for\ninstance a search engine ranking webpages given past searches. Resampling past\ncases leads to different rankings and the extraction of deeper information. Yet\na rich database, with sufficiently diverse rankings, is often beyond reach.\nInexperience demands either \"on the fly\" learning-by-doing or prudence: the\narrival of a novel case does not force (i) a revision of current rankings, (ii)\ndogmatism towards new rankings, or (iii) intransitivity. For this higher-order\nframework of inductive inference, we derive a suitably unique numerical\nrepresentation of these rankings via a matrix on eventualities x cases and\ndescribe a robust test of prudence. Applications include: the success/failure\nof startups; the veracity of fake news; and novel conditions for the existence\nof a yield curve that is robustly arbitrage-free.", "doi": "", "date": "2019-04-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.02934v5", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2628297598, "title": "Team QCRI-MIT at SemEval-2019 Task 4: Propaganda Analysis Meets\n  Hyperpartisan News Detection", "abstract": "In this paper, we describe our submission to SemEval-2019 Task 4 on\nHyperpartisan News Detection. Our system relies on a variety of engineered\nfeatures originally used to detect propaganda. This is based on the assumption\nthat biased messages are propagandistic in the sense that they promote a\nparticular political cause or viewpoint. We trained a logistic regression model\nwith features ranging from simple bag-of-words to vocabulary richness and text\nreadability features. Our system achieved 72.9% accuracy on the test data that\nis annotated manually and 60.8% on the test data that is annotated with distant\nsupervision. Additional experiments showed that significant performance\nimprovements can be achieved with better feature pre-processing.", "doi": "", "date": "2019-04-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.03513v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3168867035, "title": "Local non-Bayesian social learning with stubborn agents", "abstract": "We study a social learning model in which agents iteratively update their\nbeliefs about the true state of the world using private signals and the beliefs\nof other agents in a non-Bayesian manner. Some agents are stubborn, meaning\nthey attempt to convince others of an erroneous true state (modeling fake\nnews). We show that while agents learn the true state on short timescales, they\n\"forget\" it and believe the erroneous state to be true on longer timescales.\nUsing these results, we devise strategies for seeding stubborn agents so as to\ndisrupt learning, which outperform intuitive heuristics and give novel insights\nregarding vulnerabilities in social learning.", "doi": "", "date": "2019-04-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.12767v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3617690783, "title": "An End-to-End Framework to Identify Pathogenic Social Media Accounts on\n  Twitter", "abstract": "Pathogenic Social Media (PSM) accounts such as terrorist supporter accounts\nand fake news writers have the capability of spreading disinformation to viral\nproportions. Early detection of PSM accounts is crucial as they are likely to\nbe key users to make malicious information \"viral\". In this paper, we adopt the\ncausal inference framework along with graph-based metrics in order to\ndistinguish PSMs from normal users within a short time of their activities. We\npropose both supervised and semi-supervised approaches without taking the\nnetwork information and content into account. Results on a real-world dataset\nfrom Twitter accentuates the advantage of our proposed frameworks. We show our\napproach achieves 0.28 improvement in F1 score over existing approaches with\nthe precision of 0.90 and F1 score of 0.63.", "doi": "", "date": "2019-05-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.01553v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2570679483, "title": "Detecting Pathogenic Social Media Accounts without Content or Network\n  Structure", "abstract": "The spread of harmful mis-information in social media is a pressing problem.\nWe refer accounts that have the capability of spreading such information to\nviral proportions as \"Pathogenic Social Media\" accounts. These accounts include\nterrorist supporters accounts, water armies, and fake news writers. We\nintroduce an unsupervised causality-based framework that also leverages label\npropagation. This approach identifies these users without using network\nstructure, cascade path information, content and user's information. We show\nour approach obtains higher precision (0.75) in identifying Pathogenic Social\nMedia accounts in comparison with random (precision of 0.11) and existing bot\ndetection (precision of 0.16) methods.", "doi": "", "date": "2019-05-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.01556v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 384415318, "title": "Applications of Social Media in Hydroinformatics: A Survey", "abstract": "Floods of research and practical applications employ social media data for a\nwide range of public applications, including environmental monitoring, water\nresource managing, disaster and emergency response.Hydroinformatics can benefit\nfrom the social media technologies with newly emerged data, techniques and\nanalytical tools to handle large datasets, from which creative ideas and new\nvalues could be mined.This paper first proposes a 4W (What, Why, When, hoW)\nmodel and a methodological structure to better understand and represent the\napplication of social media to hydroinformatics, then provides an overview of\nacademic research of applying social media to hydroinformatics such as water\nenvironment, water resources, flood, drought and water Scarcity management. At\nlast,some advanced topics and suggestions of water related social media\napplications from data collection, data quality management, fake news\ndetection, privacy issues, algorithms and platforms was present to\nhydroinformatics managers and researchers based on previous discussion.", "doi": "", "date": "2019-05-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.03035v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1824506888, "title": "IdeoTrace: A Framework for Ideology Tracing with a Case Study on the\n  2016 U.S. Presidential Election", "abstract": "The 2016 United States presidential election has been characterized as a\nperiod of extreme divisiveness that was exacerbated on social media by the\ninfluence of fake news, trolls, and social bots. However, the extent to which\nthe public became more polarized in response to these influences over the\ncourse of the election is not well understood. In this paper we propose\nIdeoTrace, a framework for (i) jointly estimating the ideology of social media\nusers and news websites and (ii) tracing changes in user ideology over time. We\napply this framework to the last two months of the election period for a group\nof 47508 Twitter users and demonstrate that both liberal and conservative users\nbecame more polarized over time.", "doi": "", "date": "2019-05-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.08831v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1775633270, "title": "A trust model for spreading gossip in social networks", "abstract": "We introduce here a multi-type bootstrap percolation model, which we call\nT-Bootstrap Percolation (T-BP), and apply it to study information propagation\nin social networks. In this model, a social network is represented by a graph G\nwhose vertices have different labels corresponding to the type of role the\nperson plays in the network (e.g. a student, an educator, etc.). Once an\ninitial set of vertices of G is randomly selected to be carrying a gossip (e.g.\nto be infected), the gossip propagates to a new vertex provided it is\ntransmitted by a minimum threshold of vertices with different labels. By\nconsidering random graphs, which have been shown to closely represent social\nnetworks, we study different properties of the T-BP model through numerical\nsimulations, and describe its implications when applied to rumour spread, fake\nnews, and marketing strategies.", "doi": "", "date": "2019-05-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.11204v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 599617016, "title": "Interacting contagions are indistinguishable from social reinforcement", "abstract": "From fake news to innovative technologies, many contagions spread via a\nprocess of social reinforcement, where multiple exposures are distinct from\nprolonged exposure to a single source. Contrarily, biological agents such as\nEbola or measles are typically thought to spread as simple contagions. Here, we\ndemonstrate that interacting simple contagions are indistinguishable from\ncomplex contagions. In the social context, our results highlight the challenge\nof identifying and quantifying mechanisms, such as social reinforcement, in a\nworld where an innumerable amount of ideas, memes and behaviors interact. In\nthe biological context, this parallel allows the use of complex contagions to\neffectively quantify the non-trivial interactions of infectious diseases.", "doi": "10.1038/s41567-020-0791-2", "date": "2019-06-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.01147v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1072758624, "title": "Subtle Censorship via Adversarial Fakeness in Kyrgyzstan", "abstract": "With the shift of public discourse to social media, we see simultaneously an\nexpansion of civic engagement as the bar to enter the conversation is lowered,\nand the reaction by both state and non-state adversaries of free speech to\nsilence these voices. Traditional forms of censorship struggle in this new\nsituation to enforce the preferred narrative of those in power. Consequently,\nthey have developed new methods for controlling the conversation that use the\nsocial media platform itself.\n  Using the Central Asian republic of Kyrgyzstan as a main case study, this\ntalk explores how this new form of \"subtle\" censorship relies on pretence and\nimitation, and why interdisciplinary methods of research are needed to grapple\nwith it. We examine how \"fakeness\" in the form of fake news and profiles is\nused as methods of subtle censorship.", "doi": "", "date": "2019-06-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.08021v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 133487360, "title": "Discovering Differential Features: Adversarial Learning for Information\n  Credibility Evaluation", "abstract": "A series of deep learning approaches extract a large number of credibility\nfeatures to detect fake news on the Internet. However, these extracted features\nstill suffer from many irrelevant and noisy features that restrict severely the\nperformance of the approaches. In this paper, we propose a novel model based on\nAdversarial Networks and inspirited by the Shared-Private model (ANSP), which\naims at reducing common, irrelevant features from the extracted features for\ninformation credibility evaluation. Specifically, ANSP involves two tasks: one\nis to prevent the binary classification of true and false information for\ncapturing common features relying on adversarial networks guided by\nreinforcement learning. Another extracts credibility features (henceforth,\nprivate features) from multiple types of credibility information and compares\nwith the common features through two strategies, i.e., orthogonality\nconstraints and KL-divergence for making the private features more\ndifferential. Experiments first on two six-label LIAR and Weibo datasets\ndemonstrate that ANSP achieves the state-of-the-art performance, boosting the\naccuracy by 2.1%, 3.1%, respectively and then on four-label Twitter16 validate\nthe robustness of the model with 1.8% performance improvements.", "doi": "", "date": "2019-09-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.07523v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1077012952, "title": "Temporal Graph Kernels for Classifying Dissemination Processes", "abstract": "Many real-world graphs or networks are temporal, e.g., in a social network\npersons only interact at specific points in time. This information directs\ndissemination processes on the network, such as the spread of rumors, fake\nnews, or diseases. However, the current state-of-the-art methods for supervised\ngraph classification are designed mainly for static graphs and may not be able\nto capture temporal information. Hence, they are not powerful enough to\ndistinguish between graphs modeling different dissemination processes. To\naddress this, we introduce a framework to lift standard graph kernels to the\ntemporal domain. Specifically, we explore three different approaches and\ninvestigate the trade-offs between loss of temporal information and efficiency.\nMoreover, to handle large-scale graphs, we propose stochastic variants of our\nkernels with provable approximation guarantees. We evaluate our methods on a\nwide range of real-world social networks. Our methods beat static kernels by a\nlarge margin in terms of accuracy while still being scalable to large graphs\nand data sets. Hence, we confirm that taking temporal information into account\nis crucial for the successful classification of dissemination processes.", "doi": "", "date": "2019-10-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.05496v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3798522180, "title": "Deception through Half-Truths", "abstract": "Deception is a fundamental issue across a diverse array of settings, from\ncybersecurity, where decoys (e.g., honeypots) are an important tool, to\npolitics that can feature politically motivated \"leaks\" and fake news about\ncandidates.Typical considerations of deception view it as providing false\ninformation.However, just as important but less frequently studied is a more\ntacit form where information is strategically hidden or leaked.We consider the\nproblem of how much an adversary can affect a principal's decision by\n\"half-truths\", that is, by masking or hiding bits of information, when the\nprincipal is oblivious to the presence of the adversary. The principal's\nproblem can be modeled as one of predicting future states of variables in a\ndynamic Bayes network, and we show that, while theoretically the principal's\ndecisions can be made arbitrarily bad, the optimal attack is NP-hard to\napproximate, even under strong assumptions favoring the attacker. However, we\nalso describe an important special case where the dependency of future states\non past states is additive, in which we can efficiently compute an\napproximately optimal attack. Moreover, in networks with a linear transition\nfunction we can solve the problem optimally in polynomial time.", "doi": "", "date": "2019-11-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.05885v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2781467009, "title": "Rumor Detection on Social Media: Datasets, Methods and Opportunities", "abstract": "Social media platforms have been used for information and news gathering, and\nthey are very valuable in many applications. However, they also lead to the\nspreading of rumors and fake news. Many efforts have been taken to detect and\ndebunk rumors on social media by analyzing their content and social context\nusing machine learning techniques. This paper gives an overview of the recent\nstudies in the rumor detection field. It provides a comprehensive list of\ndatasets used for rumor detection, and reviews the important studies based on\nwhat types of information they exploit and the approaches they take. And more\nimportantly, we also present several new directions for future research.", "doi": "", "date": "2019-11-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.07199v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 828709648, "title": "Analysing Russian Trolls via NLP tools", "abstract": "The fifty-eighth American presidential election in 2016 still arouse fierce\ncontroversyat present. A portion of politicians as well as medium and voters\nbelieve that theRussian government interfered with the election of 2016 by\ncontrolling malicioussocial media accounts on twitter, such as trolls and bots\naccounts. Both of them willbroadcast fake news, derail the conversations about\nelection, and mislead people.Therefore, this paper will focus on analysing some\nof the twitter dataset about theelection of 2016 by using NLP methods and\nlooking for some interesting patterns ofwhether the Russian government\ninterfered with the election or not. We apply topicmodel on the given twitter\ndataset to extract some interesting topics and analysethe meaning, then we\nimplement supervised topic model to retrieve the relationshipbetween topics to\ncategory which is left troll or right troll, and analyse the\npattern.Additionally, we will do sentiment analysis to analyse the attitude of\nthe tweet. Afterextracting typical tweets from interesting topic, sentiment\nanalysis offers the ability toknow whether the tweet supports this topic or\nnot. Based on comprehensive analysisand evaluation, we find interesting\npatterns of the dataset as well as some meaningfultopics.", "doi": "", "date": "2019-11-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.11067v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 832908218, "title": "Transitivity and degree assortativity explained: The bipartite structure\n  of social networks", "abstract": "Dynamical processes, such as the diffusion of knowledge, opinions, pathogens,\n\"fake news\", innovation, and others, are highly dependent on the structure of\nthe social network on which they occur. However, questions on why most social\nnetworks present some particular structural features, namely high levels of\ntransitivity and degree assortativity, when compared to other types of networks\nremain open. First, we argue that every one-mode network can be regarded as a\nprojection of a bipartite network, and show that this is the case using two\nsimple examples solved with the generating functions formalism. Second, using\nsynthetic and empirical data, we reveal how the combination of the degree\ndistribution of both sets of nodes of the bipartite network --- together with\nthe presence of cycles of length four and six --- explains the observed levels\nof transitivity and degree assortativity in the one-mode projected network.\nBipartite networks with top node degrees that display a more right-skewed\ndistribution than the bottom nodes result in highly transitive and degree\nassortative projections, especially if a large number of small cycles are\npresent in the bipartite structure.", "doi": "10.1103/physreve.101.052305", "date": "2019-12-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.03211v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2750273305, "title": "Proppy: A System to Unmask Propaganda in Online News", "abstract": "We present proppy, the first publicly available real-world, real-time\npropaganda detection system for online news, which aims at raising awareness,\nthus potentially limiting the impact of propaganda and helping fight\ndisinformation. The system constantly monitors a number of news sources,\ndeduplicates and clusters the news into events, and organizes the articles\nabout an event on the basis of the likelihood that they contain propagandistic\ncontent. The system is trained on known propaganda sources using a variety of\nstylistic features. The evaluation results on a standard dataset show\nstate-of-the-art results for propaganda detection.", "doi": "", "date": "2019-12-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.06810v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2504516546, "title": "DeepFakes and Beyond: A Survey of Face Manipulation and Fake Detection", "abstract": "The free access to large-scale public databases, together with the fast\nprogress of deep learning techniques, in particular Generative Adversarial\nNetworks, have led to the generation of very realistic fake content with its\ncorresponding implications towards society in this era of fake news. This\nsurvey provides a thorough review of techniques for manipulating face images\nincluding DeepFake methods, and methods to detect such manipulations. In\nparticular, four types of facial manipulation are reviewed: i) entire face\nsynthesis, ii) identity swap (DeepFakes), iii) attribute manipulation, and iv)\nexpression swap. For each manipulation group, we provide details regarding\nmanipulation techniques, existing public databases, and key benchmarks for\ntechnology evaluation of fake detection methods, including a summary of results\nfrom those evaluations. Among all the aspects discussed in the survey, we pay\nspecial attention to the latest generation of DeepFakes, highlighting its\nimprovements and challenges for fake detection.\n  In addition to the survey information, we also discuss open issues and future\ntrends that should be considered to advance in the field.", "doi": "", "date": "2020-01-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.00179v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 794924731, "title": "Stance Detection Benchmark: How Robust Is Your Stance Detection?", "abstract": "Stance Detection (StD) aims to detect an author's stance towards a certain\ntopic or claim and has become a key component in applications like fake news\ndetection, claim validation, and argument search. However, while stance is\neasily detected by humans, machine learning models are clearly falling short of\nthis task. Given the major differences in dataset sizes and framing of StD\n(e.g. number of classes and inputs), we introduce a StD benchmark that learns\nfrom ten StD datasets of various domains in a multi-dataset learning (MDL)\nsetting, as well as from related tasks via transfer learning. Within this\nbenchmark setup, we are able to present new state-of-the-art results on five of\nthe datasets. Yet, the models still perform well below human capabilities and\neven simple adversarial attacks severely hurt the performance of MDL models.\nDeeper investigation into this phenomenon suggests the existence of biases\ninherited from multiple datasets by design. Our analysis emphasizes the need of\nfocus on robustness and de-biasing strategies in multi-task learning\napproaches. The benchmark dataset and code is made available.", "doi": "", "date": "2020-01-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.01565v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3011607664, "title": "Cluster-Based Social Reinforcement Learning", "abstract": "Social Reinforcement Learning methods, which model agents in large networks,\nare useful for fake news mitigation, personalized teaching/healthcare, and\nviral marketing, but it is challenging to incorporate inter-agent dependencies\ninto the models effectively due to network size and sparse interaction data.\nPrevious social RL approaches either ignore agents dependencies or model them\nin a computationally intensive manner. In this work, we incorporate agent\ndependencies efficiently in a compact model by clustering users (based on their\npayoff and contribution to the goal) and combine this with a method to easily\nderive personalized agent-level policies from cluster-level policies. We also\npropose a dynamic clustering approach that captures changing user behavior.\nExperiments on real-world datasets illustrate that our proposed approach learns\nmore accurate policy estimates and converges more quickly, compared to several\nbaselines that do not use agent correlations or only use static clusters.", "doi": "", "date": "2020-03-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.00627v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3209119604, "title": "Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business", "abstract": "In the age of social media, disasters and epidemics usher not only a\ndevastation and affliction in the physical world, but also prompt a deluge of\ninformation, opinions, prognoses and advice to billions of internet users. The\ncoronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World\nHealth Organization warning of a possible \"infodemic\" of fake news. In this\nstudy, we examine the alternative narratives around the coronavirus outbreak\nthrough advertisements promoted on Facebook, the largest social media platform\nin the US. Using the new Facebook Ads Library, we discover advertisers from\npublic health and non-profit sectors, alongside those from news media,\npolitics, and business, incorporating coronavirus into their messaging and\nagenda. We find the virus used in political attacks, donation solicitations,\nbusiness promotion, stock market advice, and animal rights campaigning. Among\nthese, we find several instances of possible misinformation, ranging from\nbioweapons conspiracy theories to unverifiable claims by politicians. As we\nmake the dataset available to the community, we hope the advertising domain\nwill become an important part of quality control for public health\ncommunication and public discourse in general.", "doi": "", "date": "2020-03-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.00923v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1574877969, "title": "Discover Your Social Identity from What You Tweet: a Content Based\n  Approach", "abstract": "An identity denotes the role an individual or a group plays in highly\ndifferentiated contemporary societies. In this paper, our goal is to classify\nTwitter users based on their role identities. We first collect a coarse-grained\npublic figure dataset automatically, then manually label a more fine-grained\nidentity dataset. We propose a hierarchical self-attention neural network for\nTwitter user role identity classification. Our experiments demonstrate that the\nproposed model significantly outperforms multiple baselines. We further propose\na transfer learning scheme that improves our model's performance by a large\nmargin. Such transfer learning also greatly reduces the need for a large amount\nof human labeled data.", "doi": "10.1007/978-3-030-42699-6", "date": "2020-03-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.01797v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3926579437, "title": "Social Media and Misleading Information in a Democracy: A Mechanism\n  Design Approach", "abstract": "In this paper, we present a resource allocation mechanism for the problem of\nincentivizing filtering among a finite number of strategic social media\nplatforms. We consider the presence of a strategic government and private\nknowledge of how misinformation affects the users of the social media\nplatforms. Our proposed mechanism incentivizes social media platforms to filter\nmisleading information efficiently, and thus indirectly prevents the spread of\nfake news. In particular, we design an economically inspired mechanism that\nstrongly implements all generalized Nash equilibria for efficient filtering of\nmisleading information in the induced game. We show that our mechanism is\nindividually rational, budget balanced, while it has at least one equilibrium.\nFinally, we show that for quasi-concave utilities and constraints, our\nmechanism admits a generalized Nash equilibrium and implements a Pareto\nefficient solution.", "doi": "", "date": "2020-03-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.07192v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1680115045, "title": "Skepticism and rumor spreading: the role of spatial correlations", "abstract": "Critical thinking and skepticism are fundamental mechanisms that one may use\nto prevent the spreading of rumors, fake-news and misinformation. We consider a\nsimple model in which agents without previous contact with the rumor, being\nskeptically oriented, may convince spreaders to stop their activity or, once\nexposed to the rumor, decide not to propagate it as a consequence, for example,\nof fact-checking. We extend a previous, mean-field analysis of the combined\neffect of these two mechanisms, active and passive skepticism, to include\nspatial correlations. This can be done either analytically, through the pair\napproximation, or simulating an agent-based version on diverse networks. Our\nresults show that while in mean-field there is no coexistence between spreaders\nand susceptibles (although, depending on the parameters, there may be\nbistability depending on the initial conditions), when spatial correlations are\nincluded, because of the protective effect of the isolation provided by removed\nagents, coexistence is possible.", "doi": "10.1103/physreve.101.062418", "date": "2020-04-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.00777v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2702794919, "title": "Recent advances in opinion propagation dynamics: A 2020 Survey", "abstract": "Opinion dynamics have attracted the interest of researchers from different\nfields. Local interactions among individuals create interesting dynamics for\nthe system as a whole. Such dynamics are important from a variety of\nperspectives. Group decision making, successful marketing, and constructing\nnetworks (in which consensus can be reached or prevented) are a few examples of\nexisting or potential applications. The invention of the Internet has made the\nopinion fusion faster, unilateral, and on a whole different scale. Spread of\nfake news, propaganda, and election interferences have made it clear there is\nan essential need to know more about these dynamics.\n  The emergence of new ideas in the field has accelerated over the last few\nyears. In the first quarter of 2020, at least 50 research papers have emerged,\neither peer-reviewed and published or on pre-print outlets such as arXiv. In\nthis paper, we summarize these ground-breaking ideas and their fascinating\nextensions and introduce newly surfaced concepts.", "doi": "10.1140/epjp/s13360-020-00541-2", "date": "2020-04-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.05286v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 788975348, "title": "Video Face Manipulation Detection Through Ensemble of CNNs", "abstract": "In the last few years, several techniques for facial manipulation in videos\nhave been successfully developed and made available to the masses (i.e.,\nFaceSwap, deepfake, etc.). These methods enable anyone to easily edit faces in\nvideo sequences with incredibly realistic results and a very little effort.\nDespite the usefulness of these tools in many fields, if used maliciously, they\ncan have a significantly bad impact on society (e.g., fake news spreading,\ncyber bullying through fake revenge porn). The ability of objectively detecting\nwhether a face has been manipulated in a video sequence is then a task of\nutmost importance. In this paper, we tackle the problem of face manipulation\ndetection in video sequences targeting modern facial manipulation techniques.\nIn particular, we study the ensembling of different trained Convolutional\nNeural Network (CNN) models. In the proposed solution, different models are\nobtained starting from a base network (i.e., EfficientNetB4) making use of two\ndifferent concepts: (i) attention layers; (ii) siamese training. We show that\ncombining these networks leads to promising face manipulation detection results\non two publicly available datasets with more than 119000 videos.", "doi": "", "date": "2020-04-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.07676v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1034131097, "title": "On the use of Benford's law to detect GAN-generated images", "abstract": "The advent of Generative Adversarial Network (GAN) architectures has given\nanyone the ability of generating incredibly realistic synthetic imagery. The\nmalicious diffusion of GAN-generated images may lead to serious social and\npolitical consequences (e.g., fake news spreading, opinion formation, etc.). It\nis therefore important to regulate the widespread distribution of synthetic\nimagery by developing solutions able to detect them. In this paper, we study\nthe possibility of using Benford's law to discriminate GAN-generated images\nfrom natural photographs. Benford's law describes the distribution of the most\nsignificant digit for quantized Discrete Cosine Transform (DCT) coefficients.\nExtending and generalizing this property, we show that it is possible to\nextract a compact feature vector from an image. This feature vector can be fed\nto an extremely simple classifier for GAN-generated image detection purpose.", "doi": "", "date": "2020-04-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.07682v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1634102055, "title": "A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian\n  and Indian Elections", "abstract": "Recently, messaging applications, such as WhatsApp, have been reportedly\nabused by misinformation campaigns, especially in Brazil and India. A notable\nform of abuse in WhatsApp relies on several manipulated images and memes\ncontaining all kinds of fake stories. In this work, we performed an extensive\ndata collection from a large set of WhatsApp publicly accessible groups and\nfact-checking agency websites. This paper opens a novel dataset to the research\ncommunity containing fact-checked fake images shared through WhatsApp for two\ndistinct scenarios known for the spread of fake news on the platform: the 2018\nBrazilian elections and the 2019 Indian elections.", "doi": "", "date": "2020-05-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.02443v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2019559547, "title": "Networks in a World Unknown: Public WhatsApp Groups in the Venezuelan\n  Refugee Crisis", "abstract": "By early March 2020, five million Venezuelans had fled their home country\nafter its complete economic and institutional collapse, and over 1.6 million\nhave migrated to Colombia. Migrants struggle to start their lives over in\nColombia, having arrived with few economic resources, and often no legal\ndocumentation, in cities with little to offer them. Venezuelan migrants,\nhowever, rely heavily on mobile phones and social media networks as lifelines\nfor information, opportunities, and resources -- making WhatsApp both a\ncritical tool for migrants' settlement and integration, as well as an\ninvaluable source of data through which we can better understand migrant\nexperiences. This thesis explores the dynamics of public WhatsApp groups used\nby Venezuelan migrants to Colombia, and what they can tell us about how\nmigrants use and share information. We center our research on information\nspread and trust, especially as they intersect with concentration and\ngeographic heterogeneity within groups. We analyze messages and memberships\nbroadly, then explore interaction within groups, fake news and economic scams,\nand effects of the coronavirus pandemic. Our results have a range of policy\nimplications, from reflections on Colombia's decision to shut its borders\namidst the coronavirus pandemic, to understandings of how aid organizations can\neffectively share information over social media channels.", "doi": "", "date": "2020-05-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.05883v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3325284255, "title": "GeoCoV19: A Dataset of Hundreds of Millions of Multilingual COVID-19\n  Tweets with Location Information", "abstract": "The past several years have witnessed a huge surge in the use of social media\nplatforms during mass convergence events such as health emergencies, natural or\nhuman-induced disasters. These non-traditional data sources are becoming vital\nfor disease forecasts and surveillance when preparing for epidemic and pandemic\noutbreaks. In this paper, we present GeoCoV19, a large-scale Twitter dataset\ncontaining more than 524 million multilingual tweets posted over a period of 90\ndays since February 1, 2020. Moreover, we employ a gazetteer-based approach to\ninfer the geolocation of tweets. We postulate that this large-scale,\nmultilingual, geolocated social media data can empower the research communities\nto evaluate how societies are collectively coping with this unprecedented\nglobal crisis as well as to develop computational methods to address challenges\nsuch as identifying fake news, understanding communities' knowledge gaps,\nbuilding disease forecast and surveillance models, among others.", "doi": "", "date": "2020-05-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.11177v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2118209319, "title": "CoAID: COVID-19 Healthcare Misinformation Dataset", "abstract": "As the COVID-19 virus quickly spreads around the world, unfortunately,\nmisinformation related to COVID-19 also gets created and spreads like wild\nfire. Such misinformation has caused confusion among people, disruptions in\nsociety, and even deadly consequences in health problems. To be able to\nunderstand, detect, and mitigate such COVID-19 misinformation, therefore, has\nnot only deep intellectual values but also huge societal impacts. To help\nresearchers combat COVID-19 health misinformation, therefore, we present CoAID\n(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare\nmisinformation, including fake news on websites and social platforms, along\nwith users' social engagement about such news. CoAID includes 4,251 news,\n296,000 related user engagements, 926 social platform posts about COVID-19, and\nground truth labels. The dataset is available at:\nhttps://github.com/cuilimeng/CoAID.", "doi": "", "date": "2020-05-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.00885v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2157082790, "title": "The role of time scale in the spreading of asymmetrically interacting\n  diseases", "abstract": "Diseases and other contagion phenomena in nature and society can interact\nasymmetrically, such that one can benefit from the other, which in turn impairs\nthe first, in analogy with predator-prey systems. Here, we consider two models\nfor interacting disease-like dynamics with asymmetric interactions and\ndifferent associated time scales. Using rate equations for homogeneously mixed\npopulations, we show that the stationary prevalences and phase diagrams of each\nmodel behave differently with respect to variations of the relative time\nscales. We also characterize in detail the regime where transient oscillations\nare observed, a pattern that is inherent to asymmetrical interactions but often\nignored in the literature. Our results contribute to a better understanding of\ndisease dynamics in particular, and interacting processes in general, and could\nprovide interesting insights for real-world applications, most notably, the\ninterplay between the dynamics of fact-checked and fake news.", "doi": "10.1103/physrevresearch.3.013146", "date": "2020-06-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.02774v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1231968162, "title": "Emergence of polarization in a voter model with personalized information", "abstract": "The flourishing of fake news is favored by recommendation algorithms of\nonline social networks which, based on previous users activity, provide content\nadapted to their preferences and so create filter bubbles. We introduce an\nanalytically tractable voter model with personalized information, in which an\nexternal field tends to align the agent opinion with the one she held more\nfrequently in the past. Our model shows a surprisingly rich dynamics despite\nits simplicity. An analytical mean-field approach, confirmed by numerical\nsimulations, allows us to build a phase diagram and to predict if and how\nconsensus is reached. Remarkably, polarization can be avoided only for weak\ninteraction with the personalized information and if the number of agents is\nbelow a threshold. We analytically compute this critical size, which depends on\nthe interaction probability in a strongly non linear way.", "doi": "10.1103/physrevresearch.2.043117", "date": "2020-07-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.04903v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3024805262, "title": "Forecasting Election Polls with Spin Systems", "abstract": "We show that the problem of political forecasting, i.e, predicting the result\nof elections and referendums, can be mapped to finding the ground state\nconfiguration of a classical spin system. Depending on the required prediction,\nthis spin system can be a combination of $XY$, Ising and vector Potts models,\nalways with two-spin interactions, magnetic fields, and on arbitrary graphs. By\nreduction to the Ising model our result shows that political forecasting is\nformally an NP-Hard problem. Moreover, we show that the ground state search can\nbe recasted as Higher-order and Quadratic Unconstrained Binary Optimization\n(HUBO / QUBO) Problems, which are the standard input of classical and quantum\ncombinatorial optimization techniques. We prove the validity of our approach by\nperforming a numerical experiment based on data gathered from \\emph{Twitter}\nfor a network of 10 people, finding good agreement between results from a poll\nand those predicted by our model. In general terms, our method can also be\nunderstood as a trend detection algorithm, particularly useful in the contexts\nof sentiment analysis and identification of fake news.", "doi": "", "date": "2020-07-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.05070v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 482586862, "title": "A Survey on Computational Propaganda Detection", "abstract": "Propaganda campaigns aim at influencing people's mindset with the purpose of\nadvancing a specific agenda. They exploit the anonymity of the Internet, the\nmicro-profiling ability of social networks, and the ease of automatically\ncreating and managing coordinated networks of accounts, to reach millions of\nsocial network users with persuasive messages, specifically targeted to topics\neach individual user is sensitive to, and ultimately influencing the outcome on\na targeted issue. In this survey, we review the state of the art on\ncomputational propaganda detection from the perspective of Natural Language\nProcessing and Network Analysis, arguing about the need for combined efforts\nbetween these communities. We further discuss current challenges and future\nresearch directions.", "doi": "", "date": "2020-07-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.08024v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2297655677, "title": "Mono vs Multilingual Transformer-based Models: a Comparison across\n  Several Language Tasks", "abstract": "BERT (Bidirectional Encoder Representations from Transformers) and ALBERT (A\nLite BERT) are methods for pre-training language models which can later be\nfine-tuned for a variety of Natural Language Understanding tasks. These methods\nhave been applied to a number of such tasks (mostly in English), achieving\nresults that outperform the state-of-the-art. In this paper, our contribution\nis twofold. First, we make available our trained BERT and Albert model for\nPortuguese. Second, we compare our monolingual and the standard multilingual\nmodels using experiments in semantic textual similarity, recognizing textual\nentailment, textual category classification, sentiment analysis, offensive\ncomment detection, and fake news detection, to assess the effectiveness of the\ngenerated language representations. The results suggest that both monolingual\nand multilingual models are able to achieve state-of-the-art and the advantage\nof training a single language model, if any, is small.", "doi": "", "date": "2020-07-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.09757v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1769981389, "title": "aschern at SemEval-2020 Task 11: It Takes Three to Tango: RoBERTa, CRF,\n  and Transfer Learning", "abstract": "We describe our system for SemEval-2020 Task 11 on Detection of Propaganda\nTechniques in News Articles. We developed ensemble models using RoBERTa-based\nneural architectures, additional CRF layers, transfer learning between the two\nsubtasks, and advanced post-processing to handle the multi-label nature of the\ntask, the consistency between nested spans, repetitions, and labels from\nsimilar spans in training. We achieved sizable improvements over baseline\nfine-tuned RoBERTa models, and the official evaluation ranked our system 3rd\n(almost tied with the 2nd) out of 36 teams on the span identification subtask\nwith an F1 score of 0.491, and 2nd (almost tied with the 1st) out of 31 teams\non the technique classification subtask with an F1 score of 0.62.", "doi": "", "date": "2020-08-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.02837v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2513295528, "title": "FOCAL: A Forgery Localization Framework based on Video Coding\n  Self-Consistency", "abstract": "Forgery operations on video contents are nowadays within the reach of anyone,\nthanks to the availability of powerful and user-friendly editing software.\nIntegrity verification and authentication of videos represent a major interest\nin both journalism (e.g., fake news debunking) and legal environments dealing\nwith digital evidence (e.g., a court of law). While several strategies and\ndifferent forensics traces have been proposed in recent years, latest solutions\naim at increasing the accuracy by combining multiple detectors and features.\nThis paper presents a video forgery localization framework that verifies the\nself-consistency of coding traces between and within video frames, by fusing\nthe information derived from a set of independent feature descriptors. The\nfeature extraction step is carried out by means of an explainable convolutional\nneural network architecture, specifically designed to look for and classify\ncoding artifacts. The overall framework was validated in two typical forgery\nscenarios: temporal and spatial splicing. Experimental results show an\nimprovement to the state-of-the-art on temporal splicing localization and also\npromising performance in the newly tackled case of spatial splicing, on both\nsynthetic and real-world videos.", "doi": "10.1109/ojsp.2021.3074298", "date": "2020-08-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.10454v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2344536187, "title": "QMUL-SDS at CheckThat! 2020: Determining COVID-19 Tweet Check-Worthiness\n  Using an Enhanced CT-BERT with Numeric Expressions", "abstract": "This paper describes the participation of the QMUL-SDS team for Task 1 of the\nCLEF 2020 CheckThat! shared task. The purpose of this task is to determine the\ncheck-worthiness of tweets about COVID-19 to identify and prioritise tweets\nthat need fact-checking. The overarching aim is to further support ongoing\nefforts to protect the public from fake news and help people find reliable\ninformation. We describe and analyse the results of our submissions. We show\nthat a CNN using COVID-Twitter-BERT (CT-BERT) enhanced with numeric expressions\ncan effectively boost performance from baseline results. We also show results\nof training data augmentation with rumours on other topics. Our best system\nranked fourth in the task with encouraging outcomes showing potential for\nimproved results in the future.", "doi": "", "date": "2020-08-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.13160v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2812546002, "title": "Sentimental LIAR: Extended Corpus and Deep Learning Models for Fake\n  Claim Classification", "abstract": "The rampant integration of social media in our every day lives and culture\nhas given rise to fast and easier access to the flow of information than ever\nin human history. However, the inherently unsupervised nature of social media\nplatforms has also made it easier to spread false information and fake news.\nFurthermore, the high volume and velocity of information flow in such platforms\nmake manual supervision and control of information propagation infeasible. This\npaper aims to address this issue by proposing a novel deep learning approach\nfor automated detection of false short-text claims on social media. We first\nintroduce Sentimental LIAR, which extends the LIAR dataset of short claims by\nadding features based on sentiment and emotion analysis of claims. Furthermore,\nwe propose a novel deep learning architecture based on the BERT-Base language\nmodel for classification of claims as genuine or fake. Our results demonstrate\nthat the proposed architecture trained on Sentimental LIAR can achieve an\naccuracy of 70%, which is an improvement of ~30% over previously reported\nresults for the LIAR benchmark.", "doi": "", "date": "2020-09-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.01047v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2012453888, "title": "Viable Threat on News Reading: Generating Biased News Using Natural\n  Language Models", "abstract": "Recent advancements in natural language generation has raised serious\nconcerns. High-performance language models are widely used for language\ngeneration tasks because they are able to produce fluent and meaningful\nsentences. These models are already being used to create fake news. They can\nalso be exploited to generate biased news, which can then be used to attack\nnews aggregators to change their reader's behavior and influence their bias. In\nthis paper, we use a threat model to demonstrate that the publicly available\nlanguage models can reliably generate biased news content based on an input\noriginal news. We also show that a large number of high-quality biased news\narticles can be generated using controllable text generation. A subjective\nevaluation with 80 participants demonstrated that the generated biased news is\ngenerally fluent, and a bias evaluation with 24 participants demonstrated that\nthe bias (left or right) is usually evident in the generated articles and can\nbe easily identified.", "doi": "", "date": "2020-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.02150v1", "pdf": ""}, "publisher-venue": "NLP+CSS Workshop at EMNLP\\n  2020", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2785715975, "title": "Controlling Graph Dynamics with Reinforcement Learning and Graph Neural\n  Networks", "abstract": "We consider the problem of controlling a partially-observed dynamic process\non a graph by a limited number of interventions. This problem naturally arises\nin contexts such as scheduling virus tests to curb an epidemic; targeted\nmarketing in order to promote a product; and manually inspecting posts to\ndetect fake news spreading on social networks.\n  We formulate this setup as a sequential decision problem over a temporal\ngraph process. In face of an exponential state space, combinatorial action\nspace and partial observability, we design a novel tractable scheme to control\ndynamical processes on temporal graphs. We successfully apply our approach to\ntwo popular problems that fall into our framework: prioritizing which nodes\nshould be tested in order to curb the spread of an epidemic, and influence\nmaximization on a graph.", "doi": "", "date": "2020-10-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.05313v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2785591991, "title": "How the Far-Right Polarises Twitter: 'Highjacking' Hashtags in Times of\n  COVID-19", "abstract": "Twitter influences political debates. Phenomena like fake news and hate\nspeech show that political discourse on micro-blogging can become strongly\npolarised by algorithmic enforcement of selective perception. Some political\nactors actively employ strategies to facilitate polarisation on Twitter, as\npast contributions show, via strategies of 'hashjacking'. For the example of\nCOVID-19 related hashtags and their retweet networks, we examine the case of\npartisan accounts of the German far-right party Alternative f\\\"ur Deutschland\n(AfD) and their potential use of 'hashjacking' in May 2020. Our findings\nindicate that polarisation of political party hashtags has not changed\nsignificantly in the last two years. We see that right-wing partisans are\nactively and effectively polarising the discourse by 'hashjacking' COVID-19\nrelated hashtags, like #CoronaVirusDE or #FlattenTheCurve. This polarisation\nstrategy is dominated by the activity of a limited set of heavy users. The\nresults underline the necessity to understand the dynamics of discourse\npolarisation, as an active political communication strategy of the far-right,\nby only a handful of very active accounts.", "doi": "", "date": "2020-10-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.05686v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3893087080, "title": "Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed\n  health decision making in the presence of COVID19 misinformation", "abstract": "Given the wide spread of inaccurate medical advice related to the 2019\ncoronavirus pandemic (COVID-19), such as fake remedies, treatments and\nprevention suggestions, misinformation detection has emerged as an open problem\nof high importance and interest for the NLP community. To combat potential harm\nof COVID19-related misinformation, we release Covid-HeRA, a dataset for health\nrisk assessment of COVID-19-related social media posts. More specifically, we\nstudy the severity of each misinformation story, i.e., how harmful a message\nbelieved by the audience can be and what type of signals can be used to\ndiscover high malicious fake news and detect refuted claims. We present a\ndetailed analysis, evaluate several simple and advanced classification models,\nand conclude with our experimental analysis that presents open challenges and\nfuture directions.", "doi": "", "date": "2020-10-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.08743v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1954092224, "title": "Automatic Detection of Machine Generated Text: A Critical Survey", "abstract": "Text generative models (TGMs) excel in producing text that matches the style\nof human language reasonably well. Such TGMs can be misused by adversaries,\ne.g., by automatically generating fake news and fake product reviews that can\nlook authentic and fool humans. Detectors that can distinguish text generated\nby TGM from human written text play a vital role in mitigating such misuse of\nTGMs. Recently, there has been a flurry of works from both natural language\nprocessing (NLP) and machine learning (ML) communities to build accurate\ndetectors for English. Despite the importance of this problem, there is\ncurrently no work that surveys this fast-growing literature and introduces\nnewcomers to important research challenges. In this work, we fill this void by\nproviding a critical survey and review of this literature to facilitate a\ncomprehensive understanding of this problem. We conduct an in-depth error\nanalysis of the state-of-the-art detector and discuss research directions to\nguide future work in this exciting area.", "doi": "", "date": "2020-11-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.01314v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2439917447, "title": "MEG: Multi-Evidence GNN for Multimodal Semantic Forensics", "abstract": "Fake news often involves semantic manipulations across modalities such as\nimage, text, location etc and requires the development of multimodal semantic\nforensics for its detection. Recent research has centered the problem around\nimages, calling it image repurposing -- where a digitally unmanipulated image\nis semantically misrepresented by means of its accompanying multimodal metadata\nsuch as captions, location, etc. The image and metadata together comprise a\nmultimedia package. The problem setup requires algorithms to perform multimodal\nsemantic forensics to authenticate a query multimedia package using a reference\ndataset of potentially related packages as evidences. Existing methods are\nlimited to using a single evidence (retrieved package), which ignores potential\nperformance improvement from the use of multiple evidences. In this work, we\nintroduce a novel graph neural network based model for multimodal semantic\nforensics, which effectively utilizes multiple retrieved packages as evidences\nand is scalable with the number of evidences. We compare the scalability and\nperformance of our model against existing methods. Experimental results show\nthat the proposed model outperforms existing state-of-the-art algorithms with\nan error reduction of up to 25%.", "doi": "", "date": "2020-11-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.11286v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3550005490, "title": "Towards Combating Pandemic-related Misinformation in Social Media", "abstract": "Conventional preventive measures during pandemic include social distancing\nand lockdown. Such measures in the time of social media brought about a new set\nof challenges - vulnerability to the toxic impact of online misinformation is\nhigh. A case in point is the prevailing COVID-19; as the virus propagates, so\ndoes the associated misinformation and fake news about it leading to infodemic.\nSince the outbreak, there has been a surge of studies investigating various\naspects of the pandemic. Of interest to this chapter include studies centring\non datasets from online social media platforms where the bulk of the public\ndiscourse happen. Consequently, the main goal is to support the fight against\nnegative infodemic by (1) contributing a diverse set of curated relevant\ndatasets (2) recommending relevant areas to study using the datasets (3)\ndiscussion on how relevant datasets, strategies and state-of-the-art IT tools\ncan be leveraged in managing the pandemic.", "doi": "", "date": "2020-11-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.14146v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1922709808, "title": "The Fake News Effect: Experimentally Identifying Motivated Reasoning\n  Using Trust in News", "abstract": "Motivated reasoning posits that people distort how they process new\ninformation in the direction of beliefs they find more attractive. This paper\nintroduces a novel experimental paradigm that is able to portably identify\nmotivated reasoning from Bayesian updating across a variety of factual\nquestions; the paradigm analyzes how subjects assess the veracity of\ninformation sources that tell them the median of their belief distribution is\ntoo high or too low. A Bayesian would infer nothing about the source veracity\nfrom this message, but motivated reasoners would infer that the source were\nmore truthful if it reported the direction that they find more attractive. I\nfind novel evidence for politically-motivated reasoning about immigration,\nincome mobility, crime, racial discrimination, gender, climate change, gun\nlaws, and the performance of other subjects. Motivated reasoning from messages\non these topics leads people's beliefs to become more polarized, even though\nthe messages are uninformative.", "doi": "", "date": "2020-12-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.01663v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3742174547, "title": "Fact-Enhanced Synthetic News Generation", "abstract": "The advanced text generation methods have witnessed great success in text\nsummarization, language translation, and synthetic news generation. However,\nthese techniques can be abused to generate disinformation and fake news. To\nbetter understand the potential threats of synthetic news, we develop a new\ngeneration method FactGen to generate high-quality news content. The existing\ntext generation methods either afford limited supplementary information or lose\nconsistency between the input and output which makes the synthetic news less\ntrustworthy. To address these issues, FactGen retrieves external facts to\nenrich the output and reconstructs the input claim from the generated content\nto improve the consistency among the input and the output. Experiment results\non real-world datasets show that the generated news contents of FactGen are\nconsistent and contain rich facts. We also discuss the possible defending\nmethod to identify these synthetic news pieces if FactGen is used to generate\nsynthetic news.", "doi": "", "date": "2020-12-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.04778v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2229577551, "title": "Detecting Deepfake Videos Using Euler Video Magnification", "abstract": "Recent advances in artificial intelligence make it progressively hard to\ndistinguish between genuine and counterfeit media, especially images and\nvideos. One recent development is the rise of deepfake videos, based on\nmanipulating videos using advanced machine learning techniques. This involves\nreplacing the face of an individual from a source video with the face of a\nsecond person, in the destination video. This idea is becoming progressively\nrefined as deepfakes are getting progressively seamless and simpler to compute.\nCombined with the outreach and speed of social media, deepfakes could easily\nfool individuals when depicting someone saying things that never happened and\nthus could persuade people in believing fictional scenarios, creating distress,\nand spreading fake news. In this paper, we examine a technique for possible\nidentification of deepfake videos. We use Euler video magnification which\napplies spatial decomposition and temporal filtering on video data to highlight\nand magnify hidden features like skin pulsation and subtle motions. Our\napproach uses features extracted from the Euler technique to train three models\nto classify counterfeit and unaltered videos and compare the results with\nexisting techniques.", "doi": "10.2352/issn.2470-1173.2021.4.mwsf-272", "date": "2021-01-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.11563v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 162429357, "title": "Taxonomic survey of Hindi Language NLP systems", "abstract": "Natural Language processing (NLP) represents the task of automatic handling\nof natural human language by machines.There is large spectrum of possible\napplications of NLP which help in automating tasks like translating text from\none language to other, retrieving and summarizing data from very huge\nrepositories, spam email filtering, identifying fake news in digital media,\nfind sentiment and feedback of people, find political opinions and views of\npeople on various government policies, provide effective medical assistance\nbased on past history records of patient etc. Hindi is the official language of\nIndia with nearly 691 million users in India and 366 million in rest of world.\nAt present, a number of government and private sector projects and researchers\nin India and abroad, are working towards developing NLP applications and\nresources for Indian languages. This survey gives a report of the resources and\napplications available for Hindi language NLP.", "doi": "", "date": "2021-01-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.00214v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2576896097, "title": "TruthBot: An Automated Conversational Tool for Intent Learning, Curated\n  Information Presenting, and Fake News Alerting", "abstract": "We present TruthBot, an all-in-one multilingual conversational chatbot\ndesigned for seeking truth (trustworthy and verified information) on specific\ntopics. It helps users to obtain information specific to certain topics,\nfact-check information, and get recent news. The chatbot learns the intent of a\nquery by training a deep neural network from the data of the previous intents\nand responds appropriately when it classifies the intent in one of the classes\nabove. Each class is implemented as a separate module that uses either its own\ncurated knowledge-base or searches the web to obtain the correct information.\nThe topic of the chatbot is currently set to COVID-19. However, the bot can be\neasily customized to any topic-specific responses. Our experimental results\nshow that each module performs significantly better than its closest\ncompetitor, which is verified both quantitatively and through several\nuser-based surveys in multiple languages. TruthBot has been deployed in June\n2020 and is currently running.", "doi": "", "date": "2021-01-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.00509v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3893393845, "title": "Parameterized Complexity of Immunization in the Threshold Model", "abstract": "We consider the problem of controlling the spread of harmful items in\nnetworks, such as the contagion proliferation of diseases or the diffusion of\nfake news. We assume the linear threshold model of diffusion where each node\nhas a threshold that measures the node resistance to the contagion. We study\nthe parameterized complexity of the problem: Given a network, a set of\ninitially contaminated nodes, and two integers $k$ and $\\ell$, is it possible\nto limit the diffusion to at most $k$ other nodes of the network by immunizing\nat most $\\ell$ nodes? We consider several parameters associated to the input,\nincluding: the bounds $k$ and $\\ell$, the maximum node degree $\\Delta$, the\ntreewidth, and the neighborhood diversity of the network. We first give $W[1]$\nor $W[2]$-hardness results for each of the considered parameters. Then we give\nfixed-parameter algorithms for some parameter combinations.", "doi": "", "date": "2021-02-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.03537v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1322113724, "title": "SCARLET: Explainable Attention based Graph Neural Network for Fake News\n  spreader prediction", "abstract": "False information and true information fact checking it, often co-exist in\nsocial networks, each competing to influence people in their spread paths. An\nefficient strategy here to contain false information is to proactively identify\nif nodes in the spread path are likely to endorse false information (i.e.\nfurther spread it) or refutation information (thereby help contain false\ninformation spreading). In this paper, we propose SCARLET (truSt and\nCredibility bAsed gRaph neuraL nEtwork model using aTtention) to predict likely\naction of nodes in the spread path. We aggregate trust and credibility features\nfrom a node's neighborhood using historical behavioral data and network\nstructure and explain how features of a spreader's neighborhood vary. Using\nreal world Twitter datasets, we show that the model is able to predict false\ninformation spreaders with an accuracy of over 87%.", "doi": "", "date": "2021-02-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.04627v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2019176704, "title": "The Surprising Performance of Simple Baselines for Misinformation\n  Detection", "abstract": "As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.", "doi": "", "date": "2021-04-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.06952v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 363891168, "title": "Misinfo Belief Frames: A Case Study on Covid & Climate News", "abstract": "Prior beliefs of readers impact the way in which they project meaning onto\nnews headlines. These beliefs can influence their perception of news\nreliability, as well as their reaction to news, and their likelihood of\nspreading the misinformation through social networks. However, most prior work\nfocuses on fact-checking veracity of news or stylometry rather than measuring\nimpact of misinformation. We propose Misinfo Belief Frames, a formalism for\nunderstanding how readers perceive the reliability of news and the impact of\nmisinformation. We also introduce the Misinfo Belief Frames (MBF) corpus, a\ndataset of 66k inferences over 23.5k headlines. Misinformation frames use\ncommonsense reasoning to uncover implications of real and fake news headlines\nfocused on global crises: the Covid-19 pandemic and climate change. Our results\nusing large-scale language modeling to predict misinformation frames show that\nmachine-generated inferences can influence readers' trust in news headlines\n(readers' trust in news headlines was affected in 29.3% of cases). This\ndemonstrates the potential effectiveness of using generated frames to counter\nmisinformation.", "doi": "", "date": "2021-04-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.08790v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 899884108, "title": "Claim Detection in Biomedical Twitter Posts", "abstract": "Social media contains unfiltered and unique information, which is potentially\nof great value, but, in the case of misinformation, can also do great harm.\nWith regards to biomedical topics, false information can be particularly\ndangerous. Methods of automatic fact-checking and fake news detection address\nthis problem, but have not been applied to the biomedical domain in social\nmedia yet. We aim to fill this research gap and annotate a corpus of 1200\ntweets for implicit and explicit biomedical claims (the latter also with span\nannotations for the claim phrase). With this corpus, which we sample to be\nrelated to COVID-19, measles, cystic fibrosis, and depression, we develop\nbaseline models which detect tweets that contain a claim automatically. Our\nanalyses reveal that biomedical tweets are densely populated with claims (45 %\nin a corpus sampled to contain 1200 tweets focused on the domains mentioned\nabove). Baseline classification experiments with embedding-based classifiers\nand BERT-based transfer learning demonstrate that the detection is challenging,\nhowever, shows acceptable performance for the identification of explicit\nexpressions of claims. Implicit claim tweets are more challenging to detect.", "doi": "", "date": "2021-04-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.11639v2", "pdf": ""}, "publisher-venue": "the BioNLP Workshop at NAACL 2021", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2765957619, "title": "Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021", "abstract": "On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.", "doi": "", "date": "2021-04-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13352v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2520965492, "title": "WhatTheWikiFact: Fact-Checking Claims Against Wikipedia", "abstract": "The rise of Internet has made it a major source of information.\nUnfortunately, not all information online is true, and thus a number of\nfact-checking initiatives have been launched, both manual and automatic. Here,\nwe present our contribution in this regard: WhatTheWikiFact, a system for\nautomatic claim verification using Wikipedia. The system predicts the veracity\nof an input claim, and it further shows the evidence it has retrieved as part\nof the verification process. It shows confidence scores and a list of relevant\nWikipedia articles, together with detailed information about each article,\nincluding the phrase used to retrieve it, the most relevant sentences it\ncontains, and their stances with respect to the input claim, with associated\nprobabilities.", "doi": "", "date": "2021-04-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.00826v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 534316890, "title": "SemEval-2021 Task 6: Detection of Persuasion Techniques in Texts and\n  Images", "abstract": "We describe SemEval-2021 task 6 on Detection of Persuasion Techniques in\nTexts and Images: the data, the annotation guidelines, the evaluation setup,\nthe results, and the participating systems. The task focused on memes and had\nthree subtasks: (i) detecting the techniques in the text, (ii) detecting the\ntext spans where the techniques are used, and (iii) detecting techniques in the\nentire meme, i.e., both in the text and in the image. It was a popular task,\nattracting 71 registrations, and 22 teams that eventually made an official\nsubmission on the test set. The evaluation results for the third subtask\nconfirmed the importance of both modalities, the text and the image. Moreover,\nsome teams reported benefits when not just combining the two modalities, e.g.,\nby using early or late fusion, but rather modeling the interaction between them\nin a joint model.", "doi": "", "date": "2021-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.09284v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1995684860, "title": "Newsalyze: Enabling News Consumers to Understand Media Bias", "abstract": "News is a central source of information for individuals to inform themselves\non current topics. Knowing a news article's slant and authenticity is of\ncrucial importance in times of \"fake news,\" news bots, and centralization of\nmedia ownership. We introduce Newsalyze, a bias-aware news reader focusing on a\nsubtle, yet powerful form of media bias, named bias by word choice and labeling\n(WCL). WCL bias can alter the assessment of entities reported in the news,\ne.g., \"freedom fighters\" vs. \"terrorists.\" At the core of the analysis is a\nneural model that uses a news-adapted BERT language model to determine\ntarget-dependent sentiment, a high-level effect of WCL bias. While the analysis\ncurrently focuses on only this form of bias, the visualizations already reveal\npatterns of bias when contrasting articles (overview) and in-text instances of\nbias (article view).", "doi": "10.1145/3383583.3398561", "date": "2021-05-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.09672v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3934527491, "title": "Sockpuppet Detection: a Telegram case study", "abstract": "In Online Social Networks (OSN) numerous are the cases in which users create\nmultiple accounts that publicly seem to belong to different people but are\nactually fake identities of the same person. These fictitious characters can be\nexploited to carry out abusive behaviors such as manipulating opinions,\nspreading fake news and disturbing other users. In literature this problem is\nknown as the Sockpuppet problem. In our work we focus on Telegram, a\nwide-spread instant messaging application, often known for its exploitation by\nmembers of organized crime and terrorism, and more in general for its high\npresence of people who have offensive behaviors.", "doi": "10.5281/zenodo.4744934", "date": "2021-05-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.10799v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 115929516, "title": "Multimodal Detection of Information Disorder from Social Media", "abstract": "Social media is accompanied by an increasing proportion of content that\nprovides fake information or misleading content, known as information disorder.\nIn this paper, we study the problem of multimodal fake news detection on a\nlargescale multimodal dataset. We propose a multimodal network architecture\nthat enables different levels and types of information fusion. In addition to\nthe textual and visual content of a posting, we further leverage secondary\ninformation, i.e. user comments and metadata. We fuse information at multiple\nlevels to account for the specific intrinsic structure of the modalities. Our\nresults show that multimodal analysis is highly effective for the task and all\nmodalities contribute positively when fused properly.", "doi": "", "date": "2021-05-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.15165v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1728763202, "title": "Challenges and Considerations with Code-Mixed NLP for Multilingual\n  Societies", "abstract": "Multilingualism refers to the high degree of proficiency in two or more\nlanguages in the written and oral communication modes. It often results in\nlanguage mixing, a.k.a. code-mixing, when a multilingual speaker switches\nbetween multiple languages in a single utterance of a text or speech. This\npaper discusses the current state of the NLP research, limitations, and\nforeseeable pitfalls in addressing five real-world applications for social good\ncrisis management, healthcare, political campaigning, fake news, and hate\nspeech for multilingual societies. We also propose futuristic datasets, models,\nand tools that can significantly advance the current research in multilingual\nNLP applications for the societal good. As a representative example, we\nconsider English-Hindi code-mixing but draw similar inferences for other\nlanguage pairs", "doi": "", "date": "2021-06-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.07823v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 72275448, "title": "Visualizing Evolving Trees", "abstract": "Evolving trees arise in many real-life scenarios from computer file systems\nand dynamic call graphs, to fake news propagation and disease spread. Most\nlayout algorithms for static trees, however, do not work well in an evolving\nsetting (e.g., they are not designed to be stable between time steps). Dynamic\ngraph layout algorithms are better suited to this task, although they often\nintroduce unnecessary edge crossings. With this in mind we propose two methods\nfor visualizing evolving trees that guarantee no edge crossings, while\noptimizing (1) desired edge length realization, (2) layout compactness, and (3)\nstability. We evaluate the two new methods, along with four prior approaches\n(two static and two dynamic), on real-world datasets using quantitative\nmetrics: stress, desired edge length realization, layout compactness,\nstability, and running time. The new methods are fully functional and available\non github.", "doi": "", "date": "2021-06-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.08843v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1743934669, "title": "The hidden dependence of spreading vulnerability on topological\n  complexity", "abstract": "Many dynamical phenomena, e.g., pathogen transmission, disruptions in\ntransport over networks, and (fake) news purveyance, concern spreading that\nplays out on top of networks with changing architectures over time - commonly\nknown as temporal networks. Assessing a system's proneness to facilitate\nspreading phenomena, which we refer to as its spreading vulnerability, from its\ntopological information alone remains a challenging task. We report a\nmethodological advance in terms of a novel metric for topological complexity:\n'entanglement entropy'. Using publicly available datasets, we demonstrate that\nthe metric naturally allows for topological comparisons across vastly different\nsystems, and importantly, reveals that the spreading vulnerability of a system\ncan be quantitatively related to its topological complexity. In doing so, the\nmetric opens itself for applications in a wide variety of natural, social,\nbiological and engineered systems.", "doi": "", "date": "2021-07-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.01651v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 840841843, "title": "Tackling COVID-19 Infodemic using Deep Learning", "abstract": "Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia.", "doi": "", "date": "2021-07-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.02012v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1170808741, "title": "Combating fake news by empowering fact-checked news spread via\n  topology-based interventions", "abstract": "Rapid information diffusion and large-scaled information cascades can enable\nthe undesired spread of false information. A small-scaled false information\noutbreak may potentially lead to an infodemic. We propose a novel information\ndiffusion and intervention technique to combat the spread of false news. As\nfalse information is often spreading faster in a social network, the proposed\ndiffusion methodology inhibits the spread of false news by proactively\ndiffusing the fact-checked information. Our methodology mainly relies on\ndefining the potential super-spreaders in a social network based on their\ncentrality metrics. We run an extensive set of experiments on different\nnetworks to investigate the impact of centrality metrics on the performance of\nthe proposed diffusion and intervention models. The obtained results\ndemonstrate that empowering the diffusion of fact-checked news combats the\nspread of false news further and deeper in social networks.", "doi": "", "date": "2021-07-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.05016v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 706497914, "title": "Analysis of External Content in the Vaccination Discussion on Twitter", "abstract": "The spread of coronavirus and anti-vaccine conspiracies online hindered\npublic health responses to the pandemic. We examined the content of external\narticles shared on Twitter from February to June 2020 to understand how\nconspiracy theories and fake news competed with legitimate sources of\ninformation. Examining external content--articles, rather than social media\nposts--is a novel methodology that allows for non-social media specific\nanalysis of misinformation, tracking of changing narratives over time, and\ndetermining which types of resources (government, news, scientific, or dubious)\ndominate the pandemic vaccine conversation. We find that distinct narratives\nemerge, those narratives change over time, and lack of government and\nscientific messaging on coronavirus created an information vacuum filled by\nboth traditional news and conspiracy theories.", "doi": "", "date": "2021-07-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.09183v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 215336035, "title": "DeepTitle -- Leveraging BERT to generate Search Engine Optimized\n  Headlines", "abstract": "Automated headline generation for online news articles is not a trivial task\n- machine generated titles need to be grammatically correct, informative,\ncapture attention and generate search traffic without being \"click baits\" or\n\"fake news\". In this paper we showcase how a pre-trained language model can be\nleveraged to create an abstractive news headline generator for German language.\nWe incorporate state of the art fine-tuning techniques for abstractive text\nsummarization, i.e. we use different optimizers for the encoder and decoder\nwhere the former is pre-trained and the latter is trained from scratch. We\nmodify the headline generation to incorporate frequently sought keywords\nrelevant for search engine optimization. We conduct experiments on a German\nnews data set and achieve a ROUGE-L-gram F-score of 40.02. Furthermore, we\naddress the limitations of ROUGE for measuring the quality of text\nsummarization by introducing a sentence similarity metric and human evaluation.", "doi": "", "date": "2021-07-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.10935v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4094650879, "title": "Estudo Abordando o Contexto de Not\u00edcias Falsas em Pa\u00edses de L\u00edngua\n  Portuguesa (Fake News)", "abstract": "This work consists of a study that addresses the context of false news in the\nreality of today's world. False news is a widely used expression currently.\nDuring the study, it was possible to identify problems generalized about this\ntheme, such as the wide spread that these have and the impact they have on\nsociety. From these problems it was possible to identify more specific ones,\nsuch as the origin of the news, the news source, a person who shares and/or\ncreates news and the interpersonal relationship existing. With the\nidentification of the aforementioned sub-problems, it was possible develop a\ntaxonomic model with the aim of implementing a tool that helps in detecting\nfalse news, identifying if a news is true, false or whether the user must be\ncareful (when it is not possible identify whether the news is true or false).\nAfter implementation, it was possible get a tool that allows you to calculate a\nprobability of a news being false, selected as selected options in each\nparameter. It was also possible to verify that a probability was correct and\nthat the tool is reviewed in the study carried out.", "doi": "", "date": "2021-07-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.12831v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3908535536, "title": "Predicting the Factuality of Reporting of News Media Using Observations\n  About User Attention in Their YouTube Channels", "abstract": "We propose a novel framework for predicting the factuality of reporting of\nnews media outlets by studying the user attention cycles in their YouTube\nchannels. In particular, we design a rich set of features derived from the\ntemporal evolution of the number of views, likes, dislikes, and comments for a\nvideo, which we then aggregate to the channel level. We develop and release a\ndataset for the task, containing observations of user attention on YouTube\nchannels for 489 news media. Our experiments demonstrate both complementarity\nand sizable improvements over state-of-the-art textual representations.", "doi": "", "date": "2021-08-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12519v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 516016509, "title": "Interpretable Propaganda Detection in News Articles", "abstract": "Online users today are exposed to misleading and propagandistic news articles\nand media posts on a daily basis. To counter thus, a number of approaches have\nbeen designed aiming to achieve a healthier and safer online news and media\nconsumption. Automatic systems are able to support humans in detecting such\ncontent; yet, a major impediment to their broad adoption is that besides being\naccurate, the decisions of such systems need also to be interpretable in order\nto be trusted and widely adopted by users. Since misleading and propagandistic\ncontent influences readers through the use of a number of deception techniques,\nwe propose to detect and to show the use of such techniques as a way to offer\ninterpretability. In particular, we define qualitatively descriptive features\nand we analyze their suitability for detecting deception techniques. We further\nshow that our interpretable features can be easily combined with pre-trained\nlanguage models, yielding state-of-the-art results.", "doi": "", "date": "2021-08-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12802v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1962054596, "title": "WikiCheck: An end-to-end open source Automatic Fact-Checking API based\n  on Wikipedia", "abstract": "With the growth of fake news and disinformation, the NLP community has been\nworking to assist humans in fact-checking. However, most academic research has\nfocused on model accuracy without paying attention to resource efficiency,\nwhich is crucial in real-life scenarios. In this work, we review the\nState-of-the-Art datasets and solutions for Automatic Fact-checking and test\ntheir applicability in production environments. We discover overfitting issues\nin those models, and we propose a data filtering method that improves the\nmodel's performance and generalization. Then, we design an unsupervised\nfine-tuning of the Masked Language models to improve its accuracy working with\nWikipedia. We also propose a novel query enhancing method to improve evidence\ndiscovery using the Wikipedia Search API. Finally, we present a new\nfact-checking system, the \\textit{WikiCheck} API that automatically performs a\nfacts validation process based on the Wikipedia knowledge base. It is\ncomparable to SOTA solutions in terms of accuracy and can be used on low-memory\nCPU instances.", "doi": "", "date": "2021-09-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2109.00835v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2271826773, "title": "Algorithm and Implementation of the Blog-Post Supervision Process", "abstract": "A web log or blog in short is a trendy way to share personal entries with\nothers through website. A typical blog may consist of texts, images, audios and\nvideos etc. Most of the blogs work as personal online diaries, while others may\nfocus on specific interest such as photographs (photoblog), art (artblog),\ntravel (tourblog), IT (techblog) etc. Another type of blogging called\nmicroblogging is also very well known now-a-days which contains very short\nposts. Like the developed countries, the users of blogs are gradually\nincreasing in the developing countries e.g. Bangladesh. Due to the nature of\nopen access to all users, some people misuse it to spread fake news to achieve\nindividual or political goals. Some of them also post vulgar materials that\nmake an embarrass situation for other bloggers. Even, sometimes it indulges the\nreputation of the victim. The only way to overcome this problem is to bring all\nthe posts under supervision of the blog moderator. But it totally contradicts\nwith blogging concepts. In this paper, we have implemented an algorithm that\nwould help to prevent the offensive entries from being posted. These entries\nwould go through a supervision process to justify themselves as legal posts.\nFrom the analysis of the result, we have shown that this approach can eliminate\nthe chaotic situations in blogosphere at a great extent. Our experiment shows\nthat about 90% of offensive posts can be detected and stopped from being\npublished using this approach.", "doi": "", "date": "2010-06-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1006.4542v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 784216165, "title": "Blocking Self-avoiding Walks Stops Cyber-epidemics: A Scalable GPU-based\n  Approach", "abstract": "Cyber-epidemics, the widespread of fake news or propaganda through social\nmedia, can cause devastating economic and political consequences. A common\ncountermeasure against cyber-epidemics is to disable a small subset of\nsuspected social connections or accounts to effectively contain the epidemics.\nAn example is the recent shutdown of 125,000 ISIS-related Twitter accounts.\nDespite many proposed methods to identify such subset, none are scalable enough\nto provide high-quality solutions in nowadays billion-size networks.\n  To this end, we investigate the Spread Interdiction problems that seek most\neffective links (or nodes) for removal under the well-known Linear Threshold\nmodel. We propose novel CPU-GPU methods that scale to networks with billions of\nedges, yet, possess rigorous theoretical guarantee on the solution quality. At\nthe core of our methods is an $O(1)$-space out-of-core algorithm to generate a\nnew type of random walks, called Hitting Self-avoiding Walks (HSAWs). Such a\nlow memory requirement enables handling of big networks and, more importantly,\nhiding latency via scheduling of millions of threads on GPUs. Comprehensive\nexperiments on real-world networks show that our algorithms provides much\nhigher quality solutions and are several order of magnitude faster than the\nstate-of-the art. Comparing to the (single-core) CPU counterpart, our GPU\nimplementations achieve significant speedup factors up to 177x on a single GPU\nand 338x on a GPU pair.", "doi": "", "date": "2017-02-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1702.05854v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1333326211, "title": "Public discourse and news consumption on online social media: A\n  quantitative, cross-platform analysis of the Italian Referendum", "abstract": "The rising attention to the spreading of fake news and unsubstantiated rumors\non online social media and the pivotal role played by confirmation bias led\nresearchers to investigate different aspects of the phenomenon. Experimental\nevidence showed that confirmatory information gets accepted even if containing\ndeliberately false claims while dissenting information is mainly ignored or\nmight even increase group polarization. It seems reasonable that, to address\nmisinformation problem properly, we have to understand the main determinants\nbehind content consumption and the emergence of narratives on online social\nmedia. In this paper we address such a challenge by focusing on the discussion\naround the Italian Constitutional Referendum by conducting a quantitative,\ncross-platform analysis on both Facebook public pages and Twitter accounts. We\nobserve the spontaneous emergence of well-separated communities on both\nplatforms. Such a segregation is completely spontaneous, since no\ncategorization of contents was performed a priori. By exploring the dynamics\nbehind the discussion, we find that users tend to restrict their attention to a\nspecific set of Facebook pages/Twitter accounts. Finally, taking advantage of\nautomatic topic extraction and sentiment analysis techniques, we are able to\nidentify the most controversial topics inside and across both platforms. We\nmeasure the distance between how a certain topic is presented in the\nposts/tweets and the related emotional response of users. Our results provide\ninteresting insights for the understanding of the evolution of the core\nnarratives behind different echo chambers and for the early detection of\nmassive viral phenomena around false claims.", "doi": "", "date": "2017-02-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1702.06016v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1728993076, "title": "Exposing Computer Generated Images by Using Deep Convolutional Neural\n  Networks", "abstract": "The recent computer graphics developments have upraised the quality of the\ngenerated digital content, astonishing the most skeptical viewer. Games and\nmovies have taken advantage of this fact but, at the same time, these advances\nhave brought serious negative impacts like the ones yielded by fakeimages\nproduced with malicious intents. Digital artists can compose artificial images\ncapable of deceiving the great majority of people, turning this into a very\ndangerous weapon in a timespan currently know as Fake News/Post-Truth\" Era. In\nthis work, we propose a new approach for dealing with the problem of detecting\ncomputer generated images, through the application of deep convolutional\nnetworks and transfer learning techniques. We start from Residual Networks and\ndevelop different models adapted to the binary problem of identifying if an\nimage was or not computer generated. Differently from the current\nstate-of-the-art approaches, we don't rely on hand-crafted features, but\nprovide to the model the raw pixel information, achieving the same 0.97 of\nstate-of-the-art methods with two main advantages: our methods show more stable\nresults (depicted by lower variance) and eliminate the laborious and manual\nstep of specialized features extraction and selection.", "doi": "", "date": "2017-11-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.10394v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3427752371, "title": "How Unequal Fluxes of High Energy Astrophysical Neutrinos and\n  Antineutrinos can Fake New Physics", "abstract": "Flavor ratios of very high energy astrophysical neutrinos, which can be\nstudied at the Earth by a neutrino telescope such as IceCube, can serve to\ndiagnose their production mechanism at the astrophysical source. The flavor\nratios for neutrinos and antineutrinos can be quite different as we do not know\nhow they are produced in the astrophysical environment. Due to this uncertainty\nthe neutrino and antineutrino flavor ratios at the Earth also could be quite\ndifferent. Nonetheless, it is generally assumed that flavor ratios for\nneutrinos and antineutrinos are the same at the Earth, in fitting the high\nenergy astrophysical neutrino data. This is a reasonable assumption for the\nlimited statistics for the data we currently have. However, in the future the\nfit must be performed allowing for a possible discrepancy in these two\nfractions in order to be able to disentangle different production mechanisms at\nthe source from new physics in the neutrino sector. To reinforce this issue, in\nthis work we show that a wrong assumption about the distribution of neutrino\nflavor ratios at the Earth may indeed lead to misleading interpretations of\nIceCube results.", "doi": "10.1088/1475-7516/2016/10/036", "date": "2016-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1604.08595v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1708212205, "title": "Investigating Rumor News Using Agreement-Aware Search", "abstract": "Recent years have witnessed a widespread increase of rumor news generated by\nhumans and machines. Therefore, tools for investigating rumor news have become\nan urgent necessity. One useful function of such tools is to see ways a\nspecific topic or event is represented by presenting different points of view\nfrom multiple sources.\n  In this paper, we propose Maester, a novel agreement-aware search framework\nfor investigating rumor news. Given an investigative question, Maester will\nretrieve related articles to that question, assign and display top articles\nfrom agree, disagree, and discuss categories to users. Splitting the results\ninto these three categories provides the user a holistic view towards the\ninvestigative question. We build Maester based on the following two key\nobservations: (1) relatedness can commonly be determined by keywords and\nentities occurring in both questions and articles, and (2) the level of\nagreement between the investigative question and the related news article can\noften be decided by a few key sentences. Accordingly, we use gradient boosting\ntree models with keyword/entity matching features for relatedness detection,\nand leverage recurrent neural network to infer the level of agreement. Our\nexperiments on the Fake News Challenge (FNC) dataset demonstrate up to an order\nof magnitude improvement of Maester over the original FNC winning solution, for\nagreement-aware search.", "doi": "10.1145/3269206.3272020", "date": "2018-02-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1802.07398v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 437533539, "title": "Anatomy of an online misinformation network", "abstract": "Massive amounts of fake news and conspiratorial content have spread over\nsocial media before and after the 2016 US Presidential Elections despite\nintense fact-checking efforts. How do the spread of misinformation and\nfact-checking compete? What are the structural and dynamic characteristics of\nthe core of the misinformation diffusion network, and who are its main\npurveyors? How to reduce the overall amount of misinformation? To explore these\nquestions we built Hoaxy, an open platform that enables large-scale, systematic\nstudies of how misinformation and fact-checking spread and compete on Twitter.\nHoaxy filters public tweets that include links to unverified claims or\nfact-checking articles. We perform k-core decomposition on a diffusion network\nobtained from two million retweets produced by several hundred thousand\naccounts over the six months before the election. As we move from the periphery\nto the core of the network, fact-checking nearly disappears, while social bots\nproliferate. The number of users in the main core reaches equilibrium around\nthe time of the election, with limited churn and increasingly dense\nconnections. We conclude by quantifying how effectively the network can be\ndisrupted by penalizing the most central nodes. These findings provide a first\nlook at the anatomy of a massive online misinformation diffusion network.", "doi": "10.1371/journal.pone.0196087", "date": "2018-01-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1801.06122v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1237972329, "title": "Image Provenance Analysis at Scale", "abstract": "Prior art has shown it is possible to estimate, through image processing and\ncomputer vision techniques, the types and parameters of transformations that\nhave been applied to the content of individual images to obtain new images.\nGiven a large corpus of images and a query image, an interesting further step\nis to retrieve the set of original images whose content is present in the query\nimage, as well as the detailed sequences of transformations that yield the\nquery image given the original images. This is a problem that recently has\nreceived the name of image provenance analysis. In these times of public media\nmanipulation ( e.g., fake news and meme sharing), obtaining the history of\nimage transformations is relevant for fact checking and authorship\nverification, among many other applications. This article presents an\nend-to-end processing pipeline for image provenance analysis, which works at\nreal-world scale. It employs a cutting-edge image filtering solution that is\ncustom-tailored for the problem at hand, as well as novel techniques for\nobtaining the provenance graph that expresses how the images, as nodes, are\nancestrally connected. A comprehensive set of experiments for each stage of the\npipeline is provided, comparing the proposed solution with state-of-the-art\nresults, employing previously published datasets. In addition, this work\nintroduces a new dataset of real-world provenance cases from the social media\nsite Reddit, along with baseline results.", "doi": "", "date": "2018-01-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1801.06510v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1416858474, "title": "On Human Predictions with Explanations and Predictions of Machine\n  Learning Models: A Case Study on Deception Detection", "abstract": "Humans are the final decision makers in critical tasks that involve ethical\nand legal concerns, ranging from recidivism prediction, to medical diagnosis,\nto fighting against fake news. Although machine learning models can sometimes\nachieve impressive performance in these tasks, these tasks are not amenable to\nfull automation. To realize the potential of machine learning for improving\nhuman decisions, it is important to understand how assistance from machine\nlearning models affects human performance and human agency.\n  In this paper, we use deception detection as a testbed and investigate how we\ncan harness explanations and predictions of machine learning models to improve\nhuman performance while retaining human agency. We propose a spectrum between\nfull human agency and full automation, and develop varying levels of machine\nassistance along the spectrum that gradually increase the influence of machine\npredictions. We find that without showing predicted labels, explanations alone\nslightly improve human performance in the end task. In comparison, human\nperformance is greatly improved by showing predicted labels (>20% relative\nimprovement) and can be further improved by explicitly suggesting strong\nmachine performance. Interestingly, when predicted labels are shown,\nexplanations of machine predictions induce a similar level of accuracy as an\nexplicit statement of strong machine performance. Our results demonstrate a\ntradeoff between human performance and human agency and show that explanations\nof machine predictions can moderate this tradeoff.", "doi": "10.1145/3287560.3287590", "date": "2018-11-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.07901v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2936607045, "title": "Constant State of Change: Engagement Inequality in Temporal Dynamic\n  Networks", "abstract": "The temporal changes in complex systems of interactions have excited the\nresearch community in recent years as they encompass understandings on their\ndynamics and evolution. From the collective dynamics of organizations and\nonline communities to the spreading of information and fake news, to name a\nfew, temporal dynamics are fundamental in the understanding of complex systems.\nIn this work, we quantify the level of engagement in dynamic complex systems of\ninteractions, modeled as networks. We focus on interaction networks for which\nthe dynamics of the interactions are coupled with that of the topology, such as\nonline messaging, forums, and emails. We define two indices to capture the\ntemporal level of engagement: the Temporal Network (edge) Intensity index, and\nthe Temporal Dominance Inequality index. Our surprising results are that these\nmeasures are stationary for most measured networks, regardless of vast\nfluctuations in the size of the networks in time. Moreover, more than 80% of\nweekly changes in the indices values are bounded by less than 10%. The indices\nare stable between the temporal evolution of a network but are different\nbetween networks, and a classifier can determine the network the temporal\nindices belong to with high success. We find an exception in the Enron\nmanagement email exchange during the year before its disintegration, in which\nboth indices show high volatility throughout the inspected period.", "doi": "10.1371/journal.pone.0231035", "date": "2019-10-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.01722v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2384037954, "title": "SCG: Spotting Coordinated Groups in Social Media", "abstract": "Recent events have led to a burgeoning awareness on the misuse of social\nmedia sites to affect political events, sway public opinion, and confuse the\nvoters. Such serious, hostile mass manipulation has motivated a large body of\nworks on bots/troll detection and fake news detection, which mostly focus on\nclassifying at the user level based on the content generated by the users. In\nthis study, we jointly analyze the connections among the users, as well as the\ncontent generated by them to Spot Coordinated Groups (SCG), sets of users that\nare likely to be organized towards impacting the general discourse. Given their\ntiny size (relative to the whole data), detecting these groups is\ncomputationally hard. Our proposed method detects these tiny-clusters\neffectively and efficiently. We deploy our SCG method to summarize and explain\nthe coordinated groups on Twitter around the 2019 Canadian Federal Elections,\nby analyzing over 60 thousand user accounts with 3.4 million followership\nconnections, and 1.3 million unique hashtags in the content of their tweets.\nThe users in the detected coordinated groups are over 4x more likely to get\nsuspended, whereas the hashtags which characterize their creed are linked to\nmisinformation campaigns.", "doi": "", "date": "2019-10-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.07130v5", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2065568351, "title": "Some Like it Hoax: Automated Fake News Detection in Social Networks", "abstract": "In recent years, the reliability of information on the Internet has emerged\nas a crucial issue of modern society. Social network sites (SNSs) have\nrevolutionized the way in which information is spread by allowing users to\nfreely share content. As a consequence, SNSs are also increasingly used as\nvectors for the diffusion of misinformation and hoaxes. The amount of\ndisseminated information and the rapidity of its diffusion make it practically\nimpossible to assess reliability in a timely manner, highlighting the need for\nautomatic hoax detection systems.\n  As a contribution towards this objective, we show that Facebook posts can be\nclassified with high accuracy as hoaxes or non-hoaxes on the basis of the users\nwho \"liked\" them. We present two classification techniques, one based on\nlogistic regression, the other on a novel adaptation of boolean crowdsourcing\nalgorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users,\nwe obtain classification accuracies exceeding 99% even when the training set\ncontains less than 1% of the posts. We further show that our techniques are\nrobust: they work even when we restrict our attention to the users who like\nboth hoax and non-hoax posts. These results suggest that mapping the diffusion\npattern of information can be a useful component of automatic hoax detection\nsystems.", "doi": "", "date": "2017-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1704.07506v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3714693116, "title": "Evaluation Measures for Relevance and Credibility in Ranked Lists", "abstract": "Recent discussions on alternative facts, fake news, and post truth politics\nhave motivated research on creating technologies that allow people not only to\naccess information, but also to assess the credibility of the information\npresented to them by information retrieval systems. Whereas technology is in\nplace for filtering information according to relevance and/or credibility, no\nsingle measure currently exists for evaluating the accuracy or precision (and\nmore generally effectiveness) of both the relevance and the credibility of\nretrieved results. One obvious way of doing so is to measure relevance and\ncredibility effectiveness separately, and then consolidate the two measures\ninto one. There at least two problems with such an approach: (I) it is not\ncertain that the same criteria are applied to the evaluation of both relevance\nand credibility (and applying different criteria introduces bias to the\nevaluation); (II) many more and richer measures exist for assessing relevance\neffectiveness than for assessing credibility effectiveness (hence risking\nfurther bias).\n  Motivated by the above, we present two novel types of evaluation measures\nthat are designed to measure the effectiveness of both relevance and\ncredibility in ranked lists of retrieval results. Experimental evaluation on a\nsmall human-annotated dataset (that we make freely available to the research\ncommunity) shows that our measures are expressive and intuitive in their\ninterpretation.", "doi": "", "date": "2017-08-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1708.07157v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 568837918, "title": "A Bias Aware News Recommendation System", "abstract": "In this era of fake news and political polarization, it is desirable to have\na system to enable users to access balanced news content. Current solutions\nfocus on top down, server based approaches to decide whether a news article is\nfake or biased, and display only trusted news to the end users. In this paper,\nwe follow a different approach to help the users make informed choices about\nwhich news they want to read, making users aware in real time of the bias in\nnews articles they were browsing and recommending news articles from other\nsources on the same topic with different levels of bias. We use a recent Pew\nresearch report to collect news sources that readers with varying political\ninclinations prefer to read. We then scrape news articles on a variety of\ntopics from these varied news sources. After this, we perform clustering to\nfind similar topics of the articles, as well as calculate a bias score for each\narticle. For a news article the user is currently reading, we display the bias\nscore and also display other articles on the same topic, out of the previously\ncollected articles, from different news sources. This we present to the user.\nThis approach, we hope, would make it possible for users to access more\nbalanced articles on given news topics. We present the implementation details\nof the system along with some preliminary results on news articles.", "doi": "", "date": "2018-03-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1803.03428v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1767965987, "title": "Real Time Sentiment Change Detection of Twitter Data Streams", "abstract": "In the past few years, there has been a huge growth in Twitter sentiment\nanalysis having already provided a fair amount of research on sentiment\ndetection of public opinion among Twitter users. Given the fact that Twitter\nmessages are generated constantly with dizzying rates, a huge volume of\nstreaming data is created, thus there is an imperative need for accurate\nmethods for knowledge discovery and mining of this information. Although there\nexists a plethora of twitter sentiment analysis methods in the recent\nliterature, the researchers have shifted to real-time sentiment identification\non twitter streaming data, as expected. A major challenge is to deal with the\nBig Data challenges arising in Twitter streaming applications concerning both\nVolume and Velocity. Under this perspective, in this paper, a methodological\napproach based on open source tools is provided for real-time detection of\nchanges in sentiment that is ultra efficient with respect to both memory\nconsumption and computational cost. This is achieved by iteratively collecting\ntweets in real time and discarding them immediately after their process. For\nthis purpose, we employ the Lexicon approach for sentiment characterizations,\nwhile change detection is achieved through appropriate control charts that do\nnot require historical information. We believe that the proposed methodology\nprovides the trigger for a potential large-scale monitoring of threads in an\nattempt to discover fake news spread or propaganda efforts in their early\nstages. Our experimental real-time analysis based on a recent hashtag provides\nevidence that the proposed approach can detect meaningful sentiment changes\nacross a hashtags lifetime.", "doi": "10.1109/inista.2018.8466326", "date": "2018-04-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.00482v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3600817422, "title": "Real-time Detection of Content Polluters in Partially Observable Twitter\n  Networks", "abstract": "Content polluters, or bots that hijack a conversation for political or\nadvertising purposes are a known problem for event prediction, election\nforecasting and when distinguishing real news from fake news in social media\ndata. Identifying this type of bot is particularly challenging, with\nstate-of-the-art methods utilising large volumes of network data as features\nfor machine learning models. Such datasets are generally not readily available\nin typical applications which stream social media data for real-time event\nprediction. In this work we develop a methodology to detect content polluters\nin social media datasets that are streamed in real-time. Applying our method to\nthe problem of civil unrest event prediction in Australia, we identify content\npolluters from individual tweets, without collecting social network or\nhistorical data from individual accounts. We identify some peculiar\ncharacteristics of these bots in our dataset and propose metrics for\nidentification of such accounts. We then pose some research questions around\nthis type of bot detection, including: how good Twitter is at detecting content\npolluters and how well state-of-the-art methods perform in detecting bots in\nour dataset.", "doi": "", "date": "2018-04-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.01235v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 478563974, "title": "AbuSniff: Automatic Detection and Defenses Against Abusive Facebook\n  Friends", "abstract": "Adversaries leverage social network friend relationships to collect sensitive\ndata from users and target them with abuse that includes fake news,\ncyberbullying, malware, and propaganda. Case in point, 71 out of 80 user study\nparticipants had at least 1 Facebook friend with whom they never interact,\neither in Facebook or in real life, or whom they believe is likely to abuse\ntheir posted photos or status updates, or post offensive, false or malicious\ncontent. We introduce AbuSniff, a system that identifies Facebook friends\nperceived as strangers or abusive, and protects the user by unfriending,\nunfollowing, or restricting the access to information for such friends. We\ndevelop a questionnaire to detect perceived strangers and friend abuse.We\nintroduce mutual Facebook activity features and show that they can train\nsupervised learning algorithms to predict questionnaire responses. We have\nevaluated AbuSniff through several user studies with a total of 263\nparticipants from 25 countries. After answering the questionnaire, participants\nagreed to unfollow and restrict abusers in 91.6% and 90.9% of the cases\nrespectively, and sandbox or unfriend non-abusive strangers in 92.45% of the\ncases. Without answering the questionnaire, participants agreed to take the\nAbuSniff suggested action against friends predicted to be strangers or abusive,\nin 78.2% of the cases. AbuSniff increased the participant self-reported\nwillingness to reject invitations from strangers and abusers, their awareness\nof friend abuse implications and their perceived protection from friend abuse.", "doi": "", "date": "2018-04-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.10159v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2365816725, "title": "More or Less? Predict the Social Influence of Malicious URLs on Social\n  Media", "abstract": "Users of Online Social Networks (OSNs) interact with each other more than\never. In the context of a public discussion group, people receive, read, and\nwrite comments in response to articles and postings. In the absence of access\ncontrol mechanisms, OSNs are a great environment for attackers to influence\nothers, from spreading phishing URLs, to posting fake news. Moreover, OSN user\nbehavior can be predicted by social science concepts which include conformity\nand the bandwagon effect. In this paper, we show how social recommendation\nsystems affect the occurrence of malicious URLs on Facebook. We exploit\ntemporal features to build a prediction framework, having greater than 75%\naccuracy, to predict whether the following group users' behavior will increase\nor not. Included in this work, we demarcate classes of URLs, including those\nmalicious URLs classified as creating critical damage, as well as those of a\nlesser nature which only inflict light damage such as aggressive commercial\nadvertisements and spam content. It is our hope that the data and analyses in\nthis paper provide a better understanding of OSN user reactions to different\ncategories of malicious URLs, thereby providing a way to mitigate the influence\nof these malicious URL attacks.", "doi": "", "date": "2018-12-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.02978v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 939609288, "title": "Socratrees: Exploring the Design of Argument Technology for Layman Users", "abstract": "Terms like 'misinformation', 'fake news', and 'echo chambers' permeate\ncurrent discussions on the state of the Internet. We believe a lack of\ntechnological support to evaluate, contest, and reason about information\nonline---as opposed to merely disseminating it---lies at the root of these\nproblems. Several argument technologies support such functionality, but have\nseen limited use outside of niche communities. Most research systems\noveremphasize argument analysis and structure, standing in stark contrast with\nthe informal dialectical nature of everyday argumentation. Conversely,\nnon-academic systems overlook important implications for design which can be\nderived from theory. In this paper, we present the design of a system aiming to\nstrike a balance between structured argumentation and ease of use. Socratrees\nis a website for collaborative argumentative discussion targeting layman users,\nbut includes sophisticated community guidelines and novel features inspired by\ninformal logic. During an exploratory study, we evaluate the usefulness of our\nimposed structure on argumentation and investigate how users perceive it.\nContributing to arguments remains a complex task, but most users learned to do\nso effectively with minimal guidance and all recognized that the structure of\nSocratrees may improve online discussion and results in a clearer overview of\narguments.", "doi": "", "date": "2018-12-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.04478v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3543653369, "title": "Influence Minimization Under Budget and Matroid Constraints: Extended\n  Version", "abstract": "Recently, online social networks have become major battlegrounds for\npolitical campaigns, viral marketing, and the dissemination of news. As a\nconsequence, ''bad actors'' are increasingly exploiting these platforms,\nbecoming a key challenge for their administrators, businesses and the society\nin general. The spread of fake news is a classical example of the abuse of\nsocial networks by these actors. While some have advocated for stricter\npolicies to control the spread of misinformation in social networks, this often\nhappens in detriment of their democratic and organic structure. In this paper\nwe study how to limit the influence of a target set of users in a network via\nthe removal of a few edges. The idea is to control the diffusion processes\nwhile minimizing the amount of disturbance in the network structure.\n  We formulate the influence limitation problem in a data-driven fashion, by\ntaking into account past propagation traces. Moreover, we consider two types of\nconstraints over the set of edge removals, a budget constraint and also a, more\ngeneral, set of matroid constraints. These problems lead to interesting\nchallenges in terms of algorithm design. For instance, we are able to show that\ninfluence limitation is APX-hard and propose deterministic and probabilistic\napproximation algorithms for the budgeted and matroid version of the problem,\nrespectively. Our experiments show that the proposed solutions outperform the\nbaselines by up to 40%.", "doi": "", "date": "2019-01-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.02156v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2015935537, "title": "FaceForensics++: Learning to Detect Manipulated Facial Images", "abstract": "The rapid progress in synthetic image generation and manipulation has now\ncome to a point where it raises significant concerns for the implications\ntowards society. At best, this leads to a loss of trust in digital content, but\ncould potentially cause further harm by spreading false information or fake\nnews. This paper examines the realism of state-of-the-art image manipulations,\nand how difficult it is to detect them, either automatically or by humans. To\nstandardize the evaluation of detection methods, we propose an automated\nbenchmark for facial manipulation detection. In particular, the benchmark is\nbased on DeepFakes, Face2Face, FaceSwap and NeuralTextures as prominent\nrepresentatives for facial manipulations at random compression level and size.\nThe benchmark is publicly available and contains a hidden test set as well as a\ndatabase of over 1.8 million manipulated images. This dataset is over an order\nof magnitude larger than comparable, publicly available, forgery datasets.\nBased on this data, we performed a thorough analysis of data-driven forgery\ndetectors. We show that the use of additional domainspecific knowledge improves\nforgery detection to unprecedented accuracy, even in the presence of strong\ncompression, and clearly outperforms human observers.", "doi": "", "date": "2019-01-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.08971v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2855507062, "title": "Identification and Estimation of Causal Effects from Dependent Data", "abstract": "The assumption that data samples are independent and identically distributed\n(iid) is standard in many areas of statistics and machine learning.\nNevertheless, in some settings, such as social networks, infectious disease\nmodeling, and reasoning with spatial and temporal data, this assumption is\nfalse. An extensive literature exists on making causal inferences under the iid\nassumption [18, 12, 28, 22], even when unobserved confounding bias may be\npresent. But, as pointed out in [20], causal inference in non-iid contexts is\nchallenging due to the presence of both unobserved confounding and data\ndependence. In this paper we develop a general theory describing when causal\ninferences are possible in such scenarios. We use segregated graphs [21], a\ngeneralization of latent projection mixed graphs [30], to represent causal\nmodels of this type and provide a complete algorithm for non-parametric\nidentification in these models. We then demonstrate how statistical inference\nmay be performed on causal parameters identified by this algorithm. In\nparticular, we consider cases where only a single sample is available for parts\nof the model due to full interference, i.e., all units are pathwise dependent\nand neighbors' treatments affect each others' outcomes [26]. We apply these\ntechniques to a synthetic data set which considers users sharing fake news\narticles given the structure of their social network, user activity levels, and\nbaseline demographics and socioeconomic covariates.", "doi": "", "date": "2019-02-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.01443v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2956893372, "title": "Hawkes Process for Understanding the Influence of Pathogenic Social\n  Media Accounts", "abstract": "Over the past years, political events and public opinion on the Web have been\nallegedly manipulated by accounts dedicated to spreading disinformation and\nperforming malicious activities on social media. These accounts hereafter\nreferred to as \"Pathogenic Social Media (PSM)\" accounts, are often controlled\nby terrorist supporters, water armies or fake news writers and hence can pose\nthreats to social media and general public. Understanding and analyzing PSMs\ncould help social media firms devise sophisticated and automated techniques\nthat could be deployed to stop them from reaching their audience and\nconsequently reduce their threat. In this paper, we leverage the well-known\nstatistical technique \"Hawkes Process\" to quantify the influence of PSM\naccounts on the dissemination of malicious information on social media\nplatforms. Our findings on a real-world ISIS-related dataset from Twitter\nindicate that PSMs are significantly different from regular users in making a\nmessage viral. Specifically, we observed that PSMs do not usually post URLs\nfrom mainstream news sources. Instead, their tweets usually receive large\nimpact on audience, if contained URLs from Facebook and alternative news\noutlets. In contrary, tweets posted by regular users receive nearly equal\nimpression regardless of the posted URLs and their sources. Our findings can\nfurther shed light on understanding and detecting PSM accounts.", "doi": "", "date": "2019-02-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.01970v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1955150321, "title": "Contributive Social Capital Extraction From Different Types of Online\n  Data Sources", "abstract": "It is a recurring problem of online communication that the properties of\nunknown people are hard to assess. This may lead to various issues such as the\nspread of `fake news' from untrustworthy sources. In sociology the sum of\n(social) resources available to a person through their social network is often\ndescribed as social capital. In this article, we look at social capital from a\ndifferent angle. Instead of evaluating the advantage that people have because\nof their membership in a certain group, we investigate various ways to infer\nthe social capital a person adds or may add to the network, their contributive\nsocial capital (CSC). As there is no consensus in the literature on what the\nsocial capital of a person exactly consists of, we look at various related\nproperties: expertise, reputation, trustworthiness, and influence. The analysis\nof these features is investigated for five different sources of online data:\nmicroblogging (e.g., Twitter), social networking platforms (e.g., Facebook),\ndirect communication (e.g., email), scientometrics, and threaded discussion\nboards (e.g., Reddit). In each field we discuss recent publications and put a\nfocus on the data sources used, the algorithms implemented, and the performance\nevaluation. The findings are compared and set in context to contributive social\ncapital extraction. The analysis algorithms are based on individual features\n(e.g., followers on Twitter), ratios thereof, or a person's centrality measures\n(e.g., PageRank). The machine learning approaches, such as straightforward\nclassifiers (e.g., support vector machines) use ground truths that are\nconnected to social capital. The discussion of these methods is intended to\nfacilitate research on the topic by identifying relevant data sources and the\nbest suited algorithms, and by providing tested methods for the evaluation of\nfindings.", "doi": "", "date": "2019-02-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.07636v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 724805736, "title": "Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking", "abstract": "Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.", "doi": "", "date": "2019-03-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.08404v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3813592798, "title": "Temporal Ordered Clustering in Dynamic Networks: Unsupervised and\n  Semi-supervised Learning Algorithms", "abstract": "In temporal ordered clustering, given a single snapshot of a dynamic network\nin which nodes arrive at distinct time instants, we aim at partitioning its\nnodes into $K$ ordered clusters $\\mathcal{C}_1 \\prec \\cdots \\prec\n\\mathcal{C}_K$ such that for $i<j$, nodes in cluster $\\mathcal{C}_i$ arrived\nbefore nodes in cluster $\\mathcal{C}_j$, with $K$ being a data-driven parameter\nand not known upfront. Such a problem is of considerable significance in many\napplications ranging from tracking the expansion of fake news to mapping the\nspread of information. We first formulate our problem for a general dynamic\ngraph, and propose an integer programming framework that finds the optimal\nclustering, represented as a strict partial order set, achieving the best\nprecision (i.e., fraction of successfully ordered node pairs) for a fixed\ndensity (i.e., fraction of comparable node pairs). We then develop a sequential\nimportance procedure and design unsupervised and semi-supervised algorithms to\nfind temporal ordered clusters that efficiently approximate the optimal\nsolution. To illustrate the techniques, we apply our methods to the vertex\ncopying (duplication-divergence) model which exhibits some edge-case challenges\nin inferring the clusters as compared to other network models. Finally, we\nvalidate the performance of the proposed algorithms on synthetic and real-world\nnetworks.", "doi": "", "date": "2019-05-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.00672v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3826012529, "title": "Measuring the engagement level in encrypted group conversations by using\n  temporal networks", "abstract": "Chat groups are well-known for their capacity to promote viral political and\nmarketing campaigns, spread fake news, and create rallies by hundreds of\nthousands on the streets. Also, with the increasing public awareness regarding\nprivacy and surveillance, many platforms have started to deploy end-to-end\nencrypted protocols. In this context, the group's conversations are not\naccessible in plain text or readable format by third-party organizations or\neven the platform owner. Then, the main challenge that emerges is related to\ngetting insights from users' activity of those groups, but without accessing\nthe messages. Previous approaches evaluated the user engagement by assessing\nuser's activity, however, on limited conditions where the data is encrypted,\nthey cannot be applied. In this work, we present a framework for measuring the\nlevel of engagement of group conversations and users, without reading the\nmessages. Our framework creates an ensemble of interaction networks that\nrepresent the temporal evolution of the conversation, then, we apply the\nproposed Engagement Index (EI) for each interval of conversations to assess\nusers' participation. Our results in five datasets from real-world WhatsApp\nGroups indicate that, based on the EI, it is possible to identify the most\nengaged users within a time interval, create rankings, and group users\naccording to their engagement and monitor their performance over time.", "doi": "", "date": "2019-06-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.08875v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2272093445, "title": "On the Importance of Delexicalization for Fact Verification", "abstract": "In this work we aim to understand and estimate the importance that a neural\nnetwork assigns to various aspects of the data while learning and making\npredictions. Here we focus on the recognizing textual entailment (RTE) task and\nits application to fact verification. In this context, the contributions of\nthis work are as follows. We investigate the attention weights a state of the\nart RTE method assigns to input tokens in the RTE component of fact\nverification systems, and confirm that most of the weight is assigned to POS\ntags of nouns (e.g., NN, NNP etc.) or their phrases. To verify that these\nlexicalized models transfer poorly, we implement a domain transfer experiment\nwhere a RTE component is trained on the FEVER data, and tested on the Fake News\nChallenge (FNC) dataset. As expected, even though this method achieves high\naccuracy when evaluated in the same domain, the performance in the target\ndomain is poor, marginally above chance.To mitigate this dependence on\nlexicalized information, we experiment with several strategies for masking out\nnames by replacing them with their semantic category, coupled with a unique\nidentifier to mark that the same or new entities are referenced between claim\nand evidence. The results show that, while the performance on the FEVER dataset\nremains at par with that of the model trained on lexicalized data, it improves\nsignificantly when tested in the FNC dataset. Thus our experiments demonstrate\nthat our strategy is successful in mitigating the dependency on lexical\ninformation.", "doi": "10.18653/v1/d19-1340", "date": "2019-09-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.09868v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3549701315, "title": "From classical to modern opinion dynamics", "abstract": "In this age of Facebook, Instagram and Twitter, there is rapidly growing\ninterest in understanding network-enabled opinion dynamics in large groups of\nautonomous agents. The phenomena of opinion polarization, the spread of\npropaganda and fake news, and the manipulation of sentiment are of interest to\nlarge numbers of organizations and people, some of whom are resource rich.\nWhether it is the more nefarious players such as foreign governments that are\nattempting to sway elections or large corporations that are trying to bend\nsentiment -- often quite surreptitiously, or it is more open and above board,\nlike researchers that want to spread the news of some finding or some business\ninterest that wants to make a large group of people aware of genuinely helpful\ninnovations that they are marketing, what is at stake is often significant. In\nthis paper we review many of the classical, and some of the new, social\ninteraction models aimed at understanding opinion dynamics. While the first\npapers studying opinion dynamics appeared over 60 years ago, there is still a\ngreat deal of room for innovation and exploration. We believe that the\npolitical climate and the extraordinary (even unprecedented) events in the\nsphere of politics in the last few years will inspire new interest and new\nideas. It is our aim to help those interested researchers understand what has\nalready been explored in a significant portion of the field of opinion\ndynamics. We believe that in doing this, it will become clear that there is\nstill much to be done.", "doi": "10.1142/s0129183120501016", "date": "2019-09-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.12089v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3004357316, "title": "SpoC: Spoofing Camera Fingerprints", "abstract": "Thanks to the fast progress in synthetic media generation, creating realistic\nfalse images has become very easy. Such images can be used to wrap \"rich\" fake\nnews with enhanced credibility, spawning a new wave of high-impact, high-risk\nmisinformation campaigns. Therefore, there is a fast-growing interest in\nreliable detectors of manipulated media. The most powerful detectors, to date,\nrely on the subtle traces left by any device on all images acquired by it. In\nparticular, due to proprietary in-camera processes, like demosaicing or\ncompression, each camera model leaves trademark traces that can be exploited\nfor forensic analyses. The absence or distortion of such traces in the target\nimage is a strong hint of manipulation. In this paper, we challenge such\ndetectors to gain better insight into their vulnerabilities. This is an\nimportant study in order to build better forgery detectors able to face\nmalicious attacks. Our proposal consists of a GAN-based approach that injects\ncamera traces into synthetic images. Given a GAN-generated image, we insert the\ntraces of a specific camera model into it and deceive state-of-the-art\ndetectors into believing the image was acquired by that model. Likewise, we\ndeceive independent detectors of synthetic GAN images into believing the image\nis real. Experiments prove the effectiveness of the proposed method in a wide\narray of conditions. Moreover, no prior information on the attacked detectors\nis needed, but only sample images from the target camera.", "doi": "", "date": "2019-11-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.12069v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2149777218, "title": "Information Credibility in the Social Web: Contexts, Approaches, and\n  Open Issues", "abstract": "In the Social Web scenario, large amounts of User-Generated Content (UGC) are\ndiffused through social media often without almost any form of traditional\ntrusted intermediaries. Therefore, the risk of running into misinformation is\nnot negligible. For this reason, assessing and mining the credibility of online\ninformation constitutes nowadays a fundamental research issue. Credibility,\nalso referred as believability, is a quality perceived by individuals, who are\nnot always able to discern, with their own cognitive capacities, genuine\ninformation from fake one. Hence, in the last years, several approaches have\nbeen proposed to automatically assess credibility in social media. Many of them\nare based on data-driven models, i.e., they employ machine learning techniques\nto identify misinformation, but recently also model-driven approaches are\nemerging, as well as graph-based approaches focusing on credibility\npropagation, and knowledge-based ones exploiting Semantic Web technologies.\nThree of the main contexts in which the assessment of information credibility\nhas been investigated concern: (i) the detection of opinion spam in review\nsites, (ii) the detection of fake news in microblogging, and (iii) the\ncredibility assessment of online health-related information. In this article,\nthe main issues connected to the evaluation of information credibility in the\nSocial Web, which are shared by the above-mentioned contexts, are discussed. A\nconcise survey of the approaches and methodologies that have been proposed in\nrecent years to address these issues is also presented.", "doi": "", "date": "2020-01-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.09473v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 696568724, "title": "Towards Time-Aware Context-Aware Deep Trust Prediction in Online Social\n  Networks", "abstract": "Trust can be defined as a measure to determine which source of information is\nreliable and with whom we should share or from whom we should accept\ninformation. There are several applications for trust in Online Social Networks\n(OSNs), including social spammer detection, fake news detection, retweet\nbehaviour detection and recommender systems. Trust prediction is the process of\npredicting a new trust relation between two users who are not currently\nconnected. In applications of trust, trust relations among users need to be\npredicted. This process faces many challenges, such as the sparsity of\nuser-specified trust relations, the context-awareness of trust and changes in\ntrust values over time. In this dissertation, we analyse the state-of-the-art\nin pair-wise trust prediction models in OSNs. We discuss three main challenges\nin this domain and present novel trust prediction approaches to address them.\nWe first focus on proposing a low-rank representation of users that\nincorporates users' personality traits as additional information. Then, we\npropose a set of context-aware trust prediction models. Finally, by considering\nthe time-dependency of trust relations, we propose a dynamic deep trust\nprediction approach. We design and implement five pair-wise trust prediction\napproaches and evaluate them with real-world datasets collected from OSNs. The\nexperimental results demonstrate the effectiveness of our approaches compared\nto other state-of-the-art pair-wise trust prediction models.", "doi": "", "date": "2020-03-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.09543v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3895882586, "title": "Multimodal Analytics for Real-world News using Measures of Cross-modal\n  Entity Consistency", "abstract": "The World Wide Web has become a popular source for gathering information and\nnews. Multimodal information, e.g., enriching text with photos, is typically\nused to convey the news more effectively or to attract attention. Photo content\ncan range from decorative, depict additional important information, or can even\ncontain misleading information. Therefore, automatic approaches to quantify\ncross-modal consistency of entity representation can support human assessors to\nevaluate the overall multimodal message, for instance, with regard to bias or\nsentiment. In some cases such measures could give hints to detect fake news,\nwhich is an increasingly important topic in today's society. In this paper, we\nintroduce a novel task of cross-modal consistency verification in real-world\nnews and present a multimodal approach to quantify the entity coherence between\nimage and text. Named entity linking is applied to extract persons, locations,\nand events from news texts. Several measures are suggested to calculate\ncross-modal similarity for these entities using state of the art approaches. In\ncontrast to previous work, our system automatically gathers example data from\nthe Web and is applicable to real-world news. Results on two novel datasets\nthat cover different languages, topics, and domains demonstrate the feasibility\nof our approach. Datasets and code are publicly available to foster research\ntowards this new direction.", "doi": "", "date": "2020-03-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.10421v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1574587920, "title": "Pandemic Populism: Facebook Pages of Alternative News Media and the\n  Corona Crisis -- A Computational Content Analysis", "abstract": "The COVID-19 pandemic has not only had severe political, economic, and\nsocietal effects, it has also affected media and communication systems in\nunprecedented ways. While traditional journalistic media has tried to adapt to\nthe rapidly evolving situation, alternative news media on the Internet have\ngiven the events their own ideological spin. Such voices have been criticized\nfor furthering societal confusion and spreading potentially dangerous \"fake\nnews\" or conspiracy theories via social media and other online channels. The\ncurrent study analyzes the factual basis of such fears in an initial\ncomputational content analysis of alternative news media's output on Facebook\nduring the early Corona crisis, based on a large German data set from January\nto the second half of March 2020. Using computational content analysis,\nmethods, reach, interactions, actors, and topics of the messages were examined,\nas well as the use of fabricated news and conspiracy theories. The analysis\nrevealed that the alternative news media stay true to message patterns and\nideological foundations identified in prior research. While they do not spread\nobvious lies, they are predominantly sharing overly critical, even\nanti-systemic messages, opposing the view of the mainstream news media and the\npolitical establishment. With this pandemic populism, they contribute to a\ncontradictory, menacing, and distrusting worldview, as portrayed in detail in\nthis analysis.", "doi": "", "date": "2020-04-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.02566v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2909294353, "title": "Characterising User Content on a Multi-lingual Social Network", "abstract": "Social media has been on the vanguard of political information diffusion in\nthe 21st century. Most studies that look into disinformation, political\ninfluence and fake-news focus on mainstream social media platforms. This has\ninevitably made English an important factor in our current understanding of\npolitical activity on social media. As a result, there has only been a limited\nnumber of studies into a large portion of the world, including the largest,\nmultilingual and multi-cultural democracy: India. In this paper we present our\ncharacterisation of a multilingual social network in India called ShareChat. We\ncollect an exhaustive dataset across 72 weeks before and during the Indian\ngeneral elections of 2019, across 14 languages. We investigate the cross\nlingual dynamics by clustering visually similar images together, and exploring\nhow they move across language barriers. We find that Telugu, Malayalam, Tamil\nand Kannada languages tend to be dominant in soliciting political images (often\nreferred to as memes), and posts from Hindi have the largest cross-lingual\ndiffusion across ShareChat (as well as images containing text in English). In\nthe case of images containing text that cross language barriers, we see that\nlanguage translation is used to widen the accessibility. That said, we find\ncases where the same image is associated with very different text (and\ntherefore meanings). This initial characterisation paves the way for more\nadvanced pipelines to understand the dynamics of fake and political content in\na multi-lingual and non-textual setting.", "doi": "", "date": "2020-04-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.11480v1", "pdf": ""}, "publisher-venue": "ICWSM 2020, please cite the ICWSM version", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3054001539, "title": "Out of the Echo Chamber: Detecting Countering Debate Speeches", "abstract": "An educated and informed consumption of media content has become a challenge\nin modern times. With the shift from traditional news outlets to social media\nand similar venues, a major concern is that readers are becoming encapsulated\nin \"echo chambers\" and may fall prey to fake news and disinformation, lacking\neasy access to dissenting views. We suggest a novel task aiming to alleviate\nsome of these concerns -- that of detecting articles that most effectively\ncounter the arguments -- and not just the stance -- made in a given text. We\nstudy this problem in the context of debate speeches. Given such a speech, we\naim to identify, from among a set of speeches on the same topic and with an\nopposing stance, the ones that directly counter it. We provide a large dataset\nof 3,685 such speeches (in English), annotated for this relation, which\nhopefully would be of general interest to the NLP community. We explore several\nalgorithms addressing this task, and while some are successful, all fall short\nof expert human performance, suggesting room for further research. All data\ncollected during this work is freely available for research.", "doi": "", "date": "2020-05-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.01157v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4010846600, "title": "What Was Written vs. Who Read It: News Media Profiling Using Text\n  Analysis and Social Media Context", "abstract": "Predicting the political bias and the factuality of reporting of entire news\noutlets are critical elements of media profiling, which is an understudied but\nan increasingly important research direction. The present level of\nproliferation of fake, biased, and propagandistic content online, has made it\nimpossible to fact-check every single suspicious claim, either manually or\nautomatically. Alternatively, we can profile entire news outlets and look for\nthose that are likely to publish fake or biased content. This approach makes it\npossible to detect likely \"fake news\" the moment they are published, by simply\nchecking the reliability of their source. From a practical perspective,\npolitical bias and factuality of reporting have a linguistic aspect but also a\nsocial context. Here, we study the impact of both, namely (i) what was written\n(i.e., what was published by the target medium, and how it describes itself on\nTwitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium\non Facebook, Twitter, and YouTube). We further study (iii) what was written\nabout the target medium on Wikipedia. The evaluation results show that what was\nwritten matters most, and that putting all information sources together yields\nhuge improvements over the current state-of-the-art.", "doi": "", "date": "2020-05-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.04518v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4068907780, "title": "Inference on the History of a Randomly Growing Tree", "abstract": "The spread of infectious disease in a human community or the proliferation of\nfake news on social media can be modeled as a randomly growing tree-shaped\ngraph. The history of the random growth process is often unobserved but\ncontains important information such as the source of the infection. We consider\nthe problem of statistical inference on aspects of the latent history using\nonly a single snapshot of the final tree. Our approach is to apply random\nlabels to the observed unlabeled tree and analyze the resulting distribution of\nthe growth process, conditional on the final outcome. We show that this\nconditional distribution is tractable under a shape-exchangeability condition,\nwhich we introduce here, and that this condition is satisfied for many popular\nmodels for randomly growing trees such as uniform attachment, linear\npreferential attachment and uniform attachment on a $D$-regular tree. For\ninference of the root under shape-exchangeability, we propose O(n log n) time\nalgorithms for constructing confidence sets with valid frequentist coverage as\nwell as bounds on the expected size of the confidence sets. We also provide\nefficient sampling algorithms that extend our methods to a wide class of\ninference problems.", "doi": "", "date": "2020-05-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.08794v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3559193764, "title": "FrameProv: Towards End-To-End Video Provenance", "abstract": "Video feeds are often deliberately used as evidence, as in the case of CCTV\nfootage; but more often than not, the existence of footage of a supposed event\nis perceived as proof of fact in the eyes of the public at large. This reliance\nrepresents a societal vulnerability given the existence of easy-to-use editing\ntools and means to fabricate entire video feeds using machine learning. And, as\nthe recent barrage of fake news and fake porn videos have shown, this isn't\nmerely an academic concern, it is actively been exploited. I posit that this\nexploitation is only going to get more insidious. In this position paper, I\nintroduce a long term project that aims to mitigate some of the most egregious\nforms of manipulation by embedding trustworthy components in the video\ntransmission chain. Unlike earlier works, I am not aiming to do tamper\ndetection or other forms of forensics -- approaches I think are bound to fail\nin the face of the reality of necessary editing and compression -- instead, the\naim here is to provide a way for the video publisher to prove the integrity of\nthe video feed as well as make explicit any edits they may have performed. To\ndo this, I present a novel data structure, a video-edit specification language\nand supporting infrastructure that provides end-to-end video provenance, from\nthe camera sensor to the viewer. I have implemented a prototype of this system\nand am in talks with journalists and video editors to discuss the best ways\nforward with introducing this idea to the mainstream.", "doi": "10.1145/3368860.3368866", "date": "2020-05-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.09199v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1373996609, "title": "Ratioing the President: An exploration of public engagement with Obama\n  and Trump on Twitter", "abstract": "The past decade has witnessed a marked increase in the use of social media by\npoliticians, most notably exemplified by the 45th President of the United\nStates (POTUS), Donald Trump. On Twitter, POTUS messages consistently attract\nhigh levels of engagement as measured by likes, retweets, and replies. Here, we\nquantify the balance of these activities, also known as \"ratios\", and study\ntheir dynamics as a proxy for collective political engagement in response to\npresidential communications. We find that raw activity counts increase during\nthe period leading up to the 2016 election, accompanied by a regime change in\nthe ratio of retweets-to-replies connected to the transition between\ncampaigning and governing. For the Trump account, we find words related to fake\nnews and the Mueller inquiry are more common in tweets with a high number of\nreplies relative to retweets. Finally, we find that Barack Obama consistently\nreceived a higher retweet-to-reply ratio than Donald Trump. These results\nsuggest Trump's Twitter posts are more often controversial and subject to\nenduring engagement as a given news cycle unfolds.", "doi": "10.1371/journal.pone.0248880", "date": "2020-06-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.03526v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 54841931, "title": "ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research", "abstract": "First identified in Wuhan, China, in December 2019, the outbreak of COVID-19\nhas been declared as a global emergency in January, and a pandemic in March\n2020 by the World Health Organization (WHO). Along with this pandemic, we are\nalso experiencing an \"infodemic\" of information with low credibility such as\nfake news and conspiracies. In this work, we present ReCOVery, a repository\ndesigned and constructed to facilitate research on combating such information\nregarding COVID-19. We first broadly search and investigate ~2,000 news\npublishers, from which 60 are identified with extreme [high or low] levels of\ncredibility. By inheriting the credibility of the media on which they were\npublished, a total of 2,029 news articles on coronavirus, published from\nJanuary to May 2020, are collected in the repository, along with 140,820 tweets\nthat reveal how these news articles have spread on the Twitter social network.\nThe repository provides multimodal information of news articles on coronavirus,\nincluding textual, visual, temporal, and network information. The way that news\ncredibility is obtained allows a trade-off between dataset scalability and\nlabel accuracy. Extensive experiments are conducted to present data statistics\nand distributions, as well as to provide baseline performances for predicting\nnews credibility so that future methods can be compared. Our repository is\navailable at http://coronavirus-fakenews.com.", "doi": "10.1145/3340531.3412880", "date": "2020-06-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.05557v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 244993747, "title": "Games of Social Distancing during an Epidemic: Local vs Statistical\n  Information", "abstract": "The spontaneous behavioral changes of the agents during an epidemic can have\nsignificant effects on the delay and the prevalence of its spread. In this\nwork, we study a social distancing game among the agents of a population, who\ndetermine their social interactions during the spread of an epidemic. The\ninterconnections between the agents are modeled by a network and local\ninteractions are considered. The payoffs of the agents depend on their benefits\nfrom their social interactions, as well as on the costs to their health due to\ntheir possible contamination. The information available to the agents during\nthe decision making plays a crucial role in our model. We examine two extreme\ncases. In the first case, the agents know exactly the health states of their\nneighbors and in the second they have statistical information for the global\nprevalence of the epidemic. The Nash equilibria of the games are studied and,\ninterestingly, in the second case the equilibrium strategies for an agent are\neither full isolation or no social distancing at all. Experimental studies are\npresented through simulations, where we observe that in the first case of\nperfect local information the agents can affect significantly the prevalence of\nthe epidemic with low cost for their sociability, while in the second case they\nhave to pay the burden of not being well informed. Moreover, the effects of the\ninformation quality (fake news), the health care system capacity and the\nnetwork structure are discussed and relevant simulations are provided, which\nindicate that these parameters affect the size, the peak and the start of the\noutbreak, as well as the possibility of a second outbreak.", "doi": "", "date": "2020-07-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.05185v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2518568753, "title": "A curated collection of COVID-19 online datasets", "abstract": "One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data.", "doi": "", "date": "2020-07-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.09703v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 90644879, "title": "Check_square at CheckThat! 2020: Claim Detection in Social Media via\n  Fusion of Transformer and Syntactic Features", "abstract": "In this digital age of news consumption, a news reader has the ability to\nreact, express and share opinions with others in a highly interactive and fast\nmanner. As a consequence, fake news has made its way into our daily life\nbecause of very limited capacity to verify news on the Internet by large\ncompanies as well as individuals. In this paper, we focus on solving two\nproblems which are part of the fact-checking ecosystem that can help to\nautomate fact-checking of claims in an ever increasing stream of content on\nsocial media. For the first problem, claim check-worthiness prediction, we\nexplore the fusion of syntactic features and deep transformer Bidirectional\nEncoder Representations from Transformers (BERT) embeddings, to classify\ncheck-worthiness of a tweet, i.e. whether it includes a claim or not. We\nconduct a detailed feature analysis and present our best performing models for\nEnglish and Arabic tweets. For the second problem, claim retrieval, we explore\nthe pre-trained embeddings from a Siamese network transformer model\n(sentence-transformers) specifically trained for semantic textual similarity,\nand perform KD-search to retrieve verified claims with respect to a query\ntweet.", "doi": "", "date": "2020-07-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.10534v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4152265165, "title": "Exploiting stance hierarchies for cost-sensitive stance detection of Web\n  documents", "abstract": "Fact checking is an essential challenge when combating fake news. Identifying\ndocuments that agree or disagree with a particular statement (claim) is a core\ntask in this process. In this context, stance detection aims at identifying the\nposition (stance) of a document towards a claim. Most approaches address this\ntask through a 4-class classification model where the class distribution is\nhighly imbalanced. Therefore, they are particularly ineffective in detecting\nthe minority classes (for instance, 'disagree'), even though such instances are\ncrucial for tasks such as fact-checking by providing evidence for detecting\nfalse claims. In this paper, we exploit the hierarchical nature of stance\nclasses, which allows us to propose a modular pipeline of cascading binary\nclassifiers, enabling performance tuning on a per step and class basis. We\nimplement our approach through a combination of neural and traditional\nclassification models that highlight the misclassification costs of minority\nclasses. Evaluation results demonstrate state-of-the-art performance of our\napproach and its ability to significantly improve the classification\nperformance of the important 'disagree' class.", "doi": "10.1007/s10844-021-00642-z", "date": "2020-07-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.15121v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1475320454, "title": "CD-SEIZ: Cognition-Driven SEIZ Compartmental Model for the Prediction of\n  Information Cascades on Twitter", "abstract": "Information spreading social media platforms has become ubiquitous in our\nlives due to viral information propagation regardless of its veracity. Some\ninformation cascades turn out to be viral since they circulated rapidly on the\nInternet. The uncontrollable virality of manipulated or disorientated true\ninformation (fake news) might be quite harmful, while the spread of the true\nnews is advantageous, especially in emergencies. We tackle the problem of\npredicting information cascades by presenting a novel variant of SEIZ\n(Susceptible/ Exposed/ Infected/ Skeptics) model that outperforms the original\nversion by taking into account the cognitive processing depth of users. We\ndefine an information cascade as the set of social media users' reactions to\nthe original content which requires at least minimal physical and cognitive\neffort; therefore, we considered retweet/ reply/ quote (mention) activities and\ntested our framework on the Syrian White Helmets Twitter data set from April\n1st, 2018 to April 30th, 2019. In the prediction of cascade pattern via\ntraditional compartmental models, all the activities are grouped, and their\nsummation is taken into account; however, transition rates between compartments\nshould vary according to the activity type since their requirements of physical\nand cognitive efforts are not same. Based on this assumption, we design a\ncognition-driven SEIZ (CD-SEIZ) model in the prediction of information cascades\non Twitter. We tested SIS, SEIZ, and CD-SEIZ models on 1000 Twitter cascades\nand found that CD-SEIZ has a significantly low fitting error and provides a\nstatistically more accurate estimation.", "doi": "", "date": "2020-08-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.12723v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 361344377, "title": "Linked Credibility Reviews for Explainable Misinformation Detection", "abstract": "In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task.", "doi": "", "date": "2020-08-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.12742v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 618518392, "title": "A Review on Fact Extraction and Verification", "abstract": "We study the fact checking problem, which aims to identify the veracity of a\ngiven claim. Specifically, we focus on the task of Fact Extraction and\nVERification (FEVER) and its accompanied dataset. The task consists of the\nsubtasks of retrieving the relevant documents (and sentences) from Wikipedia\nand validating whether the information in the documents supports or refutes a\ngiven claim. This task is essential and can be the building block of\napplications such as fake news detection and medical claim verification. In\nthis paper, we aim at a better understanding of the challenges of the task by\npresenting the literature in a structured and comprehensive way. We describe\nthe proposed methods by analyzing the technical perspectives of the different\napproaches and discussing the performance results on the FEVER dataset, which\nis the most well-studied and formally structured dataset on the fact extraction\nand verification task. We also conduct the largest experimental study to date\non identifying beneficial loss functions for the sentence retrieval component.\nOur analysis indicates that sampling negative sentences is important for\nimproving the performance and decreasing the computational complexity. Finally,\nwe describe open issues and future challenges, and we motivate future research\nin the task.", "doi": "", "date": "2020-10-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.03001v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2523937007, "title": "Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised\n  Learning Approach", "abstract": "Online Social Media (OSM) platforms such as Twitter, Facebook are extensively\nexploited by the users of these platforms for spreading the (mis)information to\na large audience effortlessly at a rapid pace. It has been observed that the\nmisinformation can cause panic, fear, and financial loss to society. Thus, it\nis important to detect and control the misinformation in such platforms before\nit spreads to the masses. In this work, we focus on rumors, which is one type\nof misinformation (other types are fake news, hoaxes, etc). One way to control\nthe spread of the rumors is by identifying users who are possibly the rumor\nspreaders, that is, users who are often involved in spreading the rumors. Due\nto the lack of availability of rumor spreaders labeled dataset (which is an\nexpensive task), we use publicly available PHEME dataset, which contains rumor\nand non-rumor tweets information, and then apply a weak supervised learning\napproach to transform the PHEME dataset into rumor spreaders dataset. We\nutilize three types of features, that is, user, text, and ego-network features,\nbefore applying various supervised learning approaches. In particular, to\nexploit the inherent network property in this dataset (user-user reply graph),\nwe explore Graph Convolutional Network (GCN), a type of Graph Neural Network\n(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and\nLSTM. Extensive experiments performed on the rumor spreaders dataset, where we\nachieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the\neffectiveness of our methodology for identifying possible rumor spreaders using\nthe GCN technique.", "doi": "", "date": "2020-10-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.07647v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 433642891, "title": "Model of Trust Management for Digital Industry Services. Towards\n  E-Commerce 4.0", "abstract": "The progressive digitalization is changing the way businesses work and\ninteract. Concepts like Internet of Things, Cloud Computing, Industry 4.0,\nService 4.0, Smart Production or Smart Cities are based on systems that are\nlinked to the Internet. The online access to the provided data creates\npotential to optimize processes and cost reductions, but also exposes it to a\nrisk for an inappropriate use. Trust management systems are necessary in terms\nof data security, but also to assure the trustworthiness of data that is\ndistributed. Fake news in social media is an example for problems with online\ndata that is not trustable. Security and trustworthiness of data are major\nconcerns today. The speed in digitalization makes it even a greater challenge\nfor future research. This article introduces therefore a model of online trust\ncontent usable to compute the trust of an online service advertisement. It\ncontributes to standardize business service descriptions necessary to realize\nvisions of E-commerce 4.0, because it is the basis for the development of AI\nsystems that are able to match an service request to a service advertisement.\nIt is necessary for building trust enhancing architectures in B2B e-commerce.\nTo do so, we conducted case studies, analysed websites, developed a prototype\nsystem and verified it by conducting expert interviews.", "doi": "", "date": "2020-11-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.01523v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3125971039, "title": "Optimizing sensors placement in complex networks for localization of\n  hidden signal source: A review", "abstract": "As the world becomes more and more interconnected, our everyday objects\nbecome part of the Internet of Things, and our lives get more and more mirrored\nin virtual reality, where every piece of~information, including misinformation,\nfake news and malware, can spread very fast practically anonymously. To\nsuppress such uncontrolled spread, efficient computer systems and algorithms\ncapable to~track down such malicious information spread have to be developed.\nCurrently, the most effective methods for source localization are based on\nsensors which provide the times at which they detect the~spread. We investigate\nthe problem of the optimal placement of such sensors in complex networks and\npropose a new graph measure, called Collective Betweenness, which we compare\nagainst four other metrics. Extensive numerical tests are performed on\ndifferent types of complex networks over the wide ranges of densities of\nsensors and stochasticities of signal. In these tests, we discovered clear\ndifference in comparative performance of the investigated optimal placement\nmethods between real or scale-free synthetic networks versus narrow degree\ndistribution networks. The former have a clear region for any given method's\ndominance in contrast to the latter where the performance maps are less\nhomogeneous. We find that while choosing the best method is very network and\nspread dependent, there are two methods that consistently stand out. High\nVariance Observers seem to do very well for spread with low stochasticity\nwhereas Collective Betwenness, introduced in this paper, thrives when the\nspread is highly unpredictable.", "doi": "10.1016/j.future.2020.06.023", "date": "2020-12-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.01876v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1620103597, "title": "Increase of Low-Frequency Modes of User Dynamics in Online Social\n  Networks During Overheating of Discussions", "abstract": "User dynamics in online social networks have a significant impact on not only\nthe online community but also real-world activities. As examples, we can\nmention explosive user dynamics triggered by social polarization, echo chamber\nphenomena, fake news, etc. Explosive user dynamics are frequently called online\nflaming. The wave equation-based model for online social networks (called the\noscillation model) is a theoretical model proposed to describe user dynamics in\nonline social networks. This model can be used to understand the relationship\nbetween explosive user dynamics and the structure of social networks. However,\nsince the oscillation model was introduced as a purely theoretical model of\nsocial networks, it is necessary to confirm whether the model describes real\nphenomena correctly or not. In this paper, we first show a prediction from the\noscillation model; the low-frequency oscillation mode of user dynamics will be\ndominant when the structure of online social networks changes so that user\nactivity is activated. To verify the predictions with actual data, we show\nspectral analyses of both the log data of posts on an electronic bulletin board\nsite and the frequency data of word search from Google Trends. The results\nsupport the predictions from the theoretical model.", "doi": "", "date": "2020-12-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.04252v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3418083281, "title": "Fringe News Networks: Dynamics of US News Viewership following the 2020\n  Presidential Election", "abstract": "The growing political polarization of the American electorate over the last\nseveral decades has been widely studied and documented. During the\nadministration of President Donald Trump, charges of \"fake news\" made social\nand news media not only the means but, to an unprecedented extent, the topic of\npolitical communication. Using data from before the November 3rd, 2020 US\nPresidential election, recent work has demonstrated the viability of using\nYouTube's social media ecosystem to obtain insights into the extent of US\npolitical polarization as well as the relationship between this polarization\nand the nature of the content and commentary provided by different US news\nnetworks. With that work as background, this paper looks at the sharp\ntransformation of the relationship between news consumers and here-to-fore\n\"fringe\" news media channels in the 64 days between the US presidential\nelection and the violence that took place at US Capitol on January 6th. This\npaper makes two distinct types of contributions. The first is to introduce a\nnovel methodology to analyze large social media data to study the dynamics of\nsocial political news networks and their viewers. The second is to provide\ninsights into what actually happened regarding US political social media\nchannels and their viewerships during this volatile 64 day period.", "doi": "", "date": "2021-01-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.10112v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1648758613, "title": "Semi-automatic Generation of Multilingual Datasets for Stance Detection\n  in Twitter", "abstract": "Popular social media networks provide the perfect environment to study the\nopinions and attitudes expressed by users. While interactions in social media\nsuch as Twitter occur in many natural languages, research on stance detection\n(the position or attitude expressed with respect to a specific topic) within\nthe Natural Language Processing field has largely been done for English.\nAlthough some efforts have recently been made to develop annotated data in\nother languages, there is a telling lack of resources to facilitate\nmultilingual and crosslingual research on stance detection. This is partially\ndue to the fact that manually annotating a corpus of social media texts is a\ndifficult, slow and costly process. Furthermore, as stance is a highly domain-\nand topic-specific phenomenon, the need for annotated data is specially\ndemanding. As a result, most of the manually labeled resources are hindered by\ntheir relatively small size and skewed class distribution. This paper presents\na method to obtain multilingual datasets for stance detection in Twitter.\nInstead of manually annotating on a per tweet basis, we leverage user-based\ninformation to semi-automatically label large amounts of tweets. Empirical\nmonolingual and cross-lingual experimentation and qualitative analysis show\nthat our method helps to overcome the aforementioned difficulties to build\nlarge, balanced and multilingual labeled corpora. We believe that our method\ncan be easily adapted to easily generate labeled social media data for other\nNatural Language Processing tasks and domains.", "doi": "10.1016/j.eswa.2020.114547", "date": "2021-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.11978v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3134281287, "title": "High-level Approaches to Detect Malicious Political Activity on Twitter", "abstract": "Our work represents another step into the detection and prevention of these\never-more present political manipulation efforts. We, therefore, start by\nfocusing on understanding what the state-of-the-art approaches lack -- since\nthe problem remains, this is a fair assumption. We find concerning issues\nwithin the current literature and follow a diverging path. Notably, by placing\nemphasis on using data features that are less susceptible to malicious\nmanipulation and also on looking for high-level approaches that avoid a\ngranularity level that is biased towards easy-to-spot and low impact cases.\n  We designed and implemented a framework -- Twitter Watch -- that performs\nstructured Twitter data collection, applying it to the Portuguese\nTwittersphere. We investigate a data snapshot taken on May 2020, with around 5\nmillion accounts and over 120 million tweets (this value has since increased to\nover 175 million). The analyzed time period stretches from August 2019 to May\n2020, with a focus on the Portuguese elections of October 6th, 2019. However,\nthe Covid-19 pandemic showed itself in our data, and we also delve into how it\naffected typical Twitter behavior.\n  We performed three main approaches: content-oriented, metadata-oriented, and\nnetwork interaction-oriented. We learn that Twitter's suspension patterns are\nnot adequate to the type of political trolling found in the Portuguese\nTwittersphere -- identified by this work and by an independent peer - nor to\nfake news posting accounts. We also surmised that the different types of\nmalicious accounts we independently gathered are very similar both in terms of\ncontent and interaction, through two distinct analysis, and are simultaneously\nvery distinct from regular accounts.", "doi": "", "date": "2021-02-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.04293v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 50926981, "title": "Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models", "abstract": "Misinformation of COVID-19 is prevalent on social media as the pandemic\nunfolds, and the associated risks are extremely high. Thus, it is critical to\ndetect and combat such misinformation. Recently, deep learning models using\nnatural language processing techniques, such as BERT (Bidirectional Encoder\nRepresentations from Transformers), have achieved great successes in detecting\nmisinformation. In this paper, we proposed an explainable natural language\nprocessing model based on DistilBERT and SHAP (Shapley Additive exPlanations)\nto combat misinformation about COVID-19 due to their efficiency and\neffectiveness. First, we collected a dataset of 984 claims about COVID-19 with\nfact checking. By augmenting the data using back-translation, we doubled the\nsample size of the dataset and the DistilBERT model was able to obtain good\nperformance (accuracy: 0.972; areas under the curve: 0.993) in detecting\nmisinformation about COVID-19. Our model was also tested on a larger dataset\nfor AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good\nperformance (accuracy: 0.938; areas under the curve: 0.985). The performance on\nboth datasets was better than traditional machine learning models. Second, in\norder to boost public trust in model prediction, we employed SHAP to improve\nmodel explainability, which was further evaluated using a between-subjects\nexperiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),\nand text+SHAP explanation+source and evidence (TSESE). The participants were\nsignificantly more likely to trust and share information related to COVID-19 in\nthe TSE and TSESE conditions than in the T condition. Our results provided good\nimplications in detecting misinformation about COVID-19 and improving public\ntrust.", "doi": "", "date": "2021-03-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.00747v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3317822930, "title": "Using an Epidemiological Model to Study the Spread of Misinformation\n  during the Black Lives Matter Movement", "abstract": "The proliferation of social media platforms like Twitter has heightened the\nconsequences of the spread of misinformation. To understand and model the\nspread of misinformation, in this paper, we leveraged the SEIZ (Susceptible,\nExposed, Infected, Skeptics) epidemiological model to describe the underlying\nprocess that delineates the spread of misinformation on Twitter. Compared to\nthe other epidemiological models, this model produces broader results because\nit includes the additional Skeptics (Z) compartment, wherein a user may be\nexposed to an item of misinformation but not engage in any reaction to it, and\nthe additional Exposed (E) compartment, wherein the user may need some time\nbefore deciding to spread a misinformation item. We analyzed misinformation\nregarding the unrest in Washington, D.C. in the month of March 2020 which was\npropagated by the use of the #DCblackout hashtag by different users across the\nU.S. on Twitter. Our analysis shows that misinformation can be modeled using\nthe concept of epidemiology. To the best of our knowledge, this research is the\nfirst to attempt to apply the SEIZ epidemiological model to the spread of a\nspecific item of misinformation, which is a category distinct from that of\nrumor, and a hoax on online social media platforms. Applying a mathematical\nmodel can help to understand the trends and dynamics of the spread of\nmisinformation on Twitter and ultimately help to develop techniques to quickly\nidentify and control it.", "doi": "", "date": "2021-03-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.12191v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3822613519, "title": "The Role of Context in Detecting Previously Fact-Checked Claims", "abstract": "Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.", "doi": "", "date": "2021-04-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.07423v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3488640833, "title": "Educators, Solicitors, Flamers, Motivators, Sympathizers: Characterizing\n  Roles in Online Extremist Movements", "abstract": "Social media provides the means by which extremist social movements, such as\nwhite supremacy and anti LGBTQ, thrive online. Yet, we know little about the\nroles played by the participants of such movements. In this paper, we\ninvestigate these participants to characterize their roles, their role\ndynamics, and their influence in spreading online extremism. Our participants,\nonline extremist accounts, are 4,876 public Facebook pages or groups that have\nshared information from the websites of 289 Southern Poverty Law Center\ndesignated extremist groups. By clustering the quantitative features followed\nby qualitative expert validation, we identify five roles surrounding extremist\nactivism: educators, solicitors, flamers, motivators, sympathizers. For\nexample, solicitors use links from extremist websites to attract donations and\nparticipation in extremist issues, whereas flamers share inflammatory extremist\ncontent inciting anger. We further investigate role dynamics such as, how\nstable these roles are over time and how likely will extremist accounts\ntransition from one role into another. We find that roles core to the movement,\neducators and solicitors, are more stable, while flamers and motivators can\ntransition to sympathizers with high probability. We further find that\neducators and solicitors exert the most influence in triggering extremist link\nposts, whereas flamers are influential in triggering the spread of information\nfrom fake news sources. Our results help in situating various roles on the\ntrajectory of deeper engagement into the extremist movements and understanding\nthe potential effect of various counter extremism interventions. Our findings\nhave implications for understanding how online extremist movements flourish\nthrough participatory activism and how they gain a spectrum of allies for\nmobilizing extremism online.", "doi": "", "date": "2021-05-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.08827v1", "pdf": ""}, "publisher-venue": "Computer Supported Cooperative Work (CSCW 2021)", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 383349208, "title": "The Contestation of Tech Ethics: A Sociotechnical Approach to Ethics and\n  Technology in Action", "abstract": "Recent controversies related to topics such as fake news, privacy, and\nalgorithmic bias have prompted increased public scrutiny of digital\ntechnologies and soul-searching among many of the people associated with their\ndevelopment. In response, the tech industry, academia, civil society, and\ngovernments have rapidly increased their attention to \"ethics\" in the design\nand use of digital technologies (\"tech ethics\"). Yet almost as quickly as\nethics discourse has proliferated across the world of digital technologies, the\nlimitations of these approaches have also become apparent: tech ethics is vague\nand toothless, is subsumed into corporate logics and incentives, and has a\nmyopic focus on individual engineers and technology design rather than on the\nstructures and cultures of technology production. As a result of these\nlimitations, many have grown skeptical of tech ethics and its proponents,\ncharging them with \"ethics-washing\": promoting ethics research and discourse to\ndefuse criticism and government regulation without committing to ethical\nbehavior. By looking at how ethics has been taken up in both science and\nbusiness in superficial and depoliticizing ways, I recast tech ethics as a\nterrain of contestation where the central fault line is not whether it is\ndesirable to be ethical, but what \"ethics\" entails and who gets to define it.\nThis framing highlights the significant limits of current approaches to tech\nethics and the importance of studying the formulation and real-world effects of\ntech ethics. In order to identify and develop more rigorous strategies for\nreforming digital technologies and the social relations that they mediate, I\ndescribe a sociotechnical approach to tech ethics, one that reflexively applies\nmany of tech ethics' own lessons regarding digital technologies to tech ethics\nitself.", "doi": "", "date": "2021-06-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.01784v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1741646819, "title": "Making Images Real Again: A Comprehensive Survey on Deep Image\n  Composition", "abstract": "As a common image editing operation, image composition aims to cut the\nforeground from one image and paste it on another image, resulting in a\ncomposite image. However, there are many issues that could make the composite\nimages unrealistic. These issues can be summarized as the inconsistency between\nforeground and background, which include appearance inconsistency (e.g.,\nincompatible color and illumination) and geometry inconsistency (e.g.,\nunreasonable size and location). Previous works on image composition target at\none or more issues. Since each individual issue is a complicated problem, there\nare some research directions (e.g., image harmonization, object placement)\nwhich focus on only one issue. By putting all the efforts together, we can\nacquire realistic composite images. Sometimes, we expect the composite images\nto be not only realistic but also aesthetic, in which case aesthetic evaluation\nneeds to be considered. In this survey, we summarize the datasets and methods\nfor the above research directions. We also discuss the limitations and\npotential directions to facilitate the future research for image composition.\nFinally, as a double-edged sword, image composition may also have negative\neffect on our lives (e.g., fake news) and thus it is imperative to develop\nalgorithms to fight against composite images. Datasets and codes for image\ncomposition are summarized at\nhttps://github.com/bcmi/Awesome-Image-Composition.", "doi": "", "date": "2021-06-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.14490v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3406974668, "title": "Root and community inference on the latent growth process of a network\n  using noisy attachment models", "abstract": "We introduce the PAPER (Preferential Attachment Plus Erd\\H{o}s--R\\'{e}nyi)\nmodel for random networks, where we let a random network G be the union of a\npreferential attachment (PA) tree T and additional Erd\\H{o}s--R\\'{e}nyi (ER)\nrandom edges. The PA tree component captures the fact that real world networks\noften have an underlying growth/recruitment process where vertices and edges\nare added sequentially, while the ER component can be regarded as random noise.\nGiven only a single snapshot of the final network G, we study the problem of\nconstructing confidence sets for the early history, in particular the root\nnode, of the unobserved growth process; the root node can be patient zero in a\ndisease infection network or the source of fake news in a social media network.\nWe propose an inference algorithm based on Gibbs sampling that scales to\nnetworks with millions of nodes and provide theoretical analysis showing that\nthe expected size of the confidence set is small so long as the noise level of\nthe ER edges is not too large. We also propose variations of the model in which\nmultiple growth processes occur simultaneously, reflecting the growth of\nmultiple communities, and we use these models to provide a new approach\ncommunity detection.", "doi": "", "date": "2021-07-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.00153v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 76501159, "title": "Uncovering the structure of the French media ecosystem", "abstract": "This study provides a large-scale mapping of the French media space using\ndigital methods to estimate political polarization and to study information\ncircuits. We collect data about the production and circulation of online news\nstories in France over the course of one year, adopting a multi-layer\nperspective on the media ecosystem. We source our data from websites, Twitter\nand Facebook. We also identify a certain number of important structural\nfeatures. A stochastic block model of the hyperlinks structure shows the\nsystematic rejection of counter-informational press in a separate cluster which\nhardly receives any attention from the mainstream media. Counter-informational\nsub-spaces are also peripheral on the consumption side. We measure their\nrespective audiences on Twitter and Facebook and do not observe a large\ndiscrepancy between both social networks, with counter-information space, far\nright and far left media gathering limited audiences. Finally, we also measure\nthe ideological distribution of news stories using Twitter data, which also\nsuggests that the French media landscape is quite balanced. We therefore\nconclude that the French media ecosystem does not suffer from the same level of\npolarization as the US media ecosystem. The comparison with the American\nsituation also allows us to consolidate a result from studies on\ndisinformation: the polarization of the journalistic space and the circulation\nof fake news are phenomena that only become more widespread when dominant and\ninfluential actors in the political or journalistic space spread topics and\ndubious content originally circulating in the fringe of the information space.", "doi": "", "date": "2021-07-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.12073v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 895714748, "title": "Tracking Elections: our experience during the presidential elections in\n  Ecuador", "abstract": "The world's digital transformation has influenced not only the way we do\nbusiness, but also the way we perform daily activities. In fact, the past\nPresidential elections in the United States as well as those in Great Britain\n(Brexit) and in Colombia (peace agreement referendum) are proof that social\nmedia play an important part in modern politics. In fact, this digital\npolitical field is filled by political movements and political candidates\nlooking for popular support (number of followers), regular citizens' messages\ndiscussing social issues (trending topics flooding social media), or even\npolitical propaganda in favor or against politicians or political movements\n(advertisement). One of the issues with social media in this era is the\npresence of automatic accounts (bots) that artificially fill accounts with fake\nfollowers, create false trending topics, and share fake news or simply flood\nthe net with propaganda. All this artificial information may influence people\nand sometimes may even censor people's real opinions undermining their freedom\nof speech. In this paper, we propose a methodology to track elections and a set\nof tools used to collect and analyze election data. In particular, this paper\ndiscusses our experiences during the Presidential Elections in Ecuador held in\n2017. In fact, we show how all candidates prepared an online campaign in social\nmedia (Twitter) and how the political campaign altered a common follower rate\nsubscription. We discuss that the high presence of followers during the period\nbetween the first and second round of elections may be altered by automatic\naccounts. Finally, we use bot detection systems and gathered more than 30,000\npolitical motivated bots. In our data analysis, we show that these bots were\nmainly used for propaganda purposes in favor or against a particular candidate.", "doi": "", "date": "2018-07-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1807.06147v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 229434763, "title": "Proof of Witness Presence: Blockchain Consensus for Augmented Democracy\n  in Smart Cities", "abstract": "Smart Cities evolve into complex and pervasive urban environments with a\ncitizens' mandate to meet sustainable development goals. Repositioning\ndemocratic values of citizens' choices in these complex ecosystems has turned\nout to be imperative in an era of social media filter bubbles, fake news and\nopportunities for manipulating electoral results with such means. This paper\nintroduces a new paradigm of augmented democracy that promises actively\nengaging citizens in a more informed decision-making augmented into public\nurban space. The proposed concept is inspired by a digital revive of the\nAncient Agora of Athens, an arena of public discourse, a Polis where citizens\nassemble to actively deliberate and collectively decide about public matters.\nThe core contribution of the proposed paradigm is the concept of proving\nwitness presence: making decision-making subject of providing secure evidence\nand testifying for choices made in the physical space. This paper shows how the\nchallenge of proving witness presence can be tackled with blockchain consensus\nto empower citizens' trust and overcome security vulnerabilities of GPS\nlocalization. Moreover, a novel platform for collective decision-making and\ncrowd-sensing in urban space is introduced: Smart Agora. It is shown how\nreal-time collective measurements over citizens' choices can be made in a fully\ndecentralized and privacy-preserving way. Witness presence is tested by\ndeploying a decentralized system for crowd-sensing the sustainable use of\ntransport means. Furthermore, witness presence of cycling risk is validated\nusing official accident data from public authorities, which are compared\nagainst wisdom of the crowd. The paramount role of dynamic consensus,\nself-governance and ethically aligned artificial intelligence in the augmented\ndemocracy paradigm is outlined.", "doi": "", "date": "2019-06-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.00498v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1324810732, "title": "Burning Two Worlds: Algorithms for Burning Dense and Tree-like Graphs", "abstract": "Graph burning is a simple model for the spread of social influence in\nnetworks. The objective is to measure how quickly a fire (e.g., a piece of fake\nnews) can be spread in a network. The burning process takes place in discrete\nrounds. In each round, a new fire breaks out at a selected vertex and burns it.\nMeanwhile, the old fires extend to their neighbours and burn them. A burning\nschedule selects where the new fire breaks out in each round, and the burning\nproblem asks for a schedule that burns all vertices in a minimum number of\nrounds, termed the burning number of the graph. The burning problem is known to\nbe NP-hard even when the graph is a tree or a disjoint set of paths. For\nconnected graphs, it has been conjectured that burning takes at most $\\lceil\n\\sqrt{n} \\rceil$ rounds.\n  We approach the algorithmic study of graph burning from two directions.\nFirst, we consider graphs with minimum degree $\\delta$. We present an algorithm\nthat burns any graph of size $n$ in at most $\\sqrt{\\frac{24n}{\\delta+1}}$\nrounds. In particular, for dense graphs with $\\delta \\in \\Theta(n)$, all\nvertices are burned in a constant number of rounds. More interestingly, even\nwhen $\\delta$ is a constant that is independent of the graph size, our\nalgorithm answers the graph-burning conjecture in the affirmative by burning\nthe graph in at most $\\lceil \\sqrt{n} \\rceil$ rounds. Next, we consider burning\ngraphs with bounded path-length or tree-length. These include many graph\nfamilies including connected interval graphs and connected chordal graphs. We\nshow that any graph with path-length $pl$ and diameter $d$ can be burned in\n$\\lceil \\sqrt{d-1} \\rceil + pl$ rounds. Our algorithm ensures an approximation\nratio of $1+o(1)$ for graphs of bounded path-length. We introduce another\nalgorithm that achieves an approximation ratio of $2+o(1)$ for burning graphs\nof bounded tree-length.", "doi": "", "date": "2019-09-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.00530v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 642597321, "title": "Adversarial Perturbations of Opinion Dynamics in Networks", "abstract": "We study the connections between network structure, opinion dynamics, and an\nadversary's power to artificially induce disagreements. We approach these\nquestions by extending models of opinion formation in the social sciences to\nrepresent scenarios, familiar from recent events, in which external actors seek\nto destabilize communities through sophisticated information warfare tactics\nvia fake news and bots. In many instances, the intrinsic goals of these efforts\nare not necessarily to shift the overall sentiment of the network, but rather\nto induce discord. These perturbations diffuse via opinion dynamics on the\nunderlying network, through mechanisms that have been analyzed and abstracted\nthrough work in computer science and the social sciences. We investigate the\nproperties of such attacks, considering optimal strategies both for the\nadversary seeking to create disagreement and for the entities tasked with\ndefending the network from attack. We show that for different formulations of\nthese types of objectives, different regimes of the spectral structure of the\nnetwork will limit the adversary's capacity to sow discord; this enables us to\nqualitatively describe which networks are most vulnerable against these\nperturbations. We then consider the algorithmic task of a network defender to\nmitigate these sorts of adversarial attacks by insulating nodes\nheterogeneously; we show that, by considering the geometry of this problem,\nthis optimization task can be efficiently solved via convex programming.\nFinally, we generalize these results to allow for two network structures, where\nthe opinion dynamics process and the measurement of disagreement become\nuncoupled, and determine how the adversary's power changes; for instance, this\nmay arise when opinion dynamics are controlled an online community via social\nmedia, while disagreement is measured along \"real-world\" connections.", "doi": "", "date": "2020-03-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.07010v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 697355879, "title": "Pandemic News: Facebook Pages of Mainstream News Media and the\n  Coronavirus Crisis -- A Computational Content Analysis", "abstract": "The unfolding of the COVID-19 pandemic has been an unprecedented challenge\nfor news media around the globe. While journalism is meant to process yet\nunknown events by design, the dynamically evolving situation affected all\naspects of life in such profound ways that even the routines of crisis\nreporting seemed to be insufficient. Critics noted tendencies to horse-race\nreporting and uncritical coverage, with journalism being too close to official\nstatements and too affirmative of political decisions. However, empirical data\non the performance of journalistic news media during the crisis has been\nlacking thus far. The current study analyzes the Facebook messages of\njournalistic news media during the early Coronavirus crisis, based on a large\nGerman data set from January to March 2020. Using computational content\nanalysis methods, reach and interactions, topical structure, relevant actors,\nnegativity of messages, as well as the coverage of fabricated news and\nconspiracy theories were examined. The topical structure of the near-time\nFacebook coverage changed during various stages of the crisis, with just\npartial support for the claims of critics. The initial stages were somewhat\nlacking in topical breadth, but later stages offered a broad range of coverage\non Corona-related issues and societal concerns. Further, journalistic media\ncovered fake news and conspiracy theories during the crisis, but they\nconsistently contextualized them as what they were and debunked the false\nclaims circulating in public. While some criticism regarding the performance of\njournalism during the crisis received mild empirical support, the analysis did\nnot find overwhelming signs of systemic dysfunctionalities. Overall,\njournalistic media did not default to a uniform reaction nor to sprawling,\ninformation-poor pandemic news, but they responded with a multi-perspective\ncoverage of the crisis.", "doi": "", "date": "2020-05-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.13290v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2148633739, "title": "Bias-Resistant Social News Aggregator Based on Blockchain", "abstract": "In today's world, social networks have become one of the primary sources for\ncreation and propagation of news. Social news aggregators are one of the actors\nin this area in which users post news items and use positive or negative votes\nto indicate their preference toward a news item. News items will be ordered and\ndisplayed according to their aggregated votes. This approach suffers from\nseveral problems raging from being prone to the dominance of the majority to\ndifficulty in discerning between correct and fake news, and lack of incentive\nfor honest behaviors. In this paper, we propose a graph-based news aggregator\nin which instead of voting on the news items, users submit their votes on the\nrelations between pairs of news items. More precisely, if a user believes two\nnews items support each other, he will submit a positive vote on the link\nbetween the two items, and if he believes that two news items undermine each\nother, he will submit a negative vote on the corresponding link. This approach\nhas mainly two desirable features: (1) mitigating the effect of personal\npreferences on voting, (2) connection of new items to endorsing and disputing\nevidence. This approach helps the newsreaders to understand different aspects\nof a news item better. We also introduce an incentive layer that uses\nblockchain as a distributed transparent manager to encourages users to behave\nhonestly and abstain from adversary behaviors. The incentive layer takes into\naccount that users can have different viewpoints toward news, enabling users\nfrom a wide range of viewpoints to contribute to the network and benefit from\nits rewards. In addition, we introduce a protocol that enables us to prove\nfraud in computations of the incentive layer model on the blockchain.\nUltimately, we will analyze the fraud proof protocol and examine our incentive\nlayer on a wide range of synthesized datasets.", "doi": "", "date": "2020-10-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.10083v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 26366720, "title": "GIID-Net: Generalizable Image Inpainting Detection via Neural\n  Architecture Search and Attention", "abstract": "Deep learning (DL) has demonstrated its powerful capabilities in the field of\nimage inpainting, which could produce visually plausible results. Meanwhile,\nthe malicious use of advanced image inpainting tools (e.g. removing key objects\nto report fake news) has led to increasing threats to the reliability of image\ndata. To fight against the inpainting forgeries, in this work, we propose a\nnovel end-to-end Generalizable Image Inpainting Detection Network (GIID-Net),\nto detect the inpainted regions at pixel accuracy. The proposed GIID-Net\nconsists of three sub-blocks: the enhancement block, the extraction block and\nthe decision block. Specifically, the enhancement block aims to enhance the\ninpainting traces by using hierarchically combined special layers. The\nextraction block, automatically designed by Neural Architecture Search (NAS)\nalgorithm, is targeted to extract features for the actual inpainting detection\ntasks. In order to further optimize the extracted latent features, we integrate\nglobal and local attention modules in the decision block, where the global\nattention reduces the intra-class differences by measuring the similarity of\nglobal features, while the local attention strengthens the consistency of local\nfeatures. Furthermore, we thoroughly study the generalizability of our\nGIID-Net, and find that different training data could result in vastly\ndifferent generalization capability. Extensive experimental results are\npresented to validate the superiority of the proposed GIID-Net, compared with\nthe state-of-the-art competitors. Our results would suggest that common\nartifacts are shared across diverse image inpainting methods. Finally, we build\na public inpainting dataset of 10K image pairs for the future research in this\narea.", "doi": "", "date": "2021-01-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.07419v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3682416865, "title": "Quantifying agent impacts on contact sequences in social interactions", "abstract": "Human social behavior plays a crucial role in how pathogens like SARS-CoV-2\nor fake news spread in a population. Social interactions determine the contact\nnetwork among individuals, while spreading, requiring individual-to-individual\ntransmission, takes place on top of the network. Studying the topological\naspects of a contact network, therefore, not only has the potential of leading\nto valuable insights into how the behavior of individuals impacts spreading\nphenomena, but it may also open up possibilities for devising effective\nbehavioral interventions. Because of the temporal nature of interactions -\nsince the topology of the network, containing who is in contact with whom,\nwhen, for how long, and in which precise sequence, varies (rapidly) in time -\nanalyzing them requires developing network methods and metrics that respect\ntemporal variability, in contrast to those developed for static (i.e.,\ntime-invariant) networks. Here, by means of event mapping, we propose a method\nto quantify how quickly agents mingle by transforming temporal network data of\nagent contacts. We define a novel measure called 'contact sequence centrality',\nwhich quantifies the impact of an individual on the contact sequences,\nreflecting the individual's behavioral potential for spreading. Comparing\ncontact sequence centrality across agents allows for ranking the impact of\nagents and identifying potential 'behavioral super-spreaders'. The method is\napplied to social interaction data collected at an art fair in Amsterdam. We\nrelate the measure to the existing network metrics, both temporal and static,\nand find that (mostly at longer time scales) traditional metrics lose their\nresemblance to contact sequence centrality. Our work highlights the importance\nof accounting for the sequential nature of contacts when analyzing social\ninteractions.", "doi": "", "date": "2021-07-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.01443v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1833834214, "title": "Cognitive Contagion: How to model (and potentially counter) the spread\n  of fake news", "abstract": "Understanding the spread of false or dangerous beliefs - so-called\nmis/disinformation - through a population has never seemed so urgent to many.\nNetwork science researchers have often taken a page from epidemiologists, and\nmodeled the spread of false beliefs as similar to how a disease spreads through\na social network. However, absent from those disease-inspired models is an\ninternal model of an individual's set of current beliefs, where cognitive\nscience has increasingly documented how the interaction between mental models\nand incoming messages seems to be crucially important for their adoption or\nrejection. We introduce a cognitive contagion model that combines a network\nscience approach with an internal cognitive model of the individual agents,\naffecting what they believe, and what they pass on. We show that the model,\neven with a very discrete and simplistic belief function to capture cognitive\ndissonance, both adds expressive power over existing disease-based contagion\nmodels, and qualitatively demonstrates the appropriate belief update phenomena\nat the individual level. Moreover, we situate our cognitive contagion model in\na larger public opinion diffusion model, which attempts to capture the role of\ninstitutions or media sources in belief diffusion - something that is often\nleft out. We conduct an analysis of the POD model with our simple cognitive\ndissonance-sensitive update function across various graph topologies and\ninstitutional messaging patterns. We demonstrate that population-level\naggregate outcomes of the model qualitatively match what has been reported in\nCOVID misinformation public opinion polls. The overall model sets up a\npreliminary framework with which social science misinformation researchers and\ncomputational opinion diffusion modelers can join forces to understand, and\nhopefully learn how to best counter, the spread of misinformation and\n\"alternative facts.\"", "doi": "", "date": "2021-07-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.02828v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3244559317, "title": "Exploring the effect of social media and spatial characteristics during\n  the COVID-19 pandemic in China", "abstract": "The declaration of COVID-19 as a pandemic has largely amplified the spread of\nrelated information on social media, such as Twitter, Facebook, and\nWeChat.Unlike the previous studies which focused on how to detect the\nmisinformation or fake news related toCOVID-19, we investigate how the disease\nand information co-evolve in the population. We focus onCOVID-19and its\ninformation during the period when the disease was widely spread in China,\ni.e., from January 25th to March 24th, 2020. We first explore how the disease\nand information co-evolve via the spatial analysis of the two spreading\nprocesses. We visualize the geo-location of both disease and information at the\nprovince level and find that disease is more geo-localized compared to\ninformation. We find a high correlation between the disease and information\ndata, and also people care about the spread only when it comes to their\nneighborhood. Regard to the content of the information, we find that positive\nmessages are more negatively correlated with the disease compared to negative\nand neutral messages. Additionally, we introduce machine learning algorithms,\ni.e., linear regression and random forest, to further predict the number of\ninfected using different disease spatial related and information-related\ncharacteristics. We obtain that the disease spatial related characteristics of\nnearby cities can help to improve the prediction accuracy. Meanwhile,\ninformation-related characteristics can also help to improve the prediction\nperformance, but with a delay, i.e., the improvement comes from using, for\ninstance, the number of messages 10 days ago, for disease prediction. The\nmethodology proposed in this paper may shed light on new clues of emerging\ninfections", "doi": "", "date": "2021-07-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.03766v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2120027066, "title": "News Image Steganography - A Novel Architecture Facilitates the Fake News Identification.", "abstract": "", "doi": "10.1109/vcip49819.2020.9301846", "date": "2020", "authors": [{"name": "Jizhe Zhou", "id-internal": "172/4712", "id-external": ""}, {"name": "Chi-Man Pun", "id-internal": "p/ChiManPun", "id-external": ""}, {"name": "Yu Tong", "id-internal": "22/2859", "id-external": ""}], "url": {"full": "URL#570173", "pdf": ""}, "publisher-venue": "VCIP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1951177736, "title": "Fake news agenda in the era of COVID-19 - Identifying trends through fact-checking content.", "abstract": "", "doi": "10.1016/j.osnem.2020.100116", "date": "2021", "authors": [{"name": "Wilson Ceron", "id-internal": "278/0576", "id-external": ""}, {"name": "Mathias-Felipe de-Lima-Santos", "id-internal": "281/7708", "id-external": ""}, {"name": "Marcos G. Quiles", "id-internal": "70/1985", "id-external": ""}], "url": {"full": "URL#76836", "pdf": ""}, "publisher-venue": "Online Soc. Networks Media", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 73554781, "title": "g2tmn at Constraint@AAAI2021 - Exploiting CT-BERT and Ensembling Learning for COVID-19 Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_12", "date": "2021", "authors": [{"name": "Anna Glazkova", "id-internal": "229/8527", "id-external": ""}, {"name": "Maksim Glazkov", "id-internal": "275/3767", "id-external": ""}, {"name": "Timofey Trifonov", "id-internal": "282/0099", "id-external": ""}], "url": {"full": "URL#123603", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 625964580, "title": "Identification of COVID-19 Related Fake News via Neural Stacking.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_17", "date": "2021", "authors": [{"name": "Boshko Koloski", "id-internal": "277/0961", "id-external": ""}, {"name": "Timen Stepisnik Perdih", "id-internal": "283/4592", "id-external": ""}, {"name": "Senja Pollak", "id-internal": "75/8154", "id-external": ""}, {"name": "Blaz Skrlj", "id-internal": "190/6972", "id-external": ""}], "url": {"full": "URL#123873", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 938482831, "title": "Fighting an Infodemic - COVID-19 Fake News Dataset.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_3", "date": "2021", "authors": [{"name": "Parth Patwa", "id-internal": "260/9345", "id-external": ""}, {"name": "Shivam Sharma", "id-internal": "146/2381", "id-external": ""}, {"name": "Srinivas PYKL", "id-internal": "168/6642", "id-external": ""}, {"name": "Vineeth Guptha", "id-internal": "266/0781", "id-external": ""}, {"name": "Gitanjali Kumari", "id-internal": "278/2631", "id-external": ""}, {"name": "Md. Shad Akhtar", "id-internal": "184/8579", "id-external": ""}, {"name": "Asif Ekbal", "id-internal": "11/3590", "id-external": ""}, {"name": "Amitava Das", "id-internal": "75/5002", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}], "url": {"full": "URL#124304", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2459291684, "title": "Evaluating Deep Learning Approaches for Covid19 Fake News Detection.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_15", "date": "2021", "authors": [{"name": "Apurva Wani", "id-internal": "283/4456", "id-external": ""}, {"name": "Isha Joshi", "id-internal": "283/4336", "id-external": ""}, {"name": "Snehal Khandve", "id-internal": "283/4273", "id-external": ""}, {"name": "Vedangi Wagh", "id-internal": "283/4277", "id-external": ""}, {"name": "Raviraj Joshi", "id-internal": "229/7269", "id-external": ""}], "url": {"full": "URL#124670", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2721422251, "title": "Profiling Fake News Spreaders on Social Media through Psychological and Motivational Factors.", "abstract": "", "doi": "10.1145/3465336.3475097", "date": "2021", "authors": [{"name": "Mansooreh Karami", "id-internal": "243/0884", "id-external": ""}, {"name": "Tahora H. Nazer", "id-internal": "190/5215", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#151535", "pdf": ""}, "publisher-venue": "HT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2617454963, "title": "DeHiDe - Deep Learning-based Hybrid Model to Detect Fake News using Blockchain\u2731.", "abstract": "", "doi": "10.1145/3427796.3430003", "date": "2021", "authors": [{"name": "Prashansa Agrawal", "id-internal": "276/6775", "id-external": ""}, {"name": "Parwat Singh Anjana", "id-internal": "207/5234", "id-external": ""}, {"name": "Sathya Peri", "id-internal": "41/5564", "id-external": ""}], "url": {"full": "URL#156978", "pdf": ""}, "publisher-venue": "ICDCN", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3827989039, "title": "Causal Understanding of Fake News Dissemination on Social Media.", "abstract": "", "doi": "10.1145/3447548.3467321", "date": "2021", "authors": [{"name": "Lu Cheng", "id-internal": "17/4969", "id-external": ""}, {"name": "Ruocheng Guo", "id-internal": "167/4378", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#170163", "pdf": ""}, "publisher-venue": "KDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1055989339, "title": "Multimodal Emergent Fake News Detection via Meta Neural Process Networks.", "abstract": "", "doi": "10.1145/3447548.3467153", "date": "2021", "authors": [{"name": "Yaqing Wang", "id-internal": "147/1393", "id-external": ""}, {"name": "Fenglong Ma", "id-internal": "85/10856", "id-external": ""}, {"name": "Haoyu Wang", "id-internal": "50/8499", "id-external": ""}, {"name": "Kishlay Jha", "id-internal": "177/7445", "id-external": ""}, {"name": "Jing Gao", "id-internal": "67/4834", "id-external": ""}], "url": {"full": "URL#170463", "pdf": ""}, "publisher-venue": "KDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3662393668, "title": "Mining Dual Emotion for Fake News Detection.", "abstract": "", "doi": "10.1145/3442381.3450004", "date": "2021", "authors": [{"name": "Xueyao Zhang", "id-internal": "237/9484", "id-external": ""}, {"name": "Juan Cao", "id-internal": "75/2820", "id-external": ""}, {"name": "Xirong Li", "id-internal": "58/5856", "id-external": ""}, {"name": "Qiang Sheng", "id-internal": "199/7557", "id-external": ""}, {"name": "Lei Zhong", "id-internal": "22/3431", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}], "url": {"full": "URL#187876", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1859996606, "title": "A Survey of Fake News - Fundamental Theories, Detection Methods, and Opportunities.", "abstract": "", "doi": "10.1145/3395046", "date": "2020", "authors": [{"name": "Xinyi Zhou", "id-internal": "183/6661", "id-external": ""}, {"name": "Reza Zafarani", "id-internal": "93/909", "id-external": ""}], "url": {"full": "URL#289218", "pdf": ""}, "publisher-venue": "ACM Comput. Surv.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3810412861, "title": "FANG - Leveraging Social Context for Fake News Detection Using Graph Representation.", "abstract": "", "doi": "10.1145/3340531.3412046", "date": "2020", "authors": [{"name": "Van-Hoang Nguyen", "id-internal": "272/9171", "id-external": ""}, {"name": "Kazunari Sugiyama", "id-internal": "50/7001", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Min-Yen Kan", "id-internal": "k/MinYenKan", "id-external": ""}], "url": {"full": "URL#444891", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3911258472, "title": "BRENDA - Browser Extension for Fake News Detection.", "abstract": "", "doi": "10.1145/3397271.3401396", "date": "2020", "authors": [{"name": "Bjarte Botnevik", "id-internal": "266/1405", "id-external": ""}, {"name": "Eirik Sakariassen", "id-internal": "266/1444", "id-external": ""}, {"name": "Vinay Setty", "id-internal": "36/8510", "id-external": ""}], "url": {"full": "URL#559918", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1526433269, "title": "The Web of False Information - Rumors, Fake News, Hoaxes, Clickbait, and Various Other Shenanigans.", "abstract": "", "doi": "10.1145/3309699", "date": "2019", "authors": [{"name": "Savvas Zannettou", "id-internal": "184/5969", "id-external": ""}, {"name": "Michael Sirivianos", "id-internal": "92/5463", "id-external": ""}, {"name": "Jeremy Blackburn", "id-internal": "12/8780", "id-external": ""}, {"name": "Nicolas Kourtellis", "id-internal": "96/8779", "id-external": ""}], "url": {"full": "URL#744472", "pdf": ""}, "publisher-venue": "ACM J. Data Inf. Qual.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 780601434, "title": "News labeling as early as possible - real or fake?", "abstract": "", "doi": "10.1145/3341161.3342957", "date": "2019", "authors": [{"name": "Maryam Ramezani", "id-internal": "79/542", "id-external": ""}, {"name": "Mina Rafiei", "id-internal": "242/9107", "id-external": ""}, {"name": "Soroush Omranpour", "id-internal": "242/8864", "id-external": ""}, {"name": "Hamid R. Rabiee", "id-internal": "01/4547", "id-external": ""}], "url": {"full": "URL#832847", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 291293924, "title": "Fake News Detection via NLP is Vulnerable to Adversarial Attacks.", "abstract": "", "doi": "10.5220/0007566307940800", "date": "2019", "authors": [{"name": "Zhixuan Zhou", "id-internal": "228/6035", "id-external": ""}, {"name": "Huankang Guan", "id-internal": "234/8472", "id-external": ""}, {"name": "Meghana Moorthy Bhat", "id-internal": "234/8670", "id-external": ""}, {"name": "Justin Hsu", "id-internal": "35/10964", "id-external": ""}], "url": {"full": "URL#887738", "pdf": ""}, "publisher-venue": "ICAART", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2352337752, "title": "A Topic-Agnostic Approach for Identifying Fake News Pages.", "abstract": "", "doi": "10.1145/3308560.3316739", "date": "2019", "authors": [{"name": "Sonia Castelo", "id-internal": "240/9112", "id-external": ""}, {"name": "Thais G. Almeida", "id-internal": "190/1391", "id-external": ""}, {"name": "Anas Elghafari", "id-internal": "53/8158", "id-external": ""}, {"name": "A\u00e9cio S. R. Santos", "id-internal": "135/2637", "id-external": ""}, {"name": "Kien Pham", "id-internal": "52/7031", "id-external": ""}, {"name": "Eduardo Freire Nakamura", "id-internal": "86/0", "id-external": ""}, {"name": "Juliana Freire", "id-internal": "f/JulianaFreire", "id-external": ""}], "url": {"full": "URL#995274", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3754433392, "title": "XFake - Explainable Fake News Detector with Visualizations.", "abstract": "", "doi": "10.1145/3308558.3314119", "date": "2019", "authors": [{"name": "Fan Yang 0023", "id-internal": "29/3081-23", "id-external": ""}, {"name": "Shiva K. Pentyala", "id-internal": "240/9336", "id-external": ""}, {"name": "Sina Mohseni", "id-internal": "155/4739", "id-external": ""}, {"name": "Mengnan Du", "id-internal": "183/5606", "id-external": ""}, {"name": "Hao Yuan", "id-internal": "92/867", "id-external": ""}, {"name": "Rhema Linder", "id-internal": "132/1528", "id-external": ""}, {"name": "Eric D. Ragan", "id-internal": "69/7691", "id-external": ""}, {"name": "Shuiwang Ji", "id-internal": "84/6405", "id-external": ""}, {"name": "Xia (Ben) Hu", "id-internal": "240/9062", "id-external": ""}], "url": {"full": "URL#995776", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4058946959, "title": "Fake News Identification on Twitter with Hybrid CNN and RNN Models.", "abstract": "", "doi": "10.1145/3217804.3217917", "date": "2018", "authors": [{"name": "Oluwaseun Ajao", "id-internal": "173/0924", "id-external": ""}, {"name": "Deepayan Bhowmik", "id-internal": "44/7616", "id-external": ""}, {"name": "Shahrzad Zargari", "id-internal": "122/8657", "id-external": ""}], "url": {"full": "URL#1356168", "pdf": ""}, "publisher-venue": "SMSociety", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1277541659, "title": "CSI - A Hybrid Deep Model for Fake News Detection.", "abstract": "", "doi": "10.1145/3132847.3132877", "date": "2017", "authors": [{"name": "Natali Ruchansky", "id-internal": "12/9876", "id-external": ""}, {"name": "Sungyong Seo", "id-internal": "178/3209", "id-external": ""}, {"name": "Yan Liu 0002", "id-internal": "l/YanLiu2", "id-external": ""}], "url": {"full": "URL#1581293", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2508260599, "title": "We Built a Fake News / Click Bait Filter - What Happened Next Will Blow Your Mind!", "abstract": "", "doi": "10.26615/978-954-452-049-6_045", "date": "2017", "authors": [{"name": "Georgi Karadzhov", "id-internal": "205/1966", "id-external": ""}, {"name": "Pepa Gencheva", "id-internal": "184/2024", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Ivan Koychev", "id-internal": "88/2617", "id-external": ""}], "url": {"full": "URL#1688517", "pdf": ""}, "publisher-venue": "RANLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 378061556, "title": "Automatically Identifying Fake News in Popular Twitter Threads.", "abstract": "", "doi": "10.1109/smartcloud.2017.40", "date": "2017", "authors": [{"name": "Cody Buntain", "id-internal": "34/7214", "id-external": ""}, {"name": "Jennifer Golbeck", "id-internal": "48/2412", "id-external": ""}], "url": {"full": "URL#1699124", "pdf": ""}, "publisher-venue": "SmartCloud", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}][{"id": 2004146048, "title": "It doesn't take a village to fall for misinformation - Social media use, discussion heterogeneity preference, worry of the virus, faith in scientists, and COVID-19-related misinformation beliefs.", "abstract": "", "doi": "10.1016/j.tele.2020.101547", "date": "2021", "authors": {"name": "Yan Su", "id-internal": "28/2981", "id-external": ""}, "url": {"full": "URL#105985", "pdf": ""}, "publisher-venue": "Telematics Informatics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2045402863, "title": "Encounters with Visual Misinformation and Labels Across Platforms - An Interview and Diary Study to Inform Ecosystem Approaches to Misinformation Interventions.", "abstract": "", "doi": "10.1145/3411763.3451807", "date": "2021", "authors": [{"name": "Emily Saltz", "id-internal": "207/5919", "id-external": ""}, {"name": "Claire R. Leibowicz", "id-internal": "279/6624", "id-external": ""}, {"name": "Claire Wardle", "id-internal": "240/9227", "id-external": ""}], "url": {"full": "URL#135874", "pdf": ""}, "publisher-venue": "CHI Extended Abstracts", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2073248509, "title": "Encounters with Visual Misinformation and Labels Across Platforms - An Interview and Diary Study to Inform Ecosystem Approaches to Misinformation Interventions.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Emily Saltz", "id-internal": "207/5919", "id-external": ""}, {"name": "Claire Leibowicz", "id-internal": "279/6624", "id-external": ""}, {"name": "Claire Wardle", "id-internal": "240/9227", "id-external": ""}], "url": {"full": "URL#646428", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2676781004, "title": "'Misinformation? What of it?' Motivations and individual differences in misinformation sharing on social media.", "abstract": "", "doi": "10.1002/meet.14505001102", "date": "2013", "authors": [{"name": "Xinran Chen", "id-internal": "163/7043", "id-external": ""}, {"name": "Sei-Ching Joanna Sin", "id-internal": "68/9553", "id-external": ""}], "url": {"full": "URL#2763590", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1303543743, "title": "An Ontology-Supported Misinformation Model - Toward a Digital Misinformation Library.", "abstract": "", "doi": "10.1109/tsmca.2007.902648", "date": "2007", "authors": [{"name": "Lina Zhou", "id-internal": "82/1412", "id-external": ""}, {"name": "Dongsong Zhang", "id-internal": "73/3867", "id-external": ""}], "url": {"full": "URL#4145330", "pdf": ""}, "publisher-venue": "IEEE Trans. Syst. Man Cybern. Part A", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2326953448, "title": "Information and misinformation - An investigation of the notions of information, misinformation, informing, and misinforming.", "abstract": "", "doi": "10.1002/(sici)1097-4571(198601)37:1<48::aid-asi10>3.0.co;2-3", "date": "1986", "authors": {"name": "William B. Frakes", "id-internal": "f/WBFrakes", "id-external": ""}, "url": {"full": "URL#5618958", "pdf": ""}, "publisher-venue": "J. Am. Soc. Inf. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1237834458, "title": "Information and Misinformation - An Investigation of the Notions of Information, Misinformation, Informing and Misinforming by C. J. Fox (Review).", "abstract": "", "doi": "10.1145/15497.1096832", "date": "1986", "authors": {"name": "William B. Frakes", "id-internal": "f/WBFrakes", "id-external": ""}, "url": {"full": "URL#5621632", "pdf": ""}, "publisher-venue": "SIGIR Forum", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1173238749, "title": "Machine learning techniques and older adults processing of online information and misinformation - A covid 19 study.", "abstract": "", "doi": "10.1016/j.chb.2021.106716", "date": "2021", "authors": [{"name": "Jyoti Choudrie", "id-internal": "64/5241", "id-external": ""}, {"name": "Snehasish Banerjee", "id-internal": "128/7155", "id-external": ""}, {"name": "Ketan Kotecha", "id-internal": "66/1119", "id-external": ""}, {"name": "Rahee Walambe", "id-internal": "220/4242", "id-external": ""}, {"name": "Hema Karende", "id-internal": "288/0433", "id-external": ""}, {"name": "Juhi Ameta", "id-internal": "120/7432", "id-external": ""}], "url": {"full": "URL#21791", "pdf": ""}, "publisher-venue": "Comput. Hum. Behav.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 813086837, "title": "Deceptive accusations and concealed identities as misinformation campaign strategies.", "abstract": "", "doi": "10.1007/s10588-021-09328-x", "date": "2021", "authors": [{"name": "Daniele Bellutta", "id-internal": "202/2066", "id-external": ""}, {"name": "Catherine King", "id-internal": "258/9323", "id-external": ""}, {"name": "Kathleen M. Carley", "id-internal": "72/6492", "id-external": ""}], "url": {"full": "URL#23529", "pdf": ""}, "publisher-venue": "Comput. Math. Organ. Theory", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2202500499, "title": "Flow of online misinformation during the peak of the COVID-19 pandemic in Italy.", "abstract": "", "doi": "10.1140/epjds/s13688-021-00289-4", "date": "2021", "authors": [{"name": "Guido Caldarelli", "id-internal": "50/6478", "id-external": ""}, {"name": "Rocco De Nicola", "id-internal": "n/RDNicola", "id-external": ""}, {"name": "Marinella Petrocchi", "id-internal": "30/3349", "id-external": ""}, {"name": "Manuel Pratelli", "id-internal": "269/2613", "id-external": ""}, {"name": "Fabio Saracco", "id-internal": "183/6149", "id-external": ""}], "url": {"full": "URL#35485", "pdf": ""}, "publisher-venue": "EPJ Data Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3115941096, "title": "Correction to - Flow of online misinformation during the peak of the COVID-19 pandemic in Italy.", "abstract": "", "doi": "10.1140/epjds/s13688-021-00296-5", "date": "2021", "authors": [{"name": "Guido Caldarelli", "id-internal": "50/6478", "id-external": ""}, {"name": "Rocco De Nicola", "id-internal": "n/RDNicola", "id-external": ""}, {"name": "Marinella Petrocchi", "id-internal": "30/3349", "id-external": ""}, {"name": "Manuel Pratelli", "id-internal": "269/2613", "id-external": ""}, {"name": "Fabio Saracco", "id-internal": "183/6149", "id-external": ""}], "url": {"full": "URL#35486", "pdf": ""}, "publisher-venue": "EPJ Data Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1915480211, "title": "Text Analysis Methods for Misinformation-Related Research on Finnish Language Twitter.", "abstract": "", "doi": "10.3390/fi13060157", "date": "2021", "authors": [{"name": "Jari Jussila", "id-internal": "55/10211", "id-external": ""}, {"name": "Anu Helena Suominen", "id-internal": "286/0382", "id-external": ""}, {"name": "Atte Partanen", "id-internal": "252/0846", "id-external": ""}, {"name": "Tapani Honkanen", "id-internal": "68/3718", "id-external": ""}], "url": {"full": "URL#38339", "pdf": ""}, "publisher-venue": "Future Internet", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1226035560, "title": "Healthcare professionals' acts of correcting health misinformation on social media.", "abstract": "", "doi": "10.1016/j.ijmedinf.2021.104375", "date": "2021", "authors": [{"name": "John Robert Bautista", "id-internal": "172/4058", "id-external": ""}, {"name": "Yan Zhang 0005", "id-internal": "04/3348-5", "id-external": ""}, {"name": "Jacek Gwizdka", "id-internal": "09/6688", "id-external": ""}], "url": {"full": "URL#46796", "pdf": ""}, "publisher-venue": "Int. J. Medical Informatics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 18491311, "title": "Analyzing Public Opinion and Misinformation in a COVID-19 Telegram Group Chat.", "abstract": "", "doi": "10.1109/mic.2020.3040516", "date": "2021", "authors": [{"name": "Lynnette Hui Xian Ng", "id-internal": "277/0683", "id-external": ""}, {"name": "Loke Jia Yuan", "id-internal": "277/0553", "id-external": ""}], "url": {"full": "URL#51410", "pdf": ""}, "publisher-venue": "IEEE Internet Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1154323551, "title": "Misinformation Sharing on Twitter During Zika - An Investigation of the Effect of Threat and Distance.", "abstract": "", "doi": "10.1109/mic.2020.3044543", "date": "2021", "authors": [{"name": "Rohit Valecha", "id-internal": "60/11315", "id-external": ""}, {"name": "Tejaswi Volety", "id-internal": "228/2241", "id-external": ""}, {"name": "H. Raghav Rao", "id-internal": "r/HRaghavRao", "id-external": ""}, {"name": "Kyounghee Hazel Kwon", "id-internal": "07/9151", "id-external": ""}], "url": {"full": "URL#51424", "pdf": ""}, "publisher-venue": "IEEE Internet Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 168577054, "title": "Persuasion strategies of misinformation-containing posts in the social media.", "abstract": "", "doi": "10.1016/j.ipm.2021.102665", "date": "2021", "authors": [{"name": "Sijing Chen", "id-internal": "204/3083", "id-external": ""}, {"name": "Lu Xiao 0002", "id-internal": "78/5386-2", "id-external": ""}, {"name": "Jin Mao", "id-internal": "142/3605", "id-external": ""}], "url": {"full": "URL#52780", "pdf": ""}, "publisher-venue": "Inf. Process. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3226876125, "title": "Misinformation detection using multitask learning with mutual learning for novelty detection and emotion recognition.", "abstract": "", "doi": "10.1016/j.ipm.2021.102631", "date": "2021", "authors": [{"name": "Rina Kumari", "id-internal": "254/8316", "id-external": ""}, {"name": "Nischal Ashok", "id-internal": "299/0528", "id-external": ""}, {"name": "Tirthankar Ghosal", "id-internal": "215/3590", "id-external": ""}, {"name": "Asif Ekbal", "id-internal": "11/3590", "id-external": ""}], "url": {"full": "URL#52828", "pdf": ""}, "publisher-venue": "Inf. Process. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 33904458, "title": "Detecting health misinformation in online health communities - Incorporating behavioral features into machine learning based approaches.", "abstract": "", "doi": "10.1016/j.ipm.2020.102390", "date": "2021", "authors": [{"name": "Yuehua Zhao", "id-internal": "83/6267", "id-external": ""}, {"name": "Jingwei Da", "id-internal": "253/4161", "id-external": ""}, {"name": "Jiaqi Yan", "id-internal": "79/8041", "id-external": ""}], "url": {"full": "URL#52953", "pdf": ""}, "publisher-venue": "Inf. Process. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1882553237, "title": "Characterizing the dissemination of misinformation on social media in health emergencies - An empirical study based on COVID-19.", "abstract": "", "doi": "10.1016/j.ipm.2021.102554", "date": "2021", "authors": [{"name": "Cheng Zhou", "id-internal": "61/3491", "id-external": ""}, {"name": "Haoxin Xiu", "id-internal": "294/2743", "id-external": ""}, {"name": "Yuqiu Wang", "id-internal": "233/5758", "id-external": ""}, {"name": "Xinyao Yu", "id-internal": "26/834", "id-external": ""}], "url": {"full": "URL#52963", "pdf": ""}, "publisher-venue": "Inf. Process. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 611142589, "title": "Misinformation influence minimization problem based on group disbanded in social networks.", "abstract": "", "doi": "10.1016/j.ins.2021.04.086", "date": "2021", "authors": [{"name": "Jianming Zhu", "id-internal": "50/1455", "id-external": ""}, {"name": "Peikun Ni", "id-internal": "272/3977", "id-external": ""}, {"name": "Guoqing Wang", "id-internal": "17/356", "id-external": ""}, {"name": "Yuan Li", "id-internal": "86/6196", "id-external": ""}], "url": {"full": "URL#54035", "pdf": ""}, "publisher-venue": "Inf. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3231946, "title": "2021 C-Suite Awareness - From Privacy to Misinformation to Diversity, Inclusion, and Equality.", "abstract": "", "doi": "10.1109/mitp.2021.3057245", "date": "2021", "authors": {"name": "Stephen J. Andriole", "id-internal": "95/5075", "id-external": ""}, "url": {"full": "URL#54836", "pdf": ""}, "publisher-venue": "IT Prof.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 552338205, "title": "Influence of community structure on misinformation containment in online social networks.", "abstract": "", "doi": "10.1016/j.knosys.2020.106693", "date": "2021", "authors": [{"name": "Arnab Kumar Ghoshal", "id-internal": "192/5890", "id-external": ""}, {"name": "Nabanita Das", "id-internal": "49/3105", "id-external": ""}, {"name": "Soham Das 0001", "id-internal": "88/10960", "id-external": ""}], "url": {"full": "URL#66869", "pdf": ""}, "publisher-venue": "Knowl. Based Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 322328160, "title": "Encountering misinformation online - antecedents of trust and distrust and their impact on the intensity of Facebook use.", "abstract": "", "doi": "10.1108/oir-04-2020-0130", "date": "2021", "authors": [{"name": "Yang Cheng", "id-internal": "27/986", "id-external": ""}, {"name": "Zifei Fay Chen", "id-internal": "208/9853", "id-external": ""}], "url": {"full": "URL#76211", "pdf": ""}, "publisher-venue": "Online Inf. Rev.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1783220095, "title": "An exploratory study of COVID-19 misinformation on Twitter.", "abstract": "", "doi": "10.1016/j.osnem.2020.100104", "date": "2021", "authors": [{"name": "Gautam Kishore Shahi", "id-internal": "178/1872", "id-external": ""}, {"name": "Anne Dirkson", "id-internal": "232/2085", "id-external": ""}, {"name": "Tim A. Majchrzak", "id-internal": "03/7451", "id-external": ""}], "url": {"full": "URL#76849", "pdf": ""}, "publisher-venue": "Online Soc. Networks Media", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2867223442, "title": "Misinformation vs. Situational Awareness - The Art of Deception and the Need for Cross-Domain Detection.", "abstract": "", "doi": "10.3390/s21165496", "date": "2021", "authors": [{"name": "Constantinos-Giovanni Xarhoulacos", "id-internal": "300/7009", "id-external": ""}, {"name": "Argiro Anagnostopoulou", "id-internal": "230/1444", "id-external": ""}, {"name": "George Stergiopoulos", "id-internal": "52/10878", "id-external": ""}, {"name": "Dimitris Gritzalis", "id-internal": "48/4664", "id-external": ""}], "url": {"full": "URL#92302", "pdf": ""}, "publisher-venue": "Sensors", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1004637386, "title": "Identifying Covid-19 misinformation tweets and learning their spatio-temporal topic dynamics using Nonnegative Coupled Matrix Tensor Factorization.", "abstract": "", "doi": "10.1007/s13278-021-00767-7", "date": "2021", "authors": [{"name": "Thirunavukarasu Balasubramaniam", "id-internal": "194/2536", "id-external": ""}, {"name": "Richi Nayak", "id-internal": "99/1071", "id-external": ""}, {"name": "Khanh Luong", "id-internal": "228/4094", "id-external": ""}, {"name": "Md. Abul Bashar", "id-internal": "04/8203", "id-external": ""}], "url": {"full": "URL#94953", "pdf": ""}, "publisher-venue": "Soc. Netw. Anal. Min.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 598420279, "title": "Use of bot and content flags to limit the spread of misinformation among social networks - a behavior and attitude survey.", "abstract": "", "doi": "10.1007/s13278-021-00739-x", "date": "2021", "authors": [{"name": "Candice L. Lanius", "id-internal": "190/5209", "id-external": ""}, {"name": "Ryan Weber", "id-internal": "25/6294", "id-external": ""}, {"name": "William I. MacKenzie", "id-internal": "288/0480", "id-external": ""}], "url": {"full": "URL#94987", "pdf": ""}, "publisher-venue": "Soc. Netw. Anal. Min.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2394492476, "title": "A unified account of information, misinformation, and disinformation.", "abstract": "", "doi": "10.1007/s11229-019-02444-x", "date": "2021", "authors": {"name": "Sille Obelitz S\u00f8e", "id-internal": "215/9000", "id-external": ""}, "url": {"full": "URL#99982", "pdf": ""}, "publisher-venue": "Synth.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3839362113, "title": "Misinformation During the COVID-19 Outbreak in China - Cultural, Social and Political Entanglements.", "abstract": "", "doi": "10.1109/tbdata.2021.3055758", "date": "2021", "authors": [{"name": "Yan Leng", "id-internal": "98/1164", "id-external": ""}, {"name": "Yujia Zhai", "id-internal": "70/1500", "id-external": ""}, {"name": "Shaojing Sun", "id-internal": "66/9154", "id-external": ""}, {"name": "Yifei Wu", "id-internal": "95/9480", "id-external": ""}, {"name": "Jordan Selzer", "id-internal": "265/5650", "id-external": ""}, {"name": "Sharon Strover", "id-internal": "60/5261", "id-external": ""}, {"name": "Hezhao Zhang", "id-internal": "287/1797", "id-external": ""}, {"name": "Anfan Chen", "id-internal": "263/2160", "id-external": ""}, {"name": "Ying Ding 0001", "id-internal": "38/6013-1", "id-external": ""}], "url": {"full": "URL#101687", "pdf": ""}, "publisher-venue": "IEEE Trans. Big Data", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1288782552, "title": "A Theoretically Guaranteed Approach to Efficiently Block the Influence of Misinformation in Social Networks.", "abstract": "", "doi": "10.1109/tcss.2021.3059430", "date": "2021", "authors": [{"name": "Mohammad Ali Manouchehri", "id-internal": "294/5608", "id-external": ""}, {"name": "Mohammad Sadegh Helfroush", "id-internal": "51/7841", "id-external": ""}, {"name": "Habibollah Danyali", "id-internal": "49/1705", "id-external": ""}], "url": {"full": "URL#104571", "pdf": ""}, "publisher-venue": "IEEE Trans. Comput. Soc. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 980446524, "title": "Detecting Medical Misinformation on Social Media Using Multimodal Deep Learning.", "abstract": "", "doi": "10.1109/jbhi.2020.3037027", "date": "2021", "authors": [{"name": "Zuhui Wang", "id-internal": "116/8603", "id-external": ""}, {"name": "Zhaozheng Yin", "id-internal": "89/4637", "id-external": ""}, {"name": "Young Anna Argyris", "id-internal": "164/0484", "id-external": ""}], "url": {"full": "URL#112440", "pdf": ""}, "publisher-venue": "IEEE J. Biomed. Health Informatics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3958936141, "title": "Two Truths and a Lie - Exploring Soft Moderation of COVID-19 Misinformation with Amazon Alexa.", "abstract": "", "doi": "10.1145/3465481.3470017", "date": "2021", "authors": [{"name": "Filipo Sharevski", "id-internal": "154/7105", "id-external": ""}, {"name": "Donald Gover", "id-internal": "289/7565", "id-external": ""}], "url": {"full": "URL#122747", "pdf": ""}, "publisher-venue": "ARES", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2650394052, "title": "SAMS - Human-in-the-loop Approach to Combat the Sharing of Digital Misinformation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Shaban Shabani", "id-internal": "185/3554", "id-external": ""}, {"name": "Zarina Charlesworth", "id-internal": "290/5328", "id-external": ""}, {"name": "Maria Sokhn", "id-internal": "52/7093", "id-external": ""}, {"name": "Heiko Schuldt", "id-internal": "s/HSchuldt", "id-external": ""}], "url": {"full": "URL#125085", "pdf": ""}, "publisher-venue": "AAAI Spring Symposium - Combining Machine Learning with Knowledge Engineering", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2110226707, "title": "Structurizing Misinformation Stories via Rationalizing Fact-Checks.", "abstract": "", "doi": "10.18653/v1/2021.acl-long.51", "date": "2021", "authors": [{"name": "Shan Jiang 0008", "id-internal": "04/2910-8", "id-external": ""}, {"name": "Christo Wilson", "id-internal": "79/5135", "id-external": ""}], "url": {"full": "URL#125292", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3049440719, "title": "COVID-19 and Misinformation - A Large-Scale Lexical Analysis on Twitter.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Dimosthenis Antypas", "id-internal": "299/1573", "id-external": ""}, {"name": "Jos\u00e9 Camacho-Collados", "id-internal": "165/0790", "id-external": ""}, {"name": "Alun D. Preece", "id-internal": "p/AlunDPreece", "id-external": ""}, {"name": "David Rogers", "id-internal": "24/6521", "id-external": ""}], "url": {"full": "URL#125323", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1618743695, "title": "Edited Media Understanding Frames - Reasoning About the Intent and Implications of Visual Misinformation.", "abstract": "", "doi": "10.18653/v1/2021.acl-long.158", "date": "2021", "authors": [{"name": "Jeff Da", "id-internal": "249/9397", "id-external": ""}, {"name": "Maxwell Forbes", "id-internal": "151/9292", "id-external": ""}, {"name": "Rowan Zellers", "id-internal": "182/2175", "id-external": ""}, {"name": "Anthony Zheng", "id-internal": "278/8028", "id-external": ""}, {"name": "Jena D. Hwang", "id-internal": "83/10905", "id-external": ""}, {"name": "Antoine Bosselut", "id-internal": "184/3742", "id-external": ""}, {"name": "Yejin Choi", "id-internal": "89/579", "id-external": ""}], "url": {"full": "URL#125461", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4023888394, "title": "CMTA - COVID-19 Misinformation Multilingual Analysis on Twitter.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Raj Ratn Pranesh", "id-internal": "276/7213", "id-external": ""}, {"name": "Mehrdad Farokhenajd", "id-internal": "300/4140", "id-external": ""}, {"name": "Ambesh Shekhar", "id-internal": "280/6805", "id-external": ""}, {"name": "Genoveva Vargas-Solar", "id-internal": "v/GVargas-Solar", "id-external": ""}], "url": {"full": "URL#125984", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 668333901, "title": "Looking for COVID-19 Misinformation in Multilingual Social Media Texts.", "abstract": "", "doi": "10.1007/978-3-030-85082-1_7", "date": "2021", "authors": [{"name": "Raj Ratn Pranesh", "id-internal": "276/7213", "id-external": ""}, {"name": "Mehrdad Farokhnejad", "id-internal": "237/3395", "id-external": ""}, {"name": "Ambesh Shekhar", "id-internal": "280/6805", "id-external": ""}, {"name": "Genoveva Vargas-Solar", "id-internal": "v/GVargas-Solar", "id-external": ""}], "url": {"full": "URL#126737", "pdf": ""}, "publisher-venue": "ADBIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3951782892, "title": "Fighting Misinformation on Social Media - YouTube Cancer Videos.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Abdallah M. J. Musmar", "id-internal": "300/5811", "id-external": ""}, {"name": "Sunil Mithas", "id-internal": "21/7031", "id-external": ""}, {"name": "Balaji Padmanabhan", "id-internal": "63/4332", "id-external": ""}], "url": {"full": "URL#130530", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 692714514, "title": "Debunking Misinformation Using a Game Theoretic Approach.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Naga Vemprala", "id-internal": "228/2353", "id-external": ""}, {"name": "Naveen Gudigantala", "id-internal": "57/4605", "id-external": ""}, {"name": "Raj Chaganti", "id-internal": "284/8158", "id-external": ""}], "url": {"full": "URL#130625", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 636476004, "title": "Transfer Learning Model for Disrupting Misinformation During a COVID-19 Pandemic.", "abstract": "", "doi": "10.1109/ccwc51732.2021.9376066", "date": "2021", "authors": [{"name": "Rini Raju", "id-internal": "286/0936", "id-external": ""}, {"name": "Shova Bhandari", "id-internal": "286/1013", "id-external": ""}, {"name": "Sofia A. Mohamud", "id-internal": "288/3097", "id-external": ""}, {"name": "Ebrima N. Ceesay", "id-internal": "64/4378", "id-external": ""}], "url": {"full": "URL#134441", "pdf": ""}, "publisher-venue": "CCWC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 733912084, "title": "Workshop on Technologies to Support Critical Thinking in an Age of Misinformation.", "abstract": "", "doi": "10.1145/3411763.3441350", "date": "2021", "authors": [{"name": "Tilman Dingler", "id-internal": "79/8692", "id-external": ""}, {"name": "Benjamin Tag", "id-internal": "157/5198", "id-external": ""}, {"name": "Philipp Lorenz-Spreen", "id-internal": "243/7048", "id-external": ""}, {"name": "Andrew W. Vargo", "id-internal": "218/8595", "id-external": ""}, {"name": "Simon Knight 0001", "id-internal": "41/733", "id-external": ""}, {"name": "Stephan Lewandowsky", "id-internal": "22/8704", "id-external": ""}], "url": {"full": "URL#135220", "pdf": ""}, "publisher-venue": "CHI Extended Abstracts", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2353587876, "title": "Opinions, Intentions, Freedom of Expression, ... , and Other Human Aspects of Misinformation Online.", "abstract": "", "doi": "10.1145/3411763.3441345", "date": "2021", "authors": [{"name": "Lara S. G. Piccolo", "id-internal": "99/1852", "id-external": ""}, {"name": "Diotima Bertel", "id-internal": "201/3446", "id-external": ""}, {"name": "Tracie Farrell", "id-internal": "190/1706", "id-external": ""}, {"name": "Pinelopi Troullinou", "id-internal": "206/3390", "id-external": ""}], "url": {"full": "URL#135766", "pdf": ""}, "publisher-venue": "CHI Extended Abstracts", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 95043349, "title": "CIVIC-UPM at CheckThat!\u00a02021 - Integration of Transformers in Misinformation Detection and Topic Classification.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "\u00c1lvaro Huertas-Garc\u00eda", "id-internal": "300/1692", "id-external": ""}, {"name": "Javier Huertas-Tato", "id-internal": "277/4071", "id-external": ""}, {"name": "Alejandro Mart\u00edn", "id-internal": "70/2062", "id-external": ""}, {"name": "David Camacho", "id-internal": "64/1881", "id-external": ""}], "url": {"full": "URL#137462", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1733079576, "title": "Agents for Fighting Misinformation Spread on Twitter - Design Challenges.", "abstract": "", "doi": "10.1145/3469595.3469628", "date": "2021", "authors": [{"name": "Lara S. G. Piccolo", "id-internal": "99/1852", "id-external": ""}, {"name": "Azizah C. Blackwood", "id-internal": "297/7714", "id-external": ""}, {"name": "Tracie Farrell", "id-internal": "190/1706", "id-external": ""}, {"name": "Martino Mensio", "id-internal": "218/0707", "id-external": ""}], "url": {"full": "URL#140196", "pdf": ""}, "publisher-venue": "CUI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3364606071, "title": "Narrative Trends of COVID-19 Misinformation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Thomas Marcoux", "id-internal": "251/0546", "id-external": ""}, {"name": "Nitin Agarwal", "id-internal": "72/1395", "id-external": ""}], "url": {"full": "URL#144609", "pdf": ""}, "publisher-venue": "Text2Story@ECIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2191340150, "title": "ROMCIR 2021 - Reducing Online Misinformation through Credible Information Retrieval.", "abstract": "", "doi": "10.1007/978-3-030-72240-1_87", "date": "2021", "authors": [{"name": "Fabio Saracco", "id-internal": "183/6149", "id-external": ""}, {"name": "Marco Viviani", "id-internal": "33/2831", "id-external": ""}], "url": {"full": "URL#144641", "pdf": ""}, "publisher-venue": "ECIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3345592974, "title": "Detecting and Forecasting Misinformation via Temporal and Geometric Propagation Patterns.", "abstract": "", "doi": "10.1007/978-3-030-72240-1_48", "date": "2021", "authors": [{"name": "Qiang Zhang", "id-internal": "72/3527", "id-external": ""}, {"name": "Jonathan Cook", "id-internal": "36/4096", "id-external": ""}, {"name": "Emine Yilmaz", "id-internal": "36/3270", "id-external": ""}], "url": {"full": "URL#144670", "pdf": ""}, "publisher-venue": "ECIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1330349089, "title": "Coronabot - A Conversational AI System for Tackling Misinformation.", "abstract": "", "doi": "10.1145/3462203.3475874", "date": "2021", "authors": [{"name": "Nancie Gunson", "id-internal": "81/8716", "id-external": ""}, {"name": "Weronika Sieinska", "id-internal": "260/4214", "id-external": ""}, {"name": "Yanchao Yu", "id-internal": "177/1552", "id-external": ""}, {"name": "Daniel Hern\u00e1ndez Garc\u00eda", "id-internal": "14/2258", "id-external": ""}, {"name": "Jose L. Part", "id-internal": "204/2986", "id-external": ""}, {"name": "Christian Dondrup", "id-internal": "142/3092", "id-external": ""}, {"name": "Oliver Lemon", "id-internal": "36/6352", "id-external": ""}], "url": {"full": "URL#148265", "pdf": ""}, "publisher-venue": "GoodIT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3889043886, "title": "Health Misinformation Detection in Web Content - A Structural-, Content-based, and Context-aware Approach based on Web2Vec.", "abstract": "", "doi": "10.1145/3462203.3475898", "date": "2021", "authors": [{"name": "Rishabh Upadhyay", "id-internal": "61/9702", "id-external": ""}, {"name": "Gabriella Pasi", "id-internal": "26/4672", "id-external": ""}, {"name": "Marco Viviani", "id-internal": "33/2831", "id-external": ""}], "url": {"full": "URL#148295", "pdf": ""}, "publisher-venue": "GoodIT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1530815542, "title": "Attention-Based Design and Selective Exposure Amid COVID-19 Misinformation Sharing.", "abstract": "", "doi": "10.1007/978-3-030-78468-3_34", "date": "2021", "authors": [{"name": "Zaid Amin", "id-internal": "282/0476", "id-external": ""}, {"name": "Nazlena Mohamad Ali", "id-internal": "69/5291", "id-external": ""}, {"name": "Alan F. Smeaton", "id-internal": "s/AlanFSmeaton", "id-external": ""}], "url": {"full": "URL#148660", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1026600110, "title": "Identifiability as an \"Antidote\" - Exploring Emotional Contagion and the Role of Anonymity in Twitter Discussions on Misinformation.", "abstract": "", "doi": "10.1007/978-3-030-77626-8_16", "date": "2021", "authors": [{"name": "Chen (Crystal) Chen", "id-internal": "296/5504", "id-external": ""}, {"name": "Hao Yuan", "id-internal": "92/867", "id-external": ""}, {"name": "Mike Z. Yao", "id-internal": "80/1458", "id-external": ""}], "url": {"full": "URL#148809", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2567179194, "title": "Country Characteristics, Internet Connectivity and Combating Misinformation - A Network Analysis of Global North-South.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Hyunjin Seo", "id-internal": "150/9852", "id-external": ""}, {"name": "Stuart Thorson 0001", "id-internal": "153/8028", "id-external": ""}, {"name": "Matthew Blomberg", "id-internal": "288/6761", "id-external": ""}, {"name": "Scott Appling", "id-internal": "218/0810", "id-external": ""}, {"name": "Andrea Bras", "id-internal": "288/6540", "id-external": ""}, {"name": "Avery Davis-Roberts", "id-internal": "288/6548", "id-external": ""}, {"name": "Darcey Altschwager", "id-internal": "288/6322", "id-external": ""}], "url": {"full": "URL#150826", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2705025350, "title": "WICO Graph - A Labeled Dataset of Twitter Subgraphs based on Conspiracy Theory and 5G-Corona Misinformation Tweets.", "abstract": "", "doi": "10.5220/0010262802570266", "date": "2021", "authors": [{"name": "Daniel Thilo Schroeder", "id-internal": "255/2988", "id-external": ""}, {"name": "Ferdinand Schaal", "id-internal": "286/6635", "id-external": ""}, {"name": "Petra Filkukova", "id-internal": "271/6196", "id-external": ""}, {"name": "Konstantin Pogorelov", "id-internal": "180/1700", "id-external": ""}, {"name": "Johannes Langguth", "id-internal": "14/7938", "id-external": ""}], "url": {"full": "URL#152272", "pdf": ""}, "publisher-venue": "ICAART", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3689786183, "title": "FakeWhastApp.BR - NLP and Machine Learning Techniques for Misinformation Detection in Brazilian Portuguese WhatsApp Messages.", "abstract": "", "doi": "10.5220/0010446800630074", "date": "2021", "authors": [{"name": "Lucas Cabral", "id-internal": "258/3795", "id-external": ""}, {"name": "Jos\u00e9 Maria Monteiro", "id-internal": "92/1818", "id-external": ""}, {"name": "Jos\u00e9 Wellington Franco da Silva", "id-internal": "22/7983", "id-external": ""}, {"name": "C\u00e9sar Lincoln C. Mattos", "id-internal": "150/2808", "id-external": ""}, {"name": "Pedro Jorge Chaves Mour\u00e3o", "id-internal": "293/7280", "id-external": ""}], "url": {"full": "URL#157497", "pdf": ""}, "publisher-venue": "ICEIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1730494757, "title": "The Impact of Question Type and Topic on Misinformation and Trolling on Yahoo! Answers.", "abstract": "", "doi": "10.1007/978-3-030-71305-8_10", "date": "2021", "authors": [{"name": "Pnina Fichman", "id-internal": "23/10398", "id-external": ""}, {"name": "Rachel Brill", "id-internal": "287/7837", "id-external": ""}], "url": {"full": "URL#161447", "pdf": ""}, "publisher-venue": "iConference", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 974891909, "title": "Counteracting Misinformation in Quotidian Settings.", "abstract": "", "doi": "10.1007/978-3-030-71305-8_11", "date": "2021", "authors": {"name": "Abdul Rohman", "id-internal": "224/5337", "id-external": ""}, "url": {"full": "URL#161495", "pdf": ""}, "publisher-venue": "iConference", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1171286073, "title": "e-Health for Older Adults - Navigating Misinformation.", "abstract": "", "doi": "10.5220/0010463001950202", "date": "2021", "authors": [{"name": "Amira Ghenai", "id-internal": "33/11411", "id-external": ""}, {"name": "Xueguang Ma", "id-internal": "44/9030", "id-external": ""}, {"name": "Robin Cohen", "id-internal": "24/441", "id-external": ""}, {"name": "Karyn Moffatt", "id-internal": "m/KarynMoffatt", "id-external": ""}, {"name": "Andy Yang", "id-internal": "92/3951", "id-external": ""}, {"name": "Yipeng Ji", "id-internal": "82/6088", "id-external": ""}], "url": {"full": "URL#162762", "pdf": ""}, "publisher-venue": "ICT4AWE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 997447355, "title": "Identifying Misinformation from Website Screenshots.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sara Abdali", "id-internal": "218/5833", "id-external": ""}, {"name": "Rutuja Gurav", "id-internal": "285/5322", "id-external": ""}, {"name": "Siddharth Menon", "id-internal": "285/5545", "id-external": ""}, {"name": "Daniel Fonseca", "id-internal": "04/1187", "id-external": ""}, {"name": "Negin Entezari", "id-internal": "76/10203", "id-external": ""}, {"name": "Neil Shah", "id-internal": "71/7771", "id-external": ""}, {"name": "Evangelos E. Papalexakis", "id-internal": "48/9024", "id-external": ""}], "url": {"full": "URL#162983", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 85728958, "title": "Misinformation Adoption or Rejection in the Era of COVID-19.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Maxwell A. Weinzierl", "id-internal": "277/7481", "id-external": ""}, {"name": "Suellen Hopfer", "id-internal": "294/7908", "id-external": ""}, {"name": "Sanda M. Harabagiu", "id-internal": "51/3845", "id-external": ""}], "url": {"full": "URL#163074", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1091492180, "title": "Weaving a Semantic Web of Credibility Reviews for Explainable Misinformation Detection (Extended Abstract).", "abstract": "", "doi": "10.24963/ijcai.2021/646", "date": "2021", "authors": [{"name": "Ronald Denaux", "id-internal": "84/3126", "id-external": ""}, {"name": "Martino Mensio", "id-internal": "218/0707", "id-external": ""}, {"name": "Jos\u00e9 Manu\u00e9l G\u00f3mez-P\u00e9rez", "id-internal": "74/9922", "id-external": ""}, {"name": "Harith Alani", "id-internal": "74/2147", "id-external": ""}], "url": {"full": "URL#163602", "pdf": ""}, "publisher-venue": "IJCAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1476481485, "title": "Using Service-Learning in Graduate Curriculum to Address Teenagers' Vulnerability to Web Misinformation.", "abstract": "", "doi": "10.1145/3456565.3460039", "date": "2021", "authors": {"name": "Francesca Spezzano", "id-internal": "81/7907", "id-external": ""}, "url": {"full": "URL#168833", "pdf": ""}, "publisher-venue": "ITiCSE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 586337666, "title": "The Second International MIS2 Workshop - Misinformation and Misbehavior Mining on the Web.", "abstract": "", "doi": "10.1145/3447548.3469443", "date": "2021", "authors": [{"name": "Aude Hofleitner", "id-internal": "76/11044", "id-external": ""}, {"name": "Meng Jiang 0001", "id-internal": "69/339-1", "id-external": ""}, {"name": "Srijan Kumar", "id-internal": "131/9628", "id-external": ""}, {"name": "Neil Shah", "id-internal": "71/7771", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}], "url": {"full": "URL#170255", "pdf": ""}, "publisher-venue": "KDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3881226954, "title": "Investigating the Impact of Misinformation Sources on Health Issues - Implications for Public Health.", "abstract": "", "doi": "10.3233/shti210211", "date": "2021", "authors": [{"name": "Marianna Isaakidou", "id-internal": "298/2561", "id-external": ""}, {"name": "Emmanouil Zoulias", "id-internal": "51/7941", "id-external": ""}, {"name": "Marianna Diomidous", "id-internal": "99/2715", "id-external": ""}], "url": {"full": "URL#172521", "pdf": ""}, "publisher-venue": "MIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3412978917, "title": "Infodemic, Misinformation and Disinformation in Pandemics - Scientific Landscape and the Road Ahead for Public Health Informatics Research.", "abstract": "", "doi": "10.3233/shti210278", "date": "2021", "authors": [{"name": "Javad K. Pool", "id-internal": "267/0160", "id-external": ""}, {"name": "Farhad Fatehi", "id-internal": "143/3766", "id-external": ""}, {"name": "Saeed Akhlaghpour", "id-internal": "60/10680", "id-external": ""}], "url": {"full": "URL#172603", "pdf": ""}, "publisher-venue": "MIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 961400371, "title": "On Unifying Misinformation Detection.", "abstract": "", "doi": "10.18653/v1/2021.naacl-main.432", "date": "2021", "authors": [{"name": "Nayeon Lee", "id-internal": "212/6295", "id-external": ""}, {"name": "Belinda Z. Li", "id-internal": "263/9914", "id-external": ""}, {"name": "Sinong Wang", "id-internal": "140/0795", "id-external": ""}, {"name": "Pascale Fung", "id-internal": "29/4187", "id-external": ""}, {"name": "Hao Ma", "id-internal": "86/4227", "id-external": ""}, {"name": "Wen-tau Yih", "id-internal": "07/7129", "id-external": ""}, {"name": "Madian Khabsa", "id-internal": "87/11087", "id-external": ""}], "url": {"full": "URL#173742", "pdf": ""}, "publisher-venue": "NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3237895929, "title": "Detection of Misinformation About COVID-19 in Brazilian Portuguese WhatsApp Messages.", "abstract": "", "doi": "10.1007/978-3-030-80599-9_18", "date": "2021", "authors": [{"name": "Ant\u00f4nio Diogo Forte Martins", "id-internal": "242/2263", "id-external": ""}, {"name": "Lucas Cabral", "id-internal": "258/3795", "id-external": ""}, {"name": "Pedro Jorge Chaves Mour\u00e3o", "id-internal": "293/7280", "id-external": ""}, {"name": "Jos\u00e9 Maria Monteiro", "id-internal": "92/1818", "id-external": ""}, {"name": "Javam C. Machado", "id-internal": "12/3896", "id-external": ""}], "url": {"full": "URL#174945", "pdf": ""}, "publisher-venue": "NLDB", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 722309947, "title": "Applying an Epidemiological Model to Evaluate the Propagation of Misinformation and Legitimate COVID-19-Related Information on Twitter.", "abstract": "", "doi": "10.1007/978-3-030-80387-2_3", "date": "2021", "authors": [{"name": "Maryam Maleki", "id-internal": "232/1787", "id-external": ""}, {"name": "Mohammad Arani", "id-internal": "153/4924", "id-external": ""}, {"name": "Erik Buchholz", "id-internal": "263/2187", "id-external": ""}, {"name": "Esther Mead", "id-internal": "147/6193", "id-external": ""}, {"name": "Nitin Agarwal", "id-internal": "72/1395", "id-external": ""}], "url": {"full": "URL#178527", "pdf": ""}, "publisher-venue": "SBP-BRiMS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3838581211, "title": "Combating Social Injustice and Misinformation to Engage Minority Youth in Computing Sciences.", "abstract": "", "doi": "10.1145/3408877.3432452", "date": "2021", "authors": [{"name": "Danielle Cummings", "id-internal": "38/9020", "id-external": ""}, {"name": "Marcus Anthony", "id-internal": "289/1049", "id-external": ""}, {"name": "Crystal Watson", "id-internal": "289/0917", "id-external": ""}, {"name": "Ahmad Watson", "id-internal": "289/2071", "id-external": ""}, {"name": "Sherle Boone", "id-internal": "289/2177", "id-external": ""}], "url": {"full": "URL#179657", "pdf": ""}, "publisher-venue": "SIGCSE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3421338869, "title": "Restoring Healthy Online Discourse by Detecting and Reducing Controversy, Misinformation, and Toxicity Online.", "abstract": "", "doi": "10.1145/3404835.3464926", "date": "2021", "authors": [{"name": "Shiri Dori-Hacohen", "id-internal": "09/2430", "id-external": ""}, {"name": "Keen Sung", "id-internal": "121/8970", "id-external": ""}, {"name": "Jengyu Chou", "id-internal": "297/0848", "id-external": ""}, {"name": "Julian Lustig-Gonzalez", "id-internal": "297/0312", "id-external": ""}], "url": {"full": "URL#180472", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4050532072, "title": "Vera - Prediction Techniques for Reducing Harmful Misinformation in Consumer Health Search.", "abstract": "", "doi": "10.1145/3404835.3463120", "date": "2021", "authors": [{"name": "Ronak Pradeep", "id-internal": "270/1757", "id-external": ""}, {"name": "Xueguang Ma", "id-internal": "44/9030", "id-external": ""}, {"name": "Rodrigo Nogueira", "id-internal": "156/4542", "id-external": ""}, {"name": "Jimmy Lin", "id-internal": "00/7739", "id-external": ""}], "url": {"full": "URL#180638", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2334425597, "title": "Towards Continuous Automatic Audits of Social Media Adaptive Behavior and its Role in Misinformation Spreading.", "abstract": "", "doi": "10.1145/3450614.3463353", "date": "2021", "authors": [{"name": "Jakub Simko", "id-internal": "09/8578", "id-external": ""}, {"name": "Mat\u00fas Tomlein", "id-internal": "148/1345", "id-external": ""}, {"name": "Branislav Pecher", "id-internal": "286/4470", "id-external": ""}, {"name": "R\u00f3bert M\u00f3ro", "id-internal": "13/10717", "id-external": ""}, {"name": "Ivan Srba", "id-internal": "06/9076", "id-external": ""}, {"name": "Elena Stefancova", "id-internal": "225/8181", "id-external": ""}, {"name": "Andrea Hrckova", "id-internal": "295/6382", "id-external": ""}, {"name": "Michal Kompan", "id-internal": "35/8468", "id-external": ""}, {"name": "Juraj Podrouzek", "id-internal": "295/6450", "id-external": ""}, {"name": "M\u00e1ria Bielikov\u00e1", "id-internal": "b/MariaBielikova", "id-external": ""}], "url": {"full": "URL#183809", "pdf": ""}, "publisher-venue": "UMAP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4196325360, "title": "Characterizing and Comparing COVID-19 Misinformation Across Languages, Countries and Platforms.", "abstract": "", "doi": "10.1145/3442442.3452304", "date": "2021", "authors": [{"name": "Golshan Madraki", "id-internal": "253/0313", "id-external": ""}, {"name": "Isabella Grasso", "id-internal": "257/8047", "id-external": ""}, {"name": "Jacqueline M. Otala", "id-internal": "276/5789", "id-external": ""}, {"name": "Yu Liu", "id-internal": "97/2274", "id-external": ""}, {"name": "Jeanna N. Matthews", "id-internal": "81/5025", "id-external": ""}], "url": {"full": "URL#187667", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 743211680, "title": "The Surprising Performance of Simple Baselines for Misinformation Detection.", "abstract": "", "doi": "10.1145/3442381.3450111", "date": "2021", "authors": [{"name": "Kellin Pelrine", "id-internal": "281/0602", "id-external": ""}, {"name": "Jacob Danovitch", "id-internal": "251/8947", "id-external": ""}, {"name": "Reihaneh Rabbany", "id-internal": "94/9024", "id-external": ""}], "url": {"full": "URL#187702", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1640169620, "title": "Chapter 10 The Adequacy of Artificial Intelligence Tools to Combat Misinformation.", "abstract": "", "doi": "10.1007/978-3-030-70370-7_10", "date": "2021", "authors": [{"name": "Nadejda Komendantova", "id-internal": "179/6472", "id-external": ""}, {"name": "Love Ekenberg", "id-internal": "53/544", "id-external": ""}, {"name": "Wolfgang Amann", "id-internal": "195/7836", "id-external": ""}, {"name": "Mats Danielson", "id-internal": "86/685", "id-external": ""}, {"name": "Vasilis Koulolias", "id-internal": "121/9864", "id-external": ""}], "url": {"full": "URL#188217", "pdf": ""}, "publisher-venue": "Resilience in the Digital Age", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 14354856, "title": "Understanding Health Misinformation Transmission - An Interpretable Deep Learning Approach to Manage Infodemics.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Jiaheng Xie", "id-internal": "154/3919", "id-external": ""}, {"name": "Yidong Chai", "id-internal": "205/8540", "id-external": ""}, {"name": "Xiao Liu 0016", "id-internal": "82/1364-16", "id-external": ""}], "url": {"full": "URL#190236", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3629966242, "title": "Eating Garlic Prevents COVID-19 Infection - Detecting Misinformation on the Arabic Content of Twitter.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sarah Alqurashi", "id-internal": "262/6027", "id-external": ""}, {"name": "Btool Hamoui", "id-internal": "266/0839", "id-external": ""}, {"name": "Abdulaziz Alashaikh", "id-internal": "145/7621", "id-external": ""}, {"name": "Ahmad Alhindi", "id-internal": "151/4236", "id-external": ""}, {"name": "Eisa Alanazi", "id-internal": "116/9387", "id-external": ""}], "url": {"full": "URL#191874", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 453442097, "title": "Catching Out-of-Context Misinformation with Self-supervised Learning.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Shivangi Aneja", "id-internal": "267/9370", "id-external": ""}, {"name": "Christoph Bregler", "id-internal": "b/ChristophBregler", "id-external": ""}, {"name": "Matthias Nie\u00dfner", "id-internal": "84/8221", "id-external": ""}], "url": {"full": "URL#192117", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1098727360, "title": "Auditing E-Commerce Platforms for Algorithmically Curated Vaccine Misinformation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Prerna Juneja", "id-internal": "172/1209", "id-external": ""}, {"name": "Tanushree Mitra", "id-internal": "38/11520", "id-external": ""}], "url": {"full": "URL#192973", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3079939071, "title": "Exploring Lightweight Interventions at Posting Time to Reduce the Sharing of Misinformation on Social Media.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Farnaz Jahanbakhsh", "id-internal": "199/3154", "id-external": ""}, {"name": "Amy X. Zhang", "id-internal": "133/8390", "id-external": ""}, {"name": "Adam J. Berinsky", "id-internal": "284/0913", "id-external": ""}, {"name": "Gordon Pennycook", "id-internal": "161/4730", "id-external": ""}, {"name": "David G. Rand", "id-internal": "57/8036", "id-external": ""}, {"name": "David R. Karger", "id-internal": "k/DavidRKarger", "id-external": ""}], "url": {"full": "URL#194394", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2727993137, "title": "Can Predominant Credible Information Suppress Misinformation in Crises? Empirical Studies of Tweets Related to Prevention Measures during COVID-19.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Yan Wang", "id-internal": "59/2227", "id-external": ""}, {"name": "Shangde Gao", "id-internal": "210/8412", "id-external": ""}, {"name": "Wenyu Gao", "id-internal": "92/2355", "id-external": ""}], "url": {"full": "URL#195146", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3202780133, "title": "Mainstreaming of conspiracy theories and misinformation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Neil F. Johnson 0001", "id-internal": "71/5398-1", "id-external": ""}, {"name": "Nicolas Velasquez", "id-internal": "133/4673", "id-external": ""}, {"name": "Nicholas Johnson Restrepo", "id-internal": "266/7719", "id-external": ""}, {"name": "Rhys Leahy", "id-internal": "266/7929", "id-external": ""}, {"name": "Richard F. Sear", "id-internal": "266/8117", "id-external": ""}, {"name": "Nicholas Gabriel", "id-internal": "266/7875", "id-external": ""}, {"name": "H. Larson", "id-internal": "284/9675", "id-external": ""}, {"name": "Yonatan Lupu", "id-internal": "266/7394", "id-external": ""}], "url": {"full": "URL#195692", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2611387988, "title": "NELA-GT-2020 - A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Maur\u00edcio Gruppi", "id-internal": "222/1779", "id-external": ""}, {"name": "Benjamin D. Horne", "id-internal": "166/8102", "id-external": ""}, {"name": "Sibel Adali", "id-internal": "a/SAdali", "id-external": ""}], "url": {"full": "URL#196669", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4065542601, "title": "Identifying Misinformation from Website Screenshots.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sara Abdali", "id-internal": "218/5833", "id-external": ""}, {"name": "Rutuja Gurav", "id-internal": "285/5322", "id-external": ""}, {"name": "Siddharth Menon", "id-internal": "285/5545", "id-external": ""}, {"name": "Daniel Fonseca", "id-internal": "04/1187", "id-external": ""}, {"name": "Negin Entezari", "id-internal": "76/10203", "id-external": ""}, {"name": "Neil Shah", "id-internal": "71/7771", "id-external": ""}, {"name": "Evangelos E. Papalexakis", "id-internal": "48/9024", "id-external": ""}], "url": {"full": "URL#198143", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2563574095, "title": "KNH - Multi-View Modeling with K-Nearest Hyperplanes Graph for Misinformation Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sara Abdali", "id-internal": "218/5833", "id-external": ""}, {"name": "Neil Shah", "id-internal": "71/7771", "id-external": ""}, {"name": "Evangelos E. Papalexakis", "id-internal": "48/9024", "id-external": ""}], "url": {"full": "URL#198147", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4148361952, "title": "An ontological analysis of misinformation in online social networks.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Izzat Alsmadi", "id-internal": "79/2931", "id-external": ""}, {"name": "Iyad Alazzam", "id-internal": "177/3756", "id-external": ""}, {"name": "Mohammad A. Al-Ramahi", "id-internal": "35/9730", "id-external": ""}], "url": {"full": "URL#199698", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3246408337, "title": "University of Copenhagen Participation in TREC Health Misinformation Track 2020.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Lucas Chaves Lima", "id-internal": "238/0439", "id-external": ""}, {"name": "Dustin Brandon Wright", "id-internal": "164/6559-1", "id-external": ""}, {"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}, {"name": "Maria Maistro", "id-internal": "147/9095", "id-external": ""}], "url": {"full": "URL#201765", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1131004669, "title": "Using an Epidemiological Model to Study the Spread of Misinformation during the Black Lives Matter Movement.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Maryam Maleki", "id-internal": "232/1787", "id-external": ""}, {"name": "Esther Mead", "id-internal": "147/6193", "id-external": ""}, {"name": "Mohammad Arani", "id-internal": "153/4924", "id-external": ""}, {"name": "Nitin Agarwal", "id-internal": "72/1395", "id-external": ""}], "url": {"full": "URL#205883", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1407831854, "title": "Analysing the Effect of Recommendation Algorithms on the Amplification of Misinformation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Miriam Fern\u00e1ndez", "id-internal": "54/2749", "id-external": ""}, {"name": "Alejandro Bellog\u00edn", "id-internal": "23/1049", "id-external": ""}, {"name": "Iv\u00e1n Cantador", "id-internal": "29/791", "id-external": ""}], "url": {"full": "URL#206996", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3409600851, "title": "Misinformation detection in Luganda-English code-mixed social media text.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Peter Nabende", "id-internal": "10/6604", "id-external": ""}, {"name": "David Kabiito", "id-internal": "289/5889", "id-external": ""}, {"name": "Claire Babirye", "id-internal": "289/5527", "id-external": ""}, {"name": "Hewitt Tusiime", "id-internal": "289/5927", "id-external": ""}, {"name": "Joyce Nakatumba-Nabende", "id-internal": "04/7977", "id-external": ""}], "url": {"full": "URL#208159", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1213068887, "title": "Misinformation Warning Labels - Twitter's Soft Moderation Effects on COVID-19 Vaccine Belief Echoes.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Filipo Sharevski", "id-internal": "154/7105", "id-external": ""}, {"name": "Raniem Alsaadi", "id-internal": "289/5888", "id-external": ""}, {"name": "Peter Jachim", "id-internal": "248/2439", "id-external": ""}, {"name": "Emma Pieroni", "id-internal": "280/3799", "id-external": ""}], "url": {"full": "URL#208447", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3770406743, "title": "Two Truths and a Lie - Exploring Soft Moderation of COVID-19 Misinformation with Amazon Alexa.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Donald Gover", "id-internal": "289/7565", "id-external": ""}, {"name": "Filipo Sharevski", "id-internal": "154/7105", "id-external": ""}], "url": {"full": "URL#209932", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1707567655, "title": "On Unifying Misinformation Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Nayeon Lee", "id-internal": "212/6295", "id-external": ""}, {"name": "Belinda Z. Li", "id-internal": "263/9914", "id-external": ""}, {"name": "Sinong Wang", "id-internal": "140/0795", "id-external": ""}, {"name": "Pascale Fung", "id-internal": "29/4187", "id-external": ""}, {"name": "Hao Ma", "id-internal": "86/4227", "id-external": ""}, {"name": "Wen-tau Yih", "id-internal": "07/7129", "id-external": ""}, {"name": "Madian Khabsa", "id-internal": "87/11087", "id-external": ""}], "url": {"full": "URL#210435", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2053628143, "title": "The Surprising Performance of Simple Baselines for Misinformation Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Kellin Pelrine", "id-internal": "281/0602", "id-external": ""}, {"name": "Jacob Danovitch", "id-internal": "251/8947", "id-external": ""}, {"name": "Reihaneh Rabbany", "id-internal": "94/9024", "id-external": ""}], "url": {"full": "URL#211199", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1485624829, "title": "The impact of online misinformation on U.S. COVID-19 vaccinations.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Francesco Pierri 0002", "id-internal": "80/8064-2", "id-external": ""}, {"name": "Brea Perry", "id-internal": "290/7885", "id-external": ""}, {"name": "Matthew R. DeVerna", "id-internal": "283/6276", "id-external": ""}, {"name": "Kai-Cheng Yang", "id-internal": "25/10485", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}, {"name": "John Bryden", "id-internal": "42/4876", "id-external": ""}], "url": {"full": "URL#212921", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 739314305, "title": "Misinformation, Believability, and Vaccine Acceptance Over 40 Countries - Takeaways From the Initial Phase of The COVID-19 Infodemic.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Karandeep Singh", "id-internal": "11/5722", "id-external": ""}, {"name": "Gabriel Lima", "id-internal": "125/2715", "id-external": ""}, {"name": "Meeyoung Cha", "id-internal": "57/4924", "id-external": ""}, {"name": "Chiyoung Cha", "id-internal": "267/5590", "id-external": ""}, {"name": "Juhi Kulshrestha", "id-internal": "73/10042", "id-external": ""}, {"name": "Yong-Yeol Ahn", "id-internal": "64/6974", "id-external": ""}, {"name": "Onur Varol", "id-internal": "135/8835", "id-external": ""}], "url": {"full": "URL#213029", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1112428308, "title": "Mutual Hyperlinking Among Misinformation Peddlers.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Vibhor Sehgal", "id-internal": "170/4835", "id-external": ""}, {"name": "Ankit Peshin", "id-internal": "290/9357", "id-external": ""}, {"name": "Sadia Afroz", "id-internal": "29/7562", "id-external": ""}, {"name": "Hany Farid", "id-internal": "50/6993", "id-external": ""}], "url": {"full": "URL#213365", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4238242536, "title": "Looking for COVID-19 misinformation in multilingual social media texts.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Raj Ratn Pranesh", "id-internal": "276/7213", "id-external": ""}, {"name": "Mehrdad Farokhnejad", "id-internal": "237/3395", "id-external": ""}, {"name": "Ambesh Shekhar", "id-internal": "280/6805", "id-external": ""}, {"name": "Genoveva Vargas-Solar", "id-internal": "v/GVargas-Solar", "id-external": ""}], "url": {"full": "URL#216247", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3541710650, "title": "COVID-19 Vaccine Hesitancy on Social Media - Building a Public Twitter Dataset of Anti-vaccine Content, Vaccine Misinformation and Conspiracies.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Goran Muric", "id-internal": "172/7363", "id-external": ""}, {"name": "Yusong Wu", "id-internal": "255/5686", "id-external": ""}, {"name": "Emilio Ferrara", "id-internal": "38/8773", "id-external": ""}], "url": {"full": "URL#217020", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3165277349, "title": "Follow the Money - Analyzing @slpng_giants_pt's Strategy to Combat Misinformation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "B\u00e1rbara Gomes Ribeiro", "id-internal": "292/8100", "id-external": ""}, {"name": "Manoel Horta Ribeiro", "id-internal": "193/5425", "id-external": ""}, {"name": "Virg\u00edlio A. F. Almeida", "id-internal": "a/VirgilioAlmeida", "id-external": ""}, {"name": "Wagner Meira Jr.", "id-internal": "m/WagnerMeiraJr", "id-external": ""}], "url": {"full": "URL#217994", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 418608738, "title": "Online Hate - Behavioural Dynamics and Relationship with Misinformation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Matteo Cinelli", "id-internal": "186/8303", "id-external": ""}, {"name": "Andraz Pelicon", "id-internal": "242/4711", "id-external": ""}, {"name": "Igor Mozetic", "id-internal": "55/2842", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}, {"name": "Petra Kralj Novak", "id-internal": "40/887", "id-external": ""}, {"name": "Fabiana Zollo", "id-internal": "60/9927", "id-external": ""}], "url": {"full": "URL#220701", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1121478244, "title": "Defending Democracy - Using Deep Learning to Identify and Prevent Misinformation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Anusua Trivedi", "id-internal": "120/2636", "id-external": ""}, {"name": "Alyssa Suhm", "id-internal": "294/5206", "id-external": ""}, {"name": "Prathamesh Mahankal", "id-internal": "294/4798", "id-external": ""}, {"name": "Subhiksha Mukuntharaj", "id-internal": "294/4909", "id-external": ""}, {"name": "Meghana D. Parab", "id-internal": "294/5515", "id-external": ""}, {"name": "Malvika Mohan", "id-internal": "294/4634", "id-external": ""}, {"name": "Meredith Berger", "id-internal": "294/4729", "id-external": ""}, {"name": "Arathi Sethumadhavan", "id-internal": "18/7919", "id-external": ""}, {"name": "Ashish Jaiman", "id-internal": "294/5190", "id-external": ""}, {"name": "Rahul Dodhia", "id-internal": "274/5494", "id-external": ""}], "url": {"full": "URL#222548", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4293119368, "title": "Tiplines to Combat Misinformation on Encrypted Platforms - A Case Study of the 2019 Indian Election on WhatsApp.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Ashkan Kazemi", "id-internal": "277/9400", "id-external": ""}, {"name": "Kiran Garimella", "id-internal": "117/4298", "id-external": ""}, {"name": "Gautam Kishore Shahi", "id-internal": "178/1872", "id-external": ""}, {"name": "Devin Gaffney", "id-internal": "133/8424", "id-external": ""}, {"name": "Scott A. Hale", "id-internal": "32/10840", "id-external": ""}], "url": {"full": "URL#223605", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3644693451, "title": "Case Study on Detecting COVID-19 Health-Related Misinformation in Social Media.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Mir Mehedi A. Pritom", "id-internal": "183/5614", "id-external": ""}, {"name": "Rosana Montanez Rodriguez", "id-internal": "270/0538", "id-external": ""}, {"name": "Asad Ali Khan", "id-internal": "214/8296", "id-external": ""}, {"name": "Sebastian A. Nugroho", "id-internal": "202/5798", "id-external": ""}, {"name": "Esra'a Alrashydah", "id-internal": "294/8617", "id-external": ""}, {"name": "Beatrice N. Ruiz", "id-internal": "294/8542", "id-external": ""}, {"name": "Anthony Rios", "id-internal": "133/1827", "id-external": ""}], "url": {"full": "URL#224598", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2821612980, "title": "COVID-19 Vaccines - Characterizing Misinformation Campaigns and Vaccine Hesitancy on Twitter.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Karishma Sharma", "id-internal": "222/7902", "id-external": ""}, {"name": "Yizhou Zhang", "id-internal": "120/2740", "id-external": ""}, {"name": "Yan Liu 0002", "id-internal": "l/YanLiu2", "id-external": ""}], "url": {"full": "URL#225386", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3295886069, "title": "Investigating Misinformation Dissemination on Social Media in Pakistan.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Danyal Haroon", "id-internal": "295/8979", "id-external": ""}, {"name": "Hammad Arif", "id-internal": "295/8876", "id-external": ""}, {"name": "Ahmed Abdullah Tariq", "id-internal": "295/8685", "id-external": ""}, {"name": "Fareeda Nawaz", "id-internal": "264/7542", "id-external": ""}, {"name": "Ihsan Ayyub Qazi", "id-internal": "98/776", "id-external": ""}, {"name": "Maryam Mustafa", "id-internal": "52/4442", "id-external": ""}], "url": {"full": "URL#225805", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3281409436, "title": "Categorising Fine-to-Coarse Grained Misinformation - An Empirical Study of COVID-19 Infodemic.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Ye Jiang", "id-internal": "97/6238", "id-external": ""}, {"name": "Xingyi Song", "id-internal": "185/5566", "id-external": ""}, {"name": "Carolina Scarton", "id-internal": "23/8672", "id-external": ""}, {"name": "Ahmet Aker", "id-internal": "67/7965", "id-external": ""}, {"name": "Kalina Bontcheva", "id-internal": "b/KalinaBontcheva", "id-external": ""}], "url": {"full": "URL#226850", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1513266654, "title": "Trends, Politics, Sentiments, and Misinformation - Understanding People's Reactions to COVID-19 During its Early Stages.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Omar Abdel Wahab 0001", "id-internal": "133/0483", "id-external": ""}, {"name": "Ali Mustafa", "id-internal": "14/2210", "id-external": ""}, {"name": "Andr\u00e9 Bertrand Abisseck Bamatakina", "id-internal": "295/9859", "id-external": ""}], "url": {"full": "URL#227582", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 132856877, "title": "Misinformation Detection on YouTube Using Video Captions.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Raj Jagtap", "id-internal": "296/3703", "id-external": ""}, {"name": "Abhinav Kumar", "id-internal": "115/6458", "id-external": ""}, {"name": "Rahul Goel", "id-internal": "164/1120", "id-external": ""}, {"name": "Shakshi Sharma", "id-internal": "276/6386", "id-external": ""}, {"name": "Rajesh Sharma", "id-internal": "16/7691", "id-external": ""}, {"name": "Clint P. George", "id-internal": "00/9490", "id-external": ""}], "url": {"full": "URL#229241", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2227698616, "title": "Checkovid - A COVID-19 misinformation detection system on Twitter using network and content mining perspectives.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sajad Dadgar", "id-internal": "298/0981", "id-external": ""}, {"name": "Mehdi Ghatee", "id-internal": "18/331", "id-external": ""}], "url": {"full": "URL#232941", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1848575351, "title": "Can the Crowd Judge Truthfulness? A Longitudinal Study on Recent Misinformation about COVID-19.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Kevin Roitero", "id-internal": "184/4597", "id-external": ""}, {"name": "Michael Soprano", "id-internal": "222/1241", "id-external": ""}, {"name": "Beatrice Portelli", "id-internal": "272/5540", "id-external": ""}, {"name": "Massimiliano De Luise", "id-internal": "298/0851", "id-external": ""}, {"name": "Damiano Spina", "id-internal": "74/2824", "id-external": ""}, {"name": "Vincenzo Della Mea", "id-internal": "m/VincenzoDellaMea", "id-external": ""}, {"name": "Giuseppe Serra 0001", "id-internal": "12/1985-1", "id-external": ""}, {"name": "Stefano Mizzaro", "id-internal": "74/4701", "id-external": ""}, {"name": "Gianluca Demartini", "id-internal": "05/3422", "id-external": ""}], "url": {"full": "URL#233698", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3384582576, "title": "The Many Dimensions of Truthfulness - Crowdsourcing Misinformation Assessments on a Multidimensional Scale.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Michael Soprano", "id-internal": "222/1241", "id-external": ""}, {"name": "Kevin Roitero", "id-internal": "184/4597", "id-external": ""}, {"name": "David La Barbera", "id-internal": "262/6079", "id-external": ""}, {"name": "Davide Ceolin", "id-internal": "56/10142", "id-external": ""}, {"name": "Damiano Spina", "id-internal": "74/2824", "id-external": ""}, {"name": "Stefano Mizzaro", "id-internal": "74/4701", "id-external": ""}, {"name": "Gianluca Demartini", "id-internal": "05/3422", "id-external": ""}], "url": {"full": "URL#235393", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2072141673, "title": "Automatic Detection of COVID-19 Vaccine Misinformation with Graph Link Prediction.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Maxwell A. Weinzierl", "id-internal": "277/7481", "id-external": ""}, {"name": "Sanda M. Harabagiu", "id-internal": "51/3845", "id-external": ""}], "url": {"full": "URL#235823", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3538704775, "title": "Learning to Detect Few-Shot-Few-Clue Misinformation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Qiang Zhang", "id-internal": "72/3527", "id-external": ""}, {"name": "Hongbin Huang", "id-internal": "61/2895", "id-external": ""}, {"name": "Shangsong Liang", "id-internal": "57/7731", "id-external": ""}, {"name": "Zaiqiao Meng", "id-internal": "185/0748", "id-external": ""}, {"name": "Emine Yilmaz", "id-internal": "36/3270", "id-external": ""}], "url": {"full": "URL#236494", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2209092268, "title": "Informed Crowds Can Effectively Identify Misinformation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Paul Resnick", "id-internal": "r/PaulResnick", "id-external": ""}, {"name": "Aljohara Alfayez", "id-internal": "146/7670", "id-external": ""}, {"name": "Jane Im", "id-internal": "234/4542", "id-external": ""}, {"name": "Eric Gilbert", "id-internal": "67/1320", "id-external": ""}], "url": {"full": "URL#238161", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1094013907, "title": "Lies Kill, Facts Save - Detecting COVID-19 Misinformation in Twitter.", "abstract": "", "doi": "10.1109/access.2020.3019600", "date": "2020", "authors": [{"name": "Mabrook Al-Rakhami", "id-internal": "150/8548", "id-external": ""}, {"name": "Atif Alamri", "id-internal": "25/2352", "id-external": ""}], "url": {"full": "URL#245416", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 70410239, "title": "Multi-Topic Misinformation Blocking With Budget Constraint on Online Social Networks.", "abstract": "", "doi": "10.1109/access.2020.2989140", "date": "2020", "authors": [{"name": "Dung V. Pham", "id-internal": "257/2917", "id-external": ""}, {"name": "Long Giang Nguyen", "id-internal": "120/3005", "id-external": ""}, {"name": "Ngoc-Tu Nguyen 0002", "id-internal": "75/1092-2", "id-external": ""}, {"name": "Canh V. Pham", "id-internal": "166/3485", "id-external": ""}, {"name": "Anh V. Nguyen", "id-internal": "118/5019", "id-external": ""}], "url": {"full": "URL#255739", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1768586867, "title": "Effects of misinformation diffusion during a pandemic.", "abstract": "", "doi": "10.1007/s41109-020-00327-6", "date": "2020", "authors": [{"name": "Lorenzo Prandi", "id-internal": "277/7136", "id-external": ""}, {"name": "Giuseppe Primiero", "id-internal": "60/5305", "id-external": ""}], "url": {"full": "URL#267141", "pdf": ""}, "publisher-venue": "Appl. Netw. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2733738559, "title": "The effects of source expertise and trustworthiness on recollection - the case of vaccine misinformation.", "abstract": "", "doi": "10.1007/s10339-020-00974-8", "date": "2020", "authors": [{"name": "Sara Pluviano", "id-internal": "246/4426", "id-external": ""}, {"name": "Sergio Della Sala", "id-internal": "25/3865", "id-external": ""}, {"name": "Caroline Watt", "id-internal": "246/4548", "id-external": ""}], "url": {"full": "URL#287286", "pdf": ""}, "publisher-venue": "Cogn. Process.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2063625287, "title": "An 'infodemic' infested world under lockdown - - misinformation or planned conspiracy?", "abstract": "", "doi": "10.1145/3416070", "date": "2020", "authors": {"name": "Ankuran Dutta", "id-internal": "274/3707", "id-external": ""}, "url": {"full": "URL#287759", "pdf": ""}, "publisher-venue": "XRDS", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1338346160, "title": "Battling the spread of misinformation.", "abstract": "", "doi": "10.1145/3416074", "date": "2020", "authors": {"name": "Jovian Anthony Jaison", "id-internal": "246/4546", "id-external": ""}, "url": {"full": "URL#287773", "pdf": ""}, "publisher-venue": "XRDS", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2098133268, "title": "In search of a strategy against misinformation.", "abstract": "", "doi": "10.1145/3416051", "date": "2020", "authors": {"name": "Numair Khan", "id-internal": "173/5072", "id-external": ""}, "url": {"full": "URL#287777", "pdf": ""}, "publisher-venue": "XRDS", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1899588412, "title": "Minimizing the misinformation spread in social networks.", "abstract": "", "doi": "10.1080/24725854.2019.1680909", "date": "2020", "authors": [{"name": "K\u00fcbra Taninmis", "id-internal": "239/6075", "id-external": ""}, {"name": "Necati Aras", "id-internal": "16/3293", "id-external": ""}, {"name": "I. Kuban Altinel", "id-internal": "66/3410", "id-external": ""}, {"name": "Evren G\u00fcney", "id-internal": "47/1849", "id-external": ""}], "url": {"full": "URL#308069", "pdf": ""}, "publisher-venue": "IISE Trans.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3123916859, "title": "Addressing Misinformation in Online Social Networks - Diverse Platforms and the Potential of Multiagent Trust Modeling.", "abstract": "", "doi": "10.3390/info11110539", "date": "2020", "authors": [{"name": "Robin Cohen", "id-internal": "24/441", "id-external": ""}, {"name": "Karyn Moffatt", "id-internal": "m/KarynMoffatt", "id-external": ""}, {"name": "Amira Ghenai", "id-internal": "33/11411", "id-external": ""}, {"name": "Andy Yang", "id-internal": "92/3951", "id-external": ""}, {"name": "Margaret Corwin", "id-internal": "279/4052", "id-external": ""}, {"name": "Gary Lin", "id-internal": "279/4109", "id-external": ""}, {"name": "Raymond Zhao", "id-internal": "279/3694", "id-external": ""}, {"name": "Yipeng Ji", "id-internal": "82/6088", "id-external": ""}, {"name": "Alexandre Parmentier", "id-internal": "251/0618", "id-external": ""}, {"name": "Jason P'ng", "id-internal": "279/3594", "id-external": ""}, {"name": "Wil Tan", "id-internal": "216/3782", "id-external": ""}, {"name": "Lachlan Gray", "id-internal": "279/4073", "id-external": ""}], "url": {"full": "URL#323016", "pdf": ""}, "publisher-venue": "Inf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3053304769, "title": "Viral misinformation and echo chambers - the diffusion of rumors about genetically modified organisms on social media.", "abstract": "", "doi": "10.1108/intr-11-2019-0491", "date": "2020", "authors": [{"name": "Xiaohui Wang", "id-internal": "31/3878", "id-external": ""}, {"name": "Yunya Song", "id-internal": "165/3067", "id-external": ""}], "url": {"full": "URL#324245", "pdf": ""}, "publisher-venue": "Internet Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1419623944, "title": "Optimal Signaling of Content Accuracy - Engagement vs. Misinformation.", "abstract": "", "doi": "10.1287/opre.2019.1897", "date": "2020", "authors": [{"name": "Ozan Candogan", "id-internal": "17/8147", "id-external": ""}, {"name": "Kimon Drakopoulos", "id-internal": "119/4840", "id-external": ""}], "url": {"full": "URL#324282", "pdf": ""}, "publisher-venue": "Oper. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 792939085, "title": "Conceptualising misinformation in the context of asylum seekers.", "abstract": "", "doi": "10.1016/j.ipm.2019.102127", "date": "2020", "authors": [{"name": "Hilda Ruokolainen", "id-internal": "275/5671", "id-external": ""}, {"name": "Gunilla Wid\u00e9n", "id-internal": "20/137", "id-external": ""}], "url": {"full": "URL#325761", "pdf": ""}, "publisher-venue": "Inf. Process. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3845065344, "title": "Digital Deception - Cyber Fraud and Online Misinformation.", "abstract": "", "doi": "10.1109/mitp.2020.2980090", "date": "2020", "authors": [{"name": "George Loukas", "id-internal": "40/2991", "id-external": ""}, {"name": "Charalampos Z. Patrikakis", "id-internal": "88/2848", "id-external": ""}, {"name": "Linda Wilbanks", "id-internal": "56/2060", "id-external": ""}], "url": {"full": "URL#328241", "pdf": ""}, "publisher-venue": "IT Prof.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1439300242, "title": "Contrasting the Spread of Misinformation in Online Social Networks.", "abstract": "", "doi": "10.1613/jair.1.11509", "date": "2020", "authors": [{"name": "Marco Amoruso", "id-internal": "199/6488", "id-external": ""}, {"name": "Daniele Anello", "id-internal": "199/6499", "id-external": ""}, {"name": "Vincenzo Auletta", "id-internal": "49/3388", "id-external": ""}, {"name": "Raffaele Cerulli", "id-internal": "09/6910", "id-external": ""}, {"name": "Diodato Ferraioli", "id-internal": "18/7864", "id-external": ""}, {"name": "Andrea Raiconi", "id-internal": "57/6252", "id-external": ""}], "url": {"full": "URL#329271", "pdf": ""}, "publisher-venue": "J. Artif. Intell. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 669106050, "title": "The Misinformation Age - How False Ideas Spread. Cailin O'Connor and James Owen Weatherall. New Haven, CT - Yale University Press, 2019. 280 pp. $26.00 (hardcover). (ISBN 9780300234015).", "abstract": "", "doi": "10.1002/asi.24285", "date": "2020", "authors": {"name": "Marc Kosciejew", "id-internal": "169/8229", "id-external": ""}, "url": {"full": "URL#330053", "pdf": ""}, "publisher-venue": "J. Assoc. Inf. Sci. Technol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 916737027, "title": "Experience - Managing Misinformation in Social Media - Insights for Policymakers from Twitter Analytics.", "abstract": "", "doi": "10.1145/3341107", "date": "2020", "authors": [{"name": "Reema Aswani", "id-internal": "132/0119", "id-external": ""}, {"name": "Arpan Kumar Kar", "id-internal": "96/9189", "id-external": ""}, {"name": "P. Vigneswara Ilavarasan", "id-internal": "86/1216", "id-external": ""}], "url": {"full": "URL#334941", "pdf": ""}, "publisher-venue": "ACM J. Data Inf. Qual.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 867695060, "title": "Discriminating deception from truth and misinformation - an intent-level approach.", "abstract": "", "doi": "10.1080/0952813x.2019.1652354", "date": "2020", "authors": [{"name": "Deqing Li", "id-internal": "19/2885", "id-external": ""}, {"name": "Eugene Santos Jr.", "id-internal": "56/6476", "id-external": ""}], "url": {"full": "URL#335505", "pdf": ""}, "publisher-venue": "J. Exp. Theor. Artif. Intell.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3014691524, "title": "Consumer Misinformation and the Brand Premium - A Private Label Blind Taste Test.", "abstract": "", "doi": "10.1287/mksc.2019.1189", "date": "2020", "authors": [{"name": "Bart J. Bronnenberg", "id-internal": "71/7885", "id-external": ""}, {"name": "Jean-Pierre Dub\u00e9", "id-internal": "69/7897", "id-external": ""}, {"name": "Robert E. Sanders", "id-internal": "262/8154", "id-external": ""}], "url": {"full": "URL#350493", "pdf": ""}, "publisher-venue": "Mark. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1045706316, "title": "Epistemologies of digital journalism and the study of misinformation.", "abstract": "", "doi": "10.1177/1461444819856914", "date": "2020", "authors": [{"name": "Mats Ekstr\u00f6m", "id-internal": "196/6630", "id-external": ""}, {"name": "Seth C. Lewis", "id-internal": "128/2629", "id-external": ""}, {"name": "Oscar Westlund", "id-internal": "21/9957", "id-external": ""}], "url": {"full": "URL#357428", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 954337974, "title": "Misinformation as a Window into Prejudice - COVID-19 and the Information Environment in India.", "abstract": "", "doi": "10.1145/3432948", "date": "2020", "authors": [{"name": "Syeda Zainab Akbar", "id-internal": "267/7976", "id-external": ""}, {"name": "Anmol Panda", "id-internal": "237/7659", "id-external": ""}, {"name": "Divyanshu Kukreti", "id-internal": "283/4088", "id-external": ""}, {"name": "Azhagu Meena", "id-internal": "263/3475", "id-external": ""}, {"name": "Joyojeet Pal", "id-internal": "63/5175", "id-external": ""}], "url": {"full": "URL#359358", "pdf": ""}, "publisher-venue": "Proc. ACM Hum. Comput. Interact.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4036757379, "title": "On the Misinformation Beat - Understanding the Work of Investigative Journalists Reporting on Problematic Information Online.", "abstract": "", "doi": "10.1145/3415204", "date": "2020", "authors": [{"name": "Melinda McClure Haughey", "id-internal": "278/1213", "id-external": ""}, {"name": "Meena Devii Muralikumar", "id-internal": "229/2252", "id-external": ""}, {"name": "Cameron A. Wood", "id-internal": "278/1259", "id-external": ""}, {"name": "Kate Starbird", "id-internal": "84/7848", "id-external": ""}], "url": {"full": "URL#359444", "pdf": ""}, "publisher-venue": "Proc. ACM Hum. Comput. Interact.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 176265481, "title": "Measuring Misinformation in Video Search Platforms - An Audit Study on YouTube.", "abstract": "", "doi": "10.1145/3392854", "date": "2020", "authors": [{"name": "Eslam Hussein", "id-internal": "199/6341", "id-external": ""}, {"name": "Prerna Juneja", "id-internal": "172/1209", "id-external": ""}, {"name": "Tanushree Mitra", "id-internal": "38/11520", "id-external": ""}], "url": {"full": "URL#359454", "pdf": ""}, "publisher-venue": "Proc. ACM Hum. Comput. Interact.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1184653214, "title": "MISMIS - Misinformation and Miscommunication in social media - aggregating information and analysing language.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Paolo Rosso", "id-internal": "05/3463", "id-external": ""}, {"name": "Francisco Casacuberta", "id-internal": "c/FCasacuberta", "id-external": ""}, {"name": "Julio Gonzalo", "id-internal": "52/3559", "id-external": ""}, {"name": "Laura Plaza", "id-internal": "28/714", "id-external": ""}, {"name": "Jorge Carrillo de Albornoz", "id-internal": "64/368", "id-external": ""}, {"name": "Enrique Amig\u00f3", "id-internal": "71/5174", "id-external": ""}, {"name": "M. Felisa Verdejo", "id-internal": "v/MFelisaVerdejo", "id-external": ""}, {"name": "Mariona Taul\u00e9", "id-internal": "00/5554", "id-external": ""}, {"name": "Maria Salam\u00f3", "id-internal": "42/2375", "id-external": ""}, {"name": "M. Ant\u00f2nia Mart\u00ed", "id-internal": "82/4492", "id-external": ""}], "url": {"full": "URL#360414", "pdf": ""}, "publisher-venue": "Proces. del Leng. Natural", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2056562034, "title": "Misinformation making a disease outbreak worse - outcomes compared for influenza, monkeypox, and norovirus.", "abstract": "", "doi": "10.1177/0037549719885021", "date": "2020", "authors": [{"name": "Julii Brainard", "id-internal": "10/4592", "id-external": ""}, {"name": "Paul R. Hunter", "id-internal": "263/9247", "id-external": ""}], "url": {"full": "URL#383082", "pdf": ""}, "publisher-venue": "Simul.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2639491177, "title": "Deep learning for misinformation detection on online social networks - a survey and new perspectives.", "abstract": "", "doi": "10.1007/s13278-020-00696-x", "date": "2020", "authors": [{"name": "Md. Rafiqul Islam 0006", "id-internal": "73/4468-6", "id-external": ""}, {"name": "Shaowu Liu", "id-internal": "115/5163", "id-external": ""}, {"name": "Xianzhi Wang 0001", "id-internal": "51/8330", "id-external": ""}, {"name": "Guandong Xu", "id-internal": "59/2340", "id-external": ""}], "url": {"full": "URL#384037", "pdf": ""}, "publisher-venue": "Soc. Netw. Anal. Min.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2449645273, "title": "Activity Minimization of Misinformation Influence in Online Social Networks.", "abstract": "", "doi": "10.1109/tcss.2020.2997188", "date": "2020", "authors": [{"name": "Jianming Zhu", "id-internal": "50/1455", "id-external": ""}, {"name": "Peikun Ni", "id-internal": "272/3977", "id-external": ""}, {"name": "Guoqing Wang", "id-internal": "17/356", "id-external": ""}], "url": {"full": "URL#396941", "pdf": ""}, "publisher-venue": "IEEE Trans. Comput. Soc. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2595062288, "title": "Misinformation Harms - A Tale of Two Humanitarian Crises.", "abstract": "", "doi": "10.1109/tpc.2020.3029685", "date": "2020", "authors": [{"name": "Thi Tran", "id-internal": "247/2935", "id-external": ""}, {"name": "Rohit Valecha", "id-internal": "60/11315", "id-external": ""}, {"name": "Paul Rad", "id-internal": "263/1357", "id-external": ""}, {"name": "H. Raghav Rao", "id-internal": "r/HRaghavRao", "id-external": ""}], "url": {"full": "URL#409859", "pdf": ""}, "publisher-venue": "IEEE Trans. Prof. Commun.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1994515290, "title": "Misinformation-oriented expert finding in social networks.", "abstract": "", "doi": "10.1007/s11280-019-00717-6", "date": "2020", "authors": [{"name": "GuoHui Li 0001", "id-internal": "05/10612-1", "id-external": ""}, {"name": "Ming Dong 0004", "id-internal": "22/2379-4", "id-external": ""}, {"name": "Fuming Yang", "id-internal": "260/1946", "id-external": ""}, {"name": "Jun Zeng", "id-internal": "04/1346", "id-external": ""}, {"name": "Jiansen Yuan", "id-internal": "255/9435", "id-external": ""}, {"name": "Congyuan Jin", "id-internal": "260/1640", "id-external": ""}, {"name": "Nguyen Quoc Viet Hung", "id-internal": "88/302", "id-external": ""}, {"name": "Phan Thanh Cong", "id-internal": "260/2005", "id-external": ""}, {"name": "Bolong Zheng", "id-internal": "152/4895", "id-external": ""}], "url": {"full": "URL#418384", "pdf": ""}, "publisher-venue": "World Wide Web", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 754669319, "title": "Mitigating Misinformation - Using Simulations to Examine the Effectiveness of Potential Strategies.", "abstract": "", "doi": "10.1007/978-3-030-51057-2_27", "date": "2020", "authors": {"name": "Ryan Kirk", "id-internal": "11/9814", "id-external": ""}, "url": {"full": "URL#425485", "pdf": ""}, "publisher-venue": "AHFE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2758310528, "title": "Blocking the Spread of Misinformation in a Network under Distinct Cost Models.", "abstract": "", "doi": "10.1109/asonam49781.2020.9381446", "date": "2020", "authors": [{"name": "Fernando C. Erd", "id-internal": "289/2446", "id-external": ""}, {"name": "Andr\u00e9 Lu\u00eds Vignatti", "id-internal": "163/8277", "id-external": ""}, {"name": "Murilo V. G. da Silva", "id-internal": "15/376", "id-external": ""}], "url": {"full": "URL#432609", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2109402500, "title": "An Unsupervised Misinformation Detection Framework to Analyze the Users using COVID-19 Twitter Data.", "abstract": "", "doi": "10.1109/bigdata50022.2020.9378250", "date": "2020", "authors": [{"name": "Aarzoo Dhiman", "id-internal": "236/8470", "id-external": ""}, {"name": "Durga Toshniwal", "id-internal": "37/640", "id-external": ""}], "url": {"full": "URL#435420", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4238477997, "title": "The Role of the Crowd in Countering Misinformation - A Case Study of the COVID-19 Infodemic.", "abstract": "", "doi": "10.1109/bigdata50022.2020.9377956", "date": "2020", "authors": [{"name": "Nicholas Micallef", "id-internal": "130/8112", "id-external": ""}, {"name": "Bing He", "id-internal": "64/2272", "id-external": ""}, {"name": "Srijan Kumar", "id-internal": "131/9628", "id-external": ""}, {"name": "Mustaque Ahamad", "id-internal": "73/3162", "id-external": ""}, {"name": "Nasir D. Memon", "id-internal": "89/6419", "id-external": ""}], "url": {"full": "URL#435699", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 234932892, "title": "Will the Crowd Game the Algorithm? - Using Layperson Judgments to Combat Misinformation on Social Media by Downranking Distrusted Sources.", "abstract": "", "doi": "10.1145/3313831.3376232", "date": "2020", "authors": [{"name": "Ziv Epstein", "id-internal": "181/4635", "id-external": ""}, {"name": "Gordon Pennycook", "id-internal": "161/4730", "id-external": ""}, {"name": "David G. Rand", "id-internal": "57/8036", "id-external": ""}], "url": {"full": "URL#442677", "pdf": ""}, "publisher-venue": "CHI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3711171571, "title": "The Government's Dividend - Complex Perceptions of Social Media Misinformation in China.", "abstract": "", "doi": "10.1145/3313831.3376612", "date": "2020", "authors": [{"name": "Zhicong Lu", "id-internal": "199/2729", "id-external": ""}, {"name": "Yue Jiang", "id-internal": "89/6600", "id-external": ""}, {"name": "Cheng Lu", "id-internal": "91/1482", "id-external": ""}, {"name": "Mor Naaman", "id-internal": "42/241", "id-external": ""}, {"name": "Daniel Wigdor", "id-internal": "w/DanielWigdor", "id-external": ""}], "url": {"full": "URL#443061", "pdf": ""}, "publisher-venue": "CHI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 94260696, "title": "A Linguistic Approach to Misinformation in Chinese.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Charles Lam", "id-internal": "75/5229", "id-external": ""}, {"name": "Brian Leung", "id-internal": "59/3946", "id-external": ""}, {"name": "Cora Yip", "id-internal": "280/2668", "id-external": ""}, {"name": "Jason Yung", "id-internal": "280/2658", "id-external": ""}], "url": {"full": "URL#444064", "pdf": ""}, "publisher-venue": "CHR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1855802253, "title": "The 5th International Workshop on Mining Actionable Insights from Social Networks (MAISoN 2020) - Special Edition on Dis/Misinformation Mining from Social media.", "abstract": "", "doi": "10.1145/3340531.3414078", "date": "2020", "authors": [{"name": "Ebrahim Bagheri", "id-internal": "25/806", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Fattane Zarrinkalam", "id-internal": "152/9311", "id-external": ""}], "url": {"full": "URL#444597", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2776844102, "title": "The Ebb and Flow of the COVID-19 Misinformation Themes.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Thomas Marcoux", "id-internal": "251/0546", "id-external": ""}, {"name": "Esther Mead", "id-internal": "147/6193", "id-external": ""}, {"name": "Nitin Agarwal", "id-internal": "72/1395", "id-external": ""}], "url": {"full": "URL#444866", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2261429309, "title": "Characterizing COVID-19 Misinformation Communities Using a Novel Twitter Dataset.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Shahan Ali Memon", "id-internal": "203/0185", "id-external": ""}, {"name": "Kathleen M. Carley", "id-internal": "72/6492", "id-external": ""}], "url": {"full": "URL#444872", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 523955612, "title": "Detection and Resolution of Rumors and Misinformation with NLP.", "abstract": "", "doi": "10.18653/v1/2020.coling-tutorials.4", "date": "2020", "authors": [{"name": "Leon Derczynski", "id-internal": "66/8157", "id-external": ""}, {"name": "Arkaitz Zubiaga", "id-internal": "34/7374", "id-external": ""}], "url": {"full": "URL#448782", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2380699526, "title": "Defending Against Model Stealing Attacks With Adaptive Misinformation.", "abstract": "", "doi": "10.1109/cvpr42600.2020.00085", "date": "2020", "authors": [{"name": "Sanjay Kariyappa", "id-internal": "223/6062", "id-external": ""}, {"name": "Moinuddin K. Qureshi", "id-internal": "60/6934", "id-external": ""}], "url": {"full": "URL#453640", "pdf": ""}, "publisher-venue": "CVPR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 707067298, "title": "Text Similarity Using Word Embeddings to Classify Misinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Caio Sacramento de Britto Almeida", "id-internal": "128/2821", "id-external": ""}, {"name": "D\u00e9bora Abdalla Santos", "id-internal": "266/0021", "id-external": ""}], "url": {"full": "URL#457234", "pdf": ""}, "publisher-venue": "DHandNLP@PROPOR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4068019133, "title": "Simulation of misinformation spreading processes in social networks - an application with NetLogo.", "abstract": "", "doi": "10.1109/dsaa49011.2020.00086", "date": "2020", "authors": [{"name": "Emilio Sulis", "id-internal": "162/9521", "id-external": ""}, {"name": "Marcella Tambuscio", "id-internal": "162/8994", "id-external": ""}], "url": {"full": "URL#458530", "pdf": ""}, "publisher-venue": "DSAA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3043261412, "title": "COVIDLies - Detecting COVID-19 Misinformation on Social Media.", "abstract": "", "doi": "10.18653/v1/2020.nlpcovid19-2.11", "date": "2020", "authors": [{"name": "Tamanna Hossain", "id-internal": "280/9628", "id-external": ""}, {"name": "Robert L. Logan IV", "id-internal": "210/2652", "id-external": ""}, {"name": "Arjuna Ugarte", "id-internal": "280/8893", "id-external": ""}, {"name": "Yoshitomo Matsubara", "id-internal": "194/5593", "id-external": ""}, {"name": "Sean Young", "id-internal": "123/0291", "id-external": ""}, {"name": "Sameer Singh 0001", "id-internal": "13/3568-1", "id-external": ""}], "url": {"full": "URL#465815", "pdf": ""}, "publisher-venue": "NLP4COVID@EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 118762523, "title": "Pathway to a Human-Values Based Approach to Tackle Misinformation Online.", "abstract": "", "doi": "10.1007/978-3-030-49065-2_36", "date": "2020", "authors": [{"name": "Lara S. G. Piccolo", "id-internal": "99/1852", "id-external": ""}, {"name": "Alisson Puska", "id-internal": "157/3025", "id-external": ""}, {"name": "Roberto Pereira", "id-internal": "233/8441", "id-external": ""}, {"name": "Tracie Farrell", "id-internal": "190/1706", "id-external": ""}], "url": {"full": "URL#478455", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2105637384, "title": "Misinformation in the Chinese Weibo.", "abstract": "", "doi": "10.1007/978-3-030-49570-1_28", "date": "2020", "authors": [{"name": "Lu Xiao 0002", "id-internal": "78/5386-2", "id-external": ""}, {"name": "Sijing Chen", "id-internal": "204/3083", "id-external": ""}], "url": {"full": "URL#479014", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1996015539, "title": "Misinformation Detection and Adversarial Attack Cost Analysis in Directional Social Networks.", "abstract": "", "doi": "10.1109/icccn49398.2020.9209609", "date": "2020", "authors": [{"name": "Huajie Shao", "id-internal": "179/4173", "id-external": ""}, {"name": "Shuochao Yao", "id-internal": "148/1920", "id-external": ""}, {"name": "Andong Jing", "id-internal": "271/5132", "id-external": ""}, {"name": "Shengzhong Liu", "id-internal": "166/5424", "id-external": ""}, {"name": "Dongxin Liu", "id-internal": "132/9305", "id-external": ""}, {"name": "Tianshi Wang", "id-internal": "147/8926", "id-external": ""}, {"name": "Jinyang Li 0004", "id-internal": "79/572-4", "id-external": ""}, {"name": "Chaoqi Yang", "id-internal": "224/2555", "id-external": ""}, {"name": "Ruijie Wang 0004", "id-internal": "57/5759-4", "id-external": ""}, {"name": "Tarek F. Abdelzaher", "id-internal": "a/TarekFAbdelzaher", "id-external": ""}], "url": {"full": "URL#489276", "pdf": ""}, "publisher-venue": "ICCCN", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3758987207, "title": "Reverse Prevention Sampling for Misinformation Mitigation in Social Networks.", "abstract": "", "doi": "10.4230/lipics.icdt.2020.24", "date": "2020", "authors": [{"name": "Michael Simpson", "id-internal": "150/6218", "id-external": ""}, {"name": "Venkatesh Srinivasan 0001", "id-internal": "v/SrinivasanVenkatesh", "id-external": ""}, {"name": "Alex Thomo", "id-internal": "t/AlexThomo", "id-external": ""}], "url": {"full": "URL#493397", "pdf": ""}, "publisher-venue": "ICDT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3910353468, "title": "Investigating the Psychological Mechanism of Individuals' Health Misinformation Dissemination on Social Media.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Rui Gu", "id-internal": "38/1778", "id-external": ""}, {"name": "Meng-Xiang Li", "id-internal": "15/231", "id-external": ""}], "url": {"full": "URL#496641", "pdf": ""}, "publisher-venue": "ICIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2079865160, "title": "Analysing the Extent of Misinformation in Cancer Related Tweets.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Rakesh Bal", "id-internal": "254/0883", "id-external": ""}, {"name": "Sayan Sinha", "id-internal": "231/1126", "id-external": ""}, {"name": "Swastika Dutta", "id-internal": "241/0586", "id-external": ""}, {"name": "Rishabh Joshi", "id-internal": "228/5645", "id-external": ""}, {"name": "Sayan Ghosh 0002", "id-internal": "67/6126-2", "id-external": ""}, {"name": "Ritam Dutt", "id-internal": "213/7740", "id-external": ""}], "url": {"full": "URL#510011", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 284073062, "title": "A Counterattack of Misinformation - How the Information Influence to Human Being.", "abstract": "", "doi": "10.1007/978-3-030-39512-4_93", "date": "2020", "authors": [{"name": "Subin Lee", "id-internal": "20/5949", "id-external": ""}, {"name": "Ken Nah", "id-internal": "257/0646", "id-external": ""}], "url": {"full": "URL#514639", "pdf": ""}, "publisher-venue": "IHSI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2536776963, "title": "DETERRENT - Knowledge Guided Graph Attention Network for Detecting Healthcare Misinformation.", "abstract": "", "doi": "10.1145/3394486.3403092", "date": "2020", "authors": [{"name": "Limeng Cui", "id-internal": "147/6826", "id-external": ""}, {"name": "Haeseung Seo", "id-internal": "244/0106", "id-external": ""}, {"name": "Maryam Tabar", "id-internal": "273/0186", "id-external": ""}, {"name": "Fenglong Ma", "id-internal": "85/10856", "id-external": ""}, {"name": "Suhang Wang", "id-internal": "136/9440", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}], "url": {"full": "URL#532910", "pdf": ""}, "publisher-venue": "KDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1708796209, "title": "Cascade-LSTM - A Tree-Structured Neural Classifier for Detecting Misinformation Cascades.", "abstract": "", "doi": "10.1145/3394486.3403317", "date": "2020", "authors": [{"name": "Francesco Ducci", "id-internal": "273/0140", "id-external": ""}, {"name": "Mathias Kraus", "id-internal": "199/2228", "id-external": ""}, {"name": "Stefan Feuerriegel", "id-internal": "125/0630", "id-external": ""}], "url": {"full": "URL#532933", "pdf": ""}, "publisher-venue": "KDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 910121697, "title": "Using a Word Analysis Method and GNNs to Classify Misinformation Related to 5G-Conspiracy and the COVID-19 Pandemic.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Ferdinand Schaal", "id-internal": "286/6635", "id-external": ""}, {"name": "Jesper Phillips", "id-internal": "295/2830", "id-external": ""}], "url": {"full": "URL#537437", "pdf": ""}, "publisher-venue": "MediaEval", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2694019119, "title": "Evaluating Standard Classifiers for Detecting COVID-19 Related Misinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Daniel Thilo Schroeder", "id-internal": "255/2988", "id-external": ""}, {"name": "Konstantin Pogorelov", "id-internal": "180/1700", "id-external": ""}, {"name": "Johannes Langguth", "id-internal": "14/7938", "id-external": ""}], "url": {"full": "URL#537438", "pdf": ""}, "publisher-venue": "MediaEval", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3946748658, "title": "Misinformation from Web-based News Media? Computational Analysis of Metabolic Disease Burden for Chinese.", "abstract": "", "doi": "10.1007/978-3-030-61841-4_4", "date": "2020", "authors": {"name": "Angela Chang", "id-internal": "91/1695", "id-external": ""}, "url": {"full": "URL#540775", "pdf": ""}, "publisher-venue": "MISDOOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2779953717, "title": "Near Real-Time Detection of Misinformation on Online Social Networks.", "abstract": "", "doi": "10.1007/978-3-030-61841-4_17", "date": "2020", "authors": [{"name": "Lennart van de Guchte", "id-internal": "276/8591", "id-external": ""}, {"name": "Stephan Raaijmakers", "id-internal": "26/3233", "id-external": ""}, {"name": "Erik Meeuwissen", "id-internal": "40/4238", "id-external": ""}, {"name": "Jennifer Spenader", "id-internal": "36/2231", "id-external": ""}], "url": {"full": "URL#540777", "pdf": ""}, "publisher-venue": "MISDOOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2512196888, "title": "Students Assessing Digital News and Misinformation.", "abstract": "", "doi": "10.1007/978-3-030-61841-4_5", "date": "2020", "authors": [{"name": "Thomas Nygren", "id-internal": "276/8624", "id-external": ""}, {"name": "Jenny Wiksten Folkeryd", "id-internal": "166/2530", "id-external": ""}, {"name": "Caroline Liberg", "id-internal": "166/2418", "id-external": ""}, {"name": "Mona Guath", "id-internal": "42/10597", "id-external": ""}], "url": {"full": "URL#540784", "pdf": ""}, "publisher-venue": "MISDOOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 204248458, "title": "StratLearner - Learning a Strategy for Misinformation Prevention in Social Networks.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Guangmo Tong", "id-internal": "146/0784", "id-external": ""}, "url": {"full": "URL#546765", "pdf": ""}, "publisher-venue": "NeurIPS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2295963737, "title": "Semi-supervised Multi-aspect Detection of Misinformation Using Hierarchical Joint Decomposition.", "abstract": "", "doi": "10.1007/978-3-030-67670-4_25", "date": "2020", "authors": [{"name": "Sara Abdali", "id-internal": "218/5833", "id-external": ""}, {"name": "Neil Shah", "id-internal": "71/7771", "id-external": ""}, {"name": "Evangelos E. Papalexakis", "id-internal": "48/9024", "id-external": ""}], "url": {"full": "URL#551045", "pdf": ""}, "publisher-venue": "ECML/PKDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 484278279, "title": "FireAnt - Claim-Based Medical Misinformation Detection and Monitoring.", "abstract": "", "doi": "10.1007/978-3-030-67670-4_38", "date": "2020", "authors": [{"name": "Branislav Pecher", "id-internal": "286/4470", "id-external": ""}, {"name": "Ivan Srba", "id-internal": "06/9076", "id-external": ""}, {"name": "R\u00f3bert M\u00f3ro", "id-internal": "13/10717", "id-external": ""}, {"name": "Mat\u00fas Tomlein", "id-internal": "148/1345", "id-external": ""}, {"name": "M\u00e1ria Bielikov\u00e1", "id-internal": "b/MariaBielikova", "id-external": ""}], "url": {"full": "URL#551246", "pdf": ""}, "publisher-venue": "ECML/PKDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3998536012, "title": "Recommender Systems and Misinformation - The Problem or the Solution?", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Miriam Fern\u00e1ndez", "id-internal": "54/2749", "id-external": ""}, {"name": "Alejandro Bellog\u00edn", "id-internal": "23/1049", "id-external": ""}], "url": {"full": "URL#553325", "pdf": ""}, "publisher-venue": "OHARS@RecSys", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2156659798, "title": "Workshop on Online Misinformation- and Harm-Aware Recommender Systems.", "abstract": "", "doi": "10.1145/3383313.3411537", "date": "2020", "authors": [{"name": "Antonela Tommasel", "id-internal": "162/4427", "id-external": ""}, {"name": "Daniela Godoy", "id-internal": "69/4188", "id-external": ""}, {"name": "Arkaitz Zubiaga", "id-internal": "34/7374", "id-external": ""}], "url": {"full": "URL#553433", "pdf": ""}, "publisher-venue": "RecSys", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3645007644, "title": "Workshop on Online Misinformation- and Harm-Aware Recommender Systems - Preface.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "URL#553449", "pdf": ""}, "publisher-venue": "OHARS@RecSys", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4177984423, "title": "Linked Credibility Reviews for Explainable Misinformation Detection.", "abstract": "", "doi": "10.1007/978-3-030-62419-4_9", "date": "2020", "authors": [{"name": "Ronald Denaux", "id-internal": "84/3126", "id-external": ""}, {"name": "Jos\u00e9 Manu\u00e9l G\u00f3mez-P\u00e9rez", "id-internal": "74/9922", "id-external": ""}], "url": {"full": "URL#557716", "pdf": ""}, "publisher-venue": "ISWC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3715657525, "title": "Towards Crowdsourcing Tasks for Accurate Misinformation Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Ronald Denaux", "id-internal": "84/3126", "id-external": ""}, {"name": "Flavio Merenda", "id-internal": "231/8124", "id-external": ""}, {"name": "Jos\u00e9 Manu\u00e9l G\u00f3mez-P\u00e9rez", "id-internal": "74/9922", "id-external": ""}], "url": {"full": "URL#557717", "pdf": ""}, "publisher-venue": "ASLD@ISWC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1438085979, "title": "Semantic Graph Analysis to Combat Cryptocurrency Misinformation on the Web.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Daniel Kazenoff", "id-internal": "281/3093", "id-external": ""}, {"name": "Oshani Seneviratne", "id-internal": "66/7522", "id-external": ""}, {"name": "Deborah L. McGuinness", "id-internal": "m/DLMcGuinness", "id-external": ""}], "url": {"full": "URL#557779", "pdf": ""}, "publisher-venue": "ASLD@ISWC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 533882651, "title": "Co-spread of Misinformation and Fact-Checking Content During the Covid-19 Pandemic.", "abstract": "", "doi": "10.1007/978-3-030-60975-7_3", "date": "2020", "authors": [{"name": "Gr\u00e9goire Burel", "id-internal": "78/7848", "id-external": ""}, {"name": "Tracie Farrell", "id-internal": "190/1706", "id-external": ""}, {"name": "Martino Mensio", "id-internal": "218/0707", "id-external": ""}, {"name": "Prashant Khare", "id-internal": "139/4712", "id-external": ""}, {"name": "Harith Alani", "id-internal": "74/2147", "id-external": ""}], "url": {"full": "URL#563356", "pdf": ""}, "publisher-venue": "SocInfo", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4078957304, "title": "Media competences in the training of Andean Community journalists - Needs and challenges in the face of misinformation.", "abstract": "", "doi": "10.1145/3434780.3436555", "date": "2020", "authors": [{"name": "Claudia Rodr\u00edguez-Hidalgo", "id-internal": "177/3516", "id-external": ""}, {"name": "Mar\u00eda Soledad Ram\u00edrez-Montoya", "id-internal": "178/9580", "id-external": ""}, {"name": "Diana Rivera-Rogel", "id-internal": "177/3561", "id-external": ""}, {"name": "Ignacio Aguaded 0001", "id-internal": "119/8757", "id-external": ""}], "url": {"full": "URL#567499", "pdf": ""}, "publisher-venue": "TEEM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1066919771, "title": "Webis at TREC 2020 - Health Misinformation Track Extended Abstract.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Janek Bevendorff", "id-internal": "195/5852", "id-external": ""}, {"name": "Michael V\u00f6lske", "id-internal": "59/10289", "id-external": ""}, {"name": "Benno Stein 0001", "id-internal": "69/4806-1", "id-external": ""}, {"name": "Alexander Bondarenko", "id-internal": "234/7521", "id-external": ""}, {"name": "Maik Fr\u00f6be", "id-internal": "256/9118", "id-external": ""}, {"name": "Sebastian G\u00fcnther", "id-internal": "67/6306", "id-external": ""}, {"name": "Matthias Hagen", "id-internal": "95/1130", "id-external": ""}], "url": {"full": "URL#568077", "pdf": ""}, "publisher-venue": "TREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3262152951, "title": "Overview of the TREC 2020 Health Misinformation Track.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Charles L. A. Clarke", "id-internal": "96/3666", "id-external": ""}, {"name": "Saira Rizvi", "id-internal": "295/4459", "id-external": ""}, {"name": "Mark D. Smucker", "id-internal": "07/801", "id-external": ""}, {"name": "Maria Maistro", "id-internal": "147/9095", "id-external": ""}, {"name": "Guido Zuccon", "id-internal": "22/6562", "id-external": ""}], "url": {"full": "URL#568084", "pdf": ""}, "publisher-venue": "TREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 179715354, "title": "CiTIUS at the TREC 2020 Health Misinformation Track.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Marcos Fern\u00e1ndez-Pichel", "id-internal": "271/7701", "id-external": ""}, {"name": "David E. Losada", "id-internal": "36/6230", "id-external": ""}, {"name": "Juan Carlos Pichel", "id-internal": "77/5822", "id-external": ""}, {"name": "David Elsweiler", "id-internal": "21/4257", "id-external": ""}], "url": {"full": "URL#568091", "pdf": ""}, "publisher-venue": "TREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1257348190, "title": "VOH.CoLAB at TREC 2020 Health Misinformation Track.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Simao N. Goncalves", "id-internal": "295/4767", "id-external": ""}, {"name": "Flavio Martins", "id-internal": "295/4375", "id-external": ""}], "url": {"full": "URL#568099", "pdf": ""}, "publisher-venue": "TREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1786631061, "title": "University of Copenhagen Participation in TREC Health Misinformation Track 2020.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Lucas Chaves Lima", "id-internal": "238/0439", "id-external": ""}, {"name": "Dustin Brandon Wright", "id-internal": "164/6559-1", "id-external": ""}, {"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}, {"name": "Maria Maistro", "id-internal": "147/9095", "id-external": ""}], "url": {"full": "URL#568113", "pdf": ""}, "publisher-venue": "TREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 314849751, "title": "NLM at TREC 2020 Health Misinformation and Deep Learning Tracks.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Yassine Mrabet", "id-internal": "82/670", "id-external": ""}, {"name": "Mourad Sarrouti", "id-internal": "172/1502", "id-external": ""}, {"name": "Asma Ben Abacha", "id-internal": "34/9125", "id-external": ""}, {"name": "Soumya Gayen", "id-internal": "204/2733", "id-external": ""}, {"name": "Travis R. Goodwin", "id-internal": "122/5908", "id-external": ""}, {"name": "Alastair R. Rae", "id-internal": "227/5220", "id-external": ""}, {"name": "Willie Rogers", "id-internal": "288/4996", "id-external": ""}, {"name": "Dina Demner-Fushman", "id-internal": "59/2029", "id-external": ""}], "url": {"full": "URL#568121", "pdf": ""}, "publisher-venue": "TREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2271421892, "title": "H2oloo at TREC 2020 - When all you got is a hammer... Deep Learning, Health Misinformation, and Precision Medicine.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Ronak Pradeep", "id-internal": "270/1757", "id-external": ""}, {"name": "Xueguang Ma", "id-internal": "44/9030", "id-external": ""}, {"name": "Xinyu Zhang", "id-internal": "58/4582", "id-external": ""}, {"name": "Hang Cui", "id-internal": "93/2906", "id-external": ""}, {"name": "Ruizhou Xu", "id-internal": "295/4691", "id-external": ""}, {"name": "Rodrigo Nogueira", "id-internal": "156/4542", "id-external": ""}, {"name": "Jimmy Lin", "id-internal": "00/7739", "id-external": ""}], "url": {"full": "URL#568127", "pdf": ""}, "publisher-venue": "TREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3432048378, "title": "RealSakaiLab at the TREC 2020 Health Misinformation Track.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Sijie Tao", "id-internal": "259/7383", "id-external": ""}, {"name": "Tetsuya Sakai", "id-internal": "18/6321", "id-external": ""}], "url": {"full": "URL#568141", "pdf": ""}, "publisher-venue": "TREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3037469469, "title": "Analyzing Misinformation Through The Lens of Systems Thinking.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Umme Ammara", "id-internal": "277/5864", "id-external": ""}, {"name": "Hassan Bukhari", "id-internal": "277/5642", "id-external": ""}, {"name": "Junaid Qadir 0001", "id-internal": "74/2204", "id-external": ""}], "url": {"full": "URL#568674", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2558740366, "title": "Misinformation Battle Revisited - Counter Strategies from Clinics to Artificial Intelligence.", "abstract": "", "doi": "10.1145/3366424.3384373", "date": "2020", "authors": [{"name": "Amir Ebrahimi Fard", "id-internal": "232/2063", "id-external": ""}, {"name": "Shajeeshan Lingeswaran", "id-internal": "264/2921", "id-external": ""}], "url": {"full": "URL#576985", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 559313905, "title": "Mitigating Misinformation in Online Social Network with Top-k Debunkers and Evolving User Opinions.", "abstract": "", "doi": "10.1145/3366424.3383297", "date": "2020", "authors": [{"name": "Akrati Saxena", "id-internal": "163/1823", "id-external": ""}, {"name": "Wynne Hsu", "id-internal": "h/WynneHsu", "id-external": ""}, {"name": "Mong-Li Lee", "id-internal": "l/MongLiLee", "id-external": ""}, {"name": "Hai Leong Chieu", "id-internal": "38/4132", "id-external": ""}, {"name": "Lynette Ng", "id-internal": "264/2953", "id-external": ""}, {"name": "Loo-Nin Teow", "id-internal": "60/4725", "id-external": ""}], "url": {"full": "URL#577210", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4051003035, "title": "Proceedings of the Workshop on Online Misinformation- and Harm-Aware Recommender Systems co-located with 14th ACM Conference on Recommender Systems (RecSys 2020), Rio de Janeiro, Brazil, September 25, 2020.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Antonela Tommasel", "id-internal": "162/4427", "id-external": ""}, {"name": "Daniela Godoy", "id-internal": "69/4188", "id-external": ""}, {"name": "Arkaitz Zubiaga", "id-internal": "34/7374", "id-external": ""}], "url": {"full": "URL#581117", "pdf": ""}, "publisher-venue": ["OHARS@RecSys", "CEUR Workshop Proceedings"], "type": "Editorship", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1362918095, "title": "The Rumour Mill - Making the Spread of Misinformation Explicit and Tangible.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Nanna Inie", "id-internal": "199/2723", "id-external": ""}, {"name": "Jeanette Falk Olesen", "id-internal": "208/8767", "id-external": ""}, {"name": "Leon Derczynski", "id-internal": "66/8157", "id-external": ""}], "url": {"full": "URL#588469", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3206440706, "title": "Text Similarity Using Word Embeddings to Classify Misinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Caio Sacramento de Britto Almeida", "id-internal": "128/2821", "id-external": ""}, {"name": "D\u00e9bora Abdalla Santos", "id-internal": "266/0021", "id-external": ""}], "url": {"full": "URL#594495", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2156780399, "title": "NELA-GT-2019 - A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Maur\u00edcio Gruppi", "id-internal": "222/1779", "id-external": ""}, {"name": "Benjamin D. Horne", "id-internal": "166/8102", "id-external": ""}, {"name": "Sibel Adali", "id-internal": "a/SAdali", "id-external": ""}], "url": {"full": "URL#595218", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1856008899, "title": "Coronavirus on Social Media - Analyzing Misinformation in Twitter Conversations.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Karishma Sharma", "id-internal": "222/7902", "id-external": ""}, {"name": "Sungyong Seo", "id-internal": "178/3209", "id-external": ""}, {"name": "Chuizheng Meng", "id-internal": "207/8096", "id-external": ""}, {"name": "Sirisha Rambhatla", "id-internal": "123/4808", "id-external": ""}, {"name": "Aastha Dua", "id-internal": "261/9647", "id-external": ""}, {"name": "Yan Liu 0002", "id-internal": "l/YanLiu2", "id-external": ""}], "url": {"full": "URL#596700", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3419619443, "title": "Analysing the Extent of Misinformation in Cancer Related Tweets.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Rakesh Bal", "id-internal": "254/0883", "id-external": ""}, {"name": "Sayan Sinha", "id-internal": "231/1126", "id-external": ""}, {"name": "Swastika Dutta", "id-internal": "241/0586", "id-external": ""}, {"name": "Rishabh Joshi", "id-internal": "228/5645", "id-external": ""}, {"name": "Sayan Ghosh 0002", "id-internal": "67/6126-2", "id-external": ""}, {"name": "Ritam Dutt", "id-internal": "213/7740", "id-external": ""}], "url": {"full": "URL#597198", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1453206088, "title": "A first look at COVID-19 information and misinformation sharing on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Lisa Singh", "id-internal": "80/3925", "id-external": ""}, {"name": "Shweta Bansal", "id-internal": "94/2947", "id-external": ""}, {"name": "Leticia Bode", "id-internal": "29/10689", "id-external": ""}, {"name": "Ceren Budak", "id-internal": "66/8462", "id-external": ""}, {"name": "Guangqing Chi", "id-internal": "28/10414", "id-external": ""}, {"name": "Kornraphop Kawintiranon", "id-internal": "245/5983", "id-external": ""}, {"name": "Colton Padden", "id-internal": "262/0132", "id-external": ""}, {"name": "Rebecca Vanarsdall", "id-internal": "262/0280", "id-external": ""}, {"name": "Emily K. Vraga", "id-internal": "122/9355", "id-external": ""}, {"name": "Yanchen Wang", "id-internal": "16/6169", "id-external": ""}], "url": {"full": "URL#597298", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1663165617, "title": "#ArsonEmergency and Australia's \"Black Summer\" - Polarisation and misinformation on social media.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Derek Weber", "id-internal": "82/481", "id-external": ""}, {"name": "Mehwish Nasim", "id-internal": "91/8376", "id-external": ""}, {"name": "Lucia Falzon", "id-internal": "46/3934", "id-external": ""}, {"name": "Lewis Mitchell", "id-internal": "126/5006", "id-external": ""}], "url": {"full": "URL#597768", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2339521775, "title": "Why do People Share Misinformation during the COVID-19 Pandemic?", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Samuli Laato", "id-internal": "204/1679", "id-external": ""}, {"name": "A. K. M. Najmul Islam", "id-internal": "95/1179", "id-external": ""}, {"name": "Muhammad Nazrul Islam", "id-internal": "117/8033", "id-external": ""}, {"name": "Eoin Whelan", "id-internal": "46/1066", "id-external": ""}], "url": {"full": "URL#601248", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3361071578, "title": "Quantifying Latent Moral Foundations in Twitter Narratives - The Case of the Syrian White Helmets Misinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Ece \u00c7igdem Mutlu", "id-internal": "234/7972", "id-external": ""}, {"name": "Toktam A. Oghaz", "id-internal": "234/7704", "id-external": ""}, {"name": "Ege T\u00fct\u00fcnc\u00fcler", "id-internal": "263/9868", "id-external": ""}, {"name": "Jasser Jasser", "id-internal": "201/9832", "id-external": ""}, {"name": "Ivan Garibay", "id-internal": "27/6705", "id-external": ""}], "url": {"full": "URL#602665", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 513516557, "title": "HiJoD - Semi-Supervised Multi-aspect Detection of Misinformation using Hierarchical Joint Decomposition.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Sara Abdali", "id-internal": "218/5833", "id-external": ""}, {"name": "Neil Shah", "id-internal": "71/7771", "id-external": ""}, {"name": "Evangelos E. Papalexakis", "id-internal": "48/9024", "id-external": ""}], "url": {"full": "URL#605165", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3463795171, "title": "Exposure to Social Engagement Metrics Increases Vulnerability to Misinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Mihai Avram 0002", "id-internal": "211/7789-2", "id-external": ""}, {"name": "Nicholas Micallef", "id-internal": "130/8112", "id-external": ""}, {"name": "Sameer Patil", "id-internal": "57/702", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}], "url": {"full": "URL#605324", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 278940072, "title": "An Exploratory Study of COVID-19 Misinformation on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Gautam Kishore Shahi", "id-internal": "178/1872", "id-external": ""}, {"name": "Anne Dirkson", "id-internal": "232/2085", "id-external": ""}, {"name": "Tim A. Majchrzak", "id-internal": "03/7451", "id-external": ""}], "url": {"full": "URL#605702", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 287969832, "title": "Can The Crowd Identify Misinformation Objectively? The Effects of Judgment Scale and Assessor's Background.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kevin Roitero", "id-internal": "184/4597", "id-external": ""}, {"name": "Michael Soprano", "id-internal": "222/1241", "id-external": ""}, {"name": "Shaoyang Fan", "id-internal": "265/5912", "id-external": ""}, {"name": "Damiano Spina", "id-internal": "74/2824", "id-external": ""}, {"name": "Stefano Mizzaro", "id-internal": "74/4701", "id-external": ""}, {"name": "Gianluca Demartini", "id-internal": "05/3422", "id-external": ""}], "url": {"full": "URL#606179", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 637391431, "title": "Images and Misinformation in Political Groups - Evidence from WhatsApp in India.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kiran Garimella", "id-internal": "117/4298", "id-external": ""}, {"name": "Dean Eckles", "id-internal": "72/1229", "id-external": ""}], "url": {"full": "URL#607336", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3408219893, "title": "Analysis of misinformation during the COVID-19 outbreak in China - cultural, social and political entanglements.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Yan Leng", "id-internal": "98/1164", "id-external": ""}, {"name": "Yujia Zhai", "id-internal": "70/1500", "id-external": ""}, {"name": "Shaojing Sun", "id-internal": "66/9154", "id-external": ""}, {"name": "Yifei Wu", "id-internal": "95/9480", "id-external": ""}, {"name": "Jordan Selzer", "id-internal": "265/5650", "id-external": ""}, {"name": "Sharon Strover", "id-internal": "60/5261", "id-external": ""}, {"name": "Julia Fensel", "id-internal": "265/6382", "id-external": ""}, {"name": "Alex Pentland", "id-internal": "p/AlexPentland", "id-external": ""}, {"name": "Ying Ding", "id-internal": "38/6013", "id-external": ""}], "url": {"full": "URL#607572", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2095625498, "title": "CoAID - COVID-19 Healthcare Misinformation Dataset.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Limeng Cui", "id-internal": "147/6826", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}], "url": {"full": "URL#609527", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 352280376, "title": "Detecting Misinformation on WhatsApp without Breaking Encryption.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Julio C. S. Reis", "id-internal": "223/4293", "id-external": ""}, {"name": "Philipe de Freitas Melo", "id-internal": "249/2549", "id-external": ""}, {"name": "Kiran Garimella", "id-internal": "117/4298", "id-external": ""}, {"name": "Fabr\u00edcio Benevenuto", "id-internal": "90/2878", "id-external": ""}], "url": {"full": "URL#610103", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3129839238, "title": "Disinformation and Misinformation on Twitter during the Novel Coronavirus Outbreak.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Binxuan Huang", "id-internal": "195/5963", "id-external": ""}, {"name": "Kathleen M. Carley", "id-internal": "72/6492", "id-external": ""}], "url": {"full": "URL#610848", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2994765232, "title": "Misinformation Has High Perplexity.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Nayeon Lee", "id-internal": "212/6295", "id-external": ""}, {"name": "Yejin Bang", "id-internal": "261/2805", "id-external": ""}, {"name": "Andrea Madotto", "id-internal": "174/2905", "id-external": ""}, {"name": "Pascale Fung", "id-internal": "29/4187", "id-external": ""}], "url": {"full": "URL#611022", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2059596367, "title": "Quantifying the Reach and Belief in COVID-19 Misinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Sophie Nightingale", "id-internal": "267/5413", "id-external": ""}, {"name": "Marc Faddoul", "id-internal": "251/9523", "id-external": ""}, {"name": "Hany Farid", "id-internal": "50/6993", "id-external": ""}], "url": {"full": "URL#612896", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3371371449, "title": "Reducing Misinformation in Query Autocompletions.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Djoerd Hiemstra", "id-internal": "19/3140", "id-external": ""}, "url": {"full": "URL#617299", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 826036467, "title": "Cultural Convergence - Insights into the behavior of misinformation networks on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Liz McQuillan", "id-internal": "270/0248", "id-external": ""}, {"name": "Erin McAweeney", "id-internal": "217/9411", "id-external": ""}, {"name": "Alicia Bargar", "id-internal": "244/8620", "id-external": ""}, {"name": "Alex Ruch", "id-internal": "270/0487", "id-external": ""}], "url": {"full": "URL#617617", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1503612249, "title": "Fighting Disaster Misinformation in Latin America - The #19S Mexican Earthquake Case Study.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Claudia Flores-Saviaga", "id-internal": "170/4752", "id-external": ""}, {"name": "Saiph Savage", "id-internal": "37/8857", "id-external": ""}], "url": {"full": "URL#618581", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4007701317, "title": "Combating Misinformation in Bangladesh - Roles and Responsibilities as Perceived by Journalists, Fact-checkers, and Users.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Md Mahfuzul Haque", "id-internal": "230/3595", "id-external": ""}, {"name": "Mohammad Yousuf", "id-internal": "198/1367", "id-external": ""}, {"name": "Ahmed Shatil Alam", "id-internal": "230/3449", "id-external": ""}, {"name": "Pratyasha Saha", "id-internal": "229/1485", "id-external": ""}, {"name": "Syed Ishtiaque Ahmed", "id-internal": "75/7215", "id-external": ""}, {"name": "Naeemul Hassan", "id-internal": "66/9718", "id-external": ""}], "url": {"full": "URL#621448", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3490838132, "title": "Towards Domain-Specific Characterization of Misinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Fariha Afsana", "id-internal": "213/7677", "id-external": ""}, {"name": "Muhammad Ashad Kabir", "id-internal": "59/9972", "id-external": ""}, {"name": "Naeemul Hassan", "id-internal": "66/9718", "id-external": ""}, {"name": "Manoranjan Paul", "id-internal": "99/774", "id-external": ""}], "url": {"full": "URL#622222", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2489431978, "title": "COVID-19 Misinformation and Disinformation on Social Networks - The Limits of Veritistic Countermeasures.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Andrew Buzzell", "id-internal": "270/2170", "id-external": ""}, "url": {"full": "URL#623048", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2514538984, "title": "Characterizing COVID-19 Misinformation Communities Using a Novel Twitter Dataset.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Shahan Ali Memon", "id-internal": "203/0185", "id-external": ""}, {"name": "Kathleen M. Carley", "id-internal": "72/6492", "id-external": ""}], "url": {"full": "URL#623050", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4196443272, "title": "Social Media and Health Misinformation during the US COVID Crisis.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Gillian Bolsover", "id-internal": "250/5362", "id-external": ""}, {"name": "Janet Tokitsu Tizon", "id-internal": "272/5199", "id-external": ""}], "url": {"full": "URL#624858", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1636475742, "title": "The COVID-19 Infodemic - Can the Crowd Judge Recent Misinformation Objectively?", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kevin Roitero", "id-internal": "184/4597", "id-external": ""}, {"name": "Michael Soprano", "id-internal": "222/1241", "id-external": ""}, {"name": "Beatrice Portelli", "id-internal": "272/5540", "id-external": ""}, {"name": "Damiano Spina", "id-internal": "74/2824", "id-external": ""}, {"name": "Vincenzo Della Mea", "id-internal": "m/VincenzoDellaMea", "id-external": ""}, {"name": "Giuseppe Serra 0001", "id-internal": "12/1985-1", "id-external": ""}, {"name": "Stefano Mizzaro", "id-internal": "74/4701", "id-external": ""}, {"name": "Gianluca Demartini", "id-internal": "05/3422", "id-external": ""}], "url": {"full": "URL#625009", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3015699172, "title": "Linked Credibility Reviews for Explainable Misinformation Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Ronald Denaux", "id-internal": "84/3126", "id-external": ""}, {"name": "Jos\u00e9 Manu\u00e9l G\u00f3mez-P\u00e9rez", "id-internal": "74/9922", "id-external": ""}], "url": {"full": "URL#627778", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1215447492, "title": "Misinformation and its stakeholders in Europe - a web-based analysis.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Emmanouil Koulas", "id-internal": "274/6826", "id-external": ""}, {"name": "Marios Anthopoulos", "id-internal": "274/6911", "id-external": ""}, {"name": "Sotiria Grammenou", "id-internal": "274/7158", "id-external": ""}, {"name": "Christos Kaimakamis", "id-internal": "274/6810", "id-external": ""}, {"name": "Konstantinos Kousaris", "id-internal": "274/7270", "id-external": ""}, {"name": "Fotini-Rafailia Panavou", "id-internal": "274/6801", "id-external": ""}, {"name": "Orestis Piskioulis", "id-internal": "274/6916", "id-external": ""}, {"name": "Syed Iftikhar Hussain Shah", "id-internal": "274/6910", "id-external": ""}, {"name": "Vasilios Peristeras", "id-internal": "274/7009", "id-external": ""}], "url": {"full": "URL#631548", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3408958532, "title": "Investigating Misinformation in Online Marketplaces - An Audit Study on Amazon.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Eslam Hussein", "id-internal": "199/6341", "id-external": ""}, {"name": "Hoda Eldardiry", "id-internal": "51/9923", "id-external": ""}], "url": {"full": "URL#632741", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1305503949, "title": "StratLearner - Learning a Strategy for Misinformation Prevention in Social Networks.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Guangmo Tong", "id-internal": "146/0784", "id-external": ""}, "url": {"full": "URL#633469", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 814013136, "title": "Right and left, partisanship predicts vulnerability to misinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Dimitar Nikolov", "id-internal": "28/8123", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}], "url": {"full": "URL#634316", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3614635646, "title": "Analysis of online misinformation during the peak of the COVID-19 pandemics in Italy.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Guido Caldarelli", "id-internal": "50/6478", "id-external": ""}, {"name": "Rocco De Nicola", "id-internal": "n/RDNicola", "id-external": ""}, {"name": "Marinella Petrocchi", "id-internal": "30/3349", "id-external": ""}, {"name": "Manuel Pratelli", "id-internal": "269/2613", "id-external": ""}, {"name": "Fabio Saracco", "id-internal": "183/6149", "id-external": ""}], "url": {"full": "URL#634543", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 23420933, "title": "Probabilistic Social Learning Improves the Public's Detection of Misinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Douglas Guilbeault", "id-internal": "207/7559", "id-external": ""}, {"name": "Samuel Woolley", "id-internal": "276/5961", "id-external": ""}, {"name": "Joshua Becker", "id-internal": "207/7988", "id-external": ""}], "url": {"full": "URL#636379", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3566498242, "title": "Characterizing and Comparing COVID-19 Misinformation Across Languages, Countries and Platforms.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Golshan Madraki", "id-internal": "253/0313", "id-external": ""}, {"name": "Isabella Grasso", "id-internal": "257/8047", "id-external": ""}, {"name": "Jacqueline Otala", "id-internal": "276/5789", "id-external": ""}, {"name": "Yu Liu", "id-internal": "97/2274", "id-external": ""}, {"name": "Jeanna N. Matthews", "id-internal": "81/5025", "id-external": ""}], "url": {"full": "URL#636582", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 379895894, "title": "Drink bleach or do what now? Covid-HeRA - A dataset for risk-informed health decision making in the presence of COVID19 misinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Arkin Dharawat", "id-internal": "276/6900", "id-external": ""}, {"name": "Ismini Lourentzou", "id-internal": "136/7883", "id-external": ""}, {"name": "Alex Morales", "id-internal": "130/0396", "id-external": ""}, {"name": "ChengXiang Zhai", "id-internal": "z/ChengXiangZhai", "id-external": ""}], "url": {"full": "URL#637606", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1996615599, "title": "ArCOV19-Rumors - Arabic COVID-19 Twitter Dataset for Misinformation Detection.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Fatima Haouari", "id-internal": "243/2755", "id-external": ""}, {"name": "Maram Hasanain", "id-internal": "151/5519", "id-external": ""}, {"name": "Reem Suwaileh", "id-internal": "178/5998", "id-external": ""}, {"name": "Tamer Elsayed", "id-internal": "99/5856", "id-external": ""}], "url": {"full": "URL#637618", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1308387231, "title": "Is this pofma? Analysing public opinion and misinformation in a COVID-19 Telegram group chat.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Lynnette Hui Xian Ng", "id-internal": "277/0683", "id-external": ""}, {"name": "Loke Jia Yuan", "id-internal": "277/0553", "id-external": ""}], "url": {"full": "URL#638236", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1199856205, "title": "The Role of the Crowd in Countering Misinformation - A Case Study of the COVID-19 Infodemic.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Nicholas Micallef", "id-internal": "130/8112", "id-external": ""}, {"name": "Bing He", "id-internal": "64/2272", "id-external": ""}, {"name": "Srijan Kumar", "id-internal": "131/9628", "id-external": ""}, {"name": "Mustaque Ahamad", "id-internal": "73/3162", "id-external": ""}, {"name": "Nasir D. Memon", "id-internal": "89/6419", "id-external": ""}], "url": {"full": "URL#643583", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2495550480, "title": "Towards Combating Pandemic-related Misinformation in Social Media.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Isa Inuwa-Dutse", "id-internal": "210/0811", "id-external": ""}, "url": {"full": "URL#646957", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1555397945, "title": "Predicting Misinformation and Engagement in COVID-19 Twitter Discourse in the First Months of the Outbreak.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Mirela Silva", "id-internal": "280/0129", "id-external": ""}, {"name": "Fabr\u00edcio Ceschin", "id-internal": "235/8319", "id-external": ""}, {"name": "Prakash Shrestha", "id-internal": "171/1820", "id-external": ""}, {"name": "Christopher Brant", "id-internal": "280/0616", "id-external": ""}, {"name": "Juliana Fernandes", "id-internal": "224/8482", "id-external": ""}, {"name": "Catia S. Silva", "id-internal": "188/2917", "id-external": ""}, {"name": "Andr\u00e9 Gr\u00e9gio", "id-internal": "115/4570", "id-external": ""}, {"name": "Daniela A. S. de Oliveira", "id-internal": "20/3140", "id-external": ""}, {"name": "Luiz Giovanini", "id-internal": "280/0282", "id-external": ""}], "url": {"full": "URL#648241", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1197622175, "title": "\"Thought I'd Share First\" - An Analysis of COVID-19 Conspiracy Theories and Misinformation Spread on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Dax Gerts", "id-internal": "281/6858", "id-external": ""}, {"name": "Courtney D. Shelley", "id-internal": "281/7178", "id-external": ""}, {"name": "Nidhi Parikh", "id-internal": "229/5140", "id-external": ""}, {"name": "Travis Pitts", "id-internal": "265/9977", "id-external": ""}, {"name": "Chrysm Watson Ross", "id-internal": "259/6054", "id-external": ""}, {"name": "Geoffrey Fairchild", "id-internal": "146/0669", "id-external": ""}, {"name": "Nidia Yadria Vaquera Chavez", "id-internal": "281/6840", "id-external": ""}, {"name": "Ashlynn R. Daughton", "id-internal": "186/8121", "id-external": ""}], "url": {"full": "URL#650569", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2833691887, "title": "Social Media COVID-19 Misinformation Interventions Viewed Positively, But Have Limited Impact.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Christine Geeng", "id-internal": "239/7899", "id-external": ""}, {"name": "Tiona Francisco", "id-internal": "281/7532", "id-external": ""}, {"name": "Jevin West", "id-internal": "18/2701", "id-external": ""}, {"name": "Franziska Roesner", "id-internal": "23/2758", "id-external": ""}], "url": {"full": "URL#651801", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1750346936, "title": "Attention and misinformation sharing on social media.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Zaid Amin", "id-internal": "282/0476", "id-external": ""}, {"name": "Nazlena Mohamad Ali", "id-internal": "69/5291", "id-external": ""}, {"name": "Alan F. Smeaton", "id-internal": "s/AlanFSmeaton", "id-external": ""}], "url": {"full": "URL#652384", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3721721708, "title": "Detecting Medical Misinformation on Social Media Using Multimodal Deep Learning.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Zuhui Wang", "id-internal": "116/8603", "id-external": ""}, {"name": "Zhaozheng Yin", "id-internal": "89/4637", "id-external": ""}, {"name": "Young Anna Argyris", "id-internal": "164/0484", "id-external": ""}], "url": {"full": "URL#652877", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3487336244, "title": "Misinformation-Aware Social Media - A Software Engineering Perspective.", "abstract": "", "doi": "10.1109/access.2019.2960270", "date": "2019", "authors": {"name": "Malik Almaliki", "id-internal": "142/9859", "id-external": ""}, "url": {"full": "URL#660331", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 352360388, "title": "Analysis and Detection of Health-Related Misinformation on Chinese Social Media.", "abstract": "", "doi": "10.1109/access.2019.2946624", "date": "2019", "authors": [{"name": "Yue Liu 0002", "id-internal": "74/1932-2", "id-external": ""}, {"name": "Ke Yu", "id-internal": "23/2089", "id-external": ""}, {"name": "Xiaofei Wu", "id-internal": "19/8198", "id-external": ""}, {"name": "Linbo Qing", "id-internal": "132/5829", "id-external": ""}, {"name": "Yonghong Peng", "id-internal": "80/2725", "id-external": ""}], "url": {"full": "URL#667019", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3997285506, "title": "Not All Lies Are Equal. A Study Into the Engineering of Political Misinformation in the 2016 US Presidential Election.", "abstract": "", "doi": "10.1109/access.2019.2938389", "date": "2019", "authors": [{"name": "Axel Oehmichen", "id-internal": "153/6999", "id-external": ""}, {"name": "Kevin Hua", "id-internal": "39/2437", "id-external": ""}, {"name": "Julio Amador D\u00edaz L\u00f3pez", "id-internal": "204/9865", "id-external": ""}, {"name": "Miguel Molina-Solana", "id-internal": "92/7407", "id-external": ""}, {"name": "Juan G\u00f3mez-Romero", "id-internal": "95/4289", "id-external": ""}, {"name": "Yike Guo", "id-internal": "g/YikeGuo", "id-external": ""}], "url": {"full": "URL#668236", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1345592768, "title": "Recognise misinformation and verify before sharing - a reasoned action and information literacy perspective.", "abstract": "", "doi": "10.1080/0144929x.2019.1578828", "date": "2019", "authors": [{"name": "M. Laeeq Khan", "id-internal": "126/4066", "id-external": ""}, {"name": "Ika Karlina Idris", "id-internal": "262/4457", "id-external": ""}], "url": {"full": "URL#682566", "pdf": ""}, "publisher-venue": "Behav. Inf. Technol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3683297177, "title": "What Debunking of Misinformation Does and Doesn't.", "abstract": "", "doi": "10.1089/cyber.2018.0608", "date": "2019", "authors": [{"name": "Jeong-woo Jang", "id-internal": "97/9150", "id-external": ""}, {"name": "Eun-Ju Lee", "id-internal": "61/4108", "id-external": ""}, {"name": "Soo Yun Shin", "id-internal": "122/9209", "id-external": ""}], "url": {"full": "URL#688272", "pdf": ""}, "publisher-venue": "Cyberpsychology Behav. Soc. Netw.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2999060091, "title": "Investigating Effects of Visual Anchors on Decision-Making about Misinformation.", "abstract": "", "doi": "10.1111/cgf.13679", "date": "2019", "authors": [{"name": "Ryan Wesslen", "id-internal": "217/2895", "id-external": ""}, {"name": "Sashank Santhanam", "id-internal": "221/5959", "id-external": ""}, {"name": "Alireza Karduni", "id-internal": "156/7556", "id-external": ""}, {"name": "Isaac Cho", "id-internal": "50/11181", "id-external": ""}, {"name": "Samira Shaikh", "id-internal": "59/1496", "id-external": ""}, {"name": "Wenwen Dou", "id-internal": "82/4583", "id-external": ""}], "url": {"full": "URL#690717", "pdf": ""}, "publisher-venue": "Comput. Graph. Forum", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2168484268, "title": "Attention-based convolutional approach for misinformation identification from massive and noisy microblog posts.", "abstract": "", "doi": "10.1016/j.cose.2019.02.003", "date": "2019", "authors": [{"name": "Feng Yu", "id-internal": "28/1708", "id-external": ""}, {"name": "Qiang Liu 0006", "id-internal": "61/3234-6", "id-external": ""}, {"name": "Shu Wu", "id-internal": "06/3577", "id-external": ""}, {"name": "Liang Wang 0001", "id-internal": "56/4499-1", "id-external": ""}, {"name": "Tieniu Tan", "id-internal": "t/TieniuTan", "id-external": ""}], "url": {"full": "URL#697706", "pdf": ""}, "publisher-venue": "Comput. Secur.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1615665176, "title": "Detecting misinformation in social networks using provenance data.", "abstract": "", "doi": "10.1002/cpe.4793", "date": "2019", "authors": [{"name": "Mohamed Jehad Baeth", "id-internal": "175/5448", "id-external": ""}, {"name": "Mehmet S. Aktas", "id-internal": "63/4147", "id-external": ""}], "url": {"full": "URL#698379", "pdf": ""}, "publisher-venue": "Concurr. Comput. Pract. Exp.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1137887643, "title": "Parents' beliefs in misinformation about vaccines are strengthened by pro-vaccine campaigns.", "abstract": "", "doi": "10.1007/s10339-019-00919-w", "date": "2019", "authors": [{"name": "Sara Pluviano", "id-internal": "246/4426", "id-external": ""}, {"name": "Caroline Watt", "id-internal": "246/4548", "id-external": ""}, {"name": "Giovanni Ragazzini", "id-internal": "246/4322", "id-external": ""}, {"name": "Sergio Della Sala", "id-internal": "25/3865", "id-external": ""}], "url": {"full": "URL#699117", "pdf": ""}, "publisher-venue": "Cogn. Process.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 869386736, "title": "The Future of Misinformation.", "abstract": "", "doi": "10.1109/mcse.2018.2874117", "date": "2019", "authors": {"name": "Charles Day", "id-internal": "96/4506", "id-external": ""}, "url": {"full": "URL#700093", "pdf": ""}, "publisher-venue": "Comput. Sci. Eng.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1082459315, "title": "Minimum budget for misinformation blocking in online social networks.", "abstract": "", "doi": "10.1007/s10878-019-00439-5", "date": "2019", "authors": [{"name": "Canh V. Pham", "id-internal": "166/3485", "id-external": ""}, {"name": "Quat V. Phu", "id-internal": "215/5896", "id-external": ""}, {"name": "Huan X. Hoang", "id-internal": "166/3472", "id-external": ""}, {"name": "Jun Pei", "id-internal": "61/7694", "id-external": ""}, {"name": "My T. Thai", "id-internal": "63/4711", "id-external": ""}], "url": {"full": "URL#742707", "pdf": ""}, "publisher-venue": "J. Comb. Optim.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1329058225, "title": "Disinformation and misinformation triangle.", "abstract": "", "doi": "10.1108/jd-12-2018-0209", "date": "2019", "authors": {"name": "Victoria L. Rubin", "id-internal": "36/6480", "id-external": ""}, "url": {"full": "URL#744281", "pdf": ""}, "publisher-venue": "J. Documentation", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3161328804, "title": "Financial Regulatory and Risk Management Challenges Stemming from Firm-Specific Digital Misinformation.", "abstract": "", "doi": "10.1145/3274655", "date": "2019", "authors": [{"name": "K. Michael Casey", "id-internal": "235/5496", "id-external": ""}, {"name": "Kevin Casey Jr.", "id-internal": "235/5551", "id-external": ""}], "url": {"full": "URL#744459", "pdf": ""}, "publisher-venue": "ACM J. Data Inf. Qual.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1206609049, "title": "Introduction to the Special Issue on Combating Digital Misinformation and Disinformation.", "abstract": "", "doi": "10.1145/3321484", "date": "2019", "authors": [{"name": "Naeemul Hassan", "id-internal": "66/9718", "id-external": ""}, {"name": "Chengkai Li", "id-internal": "14/3692", "id-external": ""}, {"name": "Jun Yang 0001", "id-internal": "y/JunYang1", "id-external": ""}, {"name": "Cong Yu 0001", "id-internal": "58/3771", "id-external": ""}], "url": {"full": "URL#744464", "pdf": ""}, "publisher-venue": "ACM J. Data Inf. Qual.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2465847418, "title": "Keeping track of 'alternative facts' - The neural correlates of processing misinformation corrections.", "abstract": "", "doi": "10.1016/j.neuroimage.2019.03.014", "date": "2019", "authors": [{"name": "Andrew Gordon", "id-internal": "01/2570", "id-external": ""}, {"name": "Susanne Quadflieg", "id-internal": "89/7488", "id-external": ""}, {"name": "Jonathan C. W. Brooks", "id-internal": "28/10743", "id-external": ""}, {"name": "Ullrich K. H. Ecker", "id-internal": "83/8258", "id-external": ""}, {"name": "Stephan Lewandowsky", "id-internal": "22/8704", "id-external": ""}], "url": {"full": "URL#765631", "pdf": ""}, "publisher-venue": "NeuroImage", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2083535738, "title": "QuickStop - A Markov Optimal Stopping Approach for Quickest Misinformation Detection.", "abstract": "", "doi": "10.1145/3341617.3326156", "date": "2019", "authors": [{"name": "Honghao Wei", "id-internal": "176/4191", "id-external": ""}, {"name": "Xiaohan Kang", "id-internal": "61/8656", "id-external": ""}, {"name": "Weina Wang", "id-internal": "88/2200", "id-external": ""}, {"name": "Lei Ying", "id-internal": "27/4818", "id-external": ""}], "url": {"full": "URL#770789", "pdf": ""}, "publisher-venue": "Proc. ACM Meas. Anal. Comput. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2709687510, "title": "Misinformation in Social Media - Definition, Manipulation, and Detection.", "abstract": "", "doi": "10.1145/3373464.3373475", "date": "2019", "authors": [{"name": "Liang Wu 0006", "id-internal": "20/5233-6", "id-external": ""}, {"name": "Fred Morstatter", "id-internal": "51/9687", "id-external": ""}, {"name": "Kathleen M. Carley", "id-internal": "72/6492", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#787060", "pdf": ""}, "publisher-venue": "SIGKDD Explor.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3916796709, "title": "Minimizing Misinformation Profit in Social Networks.", "abstract": "", "doi": "10.1109/tcss.2019.2944120", "date": "2019", "authors": [{"name": "Tiantian Chen", "id-internal": "183/1310", "id-external": ""}, {"name": "Wenjing Liu", "id-internal": "90/11325", "id-external": ""}, {"name": "Qizhi Fang", "id-internal": "97/1149", "id-external": ""}, {"name": "Jianxiong Guo", "id-internal": "246/8853", "id-external": ""}, {"name": "Ding-Zhu Du", "id-internal": "d/DingZhuDu", "id-external": ""}], "url": {"full": "URL#799062", "pdf": ""}, "publisher-venue": "IEEE Trans. Comput. Soc. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4143433613, "title": "Defending Elections against Malicious Spread of Misinformation.", "abstract": "", "doi": "10.1609/aaai.v33i01.33012213", "date": "2019", "authors": [{"name": "Bryan Wilder", "id-internal": "164/1648", "id-external": ""}, {"name": "Yevgeniy Vorobeychik", "id-internal": "70/2217", "id-external": ""}], "url": {"full": "URL#820371", "pdf": ""}, "publisher-venue": "AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3957293776, "title": "Friend or Foe - Studying user Trustworthiness for Friend Recommendation in the Era of Misinformation.", "abstract": "", "doi": "10.1109/aike.2019.00053", "date": "2019", "authors": {"name": "Antonela Tommasel", "id-internal": "162/4427", "id-external": ""}, "url": {"full": "URL#825438", "pdf": ""}, "publisher-venue": "AIKE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3187837914, "title": "Taxonomy of Misinformation Harms from Social Media in Humanitarian Crises.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Thi Tran", "id-internal": "247/2935", "id-external": ""}, {"name": "Rohit Valecha", "id-internal": "60/11315", "id-external": ""}], "url": {"full": "URL#828562", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 133981647, "title": "Online misinformation - from the deceiver to the victim.", "abstract": "", "doi": "10.1145/3341161.3343536", "date": "2019", "authors": [{"name": "Anu Shrestha", "id-internal": "225/5383", "id-external": ""}, {"name": "Francesca Spezzano", "id-internal": "81/7907", "id-external": ""}], "url": {"full": "URL#832859", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1782017439, "title": "Misinformation Harms During Crises - When The Human And Machine Loops Interact.", "abstract": "", "doi": "10.1109/bigdata47090.2019.9005561", "date": "2019", "authors": [{"name": "Thi Tran", "id-internal": "247/2935", "id-external": ""}, {"name": "Paul Rad", "id-internal": "263/1357", "id-external": ""}, {"name": "Rohit Valecha", "id-internal": "60/11315", "id-external": ""}, {"name": "H. Raghav Rao", "id-internal": "r/HRaghavRao", "id-external": ""}], "url": {"full": "URL#836605", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3920855087, "title": "Source reliability and the continued influence effect of misinformation - A Bayesian network approach.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Jens Koed Madsen", "id-internal": "175/9913", "id-external": ""}, {"name": "Saoirse Connor Desai", "id-internal": "176/0169", "id-external": ""}, {"name": "Toby D. Pilditch", "id-internal": "212/4113", "id-external": ""}], "url": {"full": "URL#851380", "pdf": ""}, "publisher-venue": "CogSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4087025207, "title": "Can WhatsApp Counter Misinformation by Limiting Message Forwarding?", "abstract": "", "doi": "10.1007/978-3-030-36687-2_31", "date": "2019", "authors": [{"name": "Philipe de Freitas Melo", "id-internal": "249/2549", "id-external": ""}, {"name": "Carolina Coimbra Vieira", "id-internal": "207/7031", "id-external": ""}, {"name": "Kiran Garimella", "id-internal": "117/4298", "id-external": ""}, {"name": "Pedro O. S. Vaz de Melo", "id-internal": "28/3311", "id-external": ""}, {"name": "Fabr\u00edcio Benevenuto", "id-internal": "90/2878", "id-external": ""}], "url": {"full": "URL#852564", "pdf": ""}, "publisher-venue": "COMPLEX NETWORKS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4265192758, "title": "Misinformation Containment in OSNs leveraging Community Structure.", "abstract": "", "doi": "10.1109/icawst.2019.8923277", "date": "2019", "authors": [{"name": "Arnab Kumar Ghoshal", "id-internal": "192/5890", "id-external": ""}, {"name": "Nabanita Das", "id-internal": "49/3105", "id-external": ""}, {"name": "Soham Das 0001", "id-internal": "88/10960", "id-external": ""}], "url": {"full": "URL#891090", "pdf": ""}, "publisher-venue": "iCAST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1629811907, "title": "Misinformation Detection on Online Social Media-A Survey.", "abstract": "", "doi": "10.1109/icccnt45670.2019.8944587", "date": "2019", "authors": [{"name": "Rohit Kumar Kaliyar", "id-internal": "261/1345", "id-external": ""}, {"name": "Navya Singh", "id-internal": "228/7116", "id-external": ""}], "url": {"full": "URL#894354", "pdf": ""}, "publisher-venue": "ICCCNT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1799288929, "title": "The Role of Health Literacy on Credibility Judgment of Online Health Misinformation.", "abstract": "", "doi": "10.1109/ichi.2019.8904844", "date": "2019", "authors": [{"name": "Shijie Song", "id-internal": "62/3099", "id-external": ""}, {"name": "Yuxiang (Chris) Zhao", "id-internal": "18/9170", "id-external": ""}, {"name": "Xiaokang Song", "id-internal": "121/8865", "id-external": ""}, {"name": "Qinghua Zhu 0002", "id-internal": "08/7078-2", "id-external": ""}], "url": {"full": "URL#902083", "pdf": ""}, "publisher-venue": "ICHI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4212325095, "title": "Addressing Health Misinformation Dissemination on Mobile Social Media.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Rui Gu", "id-internal": "38/1778", "id-external": ""}, {"name": "Yili Kevin Hong", "id-internal": "66/5863-2", "id-external": ""}], "url": {"full": "URL#905101", "pdf": ""}, "publisher-venue": "ICIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 874746593, "title": "Online Misinformation Spread - A Systematic Literature Map.", "abstract": "", "doi": "10.1145/3325917.3325938", "date": "2019", "authors": {"name": "Malik Almaliki", "id-internal": "142/9859", "id-external": ""}, "url": {"full": "URL#905456", "pdf": ""}, "publisher-venue": "ICISDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2756497743, "title": "Towards Automatic Detection of Misinformation in Online Medical Videos.", "abstract": "", "doi": "10.1145/1122445.3353763", "date": "2019", "authors": [{"name": "Rui Hou", "id-internal": "79/3631", "id-external": ""}, {"name": "Ver\u00f3nica P\u00e9rez-Rosas", "id-internal": "53/9684", "id-external": ""}, {"name": "Stacy Loeb", "id-internal": "248/7555", "id-external": ""}, {"name": "Rada Mihalcea", "id-internal": "m/RadaMihalcea", "id-external": ""}], "url": {"full": "URL#907898", "pdf": ""}, "publisher-venue": "ICMI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3270706992, "title": "The Spread and Mutation of Science Misinformation.", "abstract": "", "doi": "10.1007/978-3-030-15742-5_15", "date": "2019", "authors": {"name": "Ania Korsunska", "id-internal": "237/1809", "id-external": ""}, "url": {"full": "URL#910237", "pdf": ""}, "publisher-venue": "iConference", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 654248018, "title": "\"Just My Intuition\" - Awareness of Versus Acting on Political News Misinformation.", "abstract": "", "doi": "10.1007/978-3-030-15742-5_45", "date": "2019", "authors": [{"name": "Yong Ming Kow", "id-internal": "25/1432", "id-external": ""}, {"name": "Yubo Kou", "id-internal": "40/8279", "id-external": ""}, {"name": "Xitong Zhu", "id-internal": "237/1792", "id-external": ""}, {"name": "Wang Hin Sy", "id-internal": "237/1821", "id-external": ""}], "url": {"full": "URL#910238", "pdf": ""}, "publisher-venue": "iConference", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2209191543, "title": "Bias Misperceived - The Role of Partisanship and Misinformation in YouTube Comment Moderation.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Shan Jiang 0008", "id-internal": "04/2910-8", "id-external": ""}, {"name": "Ronald E. Robertson", "id-internal": "212/2681", "id-external": ""}, {"name": "Christo Wilson", "id-internal": "79/5135", "id-external": ""}], "url": {"full": "URL#917606", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 198943880, "title": "NELA-GT-2018 - A Large Multi-Labelled News Dataset for the Study of Misinformation in News Articles.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Jeppe N\u00f8rregaard", "id-internal": "239/4071", "id-external": ""}, {"name": "Benjamin D. Horne", "id-internal": "166/8102", "id-external": ""}, {"name": "Sibel Adali", "id-internal": "a/SAdali", "id-external": ""}], "url": {"full": "URL#917619", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 924048011, "title": "Beyond Uniform Reverse Sampling - A Hybrid Sampling Technique for Misinformation Prevention.", "abstract": "", "doi": "10.1109/infocom.2019.8737485", "date": "2019", "authors": [{"name": "Guangmo Amo Tong", "id-internal": "146/0784", "id-external": ""}, {"name": "Ding-Zhu Du", "id-internal": "d/DingZhuDu", "id-external": ""}], "url": {"full": "URL#927467", "pdf": ""}, "publisher-venue": "INFOCOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2355850585, "title": "Combating Misinformation Through Nudging.", "abstract": "", "doi": "10.1007/978-3-030-29390-1_51", "date": "2019", "authors": [{"name": "Loukas Konstantinou", "id-internal": "247/9905", "id-external": ""}, {"name": "Ana Karina Caraban", "id-internal": "144/5517", "id-external": ""}, {"name": "Evangelos Karapanos", "id-internal": "90/191", "id-external": ""}], "url": {"full": "URL#928371", "pdf": ""}, "publisher-venue": "INTERACT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3903719963, "title": "Challenging Misinformation - Exploring Limits and Approaches.", "abstract": "", "doi": "10.1007/978-3-030-29390-1_68", "date": "2019", "authors": [{"name": "Lara S. G. Piccolo", "id-internal": "99/1852", "id-external": ""}, {"name": "Somya Joshi", "id-internal": "41/7246", "id-external": ""}, {"name": "Evangelos Karapanos", "id-internal": "90/191", "id-external": ""}, {"name": "Tracie Farrell", "id-internal": "190/1706", "id-external": ""}], "url": {"full": "URL#928419", "pdf": ""}, "publisher-venue": "INTERACT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1706892130, "title": "Fact Checking Misinformation Using Recommendations from Emotional Pedagogical Agents.", "abstract": "", "doi": "10.1007/978-3-030-22244-4_13", "date": "2019", "authors": [{"name": "Ricky J. Sethi", "id-internal": "69/8616", "id-external": ""}, {"name": "Raghuram Rangaraju", "id-internal": "226/0935", "id-external": ""}, {"name": "Bryce Shurts", "id-internal": "241/8677", "id-external": ""}], "url": {"full": "URL#940988", "pdf": ""}, "publisher-venue": "ITS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1960754277, "title": "Vulnerable to misinformation? - Verifi!", "abstract": "", "doi": "10.1145/3301275.3302320", "date": "2019", "authors": [{"name": "Alireza Karduni", "id-internal": "156/7556", "id-external": ""}, {"name": "Isaac Cho", "id-internal": "50/11181", "id-external": ""}, {"name": "Ryan Wesslen", "id-internal": "217/2895", "id-external": ""}, {"name": "Sashank Santhanam", "id-internal": "221/5959", "id-external": ""}, {"name": "Svitlana Volkova", "id-internal": "19/8609", "id-external": ""}, {"name": "Dustin Lockhart Arendt", "id-internal": "127/0649", "id-external": ""}, {"name": "Samira Shaikh", "id-internal": "59/1496", "id-external": ""}, {"name": "Wenwen Dou", "id-internal": "82/4583", "id-external": ""}], "url": {"full": "URL#941975", "pdf": ""}, "publisher-venue": "IUI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2169444897, "title": "Multiple Topics Misinformation blocking in Online Social Networks.", "abstract": "", "doi": "10.1109/kse.2019.8919356", "date": "2019", "authors": [{"name": "Dung V. Pham", "id-internal": "257/2917", "id-external": ""}, {"name": "Hieu V. Duong", "id-internal": "121/1782", "id-external": ""}, {"name": "Canh V. Pham", "id-internal": "166/3485", "id-external": ""}, {"name": "Bao Q. Bui", "id-internal": "216/9904", "id-external": ""}, {"name": "Anh V. Nguyen", "id-internal": "118/5019", "id-external": ""}], "url": {"full": "URL#946234", "pdf": ""}, "publisher-venue": "KSE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4162866010, "title": "Human and Algorithmic Contributions to Misinformation Online - Identifying the Culprit.", "abstract": "", "doi": "10.1007/978-3-030-39627-5_1", "date": "2019", "authors": {"name": "Andr\u00e9 Calero Valdez", "id-internal": "77/7521", "id-external": ""}, "url": {"full": "URL#952872", "pdf": ""}, "publisher-venue": "MISDOOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4269605214, "title": "Health Misinformation on Social Media - A Literature Review.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Yangjun Li", "id-internal": "172/8290", "id-external": ""}, {"name": "Christy M. K. Cheung", "id-internal": "66/1988", "id-external": ""}, {"name": "Xiao-Liang Shen", "id-internal": "75/865", "id-external": ""}, {"name": "Matthew K. O. Lee", "id-internal": "90/4914", "id-external": ""}], "url": {"full": "URL#962305", "pdf": ""}, "publisher-venue": "PACIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1584760475, "title": "MisinfoMe - Who is Interacting with Misinformation?", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Martino Mensio", "id-internal": "218/0707", "id-external": ""}, {"name": "Harith Alani", "id-internal": "74/2147", "id-external": ""}], "url": {"full": "URL#973717", "pdf": ""}, "publisher-venue": "ISWC Satellites", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3663700748, "title": "ROME 2019 - Workshop on Reducing Online Misinformation Exposure.", "abstract": "", "doi": "10.1145/3331184.3331645", "date": "2019", "authors": [{"name": "Guillaume Bouchard", "id-internal": "84/1386", "id-external": ""}, {"name": "Guido Caldarelli", "id-internal": "50/6478", "id-external": ""}, {"name": "Vassilis Plachouras", "id-internal": "59/5877", "id-external": ""}], "url": {"full": "URL#975637", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1059119177, "title": "QuickStop - A Markov Optimal Stopping Approach for Quickest Misinformation Detection.", "abstract": "", "doi": "10.1145/3309697.3331513", "date": "2019", "authors": [{"name": "Honghao Wei", "id-internal": "176/4191", "id-external": ""}, {"name": "Xiaohan Kang", "id-internal": "61/8656", "id-external": ""}, {"name": "Weina Wang", "id-internal": "88/2200", "id-external": ""}, {"name": "Lei Ying", "id-internal": "27/4818", "id-external": ""}], "url": {"full": "URL#976056", "pdf": ""}, "publisher-venue": "SIGMETRICS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2249831967, "title": "An Investigation of Misinformation Harms Related to Social Media During Humanitarian Crises.", "abstract": "", "doi": "10.1007/978-981-15-3817-9_10", "date": "2019", "authors": [{"name": "Thi Tran", "id-internal": "247/2935", "id-external": ""}, {"name": "Rohit Valecha", "id-internal": "60/11315", "id-external": ""}, {"name": "Paul Rad", "id-internal": "263/1357", "id-external": ""}, {"name": "H. Raghav Rao", "id-internal": "r/HRaghavRao", "id-external": ""}], "url": {"full": "URL#977516", "pdf": ""}, "publisher-venue": "SKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3601368919, "title": "Keynote speech 1 - Misinformation Detection in Online Social Networks using Content.", "abstract": "", "doi": "10.1109/snams.2019.8931712", "date": "2019", "authors": {"name": "Anastasia Giachanou", "id-internal": "118/3830", "id-external": ""}, "url": {"full": "URL#978934", "pdf": ""}, "publisher-venue": "SNAMS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1959984188, "title": "Trustworthy Misinformation Mitigation with Soft Information Nudging.", "abstract": "", "doi": "10.1109/tps-isa48467.2019.00039", "date": "2019", "authors": [{"name": "Benjamin D. Horne", "id-internal": "166/8102", "id-external": ""}, {"name": "Maur\u00edcio Gruppi", "id-internal": "222/1779", "id-external": ""}, {"name": "Sibel Adali", "id-internal": "a/SAdali", "id-external": ""}], "url": {"full": "URL#984767", "pdf": ""}, "publisher-venue": "TPS-ISA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1602620022, "title": "Misinformation on Twitter During the Danish National Election - A Case Study.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Leon Derczynski", "id-internal": "66/8157", "id-external": ""}, {"name": "Torben Oskar Albert-Lindqvist", "id-internal": "277/6527", "id-external": ""}, {"name": "Marius Ven\u00f8 Bendsen", "id-internal": "277/6124", "id-external": ""}, {"name": "Nanna Inie", "id-internal": "199/2723", "id-external": ""}, {"name": "Viktor Due Pedersen", "id-internal": "277/5753", "id-external": ""}, {"name": "Jens Egholm Pedersen", "id-internal": "277/5618", "id-external": ""}], "url": {"full": "URL#985243", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 998892756, "title": "Understanding the Role of Human Values in the Spread of Misinformation.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Tracie Farrell", "id-internal": "190/1706", "id-external": ""}, {"name": "Lara S. G. Piccolo", "id-internal": "99/1852", "id-external": ""}, {"name": "Serena Coppolino Perfumi", "id-internal": "184/7882", "id-external": ""}, {"name": "Harith Alani", "id-internal": "74/2147", "id-external": ""}, {"name": "Martino Mensio", "id-internal": "218/0707", "id-external": ""}], "url": {"full": "URL#985244", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 904100366, "title": "Towards easy-to-implement misinformation automatic detection for online social media.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Julio C\u00e9sar Amador D\u00edaz L\u00f3pez", "id-internal": "204/9865", "id-external": ""}, {"name": "Miguel Molina-Solana", "id-internal": "92/7407", "id-external": ""}, {"name": "Juan G\u00f3mez-Romero", "id-internal": "95/4289", "id-external": ""}], "url": {"full": "URL#985247", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1062504841, "title": "Tools for Countering Misinformation on Encrypted Chat Apps.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Swair Shah", "id-internal": "195/8173", "id-external": ""}, {"name": "Denny George", "id-internal": "277/4970", "id-external": ""}, {"name": "Tarunima Prabhakar", "id-internal": "124/9022", "id-external": ""}], "url": {"full": "URL#985254", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2699142340, "title": "Language Alternation in Online Communication with Misinformation.", "abstract": "", "doi": "10.1007/978-3-030-67781-7_15", "date": "2019", "authors": [{"name": "Lina Zhou", "id-internal": "82/1412", "id-external": ""}, {"name": "Jaewan Lim", "id-internal": "228/2208", "id-external": ""}, {"name": "Hamad Alsaleh", "id-internal": "244/3704", "id-external": ""}, {"name": "Jieyu Wang", "id-internal": "53/9822", "id-external": ""}, {"name": "Dongsong Zhang", "id-internal": "73/3867", "id-external": ""}], "url": {"full": "URL#991900", "pdf": ""}, "publisher-venue": "WEB", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3822545322, "title": "Trust It or Not - Effects of Machine-Learning Warnings in Helping Individuals Mitigate Misinformation.", "abstract": "", "doi": "10.1145/3292522.3326012", "date": "2019", "authors": [{"name": "Haeseung Seo", "id-internal": "244/0106", "id-external": ""}, {"name": "Aiping Xiong", "id-internal": "162/1393", "id-external": ""}, {"name": "Dongwon Lee 0001", "id-internal": "l/DongwonLee", "id-external": ""}], "url": {"full": "URL#992236", "pdf": ""}, "publisher-venue": "WebSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 943336587, "title": "Building Sociality through Sharing - Seniors' Perspectives on Misinformation.", "abstract": "", "doi": "10.1145/3292522.3326052", "date": "2019", "authors": [{"name": "Mahika Wason", "id-internal": "244/0348", "id-external": ""}, {"name": "Sharmistha Swasti Gupta", "id-internal": "239/7086", "id-external": ""}, {"name": "Shriram Venkatraman", "id-internal": "244/0372", "id-external": ""}, {"name": "Ponnurangam Kumaraguru", "id-internal": "97/5147", "id-external": ""}], "url": {"full": "URL#992245", "pdf": ""}, "publisher-venue": "WebSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2367429880, "title": "Misinformation Dissemination on the Web.", "abstract": "", "doi": "10.1145/3308560.3316450", "date": "2019", "authors": {"name": "Jussara M. Almeida", "id-internal": "34/5480", "id-external": ""}, "url": {"full": "URL#995211", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2866506423, "title": "Identification of the Source(s) of Misinformation Propagation Utilizing Identifying Codes.", "abstract": "", "doi": "10.1145/3308560.3314200", "date": "2019", "authors": {"name": "Kaustav Basu", "id-internal": "158/8063", "id-external": ""}, "url": {"full": "URL#995245", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2911496767, "title": "Dynamics of Misinformation Cascades.", "abstract": "", "doi": "10.1145/3308560.3314194", "date": "2019", "authors": {"name": "Jasser Jasser", "id-internal": "201/9832", "id-external": ""}, "url": {"full": "URL#995430", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1832694788, "title": "A Study of Misinformation in WhatsApp groups with a focus on the Brazilian Presidential Elections.", "abstract": "", "doi": "10.1145/3308560.3316738", "date": "2019", "authors": [{"name": "Caio Machado", "id-internal": "240/9030", "id-external": ""}, {"name": "Beatriz Kira", "id-internal": "240/9292", "id-external": ""}, {"name": "Vidya Narayanan", "id-internal": "84/3679", "id-external": ""}, {"name": "Bence Kollanyi", "id-internal": "71/11368", "id-external": ""}, {"name": "Philip N. Howard", "id-internal": "58/7535", "id-external": ""}], "url": {"full": "URL#995533", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3425702647, "title": "Reply-Aided Detection of Misinformation via Bayesian Deep Learning.", "abstract": "", "doi": "10.1145/3308558.3313718", "date": "2019", "authors": [{"name": "Qiang Zhang 0026", "id-internal": "72/3527-26", "id-external": ""}, {"name": "Aldo Lipani", "id-internal": "150/5264", "id-external": ""}, {"name": "Shangsong Liang", "id-internal": "57/7731", "id-external": ""}, {"name": "Emine Yilmaz", "id-internal": "36/3270", "id-external": ""}], "url": {"full": "URL#995804", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1789923016, "title": "Beyond Uniform Reverse Sampling - A Hybrid Sampling Technique for Misinformation Prevention.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Guangmo Tong", "id-internal": "146/0784", "id-external": ""}, {"name": "Ding-Zhu Du", "id-internal": "d/DingZhuDu", "id-external": ""}], "url": {"full": "URL#1003994", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 408785780, "title": "Building Knowledge Graphs About Political Agents in the Age of Misinformation.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Daniel Schwabe", "id-internal": "s/DanielSchwabe", "id-external": ""}, {"name": "Carlos Laufer", "id-internal": "37/3537", "id-external": ""}, {"name": "Antonio Jos\u00e9 G. Busson", "id-internal": "190/1415", "id-external": ""}], "url": {"full": "URL#1005955", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1793088641, "title": "QuickStop - A Markov Optimal Stopping Approach for Quickest Misinformation Detection.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Honghao Wei", "id-internal": "176/4191", "id-external": ""}, {"name": "Xiaohan Kang", "id-internal": "61/8656", "id-external": ""}, {"name": "Weina Wang", "id-internal": "88/2200", "id-external": ""}, {"name": "Lei Ying", "id-internal": "27/4818", "id-external": ""}], "url": {"full": "URL#1011093", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3004266092, "title": "Human-Misinformation interaction - Understanding the interdisciplinary approach needed to computationally combat false information.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Alireza Karduni", "id-internal": "156/7556", "id-external": ""}, "url": {"full": "URL#1011740", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1219062960, "title": "NELA-GT-2018 - A Large Multi-Labelled News Dataset for The Study of Misinformation in News Articles.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Jeppe Norregaard", "id-internal": "239/4071", "id-external": ""}, {"name": "Benjamin D. Horne", "id-internal": "166/8102", "id-external": ""}, {"name": "Sibel Adali", "id-internal": "a/SAdali", "id-external": ""}], "url": {"full": "URL#1013909", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3685438356, "title": "Containing misinformation spreading in temporal social networks.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Wei Wang 0070", "id-internal": "35/7092-70", "id-external": ""}, {"name": "Yuanhui Ma", "id-internal": "239/8598", "id-external": ""}, {"name": "Tao Wu 0003", "id-internal": "20/5998-3", "id-external": ""}, {"name": "Yang Dai", "id-internal": "13/5606", "id-external": ""}, {"name": "Xingshu Chen", "id-internal": "43/1479", "id-external": ""}, {"name": "Lidia A. Braunstein", "id-internal": "96/518", "id-external": ""}], "url": {"full": "URL#1017228", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3286950894, "title": "Misinformation spreading on correlated multiplex networks.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Jiajun Xian", "id-internal": "248/8902", "id-external": ""}, {"name": "Dan Yang", "id-internal": "43/3014", "id-external": ""}, {"name": "Liming Pan", "id-internal": "142/2952", "id-external": ""}, {"name": "Wei Wang 0070", "id-internal": "35/7092-70", "id-external": ""}, {"name": "Zhen Wang", "id-internal": "78/6727", "id-external": ""}], "url": {"full": "URL#1036965", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3445567683, "title": "Towards Automatic Detection of Misinformation in Online Medical Videos.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Rui Hou", "id-internal": "79/3631", "id-external": ""}, {"name": "Ver\u00f3nica P\u00e9rez-Rosas", "id-internal": "53/9684", "id-external": ""}, {"name": "Stacy Loeb", "id-internal": "248/7555", "id-external": ""}, {"name": "Rada Mihalcea", "id-internal": "m/RadaMihalcea", "id-external": ""}], "url": {"full": "URL#1037365", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2038672818, "title": "The Future of Misinformation Detection - New Perspectives and Trends.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Bin Guo 0001", "id-internal": "86/2663-1", "id-external": ""}, {"name": "Yasan Ding", "id-internal": "245/2848", "id-external": ""}, {"name": "Lina Yao", "id-internal": "56/6651", "id-external": ""}, {"name": "Yunji Liang", "id-internal": "22/10796", "id-external": ""}, {"name": "Zhiwen Yu 0001", "id-internal": "z/YuZhiwen", "id-external": ""}], "url": {"full": "URL#1038173", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3759776446, "title": "Can WhatsApp Counter Misinformation by Limiting Message Forwarding?", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Philipe de Freitas Melo", "id-internal": "249/2549", "id-external": ""}, {"name": "Carolina Coimbra Vieira", "id-internal": "207/7031", "id-external": ""}, {"name": "Kiran Garimella", "id-internal": "117/4298", "id-external": ""}, {"name": "Pedro O. S. Vaz de Melo", "id-internal": "28/3311", "id-external": ""}, {"name": "Fabr\u00edcio Benevenuto", "id-internal": "90/2878", "id-external": ""}], "url": {"full": "URL#1040037", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1665022366, "title": "Trustworthy Misinformation Mitigation with Soft Information Nudging.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Benjamin D. Horne", "id-internal": "166/8102", "id-external": ""}, {"name": "Maur\u00edcio Gruppi", "id-internal": "222/1779", "id-external": ""}, {"name": "Sibel Adali", "id-internal": "a/SAdali", "id-external": ""}], "url": {"full": "URL#1049538", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1501785904, "title": "Defending Against Model Stealing Attacks with Adaptive Misinformation.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Sanjay Kariyappa", "id-internal": "223/6062", "id-external": ""}, {"name": "Moinuddin K. Qureshi", "id-internal": "60/6934", "id-external": ""}], "url": {"full": "URL#1049982", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2672505441, "title": "Warning Signs in Communicating the Machine Learning Detection Results of Misinformation with Individuals.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Limeng Cui", "id-internal": "147/6826", "id-external": ""}, "url": {"full": "URL#1051914", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1575247656, "title": "Tracking and Characterizing the Competition of Fact Checking and Misinformation - Case Studies.", "abstract": "", "doi": "10.1109/access.2018.2881037", "date": "2018", "authors": [{"name": "Chengcheng Shao", "id-internal": "150/7597", "id-external": ""}, {"name": "Pik-Mai Hui", "id-internal": "135/6735", "id-external": ""}, {"name": "Pengshuai Cui", "id-internal": "204/8379", "id-external": ""}, {"name": "Xinwen Jiang", "id-internal": "130/4046", "id-external": ""}, {"name": "Yuxing Peng", "id-internal": "42/2857", "id-external": ""}], "url": {"full": "URL#1068528", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4043425668, "title": "Research Challenges of Digital Misinformation - Toward a Trustworthy Web.", "abstract": "", "doi": "10.1609/aimag.v39i1.2783", "date": "2018", "authors": [{"name": "Giovanni Luca Ciampaglia", "id-internal": "07/8400", "id-external": ""}, {"name": "Alexios Mantzarlis", "id-internal": "212/2676", "id-external": ""}, {"name": "Gregory Maus", "id-internal": "203/0219", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}], "url": {"full": "URL#1072657", "pdf": ""}, "publisher-venue": "AI Mag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2094607525, "title": "Representing vaccine misinformation using ontologies.", "abstract": "", "doi": "10.1186/s13326-018-0190-0", "date": "2018", "authors": [{"name": "Muhammad Amith", "id-internal": "147/8455", "id-external": ""}, {"name": "Cui Tao", "id-internal": "03/4748", "id-external": ""}], "url": {"full": "URL#1079421", "pdf": ""}, "publisher-venue": "J. Biomed. Semant.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1383196220, "title": "The diffusion of misinformation on social media - Temporal pattern, message, and source.", "abstract": "", "doi": "10.1016/j.chb.2018.02.008", "date": "2018", "authors": [{"name": "Jieun Shin", "id-internal": "206/3757", "id-external": ""}, {"name": "Lian Jian", "id-internal": "95/5081", "id-external": ""}, {"name": "Kevin Driscoll", "id-internal": "50/6405", "id-external": ""}, {"name": "Fran\u00e7ois Bar", "id-internal": "45/3079", "id-external": ""}], "url": {"full": "URL#1085981", "pdf": ""}, "publisher-venue": "Comput. Hum. Behav.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3538670907, "title": "Post-Truth - Hoaxes, Misinformation, Trust and Reputation in the Network Society.", "abstract": "", "doi": "10.4018/ijep.2018040101", "date": "2018", "authors": {"name": "Luciano Paccagnella", "id-internal": "60/4151", "id-external": ""}, "url": {"full": "URL#1116661", "pdf": ""}, "publisher-venue": "Int. J. E Politics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2721203717, "title": "Countering Superintelligence Misinformation.", "abstract": "", "doi": "10.3390/info9100244", "date": "2018", "authors": {"name": "Seth D. Baum", "id-internal": "61/10325", "id-external": ""}, "url": {"full": "URL#1125764", "pdf": ""}, "publisher-venue": "Inf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 581203486, "title": "Review of - Southwell, Brian G., Thorson, Emily A. and Laura Sheble, (Eds.). Misinformation and mass audiences Austin, TX - University of Texas Press, 2018.", "abstract": "", "doi": "", "date": "2018", "authors": {"name": "T. D. Wilson 0001", "id-internal": "w/TDWilson", "id-external": ""}, "url": {"full": "URL#1128005", "pdf": ""}, "publisher-venue": "Inf. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 980469434, "title": "Maximizing misinformation restriction within time and budget constraints.", "abstract": "", "doi": "10.1007/s10878-018-0252-3", "date": "2018", "authors": [{"name": "Canh V. Pham", "id-internal": "166/3485", "id-external": ""}, {"name": "My T. Thai", "id-internal": "63/4711", "id-external": ""}, {"name": "Hieu V. Duong", "id-internal": "121/1782", "id-external": ""}, {"name": "Bao Q. Bui", "id-internal": "216/9904", "id-external": ""}, {"name": "Huan X. Hoang", "id-internal": "166/3472", "id-external": ""}], "url": {"full": "URL#1134315", "pdf": ""}, "publisher-venue": "J. Comb. Optim.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2549295697, "title": "Algorithmic detection of misinformation and disinformation - Gricean perspectives.", "abstract": "", "doi": "10.1108/jd-05-2017-0075", "date": "2018", "authors": {"name": "Sille Obelitz S\u00f8e", "id-internal": "215/9000", "id-external": ""}, "url": {"full": "URL#1135970", "pdf": ""}, "publisher-venue": "J. Documentation", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 700131456, "title": "Information and misinformation in bibliometric time-trend analysis.", "abstract": "", "doi": "10.1016/j.joi.2018.08.009", "date": "2018", "authors": {"name": "Jonathan Adams 0001", "id-internal": "77/4291-1", "id-external": ""}, "url": {"full": "URL#1142203", "pdf": ""}, "publisher-venue": "J. Informetrics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2513546192, "title": "Politics, sentiments, and misinformation - An analysis of the Twitter discussion on the 2016 Austrian Presidential Elections.", "abstract": "", "doi": "10.1016/j.osnem.2017.12.002", "date": "2018", "authors": [{"name": "Ema Kusen", "id-internal": "122/1631", "id-external": ""}, {"name": "Mark Strembeck", "id-internal": "05/6430", "id-external": ""}], "url": {"full": "URL#1158654", "pdf": ""}, "publisher-venue": "Online Soc. Networks Media", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 852351310, "title": "Fake Cures - User-centric Modeling of Health Misinformation in Social Media.", "abstract": "", "doi": "10.1145/3274327", "date": "2018", "authors": [{"name": "Amira Ghenai", "id-internal": "33/11411", "id-external": ""}, {"name": "Yelena Mejova", "id-internal": "29/758", "id-external": ""}], "url": {"full": "URL#1158872", "pdf": ""}, "publisher-venue": "Proc. ACM Hum. Comput. Interact.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1784542961, "title": "Linguistic Signals under Misinformation and Fact-Checking - Evidence from User Comments on Social Media.", "abstract": "", "doi": "10.1145/3274351", "date": "2018", "authors": [{"name": "Shan Jiang 0008", "id-internal": "04/2910-8", "id-external": ""}, {"name": "Christo Wilson", "id-internal": "79/5135", "id-external": ""}], "url": {"full": "URL#1158897", "pdf": ""}, "publisher-venue": "Proc. ACM Hum. Comput. Interact.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1416359998, "title": "Opinion - Medical misinformation in the era of Google - Computational approaches to a pervasive problem.", "abstract": "", "doi": "10.1073/pnas.1808264115", "date": "2018", "authors": [{"name": "Scott R. Granter", "id-internal": "244/5831", "id-external": ""}, {"name": "David J. Papke Jr.", "id-internal": "244/5761", "id-external": ""}], "url": {"full": "URL#1161018", "pdf": ""}, "publisher-venue": "Proc. Natl. Acad. Sci. USA", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2090052603, "title": "A Multiclass Mean-Field Game for Thwarting Misinformation Spread in the Internet of Battlefield Things.", "abstract": "", "doi": "10.1109/tcomm.2018.2866859", "date": "2018", "authors": [{"name": "Nof Abuzainab", "id-internal": "115/8725", "id-external": ""}, {"name": "Walid Saad", "id-internal": "41/6237", "id-external": ""}], "url": {"full": "URL#1184874", "pdf": ""}, "publisher-venue": "IEEE Trans. Commun.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 143667492, "title": "Mining Significant Microblogs for Misinformation Identification - An Attention-Based Approach.", "abstract": "", "doi": "10.1145/3173458", "date": "2018", "authors": [{"name": "Qiang Liu 0006", "id-internal": "61/3234-6", "id-external": ""}, {"name": "Feng Yu", "id-internal": "28/1708", "id-external": ""}, {"name": "Shu Wu", "id-internal": "06/3577", "id-external": ""}, {"name": "Liang Wang 0001", "id-internal": "56/4499-1", "id-external": ""}], "url": {"full": "URL#1191631", "pdf": ""}, "publisher-venue": "ACM Trans. Intell. Syst. Technol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 954343157, "title": "Targeted Misinformation Blocking on Online Social Networks.", "abstract": "", "doi": "10.1007/978-3-319-75417-8_10", "date": "2018", "authors": [{"name": "Canh V. Pham", "id-internal": "166/3485", "id-external": ""}, {"name": "Quat V. Phu", "id-internal": "215/5896", "id-external": ""}, {"name": "Huan X. Hoang", "id-internal": "166/3472", "id-external": ""}], "url": {"full": "URL#1207584", "pdf": ""}, "publisher-venue": "ACIIDS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 359243754, "title": "Semi-supervised Content-Based Detection of Misinformation via Tensor Embeddings.", "abstract": "", "doi": "10.1109/asonam.2018.8508241", "date": "2018", "authors": [{"name": "Gisel Bastidas Guacho", "id-internal": "218/6248", "id-external": ""}, {"name": "Sara Abdali", "id-internal": "218/5833", "id-external": ""}, {"name": "Neil Shah", "id-internal": "71/7771", "id-external": ""}, {"name": "Evangelos E. Papalexakis", "id-internal": "48/9024", "id-external": ""}], "url": {"full": "URL#1217686", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1869186209, "title": "Fight Under Uncertainty - Restraining Misinformation and Pushing out the Truth.", "abstract": "", "doi": "10.1109/asonam.2018.8508402", "date": "2018", "authors": [{"name": "Huiling Zhang", "id-internal": "147/8989", "id-external": ""}, {"name": "Alan Kuhnle", "id-internal": "153/2879", "id-external": ""}, {"name": "J. David Smith", "id-internal": "59/5114", "id-external": ""}, {"name": "My T. Thai", "id-internal": "63/4711", "id-external": ""}], "url": {"full": "URL#1217830", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1534441249, "title": "Silent Chatbot Agent Amplifies Continued-Influence Effect on Misinformation.", "abstract": "", "doi": "10.1145/3170427.3180290", "date": "2018", "authors": [{"name": "Sanghyeong Yu", "id-internal": "218/0224", "id-external": ""}, {"name": "Kwang-Hee Han", "id-internal": "63/5123", "id-external": ""}], "url": {"full": "URL#1230461", "pdf": ""}, "publisher-venue": "CHI Extended Abstracts", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 213971056, "title": "Some misinformation is more easily countered - An experiment on the continued influence effect.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Saoirse Connor Desai", "id-internal": "176/0169", "id-external": ""}, {"name": "Stian Reimers", "id-internal": "159/6855", "id-external": ""}], "url": {"full": "URL#1234418", "pdf": ""}, "publisher-venue": "CogSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3136113186, "title": "Misinformation Control in the Internet of Battlefield Things - A Multiclass Mean-Field Game.", "abstract": "", "doi": "10.1109/glocom.2018.8647236", "date": "2018", "authors": [{"name": "Nof Abuzainab", "id-internal": "115/8725", "id-external": ""}, {"name": "Walid Saad", "id-internal": "41/6237", "id-external": ""}], "url": {"full": "URL#1261974", "pdf": ""}, "publisher-venue": "GLOBECOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3415080958, "title": "The Hoaxy Misinformation and Fact-Checking Diffusion Network.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Pik-Mai Hui", "id-internal": "135/6735", "id-external": ""}, {"name": "Chengcheng Shao", "id-internal": "150/7597", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}, {"name": "Giovanni Luca Ciampaglia", "id-internal": "07/8400", "id-external": ""}], "url": {"full": "URL#1297059", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1406974428, "title": "Can You Verifi This? Studying Uncertainty and Decision-Making About Misinformation Using Visual Analytics.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Alireza Karduni", "id-internal": "156/7556", "id-external": ""}, {"name": "Ryan Wesslen", "id-internal": "217/2895", "id-external": ""}, {"name": "Sashank Santhanam", "id-internal": "221/5959", "id-external": ""}, {"name": "Isaac Cho", "id-internal": "50/11181", "id-external": ""}, {"name": "Svitlana Volkova", "id-internal": "19/8609", "id-external": ""}, {"name": "Dustin Arendt", "id-internal": "127/0649", "id-external": ""}, {"name": "Samira Shaikh", "id-internal": "59/1496", "id-external": ""}, {"name": "Wenwen Dou", "id-internal": "82/4583", "id-external": ""}], "url": {"full": "URL#1297067", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1354750690, "title": "On Misinformation Containment in Online Social Networks.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Guangmo Amo Tong", "id-internal": "146/0784", "id-external": ""}, {"name": "Ding-Zhu Du", "id-internal": "d/DingZhuDu", "id-external": ""}, {"name": "Weili Wu", "id-internal": "w/WeiliWu", "id-external": ""}], "url": {"full": "URL#1336622", "pdf": ""}, "publisher-venue": "NeurIPS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1557357842, "title": "Toward Relational Learning with Misinformation.", "abstract": "", "doi": "10.1137/1.9781611975321.80", "date": "2018", "authors": [{"name": "Liang Wu 0006", "id-internal": "20/5233-6", "id-external": ""}, {"name": "Jundong Li", "id-internal": "144/7997", "id-external": ""}, {"name": "Fred Morstatter", "id-internal": "51/9687", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#1349170", "pdf": ""}, "publisher-venue": "SDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1368813622, "title": "Optimizing a MisInformation and MisBehavior (MIB) Attack Targeting Vehicle Platoons.", "abstract": "", "doi": "10.1109/vtcfall.2018.8690803", "date": "2018", "authors": [{"name": "Bruce DeBruhl", "id-internal": "08/11298", "id-external": ""}, {"name": "Patrick Tague", "id-internal": "89/1945", "id-external": ""}], "url": {"full": "URL#1366688", "pdf": ""}, "publisher-venue": "VTC-Fall", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 673336972, "title": "MIS2 - Misinformation and Misbehavior Mining on the Web.", "abstract": "", "doi": "10.1145/3159652.3160597", "date": "2018", "authors": [{"name": "Srijan Kumar", "id-internal": "131/9628", "id-external": ""}, {"name": "Meng Jiang 0001", "id-internal": "69/339-1", "id-external": ""}, {"name": "Taeho Jung", "id-internal": "12/11514", "id-external": ""}, {"name": "Roger Jie Luo", "id-internal": "153/5288", "id-external": ""}, {"name": "Jure Leskovec", "id-internal": "l/JureLeskovec", "id-external": ""}], "url": {"full": "URL#1372547", "pdf": ""}, "publisher-venue": "WSDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 340707300, "title": "Journalism, Misinformation and Fact Checking Chairs' Welcome & Organization.", "abstract": "", "doi": "10.1145/3184558.3192300", "date": "2018", "authors": [{"name": "Giovanni Luca Ciampaglia", "id-internal": "07/8400", "id-external": ""}, {"name": "Kristina Lerman", "id-internal": "99/433", "id-external": ""}, {"name": "Panagiotis Metaxas", "id-internal": "218/0194", "id-external": ""}], "url": {"full": "URL#1372830", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1549662797, "title": "Online Misinformation - Challenges and Future Directions.", "abstract": "", "doi": "10.1145/3184558.3188730", "date": "2018", "authors": [{"name": "Miriam Fern\u00e1ndez", "id-internal": "54/2749", "id-external": ""}, {"name": "Harith Alani", "id-internal": "74/2147", "id-external": ""}], "url": {"full": "URL#1372878", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3511854218, "title": "CredEye - A Credibility Lens for Analyzing and Explaining Misinformation.", "abstract": "", "doi": "10.1145/3184558.3186967", "date": "2018", "authors": [{"name": "Kashyap Popat", "id-internal": "136/8735", "id-external": ""}, {"name": "Subhabrata Mukherjee", "id-internal": "37/11030", "id-external": ""}, {"name": "Jannik Str\u00f6tgen", "id-internal": "28/8510", "id-external": ""}, {"name": "Gerhard Weikum", "id-internal": "w/GerhardWeikum", "id-external": ""}], "url": {"full": "URL#1373127", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 237566703, "title": "A Structured Response to Misinformation - Defining and Annotating Credibility Indicators in News Articles.", "abstract": "", "doi": "10.1145/3184558.3188731", "date": "2018", "authors": [{"name": "Amy X. Zhang", "id-internal": "133/8390", "id-external": ""}, {"name": "Aditya Ranganathan", "id-internal": "218/0549", "id-external": ""}, {"name": "Sarah Emlen Metz", "id-internal": "218/0829", "id-external": ""}, {"name": "Scott Appling", "id-internal": "218/0810", "id-external": ""}, {"name": "Connie Moon Sehat", "id-internal": "218/0468", "id-external": ""}, {"name": "Norman Gilmore", "id-internal": "218/0623", "id-external": ""}, {"name": "Nick B. Adams", "id-internal": "217/9983", "id-external": ""}, {"name": "Emmanuel Vincent 0003", "id-internal": "55/3279-3", "id-external": ""}, {"name": "Jennifer Lee", "id-internal": "93/8092", "id-external": ""}, {"name": "Martin Robbins", "id-internal": "91/8035", "id-external": ""}, {"name": "Ed Bice", "id-internal": "218/0251", "id-external": ""}, {"name": "Sandro Hawke", "id-internal": "66/7507", "id-external": ""}, {"name": "David R. Karger", "id-internal": "k/DavidRKarger", "id-external": ""}, {"name": "An Xiao Mina", "id-internal": "218/0902", "id-external": ""}], "url": {"full": "URL#1373293", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4040482257, "title": "Misinformation in Social Networks - Analyzing Twitter During Crisis Events.", "abstract": "", "doi": "10.1007/978-1-4939-7131-2_296", "date": "2018", "authors": [{"name": "Aditi Gupta 0003", "id-internal": "51/4962-3", "id-external": ""}, {"name": "Ponnurangam Kumaraguru", "id-internal": "97/5147", "id-external": ""}], "url": {"full": "URL#1379319", "pdf": ""}, "publisher-venue": "Encyclopedia of Social Network Analysis and Mining. 2nd Ed.", "type": "Reference Works", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 148365354, "title": "Misinformation.", "abstract": "", "doi": "10.1007/978-1-4939-7131-2_100668", "date": "2018", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "URL#1380203", "pdf": ""}, "publisher-venue": "Encyclopedia of Social Network Analysis and Mining. 2nd Ed.", "type": "Reference Works", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2241746129, "title": "Misinformation Detection.", "abstract": "", "doi": "10.1007/978-1-4939-7131-2_100670", "date": "2018", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "URL#1380204", "pdf": ""}, "publisher-venue": "Encyclopedia of Social Network Analysis and Mining. 2nd Ed.", "type": "Reference Works", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3728169172, "title": "Anatomy of an online misinformation network.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Chengcheng Shao", "id-internal": "150/7597", "id-external": ""}, {"name": "Pik-Mai Hui", "id-internal": "135/6735", "id-external": ""}, {"name": "Lei Wang", "id-internal": "181/2817", "id-external": ""}, {"name": "Xinwen Jiang", "id-internal": "130/4046", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}, {"name": "Giovanni Luca Ciampaglia", "id-internal": "07/8400", "id-external": ""}], "url": {"full": "URL#1382955", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 471684606, "title": "A Multiclass Mean-Field Game for Thwarting Misinformation Spread in the Internet of Battlefield Things (IoBT).", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Nof Abuzainab", "id-internal": "115/8725", "id-external": ""}, {"name": "Walid Saad", "id-internal": "41/6237", "id-external": ""}], "url": {"full": "URL#1386019", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 747232443, "title": "Semi-supervised Content-based Detection of Misinformation via Tensor Embeddings.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Gisel Bastidas Guacho", "id-internal": "218/6248", "id-external": ""}, {"name": "Sara Abdali", "id-internal": "218/5833", "id-external": ""}, {"name": "Neil Shah", "id-internal": "71/7771", "id-external": ""}, {"name": "Evangelos E. Papalexakis", "id-internal": "48/9024", "id-external": ""}], "url": {"full": "URL#1393135", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1459939438, "title": "Scalable Misinformation Prevention in Social Networks.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Michael Simpson", "id-internal": "150/6218", "id-external": ""}, {"name": "Venkatesh Srinivasan 0001", "id-internal": "v/SrinivasanVenkatesh", "id-external": ""}, {"name": "Alex Thomo", "id-internal": "t/AlexThomo", "id-external": ""}], "url": {"full": "URL#1401410", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 878017667, "title": "Vulnerable to Misinformation? Verifi!", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Alireza Karduni", "id-internal": "156/7556", "id-external": ""}, {"name": "Isaac Cho", "id-internal": "50/11181", "id-external": ""}, {"name": "Ryan Wesslen", "id-internal": "217/2895", "id-external": ""}, {"name": "Sashank Santhanam", "id-internal": "221/5959", "id-external": ""}, {"name": "Svitlana Volkova", "id-internal": "19/8609", "id-external": ""}, {"name": "Dustin Arendt", "id-internal": "127/0649", "id-external": ""}, {"name": "Samira Shaikh", "id-internal": "59/1496", "id-external": ""}, {"name": "Wenwen Dou", "id-internal": "82/4583", "id-external": ""}], "url": {"full": "URL#1403915", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1187915052, "title": "Fake Cures - User-centric Modeling of Health Misinformation in Social Media.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Amira Ghenai", "id-internal": "33/11411", "id-external": ""}, {"name": "Yelena Mejova", "id-internal": "29/758", "id-external": ""}], "url": {"full": "URL#1407802", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1597152829, "title": "Defending Elections Against Malicious Spread of Misinformation.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Bryan Wilder", "id-internal": "164/1648", "id-external": ""}, {"name": "Yevgeniy Vorobeychik", "id-internal": "70/2217", "id-external": ""}], "url": {"full": "URL#1409335", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4204893247, "title": "Trends in the Diffusion of Misinformation on Social Media.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Hunt Allcott", "id-internal": "195/2708", "id-external": ""}, {"name": "Matthew Gentzkow", "id-internal": "204/7869", "id-external": ""}, {"name": "Chuan Yu", "id-internal": "50/790", "id-external": ""}], "url": {"full": "URL#1409469", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3156279472, "title": "On Misinformation Containment in Online Social Networks.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Guangmo Tong", "id-internal": "146/0784", "id-external": ""}, {"name": "Weili Wu", "id-internal": "w/WeiliWu", "id-external": ""}, {"name": "Ding-Zhu Du", "id-internal": "d/DingZhuDu", "id-external": ""}], "url": {"full": "URL#1409669", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1900276122, "title": "Information and misinformation on the internet.", "abstract": "", "doi": "10.1145/3018809", "date": "2017", "authors": {"name": "Vinton G. Cerf", "id-internal": "c/VintonGCerf", "id-external": ""}, "url": {"full": "URL#1441113", "pdf": ""}, "publisher-venue": "Commun. ACM", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 700488096, "title": "Management Misinformation Systems - A Time to Revisit?", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Kalle Lyytinen", "id-internal": "l/KLyytinen", "id-external": ""}, {"name": "Varun Grover", "id-internal": "99/4880", "id-external": ""}], "url": {"full": "URL#1487944", "pdf": ""}, "publisher-venue": "J. Assoc. Inf. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 147230007, "title": "Misinformation in a riot - a two-step flow view.", "abstract": "", "doi": "10.1108/oir-09-2015-0297", "date": "2017", "authors": [{"name": "Natalie Pang", "id-internal": "86/4590", "id-external": ""}, {"name": "Joshua Ng", "id-internal": "116/2153", "id-external": ""}], "url": {"full": "URL#1513643", "pdf": ""}, "publisher-venue": "Online Inf. Rev.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1489639184, "title": "Efficient and timely misinformation blocking under varying cost constraints.", "abstract": "", "doi": "10.1016/j.osnem.2017.07.001", "date": "2017", "authors": [{"name": "Iouliana Litou", "id-internal": "135/6871", "id-external": ""}, {"name": "Vana Kalogeraki", "id-internal": "k/VanaKalogeraki", "id-external": ""}, {"name": "Ioannis Katakis", "id-internal": "25/6745", "id-external": ""}, {"name": "Dimitrios Gunopulos", "id-internal": "g/DimitriosGunopulos", "id-external": ""}], "url": {"full": "URL#1514265", "pdf": ""}, "publisher-venue": "Online Soc. Networks Media", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1766909159, "title": "A novel approach for inhibiting misinformation propagation in human mobile opportunistic networks.", "abstract": "", "doi": "10.1007/s12083-016-0438-3", "date": "2017", "authors": [{"name": "Xiaoming Wang 0001", "id-internal": "60/2139-1", "id-external": ""}, {"name": "Yaguang Lin", "id-internal": "166/1923", "id-external": ""}, {"name": "Yanxin Zhao", "id-internal": "187/3877", "id-external": ""}, {"name": "Lichen Zhang 0001", "id-internal": "00/6357-1", "id-external": ""}, {"name": "Juhua Liang", "id-internal": "68/9265", "id-external": ""}, {"name": "Zhipeng Cai 0001", "id-internal": "14/5155-1", "id-external": ""}], "url": {"full": "URL#1516887", "pdf": ""}, "publisher-venue": "Peer Peer Netw. Appl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3191473594, "title": "Value and Misinformation in Collaborative Investing Platforms.", "abstract": "", "doi": "10.1145/3027487", "date": "2017", "authors": [{"name": "Tianyi Wang", "id-internal": "88/8398", "id-external": ""}, {"name": "Gang Wang 0011", "id-internal": "71/4292-11", "id-external": ""}, {"name": "Bolun Wang", "id-internal": "147/5236", "id-external": ""}, {"name": "Divya Sambasivan", "id-internal": "147/5135", "id-external": ""}, {"name": "Zengbin Zhang", "id-internal": "60/8398", "id-external": ""}, {"name": "Xing Li 0001", "id-internal": "26/379-1", "id-external": ""}, {"name": "Haitao Zheng 0001", "id-internal": "43/4261", "id-external": ""}, {"name": "Ben Y. Zhao", "id-internal": "z/BenYZhao", "id-external": ""}], "url": {"full": "URL#1550561", "pdf": ""}, "publisher-venue": "ACM Trans. Web", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 546572069, "title": "Contrasting the Spread of Misinformation in Online Social Networks.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Marco Amoruso", "id-internal": "199/6488", "id-external": ""}, {"name": "Daniele Anello", "id-internal": "199/6499", "id-external": ""}, {"name": "Vincenzo Auletta", "id-internal": "49/3388", "id-external": ""}, {"name": "Diodato Ferraioli", "id-internal": "18/7864", "id-external": ""}], "url": {"full": "URL#1567616", "pdf": ""}, "publisher-venue": "AAMAS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3788794741, "title": "Health Misinformation in Search and Social Media.", "abstract": "", "doi": "10.1145/3079452.3079483", "date": "2017", "authors": {"name": "Amira Ghenai", "id-internal": "33/11411", "id-external": ""}, "url": {"full": "URL#1597629", "pdf": ""}, "publisher-venue": "DH", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3721793451, "title": "An Ontological Approach to Misinformation - Quickly Finding Relevant Information.", "abstract": "", "doi": "", "date": "2017", "authors": {"name": "Chelsea Hicks", "id-internal": "119/0211", "id-external": ""}, "url": {"full": "URL#1613980", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3864314574, "title": "Temporal Influence Blocking - Minimizing the Effect of Misinformation in Social Networks.", "abstract": "", "doi": "10.1109/icde.2017.134", "date": "2017", "authors": [{"name": "Chonggang Song", "id-internal": "169/1750", "id-external": ""}, {"name": "Wynne Hsu", "id-internal": "h/WynneHsu", "id-external": ""}, {"name": "Mong-Li Lee", "id-internal": "l/MongLiLee", "id-external": ""}], "url": {"full": "URL#1627443", "pdf": ""}, "publisher-venue": "ICDE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1000371838, "title": "Catching Zika Fever - Application of Crowdsourcing and Machine Learning for Tracking Health Misinformation on Twitter.", "abstract": "", "doi": "10.1109/ichi.2017.58", "date": "2017", "authors": [{"name": "Amira Ghenai", "id-internal": "33/11411", "id-external": ""}, {"name": "Yelena Mejova", "id-internal": "29/758", "id-external": ""}], "url": {"full": "URL#1629453", "pdf": ""}, "publisher-venue": "ICHI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3921676482, "title": "Creating a Labeled Dataset for Medical Misinformation in Health Forums.", "abstract": "", "doi": "10.1109/ichi.2017.93", "date": "2017", "authors": [{"name": "Alexander Kinsora", "id-internal": "206/0101", "id-external": ""}, {"name": "Kate Barron", "id-internal": "206/0013", "id-external": ""}, {"name": "Qiaozhu Mei", "id-internal": "30/5059", "id-external": ""}, {"name": "V. G. Vinod Vydiswaran", "id-internal": "67/6469", "id-external": ""}], "url": {"full": "URL#1629472", "pdf": ""}, "publisher-venue": "ICHI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4194786623, "title": "A Convolutional Approach for Misinformation Identification.", "abstract": "", "doi": "10.24963/ijcai.2017/545", "date": "2017", "authors": [{"name": "Feng Yu", "id-internal": "28/1708", "id-external": ""}, {"name": "Qiang Liu 0006", "id-internal": "61/3234-6", "id-external": ""}, {"name": "Shu Wu", "id-internal": "06/3577", "id-external": ""}, {"name": "Liang Wang 0001", "id-internal": "56/4499-1", "id-external": ""}, {"name": "Tieniu Tan", "id-internal": "t/TieniuTan", "id-external": ""}], "url": {"full": "URL#1650285", "pdf": ""}, "publisher-venue": "IJCAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2677967080, "title": "Minimizing the spread of misinformation on online social networks with time and budget constraint.", "abstract": "", "doi": "10.1109/kse.2017.8119452", "date": "2017", "authors": [{"name": "Manh M. Vu", "id-internal": "166/3502", "id-external": ""}, {"name": "Huan X. Hoang", "id-internal": "166/3472", "id-external": ""}], "url": {"full": "URL#1669392", "pdf": ""}, "publisher-venue": "KSE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3551404311, "title": "Health Misinformation in Search and Social Media.", "abstract": "", "doi": "10.1145/3077136.3084153", "date": "2017", "authors": {"name": "Amira Ghenai", "id-internal": "33/11411", "id-external": ""}, "url": {"full": "URL#1696736", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1758091827, "title": "Detecting Misinformation in Social Networks Using Provenance Data.", "abstract": "", "doi": "10.1109/skg.2017.00022", "date": "2017", "authors": [{"name": "Mohamed Jehad Baeth", "id-internal": "175/5448", "id-external": ""}, {"name": "Mehmet S. Aktas", "id-internal": "63/4147", "id-external": ""}], "url": {"full": "URL#1698822", "pdf": ""}, "publisher-venue": "SKG", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3578756603, "title": "It's always April fools' day! - On the difficulty of social network misinformation classification via propagation features.", "abstract": "", "doi": "10.1109/wifs.2017.8267653", "date": "2017", "authors": [{"name": "Mauro Conti", "id-internal": "82/4386", "id-external": ""}, {"name": "Daniele Lain", "id-internal": "172/6530", "id-external": ""}, {"name": "Riccardo Lazzeretti", "id-internal": "87/7355", "id-external": ""}, {"name": "Giulio Lovisotto", "id-internal": "172/6496", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}], "url": {"full": "URL#1713297", "pdf": ""}, "publisher-venue": "WIFS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 682450393, "title": "It's Always April Fools' Day! On the Difficulty of Social Network Misinformation Classification via Propagation Features.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Mauro Conti", "id-internal": "82/4386", "id-external": ""}, {"name": "Daniele Lain", "id-internal": "172/6530", "id-external": ""}, {"name": "Riccardo Lazzeretti", "id-internal": "87/7355", "id-external": ""}, {"name": "Giulio Lovisotto", "id-internal": "172/6496", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}], "url": {"full": "URL#1727322", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3818333117, "title": "Catching Zika Fever - Application of Crowdsourcing and Machine Learning for Tracking Health Misinformation on Twitter.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Amira Ghenai", "id-internal": "33/11411", "id-external": ""}, {"name": "Yelena Mejova", "id-internal": "29/758", "id-external": ""}], "url": {"full": "URL#1729323", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2355259131, "title": "Mining Significant Microblogs for Misinformation Identification - An Attention-based Approach.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Qiang Liu 0006", "id-internal": "61/3234-6", "id-external": ""}, {"name": "Feng Yu", "id-internal": "28/1708", "id-external": ""}, {"name": "Shu Wu", "id-internal": "06/3577", "id-external": ""}, {"name": "Liang Wang 0001", "id-internal": "56/4499-1", "id-external": ""}], "url": {"full": "URL#1733281", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3748091016, "title": "\"Everything I Disagree With is #FakeNews\" - Correlating Political Polarization and Spread of Misinformation.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Manoel Horta Ribeiro", "id-internal": "193/5425", "id-external": ""}, {"name": "Pedro H. Calais", "id-internal": "202/1850", "id-external": ""}, {"name": "Virg\u00edlio A. F. Almeida", "id-internal": "a/VirgilioAlmeida", "id-external": ""}, {"name": "Wagner Meira Jr.", "id-internal": "m/WagnerMeiraJr", "id-external": ""}], "url": {"full": "URL#1736301", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1966689273, "title": "Misinformation spreading on Facebook.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Fabiana Zollo", "id-internal": "60/9927", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}], "url": {"full": "URL#1740691", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3104793338, "title": "Misinformation in Online Social Networks - Detect Them All with a Limited Budget.", "abstract": "", "doi": "10.1145/2885494", "date": "2016", "authors": [{"name": "Huiling Zhang", "id-internal": "147/8989", "id-external": ""}, {"name": "Md Abdul Alim", "id-internal": "12/10415", "id-external": ""}, {"name": "Xiang Li 0016", "id-internal": "40/1491-16", "id-external": ""}, {"name": "My T. Thai", "id-internal": "63/4711", "id-external": ""}, {"name": "Hien T. Nguyen", "id-internal": "25/5671", "id-external": ""}], "url": {"full": "URL#1868283", "pdf": ""}, "publisher-venue": "ACM Trans. Inf. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 430983512, "title": "Detecting misinformation in online social networks before it is too late.", "abstract": "", "doi": "10.1109/asonam.2016.7752288", "date": "2016", "authors": [{"name": "Huiling Zhang", "id-internal": "147/8989", "id-external": ""}, {"name": "Alan Kuhnle", "id-internal": "153/2879", "id-external": ""}, {"name": "Huiyuan Zhang", "id-internal": "34/9800", "id-external": ""}, {"name": "My T. Thai", "id-internal": "63/4711", "id-external": ""}], "url": {"full": "URL#1888432", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3664240284, "title": "Negation affects processing of correct and incorrect information - A visual-world paradigm for misinformation.", "abstract": "", "doi": "", "date": "2016", "authors": [{"name": "Jeffrey Viaud", "id-internal": "212/4862", "id-external": ""}, {"name": "Stephanie Huette", "id-internal": "99/9169", "id-external": ""}], "url": {"full": "URL#1905007", "pdf": ""}, "publisher-venue": "CogSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2993574573, "title": "Checking Information Reliability in Social Networks Regarding User Behavior and Developers' Effort to Avoid Misinformation.", "abstract": "", "doi": "10.1007/978-3-319-39910-2_15", "date": "2016", "authors": [{"name": "Alexandre Pinheiro", "id-internal": "146/6557", "id-external": ""}, {"name": "Claudia Cappelli", "id-internal": "20/5813", "id-external": ""}, {"name": "Cristiano Maciel", "id-internal": "62/5474", "id-external": ""}], "url": {"full": "URL#1932778", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3812237902, "title": "Combating Misinformation Online - Identification of Variables and Proof-of-Concept Study.", "abstract": "", "doi": "10.1007/978-3-319-45234-0_40", "date": "2016", "authors": [{"name": "Milan Dordevic", "id-internal": "184/6198", "id-external": ""}, {"name": "Fadi Safieddine", "id-internal": "38/6173", "id-external": ""}, {"name": "Wassim Masri", "id-internal": "02/6320", "id-external": ""}, {"name": "Pardis Pourghomi", "id-internal": "127/1573", "id-external": ""}], "url": {"full": "URL#1936714", "pdf": ""}, "publisher-venue": "I3E", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1420345118, "title": "Towards automated real-time detection of misinformation on Twitter.", "abstract": "", "doi": "10.1109/icacci.2016.7732347", "date": "2016", "authors": [{"name": "Suchita Jain", "id-internal": "177/2139", "id-external": ""}, {"name": "Vanya Sharma", "id-internal": "177/2128", "id-external": ""}, {"name": "Rishabh Kaushal", "id-internal": "177/2126", "id-external": ""}], "url": {"full": "URL#1938064", "pdf": ""}, "publisher-venue": "ICACCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 937417418, "title": "Real-Time and Cost-Effective Limitation of Misinformation Propagation.", "abstract": "", "doi": "10.1109/mdm.2016.33", "date": "2016", "authors": [{"name": "Iouliana Litou", "id-internal": "135/6871", "id-external": ""}, {"name": "Vana Kalogeraki", "id-internal": "k/VanaKalogeraki", "id-external": ""}, {"name": "Ioannis Katakis", "id-internal": "25/6745", "id-external": ""}, {"name": "Dimitrios Gunopulos", "id-internal": "g/DimitriosGunopulos", "id-external": ""}], "url": {"full": "URL#1986680", "pdf": ""}, "publisher-venue": "MDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3380563020, "title": "The Spread of Misinformation in Social Media.", "abstract": "", "doi": "10.1145/2872518.2890092", "date": "2016", "authors": {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}, "url": {"full": "URL#2032127", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4054139172, "title": "On the statistical properties of viral misinformation in online social media.", "abstract": "", "doi": "", "date": "2016", "authors": {"name": "Alessandro Bessi", "id-internal": "150/6292", "id-external": ""}, "url": {"full": "URL#2040841", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1875550113, "title": "Hoaxy - A Platform for Tracking Online Misinformation.", "abstract": "", "doi": "", "date": "2016", "authors": [{"name": "Chengcheng Shao", "id-internal": "150/7597", "id-external": ""}, {"name": "Giovanni Luca Ciampaglia", "id-internal": "07/8400", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}], "url": {"full": "URL#2056609", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2305423142, "title": "Network segregation in a model of misinformation and fact checking.", "abstract": "", "doi": "", "date": "2016", "authors": [{"name": "Marcella Tambuscio", "id-internal": "162/8994", "id-external": ""}, {"name": "Diego F. M. Oliveira", "id-internal": "120/3529", "id-external": ""}, {"name": "Giovanni Luca Ciampaglia", "id-internal": "07/8400", "id-external": ""}, {"name": "Giancarlo Ruffo", "id-internal": "05/4635", "id-external": ""}], "url": {"full": "URL#2057874", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 229344644, "title": "Veracity of Data - From Truth Discovery Computation Algorithms to Models of Misinformation Dynamics", "abstract": "", "doi": "10.2200/s00676ed1v01y201509dtm042", "date": "2015", "authors": [{"name": "Laure Berti-\u00c9quille", "id-internal": "b/LaureBertiEquille", "id-external": ""}, {"name": "Javier Borge-Holthoefer", "id-internal": "25/9892", "id-external": ""}], "url": {"full": "URL#2068641", "pdf": ""}, "publisher-venue": "Synthesis Lectures on Data Management", "type": "Books and Theses", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3230314392, "title": "User's Action and Decision Making of Retweet Messages towards Reducing Misinformation Spread during Disaster.", "abstract": "", "doi": "10.2197/ipsjjip.23.31", "date": "2015", "authors": [{"name": "Nor Athiyah Abdullah", "id-internal": "145/1679", "id-external": ""}, {"name": "Dai Nishioka", "id-internal": "44/7629", "id-external": ""}, {"name": "Yuko Tanaka", "id-internal": "13/9826", "id-external": ""}, {"name": "Yuko Murayama", "id-internal": "22/6125", "id-external": ""}], "url": {"full": "URL#2127603", "pdf": ""}, "publisher-venue": "J. Inf. Process.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3491036935, "title": "Discover the Misinformation Broadcasting in On-Line Social Networks.", "abstract": "", "doi": "", "date": "2015", "authors": [{"name": "Peiguang Lin", "id-internal": "31/4822", "id-external": ""}, {"name": "Lei Chen 0002", "id-internal": "c/LeiChen0002", "id-external": ""}, {"name": "Mingxuan Yuan", "id-internal": "74/2356", "id-external": ""}, {"name": "Peiyao Nie", "id-internal": "15/6328", "id-external": ""}], "url": {"full": "URL#2128066", "pdf": ""}, "publisher-venue": "J. Inf. Sci. Eng.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 711588595, "title": "Deterring the spread of misinformation on social network sites - A social cognitive theory-guided intervention.", "abstract": "", "doi": "10.1002/pra2.2015.145052010095", "date": "2015", "authors": [{"name": "Xinran Chen", "id-internal": "163/7043", "id-external": ""}, {"name": "Sei-Ching Joanna Sin", "id-internal": "68/9553", "id-external": ""}, {"name": "Yin-Leng Theng", "id-internal": "78/4473", "id-external": ""}, {"name": "Chei Sian Lee", "id-internal": "96/2775", "id-external": ""}], "url": {"full": "URL#2189929", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2705681999, "title": "Connected Through Crisis - Emotional Proximity and the Spread of Misinformation Online.", "abstract": "", "doi": "10.1145/2675133.2675202", "date": "2015", "authors": [{"name": "Y. Linlin Huang", "id-internal": "159/0477", "id-external": ""}, {"name": "Kate Starbird", "id-internal": "84/7848", "id-external": ""}, {"name": "Mania Orand", "id-internal": "159/0380", "id-external": ""}, {"name": "Stephanie A. Stanek", "id-internal": "159/0276", "id-external": ""}, {"name": "Heather T. Pedersen", "id-internal": "159/0413", "id-external": ""}], "url": {"full": "URL#2209245", "pdf": ""}, "publisher-venue": "CSCW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4179763277, "title": "Limiting the Spread of Misinformation While Effectively Raising Awareness in Social Networks.", "abstract": "", "doi": "10.1007/978-3-319-21786-4_4", "date": "2015", "authors": [{"name": "Huiyuan Zhang", "id-internal": "34/9800", "id-external": ""}, {"name": "Huiling Zhang", "id-internal": "147/8989", "id-external": ""}, {"name": "Xiang Li 0016", "id-internal": "40/1491-16", "id-external": ""}, {"name": "My T. Thai", "id-internal": "63/4711", "id-external": ""}], "url": {"full": "URL#2210043", "pdf": ""}, "publisher-venue": "CSoNet", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3730775319, "title": "Monitor placement to timely detect misinformation in Online Social Networks.", "abstract": "", "doi": "10.1109/icc.2015.7248478", "date": "2015", "authors": [{"name": "Huiling Zhang", "id-internal": "147/8989", "id-external": ""}, {"name": "Md Abdul Alim", "id-internal": "12/10415", "id-external": ""}, {"name": "My T. Thai", "id-internal": "63/4711", "id-external": ""}, {"name": "Hien T. Nguyen", "id-internal": "25/5671", "id-external": ""}], "url": {"full": "URL#2245068", "pdf": ""}, "publisher-venue": "ICC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3869986030, "title": "(Not) Welcome to the US - Hyper-Ebola and the Crisis of Misinformation.", "abstract": "", "doi": "", "date": "2015", "authors": [{"name": "Natalie D. Baker", "id-internal": "183/7556", "id-external": ""}, {"name": "Spyridon Samonas", "id-internal": "172/7188", "id-external": ""}, {"name": "Kristine Artello", "id-internal": "183/7476", "id-external": ""}], "url": {"full": "URL#2278400", "pdf": ""}, "publisher-venue": "ISCRAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3545927053, "title": "Why Do Social Media Users Share Misinformation?", "abstract": "", "doi": "10.1145/2756406.2756941", "date": "2015", "authors": [{"name": "Xinran Chen", "id-internal": "163/7043", "id-external": ""}, {"name": "Sei-Ching Joanna Sin", "id-internal": "68/9553", "id-external": ""}, {"name": "Yin-Leng Theng", "id-internal": "78/4473", "id-external": ""}, {"name": "Chei Sian Lee", "id-internal": "96/2775", "id-external": ""}], "url": {"full": "URL#2286509", "pdf": ""}, "publisher-venue": "JCDL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1249451918, "title": "A Model for Identifying Misinformation in Online Social Networks.", "abstract": "", "doi": "10.1007/978-3-319-26148-5_32", "date": "2015", "authors": [{"name": "Sotirios Antoniadis", "id-internal": "169/8472", "id-external": ""}, {"name": "Iouliana Litou", "id-internal": "135/6871", "id-external": ""}, {"name": "Vana Kalogeraki", "id-internal": "k/VanaKalogeraki", "id-external": ""}], "url": {"full": "URL#2301981", "pdf": ""}, "publisher-venue": "OTM Conferences", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1735607228, "title": "A Double Pulse Control Strategy for Misinformation Propagation in Human Mobile Opportunistic Networks.", "abstract": "", "doi": "10.1007/978-3-319-21837-3_56", "date": "2015", "authors": [{"name": "Xiaoming Wang 0001", "id-internal": "60/2139-1", "id-external": ""}, {"name": "Yaguang Lin", "id-internal": "166/1923", "id-external": ""}, {"name": "Lichen Zhang 0001", "id-internal": "00/6357-1", "id-external": ""}, {"name": "Zhipeng Cai 0001", "id-internal": "14/5155-1", "id-external": ""}], "url": {"full": "URL#2328757", "pdf": ""}, "publisher-venue": "WASA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1734174590, "title": "Fake and Spam Messages - Detecting Misinformation During Natural Disasters on Social Media.", "abstract": "", "doi": "10.1109/wi-iat.2015.102", "date": "2015", "authors": [{"name": "Meet Rajdev", "id-internal": "175/5279", "id-external": ""}, {"name": "Kyumin Le", "id-internal": "175/5488", "id-external": ""}], "url": {"full": "URL#2330255", "pdf": ""}, "publisher-venue": "WI-IAT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1271439186, "title": "Viral Misinformation - The Role of Homophily and Polarization.", "abstract": "", "doi": "10.1145/2740908.2745939", "date": "2015", "authors": [{"name": "Alessandro Bessi", "id-internal": "150/6292", "id-external": ""}, {"name": "Fabio Petroni", "id-internal": "118/5349", "id-external": ""}, {"name": "Michela Del Vicario", "id-internal": "151/6677", "id-external": ""}, {"name": "Fabiana Zollo", "id-internal": "60/9927", "id-external": ""}, {"name": "Aris Anagnostopoulos", "id-internal": "54/3951", "id-external": ""}, {"name": "Antonio Scala", "id-internal": "92/9669", "id-external": ""}, {"name": "Guido Caldarelli", "id-internal": "50/6478", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}], "url": {"full": "URL#2333282", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3430084319, "title": "Fact-checking Effect on Viral Hoaxes - A Model of Misinformation Spread in Social Networks.", "abstract": "", "doi": "10.1145/2740908.2742572", "date": "2015", "authors": [{"name": "Marcella Tambuscio", "id-internal": "162/8994", "id-external": ""}, {"name": "Giancarlo Ruffo", "id-internal": "05/4635", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}], "url": {"full": "URL#2333639", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2437917979, "title": "Trend of Narratives in the Age of Misinformation.", "abstract": "", "doi": "", "date": "2015", "authors": [{"name": "Alessandro Bessi", "id-internal": "150/6292", "id-external": ""}, {"name": "Fabiana Zollo", "id-internal": "60/9927", "id-external": ""}, {"name": "Michela Del Vicario", "id-internal": "151/6677", "id-external": ""}, {"name": "Antonio Scala", "id-internal": "92/9669", "id-external": ""}, {"name": "Guido Caldarelli", "id-internal": "50/6478", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}], "url": {"full": "URL#2341809", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3573810527, "title": "Echo chambers in the age of misinformation.", "abstract": "", "doi": "", "date": "2015", "authors": [{"name": "Michela Del Vicario", "id-internal": "151/6677", "id-external": ""}, {"name": "Alessandro Bessi", "id-internal": "150/6292", "id-external": ""}, {"name": "Fabiana Zollo", "id-internal": "60/9927", "id-external": ""}, {"name": "Fabio Petroni", "id-internal": "118/5349", "id-external": ""}, {"name": "Antonio Scala", "id-internal": "92/9669", "id-external": ""}, {"name": "Guido Caldarelli", "id-internal": "50/6478", "id-external": ""}, {"name": "Harry Eugene Stanley", "id-internal": "24/5927", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}], "url": {"full": "URL#2356031", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2169476701, "title": "Emotional Dynamics in the Age of Misinformation.", "abstract": "", "doi": "", "date": "2015", "authors": [{"name": "Fabiana Zollo", "id-internal": "60/9927", "id-external": ""}, {"name": "Petra Kralj Novak", "id-internal": "40/887", "id-external": ""}, {"name": "Michela Del Vicario", "id-internal": "151/6677", "id-external": ""}, {"name": "Alessandro Bessi", "id-internal": "150/6292", "id-external": ""}, {"name": "Igor Mozetic", "id-internal": "55/2842", "id-external": ""}, {"name": "Antonio Scala", "id-internal": "92/9669", "id-external": ""}, {"name": "Guido Caldarelli", "id-internal": "50/6478", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}], "url": {"full": "URL#2358064", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 56493057, "title": "Misinformation Propagation in the Age of Twitter.", "abstract": "", "doi": "10.1109/mc.2014.361", "date": "2014", "authors": [{"name": "Fang Jin", "id-internal": "22/6323", "id-external": ""}, {"name": "Wei Wang 0064", "id-internal": "35/7092-64", "id-external": ""}, {"name": "Liang Zhao 0002", "id-internal": "63/5422-2", "id-external": ""}, {"name": "Edward R. Dougherty", "id-internal": "90/3909", "id-external": ""}, {"name": "Yang Cao 0001", "id-internal": "25/7045-1", "id-external": ""}, {"name": "Chang-Tien Lu", "id-internal": "08/4367", "id-external": ""}, {"name": "Naren Ramakrishnan", "id-internal": "r/NarenRamakrishnan", "id-external": ""}], "url": {"full": "URL#2382626", "pdf": ""}, "publisher-venue": "Computer", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1984931640, "title": "Detecting misinformation in online social networks using cognitive psychology.", "abstract": "", "doi": "10.1186/s13673-014-0014-x", "date": "2014", "authors": [{"name": "K. P. Krishna Kumar", "id-internal": "95/537", "id-external": ""}, {"name": "G. Geethakumari", "id-internal": "27/5376", "id-external": ""}], "url": {"full": "URL#2395463", "pdf": ""}, "publisher-venue": "Hum. centric Comput. Inf. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1563550463, "title": "The jenny mccarthy conundrum - Public libraries, popular culture, and health misinformation.", "abstract": "", "doi": "10.1002/meet.2014.14505101102", "date": "2014", "authors": [{"name": "Mary Grace Flaherty", "id-internal": "70/9168", "id-external": ""}, {"name": "Elnora Kelly Tayag", "id-internal": "224/5656", "id-external": ""}, {"name": "Meaghan Lanier", "id-internal": "224/5424", "id-external": ""}, {"name": "Jennie Minor", "id-internal": "224/5430", "id-external": ""}], "url": {"full": "URL#2481314", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4045860883, "title": "Optimal Containment of Misinformation in Social Media - A Scenario-Based Approach.", "abstract": "", "doi": "10.1007/978-3-319-12691-3_40", "date": "2014", "authors": [{"name": "Yongjia Song", "id-internal": "139/2673", "id-external": ""}, {"name": "Thang N. Dinh", "id-internal": "54/7220", "id-external": ""}], "url": {"full": "URL#2496605", "pdf": ""}, "publisher-venue": "COCOA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3660891571, "title": "Some Aggregation Operators of General Misinformation.", "abstract": "", "doi": "10.1007/978-3-319-08852-5_57", "date": "2014", "authors": [{"name": "Doretta Vivona", "id-internal": "33/2734", "id-external": ""}, {"name": "Maria Divari", "id-internal": "13/5774", "id-external": ""}], "url": {"full": "URL#2563538", "pdf": ""}, "publisher-venue": "IPMU", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1629332688, "title": "Containment of Misinformation Propagation in Online Social Networks with given Deadline.", "abstract": "", "doi": "", "date": "2014", "authors": [{"name": "Nan Wang", "id-internal": "84/864", "id-external": ""}, {"name": "Li Yu 0002", "id-internal": "70/5913-2", "id-external": ""}, {"name": "Ni Ding", "id-internal": "120/6996", "id-external": ""}, {"name": "Dong Yang", "id-internal": "33/412", "id-external": ""}], "url": {"full": "URL#2590896", "pdf": ""}, "publisher-venue": "PACIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 781502823, "title": "Identifying Sources of Misinformation in Online Social Networks.", "abstract": "", "doi": "10.1007/978-3-319-04960-1_37", "date": "2014", "authors": [{"name": "K. P. Krishna Kumar", "id-internal": "95/537", "id-external": ""}, {"name": "G. Geethakumari", "id-internal": "27/5376", "id-external": ""}], "url": {"full": "URL#2604042", "pdf": ""}, "publisher-venue": "SIRS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 815740384, "title": "Social spam, campaigns, misinformation and crowdturfing.", "abstract": "", "doi": "10.1145/2567948.2577270", "date": "2014", "authors": [{"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}, {"name": "James Caverlee", "id-internal": "55/3697", "id-external": ""}, {"name": "Calton Pu", "id-internal": "p/CaltonPu", "id-external": ""}], "url": {"full": "URL#2621151", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2592653000, "title": "Misinformation in Social Networks, Analyzing Twitter During Crisis Events.", "abstract": "", "doi": "10.1007/978-1-4614-6170-8_296", "date": "2014", "authors": [{"name": "Aditi Gupta 0003", "id-internal": "51/4962-3", "id-external": ""}, {"name": "Ponnurangam Kumaraguru", "id-internal": "97/5147", "id-external": ""}], "url": {"full": "URL#2628377", "pdf": ""}, "publisher-venue": "Encyclopedia of Social Network Analysis and Mining", "type": "Reference Works", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1427758199, "title": "Misinformation.", "abstract": "", "doi": "10.1007/978-1-4614-6170-8_100124", "date": "2014", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "URL#2628863", "pdf": ""}, "publisher-venue": "Encyclopedia of Social Network Analysis and Mining", "type": "Reference Works", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2532436066, "title": "Viral Misinformation - The Role of Homophily and Polarization.", "abstract": "", "doi": "", "date": "2014", "authors": [{"name": "Aris Anagnostopoulos", "id-internal": "54/3951", "id-external": ""}, {"name": "Alessandro Bessi", "id-internal": "150/6292", "id-external": ""}, {"name": "Guido Caldarelli", "id-internal": "50/6478", "id-external": ""}, {"name": "Michela Del Vicario", "id-internal": "151/6677", "id-external": ""}, {"name": "Fabio Petroni", "id-internal": "118/5349", "id-external": ""}, {"name": "Antonio Scala", "id-internal": "92/9669", "id-external": ""}, {"name": "Fabiana Zollo", "id-internal": "60/9927", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}], "url": {"full": "URL#2630700", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1917589839, "title": "Analysis of misinformation containment in online social networks.", "abstract": "", "doi": "10.1016/j.comnet.2013.04.002", "date": "2013", "authors": [{"name": "Nam P. Nguyen", "id-internal": "71/8966", "id-external": ""}, {"name": "Guanhua Yan", "id-internal": "13/4177", "id-external": ""}, {"name": "My T. Thai", "id-internal": "63/4711", "id-external": ""}], "url": {"full": "URL#2666850", "pdf": ""}, "publisher-venue": "Comput. Networks", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4094128356, "title": "A social diffusion model of misinformation and disinformation for understanding human information behaviour.", "abstract": "", "doi": "", "date": "2013", "authors": [{"name": "Natascha Karlova", "id-internal": "36/10874", "id-external": ""}, {"name": "Karen E. Fisher", "id-internal": "09/7025", "id-external": ""}], "url": {"full": "URL#2696782", "pdf": ""}, "publisher-venue": "Inf. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 432077979, "title": "Information diffusion model for spread of misinformation in online social networks.", "abstract": "", "doi": "10.1109/icacci.2013.6637343", "date": "2013", "authors": [{"name": "K. P. Krishna Kumar", "id-internal": "95/537", "id-external": ""}, {"name": "G. Geethakumari", "id-internal": "27/5376", "id-external": ""}], "url": {"full": "URL#2813333", "pdf": ""}, "publisher-venue": "ICACCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2496320827, "title": "Dispelling Myths and Misinformation Using Social Media - A Three-Countries Comparison Using the Case of Tuberculosis.", "abstract": "", "doi": "10.1109/ichi.2013.34", "date": "2013", "authors": [{"name": "Yin-Leng Theng", "id-internal": "78/4473", "id-external": ""}, {"name": "Lynette Ying Qin Goh", "id-internal": "91/11104", "id-external": ""}, {"name": "May O. Lwin", "id-internal": "84/9112", "id-external": ""}, {"name": "Schubert Shou-Boon Foo", "id-internal": "f/SchubertFoo", "id-external": ""}], "url": {"full": "URL#2824065", "pdf": ""}, "publisher-venue": "ICHI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3637387890, "title": "Stock Market Manipulation Using Cyberattacks Together with Misinformation Disseminated through Social Media.", "abstract": "", "doi": "10.1109/socialcom.2013.149", "date": "2013", "authors": {"name": "Matti Mantere", "id-internal": "81/8192", "id-external": ""}, "url": {"full": "URL#2886557", "pdf": ""}, "publisher-venue": "SocialCom", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2334961335, "title": "The Impact of Analyst-Induced Misinformation on the Requirements Elicitation Process.", "abstract": "", "doi": "", "date": "2012", "authors": [{"name": "Radha Appan", "id-internal": "60/97", "id-external": ""}, {"name": "Glenn J. Browne", "id-internal": "80/2255", "id-external": ""}], "url": {"full": "URL#2989784", "pdf": ""}, "publisher-venue": "MIS Q.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2248564338, "title": "Expert Finding for Microblog Misinformation Identification.", "abstract": "", "doi": "", "date": "2012", "authors": [{"name": "Chen Liang", "id-internal": "35/3221", "id-external": ""}, {"name": "Zhiyuan Liu 0001", "id-internal": "53/3245-1", "id-external": ""}, {"name": "Maosong Sun", "id-internal": "95/3291", "id-external": ""}], "url": {"full": "URL#3049614", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2919206286, "title": "Sources of misinformation in Online Social Networks - Who to suspect?", "abstract": "", "doi": "10.1109/milcom.2012.6415780", "date": "2012", "authors": [{"name": "Dung T. Nguyen 0002", "id-internal": "60/1968-2", "id-external": ""}, {"name": "Nam P. Nguyen", "id-internal": "71/8966", "id-external": ""}, {"name": "My T. Thai", "id-internal": "63/4711", "id-external": ""}], "url": {"full": "URL#3126275", "pdf": ""}, "publisher-venue": "MILCOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1864193472, "title": "Containment of misinformation spread in online social networks.", "abstract": "", "doi": "10.1145/2380718.2380746", "date": "2012", "authors": [{"name": "Nam P. Nguyen", "id-internal": "71/8966", "id-external": ""}, {"name": "Guanhua Yan", "id-internal": "13/4177", "id-external": ""}, {"name": "My T. Thai", "id-internal": "63/4711", "id-external": ""}, {"name": "Stephan J. Eidenbenz", "id-internal": "54/5929", "id-external": ""}], "url": {"full": "URL#3160809", "pdf": ""}, "publisher-venue": "WebSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3837354187, "title": "Analytical model of misinformation of a social network node", "abstract": "", "doi": "", "date": "2012", "authors": [{"name": "Yuri Monakhov", "id-internal": "123/4727", "id-external": ""}, {"name": "Maria Medvednikova", "id-internal": "123/4725", "id-external": ""}, {"name": "Konstantin Abramov", "id-internal": "123/4647", "id-external": ""}, {"name": "Natalia Kostina", "id-internal": "123/4648", "id-external": ""}, {"name": "Roman Malyshev", "id-internal": "123/4690", "id-external": ""}, {"name": "Oleg Makarov", "id-internal": "123/4493", "id-external": ""}, {"name": "Irina B. Semenova", "id-internal": "82/1231", "id-external": ""}], "url": {"full": "URL#3181342", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2385625719, "title": "Stochastic Models of Misinformation Distribution in Online Social Networks", "abstract": "", "doi": "", "date": "2012", "authors": [{"name": "Konstantin Abramov", "id-internal": "123/4647", "id-external": ""}, {"name": "Yuri Monakhov", "id-internal": "123/4727", "id-external": ""}], "url": {"full": "URL#3181418", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3712432562, "title": "Misinformation in Healthcare Social Networks - Contributing Factors.", "abstract": "", "doi": "", "date": "2011", "authors": [{"name": "Victoria Kisekka", "id-internal": "74/10683", "id-external": ""}, {"name": "Raj Sharman", "id-internal": "94/6432", "id-external": ""}, {"name": "Ranjit Singh", "id-internal": "36/1388", "id-external": ""}, {"name": "Gurdev Singh", "id-internal": "29/7867", "id-external": ""}], "url": {"full": "URL#3283499", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 221759558, "title": "Rumor has it - Identifying Misinformation in Microblogs.", "abstract": "", "doi": "", "date": "2011", "authors": [{"name": "Vahed Qazvinian", "id-internal": "38/5620", "id-external": ""}, {"name": "Emily Rosengren", "id-internal": "84/9307", "id-external": ""}, {"name": "Dragomir R. Radev", "id-internal": "r/DragomirRRadev", "id-external": ""}, {"name": "Qiaozhu Mei", "id-internal": "30/5059", "id-external": ""}], "url": {"full": "URL#3314380", "pdf": ""}, "publisher-venue": "EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 620294290, "title": "Limiting the spread of misinformation in social networks.", "abstract": "", "doi": "10.1145/1963405.1963499", "date": "2011", "authors": [{"name": "Ceren Budak", "id-internal": "66/8462", "id-external": ""}, {"name": "Divyakant Agrawal", "id-internal": "a/DivyakantAgrawal", "id-external": ""}, {"name": "Amr El Abbadi", "id-internal": "a/AmrElAbbadi", "id-external": ""}], "url": {"full": "URL#3410539", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3216955120, "title": "Spread of Misinformation in Social Networks", "abstract": "", "doi": "", "date": "2009", "authors": [{"name": "Daron Acemoglu", "id-internal": "20/34", "id-external": ""}, {"name": "Asuman E. Ozdaglar", "id-internal": "35/2875", "id-external": ""}, {"name": "Ali ParandehGheibi", "id-internal": "47/4084", "id-external": ""}], "url": {"full": "URL#3872948", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4156281526, "title": "Bias, Misinformation and the Paradox of Neutrality.", "abstract": "", "doi": "10.28945/441", "date": "2008", "authors": [{"name": "Peter M. Bednar", "id-internal": "36/6233", "id-external": ""}, {"name": "Christine E. Welch", "id-internal": "90/6293", "id-external": ""}], "url": {"full": "URL#3913217", "pdf": ""}, "publisher-venue": "Informing Sci. Int. J. an Emerg. Transdiscipl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1746286722, "title": "Young Women's Misinformation Concerning IT Careers - Exchanging One Negative Image for Another.", "abstract": "", "doi": "10.28945/458", "date": "2007", "authors": [{"name": "Donna M. Grant", "id-internal": "60/6840", "id-external": ""}, {"name": "Linda V. Knight", "id-internal": "84/2440", "id-external": ""}, {"name": "Theresa A. Steinbach", "id-internal": "90/5449", "id-external": ""}], "url": {"full": "URL#4111674", "pdf": ""}, "publisher-venue": "Informing Sci. Int. J. an Emerg. Transdiscipl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 368970203, "title": "Cyberdating - Misinformation and (Dis)trust in Online Interactions.", "abstract": "", "doi": "10.28945/453", "date": "2007", "authors": [{"name": "Hong Wang", "id-internal": "83/5522", "id-external": ""}, {"name": "Xin-An (Lucian) Lu", "id-internal": "130/6372", "id-external": ""}], "url": {"full": "URL#4111685", "pdf": ""}, "publisher-venue": "Informing Sci. Int. J. an Emerg. Transdiscipl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2372993617, "title": "On the Difference or Equality of Information, Misinformation, and Disinformation - A Critical Research Perspective.", "abstract": "", "doi": "10.28945/473", "date": "2006", "authors": {"name": "Bernd Carsten Stahl", "id-internal": "64/687", "id-external": ""}, "url": {"full": "URL#4295842", "pdf": ""}, "publisher-venue": "Informing Sci. Int. J. an Emerg. Transdiscipl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2365784873, "title": "Expert knowledge for non-experts - Inherent and contextual risks of misinformation.", "abstract": "", "doi": "10.1108/14779960580000265", "date": "2005", "authors": {"name": "Anton Vedder", "id-internal": "96/6485", "id-external": ""}, "url": {"full": "URL#4471762", "pdf": ""}, "publisher-venue": "J. Inf. Commun. Ethics Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1178925363, "title": "Email and Misinformation - A South African Case Study.", "abstract": "", "doi": "10.28945/502", "date": "2004", "authors": [{"name": "Laurette Pretorius", "id-internal": "36/5258", "id-external": ""}, {"name": "Andries Barnard", "id-internal": "17/1581", "id-external": ""}], "url": {"full": "URL#4615602", "pdf": ""}, "publisher-venue": "Informing Sci. Int. J. an Emerg. Transdiscipl.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2872586481, "title": "Building a Misinformation Ontology.", "abstract": "", "doi": "10.1109/wi.2004.37", "date": "2004", "authors": [{"name": "Lina Zhou", "id-internal": "82/1412", "id-external": ""}, {"name": "Dongsong Zhang", "id-internal": "73/3867", "id-external": ""}], "url": {"full": "URL#4718935", "pdf": ""}, "publisher-venue": "Web Intelligence", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1742404739, "title": "E-epistemology and misinformation.", "abstract": "", "doi": "10.1145/769800.769829", "date": "2003", "authors": {"name": "Peter G. Neumann", "id-internal": "n/PeterGNeumann", "id-external": ""}, "url": {"full": "URL#4731162", "pdf": ""}, "publisher-venue": "Commun. ACM", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2495587596, "title": "Review of - Mintz, Anne P. (ed.) Web of deception. Misinformation on the Internet. Medford, N.J. - Information Today, Inc. 2002. 275 p. ISBN 0-910965-60-9.", "abstract": "", "doi": "", "date": "2003", "authors": {"name": "Gunnel Hessler", "id-internal": "128/7270", "id-external": ""}, "url": {"full": "URL#4745984", "pdf": ""}, "publisher-venue": "Inf. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3078278326, "title": "Book reviews - The Creation and Persistance of Misinformation in Shared Library Catalogs - Language and Subject Knowledge in a Technical Era.", "abstract": "", "doi": "10.1002/asi.10216", "date": "2003", "authors": {"name": "Shirley J. Lincicum", "id-internal": "99/815", "id-external": ""}, "url": {"full": "URL#4747433", "pdf": ""}, "publisher-venue": "J. Assoc. Inf. Sci. Technol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1003781483, "title": "Book Review - Web of deception - misinformation on the Internet.", "abstract": "", "doi": "10.1177/096100060303500111", "date": "2003", "authors": {"name": "Phil Bradley", "id-internal": "23/180", "id-external": ""}, "url": {"full": "URL#4751077", "pdf": ""}, "publisher-venue": "J. Libr. Inf. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 645516618, "title": "Scholarly misconduct and misinformation on the World Wide Web.", "abstract": "", "doi": "10.1108/eum0000000005747", "date": "2001", "authors": {"name": "Philip James Calvert", "id-internal": "56/810", "id-external": ""}, "url": {"full": "URL#4941170", "pdf": ""}, "publisher-venue": "Electron. Libr.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 608695796, "title": "Information and Misinformation Online - Recommendations for Facilitating Accurate Mental Health Information Retrieval and Evaluation.", "abstract": "", "doi": "10.1089/10949310050191737", "date": "2000", "authors": [{"name": "Janet Morahan-Martin", "id-internal": "28/8836", "id-external": ""}, {"name": "Colleen D. Anderson", "id-internal": "123/1613", "id-external": ""}], "url": {"full": "URL#5019681", "pdf": ""}, "publisher-venue": "Cyberpsychology Behav. Soc. Netw.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2560532636, "title": "Medical misinformation on the Web - mitigation or control?", "abstract": "", "doi": "10.1145/277351.277358", "date": "1998", "authors": {"name": "David B. Resnik", "id-internal": "67/8217", "id-external": ""}, "url": {"full": "URL#5183750", "pdf": ""}, "publisher-venue": "SIGCAS Comput. Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1267585229, "title": "Confusion and misinformation on financial chaos.", "abstract": "", "doi": "10.1002/cplx.6130010309", "date": "1995", "authors": {"name": "Blake LeBaron", "id-internal": "35/1055", "id-external": ""}, "url": {"full": "URL#5337053", "pdf": ""}, "publisher-venue": "Complex.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2313890598, "title": "Can Predominant Credible Information Suppress Misinformation in Crises?\n  Empirical Studies of Tweets Related to Prevention Measures during COVID-19", "abstract": "During COVID-19, misinformation on social media affects the adoption of\nappropriate prevention behaviors. It is urgent to suppress the misinformation\nto prevent negative public health consequences. Although an array of studies\nhas proposed misinformation suppression strategies, few have investigated the\nrole of predominant credible information during crises. None has examined its\neffect quantitatively using longitudinal social media data. Therefore, this\nresearch investigates the temporal correlations between credible information\nand misinformation, and whether predominant credible information can suppress\nmisinformation for two prevention measures (i.e. topics), i.e. wearing masks\nand social distancing using tweets collected from February 15 to June 30, 2020.\nWe trained Support Vector Machine classifiers to retrieve relevant tweets and\nclassify tweets containing credible information and misinformation for each\ntopic. Based on cross-correlation analyses of credible and misinformation time\nseries for both topics, we find that the previously predominant credible\ninformation can lead to the decrease of misinformation (i.e. suppression) with\na time lag. The research findings provide empirical evidence for suppressing\nmisinformation with credible information in complex online environments and\nsuggest practical strategies for future information management during crises\nand emergencies.", "doi": "", "date": "2021-02-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.00976v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 525621240, "title": "Misinformation detection in Luganda-English code-mixed social media text", "abstract": "The increasing occurrence, forms, and negative effects of misinformation on\nsocial media platforms has necessitated more misinformation detection tools.\nCurrently, work is being done addressing COVID-19 misinformation however, there\nare no misinformation detection tools for any of the 40 distinct indigenous\nUgandan languages. This paper addresses this gap by presenting basic language\nresources and a misinformation detection data set based on code-mixed\nLuganda-English messages sourced from the Facebook and Twitter social media\nplatforms. Several machine learning methods are applied on the misinformation\ndetection data set to develop classification models for detecting whether a\ncode-mixed Luganda-English message contains misinformation or not. A 10-fold\ncross validation evaluation of the classification methods in an experimental\nmisinformation detection task shows that a Discriminative Multinomial Naive\nBayes (DMNB) method achieves the highest accuracy and F-measure of 78.19% and\n77.90% respectively. Also, Support Vector Machine and Bagging ensemble\nclassification models achieve comparable results. These results are promising\nsince the machine learning models are based on n-gram features from only the\nmisinformation detection dataset.", "doi": "", "date": "2021-03-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.00124v2", "pdf": ""}, "publisher-venue": "African NLP workshop @EACL 2021", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3431246549, "title": "Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study\n  of COVID-19 Infodemic", "abstract": "The spreading COVID-19 misinformation over social media already draws the\nattention of many researchers. According to Google Scholar, about 26000\nCOVID-19 related misinformation studies have been published to date. Most of\nthese studies focusing on 1) detect and/or 2) analysing the characteristics of\nCOVID-19 related misinformation. However, the study of the social behaviours\nrelated to misinformation is often neglected. In this paper, we introduce a\nfine-grained annotated misinformation tweets dataset including social\nbehaviours annotation (e.g. comment or question to the misinformation). The\ndataset not only allows social behaviours analysis but also suitable for both\nevidence-based or non-evidence-based misinformation classification task. In\naddition, we introduce leave claim out validation in our experiments and\ndemonstrate the misinformation classification performance could be\nsignificantly different when applying to real-world unseen misinformation.", "doi": "", "date": "2021-06-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.11702v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1561896543, "title": "Can WhatsApp Benefit from Debunked Fact-Checked Stories to Reduce\n  Misinformation?", "abstract": "WhatsApp was alleged to be widely used to spread misinformation and\npropaganda during elections in Brazil and India. Due to the private encrypted\nnature of the messages on WhatsApp, it is hard to track the dissemination of\nmisinformation at scale. In this work, using public WhatsApp data, we observe\nthat misinformation has been largely shared on WhatsApp public groups even\nafter they were already fact-checked by popular fact-checking agencies. This\nrepresents a significant portion of misinformation spread in both Brazil and\nIndia in the groups analyzed. We posit that such misinformation content could\nbe prevented if WhatsApp had a means to flag already fact-checked content. To\nthis end, we propose an architecture that could be implemented by WhatsApp to\ncounter such misinformation. Our proposal respects the current end-to-end\nencryption architecture on WhatsApp, thus protecting users' privacy while\nproviding an approach to detect the misinformation that benefits from\nfact-checking efforts.", "doi": "", "date": "2020-06-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.02471v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2777708586, "title": "Towards Domain-Specific Characterization of Misinformation", "abstract": "The rapid dissemination of health misinformation poses an increasing risk to\npublic health. To best understand the way of combating health misinformation,\nit is important to acknowledge how the fundamental characteristics of\nmisinformation differ from domain to domain. This paper presents a pathway\ntowards domain-specific characterization of misinformation so that we can\naddress the concealed behavior of health misinformation compared to others and\ntake proper initiative accordingly for combating it. With this aim, we have\nmentioned several possible approaches to identify discriminating features of\nmedical misinformation from other types of misinformation. Thereafter, we\nbriefly propose a research plan followed by possible challenges to meet up. The\nfindings of the proposed research idea will provide new directions to the\nmisinformation research community.", "doi": "", "date": "2020-07-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.14806v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1113248402, "title": "Human-Misinformation interaction: Understanding the interdisciplinary\n  approach needed to computationally combat false information", "abstract": "The prevalence of new technologies and social media has amplified the effects\nof misinformation on our societies. Thus, it is necessary to create\ncomputational tools to mitigate their effects effectively. This study aims to\nprovide a critical overview of computational approaches concerned with\ncombating misinformation. To this aim, I offer an overview of scholarly\ndefinitions of misinformation. I adopt a framework for studying misinformation\nthat suggests paying attention to the source, content, and consumers as the\nthree main elements involved in the process of misinformation and I provide an\noverview of literature from disciplines of psychology, media studies, and\ncognitive sciences that deal with each of these elements. Using the framework,\nI overview the existing computational methods that deal with 1) misinformation\ndetection and fact-checking using Content 2) Identifying untrustworthy Sources\nand social bots, and 3) Consumer-facing tools and methods aiming to make humans\nresilient to misinformation. I find that the vast majority of works in computer\nscience and information technology is concerned with the crucial tasks of\ndetection and verification of content and sources of misinformation. Moreover,\nI find that computational research focusing on Consumers of Misinformation in\nHuman-Computer Interaction (HCI) and related fields are very sparse and often\ndo not deal with the subtleties of this process. The majority of existing\ninterfaces and systems are less concerned with the usability of the tools\nrather than the robustness and accuracy of the detection methods. Using this\nsurvey, I call for an interdisciplinary approach towards human-misinformation\ninteraction that focuses on building methods and tools that robustly deal with\nsuch complex psychological/social phenomena.", "doi": "", "date": "2019-03-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.07136v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 76680794, "title": "Investigating Misinformation in Online Marketplaces: An Audit Study on\n  Amazon", "abstract": "Search and recommendation systems are ubiquitous and irreplaceable tools in\nour daily lives. Despite their critical role in selecting and ranking the most\nrelevant information, they typically do not consider the veracity of\ninformation presented to the user. In this paper, we introduce an audit\nmethodology to investigate the extent of misinformation presented in search\nresults and recommendations on online marketplaces. We investigate the factors\nand personalization attributes that influence the amount of misinformation in\nsearches and recommendations. Recently, several media reports criticized Amazon\nfor hosting and recommending items that promote misinformation on topics such\nas vaccines. Motivated by those reports, we apply our algorithmic auditing\nmethodology on Amazon to verify those claims. Our audit study investigates (a)\nfactors that might influence the search algorithms of Amazon and (b)\npersonalization attributes that contribute to amplifying the amount of\nmisinformation recommended to users in their search results and\nrecommendations. Our audit study collected ~526k search results and ~182k\nhomepage recommendations, with ~8.5k unique items. Each item is annotated for\nits stance on vaccines' misinformation (pro, neutral, or anti). Our study\nreveals that (1) the selection and ranking by the default Featured search\nalgorithm of search results that have misinformation stances are positively\ncorrelated with the stance of search queries and customers' evaluation of items\n(ratings and reviews), (2) misinformation stances of search results are neither\naffected by users' activities nor by interacting (browsing, wish-listing,\nshopping) with items that have a misinformation stance, and (3) a filter bubble\nbuilt-in users' homepages have a misinformation stance positively correlated\nwith the misinformation stance of items that a user interacts with.", "doi": "", "date": "2020-09-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.12468v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2730503010, "title": "Characterizing and Comparing COVID-19 Misinformation Across Languages,\n  Countries and Platforms", "abstract": "Misinformation/disinformation about COVID-19 has been rampant on social media\naround the world. In this study, we investigate COVID-19 misinformation/\ndisinformation on social media in multiple languages - Farsi (Persian),\nChinese, and English, about multiple countries - Iran, China, and the United\nStates (US), and on multiple platforms such as Twitter, Facebook, Instagram,\nWeibo, and WhatsApp. Misinformation, especially about a global pandemic, is a\nglobal problem yet it is common for studies of COVID-19 misinformation on\nsocial media to focus on a single language, like English, a single country,\nlike the US, or a single platform, like Twitter. We utilized opportunistic\nsampling to compile 200 specific items of viral and yet debunked misinformation\nacross these languages, countries and platforms emerged between January 1 and\nAugust 31. We then categorized this collection based both on the topics of the\nmisinformation and the underlying roots of that misinformation. Our\nmulti-cultural and multilingual team observed that the nature of COVID-19\nmisinformation on social media varied in substantial ways across different\nlanguages/countries depending on the cultures, beliefs/religions, popularity of\nsocial media, types of platforms, freedom of speech and the power of people\nversus governments. We observe that politics is at the root of most of the\ncollected misinformation across all three languages in this dataset. We further\nobserve the different impact of government restrictions on platforms and\nplatform restrictions on content in Iran, China, and the US and their impact on\na key question of our age: how do we control misinformation without silencing\nthe voices we need to hold governments accountable?", "doi": "", "date": "2020-10-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.06455v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3317822930, "title": "Using an Epidemiological Model to Study the Spread of Misinformation\n  during the Black Lives Matter Movement", "abstract": "The proliferation of social media platforms like Twitter has heightened the\nconsequences of the spread of misinformation. To understand and model the\nspread of misinformation, in this paper, we leveraged the SEIZ (Susceptible,\nExposed, Infected, Skeptics) epidemiological model to describe the underlying\nprocess that delineates the spread of misinformation on Twitter. Compared to\nthe other epidemiological models, this model produces broader results because\nit includes the additional Skeptics (Z) compartment, wherein a user may be\nexposed to an item of misinformation but not engage in any reaction to it, and\nthe additional Exposed (E) compartment, wherein the user may need some time\nbefore deciding to spread a misinformation item. We analyzed misinformation\nregarding the unrest in Washington, D.C. in the month of March 2020 which was\npropagated by the use of the #DCblackout hashtag by different users across the\nU.S. on Twitter. Our analysis shows that misinformation can be modeled using\nthe concept of epidemiology. To the best of our knowledge, this research is the\nfirst to attempt to apply the SEIZ epidemiological model to the spread of a\nspecific item of misinformation, which is a category distinct from that of\nrumor, and a hoax on online social media platforms. Applying a mathematical\nmodel can help to understand the trends and dynamics of the spread of\nmisinformation on Twitter and ultimately help to develop techniques to quickly\nidentify and control it.", "doi": "", "date": "2021-03-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.12191v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1429833741, "title": "COVID-19 Vaccines: Characterizing Misinformation Campaigns and Vaccine\n  Hesitancy on Twitter", "abstract": "Vaccine hesitancy and misinformation on social media has increased concerns\nabout COVID-19 vaccine uptake required to achieve herd immunity and overcome\nthe pandemic. However anti-science and political misinformation and\nconspiracies have been rampant throughout the pandemic. For COVID-19 vaccines,\nwe investigate misinformation and conspiracy campaigns and their characteristic\nbehaviours. We identify whether coordinated efforts are used to promote\nmisinformation in vaccine related discussions, and find accounts coordinately\npromoting a `Great Reset' conspiracy group promoting vaccine related\nmisinformation and strong anti-vaccine and anti-social messages such as boycott\nvaccine passports, no lock-downs and masks. We characterize other\nmisinformation communities from the information diffusion structure, and study\nthe large anti-vaccine misinformation community and smaller anti-vaccine\ncommunities, including a far-right anti-vaccine conspiracy group. In comparison\nwith the mainstream and health news, left-leaning group, which are more\npro-vaccine, the right-leaning group is influenced more by the anti-vaccine and\nfar-right misinformation/conspiracy communities. The misinformation communities\nare more vocal either specific to the vaccine discussion or political\ndiscussion, and we find other differences in the characteristic behaviours of\ndifferent communities. Lastly, we investigate misinformation narratives and\ntactics of information distortion that can increase vaccine hesitancy, using\ntopic modeling and comparison with reported vaccine side-effects (VAERS)\nfinding rarer side-effects are more frequently discussed on social media.", "doi": "", "date": "2021-06-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.08423v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4185610801, "title": "Analysing the Effect of Recommendation Algorithms on the Amplification\n  of Misinformation", "abstract": "Recommendation algorithms have been pointed out as one of the major culprits\nof misinformation spreading in the digital sphere. However, it is still unclear\nhow these algorithms really propagate misinformation, e.g., it has not been\nshown which particular recommendation approaches are more prone to suggest\nmisinforming items, or which internal parameters of the algorithms could be\ninfluencing more on their misinformation propagation capacity.\n  Motivated by this fact, in this paper we present an analysis of the effect of\nsome of the most popular recommendation algorithms on the spread of\nmisinformation in Twitter. A set of guidelines on how to adapt these algorithms\nis provided based on such analysis and a comprehensive review of the research\nliterature. A dataset is also generated and released to the scientific\ncommunity to stimulate discussions on the future design and development of\nrecommendation algorithms to counter misinformation. The dataset includes\neditorially labelled news items and claims regarding their misinformation\nnature.", "doi": "", "date": "2021-03-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.14748v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1876740406, "title": "Misinformation Detection on YouTube Using Video Captions", "abstract": "Millions of people use platforms such as YouTube, Facebook, Twitter, and\nother mass media. Due to the accessibility of these platforms, they are often\nused to establish a narrative, conduct propaganda, and disseminate\nmisinformation. This work proposes an approach that uses state-of-the-art NLP\ntechniques to extract features from video captions (subtitles). To evaluate our\napproach, we utilize a publicly accessible and labeled dataset for classifying\nvideos as misinformation or not. The motivation behind exploring video captions\nstems from our analysis of videos metadata. Attributes such as the number of\nviews, likes, dislikes, and comments are ineffective as videos are hard to\ndifferentiate using this information. Using caption dataset, the proposed\nmodels can classify videos among three classes (Misinformation, Debunking\nMisinformation, and Neutral) with 0.85 to 0.90 F1-score. To emphasize the\nrelevance of the misinformation class, we re-formulate our classification\nproblem as a two-class classification - Misinformation vs. others (Debunking\nMisinformation and Neutral). In our experiments, the proposed models can\nclassify videos with 0.92 to 0.95 F1-score and 0.78 to 0.90 AUC ROC.", "doi": "", "date": "2021-07-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.00941v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3094827259, "title": "On Unifying Misinformation Detection", "abstract": "In this paper, we introduce UnifiedM2, a general-purpose misinformation model\nthat jointly models multiple domains of misinformation with a single, unified\nsetup. The model is trained to handle four tasks: detecting news bias,\nclickbait, fake news, and verifying rumors. By grouping these tasks together,\nUnifiedM2learns a richer representation of misinformation, which leads to\nstate-of-the-art or comparable performance across all tasks. Furthermore, we\ndemonstrate that UnifiedM2's learned representation is helpful for few-shot\nlearning of unseen misinformation tasks/datasets and model's generalizability\nto unseen events.", "doi": "", "date": "2021-04-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.05243v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1879367871, "title": "Misinformation spreading on correlated multiplex networks", "abstract": "The numerous expanding online social networks offer fast channels for\nmisinformation spreading, which could have a serious impact on socioeconomic\nsystems. Researchers across multiple areas have paid attention to this issue\nwith a view of addressing it. However, no systematical theoretical study has\nbeen performed to date on observing misinformation spreading on correlated\nmultiplex networks. In this study, we propose a multiplex network-based\nmisinformation spreading model, considering the fact that each individual can\nobtain misinformation from multiple platforms. Subsequently, we develop a\nheterogeneous edge-base compartmental theory to comprehend the spreading\ndynamics of our proposed model. In addition, we establish an analytical method\nbased on stability analysis to obtain the misinformation outbreak threshold. On\nthe basis of these theories, we finally analyze the influence of different\ndynamical and structural parameters on the misinformation spreading dynamics.\nResults show that the misinformation outbreak size $R(\\infty)$ grows\ncontinuously with the effective transmission probability $\\beta$ once $\\beta$\nexceeds a certain value, that is, the outbreak threshold $\\beta_c$. A large\naverage degrees, strong degree heterogeneity, or positive inter-layer\ncorrelation will reduce $\\beta_c$, accelerating the outbreak of misinformation.\nBesides, increasing the degree heterogeneity or a more positive inter-layer\ncorrelation will both enlarge (reduce) $R(\\infty)$ for small (large) values of\n$\\beta$. Our systematic theoretical analysis results agree well with the\nnumerical simulation results. Our proposed model and accurate theoretical\nanalysis will serve as a useful framework to understand and predict the\nspreading dynamics of misinformation on multiplex networks, and thereby pave\nthe way to address this serious issue.", "doi": "10.1063/1.5121394", "date": "2019-09-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.00397v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3865039930, "title": "Characterizing COVID-19 Misinformation Communities Using a Novel Twitter\n  Dataset", "abstract": "From conspiracy theories to fake cures and fake treatments, COVID-19 has\nbecome a hot-bed for the spread of misinformation online. It is more important\nthan ever to identify methods to debunk and correct false information online.\nIn this paper, we present a methodology and analyses to characterize the two\ncompeting COVID-19 misinformation communities online: (i) misinformed users or\nusers who are actively posting misinformation, and (ii) informed users or users\nwho are actively spreading true information, or calling out misinformation. The\ngoals of this study are two-fold: (i) collecting a diverse set of annotated\nCOVID-19 Twitter dataset that can be used by the research community to conduct\nmeaningful analysis; and (ii) characterizing the two target communities in\nterms of their network structure, linguistic patterns, and their membership in\nother communities. Our analyses show that COVID-19 misinformed communities are\ndenser, and more organized than informed communities, with a possibility of a\nhigh volume of the misinformation being part of disinformation campaigns. Our\nanalyses also suggest that a large majority of misinformed users may be\nanti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19\ninformed users tend to use more narratives than misinformed users.", "doi": "", "date": "2020-08-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.00791v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 776382815, "title": "Predicting Misinformation and Engagement in COVID-19 Twitter Discourse\n  in the First Months of the Outbreak", "abstract": "Disinformation entails the purposeful dissemination of falsehoods towards a\ngreater dubious agenda and the chaotic fracturing of a society. The general\npublic has grown aware of the misuse of social media towards these nefarious\nends, where even global public health crises have not been immune to\nmisinformation (deceptive content spread without intended malice). In this\npaper, we examine nearly 505K COVID-19-related tweets from the initial months\nof the pandemic to understand misinformation as a function of bot-behavior and\nengagement. Using a correlation-based feature selection method, we selected the\n11 most relevant feature subsets among over 170 features to distinguish\nmisinformation from facts, and to predict highly engaging misinformation tweets\nabout COVID-19. We achieved an average F-score of at least 72\\% with ten\npopular multi-class classifiers, reinforcing the relevance of the selected\nfeatures. We found that (i) real users tweet both facts and misinformation,\nwhile bots tweet proportionally more misinformation; (ii) misinformation tweets\nwere less engaging than facts; (iii) the textual content of a tweet was the\nmost important to distinguish fact from misinformation while (iv) user account\nmetadata and human-like activity were most important to predict high engagement\nin factual and misinformation tweets; and (v) sentiment features were not\nrelevant.", "doi": "", "date": "2020-12-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.02164v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2617509587, "title": "Corrective Information Does Not Necessarily Curb Social Disruption", "abstract": "The spread of misinformation can cause social confusion. The authenticity of\ninformation on a social networking service (SNS) is unknown, and false\ninformation can be easily spread. Consequently, many studies have been\nconducted on methods to control the spread of misinformation on social\nnetworking sites. However, few studies have examined the impact of the spread\nof misinformation and its corrections on society. This study models the impact\nof the reduction of misinformation and the diffusion of corrective information\non social disruption, and it identifies the features of this impact. In this\nstudy, we analyzed misinformation regarding the shortage of toilet paper during\nthe 2020 COVID-19 epidemic, its corrections, and the excessive purchasing\ncaused by this information. First, we analyze the amount of misinformation and\ncorrective information spread on SNS, and we create a regression model to\nestimate the real-world impact of misinformation and its correction. This model\nis used to analyze the change in real-world impact corresponding to the change\nin the diffusion of misinformation and corrective information. Our analysis\nshows that the corrective information was spread to a much greater extent than\nthe misinformation. In addition, our model reveals that the corrective\ninformation was what caused the excessive purchasing behavior. As a result of\nour further analysis, we found that the amount of diffusion of corrective\ninformation required to minimize the impact on the real world depends on the\namount of the diffusion of misinformation.", "doi": "", "date": "2021-01-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.09665v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 337261602, "title": "Automatic Detection of COVID-19 Vaccine Misinformation with Graph Link\n  Prediction", "abstract": "Enormous hope in the efficacy of vaccines became recently a successful\nreality in the fight against the COVID-19 pandemic. However, vaccine hesitancy,\nfueled by exposure to social media misinformation about COVID-19 vaccines\nbecame a major hurdle. Therefore, it is essential to automatically detect where\nmisinformation about COVID-19 vaccines on social media is spread and what kind\nof misinformation is discussed, such that inoculation interventions can be\ndelivered at the right time and in the right place, in addition to\ninterventions designed to address vaccine hesitancy. This paper is addressing\nthe first step in tackling hesitancy against COVID-19 vaccines, namely the\nautomatic detection of known misinformation about the vaccines on Twitter, the\nsocial media platform that has the highest volume of conversations about\nCOVID-19 and its vaccines. We present CoVaxLies, a new dataset of tweets judged\nrelevant to several misinformation targets about COVID-19 vaccines on which a\nnovel method of detecting misinformation was developed. Our method organizes\nCoVaxLies in a Misinformation Knowledge Graph as it casts misinformation\ndetection as a graph link prediction problem. The misinformation detection\nmethod detailed in this paper takes advantage of the link scoring functions\nprovided by several knowledge embedding methods. The experimental results\ndemonstrate the superiority of this method when compared with\nclassification-based methods, widely used currently.", "doi": "", "date": "2021-08-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.02314v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4241674443, "title": "On Misinformation Containment in Online Social Networks", "abstract": "The widespread online misinformation could cause public panic and serious\neconomic damages. The misinformation containment problem aims at limiting the\nspread of misinformation in online social networks by launching competing\ncampaigns. Motivated by realistic scenarios, we present the first analysis of\nthe misinformation containment problem for the case when an arbitrary number of\ncascades are allowed. This paper makes four contributions. First, we provide a\nformal model for multi-cascade diffusion and introduce an important concept\ncalled as cascade priority. Second, we show that the misinformation containment\nproblem cannot be approximated within a factor of\n$\\Omega(2^{\\log^{1-\\epsilon}n^4})$ in polynomial time unless $NP \\subseteq\nDTIME(n^{\\polylog{n}})$. Third, we introduce several types of cascade priority\nthat are frequently seen in real social networks. Finally, we design novel\nalgorithms for solving the misinformation containment problem. The\neffectiveness of the proposed algorithm is supported by encouraging\nexperimental results.", "doi": "", "date": "2018-09-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.06486v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2118209319, "title": "CoAID: COVID-19 Healthcare Misinformation Dataset", "abstract": "As the COVID-19 virus quickly spreads around the world, unfortunately,\nmisinformation related to COVID-19 also gets created and spreads like wild\nfire. Such misinformation has caused confusion among people, disruptions in\nsociety, and even deadly consequences in health problems. To be able to\nunderstand, detect, and mitigate such COVID-19 misinformation, therefore, has\nnot only deep intellectual values but also huge societal impacts. To help\nresearchers combat COVID-19 health misinformation, therefore, we present CoAID\n(Covid-19 heAlthcare mIsinformation Dataset), with diverse COVID-19 healthcare\nmisinformation, including fake news on websites and social platforms, along\nwith users' social engagement about such news. CoAID includes 4,251 news,\n296,000 related user engagements, 926 social platform posts about COVID-19, and\nground truth labels. The dataset is available at:\nhttps://github.com/cuilimeng/CoAID.", "doi": "", "date": "2020-05-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.00885v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2146968747, "title": "Encounters with Visual Misinformation and Labels Across Platforms: An\n  Interview and Diary Study to Inform Ecosystem Approaches to Misinformation\n  Interventions", "abstract": "Since 2016, the amount of academic research with the keyword \"misinformation\"\nhas more than doubled [2]. This research often focuses on article headlines\nshown in artificial testing environments, yet misinformation largely spreads\nthrough images and video posts shared in highly-personalized platform contexts.\nA foundation of qualitative research is necessary to begin filling this gap to\nensure platforms' visual misinformation interventions are aligned with users'\nneeds and understanding of information in their personal contexts, across\nplatforms. In two studies, we combined in-depth interviews (n=15) with diary\nand co-design methods (n=23) to investigate how a broad mix of Americans\nexposed to misinformation during COVID-19 understand their visual information\nenvironments, including encounters with interventions such as Facebook\nfact-checking labels. Analysis reveals a deep division in user attitudes about\nplatform labeling interventions for visual information which are perceived by\nmany as overly paternalistic, biased, and punitive. Alongside these findings,\nwe discuss our methods as a model for continued independent qualitative\nresearch on cross-platform user experiences of misinformation that inform\ninterventions.", "doi": "", "date": "2020-11-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.12758v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 848647816, "title": "Eating Garlic Prevents COVID-19 Infection: Detecting Misinformation on\n  the Arabic Content of Twitter", "abstract": "The rapid growth of social media content during the current pandemic provides\nuseful tools for disseminating information which has also become a root for\nmisinformation. Therefore, there is an urgent need for fact-checking and\neffective techniques for detecting misinformation in social media. In this\nwork, we study the misinformation in the Arabic content of Twitter. We\nconstruct a large Arabic dataset related to COVID-19 misinformation and\ngold-annotate the tweets into two categories: misinformation or not. Then, we\napply eight different traditional and deep machine learning models, with\ndifferent features including word embeddings and word frequency. The word\nembedding models (\\textsc{FastText} and word2vec) exploit more than two million\nArabic tweets related to COVID-19. Experiments show that optimizing the area\nunder the curve (AUC) improves the models' performance and the Extreme Gradient\nBoosting (XGBoost) presents the highest accuracy in detecting COVID-19\nmisinformation online.", "doi": "", "date": "2021-01-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.05626v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 167840347, "title": "Vulnerable to Misinformation? Verifi!", "abstract": "We present Verifi2, a visual analytic system to support the investigation of\nmisinformation on social media. On the one hand, social media platforms empower\nindividuals and organizations by democratizing the sharing of information. On\nthe other hand, even well-informed and experienced social media users are\nvulnerable to misinformation. To address the issue, various models and studies\nhave emerged from multiple disciplines to detect and understand the effects of\nmisinformation. However, there is still a lack of intuitive and accessible\ntools that help social media users distinguish misinformation from verified\nnews. In this paper, we present Verifi2, a visual analytic system that uses\nstate-of-the-art computational methods to highlight salient features from text,\nsocial network, and images. By exploring news on a source level through\nmultiple coordinated views in Verifi2, users can interact with the complex\ndimensions that characterize misinformation and contrast how real and\nsuspicious news outlets differ on these dimensions. To evaluate Verifi2, we\nconduct interviews with experts in digital media, journalism, education,\npsychology, and computing who study misinformation. Our interviews show\npromising potential for Verifi2 to serve as an educational tool on\nmisinformation. Furthermore, our interview results highlight the complexity of\nthe problem of combating misinformation and call for more work from the\nvisualization community.", "doi": "", "date": "2018-07-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1807.09739v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3298579215, "title": "Case Study on Detecting COVID-19 Health-Related Misinformation in Social\n  Media", "abstract": "COVID-19 pandemic has generated what public health officials called an\ninfodemic of misinformation. As social distancing and stay-at-home orders came\ninto effect, many turned to social media for socializing. This increase in\nsocial media usage has made it a prime vehicle for the spreading of\nmisinformation. This paper presents a mechanism to detect COVID-19\nhealth-related misinformation in social media following an interdisciplinary\napproach. Leveraging social psychology as a foundation and existing\nmisinformation frameworks, we defined misinformation themes and associated\nkeywords incorporated into the misinformation detection mechanism using applied\nmachine learning techniques. Next, using the Twitter dataset, we explored the\nperformance of the proposed methodology using multiple state-of-the-art machine\nlearning classifiers. Our method shows promising results with at most 78%\naccuracy in classifying health-related misinformation versus true information\nusing uni-gram-based NLP feature generations from tweets and the Decision Tree\nclassifier. We also provide suggestions on alternatives for countering\nmisinformation and ethical consideration for the study.", "doi": "", "date": "2021-06-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.06811v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 109797050, "title": "You are right. I am ALARMED -- But by Climate Change Counter Movement", "abstract": "The world is facing the challenge of climate crisis. Despite the consensus in\nscientific community about anthropogenic global warming, the web is flooded\nwith articles spreading climate misinformation. These articles are carefully\nconstructed by climate change counter movement (cccm) organizations to\ninfluence the narrative around climate change. We revisit the literature on\nclimate misinformation in social sciences and repackage it to introduce in the\ncommunity of NLP. Despite considerable work in detection of fake news, there is\nno misinformation dataset available that is specific to the domain.of climate\nchange. We try to bridge this gap by scraping and releasing articles with known\nclimate change misinformation.", "doi": "", "date": "2020-04-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.14907v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 361471715, "title": "Examining the Global Spread of COVID-19 Misinformation", "abstract": "The global COVID-19 pandemic has led to the online proliferation of health-,\npolitical-, and conspiratorial-based misinformation. Understanding the reach\nand belief in this misinformation is vital to managing this crisis, as well as\nfuture crises. The results from our global survey finds a troubling reach of\nand belief in COVID-related misinformation, as well as a correlation with those\nthat primarily consume news from social media, and, in the United States, a\nstrong correlation with political leaning.", "doi": "", "date": "2020-06-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.08830v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2072666237, "title": "Is this pofma? Analysing public opinion and misinformation in a COVID-19\n  Telegram group chat", "abstract": "We analyse a Singapore-based COVID-19 Telegram group with more than 10,000\nparticipants. First, we study the group's opinion over time, focusing on four\ndimensions: participation, sentiment, topics, and psychological features. We\nfind that engagement peaked when the Ministry of Health raised the disease\nalert level, but this engagement was not sustained. Second, we search for\ngovernment-identified misinformation in the group. We find that\ngovernment-identified misinformation is rare, and that messages discussing\nthese pieces of misinformation express skepticism.", "doi": "10.36190/2020.12", "date": "2020-10-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.10113v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3011025938, "title": "Understanding Health Misinformation Transmission: An Interpretable Deep\n  Learning Approach to Manage Infodemics", "abstract": "Health misinformation on social media devastates physical and mental health,\ninvalidates health gains, and potentially costs lives. Understanding how health\nmisinformation is transmitted is an urgent goal for researchers, social media\nplatforms, health sectors, and policymakers to mitigate those ramifications.\nDeep learning methods have been deployed to predict the spread of\nmisinformation. While achieving the state-of-the-art predictive performance,\ndeep learning methods lack the interpretability due to their blackbox nature.\nTo remedy this gap, this study proposes a novel interpretable deep learning\napproach, Generative Adversarial Network based Piecewise Wide and Attention\nDeep Learning (GAN-PiWAD), to predict health misinformation transmission in\nsocial media. Improving upon state-of-the-art interpretable methods, GAN-PiWAD\ncaptures the interactions among multi-modal data, offers unbiased estimation of\nthe total effect of each feature, and models the dynamic total effect of each\nfeature when its value varies. We select features according to social exchange\ntheory and evaluate GAN-PiWAD on 4,445 misinformation videos. The proposed\napproach outperformed strong benchmarks. Interpretation of GAN-PiWAD indicates\nvideo description, negative video content, and channel credibility are key\nfeatures that drive viral transmission of misinformation. This study\ncontributes to IS with a novel interpretable deep learning method that is\ngeneralizable to understand other human decision factors. Our findings provide\ndirect implications for social media platforms and policymakers to design\nproactive interventions to identify misinformation, control transmissions, and\nmanage infodemics.", "doi": "", "date": "2020-12-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.01076v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 464573038, "title": "The impact of online misinformation on U.S. COVID-19 vaccinations", "abstract": "Widespread uptake of COVID-19 vaccines is necessary to achieve herd immunity.\nHowever, surveys have found concerning numbers of U.S. adults hesitant or\nunwilling to be vaccinated. Online misinformation may play an important role in\nvaccine hesitancy, but we lack a clear picture of the extent to which it will\nimpact vaccination uptake. Here, we study how vaccination rates and vaccine\nhesitancy are associated with levels of online misinformation about vaccines\nshared by 1.6 million Twitter users geolocated at the U.S. state and county\nlevels. We find a negative relationship between misinformation and vaccination\nuptake rates. Online misinformation is also correlated with vaccine hesitancy\nrates taken from survey data. Associations between vaccine outcomes and\nmisinformation remain significant when accounting for political as well as\ndemographic and socioeconomic factors. While vaccine hesitancy is strongly\nassociated with Republican vote share, we observe that the effect of online\nmisinformation on hesitancy is strongest across Democratic rather than\nRepublican counties. These results suggest that addressing online\nmisinformation must be a key component of interventions aimed to maximize the\neffectiveness of vaccination campaigns.", "doi": "", "date": "2021-04-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.10635v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 897197866, "title": "Checkovid: A COVID-19 misinformation detection system on Twitter using\n  network and content mining perspectives", "abstract": "During the COVID-19 pandemic, social media platforms were ideal for\ncommunicating due to social isolation and quarantine. Also, it was the primary\nsource of misinformation dissemination on a large scale, referred to as the\ninfodemic. Therefore, automatic debunking misinformation is a crucial problem.\nTo tackle this problem, we present two COVID-19 related misinformation datasets\non Twitter and propose a misinformation detection system comprising\nnetwork-based and content-based processes based on machine learning algorithms\nand NLP techniques. In the network-based process, we focus on social\nproperties, network characteristics, and users. On the other hand, we classify\nmisinformation using the content of the tweets directly in the content-based\nprocess, which contains text classification models (paragraph-level and\nsentence-level) and similarity models. The evaluation results on the\nnetwork-based process show the best results for the artificial neural network\nmodel with an F1 score of 88.68%. In the content-based process, our novel\nsimilarity models, which obtained an F1 score of 90.26%, show an improvement in\nthe misinformation classification results compared to the network-based models.\nIn addition, in the text classification models, the best result was achieved\nusing the stacking ensemble-learning model by obtaining an F1 score of 95.18%.\nFurthermore, we test our content-based models on the Constraint@AAAI2021\ndataset, and by getting an F1 score of 94.38%, we improve the baseline results.\nFinally, we develop a fact-checking website called Checkovid that uses each\nprocess to detect misinformative and informative claims in the domain of\nCOVID-19 from different perspectives.", "doi": "", "date": "2021-07-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.09768v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 217409772, "title": "Analysis of misinformation during the COVID-19 outbreak in China:\n  cultural, social and political entanglements", "abstract": "COVID-19 resulted in an infodemic, which could erode public trust, impede\nvirus containment, and outlive the pandemic itself. The evolving and fragmented\nmedia landscape is a key driver of the spread of misinformation. Using\nmisinformation identified by the fact-checking platform by Tencent and posts on\nWeibo, our results showed that the evolution of misinformation follows an\nissue-attention cycle, pertaining to topics such as city lockdown, cures, and\npreventions, and school reopening. Sources of authority weigh in on these\ntopics, but their influence is complicated by peoples' pre-existing beliefs and\ncultural practices. Finally, social media has a complicated relationship with\nestablished or legacy media systems. Sometimes they reinforce each other, but\nin general, social media may have a topic cycle of its own making. Our findings\nshed light on the distinct characteristics of misinformation during the\nCOVID-19 and offer insights into combating misinformation in China and across\nthe world at large.", "doi": "", "date": "2020-05-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.10414v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 75450097, "title": "Misinformation Has High Perplexity", "abstract": "Debunking misinformation is an important and time-critical task as there\ncould be adverse consequences when misinformation is not quashed promptly.\nHowever, the usual supervised approach to debunking via misinformation\nclassification requires human-annotated data and is not suited to the fast\ntime-frame of newly emerging events such as the COVID-19 outbreak. In this\npaper, we postulate that misinformation itself has higher perplexity compared\nto truthful statements, and propose to leverage the perplexity to debunk false\nclaims in an unsupervised manner. First, we extract reliable evidence from\nscientific and news sources according to sentence similarity to the claims.\nSecond, we prime a language model with the extracted evidence and finally\nevaluate the correctness of given claims based on the perplexity scores at\ndebunking time. We construct two new COVID-19-related test sets, one is\nscientific, and another is political in content, and empirically verify that\nour system performs favorably compared to existing systems. We are releasing\nthese datasets publicly to encourage more research in debunking misinformation\non COVID-19 and other topics.", "doi": "", "date": "2020-06-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.04666v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1623581690, "title": "Attention and misinformation sharing on social media", "abstract": "The behaviour of sharing information on social media should be fulfilled only\nwhen a user is exhibiting attentive behaviour. So that the useful information\ncan be consumed constructively, and misinformation can be identified and\nignored. Attentive behaviour is related to users' cognitive abilities in their\nprocessing of set information. The work described in this paper examines the\nissue of attentive factors that affect users' behaviour when they share\nmisinformation on social media. The research aims to identify the significance\nof prevailing attention factors towards sharing misinformation on social media.\nWe used a closed-ended questionnaire which consisted of a psychometric scale to\nmeasure attention behaviour with participants (n = 112). The regression\nequation results are obtained as: y=(19,533-0,390+e) from a set of regression\nanalyses shows that attention factors have a significant negative correlation\neffect for users to share misinformation on social media. Along with the\nfindings of the analysis results, we propose that attentive factors are\nincorporated into a social media application's future design that could\nintervene in user attention and avoid potential harm caused by the spread of\nmisinformation.", "doi": "", "date": "2020-12-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.12593v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 363891168, "title": "Misinfo Belief Frames: A Case Study on Covid & Climate News", "abstract": "Prior beliefs of readers impact the way in which they project meaning onto\nnews headlines. These beliefs can influence their perception of news\nreliability, as well as their reaction to news, and their likelihood of\nspreading the misinformation through social networks. However, most prior work\nfocuses on fact-checking veracity of news or stylometry rather than measuring\nimpact of misinformation. We propose Misinfo Belief Frames, a formalism for\nunderstanding how readers perceive the reliability of news and the impact of\nmisinformation. We also introduce the Misinfo Belief Frames (MBF) corpus, a\ndataset of 66k inferences over 23.5k headlines. Misinformation frames use\ncommonsense reasoning to uncover implications of real and fake news headlines\nfocused on global crises: the Covid-19 pandemic and climate change. Our results\nusing large-scale language modeling to predict misinformation frames show that\nmachine-generated inferences can influence readers' trust in news headlines\n(readers' trust in news headlines was affected in 29.3% of cases). This\ndemonstrates the potential effectiveness of using generated frames to counter\nmisinformation.", "doi": "", "date": "2021-04-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.08790v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1800948933, "title": "Looking for COVID-19 misinformation in multilingual social media texts", "abstract": "This paper presents the Multilingual COVID-19 Analysis Method (CMTA) for\ndetecting and observing the spread of misinformation about this disease within\ntexts. CMTA proposes a data science (DS) pipeline that applies machine learning\nmodels for processing, classifying (Dense-CNN) and analyzing (MBERT)\nmultilingual (micro)-texts. DS pipeline data preparation tasks extract features\nfrom multilingual textual data and categorize it into specific information\nclasses (i.e., 'false', 'partly false', 'misleading'). The CMTA pipeline has\nbeen experimented with multilingual micro-texts (tweets), showing\nmisinformation spread across different languages. To assess the performance of\nCMTA and put it in perspective, we performed a comparative analysis of CMTA\nwith eight monolingual models used for detecting misinformation. The comparison\nshows that CMTA has surpassed various monolingual models and suggests that it\ncan be used as a general method for detecting misinformation in multilingual\nmicro-texts. CMTA experimental results show misinformation trends about\nCOVID-19 in different languages during the first pandemic months.", "doi": "", "date": "2021-05-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.03313v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2765496514, "title": "Defending Democracy: Using Deep Learning to Identify and Prevent\n  Misinformation", "abstract": "The rise in online misinformation in recent years threatens democracies by\ndistorting authentic public discourse and causing confusion, fear, and even, in\nextreme cases, violence. There is a need to understand the spread of false\ncontent through online networks for developing interventions that disrupt\nmisinformation before it achieves virality. Using a Deep Bidirectional\nTransformer for Language Understanding (BERT) and propagation graphs, this\nstudy classifies and visualizes the spread of misinformation on a social media\nnetwork using publicly available Twitter data. The results confirm prior\nresearch around user clusters and the virality of false content while improving\nthe precision of deep learning models for misinformation detection. The study\nfurther demonstrates the suitability of BERT for providing a scalable model for\nfalse information detection, which can contribute to the development of more\ntimely and accurate interventions to slow the spread of misinformation in\nonline environments.", "doi": "", "date": "2021-06-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.02607v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1587818392, "title": "Learning to Detect Few-Shot-Few-Clue Misinformation", "abstract": "The quality of digital information on the web has been disquieting due to the\nlack of careful manual review. Consequently, a large volume of false textual\ninformation has been disseminating for a long time since the prevalence of\nsocial media. The potential negative influence of misinformation on the public\nis a growing concern. Therefore, it is strongly motivated to detect online\nmisinformation as early as possible. Few-shot-few-clue learning applies in this\nmisinformation detection task when the number of annotated statements is quite\nfew (called few shots) and the corresponding evidence is also quite limited in\neach shot (called few clues). Within the few-shot-few-clue framework, we\npropose a Bayesian meta-learning algorithm to extract the shared patterns among\ndifferent topics (i.e.different tasks) of misinformation. Moreover, we derive a\nscalable method, i.e., amortized variational inference, to optimize the\nBayesian meta-learning algorithm. Empirical results on three benchmark datasets\ndemonstrate the superiority of our algorithm. This work focuses more on\noptimizing parameters than designing detection models, and will generate fresh\ninsights into data-efficient detection of online misinformation at early\nstages.", "doi": "", "date": "2021-08-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.03805v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 380648522, "title": "Mining Significant Microblogs for Misinformation Identification: An\n  Attention-based Approach", "abstract": "With the rapid growth of social media, massive misinformation is also\nspreading widely on social media, such as microblog, and bring negative effects\nto human life. Nowadays, automatic misinformation identification has drawn\nattention from academic and industrial communities. For an event on social\nmedia usually consists of multiple microblogs, current methods are mainly based\non global statistical features. However, information on social media is full of\nnoisy and outliers, which should be alleviated. Moreover, most of microblogs\nabout an event have little contribution to the identification of\nmisinformation, where useful information can be easily overwhelmed by useless\ninformation. Thus, it is important to mine significant microblogs for a\nreliable misinformation identification method. In this paper, we propose an\nAttention-based approach for Identification of Misinformation (AIM). Based on\nthe attention mechanism, AIM can select microblogs with largest attention\nvalues for misinformation identification. The attention mechanism in AIM\ncontains two parts: content attention and dynamic attention. Content attention\nis calculated based textual features of each microblog. Dynamic attention is\nrelated to the time interval between the posting time of a microblog and the\nbeginning of the event. To evaluate AIM, we conduct a series of experiments on\nthe Weibo dataset and the Twitter dataset, and the experimental results show\nthat the proposed AIM model outperforms the state-of-the-art methods.", "doi": "", "date": "2017-06-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1706.06314v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1603573823, "title": "\"Thought I'd Share First\" and Other Conspiracy Theory Tweets from the\n  COVID-19 Infodemic: Exploratory Study", "abstract": "Background: The COVID-19 outbreak has left many people isolated within their\nhomes; these people are turning to social media for news and social connection,\nwhich leaves them vulnerable to believing and sharing misinformation.\nHealth-related misinformation threatens adherence to public health messaging,\nand monitoring its spread on social media is critical to understanding the\nevolution of ideas that have potentially negative public health impacts.\nResults: Analysis using model-labeled data was beneficial for increasing the\nproportion of data matching misinformation indicators. Random forest classifier\nmetrics varied across the four conspiracy theories considered (F1 scores\nbetween 0.347 and 0.857); this performance increased as the given conspiracy\ntheory was more narrowly defined. We showed that misinformation tweets\ndemonstrate more negative sentiment when compared to nonmisinformation tweets\nand that theories evolve over time, incorporating details from unrelated\nconspiracy theories as well as real-world events. Conclusions: Although we\nfocus here on health-related misinformation, this combination of approaches is\nnot specific to public health and is valuable for characterizing misinformation\nin general, which is an important first step in creating targeted messaging to\ncounteract its spread. Initial messaging should aim to preempt generalized\nmisinformation before it becomes widespread, while later messaging will need to\ntarget evolving conspiracy theories and the new facets of each as they become\nincorporated.", "doi": "10.2196/26527", "date": "2020-12-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.07729v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 845690894, "title": "Investigating Misinformation Dissemination on Social Media in Pakistan", "abstract": "Fake news and misinformation are one of the most significant challenges\nbrought about by advances in communication technologies. We chose to research\nthe spread of fake news in Pakistan because of some unfortunate incidents that\ntook place during 2020. These included the downplaying of the severity of the\nCOVID-19 pandemic, and protests by right-wing political movements. We observed\nthat fake news and misinformation contributed significantly to these events and\nespecially affected low-literate and low-income populations. We conducted a\ncross-platform comparison of misinformation on WhatsApp, Twitter and YouTube\nwith a primary focus on messages shared in public WhatsApp groups, and analysed\nthe characteristics of misinformation, techniques used to make is believable,\nand how users respond to it. To the best of our knowledge, this is the first\nattempt to compare misinformation on all three platforms in Pakistan. Data\ncollected over a span of eight months helped us identify fake news and\nmisinformation related to politics, religion and health, among other\ncategories. Common elements which were used by fake news creators in Pakistan\nto make false content seem believable included: appeals to emotion, conspiracy\ntheories, political and religious polarization, incorrect facts and\nimpersonation of credible sources.", "doi": "", "date": "2021-06-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.09338v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3749142344, "title": "The Role of the Crowd in Countering Misinformation: A Case Study of the\n  COVID-19 Infodemic", "abstract": "Fact checking by professionals is viewed as a vital defense in the fight\nagainst misinformation.While fact checking is important and its impact has been\nsignificant, fact checks could have limited visibility and may not reach the\nintended audience, such as those deeply embedded in polarized communities.\nConcerned citizens (i.e., the crowd), who are users of the platforms where\nmisinformation appears, can play a crucial role in disseminating fact-checking\ninformation and in countering the spread of misinformation. To explore if this\nis the case, we conduct a data-driven study of misinformation on the Twitter\nplatform, focusing on tweets related to the COVID-19 pandemic, analyzing the\nspread of misinformation, professional fact checks, and the crowd response to\npopular misleading claims about COVID-19. In this work, we curate a dataset of\nfalse claims and statements that seek to challenge or refute them. We train a\nclassifier to create a novel dataset of 155,468 COVID-19-related tweets,\ncontaining 33,237 false claims and 33,413 refuting arguments.Our findings show\nthat professional fact-checking tweets have limited volume and reach. In\ncontrast, we observe that the surge in misinformation tweets results in a quick\nresponse and a corresponding increase in tweets that refute such\nmisinformation. More importantly, we find contrasting differences in the way\nthe crowd refutes tweets, some tweets appear to be opinions, while others\ncontain concrete evidence, such as a link to a reputed source. Our work\nprovides insights into how misinformation is organically countered in social\nplatforms by some of their users and the role they play in amplifying\nprofessional fact checks.These insights could lead to development of tools and\nmechanisms that can empower concerned citizens in combating misinformation. The\ncode and data can be found in\nhttp://claws.cc.gatech.edu/covid_counter_misinformation.html.", "doi": "", "date": "2020-11-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.05773v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2911072355, "title": "The Value of Misinformation and Disinformation", "abstract": "Information is a critical dimension in warfare. Inaccurate information such\nas misinformation or disinformation further complicates military operations. In\nthis paper, we examine the value of misinformation and disinformation to a\nmilitary leader who through investment in people, programs and technology is\nable to affect the accuracy of information communicated between other actors.\nWe model the problem as a partially observable stochastic game with three\nagents, a leader and two followers. We determine the value to the leader of\nmisinformation or disinformation being communicated between two (i) adversarial\nfollowers and (ii) allied followers. We demonstrate that only under certain\nconditions, the prevalent intuition that the leader would benefit from less\n(more) accurate communication between adversarial (allied) followers is valid.\nWe analyzed why the intuition may fail and show a holistic paradigm taking into\naccount both the reward structures and policies of agents is necessary in order\nto correctly determine the value of misinformation and disinformation. Our\nresearch identifies efficient targeted investments to affect the accuracy of\ninformation communicated between followers to the leader's advantage.", "doi": "", "date": "2019-01-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.01464v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1143232107, "title": "Towards Automatic Detection of Misinformation in Online Medical Videos", "abstract": "Recent years have witnessed a significant increase in the online sharing of\nmedical information, with videos representing a large fraction of such online\nsources. Previous studies have however shown that more than half of the\nhealth-related videos on platforms such as YouTube contain misleading\ninformation and biases. Hence, it is crucial to build computational tools that\ncan help evaluate the quality of these videos so that users can obtain accurate\ninformation to help inform their decisions. In this study, we focus on the\nautomatic detection of misinformation in YouTube videos. We select prostate\ncancer videos as our entry point to tackle this problem. The contribution of\nthis paper is twofold. First, we introduce a new dataset consisting of 250\nvideos related to prostate cancer manually annotated for misinformation.\nSecond, we explore the use of linguistic, acoustic, and user engagement\nfeatures for the development of classification models to identify\nmisinformation. Using a series of ablation experiments, we show that we can\nbuild automatic models with accuracies of up to 74%, corresponding to a 76.5%\nprecision and 73.2% recall for misinformative instances.", "doi": "", "date": "2019-09-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.01543v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 154967900, "title": "Analysing the Extent of Misinformation in Cancer Related Tweets", "abstract": "Twitter has become one of the most sought after places to discuss a wide\nvariety of topics, including medically relevant issues such as cancer. This\nhelps spread awareness regarding the various causes, cures and prevention\nmethods of cancer. However, no proper analysis has been performed, which\ndiscusses the validity of such claims. In this work, we aim to tackle the\nmisinformation spread in such platforms. We collect and present a dataset\nregarding tweets which talk specifically about cancer and propose an\nattention-based deep learning model for automated detection of misinformation\nalong with its spread. We then do a comparative analysis of the linguistic\nvariation in the text corresponding to misinformation and truth. This analysis\nhelps us gather relevant insights on various social aspects related to\nmisinformed tweets.", "doi": "", "date": "2020-03-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.13657v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 89301452, "title": "Exposure to Social Engagement Metrics Increases Vulnerability to\n  Misinformation", "abstract": "News feeds in virtually all social media platforms include engagement\nmetrics, such as the number of times each post is liked and shared. We find\nthat exposure to these social engagement signals increases the vulnerability of\nusers to misinformation. This finding has important implications for the design\nof social media interactions in the misinformation age. To reduce the spread of\nmisinformation, we call for technology platforms to rethink the display of\nsocial engagement metrics. Further research is needed to investigate whether\nand how engagement metrics can be presented without amplifying the spread of\nlow-credibility information.", "doi": "10.37016/mr-2020-033", "date": "2020-05-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.04682v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2327494900, "title": "COVID-19 Misinformation and Disinformation on Social Networks -- The\n  Limits of Veritistic Countermeasures", "abstract": "The COVID-19 pandemic has been the subject of a vast amount of\nmisinformation, particularly in digital information environments, and major\nsocial media platforms recently publicized some of the countermeasures they are\nadopting. This presents an opportunity to examine the nature of the\nmisinformation and disinformation being produced, and the theoretical and\ntechnological paradigm used to counter it. I argue that this approach is based\non a conception of misinformation as epistemic pollution that can only justify\na limited and potentially inadequate response , and that some of the measures\nundertaken in practice outrun this. In fact, social networks manage ecological\nand architectural conditions that influence discourse on their platforms in\nways that should motivate reconsideration of the justifications that ground\nepistemic interventions to combat misinformation, and the types of intervention\nthat they warrant. The editorial role of platforms should not be framed solely\nas the management of epistemic pollution, but instead as managing the epistemic\nenvironment in which narratives and social epistemic processes take place.\nThere is an element of inevitable epistemic paternalism involved in this, and\nexploration of the independent constraints on its justifiability can help\ndetermine proper limits of its exercise in practice.", "doi": "", "date": "2020-08-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.00784v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3070640770, "title": "Right and left, partisanship predicts (asymmetric) vulnerability to\n  misinformation", "abstract": "We analyze the relationship between partisanship, echo chambers, and\nvulnerability to online misinformation by studying news sharing behavior on\nTwitter. While our results confirm prior findings that online misinformation\nsharing is strongly correlated with right-leaning partisanship, we also uncover\na similar, though weaker trend among left-leaning users. Because of the\ncorrelation between a user's partisanship and their position within a partisan\necho chamber, these types of influence are confounded. To disentangle their\neffects, we perform a regression analysis and find that vulnerability to\nmisinformation is most strongly influenced by partisanship for both left- and\nright-leaning users.", "doi": "10.37016/mr-2020-55", "date": "2020-10-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.01462v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 986129881, "title": "Social Media COVID-19 Misinformation Interventions Viewed Positively,\n  But Have Limited Impact", "abstract": "Amidst COVID-19 misinformation spreading, social media platforms like\nFacebook and Twitter rolled out design interventions, including banners linking\nto authoritative resources and more specific \"false information\" labels. In\nlate March 2020, shortly after these interventions began to appear, we\nconducted an exploratory mixed-methods survey (N = 311) to learn: what are\nsocial media users' attitudes towards these interventions, and to what extent\ndo they self-report effectiveness? We found that most participants indicated a\npositive attitude towards interventions, particularly post-specific labels for\nmisinformation. Still, the majority of participants discovered or corrected\nmisinformation through other means, most commonly web searches, suggesting room\nfor platforms to do more to stem the spread of COVID-19 misinformation.", "doi": "", "date": "2020-12-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.11055v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3765523124, "title": "University of Copenhagen Participation in TREC Health Misinformation\n  Track 2020", "abstract": "In this paper, we describe our participation in the TREC Health\nMisinformation Track 2020. We submitted $11$ runs to the Total Recall Task and\n13 runs to the Ad Hoc task. Our approach consists of 3 steps: (1) we create an\ninitial run with BM25 and RM3; (2) we estimate credibility and misinformation\nscores for the documents in the initial run; (3) we merge the relevance,\ncredibility and misinformation scores to re-rank documents in the initial run.\nTo estimate credibility scores, we implement a classifier which exploits\nfeatures based on the content and the popularity of a document. To compute the\nmisinformation score, we apply a stance detection approach with a pretrained\nTransformer language model. Finally, we use different approaches to merge\nscores: weighted average, the distance among score vectors and rank fusion.", "doi": "", "date": "2021-03-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.02462v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 839840356, "title": "Misinformation Warning Labels: Twitter's Soft Moderation Effects on\n  COVID-19 Vaccine Belief Echoes", "abstract": "Twitter, prompted by the rapid spread of alternative narratives, started\nactively warning users about the spread of COVID-19 misinformation. This form\nof soft moderation comes in two forms: as a warning cover before the Tweet is\ndisplayed to the user and as a warning tag below the Tweet. This study\ninvestigates how each of the soft moderation forms affects the perceived\naccuracy of COVID-19 vaccine misinformation on Twitter. The results suggest\nthat the warning covers work, but not the tags, in reducing the perception of\naccuracy of COVID-19 vaccine misinformation on Twitter. \"Belief echoes\" do\nexist among Twitter users, unfettered by any warning labels, in relationship to\nthe perceived safety and efficacy of the COVID-19 vaccine as well as the\nvaccination hesitancy for themselves and their children. The implications of\nthese results are discussed in the context of usable security affordances for\ncombating misinformation on social media.", "doi": "", "date": "2021-04-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.00779v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3024524052, "title": "No Calm in The Storm: Investigating QAnon Website Relationships", "abstract": "QAnon is a far-right conspiracy theory whose followers largely organize\nonline. In this work, we use web crawls seeded from two of the largest QAnon\nhotbeds on the Internet, Voat and 8kun, to build a hyperlink graph. We then use\nthis graph to identify, understand, and learn from the websites that spread\nQAnon content online. We curate the largest list of QAnon centered websites to\ndate, from which we document the types of QAnon sites, their hosting providers,\nas well as their popularity. We further analyze QAnon websites' connection to\nmainstream news and misinformation online, highlighting the outsized role\nmisinformation websites play in spreading the conspiracy. Finally, we leverage\nthe observed relationship between QAnon and misinformation sites to build a\nrandom forest classifier that distinguishes between misinformation and\nauthentic news sites, getting a performance of 0.98 AUC on a test set. Our\nresults demonstrate new and effective ways to study conspiracy and\nmisinformation on the Internet.", "doi": "", "date": "2021-06-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.15715v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4069961248, "title": "Policy and Planning for Large Infrastructure Projects: Problems, Causes,\n  Cures", "abstract": "This paper argues, first, that a major problem in the planning of large\ninfrastructure projects is the high level of misinformation about costs and\nbenefits that decision makers face in deciding whether to build, and the high\nrisks such misinformation generates. Second, it explores the causes of\nmisinformation and risk, mainly in the guise of optimism bias and strategic\nmisrepresentation. Finally, the paper presents a number of measures aimed at\nimproving planning and decision making for large infrastructure projects,\nincluding changed incentive structures and better planning methods. Thus the\npaper is organized as a simple triptych consisting in problems, causes, and\ncures.", "doi": "", "date": "2013-03-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1303.7400v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1256840461, "title": "Images and Misinformation in Political Groups: Evidence from WhatsApp in\n  India", "abstract": "WhatsApp is a key medium for the spread of news and rumors, often shared as\nimages. We study a large collection of politically-oriented WhatsApp groups in\nIndia, focusing on the period leading up to the 2019 Indian national elections.\nBy labeling samples of random and popular images, we find that around 13% of\nshared images are known misinformation and most fall into three types of\nimages. Machine learning methods can be used to predict whether a viral image\nis misinformation, but are brittle to shifts in content over time.", "doi": "", "date": "2020-05-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.09784v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2391684251, "title": "This photograph has been altered: Testing the effectiveness of image\n  forensic labeling on news image credibility", "abstract": "Despite the ubiquity and proliferation of images and videos in online news\nenvironments, much of the existing research on misinformation and its\ncorrection is solely focused on textual misinformation, and little is known\nabout how ordinary users evaluate fake or manipulated images and the most\neffective ways to label and correct such falsities. We designed a visual\nforensic label of image authenticity, Picture-O-Meter, and tested the label's\nefficacy in relation to its source and placement in an experiment with 2440\nparticipants. Our findings demonstrate that, despite human beings' general\ninability to detect manipulated images on their own, image forensic labels are\nan effective tool for counteracting visual misinformation.", "doi": "", "date": "2021-01-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.07951v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2609627742, "title": "Pilot Study Suggests Online Media Literacy Programming Reduces Belief in\n  False News in Indonesia", "abstract": "Amidst the threat of digital misinformation, we offer a pilot study regarding\nthe efficacy of an online social media literacy campaign aimed at empowering\nindividuals in Indonesia with skills to help them identify misinformation. We\nfound that users who engaged with our online training materials and educational\nvideos were more likely to identify misinformation than those in our control\ngroup (total $N$=1000). Given the promising results of our preliminary study,\nwe plan to expand efforts in this area, and build upon lessons learned from\nthis pilot study.", "doi": "", "date": "2021-07-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.08034v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4070026767, "title": "Leveraging the Crowd to Detect and Reduce the Spread of Fake News and\n  Misinformation", "abstract": "Online social networking sites are experimenting with the following\ncrowd-powered procedure to reduce the spread of fake news and misinformation:\nwhenever a user is exposed to a story through her feed, she can flag the story\nas misinformation and, if the story receives enough flags, it is sent to a\ntrusted third party for fact checking. If this party identifies the story as\nmisinformation, it is marked as disputed. However, given the uncertain number\nof exposures, the high cost of fact checking, and the trade-off between flags\nand exposures, the above mentioned procedure requires careful reasoning and\nsmart algorithms which, to the best of our knowledge, do not exist to date.\n  In this paper, we first introduce a flexible representation of the above\nprocedure using the framework of marked temporal point processes. Then, we\ndevelop a scalable online algorithm, Curb, to select which stories to send for\nfact checking and when to do so to efficiently reduce the spread of\nmisinformation with provable guarantees. In doing so, we need to solve a novel\nstochastic optimal control problem for stochastic differential equations with\njumps, which is of independent interest. Experiments on two real-world datasets\ngathered from Twitter and Weibo show that our algorithm may be able to\neffectively reduce the spread of fake news and misinformation.", "doi": "", "date": "2017-11-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.09918v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 437533539, "title": "Anatomy of an online misinformation network", "abstract": "Massive amounts of fake news and conspiratorial content have spread over\nsocial media before and after the 2016 US Presidential Elections despite\nintense fact-checking efforts. How do the spread of misinformation and\nfact-checking compete? What are the structural and dynamic characteristics of\nthe core of the misinformation diffusion network, and who are its main\npurveyors? How to reduce the overall amount of misinformation? To explore these\nquestions we built Hoaxy, an open platform that enables large-scale, systematic\nstudies of how misinformation and fact-checking spread and compete on Twitter.\nHoaxy filters public tweets that include links to unverified claims or\nfact-checking articles. We perform k-core decomposition on a diffusion network\nobtained from two million retweets produced by several hundred thousand\naccounts over the six months before the election. As we move from the periphery\nto the core of the network, fact-checking nearly disappears, while social bots\nproliferate. The number of users in the main core reaches equilibrium around\nthe time of the election, with limited churn and increasingly dense\nconnections. We conclude by quantifying how effectively the network can be\ndisrupted by penalizing the most central nodes. These findings provide a first\nlook at the anatomy of a massive online misinformation diffusion network.", "doi": "10.1371/journal.pone.0196087", "date": "2018-01-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1801.06122v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1848677359, "title": "It's Always April Fools' Day! On the Difficulty of Social Network\n  Misinformation Classification via Propagation Features", "abstract": "Given the huge impact that Online Social Networks (OSN) had in the way people\nget informed and form their opinion, they became an attractive playground for\nmalicious entities that want to spread misinformation, and leverage their\neffect. In fact, misinformation easily spreads on OSN and is a huge threat for\nmodern society, possibly influencing also the outcome of elections, or even\nputting people's life at risk (e.g., spreading \"anti-vaccines\" misinformation).\nTherefore, it is of paramount importance for our society to have some sort of\n\"validation\" on information spreading through OSN. The need for a wide-scale\nvalidation would greatly benefit from automatic tools.\n  In this paper, we show that it is difficult to carry out an automatic\nclassification of misinformation considering only structural properties of\ncontent propagation cascades. We focus on structural properties, because they\nwould be inherently difficult to be manipulated, with the the aim of\ncircumventing classification systems. To support our claim, we carry out an\nextensive evaluation on Facebook posts belonging to conspiracy theories (as\nrepresentative of misinformation), and scientific news (representative of\nfact-checked content). Our findings show that conspiracy content actually\nreverberates in a way which is hard to distinguish from the one scientific\ncontent does: for the classification mechanisms we investigated, classification\nF1-score never exceeds 0.65 during content propagation stages, and is still\nless than 0.7 even after propagation is complete.", "doi": "", "date": "2017-01-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1701.04221v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 194005363, "title": "Beyond Uniform Reverse Sampling: A Hybrid Sampling Technique for\n  Misinformation Prevention", "abstract": "Online misinformation has been considered as one of the top global risks as\nit may cause serious consequences such as economic damages and public panic.\nThe misinformation prevention problem aims at generating a positive cascade\nwith appropriate seed nodes in order to compete against the misinformation. In\nthis paper, we study the misinformation prevention problem under the prominent\nindependent cascade model. Due to the #P-hardness in computing influence, the\ncore problem is to design effective sampling methods to estimate the function\nvalue. The main contribution of this paper is a novel sampling method.\nDifferent from the classic reverse sampling technique which treats all nodes\nequally and samples the node uniformly, the proposed method proceeds with a\nhybrid sampling process which is able to attach high weights to the users who\nare prone to be affected by the misinformation. Consequently, the new sampling\nmethod is more powerful in generating effective samples used for computing seed\nnodes for the positive cascade. Based on the new hybrid sample technique, we\ndesign an algorithm offering a $(1-1/e-\\epsilon)$-approximation. We\nexperimentally evaluate the proposed method on extensive datasets and show that\nit significantly outperforms the state-of-the-art solutions.", "doi": "", "date": "2019-01-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.05149v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4055763631, "title": "COVID-19 on Social Media: Analyzing Misinformation in Twitter\n  Conversations", "abstract": "The ongoing Coronavirus (COVID-19) pandemic highlights the\ninter-connectedness of our present-day globalized world. With social distancing\npolicies in place, virtual communication has become an important source of\n(mis)information. As increasing number of people rely on social media platforms\nfor news, identifying misinformation and uncovering the nature of online\ndiscourse around COVID-19 has emerged as a critical task. To this end, we\ncollected streaming data related to COVID-19 using the Twitter API, starting\nMarch 1, 2020. We identified unreliable and misleading contents based on\nfact-checking sources, and examined the narratives promoted in misinformation\ntweets, along with the distribution of engagements with these tweets. In\naddition, we provide examples of the spreading patterns of prominent\nmisinformation tweets. The analysis is presented and updated on a publically\naccessible dashboard (https://usc-melady.github.io/COVID-19-Tweet-Analysis) to\ntrack the nature of online discourse and misinformation about COVID-19 on\nTwitter from March 1 - June 5, 2020. The dashboard provides a daily list of\nidentified misinformation tweets, along with topics, sentiments, and emerging\ntrends in the COVID-19 Twitter discourse. The dashboard is provided to improve\nvisibility into the nature and quality of information shared online, and\nprovide real-time access to insights and information extracted from the\ndataset.", "doi": "", "date": "2020-03-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.12309v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3868051064, "title": "An Exploratory Study of COVID-19 Misinformation on Twitter", "abstract": "During the COVID-19 pandemic, social media has become a home ground for\nmisinformation. To tackle this infodemic, scientific oversight, as well as a\nbetter understanding by practitioners in crisis management, is needed. We have\nconducted an exploratory study into the propagation, authors and content of\nmisinformation on Twitter around the topic of COVID-19 in order to gain early\ninsights. We have collected all tweets mentioned in the verdicts of\nfact-checked claims related to COVID-19 by over 92 professional fact-checking\norganisations between January and mid-July 2020 and share this corpus with the\ncommunity. This resulted in 1 500 tweets relating to 1 274 false and 276\npartially false claims, respectively. Exploratory analysis of author accounts\nrevealed that the verified twitter handle(including Organisation/celebrity) are\nalso involved in either creating (new tweets) or spreading (retweet) the\nmisinformation. Additionally, we found that false claims propagate faster than\npartially false claims. Compare to a background corpus of COVID-19 tweets,\ntweets with misinformation are more often concerned with discrediting other\ninformation on social media. Authors use less tentative language and appear to\nbe more driven by concerns of potential harm to others. Our results enable us\nto suggest gaps in the current scientific coverage of the topic as well as\npropose actions for authorities and social media users to counter\nmisinformation.", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.05710v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 50926981, "title": "Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models", "abstract": "Misinformation of COVID-19 is prevalent on social media as the pandemic\nunfolds, and the associated risks are extremely high. Thus, it is critical to\ndetect and combat such misinformation. Recently, deep learning models using\nnatural language processing techniques, such as BERT (Bidirectional Encoder\nRepresentations from Transformers), have achieved great successes in detecting\nmisinformation. In this paper, we proposed an explainable natural language\nprocessing model based on DistilBERT and SHAP (Shapley Additive exPlanations)\nto combat misinformation about COVID-19 due to their efficiency and\neffectiveness. First, we collected a dataset of 984 claims about COVID-19 with\nfact checking. By augmenting the data using back-translation, we doubled the\nsample size of the dataset and the DistilBERT model was able to obtain good\nperformance (accuracy: 0.972; areas under the curve: 0.993) in detecting\nmisinformation about COVID-19. Our model was also tested on a larger dataset\nfor AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good\nperformance (accuracy: 0.938; areas under the curve: 0.985). The performance on\nboth datasets was better than traditional machine learning models. Second, in\norder to boost public trust in model prediction, we employed SHAP to improve\nmodel explainability, which was further evaluated using a between-subjects\nexperiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),\nand text+SHAP explanation+source and evidence (TSESE). The participants were\nsignificantly more likely to trust and share information related to COVID-19 in\nthe TSE and TSESE conditions than in the T condition. Our results provided good\nimplications in detecting misinformation about COVID-19 and improving public\ntrust.", "doi": "", "date": "2021-03-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.00747v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2655603207, "title": "Network segregation in a model of misinformation and fact checking", "abstract": "Misinformation under the form of rumor, hoaxes, and conspiracy theories\nspreads on social media at alarming rates. One hypothesis is that, since social\nmedia are shaped by homophily, belief in misinformation may be more likely to\nthrive on those social circles that are segregated from the rest of the\nnetwork. One possible antidote is fact checking which, in some cases, is known\nto stop rumors from spreading further. However, fact checking may also backfire\nand reinforce the belief in a hoax. Here we take into account the combination\nof network segregation, finite memory and attention, and fact-checking efforts.\nWe consider a compartmental model of two interacting epidemic processes over a\nnetwork that is segregated between gullible and skeptic users. Extensive\nsimulation and mean-field analysis show that a more segregated network\nfacilitates the spread of a hoax only at low forgetting rates, but has no\neffect when agents forget at faster rates. This finding may inform the\ndevelopment of mitigation techniques and overall inform on the risks of\nuncontrolled misinformation online.", "doi": "10.1007/s42001-018-0018-9", "date": "2016-10-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1610.04170v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2617200188, "title": "Polarization and Fake News: Early Warning of Potential Misinformation\n  Targets", "abstract": "Users polarization and confirmation bias play a key role in misinformation\nspreading on online social media. Our aim is to use this information to\ndetermine in advance potential targets for hoaxes and fake news. In this paper,\nwe introduce a general framework for promptly identifying polarizing content on\nsocial media and, thus, \"predicting\" future fake news topics. We validate the\nperformances of the proposed methodology on a massive Italian Facebook dataset,\nshowing that we are able to identify topics that are susceptible to\nmisinformation with 77% accuracy. Moreover, such information may be embedded as\na new feature in an additional classifier able to recognize fake news with 91%\naccuracy. The novelty of our approach consists in taking into account a series\nof characteristics related to users behavior on online social media, making a\nfirst, important step towards the smoothing of polarization and the mitigation\nof misinformation phenomena.", "doi": "", "date": "2018-02-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1802.01400v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4206700433, "title": "QuickStop: A Markov Optimal Stopping Approach for Quickest\n  Misinformation Detection", "abstract": "This paper combines data-driven and model-driven methods for real-time\nmisinformation detection. Our algorithm, named QuickStop, is an optimal\nstopping algorithm based on a probabilistic information spreading model\nobtained from labeled data. The algorithm consists of an offline machine\nlearning algorithm for learning the probabilistic information spreading model\nand an online optimal stopping algorithm to detect misinformation. The online\ndetection algorithm has both low computational and memory complexities. Our\nnumerical evaluations with a real-world dataset show that QuickStop outperforms\nexisting misinformation detection algorithms in terms of both accuracy and\ndetection time (number of observations needed for detection). Our evaluations\nwith synthetic data further show that QuickStop is robust to (offline) learning\nerrors.", "doi": "", "date": "2019-03-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.04887v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3060451609, "title": "Containing misinformation spreading in temporal social networks", "abstract": "Many researchers from a variety of fields including computer science, network\nscience and mathematics have focused on how to contain the outbreaks of\nInternet misinformation that threaten social systems and undermine societal\nhealth. Most research on this topic treats the connections among individuals as\nstatic, but these connections change in time, and thus social networks are also\ntemporal networks. Currently there is no theoretical approach to the problem of\ncontaining misinformation outbreaks in temporal networks. We thus propose a\nmisinformation spreading model for temporal networks and describe it using a\nnew theoretical approach. We propose a heuristic-containing (HC) strategy based\non optimizing final outbreak size that outperforms simplified strategies such\nas those that are random-containing (RC) and targeted-containing (TC). We\nverify the effectiveness of our HC strategy on both artificial and real-world\nnetworks by performing extensive numerical simulations and theoretical\nanalyses. We find that the HC strategy greatly increases the outbreak threshold\nand decreases the final outbreak threshold.", "doi": "10.1063/1.5114853", "date": "2019-04-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.10801v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2271000682, "title": "The Limitations of Stylometry for Detecting Machine-Generated Fake News", "abstract": "Recent developments in neural language models (LMs) have raised concerns\nabout their potential misuse for automatically spreading misinformation. In\nlight of these concerns, several studies have proposed to detect\nmachine-generated fake news by capturing their stylistic differences from\nhuman-written text. These approaches, broadly termed stylometry, have found\nsuccess in source attribution and misinformation detection in human-written\ntexts. However, in this work, we show that stylometry is limited against\nmachine-generated misinformation. While humans speak differently when trying to\ndeceive, LMs generate stylistically consistent text, regardless of underlying\nmotive. Thus, though stylometry can successfully prevent impersonation by\nidentifying text provenance, it fails to distinguish legitimate LM applications\nfrom those that introduce false information. We create two benchmarks\ndemonstrating the stylistic similarity between malicious and legitimate uses of\nLMs, employed in auto-completion and editing-assistance settings. Our findings\nhighlight the need for non-stylometry approaches in detecting machine-generated\nmisinformation, and open up the discussion on the desired evaluation\nbenchmarks.", "doi": "", "date": "2019-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.09805v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1808254660, "title": "Independent Component Analysis for Trustworthy Cyberspace during High\n  Impact Events: An Application to Covid-19", "abstract": "Social media has become an important communication channel during high impact\nevents, such as the COVID-19 pandemic. As misinformation in social media can\nrapidly spread, creating social unrest, curtailing the spread of misinformation\nduring such events is a significant data challenge. While recent solutions that\nare based on machine learning have shown promise for the detection of\nmisinformation, most widely used methods include approaches that rely on either\nhandcrafted features that cannot be optimal for all scenarios, or those that\nare based on deep learning where the interpretation of the prediction results\nis not directly accessible. In this work, we propose a data-driven solution\nthat is based on the ICA model, such that knowledge discovery and detection of\nmisinformation are achieved jointly. To demonstrate the effectiveness of our\nmethod and compare its performance with deep learning methods, we developed a\nlabeled COVID-19 Twitter dataset based on socio-linguistic criteria.", "doi": "", "date": "2020-06-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.01284v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2102923340, "title": "Social Media and Health Misinformation during the US COVID Crisis", "abstract": "Health misinformation has been found to be prevalent on social media,\nparticularly in new public health crises in which there is limited scientific\ninformation. However, social media can also play a role in limiting and\nrefuting health misinformation. Using as a case study US President Donald\nTrump's controversial comments about the promise and power of UV light- and\ndisinfectant-based treatments, this data memo examines how these comments were\ndiscussed and responded to on Twitter. We find that these comments fell into\nestablished politically partisan narratives and dominated discussion of both\npolitics and COVID in the days following. Contestation of the comments was much\nmore prevalent than support. Supporters attacked media coverage in line with\nexisting Trump narratives. Contesters responded with humour and shared\nmainstream media coverage condemning the comments. These practices would have\nstrengthened the original misinformation through repetition and done little to\nconstruct a successful refutation for those who might have believed them. This\nresearch adds much-needed knowledge to our understanding of the information\nenvironment surrounding COVID and demonstrates that, despite calls for the\ndepoliticization of health information in this public health crisis, this is\nlargely being approached as a political issue along divisive, polarised,\npartisan lines.", "doi": "", "date": "2020-08-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.05271v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3858679386, "title": "Misinformation and its stakeholders in Europe: a web-based analysis", "abstract": "The rise of the internet and computational power in recent years allowed for\nthe exponential growth of misinformation phenomena. An issue that was a\nnon-issue a decade ago, became a challenge for societal cohesion. The emergence\nof this new threat has led many stakeholders, especially in Europe, to act in\norder to tackle this phenomenon. This paper provides in its first part a\nliterature review on misinformation in Europe, and in its second part a\nwebometrics analysis on the identified key stakeholders. In the results we\ndiscuss who those stakeholders are, what actions do they perform to limit\nmisinformation and whether those actions have an impact.", "doi": "", "date": "2020-09-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.09218v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4247100709, "title": "Designing Indicators to Combat Fake Media", "abstract": "The growth of misinformation technology necessitates the need to identify\nfake videos. One approach to preventing the consumption of these fake videos is\nprovenance which allows the user to authenticate media content to its original\nsource. This research designs and investigates the use of provenance indicators\nto help users identify fake videos. We first interview users regarding their\nexperiences with different misinformation modes (text, image, video) to guide\nthe design of indicators within users' existing perspectives. Then, we conduct\na participatory design study to develop and design fake video indicators.\nFinally, we evaluate participant-designed indicators via both expert\nevaluations and quantitative surveys with a large group of end-users. Our\nresults provide concrete design guidelines for the emerging issue of fake\nvideos. Our findings also raise concerns regarding users' tendency to\novergeneralize from misinformation warning messages, suggesting the need for\nfurther research on warning design in the ongoing fight against misinformation.", "doi": "", "date": "2020-10-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.00544v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3893087080, "title": "Drink bleach or do what now? Covid-HeRA: A dataset for risk-informed\n  health decision making in the presence of COVID19 misinformation", "abstract": "Given the wide spread of inaccurate medical advice related to the 2019\ncoronavirus pandemic (COVID-19), such as fake remedies, treatments and\nprevention suggestions, misinformation detection has emerged as an open problem\nof high importance and interest for the NLP community. To combat potential harm\nof COVID19-related misinformation, we release Covid-HeRA, a dataset for health\nrisk assessment of COVID-19-related social media posts. More specifically, we\nstudy the severity of each misinformation story, i.e., how harmful a message\nbelieved by the audience can be and what type of signals can be used to\ndiscover high malicious fake news and detect refuted claims. We present a\ndetailed analysis, evaluate several simple and advanced classification models,\nand conclude with our experimental analysis that presents open challenges and\nfuture directions.", "doi": "", "date": "2020-10-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.08743v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2264582811, "title": "ArCOV19-Rumors: Arabic COVID-19 Twitter Dataset for Misinformation\n  Detection", "abstract": "In this paper we introduce ArCOV19-Rumors, an Arabic COVID-19 Twitter dataset\nfor misinformation detection composed of tweets containing claims from 27th\nJanuary till the end of April 2020. We collected 138 verified claims, mostly\nfrom popular fact-checking websites, and identified 9.4K relevant tweets to\nthose claims. Tweets were manually-annotated by veracity to support research on\nmisinformation detection, which is one of the major problems faced during a\npandemic. ArCOV19-Rumors supports two levels of misinformation detection over\nTwitter: verifying free-text claims (called claim-level verification) and\nverifying claims expressed in tweets (called tweet-level verification). Our\ndataset covers, in addition to health, claims related to other topical\ncategories that were influenced by COVID-19, namely, social, politics, sports,\nentertainment, and religious. Moreover, we present benchmarking results for\ntweet-level verification on the dataset. We experimented with SOTA models of\nversatile approaches that either exploit content, user profiles features,\ntemporal features and propagation structure of the conversational threads for\ntweet verification.", "doi": "", "date": "2020-10-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.08768v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 138365676, "title": "An ontological analysis of misinformation in online social networks", "abstract": "The internet, Online Social Networks (OSNs) and smart phones enable users to\ncreate tremendous amount of information. Users who search for general or\nspecific knowledge may not have these days problems of information scarce but\nmisinformation. Misinformation nowadays can refer to a continuous spectrum\nbetween what can be seen as \"facts\" or \"truth\", if humans agree on the\nexistence of such, to false information that everyone agree that it is false.\nIn this paper, we will look at this spectrum of information/misinformation and\ncompare between some of the major relevant concepts. While few fact-checking\nwebsites exist to evaluate news articles or some of the popular claims people\nexchange, nonetheless this can be seen as a little effort in the mission to tag\nonline information with their \"proper\" category or label.", "doi": "", "date": "2021-02-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.11362v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2440449892, "title": "Mutual Hyperlinking Among Misinformation Peddlers", "abstract": "The internet promised to democratize access to knowledge and make the world\nmore open and understanding. The reality of today's internet, however, is far\nfrom this ideal. Misinformation, lies, and conspiracies dominate many social\nmedia platforms. This toxic online world has had real-world implications\nranging from genocide to, election interference, and threats to global public\nhealth. A frustrated public and impatient government regulators are calling for\na more vigorous response to mis- and disinformation campaigns designed to sow\ncivil unrest and inspire violence against individuals, societies, and\ndemocracies. We describe a large-scale, domain-level analysis that reveals\nseemingly coordinated efforts between multiple domains to spread and amplify\nmisinformation. We also describe how the hyperlinks shared by certain Twitter\nusers can be used to surface problematic domains. These analyses can be used by\nsearch engines and social media recommendation algorithms to systematically\ndiscover and demote misinformation peddlers.", "doi": "", "date": "2021-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.11694v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3396239724, "title": "The State of Infodemic on Twitter", "abstract": "Following the wave of misinterpreted, manipulated and malicious information\ngrowing on the Internet, the misinformation surrounding COVID-19 has become a\nparamount issue. In the context of the current COVID-19 pandemic, social media\nposts and platforms are at risk of rumors and misinformation in the face of the\nserious uncertainty surrounding the virus itself. At the same time, the\nuncertainty and new nature of COVID-19 means that other unconfirmed information\nthat may appear \"rumored\" may be an important indicator of the behavior and\nimpact of this new virus. Twitter, in particular, has taken a center stage in\nthis storm where Covid-19 has been a much talked about subject. We have\npresented an exploratory analysis of the tweets and the users who are involved\nin spreading misinformation and then delved into machine learning models and\nnatural language processing techniques to identify if a tweet contains\nmisinformation.", "doi": "", "date": "2021-05-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.07730v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 68112257, "title": "Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform", "abstract": "This paper evaluates Parler, the controversial social media platform, from\ntwo seemingly orthogonal perspectives: UX design perspective and data science.\nUX design researchers explore how users react to the interface/content of their\nsocial media feeds; Data science researchers analyze the misinformation flow in\nthese feeds to detect alternative narratives and state-sponsored disinformation\ncampaigns. We took a critical look into the intersection of these approaches to\nunderstand how Parler's interface itself is conductive to the flow of\nmisinformation and the perception of \"free speech\" among its audience. Parler\ndrew widespread attention leading up to and after the 2020 U.S. elections as\nthe \"alternative\" place for free speech, as a reaction to other mainstream\nsocial media platform which actively engaged in labeling misinformation with\ncontent warnings. Because platforms like Parler are disruptive to the social\nmedia landscape, we believe the evaluation uniquely uncovers the platform's\nconductivity to the spread of misinformation.", "doi": "", "date": "2021-06-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.00163v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 317670071, "title": "\"Everything I Disagree With is #FakeNews\": Correlating Political\n  Polarization and Spread of Misinformation", "abstract": "An important challenge in the process of tracking and detecting the\ndissemination of misinformation is to understand the political gap between\npeople that engage with the so called \"fake news\". A possible factor\nresponsible for this gap is opinion polarization, which may prompt the general\npublic to classify content that they disagree or want to discredit as fake. In\nthis work, we study the relationship between political polarization and content\nreported by Twitter users as related to \"fake news\". We investigate how\npolarization may create distinct narratives on what misinformation actually is.\nWe perform our study based on two datasets collected from Twitter. The first\ndataset contains tweets about US politics in general, from which we compute the\ndegree of polarization of each user towards the Republican and Democratic\nParty. In the second dataset, we collect tweets and URLs that co-occurred with\n\"fake news\" related keywords and hashtags, such as #FakeNews and\n#AlternativeFact, as well as reactions towards such tweets and URLs. We then\nanalyze the relationship between polarization and what is perceived as\nmisinformation, and whether users are designating information that they\ndisagree as fake. Our results show an increase in the polarization of users and\nURLs associated with fake-news keywords and hashtags, when compared to\ninformation not labeled as \"fake news\". We discuss the impact of our findings\non the challenges of tracking \"fake news\" in the ongoing battle against\nmisinformation.", "doi": "", "date": "2017-06-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1706.05924v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3138189423, "title": "Reverse Prevention Sampling for Misinformation Mitigation in Social\n  Networks", "abstract": "In this work, we consider misinformation propagating through a social network\nand study the problem of its prevention. In this problem, a \"bad\" campaign\nstarts propagating from a set of seed nodes in the network and we use the\nnotion of a limiting (or \"good\") campaign to counteract the effect of\nmisinformation. The goal is to identify a set of $k$ users that need to be\nconvinced to adopt the limiting campaign so as to minimize the number of people\nthat adopt the \"bad\" campaign at the end of both propagation processes.\n  This work presents \\emph{RPS} (Reverse Prevention Sampling), an algorithm\nthat provides a scalable solution to the misinformation mitigation problem. Our\ntheoretical analysis shows that \\emph{RPS} runs in $O((k + l)(n + m)(\\frac{1}{1\n- \\gamma}) \\log n / \\epsilon^2 )$ expected time and returns a $(1 - 1/e -\n\\epsilon)$-approximate solution with at least $1 - n^{-l}$ probability (where\n$\\gamma$ is a typically small network parameter and $l$ is a confidence\nparameter). The time complexity of \\emph{RPS} substantially improves upon the\npreviously best-known algorithms that run in time $\\Omega(m n k \\cdot\nPOLY(\\epsilon^{-1}))$. We experimentally evaluate \\emph{RPS} on large datasets\nand show that it outperforms the state-of-the-art solution by several orders of\nmagnitude in terms of running time. This demonstrates that misinformation\nmitigation can be made practical while still offering strong theoretical\nguarantees.", "doi": "", "date": "2018-07-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1807.01162v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3188306556, "title": "Adversarial Targeted Forgetting in Regularization and Generative Based\n  Continual Learning Models", "abstract": "Continual (or \"incremental\") learning approaches are employed when additional\nknowledge or tasks need to be learned from subsequent batches or from streaming\ndata. However these approaches are typically adversary agnostic, i.e., they do\nnot consider the possibility of a malicious attack. In our prior work, we\nexplored the vulnerabilities of Elastic Weight Consolidation (EWC) to the\nperceptible misinformation. We now explore the vulnerabilities of other\nregularization-based as well as generative replay-based continual learning\nalgorithms, and also extend the attack to imperceptible misinformation. We show\nthat an intelligent adversary can take advantage of a continual learning\nalgorithm's capabilities of retaining existing knowledge over time, and force\nit to learn and retain deliberately introduced misinformation. To demonstrate\nthis vulnerability, we inject backdoor attack samples into the training data.\nThese attack samples constitute the misinformation, allowing the attacker to\ncapture control of the model at test time. We evaluate the extent of this\nvulnerability on both rotated and split benchmark variants of the MNIST dataset\nunder two important domain and class incremental learning scenarios. We show\nthat the adversary can create a \"false memory\" about any task by inserting\ncarefully-designed backdoor samples to the test instances of that task thereby\ncontrolling the amount of forgetting of any task of its choosing. Perhaps most\nimportantly, we show this vulnerability to be very acute and damaging: the\nmodel memory can be easily compromised with the addition of backdoor samples\ninto as little as 1\\% of the training data, even when the misinformation is\nimperceptible to human eye.", "doi": "", "date": "2021-02-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.08355v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 90959907, "title": "Automatically applying a credibility appraisal tool to track\n  vaccination-related communications shared on social media", "abstract": "Background:\n  Tools used to appraise the credibility of health information are\ntime-consuming to apply and require context-specific expertise, limiting their\nuse for quickly identifying and mitigating the spread of misinformation as it\nemerges. Our aim was to estimate the proportion of vaccination-related posts on\nTwitter are likely to be misinformation, and how unevenly exposure to\nmisinformation was distributed among Twitter users.\n  Methods:\n  Sampling from 144,878 vaccination-related web pages shared on Twitter between\nJanuary 2017 and March 2018, we used a seven-point checklist adapted from two\nvalidated tools to appraise the credibility of a small subset of 474. These\nwere used to train several classifiers (random forest, support vector machines,\nand a recurrent neural network with transfer learning), using the text from a\nweb page to predict whether the information satisfies each of the seven\ncriteria.\n  Results:\n  Applying the best performing classifier to the 144,878 web pages, we found\nthat 14.4% of relevant posts to text-based communications were linked to\nwebpages of low credibility and made up 9.2% of all potential\nvaccination-related exposures. However, the 100 most popular links to\nmisinformation were potentially seen by between 2 million and 80 million\nTwitter users, and for a substantial sub-population of Twitter users engaging\nwith vaccination-related information, links to misinformation appear to\ndominate the vaccination-related information to which they were exposed.\n  Conclusions:\n  We proposed a new method for automatically appraising the credibility of\nwebpages based on a combination of validated checklist tools. The results\nsuggest that an automatic credibility appraisal tool can be used to find\npopulations at higher risk of exposure to misinformation or applied proactively\nto add friction to the sharing of low credibility vaccination information.", "doi": "10.2196/14007", "date": "2019-03-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.07219v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2149828467, "title": "Conspiracy vs science: A large-scale analysis of online discussion\n  cascades", "abstract": "With the emergence and rapid proliferation of social media platforms and\nsocial networking sites, recent years have witnessed a surge of misinformation\nspreading in our daily life. Drawing on a large-scale dataset which covers more\nthan 1.4M posts and 18M comments, we investigate the propagation of two\ndistinct narratives--(i) conspiracy information, whose claims are generally\nunsubstantiated and thus referred as misinformation to some extent, and (ii)\nscientific information, whose origins are generally readily identifiable and\nverifiable--in an online social media platform. We find that conspiracy\ncascades tend to propagate in a multigenerational branching process while\nscience cascades are more likely to grow in a breadth-first manner.\nSpecifically, conspiracy information triggers larger cascades, involves more\nusers and generations, persists longer, is more viral and bursty than science\ninformation. Content analysis reveals that conspiracy cascades contain more\nnegative words and emotional words which convey anger, fear, disgust, surprise\nand trust. We also find that conspiracy cascades are more concerned with\npolitical and controversial topics. After applying machine learning models, we\nachieve an AUC score of nearly 90% in discriminating conspiracy from science\nnarratives.\n  We find that conspiracy cascades are more likely to be controlled by a\nbroader set of users than science cascades, imposing new challenges on the\nmanagement of misinformation. Although political affinity is thought to affect\nthe consumption of misinformation, there is very little evidence that political\norientation of the information source plays a role during the propagation of\nconspiracy information. Our study provides complementing evidence to current\nmisinformation research and has practical policy implications to stem the\npropagation and mitigate the influence of misinformation online.", "doi": "10.1007/s11280-021-00862-x", "date": "2020-06-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.00765v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3147840973, "title": "Stochastic Models of Misinformation Distribution in Online Social\n  Networks", "abstract": "This report contains results of an experimental study of the distribution of\nmisinformation in online social networks (OSNs). We consider the classification\nof the topologies of OSNs and analyze the parameters identified in order to\nrelate the topology of a real network with one of the classes. We propose an\nalgorithm for conducting a search for the percolation cluster in the social\ngraph.", "doi": "", "date": "2012-12-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1212.1002v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1606922489, "title": "Trends in the Diffusion of Misinformation on Social Media", "abstract": "We measure trends in the diffusion of misinformation on Facebook and Twitter\nbetween January 2015 and July 2018. We focus on stories from 570 sites that\nhave been identified as producers of false stories. Interactions with these\nsites on both Facebook and Twitter rose steadily through the end of 2016.\nInteractions then fell sharply on Facebook while they continued to rise on\nTwitter, with the ratio of Facebook engagements to Twitter shares falling by\napproximately 60 percent. We see no similar pattern for other news, business,\nor culture sites, where interactions have been relatively stable over time and\nhave followed similar trends on the two platforms both before and after the\nelection.", "doi": "", "date": "2018-09-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.05901v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 479109114, "title": "The Age-related Differences in Web Information Search Process", "abstract": "Older adults' need for quality health information has never been more\ncritical as during the COVID-19 pandemic. Yet, they are susceptible to the\nwide-spread misinformation disseminated through search engines and social\nmedia. To build a search-related behavioral profile of older adults, this\narticle surveys the empirical research on age-related differences in query\nformulation, search strategies, information evaluation, and susceptibility to\nmisinformation effects. It also decomposes the mechanisms (i.e., cognitive\nchanges, development goal shift) and moderators (i.e., search task and\ninterface design) of such differences. To inform the design of information\nsystems to improve older adults' information search experience, we discuss\nopportunities for future research.", "doi": "", "date": "2020-10-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.13352v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3923193352, "title": "A Paragraph-level Multi-task Learning Model for Scientific\n  Fact-Verification", "abstract": "Even for domain experts, it is a non-trivial task to verify a scientific\nclaim by providing supporting or refuting evidence rationales. The situation\nworsens as misinformation is proliferated on social media or news websites,\nmanually or programmatically, at every moment. As a result, an automatic\nfact-verification tool becomes crucial for combating the spread of\nmisinformation. In this work, we propose a novel, paragraph-level, multi-task\nlearning model for the SciFact task by directly computing a sequence of\ncontextualized sentence embeddings from a BERT model and jointly training the\nmodel on rationale selection and stance prediction.", "doi": "", "date": "2020-12-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.14500v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 325820923, "title": "Helping People Deal With Disinformation -- A Socio-Technical Perspective", "abstract": "At the latest since the advent of the Internet, disinformation and conspiracy\ntheories have become ubiquitous. Recent examples like QAnon and Pizzagate prove\nthat false information can lead to real violence. In this motivation statement\nfor the Workshop on Human Aspects of Misinformation at CHI 2021, I explain my\nresearch agenda focused on 1. why people believe in disinformation, 2. how\npeople can be best supported in recognizing disinformation, and 3. what the\npotentials and risks of different tools designed to fight disinformation are.", "doi": "", "date": "2021-04-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.04311v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1388575608, "title": "Single-Leader-Multiple-Followers Stackelberg Security Game with\n  Hypergame Framework", "abstract": "In this paper, we employ a hypergame framework to analyze the\nsingle-leader-multiple-followers (SLMF) Stackelberg security game with two\ntypical misinformed situations: misperception and deception. We provide a\nstability criterion with the help of hyper Nash equilibrium (HNE) to analyze\nboth strategic stability and cognitive stability of equilibria in SLMF games\nwith misinformation. To this end, we find mild stable conditions such that the\nequilibria with misperception and deception can derive HNE. Moreover, we\nanalyze the robustness of the equilibria to reveal whether the players have the\nability to keep their profits.", "doi": "", "date": "2021-07-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.14625v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3007341276, "title": "Spread of Misinformation in Social Networks", "abstract": "We provide a model to investigate the tension between information aggregation\nand spread of misinformation in large societies (conceptualized as networks of\nagents communicating with each other). Each individual holds a belief\nrepresented by a scalar. Individuals meet pairwise and exchange information,\nwhich is modeled as both individuals adopting the average of their pre-meeting\nbeliefs. When all individuals engage in this type of information exchange, the\nsociety will be able to effectively aggregate the initial information held by\nall individuals. There is also the possibility of misinformation, however,\nbecause some of the individuals are \"forceful,\" meaning that they influence the\nbeliefs of (some) of the other individuals they meet, but do not change their\nown opinion. The paper characterizes how the presence of forceful agents\ninterferes with information aggregation. Under the assumption that even\nforceful agents obtain some information (however infrequent) from some others\n(and additional weak regularity conditions), we first show that beliefs in this\nclass of societies converge to a consensus among all individuals. This\nconsensus value is a random variable, however, and we characterize its\nbehavior. Our main results quantify the extent of misinformation in the society\nby either providing bounds or exact results (in some special cases) on how far\nthe consensus value can be from the benchmark without forceful agents (where\nthere is efficient information aggregation). The worst outcomes obtain when\nthere are several forceful agents and forceful agents themselves update their\nbeliefs only on the basis of information they obtain from individuals most\nlikely to have received their own information previously.", "doi": "", "date": "2009-06-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/0906.5007v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 595606034, "title": "The Fake News Spreading Plague: Was it Preventable?", "abstract": "In 2010, a paper entitled \"From Obscurity to Prominence in Minutes: Political\nSpeech and Real-time search\" won the Best Paper Prize of the Web Science 2010\nConference. Among its findings were the discovery and documentation of what was\ntermed a \"Twitter-bomb\", an organized effort to spread misinformation about the\ndemocratic candidate Martha Coakley through anonymous Twitter accounts. In this\npaper, after summarizing the details of that event, we outline the recipe of\nhow social networks are used to spread misinformation. One of the most\nimportant steps in such a recipe is the \"infiltration\" of a community of users\nwho are already engaged in conversations about a topic, to use them as organic\nspreaders of misinformation in their extended subnetworks. Then, we take this\nmisinformation spreading recipe and indicate how it was successfully used to\nspread fake news during the 2016 U.S. Presidential Election. The main\ndifferences between the scenarios are the use of Facebook instead of Twitter,\nand the respective motivations (in 2010: political influence; in 2016:\nfinancial benefit through online advertising). After situating these events in\nthe broader context of exploiting the Web, we seize this opportunity to address\nlimitations of the reach of research findings and to start a conversation about\nhow communities of researchers can increase their impact on real-world societal\nissues.", "doi": "", "date": "2017-03-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1703.06988v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2367808744, "title": "Facts and Fabrications about Ebola: A Twitter Based Study", "abstract": "Microblogging websites like Twitter have been shown to be immensely useful\nfor spreading information on a global scale within seconds. The detrimental\neffect, however, of such platforms is that misinformation and rumors are also\nas likely to spread on the network as credible, verified information. From a\npublic health standpoint, the spread of misinformation creates unnecessary\npanic for the public. We recently witnessed several such scenarios during the\noutbreak of Ebola in 2014 [14, 1]. In order to effectively counter the medical\nmisinformation in a timely manner, our goal here is to study the nature of such\nmisinformation and rumors in the United States during fall 2014 when a handful\nof Ebola cases were confirmed in North America. It is a well known convention\non Twitter to use hashtags to give context to a Twitter message (a tweet). In\nthis study, we collected approximately 47M tweets from the Twitter streaming\nAPI related to Ebola. Based on hashtags, we propose a method to classify the\ntweets into two sets: credible and speculative. We analyze these two sets and\nstudy how they differ in terms of a number of features extracted from the\nTwitter API. In conclusion, we infer several interesting differences between\nthe two sets. We outline further potential directions to using this material\nfor monitoring and separating speculative tweets from credible ones, to enable\nimproved public health information.", "doi": "", "date": "2015-08-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1508.02079v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 336018592, "title": "Emotion Cognizance Improves Health Fake News Identification", "abstract": "Identifying misinformation is increasingly being recognized as an important\ncomputational task with high potential social impact. Misinformation and fake\ncontents are injected into almost every domain of news including politics,\nhealth, science, business, etc., among which, the fakeness in health domain\npose serious adverse effects to scare or harm the society. Misinformation\ncontains scientific claims or content from social media exaggerated with strong\nemotion content to attract eyeballs. In this paper, we consider the utility of\nthe affective character of news articles for fake news identification in the\nhealth domain and present evidence that emotion cognizant representations are\nsignificantly more suited for the task. We outline a technique to leverage\nemotion intensity lexicons to develop emotionized text representations, and\nevaluate the utility of such a representation for identifying fake news\nrelating to health in various supervised and unsupervised scenarios. The\nconsistent and significant empirical gains that we observe over a range of\ntechnique types and parameter settings establish the utility of the emotional\ninformation in news articles, an often overlooked aspect, for the task of\nmisinformation identification in the health domain.", "doi": "", "date": "2019-06-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.10365v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2591210372, "title": "Can WhatsApp Counter Misinformation by Limiting Message Forwarding?", "abstract": "WhatsApp is the most popular messaging app in the world. The closed nature of\nthe app, in addition to the ease of transferring multimedia and sharing\ninformation to large-scale groups make WhatsApp unique among other platforms,\nwhere an anonymous encrypted messages can become viral, reaching multiple users\nin a short period of time. The personal feeling and immediacy of messages\ndirectly delivered to the user's phone on WhatsApp was extensively abused to\nspread unfounded rumors and create misinformation campaigns during recent\nelections in Brazil and India. WhatsApp has been deploying measures to mitigate\nthis problem, such as reducing the limit for forwarding a message to at most\nfive users at once. Despite the welcomed effort to counter the problem, there\nis no evidence so far on the real effectiveness of such restrictions. In this\nwork, we propose a methodology to evaluate the effectiveness of such measures\non the spreading of misinformation circulating on WhatsApp. We use an\nepidemiological model and real data gathered from WhatsApp in Brazil, India and\nIndonesia to assess the impact of limiting virality features in this kind of\nnetwork. Our results suggest that the current efforts deployed by WhatsApp can\noffer significant delays on the information spread, but they are ineffective in\nblocking the propagation of misinformation campaigns through public groups when\nthe content has a high viral nature.", "doi": "", "date": "2019-09-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.08740v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 699216372, "title": "Trustworthy Misinformation Mitigation with Soft Information Nudging", "abstract": "Research in combating misinformation reports many negative results: facts may\nnot change minds, especially if they come from sources that are not trusted.\nIndividuals can disregard and justify lies told by trusted sources. This\nproblem is made even worse by social recommendation algorithms which help\namplify conspiracy theories and information confirming one's own biases due to\ncompanies' efforts to optimize for clicks and watch time over individuals' own\nvalues and public good. As a result, more nuanced voices and facts are drowned\nout by a continuous erosion of trust in better information sources. Most\nmisinformation mitigation techniques assume that discrediting, filtering, or\ndemoting low veracity information will help news consumers make better\ninformation decisions. However, these negative results indicate that some news\nconsumers, particularly extreme or conspiracy news consumers will not be\nhelped.\n  We argue that, given this background, technology solutions to combating\nmisinformation should not simply seek facts or discredit bad news sources, but\ninstead use more subtle nudges towards better information consumption. Repeated\nexposure to such nudges can help promote trust in better information sources\nand also improve societal outcomes in the long run. In this article, we will\ntalk about technological solutions that can help us in developing such an\napproach, and introduce one such model called Trust Nudging.", "doi": "", "date": "2019-11-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.05825v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3713759163, "title": "Semi-Supervised Multi-aspect Detection of Misinformation using\n  Hierarchical Joint Decomposition", "abstract": "Distinguishing between misinformation and real information is one of the most\nchallenging problems in today's interconnected world. The vast majority of the\nstate-of-the-art in detecting misinformation is fully supervised, requiring a\nlarge number of high-quality human annotations. However, the availability of\nsuch annotations cannot be taken for granted, since it is very costly,\ntime-consuming, and challenging to do so in a way that keeps up with the\nproliferation of misinformation. In this work, we are interested in exploring\nscenarios where the number of annotations is limited. In such scenarios, we\ninvestigate how tapping on a diverse number of resources that characterize a\nnews article, henceforth referred to as \"aspects\" can compensate for the lack\nof labels. In particular, our contributions in this paper are twofold: 1) We\npropose the use of three different aspects: article content, context of social\nsharing behaviors, and host website/domain features, and 2) We introduce a\nprincipled tensor based embedding framework that combines all those aspects\neffectively. We propose HiJoD a 2-level decomposition pipeline which not only\noutperforms state-of-the-art methods with F1-scores of 74% and 81% on Twitter\nand Politifact datasets respectively but also is an order of magnitude faster\nthan similar ensemble approaches.", "doi": "", "date": "2020-05-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.04310v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1874452516, "title": "Threat from being Social: Vulnerability Analysis of Social Network\n  Coupled Smart Grid", "abstract": "Social Networks (SNs) have been gradually applied by utility companies as an\naddition to smart grid and are proved to be helpful in smoothing load curves\nand reducing energy usage. However, SNs also bring in new threats to smart\ngrid: misinformation in SNs may cause smart grid users to alter their demand,\nresulting in transmission line overloading and in turn leading to catastrophic\nimpact to the grid. In this paper, we discuss the interdependency in the social\nnetwork coupled smart grid and focus on its vulnerability. That is, how much\ncan the smart grid be damaged when misinformation related to it diffuses in\nSNs? To analytically study the problem, we propose the Misinformation Attack\nProblem in Social-Smart Grid (MAPSS) that identifies the top critical nodes in\nthe SN, such that the smart grid can be greatly damaged when misinformation\npropagates from those nodes. This problem is challenging as we have to\nincorporate the complexity of the two networks concurrently. Nevertheless, we\npropose a technique that can explicitly take into account information diffusion\nin SN, power flow balance and cascading failure in smart grid integratedly when\nevaluating node criticality, based on which we propose various strategies in\nselecting the most critical nodes. Also, we introduce controlled load shedding\nas a protection strategy to reduce the impact of cascading failure. The\neffectiveness of our algorithms are demonstrated by experiments on IEEE bus\ntest cases as well as the Pegase data set.", "doi": "10.1109/access.2017.2738565", "date": "2020-05-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.08705v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 361344377, "title": "Linked Credibility Reviews for Explainable Misinformation Detection", "abstract": "In recent years, misinformation on the Web has become increasingly rampant.\nThe research community has responded by proposing systems and challenges, which\nare beginning to be useful for (various subtasks of) detecting misinformation.\nHowever, most proposed systems are based on deep learning techniques which are\nfine-tuned to specific domains, are difficult to interpret and produce results\nwhich are not machine readable. This limits their applicability and adoption as\nthey can only be used by a select expert audience in very specific settings. In\nthis paper we propose an architecture based on a core concept of Credibility\nReviews (CRs) that can be used to build networks of distributed bots that\ncollaborate for misinformation detection. The CRs serve as building blocks to\ncompose graphs of (i) web content, (ii) existing credibility signals\n--fact-checked claims and reputation reviews of websites--, and (iii)\nautomatically computed reviews. We implement this architecture on top of\nlightweight extensions to Schema.org and services providing generic NLP tasks\nfor semantic similarity and stance detection. Evaluations on existing datasets\nof social-media posts, fake news and political speeches demonstrates several\nadvantages over existing systems: extensibility, domain-independence,\ncomposability, explainability and transparency via provenance. Furthermore, we\nobtain competitive results without requiring finetuning and establish a new\nstate of the art on the Clef'18 CheckThat! Factuality task.", "doi": "", "date": "2020-08-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.12742v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2343581164, "title": "Identifying Misinformation from Website Screenshots", "abstract": "Can the look and the feel of a website give information about the\ntrustworthiness of an article? In this paper, we propose to use a promising,\nyet neglected aspect in detecting the misinformativeness: the overall look of\nthe domain webpage. To capture this overall look, we take screenshots of news\narticles served by either misinformative or trustworthy web domains and\nleverage a tensor decomposition based semi-supervised classification technique.\nThe proposed approach i.e., VizFake is insensitive to a number of image\ntransformations such as converting the image to grayscale, vectorizing the\nimage and losing some parts of the screenshots. VizFake leverages a very small\namount of known labels, mirroring realistic and practical scenarios, where\nlabels (especially for known misinformative articles), are scarce and quickly\nbecome dated. The F1 score of VizFake on a dataset of 50k screenshots of news\narticles spanning more than 500 domains is roughly 85% using only 5% of ground\ntruth labels. Furthermore, tensor representations of VizFake, obtained in an\nunsupervised manner, allow for exploratory analysis of the data that provides\nvaluable insights into the problem. Finally, we compare VizFake with deep\ntransfer learning, since it is a very popular black-box approach for image\nclassification and also well-known text text-based methods. VizFake achieves\ncompetitive accuracy with deep transfer learning models while being two orders\nof magnitude faster and not requiring laborious hyper-parameter tuning.", "doi": "", "date": "2021-02-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.07849v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3082450491, "title": "Misinformation, Believability, and Vaccine Acceptance Over 40 Countries:\n  Takeaways From the Initial Phase of The COVID-19 Infodemic", "abstract": "The COVID-19 pandemic has been damaging to the lives of people all around the\nworld. Accompanied by the pandemic is an infodemic, an abundant and\nuncontrolled spreading of potentially harmful misinformation. The infodemic may\nseverely change the pandemic's course by interfering with public health\ninterventions such as wearing masks, social distancing, and vaccination. In\nparticular, the impact of the infodemic on vaccination is critical because it\nholds the key to reverting to pre-pandemic normalcy. This paper presents\nfindings from a global survey on the extent of worldwide exposure to the\nCOVID-19 infodemic, assesses different populations' susceptibility to false\nclaims, and analyzes its association with vaccine acceptance. Based on\nresponses gathered from over 18,400 individuals from 40 countries, we find a\nstrong association between perceived believability of misinformation and\nvaccination hesitancy. Additionally, our study shows that only half of the\nonline users exposed to rumors might have seen the fact-checked information.\nMoreover, depending on the country, between 6% and 37% of individuals\nconsidered these rumors believable. Our survey also shows that poorer regions\nare more susceptible to encountering and believing COVID-19 misinformation. We\ndiscuss implications of our findings on public campaigns that proactively\nspread accurate information to countries that are more susceptible to the\ninfodemic. We also highlight fact-checking platforms' role in better\nidentifying and prioritizing claims that are perceived to be believable and\nhave wide exposure. Our findings give insights into better handling of risk\ncommunication during the initial phase of a future pandemic.", "doi": "", "date": "2021-04-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.10864v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 523040250, "title": "Characterizing Abhorrent, Misinformative, and Mistargeted Content on\n  YouTube", "abstract": "YouTube has revolutionized the way people discover and consume video.\nAlthough YouTube facilitates easy access to hundreds of well-produced and\ntrustworthy videos, abhorrent, misinformative, and mistargeted content is also\ncommon. The platform is plagued by various types of problematic content: 1)\ndisturbing videos targeting young children; 2) hateful and misogynistic\ncontent; and 3) pseudoscientific misinformation. While YouTube's recommendation\nalgorithm plays a vital role in increasing user engagement and YouTube's\nmonetization, its role in unwittingly promoting problematic content is not\nentirely understood. In this thesis, we shed some light on the degree of\nproblematic content on YouTube and the role of the recommendation algorithm in\nthe dissemination of such content. Following a data-driven quantitative\napproach, we analyze thousands of videos on YouTube, to shed light on: 1) the\nrisks of YouTube media consumption by young children; 2) the role of the\nrecommendation algorithm in the dissemination of misogynistic content, by\nfocusing on the Involuntary Celibates (Incels) community; and 3) user exposure\nto pseudoscientific content on various parts of the platform and how this\nexposure changes based on the user's watch history. Our analysis reveals that\nyoung children are likely to encounter disturbing content when they randomly\nbrowse the platform. By analyzing the Incel community on YouTube, we find that\nIncel activity is increasing over time and that platforms may play an active\nrole in steering users towards extreme content. Finally, when studying\npseudoscientific misinformation, we find that YouTube suggests more\npseudoscientific content regarding traditional pseudoscientific topics (e.g.,\nflat earth) than for emerging ones (like COVID-19) and that these\nrecommendations are more common on the search results page than on a user's\nhomepage or the video recommendations section.", "doi": "", "date": "2021-05-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.09819v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4043606725, "title": "FauxWard: A Graph Neural Network Approach to Fauxtography Detection\n  Using Social Media Comments", "abstract": "Online social media has been a popular source for people to consume and share\nnews content. More recently, the spread of misinformation online has caused\nwidespread concerns. In this work, we focus on a critical task of detecting\nfauxtography on social media where the image and associated text together\nconvey misleading information. Many efforts have been made to mitigate\nmisinformation online, but we found that the fauxtography problem has not been\nfully addressed by existing work. Solutions focusing on detecting fake images\nor misinformed texts alone on social media often fail to identify the\nmisinformation delivered together by the image and the associated text of a\nfauxtography post. In this paper, we develop FauxWard, a novel graph\nconvolutional neural network framework that explicitly explores the complex\ninformation extracted from a user comment network of a social media post to\neffectively identify fauxtography. FauxWard is content-free in the sense that\nit does not analyze the visual or textual contents of the post itself, which\nmakes it robust against sophisticated fauxtography uploaders who intentionally\ncraft image-centric posts by editing either the text or image content. We\nevaluate FauxWard on two real-world datasets collected from mainstream social\nmedia platforms (i.e., Reddit and Twitter). The results show that FauxWard is\nboth effective and efficient in identifying fauxtography posts on social media.", "doi": "10.1007/s13278-020-00689-w", "date": "2021-06-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.11227v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1752406650, "title": "The coercive logic of fake news", "abstract": "The spread of misinformation and \"fake news\" continues to be a major focus of\npublic concern. A great deal of recent research has examined who falls for\nmisinformation and why, and what can be done to make people more discerning\nconsumers of news. Comparatively little work, however, has considered the\nchoices of those who produce misinformation, and how these choices interact\nwith the psychology of news consumers. Here we use game-theoretic models to\nstudy the strategic interaction between news publishers and news readers. We\nshow that publishers who seek to spread misinformation can generate high\nengagement with falsehoods by using strategies that mix true and false stories\nover time, in such a way that they serve more false stories to more loyal\nreaders. These coercive strategies cause false stories to receive higher reader\nengagement than true stories - even when readers strictly prefer truth over\nfalsehood. In contrast, publishers who seek to promote engagement with accurate\ninformation will use strategies that generate more engagement with true stories\nthan with false stories. We confirm these predictions empirically by examining\n1,000 headlines from 20 mainstream and 20 fake news sites, comparing Facebook\nengagement data with 20,000 perceived accuracy ratings collected in a survey\nexperiment. We then use our model to analyze possible ways to disincentivize\nfake news, finding that reducing the capacity of news sources to microtarget\nreaders, and increasing readers' level of attention, reduces the efficacy of\ncoercion. Finally, we show that if a publisher incorrectly assumes that readers\nprefer falsehoods, their resulting publication strategy can manufacture greater\nengagement with false news - leading to a self-reinforcing cycle of false news\npromotion.", "doi": "", "date": "2021-08-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.13687v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1804616189, "title": "On the statistical properties of viral misinformation in online social\n  media", "abstract": "The massive diffusion of online social media allows for the rapid and\nuncontrolled spreading of conspiracy theories, hoaxes, unsubstantiated claims,\nand false news. Such an impressive amount of misinformation can influence\npolicy preferences and encourage behaviors strongly divergent from recommended\npractices. In this paper, we study the statistical properties of viral\nmisinformation in online social media. By means of methods belonging to Extreme\nValue Theory, we show that the number of extremely viral posts over time\nfollows a homogeneous Poisson process, and that the interarrival times between\nsuch posts are independent and identically distributed, following an\nexponential distribution. Moreover, we characterize the uncertainty around the\nrate parameter of the Poisson process through Bayesian methods. Finally, we are\nable to derive the predictive posterior probability distribution of the number\nof posts exceeding a certain threshold of shares over a finite interval of\ntime.", "doi": "10.1016/j.physa.2016.11.012", "date": "2016-09-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1609.09435v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 759676494, "title": "Analytical model of misinformation of a social network node", "abstract": "This paper presents the research of the influence of cognitive, behavioral,\nrepresentational factors on the susceptibility of the participants in social\nnetworks to misinformation, as well as on the activity of the nodes in this\nregard. The importance of this research consists of method of blocking the\npropaganda. This is very important because when people involuntarily acquire\ninformation some of them experience an undesired change in their social\nattitude. Such phenomena typically lead towards the information warfare. A\nmodel was developed during this research for calculating the level of\nmisinformation of the social network participant (network node) based on the\nmodel of iterative learning process.", "doi": "", "date": "2012-12-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1212.0336v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1826197804, "title": "Misinformation spreading on Facebook", "abstract": "Social media are pervaded by unsubstantiated or untruthful rumors, that\ncontribute to the alarming phenomenon of misinformation. The widespread\npresence of a heterogeneous mass of information sources may affect the\nmechanisms behind the formation of public opinion. Such a scenario is a florid\nenvironment for digital wildfires when combined with functional illiteracy,\ninformation overload, and confirmation bias. In this essay, we focus on a\ncollection of works aiming at providing quantitative evidence about the\ncognitive determinants behind misinformation and rumor spreading. We account\nfor users' behavior with respect to two distinct narratives: a) conspiracy and\nb) scientific information sources. In particular, we analyze Facebook data on a\ntime span of five years in both the Italian and the US context, and measure\nusers' response to i) information consistent with one's narrative, ii) troll\ncontents, and iii) dissenting information e.g., debunking attempts. Our\nfindings suggest that users tend to a) join polarized communities sharing a\ncommon narrative (echo chambers), b) acquire information confirming their\nbeliefs (confirmation bias) even if containing false claims, and c) ignore\ndissenting information.", "doi": "", "date": "2017-06-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1706.09494v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 884242590, "title": "Informative and misinformative interactions in a school of fish", "abstract": "It is generally accepted that, when moving in groups, animals process\ninformation to coordinate their motion. Recent studies have begun to apply\nrigorous methods based on Information Theory to quantify such distributed\ncomputation. Following this perspective, we use transfer entropy to quantify\ndynamic information flows locally in space and time across a school of fish\nduring directional changes around a circular tank, i.e. U-turns. This analysis\nreveals peaks in information flows during collective U-turns and identifies two\ndifferent flows: an informative flow (positive transfer entropy) based on fish\nthat have already turned about fish that are turning, and a misinformative flow\n(negative transfer entropy) based on fish that have not turned yet about fish\nthat are turning. We also reveal that the information flows are related to\nrelative position and alignment between fish, and identify spatial patterns of\ninformation and misinformation cascades. This study offers several\nmethodological contributions and we expect further application of these\nmethodologies to reveal intricacies of self-organisation in other animal groups\nand active matter in general.", "doi": "", "date": "2017-05-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1705.01213v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2738686683, "title": "Fake Cures: User-centric Modeling of Health Misinformation in Social\n  Media", "abstract": "Social media's unfettered access has made it an important venue for health\ndiscussion and a resource for patients and their loved ones. However, the\nquality of the information available, as well as the motivations of its\nposters, has been questioned. This work examines the individuals on social\nmedia that are posting questionable health-related information, and in\nparticular promoting cancer treatments which have been shown to be ineffective\n(making it a kind of misinformation, willful or not). Using a multi-stage user\nselection process, we study 4,212 Twitter users who have posted about one of\n139 such \"treatments\", and compare them to a baseline of users generally\ninterested in cancer. Considering features capturing user attributes, writing\nstyle, and sentiment, we build a classifier which is able to identify users\nprone to propagate such misinformation at an accuracy of over 90%, providing a\npotential tool for public health officials to identify such individuals for\npreventive intervention.", "doi": "", "date": "2018-09-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.00557v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1862227625, "title": "Defending Elections Against Malicious Spread of Misinformation", "abstract": "The integrity of democratic elections depends on voters' access to accurate\ninformation. However, modern media environments, which are dominated by social\nmedia, provide malicious actors with unprecedented ability to manipulate\nelections via misinformation, such as fake news. We study a zero-sum game\nbetween an attacker, who attempts to subvert an election by propagating a fake\nnew story or other misinformation over a set of advertising channels, and a\ndefender who attempts to limit the attacker's impact. Computing an equilibrium\nin this game is challenging as even the pure strategy sets of players are\nexponential. Nevertheless, we give provable polynomial-time approximation\nalgorithms for computing the defender's minimax optimal strategy across a range\nof settings, encompassing different population structures as well as models of\nthe information available to each player. Experimental results confirm that our\nalgorithms provide near-optimal defender strategies and showcase variations in\nthe difficulty of defending elections depending on the resources and knowledge\navailable to the defender.", "doi": "", "date": "2018-09-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.05521v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3978188041, "title": "YouTube Chatter: Understanding Online Comments Discourse on\n  Misinformative and Political YouTube Videos", "abstract": "We conduct a preliminary analysis of comments on political YouTube content\ncontaining misinformation in comparison to comments on trustworthy or\napolitical videos, labelling the bias and factual ratings of our channels\naccording to Media Bias Fact Check where applicable. One of our most\ninteresting discoveries is that especially-polarized or misinformative\npolitical channels (Left-Bias, Right-Bias, PragerU, Conspiracy-Pseudoscience,\nand Questionable Source) generate 7.5x more comments per view and 10.42x more\nreplies per view than apolitical or Pro-Science channels; in particular,\nConspiracy-Pseudoscience and Questionable Sources generate 8.3x more comments\nper view and 11.0x more replies per view than apolitical and Pro-Science\nchannels. We also compared average thread lengths, average comment lengths, and\nprofanity rates across channels, and present simple machine learning\nclassifiers for predicting the bias category of a video based on these\nstatistics.", "doi": "", "date": "2019-06-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.00435v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4267901675, "title": "The Future of Misinformation Detection: New Perspectives and Trends", "abstract": "The massive spread of misinformation in social networks has become a global\nrisk, implicitly influencing public opinion and threatening social/political\ndevelopment. Misinformation detection (MID) has thus become a surging research\ntopic in recent years. As a promising and rapid developing research field, we\nfind that many efforts have been paid to new research problems and approaches\nof MID. Therefore, it is necessary to give a comprehensive review of the new\nresearch trends of MID. We first give a brief review of the literature history\nof MID, based on which we present several new research challenges and\ntechniques of it, including early detection, detection by multimodal data\nfusion, and explanatory detection. We further investigate the extraction and\nusage of various crowd intelligence in MID, which paves a promising way to\ntackle MID challenges. Finally, we give our own views on the open issues and\nfuture research directions of MID, such as model adaptivity/generality to new\nevents, embracing of novel machine learning models, explanatory detection\nmodels, and so on.", "doi": "", "date": "2019-09-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.03654v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1947246133, "title": "Warning Signs in Communicating the Machine Learning Detection Results of\n  Misinformation with Individuals", "abstract": "With the prevalence of misinformation online, researchers have focused on\ndeveloping various machine learning algorithms to detect fake news. However,\nusers' perception of machine learning outcomes and related behaviors have been\nwidely ignored. Hence, this paper proposed to bridge this gap by studying how\nto pass the detection results of machine learning to the users, and aid their\ndecisions in handling misinformation. An online experiment was conducted, to\nevaluate the effect of the proposed machine learning warning sign against a\ncontrol condition. We examined participants' detection and sharing of news. The\ndata showed that warning sign's effects on participants' trust toward the fake\nnews were not significant. However, we found that people's uncertainty about\nthe authenticity of the news dropped with the presence of the machine learning\nwarning sign. We also found that social media experience had effects on users'\ntrust toward the fake news, and age and social media experience had effects on\nusers' sharing decision. Therefore, the results indicate that there are many\nfactors worth studying that affect people's trust in the news. Moreover, the\nwarning sign in communicating machine learning detection results is different\nfrom ordinary warnings and needs more detailed research and design. These\nfindings hold important implications for the design of machine learning\nwarnings.", "doi": "", "date": "2019-11-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.11920v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1974247915, "title": "Why do People Share Misinformation during the COVID-19 Pandemic?", "abstract": "The World Health Organization have emphasised that misinformation - spreading\nrapidly through social media - poses a serious threat to the COVID-19 response.\nDrawing from theories of health perception and cognitive load, we develop and\ntest a research model hypothesizing why people share unverified COVID-19\ninformation through social media. Our findings suggest a person's trust in\nonline information and perceived information overload are strong predictors of\nunverified information sharing. Furthermore, these factors, along with a\nperson's perceived COVID-19 severity and vulnerability influence cyberchondria.\nFemales were significantly more likely to suffer from cyberchondria, however,\nmales were more likely to share news without fact checking their source. Our\nfindings suggest that to mitigate the spread of COVID-19 misinformation and\ncyberchondria, measures should be taken to enhance a healthy skepticism of\nhealth news while simultaneously guarding against information overload.", "doi": "10.1080/0960085x.2020.1770632", "date": "2020-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.09600v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1507020360, "title": "Where Are the Facts? Searching for Fact-checked Information to Alleviate\n  the Spread of Fake News", "abstract": "Although many fact-checking systems have been developed in academia and\nindustry, fake news is still proliferating on social media. These systems\nmostly focus on fact-checking but usually neglect online users who are the main\ndrivers of the spread of misinformation. How can we use fact-checked\ninformation to improve users' consciousness of fake news to which they are\nexposed? How can we stop users from spreading fake news? To tackle these\nquestions, we propose a novel framework to search for fact-checking articles,\nwhich address the content of an original tweet (that may contain\nmisinformation) posted by online users. The search can directly warn fake news\nposters and online users (e.g. the posters' followers) about misinformation,\ndiscourage them from spreading fake news, and scale up verified content on\nsocial media. Our framework uses both text and images to search for\nfact-checking articles, and achieves promising results on real-world datasets.\nOur code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.", "doi": "", "date": "2020-10-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.03159v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2375856394, "title": "Probabilistic Social Learning Improves the Public's Detection of\n  Misinformation", "abstract": "The digital spread of misinformation is one of the leading threats to\ndemocracy, public health, and the global economy. Popular strategies for\nmitigating misinformation include crowdsourcing, machine learning, and media\nliteracy programs that require social media users to classify news in binary\nterms as either true or false. However, research on peer influence suggests\nthat framing decisions in binary terms can amplify judgment errors and limit\nsocial learning, whereas framing decisions in probabilistic terms can reliably\nimprove judgments. In this preregistered experiment, we compare online peer\nnetworks that collaboratively evaluate the veracity of news by communicating\neither binary or probabilistic judgments. Exchanging probabilistic estimates of\nnews veracity substantially improved individual and group judgments, with the\neffect of eliminating polarization in news evaluation. By contrast, exchanging\nbinary classifications reduced social learning and entrenched polarization. The\nbenefits of probabilistic social learning are robust to participants'\neducation, gender, race, income, religion, and partisanship.", "doi": "10.1371/journal.pone.0247487", "date": "2020-10-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.06019v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 704972730, "title": "CHECKED: Chinese COVID-19 Fake News Dataset", "abstract": "COVID-19 has impacted all lives. To maintain social distancing and avoiding\nexposure, works and lives have gradually moved online. Under this trend, social\nmedia usage to obtain COVID-19 news has increased. Also, misinformation on\nCOVID-19 is frequently spread on social media. In this work, we develop\nCHECKED, the first Chinese dataset on COVID-19 misinformation. CHECKED provides\na total 2,104 verified microblogs related to COVID-19 from December 2019 to\nAugust 2020, identified by using a specific list of keywords. Correspondingly,\nCHECKED includes 1,868,175 reposts, 1,185,702 comments, and 56,852,736 likes\nthat reveal how these verified microblogs are spread and reacted on Weibo. The\ndataset contains a rich set of multimedia information for each microblog\nincluding ground-truth label, textual, visual, temporal, and network\ninformation. Extensive experiments have been conducted to analyze CHECKED data\nand to provide benchmark results for well-established methods when predicting\nfake news using CHECKED. We hope that CHECKED can facilitate studies that\ntarget misinformation on coronavirus. The dataset is available at\nhttps://github.com/cyang03/CHECKED.", "doi": "", "date": "2020-10-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.09029v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4082178080, "title": "Check Mate: Prioritizing User Generated Multi-Media Content for\n  Fact-Checking", "abstract": "Volume of content and misinformation on social media is rapidly increasing.\nThere is a need for systems that can support fact checkers by prioritizing\ncontent that needs to be fact checked. Prior research on prioritizing content\nfor fact-checking has focused on news media articles, predominantly in English\nlanguage. Increasingly, misinformation is found in user-generated content. In\nthis paper we present a novel dataset that can be used to prioritize\ncheck-worthy posts from multi-media content in Hindi. It is unique in its 1)\nfocus on user generated content, 2) language and 3) accommodation of\nmulti-modality in social media posts. In addition, we also provide metadata for\neach post such as number of shares and likes of the post on ShareChat, a\npopular Indian social media platform, that allows for correlative analysis\naround virality and misinformation. The data is accessible on Zenodo\n(https://zenodo.org/record/4032629) under Creative Commons Attribution License\n(CC BY 4.0).", "doi": "", "date": "2020-10-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.13387v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3550005490, "title": "Towards Combating Pandemic-related Misinformation in Social Media", "abstract": "Conventional preventive measures during pandemic include social distancing\nand lockdown. Such measures in the time of social media brought about a new set\nof challenges - vulnerability to the toxic impact of online misinformation is\nhigh. A case in point is the prevailing COVID-19; as the virus propagates, so\ndoes the associated misinformation and fake news about it leading to infodemic.\nSince the outbreak, there has been a surge of studies investigating various\naspects of the pandemic. Of interest to this chapter include studies centring\non datasets from online social media platforms where the bulk of the public\ndiscourse happen. Consequently, the main goal is to support the fight against\nnegative infodemic by (1) contributing a diverse set of curated relevant\ndatasets (2) recommending relevant areas to study using the datasets (3)\ndiscussion on how relevant datasets, strategies and state-of-the-art IT tools\ncan be leveraged in managing the pandemic.", "doi": "", "date": "2020-11-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.14146v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3211719312, "title": "Conspiracy Machines -- The Role of Social Bots during the COVID-19\n  Infodemic", "abstract": "The omnipresent COVID-19 pandemic gave rise to a parallel spreading of\nmisinformation, also referred to as an Infodemic. Consequently, social media\nhave become targets for the application of social bots, that is, algorithms\nthat mimic human behaviour. Their ability to exert influence on social media\ncan be exploited by amplifying misinformation, rumours, or conspiracy theories\nwhich might be harmful to society and the mastery of the pandemic. By applying\nsocial bot detection and content analysis techniques, this study aims to\ndetermine the extent to which social bots interfere with COVID- 19 discussions\non Twitter. A total of 78 presumptive bots were detected within a sample of\n542,345 users. The analysis revealed that bot-like users who disseminate\nmisinformation, at the same time, intersperse news from renowned sources. The\nfindings of this research provide implications for improved bot detection and\nmanaging potential threats through social bots during ongoing and future\ncrises.", "doi": "", "date": "2020-12-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.09536v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4031890545, "title": "The Fault in the Stars: Understanding the Underground Market of Amazon\n  Reviews", "abstract": "In recent times, the Internet has been plagued by a tremendous amount of\nmisinformation. Online markets such as Amazon are also not free from\nmisinformation. In this work, we study the misinformation propagated to\nconsumers through the form of Amazon reviews. There exists a vast underground\nmarket where reviews by real Amazon users are purchased and sold. While such a\npractice violates Amazon's terms of service, we observe that there exists a\ncomplex network consisting of thousands of sellers and agents, who provide a\nrebate to consumers for leaving positive reviews to over $5000$ products. Based\non interviews with members involved in the reviews market, we understand the\nworking of this market, and the tactics used to avoid detection by Amazon. We\nalso present a set of recommendations of features that Amazon and similar\nonline markets can take into consideration to detect such reviews.", "doi": "", "date": "2021-01-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.04217v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3826820957, "title": "Two Truths and a Lie: Exploring Soft Moderation of COVID-19\n  Misinformation with Amazon Alexa", "abstract": "In this paper, we analyzed the perceived accuracy of COVID-19 vaccine Tweets\nwhen they were spoken back by a third-party Amazon Alexa skill. We mimicked the\nsoft moderation that Twitter applies to COVID-19 misinformation content in both\nforms of warning covers and warning tags to investigate whether the third-party\nskill could affect how and when users heed these warnings. The results from a\n304-participant study suggest that the spoken back warning covers may not work\nas intended, even when converted from text to speech. We controlled for\nCOVID-19 vaccination hesitancy and political leanings and found that the\nvaccination hesitant Alexa users ignored any type of warning as long as the\nTweets align with their personal beliefs. The politically independent users\ntrusted Alexa less then their politically-laden counterparts and that helped\nthem accurately perceiving truthful COVID-19 information. We discuss soft\nmoderation adaptations for voice assistants to achieve the intended effect of\ncurbing COVID-19 misinformation.", "doi": "", "date": "2021-04-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.04077v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2797437843, "title": "Both Rates of Fake News and Fact-based News on Twitter Negatively\n  Correlate with the State-level COVID-19 Vaccine Uptake", "abstract": "There is evidence of misinformation in the online discourses and discussions\nabout the COVID-19 vaccines. Using a sample of 1.6 million geotagged English\ntweets and the data from the CDC COVID Data Tracker, we conduct a quantitative\nstudy to understand the influence of both misinformation and fact-based news on\nTwitter on the COVID-19 vaccine uptake in the U.S. from April 19 when U.S.\nadults were vaccine eligible to May 7, 2021, after controlling state-level\nfactors such as demographics, education, and the pandemic severity. We identify\nthe tweets related to either misinformation or fact-based news by analyzing the\nURLs. By analyzing the content of the most frequent tweets of these two groups,\nwe find that their structures are similar, making it difficult for Twitter\nusers to distinguish one from another by reading the text alone. The users who\nspread both fake news and fact-based news tend to show a negative attitude\ntowards the vaccines. We further conduct the Fama-MacBeth regression with the\nNewey-West adjustment to examine the effect of fake-news-related and\nfact-related tweets on the vaccination rate, and find marginally negative\ncorrelations.", "doi": "", "date": "2021-06-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.07435v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3578061101, "title": "Countering Misinformation on Social Media Through Educational\n  Interventions: Evidence from a Randomized Experiment in Pakistan", "abstract": "Fake news is a growing problem in developing countries with potentially\nfar-reaching consequences. We conduct a randomized experiment in urban Pakistan\nto evaluate the effectiveness of two educational interventions to counter\nmisinformation among low-digital literacy populations. We do not find a\nsignificant effect of video-based general educational messages about\nmisinformation. However, when such messages are augmented with personalized\nfeedback based on individuals' past engagement with fake news, we find an\nimprovement of 0.14 standard deviations in identifying fake news. We also find\nnegative but insignificant effects on identifying true news, driven by female\nrespondents. Our results suggest that educational interventions can enable\ninformation discernment but their effectiveness critically depends on how well\ntheir features and delivery are customized for the population of interest.", "doi": "", "date": "2021-07-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.02775v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1044246581, "title": "A Machine Learning Application for Raising WASH Awareness in the Times\n  of COVID-19 Pandemic", "abstract": "Background: The COVID-19 pandemic has uncovered the potential of digital\nmisinformation in shaping the health of nations. The deluge of unverified\ninformation that spreads faster than the epidemic itself is an unprecedented\nphenomenon that has put millions of lives in danger. Mitigating this Infodemic\nrequires strong health messaging systems that are engaging, vernacular,\nscalable, effective and continuously learn the new patterns of misinformation.\n  Objective: We created WashKaro, a multi-pronged intervention for mitigating\nmisinformation through conversational AI, machine translation and natural\nlanguage processing. WashKaro provides the right information matched against\nWHO guidelines through AI, and delivers it in the right format in local\nlanguages.\n  Methods: We theorize (i) an NLP based AI engine that could continuously\nincorporate user feedback to improve relevance of information, (ii) bite sized\naudio in the local language to improve penetrance in a country with skewed\ngender literacy ratios, and (iii) conversational but interactive AI engagement\nwith users towards an increased health awareness in the community. Results: A\ntotal of 5026 people who downloaded the app during the study window, among\nthose 1545 were active users. Our study shows that 3.4 times more females\nengaged with the App in Hindi as compared to males, the relevance of\nAI-filtered news content doubled within 45 days of continuous machine learning,\nand the prudence of integrated AI chatbot Satya increased thus proving the\nusefulness of an mHealth platform to mitigate health misinformation.\n  Conclusion: We conclude that a multi-pronged machine learning application\ndelivering vernacular bite-sized audios and conversational AI is an effective\napproach to mitigate health misinformation.", "doi": "", "date": "2020-03-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.07074v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1057288816, "title": "A Multiclass Mean-Field Game for Thwarting Misinformation Spread in the\n  Internet of Battlefield Things (IoBT)", "abstract": "In this paper, the problem of misinformation propagation is studied for an\nInternet of Battlefield Things (IoBT) system in which an attacker seeks to\ninject false information in the IoBT nodes in order to compromise the IoBT\noperations. In the considered model, each IoBT node seeks to counter the\nmisinformation attack by finding the optimal probability of accepting a given\ninformation that minimizes its cost at each time instant. The cost is expressed\nin terms of the quality of information received as well as the infection cost.\nThe problem is formulated as a mean-field game with multiclass agents which is\nsuitable to model a massive heterogeneous IoBT system. For this game, the\nmean-field equilibrium is characterized, and an algorithm based on the forward\nbackward sweep method is proposed to find the mean-field equilibrium. Then, the\nfinite IoBT case is considered, and the conditions of convergence of the Nash\nequilibria in the finite case to the mean-field equilibrium are presented.\nNumerical results show that the proposed scheme can achieve a 1.2-fold increase\nin the quality of information (QoI) compared to a baseline scheme in which the\nIoBT nodes are always transmitting. The results also show that the proposed\nscheme can reduce the proportion of infected nodes by 99% compared to the\nbaseline.", "doi": "", "date": "2018-01-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1802.06887v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 134993678, "title": "Viral Misinformation: The Role of Homophily and Polarization", "abstract": "The spreading of unsubstantiated rumors on online social networks (OSN)\neither unintentionally or intentionally (e.g., for political reasons or even\ntrolling) can have serious consequences such as in the recent case of rumors\nabout Ebola causing disruption to health-care workers. Here we show that\nindicators aimed at quantifying information consumption patterns might provide\nimportant insights about the virality of false claims. In particular, we\naddress the driving forces behind the popularity of contents by analyzing a\nsample of 1.2M Facebook Italian users consuming different (and opposite) types\nof information (science and conspiracy news). We show that users' engagement\nacross different contents correlates with the number of friends having similar\nconsumption patterns (homophily), indicating the area in the social network\nwhere certain types of contents are more likely to spread. Then, we test\ndiffusion patterns on an external sample of $4,709$ intentional satirical false\nclaims showing that neither the presence of hubs (structural properties) nor\nthe most active users (influencers) are prevalent in viral phenomena. Instead,\nwe found out that in an environment where misinformation is pervasive, users'\naggregation around shared beliefs may make the usual exposure to conspiracy\nstories (polarization) a determinant for the virality of false information.", "doi": "", "date": "2014-11-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1411.2893v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3330952186, "title": "The spread of low-credibility content by social bots", "abstract": "The massive spread of digital misinformation has been identified as a major\nglobal risk and has been alleged to influence elections and threaten\ndemocracies. Communication, cognitive, social, and computer scientists are\nengaged in efforts to study the complex causes for the viral diffusion of\nmisinformation online and to develop solutions, while search and social media\nplatforms are beginning to deploy countermeasures. With few exceptions, these\nefforts have been mainly informed by anecdotal evidence rather than systematic\ndata. Here we analyze 14 million messages spreading 400 thousand articles on\nTwitter during and following the 2016 U.S. presidential campaign and election.\nWe find evidence that social bots played a disproportionate role in amplifying\nlow-credibility content. Accounts that actively spread articles from\nlow-credibility sources are significantly more likely to be bots. Automated\naccounts are particularly active in amplifying content in the very early\nspreading moments, before an article goes viral. Bots also target users with\nmany followers through replies and mentions. Humans are vulnerable to this\nmanipulation, retweeting bots who post links to low-credibility content.\nSuccessful low-credibility sources are heavily supported by social bots. These\nresults suggest that curbing social bots may be an effective strategy for\nmitigating the spread of online misinformation.", "doi": "10.1038/s41467-018-06930-7", "date": "2017-07-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1707.07592v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1395610346, "title": "Twitter and Facebook posts about COVID-19 are less likely to spread\n  false and low-credibility content compared to other health topics", "abstract": "On February 2, 2020, the World Health Organization declared a COVID-19 social\nmedia \"infodemic\", with special attention to misinformation -- frequently\nunderstood as false claims. To understand the infodemic's scope and scale, we\nanalyzed over 500 million posts from Twitter and Facebook about COVID-19 and\nother health topics, between March 8 and May 1, 2020. Following prior work, we\nassumed URL source credibility is a proxy for false content, but we also tested\nthis assumption. Contrary to expectations, we found that messages about\nCOVID-19 were more likely to contain links to more credible sources.\nAdditionally, messages linking to government sources, and to news with\nintermediate credibility, were shared more often, on average, than links to\nnon-credible sources. These results suggest that more ambiguous forms of\nmisinformation about COVID-19 may be more likely to be disseminated through\ncredible sources when compared to other health topics. Furthermore, the\nassumption that credibility is an adequate proxy for false content may\noverestimate the prevalence of false content online: less than 25% of posts\nlinking to the least credible sources contained false content. Our results\nemphasize the importance of distinguishing between explicit falsehoods and more\nambiguous forms of misinformation due to the search for meaning in an\nenvironment of scientific uncertainty.", "doi": "", "date": "2020-07-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.09682v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2518568753, "title": "A curated collection of COVID-19 online datasets", "abstract": "One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data.", "doi": "", "date": "2020-07-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.09703v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2523937007, "title": "Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised\n  Learning Approach", "abstract": "Online Social Media (OSM) platforms such as Twitter, Facebook are extensively\nexploited by the users of these platforms for spreading the (mis)information to\na large audience effortlessly at a rapid pace. It has been observed that the\nmisinformation can cause panic, fear, and financial loss to society. Thus, it\nis important to detect and control the misinformation in such platforms before\nit spreads to the masses. In this work, we focus on rumors, which is one type\nof misinformation (other types are fake news, hoaxes, etc). One way to control\nthe spread of the rumors is by identifying users who are possibly the rumor\nspreaders, that is, users who are often involved in spreading the rumors. Due\nto the lack of availability of rumor spreaders labeled dataset (which is an\nexpensive task), we use publicly available PHEME dataset, which contains rumor\nand non-rumor tweets information, and then apply a weak supervised learning\napproach to transform the PHEME dataset into rumor spreaders dataset. We\nutilize three types of features, that is, user, text, and ego-network features,\nbefore applying various supervised learning approaches. In particular, to\nexploit the inherent network property in this dataset (user-user reply graph),\nwe explore Graph Convolutional Network (GCN), a type of Graph Neural Network\n(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and\nLSTM. Extensive experiments performed on the rumor spreaders dataset, where we\nachieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the\neffectiveness of our methodology for identifying possible rumor spreaders using\nthe GCN technique.", "doi": "", "date": "2020-10-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.07647v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 250185027, "title": "Challenges and Opportunities in Rapid Epidemic Information Propagation\n  with Live Knowledge Aggregation from Social Media", "abstract": "A rapidly evolving situation such as the COVID-19 pandemic is a significant\nchallenge for AI/ML models because of its unpredictability. %The most reliable\nindicator of the pandemic spreading has been the number of test positive cases.\nHowever, the tests are both incomplete (due to untested asymptomatic cases) and\nlate (due the lag from the initial contact event, worsening symptoms, and test\nresults). Social media can complement physical test data due to faster and\nhigher coverage, but they present a different challenge: significant amounts of\nnoise, misinformation and disinformation. We believe that social media can\nbecome good indicators of pandemic, provided two conditions are met. The first\n(True Novelty) is the capture of new, previously unknown, information from\nunpredictably evolving situations. The second (Fact vs. Fiction) is the\ndistinction of verifiable facts from misinformation and disinformation. Social\nmedia information that satisfy those two conditions are called live knowledge.\nWe apply evidence-based knowledge acquisition (EBKA) approach to collect,\nfilter, and update live knowledge through the integration of social media\nsources with authoritative sources. Although limited in quantity, the reliable\ntraining data from authoritative sources enable the filtering of misinformation\nas well as capturing truly new information. We describe the EDNA/LITMUS tools\nthat implement EBKA, integrating social media such as Twitter and Facebook with\nauthoritative sources such as WHO and CDC, creating and updating live knowledge\non the COVID-19 pandemic.", "doi": "", "date": "2020-11-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.05416v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4194081531, "title": "Mainstreaming of conspiracy theories and misinformation", "abstract": "Parents - particularly moms - increasingly consult social media for support\nwhen taking decisions about their young children, and likely also when advising\nother family members such as elderly relatives. Minimizing malignant online\ninfluences is therefore crucial to securing their assent for policies ranging\nfrom vaccinations, masks and social distancing against the pandemic, to\nhousehold best practices against climate change, to acceptance of future 5G\ntowers nearby. Here we show how a strengthening of bonds across online\ncommunities during the pandemic, has led to non-Covid-19 conspiracy theories\n(e.g. fluoride, chemtrails, 5G) attaining heightened access to mainstream\nparent communities. Alternative health communities act as the critical conduits\nbetween conspiracy theorists and parents, and make the narratives more\npalatable to the latter. We demonstrate experimentally that these\ninter-community bonds can perpetually generate new misinformation, irrespective\nof any changes in factual information. Our findings show explicitly why\nFacebook's current policies have failed to stop the mainstreaming of\nnon-Covid-19 and Covid-19 conspiracy theories and misinformation, and why\ntargeting the largest communities will not work. A simple yet exactly solvable\nand empirically grounded mathematical model, shows how modest tailoring of\nmainstream communities' couplings could prevent them from tipping against\nestablishment guidance. Our conclusions should also apply to other social media\nplatforms and topics.", "doi": "", "date": "2021-02-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.02382v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1853032834, "title": "COVID-19 Vaccine Hesitancy on Social Media: Building a Public Twitter\n  Dataset of Anti-vaccine Content, Vaccine Misinformation and Conspiracies", "abstract": "False claims about COVID-19 vaccines can undermine public trust in ongoing\nvaccination campaigns, thus posing a threat to global public health.\nMisinformation originating from various sources has been spreading online since\nthe beginning of the COVID-19 pandemic. In this paper, we present a dataset of\nTwitter posts that exhibit a strong anti-vaccine stance. The dataset consists\nof two parts: a) a streaming keyword-centered data collection with more than\n1.8 million tweets, and b) a historical account-level collection with more than\n135 million tweets. The former leverages the Twitter streaming API to follow a\nset of specific vaccine-related keywords starting from mid-October 2020. The\nlatter consists of all historical tweets of 70K accounts that were engaged in\nthe active spreading of anti-vaccine narratives. We present descriptive\nanalyses showing the volume of activity over time, geographical distributions,\ntopics, news sources, and inferred account political leaning. This dataset can\nbe used in studying anti-vaccine misinformation on social media and enable a\nbetter understanding of vaccine hesitancy. In compliance with Twitter's Terms\nof Service, our anonymized dataset is publicly available at:\nhttps://github.com/gmuric/avax-tweets-dataset", "doi": "", "date": "2021-05-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.05134v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 568362425, "title": "Piercing the Veil: Designs to Support Information Literacy on Social\n  Platforms", "abstract": "In this position paper we approach problems concerning critical digital and\ninformation literacy with ideas to provide more digestible explanations of\nabstract concepts through interface design. In particular, we focus on social\nmedia platforms where we see the possibility of counteracting the spread of\nmisinformation by providing users with more proficiency through our approaches.\nWe argue that the omnipresent trend to abstract away and hide information from\nusers via UI/UX design opposes their ability to self-learn. This leads us to\npropose a different framework in which we unify elegant and simple interfaces\nwith nudges that promote a look behind the curtain. Such designs serve to\nfoster a deeper understanding of employed technologies and aim to increase the\ncritical assessment of content encountered on social platforms. Furthermore, we\nconsider users with an intermediary skill level to be largely ignored in\ncurrent approaches, as they are given no tools to broaden their knowledge\nwithout consultation of expert material. The resulting stagnation is\nexemplified by the tactics of misinformation campaigns, which exploit the\nensuing lack of information literacy and critical thinking. We propose an\napproach to design that sufficiently emancipates users in both aspects by\npromoting a look behind the abstraction of UI/UX so that an autonomous learning\nprocess is given the chance to occur. Furthermore, we name ideas for future\nresearch within this area that take our considerations into account.", "doi": "", "date": "2021-06-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.01627v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1753892714, "title": "Italian Twitter semantic network during the Covid-19 epidemic", "abstract": "The Covid-19 pandemic has had a deep impact on the lives of the entire world\npopulation, inducing a participated societal debate. As in other contexts, the\ndebate has been the subject of several d/misinformation campaigns; in a quite\nunprecedented fashion, however, the presence of false information has seriously\nput at risk the public health. In this sense, detecting the presence of\nmalicious narratives and identifying the kinds of users that are more prone to\nspread them represent the first step to limit the persistence of the former\nones. In the present paper we analyse the semantic network observed on Twitter\nduring the first Italian lockdown (induced by the hashtags contained in\napproximately 1.5 millions tweets published between the 23rd of March 2020 and\nthe 23rd of April 2020) and study the extent to which various discursive\ncommunities are exposed to d/misinformation arguments. As observed in other\nstudies, the recovered discursive communities largely overlap with traditional\npolitical parties, even if the debated topics concern different facets of the\nmanagement of the pandemic. Although the themes directly related to\nd/misinformation are a minority of those discussed within our semantic\nnetworks, their popularity is unevenly distributed among the various discursive\ncommunities.", "doi": "", "date": "2021-06-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.05815v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3907811730, "title": "Building Knowledge Graphs About Political Agents in the Age of\n  Misinformation", "abstract": "This paper presents the construction of a Knowledge Graph about relations\nbetween agents in a political system. It discusses the main modeling\nchallenges, with emphasis on the issue of trust and provenance. Implementation\ndecisions are also presented", "doi": "", "date": "2019-01-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.11408v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3915563228, "title": "Flow of online misinformation during the peak of the COVID-19 pandemic\n  in Italy", "abstract": "The COVID-19 pandemic has impacted on every human activity and, because of\nthe urgency of finding the proper responses to such an unprecedented emergency,\nit generated a diffused societal debate. The online version of this discussion\nwas not exempted by the presence of d/misinformation campaigns, but differently\nfrom what already witnessed in other debates, the COVID-19 -- intentional or\nnot -- flow of false information put at severe risk the public health, reducing\nthe effectiveness of governments' countermeasures. In the present manuscript,\nwe study the effective impact of misinformation in the Italian societal debate\non Twitter during the pandemic, focusing on the various discursive communities.\nIn order to extract the discursive communities, we focus on verified users,\ni.e. accounts whose identity is officially certified by Twitter. We thus infer\nthe various discursive communities based on how verified users are perceived by\nstandard ones: if two verified accounts are considered as similar by non\nunverified ones, we link them in the network of certified accounts. We first\nobserve that, beside being a mostly scientific subject, the COVID-19 discussion\nshow a clear division in what results to be different political groups. At this\npoint, by using a commonly available fact-checking software (NewsGuard), we\nassess the reputation of the pieces of news exchanged. We filter the network of\nretweets (i.e. users re-broadcasting the same elementary piece of information,\nor tweet) from random noise and check the presence of messages displaying an\nurl. The impact of misinformation posts reaches the 22.1% in the right and\ncenter-right wing community and its contribution is even stronger in absolute\nnumbers, due to the activity of this group: 96% of all non reputable urls\nshared by political groups come from this community.", "doi": "", "date": "2020-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.01913v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2243931986, "title": "Fighting the COVID-19 Infodemic with a Holistic BERT Ensemble", "abstract": "This paper describes the TOKOFOU system, an ensemble model for misinformation\ndetection tasks based on six different transformer-based pre-trained encoders,\nimplemented in the context of the COVID-19 Infodemic Shared Task for English.\nWe fine tune each model on each of the task's questions and aggregate their\nprediction scores using a majority voting approach. TOKOFOU obtains an overall\nF1 score of 89.7%, ranking first.", "doi": "", "date": "2021-04-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.05745v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3858495194, "title": "Social Media, News and Political Information during the US Election: Was\n  Polarizing Content Concentrated in Swing States?", "abstract": "US voters shared large volumes of polarizing political news and information\nin the form of links to content from Russian, WikiLeaks and junk news sources.\nWas this low quality political information distributed evenly around the\ncountry, or concentrated in swing states and particular parts of the country?\nIn this data memo we apply a tested dictionary of sources about political news\nand information being shared over Twitter over a ten day period around the 2016\nPresidential Election. Using self-reported location information, we place a\nthird of users by state and create a simple index for the distribution of\npolarizing content around the country. We find that (1) nationally, Twitter\nusers got more misinformation, polarizing and conspiratorial content than\nprofessionally produced news. (2) Users in some states, however, shared more\npolarizing political news and information than users in other states. (3)\nAverage levels of misinformation were higher in swing states than in\nuncontested states, even when weighted for the relative size of the user\npopulation in each state. We conclude with some observations about the impact\nof strategically disseminated polarizing information on public life.", "doi": "", "date": "2018-02-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1802.03573v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2638734982, "title": "Probability Mass Exclusions and the Directed Components of Pointwise\n  Mutual Information", "abstract": "This paper examines how an event from one random variable provides pointwise\nmutual information about an event from another variable via probability mass\nexclusions. We start by introducing probability mass diagrams, which provide a\nvisual representation of how a prior distribution is transformed to a posterior\ndistribution through exclusions. With the aid of these diagrams, we identify\ntwo distinct types of probability mass exclusions---namely informative and\nmisinformative exclusions. Then, motivated by Fano's derivation of the\npointwise mutual information, we propose four postulates which aim to decompose\nthe pointwise mutual information into two separate informational components: a\nnon-negative term associated with the informative exclusion and a non-positive\nterm associated with the misinformative exclusions. This yields a novel\nderivation of a familiar decomposition of the pointwise mutual information into\nentropic components. We conclude by discussing the relevance of considering\ninformation in terms of probability mass exclusions to the ongoing effort to\ndecompose multivariate information.", "doi": "10.3390/e20110826", "date": "2018-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1801.09223v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2464997893, "title": "Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of\n  User Engagement and Challenges", "abstract": "Fake news and misinformation spread in developing countries as fast as they\ndo in developed countries with increasing penetration of the internet and\nsocial media. However, fighting misinformation is more difficult in developing\ncountries where resources and necessary technologies are scarce. This study\nprovides an understanding of the challenges various fact-checking initiatives\nface in three South Asian countries--Bangladesh, India, and Nepal. In-depth\ninterviews were conducted with senior editors of six fact-checking initiatives.\nChallenges identified include lack of resources, technologies, and political\npressure. An analysis of Facebook pages of these initiatives shows increasing\nuser engagement with their posts.", "doi": "", "date": "2018-11-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.01806v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2068336266, "title": "Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language", "abstract": "In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.", "doi": "", "date": "2019-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.02202v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3602648034, "title": "What Are People Tweeting about Zika? An Exploratory Study Concerning\n  Symptoms, Treatment, Transmission, and Prevention", "abstract": "The purpose of this study was to do a dataset distribution analysis, a\nclassification performance analysis, and a topical analysis concerning what\npeople are tweeting about four disease characteristics: symptoms, transmission,\nprevention, and treatment. A combination of natural language processing and\nmachine learning techniques were used to determine what people are tweeting\nabout Zika. Specifically, a two-stage classifier system was built to find\nrelevant tweets on Zika, and then categorize these into the four disease\ncategories. Tweets in each disease category were then examined using latent\ndirichlet allocation (LDA) to determine the five main tweet topics for each\ndisease characteristic. Results 1,234,605 tweets were collected. Tweets by\nmales and females were similar (28% and 23% respectively). The classifier\nperformed well on the training and test data for relevancy (F=0.87 and 0.99\nrespectively) and disease characteristics (F=0.79 and 0.90 respectively). Five\ntopics for each category were found and discussed with a focus on the symptoms\ncategory. Through this process, we demonstrate how misinformation can be\ndiscovered so that public health officials can respond to the tweets with\nmisinformation.", "doi": "", "date": "2017-01-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1701.07490v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4228587344, "title": "Agent Based Rumor Spreading in a scale-free network", "abstract": "In the last years, the study of rumor spreading on social networks produced a\nlot of interest among the scientific community, expecially due to the role of\nsocial networks in the last political events. The goal of this work is to\nreproduce real-like diffusions of information and misinformation in a\nscale-free network using a multi-agent-based model. The data concerning the\nvirtual spreading are easily obtainable, in particular the diffusion of\ninformation during the announcement for the discovery of the Higgs Boson on\nTwitter was recorded and investigated in detail. We made some assumptions on\nthe micro behavior of our agents and registered the effects in a statistical\nanalysis replying the real data diffusion. Then, we studied an hypotetical\nresponse to a misinformation diffusion adding debunking agents and trying to\nmodel a critic response from the agents using real data from a hoax regarding\nthe Occupy Wall Street movement. After tuning our model to reproduce these\nresults, we measured some network properties and proved the emergence of\nsubstantially separated structures like echochambers, independently from the\nnetwork size scale, i.e. with one hundred, one thousand and ten thousand\nagents.", "doi": "", "date": "2018-05-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1805.05999v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2343131615, "title": "A Topic-Agnostic Approach for Identifying Fake News Pages", "abstract": "Fake news and misinformation have been increasingly used to manipulate\npopular opinion and influence political processes. To better understand fake\nnews, how they are propagated, and how to counter their effect, it is necessary\nto first identify them. Recently, approaches have been proposed to\nautomatically classify articles as fake based on their content. An important\nchallenge for these approaches comes from the dynamic nature of news: as new\npolitical events are covered, topics and discourse constantly change and thus,\na classifier trained using content from articles published at a given time is\nlikely to become ineffective in the future. To address this challenge, we\npropose a topic-agnostic (TAG) classification strategy that uses linguistic and\nweb-markup features to identify fake news pages. We report experimental results\nusing multiple data sets which show that our approach attains high accuracy in\nthe identification of fake news, even as topics evolve over time.", "doi": "10.1145/3308560.3316739", "date": "2019-05-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.00957v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1530765210, "title": "Check-It: A Plugin for Detecting and Reducing the Spread of Fake News\n  and Misinformation on the Web", "abstract": "Over the past few years, we have been witnessing the rise of misinformation\non the Web. People fall victims of fake news during their daily lives and\nassist their further propagation knowingly and inadvertently. There have been\nmany initiatives that are trying to mitigate the damage caused by fake news,\nfocusing on signals from either domain flag-lists, online social networks or\nartificial intelligence. In this work, we present Check-It, a system that\ncombines, in an intelligent way, a variety of signals into a pipeline for fake\nnews identification. Check-It is developed as a web browser plugin with the\nobjective of efficient and timely fake news detection, respecting the user's\nprivacy. Experimental results show that Check-It is able to outperform the\nstate-of-the-art methods. On a dataset, consisting of 9 millions of articles\nlabeled as fake and real, Check-It obtains classification accuracies that\nexceed 99%.", "doi": "", "date": "2019-05-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.04260v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3102661362, "title": "Defending Against Model Stealing Attacks with Adaptive Misinformation", "abstract": "Deep Neural Networks (DNNs) are susceptible to model stealing attacks, which\nallows a data-limited adversary with no knowledge of the training dataset to\nclone the functionality of a target model, just by using black-box query\naccess. Such attacks are typically carried out by querying the target model\nusing inputs that are synthetically generated or sampled from a surrogate\ndataset to construct a labeled dataset. The adversary can use this labeled\ndataset to train a clone model, which achieves a classification accuracy\ncomparable to that of the target model. We propose \"Adaptive Misinformation\" to\ndefend against such model stealing attacks. We identify that all existing model\nstealing attacks invariably query the target model with Out-Of-Distribution\n(OOD) inputs. By selectively sending incorrect predictions for OOD queries, our\ndefense substantially degrades the accuracy of the attacker's clone model (by\nup to 40%), while minimally impacting the accuracy (<0.5%) for benign users.\nCompared to existing defenses, our defense has a significantly better security\nvs accuracy trade-off and incurs minimal computational overhead.", "doi": "", "date": "2019-11-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.07100v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2993353884, "title": "Rumor Detection and Classification for Twitter Data", "abstract": "With the pervasiveness of online media data as a source of information\nverifying the validity of this information is becoming even more important yet\nquite challenging. Rumors spread a large quantity of misinformation on\nmicroblogs. In this study we address two common issues within the context of\nmicroblog social media. First we detect rumors as a type of misinformation\npropagation and next we go beyond detection to perform the task of rumor\nclassification. WE explore the problem using a standard data set. We devise\nnovel features and study their impact on the task. We experiment with various\nlevels of preprocessing as a precursor of the classification as well as\ngrouping of features. We achieve and f-measure of over 0.82 in RDC task in\nmixed rumors data set and 84 percent in a single rumor data set using a\ntwo-step classification approach.", "doi": "", "date": "2019-11-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.08926v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1462029689, "title": "NELA-GT-2019: A Large Multi-Labelled News Dataset for The Study of\n  Misinformation in News Articles", "abstract": "In this paper, we present an updated version of the NELA-GT-2018 dataset\n(N{\\o}rregaard, Horne, and Adal{\\i} 2019), entitled NELA-GT-2019. NELA-GT-2019\ncontains 1.12M news articles from 260 sources collected between January 1st\n2019 and December 31st 2019. Just as with NELA-GT-2018, these sources come from\na wide range of mainstream news sources and alternative news sources. Included\nwith the dataset are source-level ground truth labels from 7 different\nassessment sites covering multiple dimensions of veracity. The NELA-GT-2019\ndataset can be found at: https://doi.org/10.7910/DVN/O7FWPO", "doi": "", "date": "2020-03-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.08444v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2717820776, "title": "Too Many Claims to Fact-Check: Prioritizing Political Claims Based on\n  Check-Worthiness", "abstract": "The massive amount of misinformation spreading on the Internet on a daily\nbasis has enormous negative impacts on societies. Therefore, we need automated\nsystems helping fact-checkers in the combat against misinformation. In this\npaper, we propose a model prioritizing the claims based on their\ncheck-worthiness. We use BERT model with additional features including\ndomain-specific controversial topics, word embeddings, and others. In our\nexperiments, we show that our proposed model outperforms all state-of-the-art\nmodels in both test collections of CLEF Check That! Lab in 2018 and 2019. We\nalso conduct a qualitative analysis to shed light-detecting check-worthy\nclaims. We suggest requesting rationales behind judgments are needed to\nunderstand subjective nature of the task and problematic labels.", "doi": "", "date": "2020-04-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.08166v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 602647854, "title": "BRENDA: Browser Extension for Fake News Detection", "abstract": "Misinformation such as fake news has drawn a lot of attention in recent\nyears. It has serious consequences on society, politics and economy. This has\nlead to a rise of manually fact-checking websites such as Snopes and\nPolitifact. However, the scale of misinformation limits their ability for\nverification. In this demonstration, we propose BRENDA a browser extension\nwhich can be used to automate the entire process of credibility assessments of\nfalse claims. Behind the scenes BRENDA uses a tested deep neural network\narchitecture to automatically identify fact check worthy claims and classifies\nas well as presents the result along with evidence to the user. Since BRENDA is\na browser extension, it facilities fast automated fact checking for the end\nuser without having to leave the Webpage.", "doi": "10.1145/3397271.3401396", "date": "2020-05-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.13270v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3816838345, "title": "Reducing Misinformation in Query Autocompletions", "abstract": "Query autocompletions help users of search engines to speed up their searches\nby recommending completions of partially typed queries in a drop down box.\nThese recommended query autocompletions are usually based on large logs of\nqueries that were previously entered by the search engine's users. Therefore,\nmisinformation entered -- either accidentally or purposely to manipulate the\nsearch engine -- might end up in the search engine's recommendations,\npotentially harming organizations, individuals, and groups of people. This\npaper proposes an alternative approach for generating query autocompletions by\nextracting anchor texts from a large web crawl, without the need to use query\nlogs. Our evaluation shows that even though query log autocompletions perform\nbetter for shorter queries, anchor text autocompletions outperform query log\nautocompletions for queries of 2 words or more.", "doi": "", "date": "2020-07-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.02620v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2858399130, "title": "Political audience diversity and news reliability in algorithmic ranking", "abstract": "Newsfeed algorithms frequently amplify misinformation and other low-quality\ncontent. How can social media platforms more effectively promote reliable\ninformation? Existing approaches are difficult to scale and vulnerable to\nmanipulation. In this paper, we propose using the political diversity of a\nwebsite's audience as a quality signal. Using news source reliability ratings\nfrom domain experts and web browsing data from a diverse sample of 6,890 U.S.\ncitizens, we first show that websites with more extreme and less politically\ndiverse audiences have lower journalistic standards. We then incorporate\naudience diversity into a standard collaborative filtering framework and show\nthat our improved algorithm increases the trustworthiness of websites suggested\nto users -- especially those who most frequently consume misinformation --\nwhile keeping recommendations relevant. These findings suggest that partisan\naudience diversity is a valuable signal of higher journalistic standards that\nshould be incorporated into algorithmic ranking decisions.", "doi": "", "date": "2020-07-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.08078v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1766668958, "title": "Not sure? Handling hesitancy of COVID-19 vaccines", "abstract": "From the moment the first COVID-19 vaccines are rolled out, there will need\nto be a large fraction of the global population ready in line. It is therefore\ncrucial to start managing the growing global hesitancy to any such COVID-19\nvaccine. The current approach of trying to convince the \"no\"s cannot work\nquickly enough, nor can the current policy of trying to find, remove and/or\nrebut all the individual pieces of COVID and vaccine misinformation. Instead,\nwe show how this can be done in a simpler way by moving away from chasing\nmisinformation content and focusing instead on managing the \"yes--no--not-sure\"\nhesitancy ecosystem.", "doi": "", "date": "2020-09-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.08413v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 975231414, "title": "COVID-19's (mis)information ecosystem on Twitter: How partisanship\n  boosts the spread of conspiracy narratives on German speaking Twitter", "abstract": "In late 2019, the gravest pandemic in a century began spreading across the\nworld. A state of uncertainty related to what has become known as SARS-CoV-2\nhas since fueled conspiracy narratives on social media about the origin,\ntransmission and medical treatment of and vaccination against the resulting\ndisease, COVID-19. Using social media intelligence to monitor and understand\nthe proliferation of conspiracy narratives is one way to analyze the\ndistribution of misinformation on the pandemic. We analyzed more than 9.5M\nGerman language tweets about COVID-19. The results show that only about 0.6% of\nall those tweets deal with conspiracy theory narratives. We also found that the\npolitical orientation of users correlates with the volume of content users\ncontribute to the dissemination of conspiracy narratives, implying that\npartisan communicators have a higher motivation to take part in conspiratorial\ndiscussions on Twitter. Finally, we showed that contrary to other studies,\nautomated accounts do not significantly influence the spread of misinformation\nin the German speaking Twitter sphere. They only represent about 1.31% of all\nconspiracy-related activities in our database.", "doi": "", "date": "2020-09-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.12905v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1320489378, "title": "StratLearner: Learning a Strategy for Misinformation Prevention in\n  Social Networks", "abstract": "Given a combinatorial optimization problem taking an input, can we learn a\nstrategy to solve it from the examples of input-solution pairs without knowing\nits objective function? In this paper, we consider such a setting and study the\nmisinformation prevention problem. Given the examples of attacker-protector\npairs, our goal is to learn a strategy to compute protectors against future\nattackers, without the need of knowing the underlying diffusion model. To this\nend, we design a structured prediction framework, where the main idea is to\nparameterize the scoring function using random features constructed through\ndistance functions on randomly sampled subgraphs, which leads to a kernelized\nscoring function with weights learnable via the large margin method. Evidenced\nby experiments, our method can produce near-optimal protectors without using\nany information of the diffusion model, and it outperforms other possible\ngraph-based and learning-based methods by an evident margin.", "doi": "", "date": "2020-09-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.14337v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4252966285, "title": "A Cross-lingual Natural Language Processing Framework for Infodemic\n  Management", "abstract": "The COVID-19 pandemic has put immense pressure on health systems which are\nfurther strained due to the misinformation surrounding it. Under such a\nsituation, providing the right information at the right time is crucial. There\nis a growing demand for the management of information spread using Artificial\nIntelligence. Hence, we have exploited the potential of Natural Language\nProcessing for identifying relevant information that needs to be disseminated\namongst the masses. In this work, we present a novel Cross-lingual Natural\nLanguage Processing framework to provide relevant information by matching daily\nnews with trusted guidelines from the World Health Organization. The proposed\npipeline deploys various techniques of NLP such as summarizers, word\nembeddings, and similarity metrics to provide users with news articles along\nwith a corresponding healthcare guideline. A total of 36 models were evaluated\nand a combination of LexRank based summarizer on Word2Vec embedding with Word\nMover distance metric outperformed all other models. This novel open-source\napproach can be used as a template for proactive dissemination of relevant\nhealthcare information in the midst of misinformation spread associated with\nepidemics.", "doi": "", "date": "2020-10-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.16357v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 701458016, "title": "TIB's Visual Analytics Group at MediaEval '20: Detecting Fake News on\n  Corona Virus and 5G Conspiracy", "abstract": "Fake news on social media has become a hot topic of research as it negatively\nimpacts the discourse of real news in the public. Specifically, the ongoing\nCOVID-19 pandemic has seen a rise of inaccurate and misleading information due\nto the surrounding controversies and unknown details at the beginning of the\npandemic. The FakeNews task at MediaEval 2020 tackles this problem by creating\na challenge to automatically detect tweets containing misinformation based on\ntext and structure from Twitter follower network. In this paper, we present a\nsimple approach that uses BERT embeddings and a shallow neural network for\nclassifying tweets using only text, and discuss our findings and limitations of\nthe approach in text-based misinformation detection.", "doi": "", "date": "2021-01-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.03529v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2004935997, "title": "Rihanna versus Bollywood: Twitter Influencers and the Indian Farmers'\n  Protest", "abstract": "A tweet from popular entertainer and businesswoman, Rihanna, bringing\nattention to farmers' protests around Delhi set off heightened activity on\nIndian social media. An immediate consequence was the weighing in by Indian\npoliticians, entertainers, media and other influencers on the issue. In this\npaper, we use data from Twitter and an archive of debunked misinformation\nstories to understand some of the patterns around influencer engagement with a\npolitical issue. We found that more followed influencers were less likely to\ncome out in support of the tweet. We also find that the later engagement of\nmajor influencers on the side of the government's position shows suggestion's\nof collusion. Irrespective of their position on the issue, influencers who\nengaged saw a significant rise in their following after their tweets. While a\nnumber of tweets thanked Rihanna for raising awareness on the issue, she was\nsystematically trolled on the grounds of her gender, race, nationality and\nreligion. Finally, we observed how misinformation existing prior to the tweet\nset up the grounds for alternative narratives that emerged.", "doi": "", "date": "2021-02-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.04031v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1366350386, "title": "The Deepfake Detection Dilemma: A Multistakeholder Exploration of\n  Adversarial Dynamics in Synthetic Media", "abstract": "Synthetic media detection technologies label media as either synthetic or\nnon-synthetic and are increasingly used by journalists, web platforms, and the\ngeneral public to identify misinformation and other forms of problematic\ncontent. As both well-resourced organizations and the non-technical general\npublic generate more sophisticated synthetic media, the capacity for purveyors\nof problematic content to adapt induces a \\newterm{detection dilemma}: as\ndetection practices become more accessible, they become more easily\ncircumvented. This paper describes how a multistakeholder cohort from academia,\ntechnology platforms, media entities, and civil society organizations active in\nsynthetic media detection and its socio-technical implications evaluates the\ndetection dilemma. Specifically, we offer an assessment of detection contexts\nand adversary capacities sourced from the broader, global AI and media\nintegrity community concerned with mitigating the spread of harmful synthetic\nmedia. A collection of personas illustrates the intersection between\nunsophisticated and highly-resourced sponsors of misinformation in the context\nof their technical capacities. This work concludes that there is no \"best\"\napproach to navigating the detector dilemma, but derives a set of implications\nfrom multistakeholder input to better inform detection process decisions and\npolicies, in practice.", "doi": "", "date": "2021-02-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.06109v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1971470245, "title": "KNH: Multi-View Modeling with K-Nearest Hyperplanes Graph for\n  Misinformation Detection", "abstract": "Graphs are one of the most efficacious structures for representing datapoints\nand their relations, and they have been largely exploited for different\napplications. Previously, the higher-order relations between the nodes have\nbeen modeled by a generalization of graphs known as hypergraphs. In\nhypergraphs, the edges are defined by a set of nodes i.e., hyperedges to\ndemonstrate the higher order relationships between the data. However, there is\nno explicit higher-order generalization for nodes themselves. In this work, we\nintroduce a novel generalization of graphs i.e., K-Nearest Hyperplanes graph\n(KNH) where the nodes are defined by higher order Euclidean subspaces for\nmulti-view modeling of the nodes. In fact, in KNH, nodes are hyperplanes or\nmore precisely m-flats instead of datapoints. We experimentally evaluate the\nKNH graph on two multi-aspect datasets for misinformation detection. The\nexperimental results suggest that multi-view modeling of articles using KNH\ngraph outperforms the classic KNN graph in terms of classification performance.", "doi": "", "date": "2021-02-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.07857v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2067170690, "title": "The Coronavirus is a Bioweapon: Analysing Coronavirus Fact-Checked\n  Stories", "abstract": "The 2020 coronavirus pandemic has heightened the need to flag\ncoronavirus-related misinformation, and fact-checking groups have taken to\nverifying misinformation on the Internet. We explore stories reported by\nfact-checking groups PolitiFact, Poynter and Snopes from January to June 2020,\ncharacterising them into six story clusters before then analyse time-series and\nstory validity trends and the level of agreement across sites. We further break\ndown the story clusters into more granular story types by proposing a unique\nautomated method with a BERT classifier, which can be used to classify diverse\nstory sources, in both fact-checked stories and tweets.", "doi": "", "date": "2021-04-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.01215v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2019176704, "title": "The Surprising Performance of Simple Baselines for Misinformation\n  Detection", "abstract": "As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.", "doi": "", "date": "2021-04-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.06952v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2765957619, "title": "Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021", "abstract": "On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.", "doi": "", "date": "2021-04-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13352v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1229799366, "title": "COVID-Fact: Fact Extraction and Verification of Real-World Claims on\n  COVID-19 Pandemic", "abstract": "We introduce a FEVER-like dataset COVID-Fact of $4,086$ claims concerning the\nCOVID-19 pandemic. The dataset contains claims, evidence for the claims, and\ncontradictory claims refuted by the evidence. Unlike previous approaches, we\nautomatically detect true claims and their source articles and then generate\ncounter-claims using automatic methods rather than employing human annotators.\nAlong with our constructed resource, we formally present the task of\nidentifying relevant evidence for the claims and verifying whether the evidence\nrefutes or supports a given claim. In addition to scientific claims, our data\ncontains simplified general claims from media sources, making it better suited\nfor detecting general misinformation regarding COVID-19. Our experiments\nindicate that COVID-Fact will provide a challenging testbed for the development\nof new systems and our approach will reduce the costs of building\ndomain-specific datasets for detecting misinformation.", "doi": "", "date": "2021-06-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.03794v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 248807508, "title": "MIND - Mainstream and Independent News Documents Corpus", "abstract": "This paper presents and characterizes MIND, a new Portuguese corpus comprised\nof different types of articles collected from online mainstream and alternative\nmedia sources, over a 10-month period. The articles in the corpus are organized\ninto five collections: facts, opinions, entertainment, satires, and conspiracy\ntheories. Throughout this paper, we explain how the data collection process was\nconducted, and present a set of linguistic metrics that allow us to perform a\npreliminary characterization of the texts included in the corpus. Also, we\ndeliver an analysis of the most frequent topics in the corpus, and discuss the\nmain differences and similarities among the collections considered. Finally, we\nenumerate some tasks and applications that could benefit from this corpus, in\nparticular the ones (in)directly related to misinformation detection. Overall,\nour contribution of a corpus and initial analysis are designed to support\nfuture exploratory news studies, and provide a better insight into\nmisinformation.", "doi": "", "date": "2021-08-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.06249v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2470493018, "title": "The Junk News Aggregator: Examining junk news posted on Facebook,\n  starting with the 2018 US Midterm Elections", "abstract": "In recent years, the phenomenon of online misinformation and junk news\ncirculating on social media has come to constitute an important and widespread\nproblem affecting public life online across the globe, particularly around\nimportant political events such as elections. At the same time, there have been\ncalls for more transparency around misinformation on social media platforms, as\nmany of the most popular social media platforms function as \"walled gardens,\"\nwhere it is impossible for researchers and the public to readily examine the\nscale and nature of misinformation activity as it unfolds on the platforms. In\norder to help address this, we present the Junk News Aggregator, a publicly\navailable interactive web tool, which allows anyone to examine, in near\nreal-time, all of the public content posted to Facebook by important junk news\nsources in the US. It allows the public to gain access to and examine the\nlatest articles posted on Facebook (the most popular social media platform in\nthe US and one where content is not readily accessible at scale from the open\nWeb), as well as organise them by time, news publisher, and keywords of\ninterest, and sort them based on all eight engagement metrics available on\nFacebook. Therefore, the Aggregator allows the public to gain insights on the\nvolume, content, key themes, and types and volumes of engagement received by\ncontent posted by junk news publishers, in near real-time, hence opening up and\noffering transparency in these activities as they unfold, at scale across the\ntop most popular junk news publishers. In this way, the Aggregator can help\nincrease transparency around the nature, volume, and engagement with junk news\non social media, and serve as a media literacy tool for the public.", "doi": "", "date": "2019-01-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.07920v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2195890936, "title": "Psychometric Analysis and Coupling of Emotions Between State Bulletins\n  and Twitter in India during COVID-19 Infodemic", "abstract": "COVID-19 infodemic has been spreading faster than the pandemic itself. The\nmisinformation riding upon the infodemic wave poses a major threat to people's\nhealth and governance systems. Since social media is the largest source of\ninformation, managing the infodemic not only requires mitigating of\nmisinformation but also an early understanding of psychological patterns\nresulting from it. During the COVID-19 crisis, Twitter alone has seen a sharp\n45% increase in the usage of its curated events page, and a 30% increase in its\ndirect messaging usage, since March 6th 2020. In this study, we analyze the\npsychometric impact and coupling of the COVID-19 infodemic with the official\nbulletins related to COVID-19 at the national and state level in India. We look\nat these two sources with a psycho-linguistic lens of emotions and quantified\nthe extent and coupling between the two. We modified path, a deep skip-gram\nbased open-sourced lexicon builder for effective capture of health-related\nemotions. We were then able to capture the time-evolution of health-related\nemotions in social media and official bulletins. An analysis of lead-lag\nrelationships between the time series of extracted emotions from official\nbulletins and social media using Granger's causality showed that state\nbulletins were leading the social media for some emotions such as Medical\nEmergency. Further insights that are potentially relevant for the policymaker\nand the communicators actively engaged in mitigating misinformation are also\ndiscussed. Our paper also introduces CoronaIndiaDataset2, the first social\nmedia based COVID-19 dataset at national and state levels from India with over\n5.6 million national and 2.6 million state-level tweets. Finally, we present\nour findings as COVibes, an interactive web application capturing psychometric\ninsights captured upon the CoronaIndiaDataset, both at a national and state\nlevel.", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.05513v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2243324242, "title": "Exploring Lightweight Interventions at Posting Time to Reduce the\n  Sharing of Misinformation on Social Media", "abstract": "When users on social media share content without considering its veracity,\nthey may unwittingly be spreading misinformation. In this work, we investigate\nthe design of lightweight interventions that nudge users to assess the accuracy\nof information as they share it. Such assessment may deter users from posting\nmisinformation in the first place, and their assessments may also provide\nuseful guidance to friends aiming to assess those posts themselves. In support\nof lightweight assessment, we first develop a taxonomy of the reasons why\npeople believe a news claim is or is not true; this taxonomy yields a checklist\nthat can be used at posting time. We conduct evaluations to demonstrate that\nthe checklist is an accurate and comprehensive encapsulation of people's\nfree-response rationales. In a second experiment, we study the effects of three\nbehavioral nudges -- 1) checkboxes indicating whether headings are accurate, 2)\ntagging reasons (from our taxonomy) that a post is accurate via a checklist and\n3) providing free-text rationales for why a headline is or is not accurate --\non people's intention of sharing the headline on social media. From an\nexperiment with 1668 participants, we find that both providing accuracy\nassessment and rationale reduce the sharing of false content. They also reduce\nthe sharing of true content, but to a lesser degree that yields an overall\ndecrease in the fraction of shared content that is false. Our findings have\nimplications for designing social media and news sharing platforms that draw\nfrom richer signals of content credibility contributed by users. In addition,\nour validated taxonomy can be used by platforms and researchers as a way to\ngather rationales in an easier fashion than free-response.", "doi": "10.1145/3449092", "date": "2021-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.11824v5", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1833834214, "title": "Cognitive Contagion: How to model (and potentially counter) the spread\n  of fake news", "abstract": "Understanding the spread of false or dangerous beliefs - so-called\nmis/disinformation - through a population has never seemed so urgent to many.\nNetwork science researchers have often taken a page from epidemiologists, and\nmodeled the spread of false beliefs as similar to how a disease spreads through\na social network. However, absent from those disease-inspired models is an\ninternal model of an individual's set of current beliefs, where cognitive\nscience has increasingly documented how the interaction between mental models\nand incoming messages seems to be crucially important for their adoption or\nrejection. We introduce a cognitive contagion model that combines a network\nscience approach with an internal cognitive model of the individual agents,\naffecting what they believe, and what they pass on. We show that the model,\neven with a very discrete and simplistic belief function to capture cognitive\ndissonance, both adds expressive power over existing disease-based contagion\nmodels, and qualitatively demonstrates the appropriate belief update phenomena\nat the individual level. Moreover, we situate our cognitive contagion model in\na larger public opinion diffusion model, which attempts to capture the role of\ninstitutions or media sources in belief diffusion - something that is often\nleft out. We conduct an analysis of the POD model with our simple cognitive\ndissonance-sensitive update function across various graph topologies and\ninstitutional messaging patterns. We demonstrate that population-level\naggregate outcomes of the model qualitatively match what has been reported in\nCOVID misinformation public opinion polls. The overall model sets up a\npreliminary framework with which social science misinformation researchers and\ncomputational opinion diffusion modelers can join forces to understand, and\nhopefully learn how to best counter, the spread of misinformation and\n\"alternative facts.\"", "doi": "", "date": "2021-07-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.02828v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3880061066, "title": "Self-Assembly of Information in Networks", "abstract": "We model self-assembly of information in networks to investigate necessary\nconditions for building a global perception of a system by local communication.\nOur approach is to let agents chat in a model system to self-organize distant\ncommunication-pathways. We demonstrate that simple local rules allow agents to\nbuild a perception of the system, that is robust to dynamical changes and\nmistakes. We find that messages are most effectively forwarded in the presence\nof hubs, while transmission in hub-free networks is more robust against\nmisinformation and failures.", "doi": "10.1209/epl/i2006-10064-2", "date": "2006-03-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/physics/0603218v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2123959733, "title": "Related Fact Checks: a tool for combating fake news", "abstract": "The emergence of \"Fake News\" and misinformation via online news and social\nmedia has spurred an interest in computational tools to combat this phenomenon.\nIn this paper we present a new \"Related Fact Checks\" service, which can help a\nreader critically evaluate an article and make a judgment on its veracity by\nbringing up fact checks that are relevant to the article. We describe the core\ntechnical problems that need to be solved in building a \"Related Fact Checks\"\nservice, and present results from an evaluation of an implementation.", "doi": "", "date": "2017-10-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.00715v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 53146396, "title": "Seeing Through Misinformation: A Framework for Identifying Fake Online\n  News", "abstract": "The fake news epidemic makes it imperative to develop a diagnostic framework\nthat is both parsimonious and valid to guide present and future efforts in fake\nnews detection. This paper represents one of the very first attempts to fill a\nvoid in the research on this topic. The LeSiE (Lexical Structure, Simplicity,\nEmotion) framework we created and validated allows lay people to identify\npotential fake news without the use of calculators or complex statistics by\nlooking out for three simple cues.", "doi": "", "date": "2018-03-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.03508v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1154122000, "title": "Demystifying Deception Technology:A Survey", "abstract": "Deception boosts security for systems and components by denial, deceit,\nmisinformation, camouflage and obfuscation. In this work an extensive overview\nof the deception technology environment is presented. Taxonomies, theoretical\nbackgrounds, psychological aspects as well as concepts, implementations, legal\naspects and ethics are discussed and compared.", "doi": "", "date": "2018-04-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.06196v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2287469081, "title": "Trust and Trustworthiness in Social Recommender Systems", "abstract": "The prevalence of misinformation on online social media has tangible\nempirical connections to increasing political polarization and partisan\nantipathy in the United States. Ranking algorithms for social recommendation\noften encode broad assumptions about network structure (like homophily) and\ngroup cognition (like, social action is largely imitative). Assumptions like\nthese can be na\\\"ive and exclusionary in the era of fake news and ideological\nuniformity towards the political poles. We examine these assumptions with aid\nfrom the user-centric framework of trustworthiness in social recommendation.\nThe constituent dimensions of trustworthiness (diversity, transparency,\nexplainability, disruption) highlight new opportunities for discouraging\ndogmatization and building decision-aware, transparent news recommender\nsystems.", "doi": "", "date": "2019-03-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.01780v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 599790588, "title": "NELA-GT-2018: A Large Multi-Labelled News Dataset for The Study of\n  Misinformation in News Articles", "abstract": "In this paper, we present a dataset of 713k articles collected between\n02/2018-11/2018. These articles are collected directly from 194 news and media\noutlets including mainstream, hyper-partisan, and conspiracy sources. We\nincorporate ground truth ratings of the sources from 8 different assessment\nsites covering multiple dimensions of veracity, including reliability, bias,\ntransparency, adherence to journalistic standards, and consumer trust. The\nNELA-GT-2018 dataset can be found at https://doi.org/10.7910/DVN/ULHLCB.", "doi": "", "date": "2019-04-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.01546v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1598392052, "title": "Multilingual Multimodal Digital Deception Detection and Disinformation\n  Spread across Social Platforms", "abstract": "Our main contribution in this work is novel results of multilingual models\nthat go beyond typical applications of rumor or misinformation detection in\nEnglish social news content to identify fine-grained classes of digital\ndeception across multiple languages (e.g. Russian, Spanish, etc.). In addition,\nwe present models for multimodal deception detection from images and text and\ndiscuss the limitations of image only and text only models. Finally, we\nelaborate on the ongoing work on measuring deceptive content (in particular\ndisinformation) spread across social platforms.", "doi": "", "date": "2019-09-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.05838v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4277480656, "title": "Text Similarity Using Word Embeddings to Classify Misinformation", "abstract": "Fake news is a growing problem in the last years, especially during\nelections. It's hard work to identify what is true and what is false among all\nthe user generated content that circulates every day. Technology can help with\nthat work and optimize the fact-checking process. In this work, we address the\nchallenge of finding similar content in order to be able to suggest to a\nfact-checker articles that could have been verified before and thus avoid that\nthe same information is verified more than once. This is especially important\nin collaborative approaches to fact-checking where members of large teams will\nnot know what content others have already fact-checked.", "doi": "", "date": "2020-03-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.06634v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2040975087, "title": "P-Values in a Post-Truth World", "abstract": "The role of statisticians in society is to provide tools, techniques, and\nguidance with regards to how much to trust data. This role is increasingly more\nimportant with more data and more misinformation than ever before. The American\nStatistical Association recently released two statements on p-values, and\nprovided four guiding principles. We evaluate their claims using these\nprinciples and find that they failed to adhere to them. In this age of\ndistrust, we have an opportunity to be role models of trustworthiness, and\nresponsibility to take it.", "doi": "", "date": "2020-07-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.03611v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2887820819, "title": "The Emerging Threats of Deepfake Attacks and Countermeasures", "abstract": "Deepfake technology (DT) has taken a new level of sophistication.\nCybercriminals now can manipulate sounds, images, and videos to defraud and\nmisinform individuals and businesses. This represents a growing threat to\ninternational institutions and individuals which needs to be addressed. This\npaper provides an overview of deepfakes, their benefits to society, and how DT\nworks. Highlights the threats that are presented by deepfakes to businesses,\npolitics, and judicial systems worldwide. Additionally, the paper will explore\npotential solutions to deepfakes and conclude with future research direction.", "doi": "10.13140/rg.2.2.23089.81762", "date": "2020-12-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.07989v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3514688412, "title": "How Misuse of Statistics Can Spread Misinformation: A Study of\n  Misrepresentation of COVID-19 Data", "abstract": "This paper investigates various ways in which a pandemic such as the novel\ncoronavirus, could be predicted using different mathematical models. It also\nstudies the various ways in which these models could be depicted using various\nvisualization techniques. This paper aims to present various statistical\ntechniques suggested by the Centres for Disease Control and Prevention in order\nto represent the epidemiological data. The main focus of this paper is to\nanalyse how epidemiological data or contagious diseases are theorized using any\navailable information and later may be presented wrongly by not following the\nguidelines, leading to inaccurate representation and interpretations of the\ncurrent scenario of the pandemic; with a special reference to the Indian\nSubcontinent.", "doi": "", "date": "2021-02-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.07198v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1677678114, "title": "Extractive and Abstractive Explanations for Fact-Checking and Evaluation\n  of News", "abstract": "In this paper, we explore the construction of natural language explanations\nfor news claims, with the goal of assisting fact-checking and news evaluation\napplications. We experiment with two methods: (1) an extractive method based on\nBiased TextRank -- a resource-effective unsupervised graph-based algorithm for\ncontent extraction; and (2) an abstractive method based on the GPT-2 language\nmodel. We perform comparative evaluations on two misinformation datasets in the\npolitical and health news domains, and find that the extractive method shows\nthe most promise.", "doi": "", "date": "2021-04-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.12918v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1871487019, "title": "Can the Wikipedia moderation model rescue the social marketplace of\n  ideas?", "abstract": "Facebook announced a community review program in December 2019 and Twitter\nlaunched a community-based platform to address misinformation, called\nBirdwatch, in January 2021. We provide an overview of the potential affordances\nof such community based approaches to content moderation based on past\nresearch. While our analysis generally supports a community-based approach to\ncontent moderation, it also warns against potential pitfalls, particularly when\nthe implementation of the new infrastructures does not promote diversity. We\ncall for more multidisciplinary research utilizing methods from complex systems\nstudies, behavioural sociology, and computational social science to advance the\nresearch on crowd-based content moderation.", "doi": "", "date": "2021-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13754v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 354168706, "title": "A Survey on Automated Fact-Checking", "abstract": "Fact-checking has become increasingly important due to the speed with which\nboth information and misinformation can spread in the modern media ecosystem.\nTherefore, researchers have been exploring how fact-checking can be automated,\nusing techniques based on natural language processing, machine learning,\nknowledge representation, and databases to automatically predict the veracity\nof claims. In this paper, we survey automated fact-checking stemming from\nnatural language processing, and discuss its connections to related tasks and\ndisciplines. In this process, we present an overview of existing datasets and\nmodels, aiming to unify the various definitions given and identify common\nconcepts. Finally, we highlight challenges for future research.", "doi": "", "date": "2021-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.11896v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3226702691, "title": "On the Influence of Twitter Trolls during the 2016 US Presidential\n  Election", "abstract": "It is a widely accepted fact that state-sponsored Twitter accounts operated\nduring the 2016 US presidential election spreading millions of tweets with\nmisinformation and inflammatory political content. Whether these social media\ncampaigns of the so-called \"troll\" accounts were able to manipulate public\nopinion is still in question. Here we aim to quantify the influence of troll\naccounts and the impact they had on Twitter by analyzing 152.5 million tweets\nfrom 9.9 million users, including 822 troll accounts. The data collected during\nthe US election campaign, contain original troll tweets before they were\ndeleted by Twitter. From these data, we constructed a very large interaction\ngraph; a directed graph of 9.3 million nodes and 169.9 million edges. Recently,\nTwitter released datasets on the misinformation campaigns of 8,275\nstate-sponsored accounts linked to Russia, Iran and Venezuela as part of the\ninvestigation on the foreign interference in the 2016 US election. These data\nserve as ground-truth identifier of troll users in our dataset. Using graph\nanalysis techniques we qualify the diffusion cascades of web and media context\nthat have been shared by the troll accounts. We present strong evidence that\nauthentic users were the source of the viral cascades. Although the trolls were\nparticipating in the viral cascades, they did not have a leading role in them\nand only four troll accounts were truly influential.", "doi": "", "date": "2019-10-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.00531v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 272996882, "title": "A Machine Learning Analysis of the Features in Deceptive and Credible\n  News", "abstract": "Fake news is a type of pervasive propaganda that spreads misinformation\nonline, taking advantage of social media's extensive reach to manipulate public\nperception. Over the past three years, fake news has become a focal discussion\npoint in the media due to its impact on the 2016 U.S. presidential election.\nFake news can have severe real-world implications: in 2016, a man walked into a\npizzeria carrying a rifle because he read that Hillary Clinton was harboring\nchildren as sex slaves. This project presents a high accuracy (87%) machine\nlearning classifier that determines the validity of news based on the word\ndistributions and specific linguistic and stylistic differences in the first\nfew sentences of an article. This can help readers identify the validity of an\narticle by looking for specific features in the opening lines aiding them in\nmaking informed decisions. Using a dataset of 2,107 articles from 30 different\nwebsites, this project establishes an understanding of the variations between\nfake and credible news by examining the model, dataset, and features. This\nclassifier appears to use the differences in word distribution, levels of tone\nauthenticity, and frequency of adverbs, adjectives, and nouns. The\ndifferentiation in the features of these articles can be used to improve future\nclassifiers. This classifier can also be further applied directly to browsers\nas a Google Chrome extension or as a filter for social media outlets or news\nwebsites to reduce the spread of misinformation.", "doi": "", "date": "2019-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.02223v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3993308270, "title": "Catching Zika Fever: Application of Crowdsourcing and Machine Learning\n  for Tracking Health Misinformation on Twitter", "abstract": "In February 2016, World Health Organization declared the Zika outbreak a\nPublic Health Emergency of International Concern. With developing evidence it\ncan cause birth defects, and the Summer Olympics coming up in the worst\naffected country, Brazil, the virus caught fire on social media. In this work,\nuse Zika as a case study in building a tool for tracking the misinformation\naround health concerns on Twitter. We collect more than 13 million tweets --\nspanning the initial reports in February 2016 and the Summer Olympics --\nregarding the Zika outbreak and track rumors outlined by the World Health\nOrganization and Snopes fact checking website. The tool pipeline, which\nincorporates health professionals, crowdsourcing, and machine learning, allows\nus to capture health-related rumors around the world, as well as clarification\ncampaigns by reputable health organizations. In the case of Zika, we discover\nan extremely bursty behavior of rumor-related topics, and show that, once the\nquestionable topic is detected, it is possible to identify rumor-bearing tweets\nusing automated techniques. Thus, we illustrate insights the proposed tools\nprovide into potentially harmful information on social media, allowing public\nhealth researchers and practitioners to respond with a targeted and timely\naction.", "doi": "", "date": "2017-07-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1707.03778v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3599046312, "title": "Characterizing the public perception of WhatsApp through the lens of\n  media", "abstract": "WhatsApp is, as of 2018, a significant component of the global information\nand communication infrastructure, especially in developing countries. However,\nprobably due to its strong end-to-end encryption, WhatsApp became an attractive\nplace for the dissemination of misinformation, extremism and other forms of\nundesirable behavior. In this paper, we investigate the public perception of\nWhatsApp through the lens of media. We analyze two large datasets of news and\nshow the kind of content that is being associated with WhatsApp in different\nregions of the world and over time. Our analyses include the examination of\nnamed entities, general vocabulary, and topics addressed in news articles that\nmention WhatsApp, as well as the polarity of these texts. Among other results,\nwe demonstrate that the vocabulary and topics around the term \"whatsapp\" in the\nmedia have been changing over the years and in 2018 concentrate on matters\nrelated to misinformation, politics and criminal scams. More generally, our\nfindings are useful to understand the impact that tools like WhatsApp play in\nthe contemporary society and how they are seen by the communities themselves.", "doi": "", "date": "2018-08-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.05927v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2100870460, "title": "Propagation from Deceptive News Sources: Who Shares, How Much, How\n  Evenly, and How Quickly?", "abstract": "As people rely on social media as their primary sources of news, the spread\nof misinformation has become a significant concern. In this large-scale study\nof news in social media we analyze eleven million posts and investigate\npropagation behavior of users that directly interact with news accounts\nidentified as spreading trusted versus malicious content. Unlike previous work,\nwhich looks at specific rumors, topics, or events, we consider all content\npropagated by various news sources. Moreover, we analyze and contrast\npopulation versus sub-population behaviour (by demographics) when spreading\nmisinformation, and distinguish between two types of propagation, i.e., direct\nretweets and mentions. Our evaluation examines how evenly, how many, how\nquickly, and which users propagate content from various types of news sources\non Twitter.\n  Our analysis has identified several key differences in propagation behavior\nfrom trusted versus suspicious news sources. These include high inequity in the\ndiffusion rate based on the source of disinformation, with a small group of\nhighly active users responsible for the majority of disinformation spread\noverall and within each demographic. Analysis by demographics showed that users\nwith lower annual income and education share more from disinformation sources\ncompared to their counterparts. News content is shared significantly more\nquickly from trusted, conspiracy, and disinformation sources compared to\nclickbait and propaganda. Older users propagate news from trusted sources more\nquickly than younger users, but they share from suspicious sources after longer\ndelays. Finally, users who interact with clickbait and conspiracy sources are\nlikely to share from propaganda accounts, but not the other way around.", "doi": "10.1109/tcss.2018.2881071", "date": "2018-12-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.03533v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2659291944, "title": "A blockchain based Secure and Trusted framework for Information\n  Propagation on Online Social Networks", "abstract": "The online social networks facilitate naturally for the users to share\ninformation. On these platforms, each user shares information based on his or\nher interests. The particular information being shared by a user may be\nlegitimate or fake. Sometimes a misinformation, propagated by users and group\ncan create chaos or in some cases, might leads to cases of riots. Nowadays the\nthird party like ALT news and Cobrapost check the information authenticity, but\nit takes too much time to validate the news. Therefore, a robust and new system\nis required to check the information authenticity within the network, to stop\nthe propagation of misinformation. In this paper, we propose a blockchain based\nframework for sharing the information securely at the peer level. In the\nblockchain model, a chain is created by combining blocks of information. Each\nnode of network propagates the information based on its credibility to its peer\nnodes. The credibility of a node will vary according to the respective\ninformation. Trust is calculated between sender and receiver in two ways:(i)\nLocal trust used for sharing information at the peer level and (ii) global\ntrust is used for a credibility check of each user in the network. We evaluate\nour framework using real dataset derived from Facebook. Our approach achieves\nan accuracy of 83% which shows the effectiveness of our proposed framework.", "doi": "10.1007/s13278-021-00754-y", "date": "2018-12-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.10508v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3743423723, "title": "Consequential Ranking Algorithms and Long-term Welfare", "abstract": "Ranking models are typically designed to provide rankings that optimize some\nmeasure of immediate utility to the users. As a result, they have been unable\nto anticipate an increasing number of undesirable long-term consequences of\ntheir proposed rankings, from fueling the spread of misinformation and\nincreasing polarization to degrading social discourse. Can we design ranking\nmodels that understand the consequences of their proposed rankings and, more\nimportantly, are able to avoid the undesirable ones? In this paper, we first\nintroduce a joint representation of rankings and user dynamics using Markov\ndecision processes. Then, we show that this representation greatly simplifies\nthe construction of consequential ranking models that trade off the immediate\nutility and the long-term welfare. In particular, we can obtain optimal\nconsequential rankings just by applying weighted sampling on the rankings\nprovided by models that maximize measures of immediate utility. However, in\npractice, such a strategy may be inefficient and impractical, specially in high\ndimensional scenarios. To overcome this, we introduce an efficient\ngradient-based algorithm to learn parameterized consequential ranking models\nthat effectively approximate optimal ones. We showcase our methodology using\nsynthetic and real data gathered from Reddit and show that ranking models\nderived using our methodology provide ranks that may mitigate the spread of\nmisinformation and improve the civility of online discussions.", "doi": "", "date": "2019-05-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.05305v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 686000257, "title": "A Data Set of Internet Claims and Comparison of their Sentiments with\n  Credibility", "abstract": "In this modern era, communication has become faster and easier. This means\nfallacious information can spread as fast as reality. Considering the damage\nthat fake news kindles on the psychology of people and the fact that such news\nproliferates faster than truth, we need to study the phenomenon that helps\nspread fake news. An unbiased data set that depends on reality for rating news\nis necessary to construct predictive models for its classification. This paper\ndescribes the methodology to create such a data set. We collect our data from\nsnopes.com which is a fact-checking organization. Furthermore, we intend to\ncreate this data set not only for classification of the news but also to find\npatterns that reason the intent behind misinformation. We also formally define\nan Internet Claim, its credibility, and the sentiment behind such a claim. We\ntry to realize the relationship between the sentiment of a claim with its\ncredibility. This relationship pours light on the bigger picture behind the\npropagation of misinformation. We pave the way for further research based on\nthe methodology described in this paper to create the data set and usage of\npredictive modeling along with research-based on psychology/mentality of people\nto understand why fake news spreads much faster than reality.", "doi": "", "date": "2019-11-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.10130v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3218219695, "title": "A Feature-Driven Approach for Identifying Pathogenic Social Media\n  Accounts", "abstract": "Over the past few years, we have observed different media outlets' attempts\nto shift public opinion by framing information to support a narrative that\nfacilitate their goals. Malicious users referred to as \"pathogenic social\nmedia\" (PSM) accounts are more likely to amplify this phenomena by spreading\nmisinformation to viral proportions. Understanding the spread of misinformation\nfrom account-level perspective is thus a pressing problem. In this work, we aim\nto present a feature-driven approach to detect PSM accounts in social media.\nInspired by the literature, we set out to assess PSMs from three broad\nperspectives: (1) user-related information (e.g., user activity, profile\ncharacteristics), (2) source-related information (i.e., information linked via\nURLs shared by users) and (3) content-related information (e.g., tweets\ncharacteristics). For the user-related information, we investigate malicious\nsignals using causality analysis (i.e., if user is frequently a cause of viral\ncascades) and profile characteristics (e.g., number of followers, etc.). For\nthe source-related information, we explore various malicious properties linked\nto URLs (e.g., URL address, content of the associated website, etc.). Finally,\nfor the content-related information, we examine attributes (e.g., number of\nhashtags, suspicious hashtags, etc.) from tweets posted by users. Experiments\non real-world Twitter data from different countries demonstrate the\neffectiveness of the proposed approach in identifying PSM users.", "doi": "", "date": "2020-01-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.04624v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2149777218, "title": "Information Credibility in the Social Web: Contexts, Approaches, and\n  Open Issues", "abstract": "In the Social Web scenario, large amounts of User-Generated Content (UGC) are\ndiffused through social media often without almost any form of traditional\ntrusted intermediaries. Therefore, the risk of running into misinformation is\nnot negligible. For this reason, assessing and mining the credibility of online\ninformation constitutes nowadays a fundamental research issue. Credibility,\nalso referred as believability, is a quality perceived by individuals, who are\nnot always able to discern, with their own cognitive capacities, genuine\ninformation from fake one. Hence, in the last years, several approaches have\nbeen proposed to automatically assess credibility in social media. Many of them\nare based on data-driven models, i.e., they employ machine learning techniques\nto identify misinformation, but recently also model-driven approaches are\nemerging, as well as graph-based approaches focusing on credibility\npropagation, and knowledge-based ones exploiting Semantic Web technologies.\nThree of the main contexts in which the assessment of information credibility\nhas been investigated concern: (i) the detection of opinion spam in review\nsites, (ii) the detection of fake news in microblogging, and (iii) the\ncredibility assessment of online health-related information. In this article,\nthe main issues connected to the evaluation of information credibility in the\nSocial Web, which are shared by the above-mentioned contexts, are discussed. A\nconcise survey of the approaches and methodologies that have been proposed in\nrecent years to address these issues is also presented.", "doi": "", "date": "2020-01-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.09473v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 423642822, "title": "Targeted Forgetting and False Memory Formation in Continual Learners\n  through Adversarial Backdoor Attacks", "abstract": "Artificial neural networks are well-known to be susceptible to catastrophic\nforgetting when continually learning from sequences of tasks. Various continual\n(or \"incremental\") learning approaches have been proposed to avoid catastrophic\nforgetting, but they are typically adversary agnostic, i.e., they do not\nconsider the possibility of a malicious attack. In this effort, we explore the\nvulnerability of Elastic Weight Consolidation (EWC), a popular continual\nlearning algorithm for avoiding catastrophic forgetting. We show that an\nintelligent adversary can bypass the EWC's defenses, and instead cause gradual\nand deliberate forgetting by introducing small amounts of misinformation to the\nmodel during training. We demonstrate such an adversary's ability to assume\ncontrol of the model via injection of \"backdoor\" attack samples on both\npermuted and split benchmark variants of the MNIST dataset. Importantly, once\nthe model has learned the adversarial misinformation, the adversary can then\ncontrol the amount of forgetting of any task. Equivalently, the malicious actor\ncan create a \"false memory\" about any task by inserting carefully-designed\nbackdoor samples to any fraction of the test instances of that task. Perhaps\nmost damaging, we show this vulnerability to be very acute; neural network\nmemory can be easily compromised with the addition of backdoor samples into as\nlittle as 1% of the training data of even a single task.", "doi": "", "date": "2020-02-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.07111v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1229093304, "title": "Exploring the Role of Visual Content in Fake News Detection", "abstract": "The increasing popularity of social media promotes the proliferation of fake\nnews, which has caused significant negative societal effects. Therefore, fake\nnews detection on social media has recently become an emerging research area of\ngreat concern. With the development of multimedia technology, fake news\nattempts to utilize multimedia content with images or videos to attract and\nmislead consumers for rapid dissemination, which makes visual content an\nimportant part of fake news. Despite the importance of visual content, our\nunderstanding of the role of visual content in fake news detection is still\nlimited. This chapter presents a comprehensive review of the visual content in\nfake news, including the basic concepts, effective visual features,\nrepresentative detection methods and challenging issues of multimedia fake news\ndetection. This chapter can help readers to understand the role of visual\ncontent in fake news detection, and effectively utilize visual content to\nassist in detecting multimedia fake news.", "doi": "10.1007/978-3-030-42699-6", "date": "2020-03-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.05096v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2332691177, "title": "Network disruption: maximizing disagreement and polarization in social\n  networks", "abstract": "Recent years have seen a marked increase in the spread of misinformation, a\nphenomenon which has been accelerated and amplified by social media such as\nFacebook and Twitter. While some actors spread misinformation to push a\nspecific agenda, it has also been widely documented that others aim to simply\ndisrupt the network by increasing disagreement and polarization across the\nnetwork and thereby destabilizing society. Popular social networks are also\nvulnerable to large-scale attacks. Motivated by this reality, we introduce a\nsimple model of network disruption where an adversary can take over a limited\nnumber of user profiles in a social network with the aim of maximizing\ndisagreement and/or polarization in the network.\n  We investigate this model both theoretically and empirically. We show that\nthe adversary will always change the opinion of a taken-over profile to an\nextreme in order to maximize disruption. We also prove that an adversary can\nincrease disagreement / polarization at most linearly in the number of user\nprofiles it takes over. Furthermore, we present a detailed empirical study of\nseveral natural algorithms for the adversary on both synthetic networks and\nreal world (Reddit and Twitter) data sets. These show that even simple,\nunsophisticated heuristics, such as targeting centrists, can disrupt a network\neffectively, causing a large increase in disagreement / polarization. Studying\nthe problem of network disruption through the lens of an adversary thus\nhighlights the seriousness of the problem.", "doi": "", "date": "2020-03-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.08377v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1439420188, "title": "BaitWatcher: A lightweight web interface for the detection of\n  incongruent news headlines", "abstract": "In digital environments where substantial amounts of information are shared\nonline, news headlines play essential roles in the selection and diffusion of\nnews articles. Some news articles attract audience attention by showing\nexaggerated or misleading headlines. This study addresses the \\textit{headline\nincongruity} problem, in which a news headline makes claims that are either\nunrelated or opposite to the contents of the corresponding article. We present\n\\textit{BaitWatcher}, which is a lightweight web interface that guides readers\nin estimating the likelihood of incongruence in news articles before clicking\non the headlines. BaitWatcher utilizes a hierarchical recurrent encoder that\nefficiently learns complex textual representations of a news headline and its\nassociated body text. For training the model, we construct a million scale\ndataset of news articles, which we also release for broader research use. Based\non the results of a focus group interview, we discuss the importance of\ndeveloping an interpretable AI agent for the design of a better interface for\nmitigating the effects of online misinformation.", "doi": "10.1007/978-3-030-42699-6", "date": "2020-03-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.11459v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2971176555, "title": "Characterizing Sociolinguistic Variation in the Competing Vaccination\n  Communities", "abstract": "Public health practitioners and policy makers grapple with the challenge of\ndevising effective message-based interventions for debunking public health\nmisinformation in cyber communities. \"Framing\" and \"personalization\" of the\nmessage is one of the key features for devising a persuasive messaging\nstrategy. For an effective health communication, it is imperative to focus on\n\"preference-based framing\" where the preferences of the target sub-community\nare taken into consideration. To achieve that, it is important to understand\nand hence characterize the target sub-communities in terms of their social\ninteractions. In the context of health-related misinformation, vaccination\nremains to be the most prevalent topic of discord. Hence, in this paper, we\nconduct a sociolinguistic analysis of the two competing vaccination communities\non Twitter: \"pro-vaxxers\" or individuals who believe in the effectiveness of\nvaccinations, and \"anti-vaxxers\" or individuals who are opposed to\nvaccinations. Our data analysis show significant linguistic variation between\nthe two communities in terms of their usage of linguistic intensifiers,\npronouns, and uncertainty words. Our network-level analysis show significant\ndifferences between the two communities in terms of their network density,\necho-chamberness, and the EI index. We hypothesize that these sociolinguistic\ndifferences can be used as proxies to characterize and understand these\ncommunities to devise better message interventions.", "doi": "", "date": "2020-06-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.04334v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1077276239, "title": "Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms", "abstract": "With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.", "doi": "", "date": "2020-07-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.07996v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2884521432, "title": "SGG: Spinbot, Grammarly and GloVe based Fake News Detection", "abstract": "Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.", "doi": "", "date": "2020-08-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.06854v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 456582535, "title": "Investigating Differences in Crowdsourced News Credibility Assessment:\n  Raters, Tasks, and Expert Criteria", "abstract": "Misinformation about critical issues such as climate change and vaccine\nsafety is oftentimes amplified on online social and search platforms. The\ncrowdsourcing of content credibility assessment by laypeople has been proposed\nas one strategy to combat misinformation by attempting to replicate the\nassessments of experts at scale. In this work, we investigate news credibility\nassessments by crowds versus experts to understand when and how ratings between\nthem differ. We gather a dataset of over 4,000 credibility assessments taken\nfrom 2 crowd groups---journalism students and Upwork workers---as well as 2\nexpert groups---journalists and scientists---on a varied set of 50 news\narticles related to climate science, a topic with widespread disconnect between\npublic opinion and expert consensus. Examining the ratings, we find differences\nin performance due to the makeup of the crowd, such as rater demographics and\npolitical leaning, as well as the scope of the tasks that the crowd is assigned\nto rate, such as the genre of the article and partisanship of the publication.\nFinally, we find differences between expert assessments due to differing expert\ncriteria that journalism versus science experts use---differences that may\ncontribute to crowd discrepancies, but that also suggest a way to reduce the\ngap by designing crowd tasks tailored to specific expert criteria. From these\nfindings, we outline future research directions to better design crowd\nprocesses that are tailored to specific crowds and types of content.", "doi": "10.1145/3415164", "date": "2020-08-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.09533v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1852971266, "title": "Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models", "abstract": "While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.", "doi": "", "date": "2020-09-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.02931v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 741310448, "title": "\"It is just a flu\": Assessing the Effect of Watch History on YouTube's\n  Pseudoscientific Video Recommendations", "abstract": "The role played by YouTube's recommendation algorithm in unwittingly\npromoting misinformation and conspiracy theories is not entirely understood.\nYet, this can have dire real-world consequences, especially when\npseudoscientific content is promoted to users at critical times, such as the\nCOVID-19 pandemic. In this paper, we set out to characterize and detect\npseudoscientific misinformation on YouTube. We collect 6.6K videos related to\nCOVID-19, the Flat Earth theory, as well as the anti-vaccination and anti-mask\nmovements. Using crowdsourcing, we annotate them as pseudoscience, legitimate\nscience, or irrelevant and train a deep learning classifier to detect\npseudoscientific videos with an accuracy of 0.79.\n  We quantify user exposure to this content on various parts of the platform\nand how this exposure changes based on the user's watch history. We find that\nYouTube suggests more pseudoscientific content regarding traditional\npseudoscientific topics (e.g., flat earth, anti-vaccination) than for emerging\nones (like COVID-19). At the same time, these recommendations are more common\non the search results page than on a user's homepage or in the recommendation\nsection when actively watching videos. Finally, we shed light on how a user's\nwatch history substantially affects the type of recommended videos.", "doi": "", "date": "2020-10-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.11638v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 394441329, "title": "The COVID-19 Infodemic: Twitter versus Facebook", "abstract": "The global spread of the novel coronavirus is affected by the spread of\nrelated misinformation -- the so-called COVID-19 Infodemic -- that makes\npopulations more vulnerable to the disease through resistance to mitigation\nefforts. Here we analyze the prevalence and diffusion of links to\nlow-credibility content about the pandemic across two major social media\nplatforms, Twitter and Facebook. We characterize cross-platform similarities\nand differences in popular sources, diffusion patterns, influencers,\ncoordination, and automation. Comparing the two platforms, we find divergence\namong the prevalence of popular low-credibility sources and suspicious videos.\nA minority of accounts and pages exert a strong influence on each platform.\nThese misinformation \"superspreaders\" are often associated with the\nlow-credibility sources and tend to be verified by the platforms. On both\nplatforms, there is evidence of coordinated sharing of Infodemic content. The\novert nature of this manipulation points to the need for societal-level\nsolutions in addition to mitigation strategies within the platforms. However,\nwe highlight limits imposed by inconsistent data-access policies on our\ncapability to study harmful manipulations of information ecosystems.", "doi": "", "date": "2020-12-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.09353v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3954653402, "title": "Detecting Medical Misinformation on Social Media Using Multimodal Deep\n  Learning", "abstract": "In 2019, outbreaks of vaccine-preventable diseases reached the highest number\nin the US since 1992. Medical misinformation, such as antivaccine content\npropagating through social media, is associated with increases in vaccine delay\nand refusal. Our overall goal is to develop an automatic detector for\nantivaccine messages to counteract the negative impact that antivaccine\nmessages have on the public health. Very few extant detection systems have\nconsidered multimodality of social media posts (images, texts, and hashtags),\nand instead focus on textual components, despite the rapid growth of\nphoto-sharing applications (e.g., Instagram). As a result, existing systems are\nnot sufficient for detecting antivaccine messages with heavy visual components\n(e.g., images) posted on these newer platforms. To solve this problem, we\npropose a deep learning network that leverages both visual and textual\ninformation. A new semantic- and task-level attention mechanism was created to\nhelp our model to focus on the essential contents of a post that signal\nantivaccine messages. The proposed model, which consists of three branches, can\ngenerate comprehensive fused features for predictions. Moreover, an ensemble\nmethod is proposed to further improve the final prediction accuracy. To\nevaluate the proposed model's performance, a real-world social media dataset\nthat consists of more than 30,000 samples was collected from Instagram between\nJanuary 2016 and October 2019. Our 30 experiment results demonstrate that the\nfinal network achieves above 97% testing accuracy and outperforms other\nrelevant models, demonstrating that it can detect a large amount of antivaccine\nmessages posted daily. The implementation code is available at\nhttps://github.com/wzhings/antivaccine_detection.", "doi": "", "date": "2020-12-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.13968v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2803771738, "title": "Cross-SEAN: A Cross-Stitch Semi-Supervised Neural Attention Model for\n  COVID-19 Fake News Detection", "abstract": "As the COVID-19 pandemic sweeps across the world, it has been accompanied by\na tsunami of fake news and misinformation on social media. At the time when\nreliable information is vital for public health and safety, COVID-19 related\nfake news has been spreading even faster than the facts. During times such as\nthe COVID-19 pandemic, fake news can not only cause intellectual confusion but\ncan also place lives of people at risk. This calls for an immediate need to\ncontain the spread of such misinformation on social media. We introduce CTF,\nthe first COVID-19 Twitter fake news dataset with labeled genuine and fake\ntweets. Additionally, we propose Cross-SEAN, a cross-stitch based\nsemi-supervised end-to-end neural attention model, which leverages the large\namount of unlabelled data. Cross-SEAN partially generalises to emerging fake\nnews as it learns from relevant external knowledge. We compare Cross-SEAN with\nseven state-of-the-art fake news detection methods. We observe that it achieves\n$0.95$ F1 Score on CTF, outperforming the best baseline by $9\\%$. We also\ndevelop Chrome-SEAN, a Cross-SEAN based chrome extension for real-time\ndetection of fake tweets.", "doi": "", "date": "2021-02-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.08924v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 235588216, "title": "A Survey on Multimodal Disinformation Detection", "abstract": "Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.", "doi": "", "date": "2021-03-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.12541v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 998074582, "title": "Community-Based Fact-Checking on Twitter's Birdwatch Platform", "abstract": "Misinformation undermines the credibility of social media and poses\nsignificant threats to modern societies. As a countermeasure, Twitter has\nrecently introduced \"Birdwatch,\" a community-driven approach to address\nmisinformation on Twitter. On Birdwatch, users can identify tweets they believe\nare misleading, write notes that provide context to the tweet and rate the\nquality of other users' notes. In this work, we empirically analyze how users\ninteract with this new feature. For this purpose, we collect all Birdwatch\nnotes and ratings since the introduction of the feature in early 2021. We then\nmap each Birdwatch note to the fact-checked tweet using Twitter's historical\nAPI. In addition, we use text mining methods to extract content characteristics\nfrom the text explanations in the Birdwatch notes (e.g., sentiment). Our\nempirical analysis yields the following main findings: (i) users more\nfrequently file Birdwatch notes for misleading than not misleading tweets.\nThese misleading tweets are primarily reported because of factual errors, lack\nof important context, or because they contain unverified claims. (ii) Birdwatch\nnotes are more helpful to other users if they link to trustworthy sources and\nif they embed a more positive sentiment. (iii) The helpfulness of Birdwatch\nnotes depends on the social influence of the author of the fact-checked tweet.\nFor influential users with many followers, Birdwatch notes yield a lower level\nof consensus among users and community-created fact checks are more likely to\nbe seen as being incorrect. Altogether, our findings can help social media\nplatforms to formulate guidelines for users on how to write more helpful fact\nchecks. At the same time, our analysis suggests that community-based\nfact-checking faces challenges regarding biased views and polarization among\nthe user base.", "doi": "", "date": "2021-04-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.07175v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1169904294, "title": "Follow the Money: Analyzing @slpng_giants_pt's Strategy to Combat\n  Misinformation", "abstract": "In 2020, the activist movement @sleeping_giants_pt (SGB) made a splash in\nBrazil. Similar to its international counterparts, the movement carried\n\"campaigns\" against media outlets spreading misinformation. In those, SGB\ntargeted companies whose ads were shown in these outlets, publicly asking them\nto remove the ads. In this work, we present a careful characterization of SGB's\nactivism model, analyzing the three campaigns carried by the movement up to\nSeptember 2020. We study how successful its complaints were and what factors\nare associated with their success, how attention towards the targeted media\noutlets progressed, and how online interactions with the companies were\nimpacted after they were targeted. Leveraging an annotated corpus of SGB's\ntweets as well as other data from Twitter and Google Search, we show that SGB's\n\"campaigns\" were largely successful: over 86\\% of companies (n=161) responded\npositively to SGB's requests, and, for those that responded, we find user\npressure to be negatively correlated with the time companies take to answer\n($r$=-0.67; $p$<0.001). Finally, we find that, although changes in the\ninteractions with companies were transient, the impact in targeted media\noutlets endured: all three outlets experienced a significant decrease in\nengagement on Twitter and search volume on Google following the start of SGB's\ncampaigns. Overall, our work suggests that internet-based activism can leverage\nthe transient attention it captures towards concrete goals to have a\nlong-lasting impact.", "doi": "", "date": "2021-05-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.07523v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2678195068, "title": "Stance Detection with BERT Embeddings for Credibility Analysis of\n  Information on Social Media", "abstract": "The evolution of electronic media is a mixed blessing. Due to the easy\naccess, low cost, and faster reach of the information, people search out and\ndevour news from online social networks. In contrast, the increasing acceptance\nof social media reporting leads to the spread of fake news. This is a minacious\nproblem that causes disputes and endangers societal stability and harmony. Fake\nnews spread has gained attention from researchers due to its vicious nature.\nproliferation of misinformation in all media, from the internet to cable news,\npaid advertising and local news outlets, has made it essential for people to\nidentify the misinformation and sort through the facts. Researchers are trying\nto analyze the credibility of information and curtail false information on such\nplatforms. Credibility is the believability of the piece of information at\nhand. Analyzing the credibility of fake news is challenging due to the intent\nof its creation and the polychromatic nature of the news. In this work, we\npropose a model for detecting fake news. Our method investigates the content of\nthe news at the early stage i.e. when the news is published but is yet to be\ndisseminated through social media. Our work interprets the content with\nautomatic feature extraction and the relevance of the text pieces. In summary,\nwe introduce stance as one of the features along with the content of the\narticle and employ the pre-trained contextualized word embeddings BERT to\nobtain the state-of-art results for fake news detection. The experiment\nconducted on the real-world dataset indicates that our model outperforms the\nprevious work and enables fake news detection with an accuracy of 95.32%.", "doi": "10.7717/peerj-cs.467", "date": "2021-05-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.10272v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1242766609, "title": "Trends, Politics, Sentiments, and Misinformation: Understanding People's\n  Reactions to COVID-19 During its Early Stages", "abstract": "The sudden outbreak of COVID-19 resulted in large volumes of data shared on\ndifferent social media platforms. Analyzing and visualizing these data is\ndoubtlessly essential to having a deep understanding of the pandemic's impacts\non people's lives and their reactions to them. In this work, we conduct a\nlarge-scale spatiotemporal data analytic study to understand peoples' reactions\nto the COVID-19 pandemic during its early stages. In particular, we analyze a\nJSON-based dataset that is collected from news/messages/boards/blogs in English\nabout COVID-19 over a period of 4 months, for a total of 5.2M posts. The data\nare collected from December 2019 to March 2020 from several social media\nplatforms such as Facebook, LinkedIn, Pinterest, StumbleUpon and VK. Our study\naims mainly to understand which implications of COVID-19 have interested social\nmedia users the most and how did they vary over time, the spatiotemporal\ndistribution of misinformation, and the public opinion toward public figures\nduring the pandemic. Our results can be used by many parties (e.g.,\ngovernments, psychologists, etc.) to make more informative decisions, taking\ninto account the actual interests and opinions of the people.", "doi": "", "date": "2021-06-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.13385v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1363271085, "title": "Improved x-space Algorithm for Min-Max Bilevel Integer Programming with\n  an Application to Misinformation Spread in Social Networks", "abstract": "In this work we propose an improvement of the $x$-space algorithm developed\nfor solving a class of min--max bilevel optimization problems (Tang Y., Richard\nJ.P.P., Smith J.C. (2016), A class of algorithms for mixed-integer bilevel\nmin--max optimization. Journal of Global Optimization, 66(2), 225--262). In\nthis setting, the leader of the upper level problem aims at restricting the\nfollower's decisions by minimizing an objective function, which the follower\nintends to maximize in the lower level problem by making decisions still\navailable to her. The $x$-space algorithm solves upper and lower bound problems\nconsecutively until convergence, and requires the dualization of an\napproximation of the follower's problem in formulating the lower bound problem.\nWe first reformulate the lower bound problem using the properties of an optimal\nsolution to the original formulation, which makes the dualization step\nunnecessary. The reformulation makes possible the integration of a greedy\ncovering heuristic into the solution scheme, which results in a considerable\nincrease in the efficiency. The new algorithm referred to as the improved\n$x$-space algorithm is implemented and applied to a recent min--max bilevel\noptimization problem that arises in the context of reducing the misinformation\nspread in social networks. It is also assessed on the benchmark instances of\ntwo other bilevel problems: zero-one knapsack problem with interdiction and\nmaximum clique problem with interdiction. Numerical results indicate that the\nperformance of the new algorithm is superior to that of the original algorithm,\nand also compares favorably with a recent algorithm developed for mixed-integer\nbilevel linear programs.", "doi": "10.1016/j.ejor.2021.05.008", "date": "2020-05-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.08039v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4033215633, "title": "Understanding the dynamics emerging from infodemics: A call to action\n  for interdisciplinary research", "abstract": "Research on infodemics, i.e., the rapid spread of (mis)information related to\na hazardous event, such as the COVID-19 pandemic, requires the integration of a\nmultiplicity of scientific disciplines. The dynamics emerging from infodemics\nhave the potential to generate complex behavioral patterns. In order to react\nappropriately, it is of ultimate importance for the fields of Business and\nEconomics to understand the dynamics emerging from it. In the short run,\ndynamics might lead to an adaptation in household spending or to a shift in\nbuying behavior towards online providers. In the long run, changes in\ninvestments, consumer behavior, and markets are to be expected. We argue that\nthe dynamics emerge from complex interactions among multiple factors, such as\ninformation and misinformation accessible for individuals and the formation and\nrevision of beliefs. (Mis)information accessible to individuals is, amongst\nothers, affected by algorithms specifically designed to provide personalized\ninformation, while automated fact-checking algorithms can help reduce the\namount of circulating misinformation. The formation and revision of individual\n(and probably false) beliefs and individual fact-checking and interpretation of\ninformation are heavily affected by linguistic patterns inherent to information\nduring pandemics and infodemics and further factors, such as affect, intuition\nand motives. We argue that, in order to get a deep(er) understanding of the\ndynamics emerging from infodemics, the fields of Business and Economics should\nintegrate the perspectives of Computer Science and Information Systems,\n(Computational) Linguistics, and Cognitive Science into the wider context of\neconomic systems (e.g., organizations, markets or industries) and propose a way\nto do so.", "doi": "", "date": "2020-07-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.12226v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 169526583, "title": "Impossible by Conventional Means: Ten Years on from the DARPA Red\n  Balloon Challenge", "abstract": "Ten years ago, DARPA launched the 'Network Challenge', more commonly known as\nthe 'DARPA Red Balloon Challenge'. Ten red weather balloons were fixed at\nunknown locations in the US. An open challenge was launched to locate all ten,\nthe first to do so would be declared the winner receiving a cash prize. A team\nfrom MIT Media Lab was able to locate them all within 9 hours using social\nmedia and a novel reward scheme that rewarded viral recruitment. This\nachievement was rightly seen as proof of the remarkable ability of social\nmedia, then relatively nascent, to solve real world problems such as\nlarge-scale spatial search. Upon reflection, however, the challenge was also\nremarkable as it succeeded despite many efforts to provide false information on\nthe location of the balloons. At the time the false reports were filtered based\non manual inspection of visual proof and comparing the IP addresses of those\nreporting with the purported coordinates of the balloons. In the ten years\nsince, misinformation on social media has grown in prevalence and\nsophistication to be one of the defining social issues of our time. Seen\ndifferently we can cast the misinformation observed in the Red Balloon\nChallenge, and unexpected adverse effects in other social mobilisation\nchallenges subsequently, not as bugs but as essential features. We further\ninvestigate the role of the increasing levels of political polarisation in\nmodulating social mobilisation. We confirm that polarisation not only impedes\nthe overall success of mobilisation, but also leads to a low reachability to\noppositely polarised states, significantly hampering recruitment. We find that\ndiversifying geographic pathways of social influence are key to circumvent\nbarriers of political mobilisation and can boost the success of new open\nchallenges.", "doi": "", "date": "2020-08-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.05940v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 695329590, "title": "No Rumours Please! A Multi-Indic-Lingual Approach for COVID Fake-Tweet\n  Detection", "abstract": "The sudden widespread menace created by the present global pandemic COVID-19\nhas had an unprecedented effect on our lives. Man-kind is going through\nhumongous fear and dependence on social media like never before. Fear\ninevitably leads to panic, speculations, and the spread of misinformation. Many\ngovernments have taken measures to curb the spread of such misinformation for\npublic well being. Besides global measures, to have effective outreach, systems\nfor demographically local languages have an important role to play in this\neffort. Towards this, we propose an approach to detect fake news about COVID-19\nearly on from social media, such as tweets, for multiple Indic-Languages\nbesides English. In addition, we also create an annotated dataset of Hindi and\nBengali tweet for fake news detection. We propose a BERT based model augmented\nwith additional relevant features extracted from Twitter to identify fake\ntweets. To expand our approach to multiple Indic languages, we resort to mBERT\nbased model which is fine-tuned over created dataset in Hindi and Bengali. We\nalso propose a zero-shot learning approach to alleviate the data scarcity issue\nfor such low resource languages. Through rigorous experiments, we show that our\napproach reaches around 89% F-Score in fake tweet detection which supercedes\nthe state-of-the-art (SOTA) results. Moreover, we establish the first benchmark\nfor two Indic-Languages, Hindi and Bengali. Using our annotated data, our model\nachieves about 79% F-Score in Hindi and 81% F-Score for Bengali Tweets. Our\nzero-shot model achieves about 81% F-Score in Hindi and 78% F-Score for Bengali\nTweets without any annotated data, which clearly indicates the efficacy of our\napproach.", "doi": "", "date": "2020-10-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.06906v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3908792315, "title": "Political Bias and Factualness in News Sharing across more than 100,000\n  Online Communities", "abstract": "As civil discourse increasingly takes place online, misinformation and the\npolarization of news shared in online communities have become ever more\nrelevant concerns with real world harms across our society. Studying online\nnews sharing at scale is challenging due to the massive volume of content which\nis shared by millions of users across thousands of communities. Therefore,\nexisting research has largely focused on specific communities or specific\ninterventions, such as bans. However, understanding the prevalence and spread\nof misinformation and polarization more broadly, across thousands of online\ncommunities, is critical for the development of governance strategies,\ninterventions, and community design. Here, we conduct the largest study of news\nsharing on reddit to date, analyzing more than 550 million links spanning 4\nyears. We use non-partisan news source ratings from Media Bias/Fact Check to\nannotate links to news sources with their political bias and factualness. We\nfind that, compared to left-leaning communities, right-leaning communities have\n105% more variance in the political bias of their news sources, and more links\nto relatively-more biased sources, on average. We observe that reddit users'\nvoting and re-sharing behaviors generally decrease the visibility of extremely\nbiased and low factual content, which receives 20% fewer upvotes and 30% fewer\nexposures from crossposts than more neutral or more factual content. This\nsuggests that reddit is more resilient to low factual content than Twitter. We\nshow that extremely biased and low factual content is very concentrated, with\n99% of such content being shared in only 0.5% of communities, giving credence\nto the recent strategy of community-wide bans and quarantines.", "doi": "", "date": "2021-02-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.08537v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 657084142, "title": "Can the Crowd Judge Truthfulness? A Longitudinal Study on Recent\n  Misinformation about COVID-19", "abstract": "Recently, the misinformation problem has been addressed with a\ncrowdsourcing-based approach: to assess the truthfulness of a statement,\ninstead of relying on a few experts, a crowd of non-expert is exploited. We\nstudy whether crowdsourcing is an effective and reliable method to assess\ntruthfulness during a pandemic, targeting statements related to COVID-19, thus\naddressing (mis)information that is both related to a sensitive and personal\nissue and very recent as compared to when the judgment is done. In our\nexperiments, crowd workers are asked to assess the truthfulness of statements,\nand to provide evidence for the assessments. Besides showing that the crowd is\nable to accurately judge the truthfulness of the statements, we report results\non workers behavior, agreement among workers, effect of aggregation functions,\nof scales transformations, and of workers background and bias. We perform a\nlongitudinal study by re-launching the task multiple times with both novice and\nexperienced workers, deriving important insights on how the behavior and\nquality change over time. Our results show that: workers are able to detect and\nobjectively categorize online (mis)information related to COVID-19; both\ncrowdsourced and expert judgments can be transformed and aggregated to improve\nquality; worker background and other signals (e.g., source of information,\nbehavior) impact the quality of the data. The longitudinal study demonstrates\nthat the time-span has a major effect on the quality of the judgments, for both\nnovice and experienced workers. Finally, we provide an extensive failure\nanalysis of the statements misjudged by the crowd-workers.", "doi": "", "date": "2021-07-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.11755v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2272749452, "title": "The Many Dimensions of Truthfulness: Crowdsourcing Misinformation\n  Assessments on a Multidimensional Scale", "abstract": "Recent work has demonstrated the viability of using crowdsourcing as a tool\nfor evaluating the truthfulness of public statements. Under certain conditions\nsuch as: (1) having a balanced set of workers with different backgrounds and\ncognitive abilities; (2) using an adequate set of mechanisms to control the\nquality of the collected data; and (3) using a coarse grained assessment scale,\nthe crowd can provide reliable identification of fake news. However, fake news\nare a subtle matter: statements can be just biased (\"cherrypicked\"), imprecise,\nwrong, etc. and the unidimensional truth scale used in existing work cannot\naccount for such differences. In this paper we propose a multidimensional\nnotion of truthfulness and we ask the crowd workers to assess seven different\ndimensions of truthfulness selected based on existing literature: Correctness,\nNeutrality, Comprehensibility, Precision, Completeness, Speaker's\nTrustworthiness, and Informativeness. We deploy a set of quality control\nmechanisms to ensure that the thousands of assessments collected on 180\npublicly available fact-checked statements distributed over two datasets are of\nadequate quality, including a custom search engine used by the crowd workers to\nfind web pages supporting their truthfulness assessments. A comprehensive\nanalysis of crowdsourced judgments shows that: (1) the crowdsourced assessments\nare reliable when compared to an expert-provided gold standard; (2) the\nproposed dimensions of truthfulness capture independent pieces of information;\n(3) the crowdsourcing task can be easily learned by the workers; and (4) the\nresulting assessments provide a useful basis for a more complete estimation of\nstatement truthfulness.", "doi": "10.1016/j.ipm.2021.102710", "date": "2021-08-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.01222v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 364947167, "title": "Tainted Evidence: Cosmological Model Selection vs. Fitting", "abstract": "Interpretation of cosmological data to determine the number and values of\nparameters describing the universe must not rely solely on statistics but\ninvolve physical insight. When statistical techniques such as \"model selection\"\nor \"integrated survey optimization\" blindly apply Occam's Razor, this can lead\nto painful results. We emphasize that the sensitivity to prior probabilities\nand to the number of models compared can lead to \"prior selection\" rather than\nrobust model selection. A concrete example demonstrates that Information\nCriteria can in fact misinform over a large region of parameter space.", "doi": "10.1142/s0218271808013881", "date": "2007-02-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/astro-ph/0702542v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2591114016, "title": "Paradoxical popups: Why are they hard to catch?", "abstract": "Even professional baseball players occasionally find it difficult to\ngracefully approach seemingly routine pop-ups. This paper describes a set of\ntowering pop-ups with trajectories that exhibit cusps and loops near the apex.\nFor a normal fly ball, the horizontal velocity is continuously decreasing due\nto drag caused by air resistance. But for pop-ups, the Magnus force (the force\ndue to the ball spinning in a moving airflow) is larger than the drag force. In\nthese cases the horizontal velocity decreases in the beginning, like a normal\nfly ball, but after the apex, the Magnus force accelerates the horizontal\nmotion. We refer to this class of pop-ups as paradoxical because they appear to\nmisinform the typically robust optical control strategies used by fielders and\nlead to systematic vacillation in running paths, especially when a trajectory\nterminates near the fielder. In short, some of the dancing around when\ninfielders pursue pop-ups can be well explained as a combination of bizarre\ntrajectories and misguidance by the normally reliable optical control strategy,\nrather than apparent fielder error. Former major league infielders confirm that\nour model agrees with their experiences.", "doi": "10.1119/1.2937899", "date": "2008-03-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/0803.4357v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1264822285, "title": "Positive Logic with Adjoint Modalities: Proof Theory, Semantics and\n  Reasoning about Information", "abstract": "We consider a simple modal logic whose non-modal part has conjunction and\ndisjunction as connectives and whose modalities come in adjoint pairs, but are\nnot in general closure operators. Despite absence of negation and implication,\nand of axioms corresponding to the characteristic axioms of (e.g.) T, S4 and\nS5, such logics are useful, as shown in previous work by Baltag, Coecke and the\nfirst author, for encoding and reasoning about information and misinformation\nin multi-agent systems. For such a logic we present an algebraic semantics,\nusing lattices with agent-indexed families of adjoint pairs of operators, and a\ncut-free sequent calculus. The calculus exploits operators on sequents, in the\nstyle of \"nested\" or \"tree-sequent\" calculi; cut-admissibility is shown by\nconstructive syntactic methods. The applicability of the logic is illustrated\nby reasoning about the muddy children puzzle, for which the calculus is\naugmented with extra rules to express the facts of the muddy children scenario.", "doi": "", "date": "2009-03-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/0903.2448v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 112028697, "title": "Detecting and Tracking the Spread of Astroturf Memes in Microblog\n  Streams", "abstract": "Online social media are complementing and in some cases replacing\nperson-to-person social interaction and redefining the diffusion of\ninformation. In particular, microblogs have become crucial grounds on which\npublic relations, marketing, and political battles are fought. We introduce an\nextensible framework that will enable the real-time analysis of meme diffusion\nin social media by mining, visualizing, mapping, classifying, and modeling\nmassive streams of public microblogging events. We describe a Web service that\nleverages this framework to track political memes in Twitter and help detect\nastroturfing, smear campaigns, and other misinformation in the context of U.S.\npolitical elections. We present some cases of abusive behaviors uncovered by\nour service. Finally, we discuss promising preliminary results on the detection\nof suspicious memes via supervised learning based on features extracted from\nthe topology of the diffusion networks, sentiment analysis, and crowdsourced\nannotations.", "doi": "10.1145/1963192.1963301", "date": "2010-11-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1011.3768v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 139453095, "title": "Containing Viral Spread on Sparse Random Graphs: Bounds, Algorithms, and\n  Experiments", "abstract": "Viral spread on large graphs has many real-life applications such as malware\npropagation in computer networks and rumor (or misinformation) spread in\nTwitter-like online social networks. Although viral spread on large graphs has\nbeen intensively analyzed on classical models such as\nSusceptible-Infectious-Recovered, there still exits a deficit of effective\nmethods in practice to contain epidemic spread once it passes a critical\nthreshold. Against this backdrop, we explore methods of containing viral spread\nin large networks with the focus on sparse random networks. The viral\ncontainment strategy is to partition a large network into small components and\nthen to ensure the sanity of all messages delivered across different\ncomponents. With such a defense mechanism in place, an epidemic spread starting\nfrom any node is limited to only those nodes belonging to the same component as\nthe initial infection node. We establish both lower and upper bounds on the\ncosts of inspecting inter-component messages. We further propose\nheuristic-based approaches to partition large input graphs into small\ncomponents. Finally, we study the performance of our proposed algorithms under\ndifferent network topologies and different edge weight models.", "doi": "", "date": "2013-10-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1310.1942v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4177214514, "title": "Social Learning in a Human Society: An Experimental Study", "abstract": "This paper presents an experimental study to investigate the learning and\ndecision making behavior of individuals in a human society. Social learning is\nused as the mathematical basis for modelling interaction of individuals that\naim to perform a perceptual task interactively. A psychology experiment was\nconducted on a group of undergraduate students at the University of British\nColumbia to examine whether the decision (action) of one individual affects the\ndecision of the subsequent individuals. The major experimental observation that\nstands out here is that the participants of the experiment (agents) were\naffected by decisions of their partners in a relatively large fraction (60%) of\ntrials. We fit a social learning model that mimics the interactions between\nparticipants of the psychology experiment. Misinformation propagation (also\nknown as data incest) within the society under study is further investigated in\nthis paper.", "doi": "", "date": "2014-08-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1408.5378v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3314180837, "title": "Distributed Rumor Blocking with Multiple Positive Cascades", "abstract": "Misinformation and rumor can spread rapidly and widely through online social\nnetworks and therefore rumor controlling has become a critical issue. It is\noften assumed that there is a single authority whose goal is to minimize the\nspread of rumor by generating a positive cascade. In this paper, we study a\nmore realistic scenario when there are multiple positive cascades generated by\ndifferent agents. For the multiple-cascade diffusion, we propose the P2P\nindependent cascade (PIC) model for private social communications. The main\npart of this paper is an analysis of the rumor blocking effect (i.e. the number\nof the users activated by rumor) when the agents non-cooperatively generate the\npositive cascades. We show that the rumor blocking effect provided by the Nash\nequilibrium will not be arbitrarily worse even if the positive cascades are\ngenerated non-cooperatively. In addition, we give a discussion on how the\ncascade priority and activation order affect the rumor blocking problem. We\nexperimentally examine the Nash equilibrium of the proposed games by\nsimulations done on real social network structures.", "doi": "", "date": "2017-11-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.07412v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2797911008, "title": "Controlling Elections through Social Influence", "abstract": "Election control considers the problem of an adversary who attempts to tamper\nwith a voting process, in order to either ensure that their favored candidate\nwins (constructive control) or another candidate loses (destructive control).\nAs online social networks have become significant sources of information for\npotential voters, a new tool in an attacker's arsenal is to effect control by\nharnessing social influence, for example, by spreading fake news and other\nforms of misinformation through online social media.\n  We consider the computational problem of election control via social\ninfluence, studying the conditions under which finding good adversarial\nstrategies is computationally feasible. We consider two objectives for the\nadversary in both the constructive and destructive control settings:\nprobability and margin of victory (POV and MOV, respectively). We present\nseveral strong negative results, showing, for example, that the problem of\nmaximizing POV is inapproximable for any constant factor. On the other hand, we\npresent approximation algorithms which provide somewhat weaker approximation\nguarantees, such as bicriteria approximations for the POV objective and\nconstant-factor approximations for MOV. Finally, we present mixed integer\nprogramming formulations for these problems. Experimental results show that our\napproximation algorithms often find near-optimal control strategies, indicating\nthat election control through social influence is a salient threat to election\nintegrity.", "doi": "", "date": "2017-11-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.08615v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1831307274, "title": "Probably a discovery: Bad mathematics means rough scientific\n  communication", "abstract": "According to the media, in spring of this year the experiment CDF at Fermilab\nhas made most likely (\"this result has a 99.7 percent chance of being correct\",\nDiscovery News) a great discovery (\"the most significant in physics in half a\ncentury\", NYT). However, since the very beginning, practically all particle\nphysics experts did not believe that was the case. This is the last of a quite\nlong series of fake claims based on trivial mistakes in the probabilistic\nreasoning. The main purpose of this note is to invite everybody, but especially\njournalists and general public, most times innocent victims of misinformation\nof this kind, to mistrust claims not explicitly reported in terms of how much\nwe should believe something, under well stated conditions and assumptions. (A\nlast minute appendix has been added, with comments on the recent news\nconcerning the Higgs at LHC.)", "doi": "", "date": "2011-12-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1112.3620v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4053897505, "title": "Social determinants of content selection in the age of (mis)information", "abstract": "Despite the enthusiastic rhetoric about the so called \\emph{collective\nintelligence}, conspiracy theories -- e.g. global warming induced by chemtrails\nor the link between vaccines and autism -- find on the Web a natural medium for\ntheir dissemination. Users preferentially consume information according to\ntheir system of beliefs and the strife within users of opposite narratives may\nresult in heated debates. In this work we provide a genuine example of\ninformation consumption from a sample of 1.2 million of Facebook Italian users.\nWe show by means of a thorough quantitative analysis that information\nsupporting different worldviews -- i.e. scientific and conspiracist news -- are\nconsumed in a comparable way by their respective users. Moreover, we measure\nthe effect of the exposure to 4709 evidently false information (satirical\nversion of conspiracy theses) and to 4502 debunking memes (information aiming\nat contrasting unsubstantiated rumors) of the most polarized users of\nconspiracy claims. We find that either contrasting or teasing consumers of\nconspiracy narratives increases their probability to interact again with\nunsubstantiated rumors.", "doi": "", "date": "2014-09-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1409.2651v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 127501685, "title": "Online Reputation and Polling Systems: Data Incest, Social Learning and\n  Revealed Preferences", "abstract": "This paper considers online reputation and polling systems where individuals\nmake recommendations based on their private observations and recommendations of\nfriends. Such interaction of individuals and their social influence is modelled\nas social learning on a directed acyclic graph. Data incest (misinformation\npropagation) occurs due to unintentional re-use of identical actions in the\nfor- mation of public belief in social learning; the information gathered by\neach agent is mistakenly considered to be independent. This results in\noverconfidence and bias in estimates of the state. Necessary and sufficient\nconditions are given on the structure of information exchange graph to mitigate\ndata incest. Incest removal algorithms are presented. Experimental results on\nhuman subjects are presented to illustrate the effect of social influence and\ndata incest on decision making. These experimental results indicate that social\nlearning protocols require careful design to handle and mitigate data incest.\nThe incest removal algorithms are illustrated in an expectation polling system\nwhere participants in a poll respond with a summary of their friends' beliefs.\nFinally, the principle of revealed preferences arising in micro-economics\ntheory is used to parse Twitter datasets to determine if social sensors are\nutility maximizers and then determine their utility functions.", "doi": "", "date": "2015-01-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1501.00994v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3427649338, "title": "Computational fact checking from knowledge networks", "abstract": "Traditional fact checking by expert journalists cannot keep up with the\nenormous volume of information that is now generated online. Computational fact\nchecking may significantly enhance our ability to evaluate the veracity of\ndubious information. Here we show that the complexities of human fact checking\ncan be approximated quite well by finding the shortest path between concept\nnodes under properly defined semantic proximity metrics on knowledge graphs.\nFramed as a network problem this approach is feasible with efficient\ncomputational techniques. We evaluate this approach by examining tens of\nthousands of claims related to history, entertainment, geography, and\nbiographical information using a public knowledge graph extracted from\nWikipedia. Statements independently known to be true consistently receive\nhigher support via our method than do false ones. These findings represent a\nsignificant step toward scalable computational fact-checking methods that may\none day mitigate the spread of harmful misinformation.", "doi": "10.1371/journal.pone.0128193", "date": "2015-01-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1501.03471v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1257747093, "title": "Political Bots and the Manipulation of Public Opinion in Venezuela", "abstract": "Social and political bots have a small but strategic role in Venezuelan\npolitical conversations. These automated scripts generate content through\nsocial media platforms and then interact with people. In this preliminary study\non the use of political bots in Venezuela, we analyze the tweeting, following\nand retweeting patterns for the accounts of prominent Venezuelan politicians\nand prominent Venezuelan bots. We find that bots generate a very small\nproportion of all the traffic about political life in Venezuela. Bots are used\nto retweet content from Venezuelan politicians but the effect is subtle in that\nless than 10 percent of all retweets come from bot-related platforms.\nNonetheless, we find that the most active bots are those used by Venezuela's\nradical opposition. Bots are pretending to be political leaders, government\nagencies and political parties more than citizens. Finally, bots are promoting\ninnocuous political events more than attacking opponents or spreading\nmisinformation.", "doi": "", "date": "2015-07-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1507.07109v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 103522975, "title": "Echo chambers in the age of misinformation", "abstract": "The wide availability of user-provided content in online social media\nfacilitates the aggregation of people around common interests, worldviews, and\nnarratives. Despite the enthusiastic rhetoric on the part of some that this\nprocess generates \"collective intelligence\", the WWW also allows the rapid\ndissemination of unsubstantiated conspiracy theories that often elicite rapid,\nlarge, but naive social responses such as the recent case of Jade Helm 15 --\nwhere a simple military exercise turned out to be perceived as the beginning of\nthe civil war in the US. We study how Facebook users consume information\nrelated to two different kinds of narrative: scientific and conspiracy news. We\nfind that although consumers of scientific and conspiracy stories present\nsimilar consumption patterns with respect to content, the sizes of the\nspreading cascades differ. Homogeneity appears to be the primary driver for the\ndiffusion of contents, but each echo chamber has its own cascade dynamics. To\nmimic these dynamics, we introduce a data-driven percolation model on signed\nnetworks.", "doi": "", "date": "2015-09-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1509.00189v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 670088376, "title": "BotOrNot: A System to Evaluate Social Bots", "abstract": "While most online social media accounts are controlled by humans, these\nplatforms also host automated agents called social bots or sybil accounts.\nRecent literature reported on cases of social bots imitating humans to\nmanipulate discussions, alter the popularity of users, pollute content and\nspread misinformation, and even perform terrorist propaganda and recruitment\nactions. Here we present BotOrNot, a publicly-available service that leverages\nmore than one thousand features to evaluate the extent to which a Twitter\naccount exhibits similarity to the known characteristics of social bots. Since\nits release in May 2014, BotOrNot has served over one million requests via our\nwebsite and APIs.", "doi": "10.1145/2872518.2889302", "date": "2016-02-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1602.00975v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1086069441, "title": "Cost overruns in Large-Scale Transportation Infrastructure Projects:\n  Explanations and Their Theoretical Embeddedness", "abstract": "Managing large-scale transportation infrastructure projects is difficult due\nto frequent misinformation about the costs which results in large cost overruns\nthat often threaten the overall project viability. This paper investigates the\nexplanations for cost overruns that are given in the literature. Overall, four\ncategories of explanations can be distinguished: technical, economic,\npsychological, and political. Political explanations have been seen to be the\nmost dominant explanations for cost overruns. Agency theory is considered the\nmost interesting for political explanations and an eclectic theory is also\nconsidered possible. Nonpolitical explanations are diverse in character,\ntherefore a range of different theories (including rational choice theory and\nprospect theory), depending on the kind of explanation is considered more\nappropriate than one all-embracing theory.", "doi": "", "date": "2013-07-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1307.2176v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2694796132, "title": "Non-existence of greedy bases in direct sums of mixed $\\ell_{p}$ spaces", "abstract": "The fact that finite direct sums of two or more mutually different spaces\nfrom the family $\\{\\ell_{p} : 1\\le p<\\infty\\}\\cup c_{0}$ fail to have greedy\nbases is stated in [Dilworth et al., Greedy bases for Besov spaces, Constr.\nApprox. 34 (2011), no. 2, 281-296]. However, the concise proof that the authors\ngive of this fundamental result in greedy approximation relies on a fallacious\nargument, namely the alleged uniqueness of unconditional basis up to\npermutation of the spaces involved. The main goal of this note is to settle the\nproblem by providing a correct proof. For that we first show that all greedy\nbases in an $\\ell_{p}$ space have fundamental functions of the same order. As a\nby-product of our work we obtain that every almost greedy basis of a Banach\nspace with unconditional basis and nontrivial type contains a greedy subbasis.", "doi": "", "date": "2014-01-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1401.0693v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2278450629, "title": "Understanding Information Spreading in Social Media during Hurricane\n  Sandy: User Activity and Network Properties", "abstract": "Many people use social media to seek information during disasters while\nlacking access to traditional information sources. In this study, we analyze\nTwitter data to understand information spreading activities of social media\nusers during hurricane Sandy. We create multiple subgraphs of Twitter users\nbased on activity levels and analyze network properties of the subgraphs. We\nobserve that user information sharing activity follows a power-law distribution\nsuggesting the existence of few highly active nodes in disseminating\ninformation and many other nodes being less active. We also observe close\nenough connected components and isolates at all levels of activity, and\nnetworks become less transitive, but more assortative for larger subgraphs. We\nalso analyze the association between user activities and characteristics that\nmay influence user behavior to spread information during a crisis. Users become\nmore active in spreading information if they are centrally placed in the\nnetwork, less eccentric, and have higher degrees. Our analysis provides\ninsights on how to exploit user characteristics and network properties to\nspread information or limit the spreading of misinformation during a crisis\nevent.", "doi": "", "date": "2017-06-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1706.03019v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2496482502, "title": "Junk News on Military Affairs and National Security: Social Media\n  Disinformation Campaigns Against US Military Personnel and Veterans", "abstract": "Social media provides political news and information for both active duty\nmilitary personnel and veterans. We analyze the subgroups of Twitter and\nFacebook users who spend time consuming junk news from websites that target US\nmilitary personnel and veterans with conspiracy theories, misinformation, and\nother forms of junk news about military affairs and national security issues.\n(1) Over Twitter we find that there are significant and persistent interactions\nbetween current and former military personnel and a broad network of extremist,\nRussia-focused, and international conspiracy subgroups. (2) Over Facebook, we\nfind significant and persistent interactions between public pages for military\nand veterans and subgroups dedicated to political conspiracy, and both sides of\nthe political spectrum. (3) Over Facebook, the users who are most interested in\nconspiracy theories and the political right seem to be distributing the most\njunk news, whereas users who are either in the military or are veterans are\namong the most sophisticated news consumers, and share very little junk news\nthrough the network.", "doi": "", "date": "2018-02-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1802.03572v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1722008185, "title": "Opinion Dynamics via Search Engines (and other Algorithmic Gatekeepers)", "abstract": "Ranking algorithms are the information gatekeepers of the Internet era. We\ndevelop a stylized model to study the effects of ranking algorithms on opinion\ndynamics. We consider a search engine that uses an algorithm based on\npopularity and on personalization. We find that popularity-based rankings\ngenerate an advantage of the fewer effect: fewer websites reporting a given\nsignal attract relatively more traffic overall. This highlights a novel,\nranking-driven channel that explains the diffusion of misinformation, as\nwebsites reporting incorrect information may attract an amplified amount of\ntraffic precisely because they are few. Furthermore, when individuals provide\nsufficiently positive feedback to the ranking algorithm, popularity-based\nrankings tend to aggregate information while personalization acts in the\nopposite direction.", "doi": "", "date": "2018-10-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1810.06973v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1063080948, "title": "Collective attention in the age of (mis)information", "abstract": "In this work we study, on a sample of 2.3 million individuals, how Facebook\nusers consumed different information at the edge of political discussion and\nnews during the last Italian electoral competition. Pages are categorized,\naccording to their topics and the communities of interests they pertain to, in\na) alternative information sources (diffusing topics that are neglected by\nscience and main stream media); b) online political activism; and c) main\nstream media. We show that attention patterns are similar despite the different\nqualitative nature of the information, meaning that unsubstantiated claims\n(mainly conspiracy theories) reverberate for as long as other information.\nFinally, we categorize users according to their interaction patterns among the\ndifferent topics and measure how a sample of this social ecosystem (1279 users)\nresponded to the injection of 2788 false information posts. Our analysis\nreveals that users which are prominently interacting with alternative\ninformation sources (i.e. more exposed to unsubstantiated claims) are more\nprone to interact with false claims.", "doi": "", "date": "2014-03-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1403.3344v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2099269274, "title": "How Humans versus Bots React to Deceptive and Trusted News Sources: A\n  Case Study of Active Users", "abstract": "Society's reliance on social media as a primary source of news has spawned a\nrenewed focus on the spread of misinformation. In this work, we identify the\ndifferences in how social media accounts identified as bots react to news\nsources of varying credibility, regardless of the veracity of the content those\nsources have shared. We analyze bot and human responses annotated using a\nfine-grained model that labels responses as being an answer, appreciation,\nagreement, disagreement, an elaboration, humor, or a negative reaction. We\npresent key findings of our analysis into the prevalence of bots, the variety\nand speed of bot and human reactions, and the disparity in authorship of\nreaction tweets between these two sub-populations. We observe that bots are\nresponsible for 9-15% of the reactions to sources of any given type but\ncomprise only 7-10% of accounts responsible for reaction-tweets; trusted news\nsources have the highest proportion of humans who reacted; bots respond with\nsignificantly shorter delays than humans when posting answer-reactions in\nresponse to sources identified as propaganda. Finally, we report significantly\ndifferent inequality levels in reaction rates for accounts identified as bots\nvs not.", "doi": "", "date": "2018-07-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1807.05327v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 145601388, "title": "Fake news as we feel it: perception and conceptualization of the term\n  \"fake news\" in the media", "abstract": "In this article, we quantitatively analyze how the term \"fake news\" is being\nshaped in news media in recent years. We study the perception and the\nconceptualization of this term in the traditional media using eight years of\ndata collected from news outlets based in 20 countries. Our results not only\ncorroborate previous indications of a high increase in the usage of the\nexpression \"fake news\", but also show contextual changes around this expression\nafter the United States presidential election of 2016. Among other results, we\nfound changes in the related vocabulary, in the mentioned entities, in the\nsurrounding topics and in the contextual polarity around the term \"fake news\",\nsuggesting that this expression underwent a change in perception and\nconceptualization after 2016. These outcomes expand the understandings on the\nusage of the term \"fake news\", helping to comprehend and more accurately\ncharacterize this relevant social phenomenon linked to misinformation and\nmanipulation.", "doi": "", "date": "2018-07-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1807.06926v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2867829449, "title": "A Deep Ensemble Framework for Fake News Detection and Classification", "abstract": "Fake news, rumor, incorrect information, and misinformation detection are\nnowadays crucial issues as these might have serious consequences for our social\nfabrics. The rate of such information is increasing rapidly due to the\navailability of enormous web information sources including social media feeds,\nnews blogs, online newspapers etc.\n  In this paper, we develop various deep learning models for detecting fake\nnews and classifying them into the pre-defined fine-grained categories.\n  At first, we develop models based on Convolutional Neural Network (CNN) and\nBi-directional Long Short Term Memory (Bi-LSTM) networks. The representations\nobtained from these two models are fed into a Multi-layer Perceptron Model\n(MLP) for the final classification. Our experiments on a benchmark dataset show\npromising results with an overall accuracy of 44.87\\%, which outperforms the\ncurrent state of the art.", "doi": "", "date": "2018-11-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.04670v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1704684087, "title": "Improving Rotated Text Detection with Rotation Region Proposal Networks", "abstract": "A significant number of images shared on social media platforms such as\nFacebook and Instagram contain text in various forms. It's increasingly\nbecoming commonplace for bad actors to share misinformation, hate speech or\nother kinds of harmful content as text overlaid on images on such platforms. A\nscene-text understanding system should hence be able to handle text in various\norientations that the adversary might use. Moreover, such a system can be\nincorporated into screen readers used to aid the visually impaired. In this\nwork, we extend the scene-text extraction system at Facebook, Rosetta, to\nefficiently handle text in various orientations. Specifically, we incorporate\nthe Rotation Region Proposal Networks (RRPN) in our text extraction pipeline\nand offer practical suggestions for building and deploying a model for\ndetecting and recognizing text in arbitrary orientations efficiently.\nExperimental results show a significant improvement on detecting rotated text.", "doi": "", "date": "2018-11-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.07031v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1989074410, "title": "Generate, Segment and Refine: Towards Generic Manipulation Segmentation", "abstract": "Detecting manipulated images has become a significant emerging challenge. The\nadvent of image sharing platforms and the easy availability of advanced photo\nediting software have resulted in a large quantities of manipulated images\nbeing shared on the internet. While the intent behind such manipulations varies\nwidely, concerns on the spread of fake news and misinformation is growing.\nCurrent state of the art methods for detecting these manipulated images suffers\nfrom the lack of training data due to the laborious labeling process. We\naddress this problem in this paper, for which we introduce a manipulated image\ngeneration process that creates true positives using currently available\ndatasets. Drawing from traditional work on image blending, we propose a novel\ngenerator for creating such examples. In addition, we also propose to further\ncreate examples that force the algorithm to focus on boundary artifacts during\ntraining. Strong experimental results validate our proposal.", "doi": "", "date": "2018-11-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.09729v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2524550582, "title": "Combating Fake News with Interpretable News Feed Algorithms", "abstract": "Nowadays, artificial intelligence algorithms are used for targeted and\npersonalized content distribution in the large scale as part of the intense\ncompetition for attention in the digital media environment. Unfortunately,\ntargeted information dissemination may result in intellectual isolation and\ndiscrimination. Further, as demonstrated in recent political events in the US\nand EU, malicious bots and social media users can create and propagate targeted\n`fake news' content in different forms for political gains. From the other\ndirection, fake news detection algorithms attempt to combat such problems by\nidentifying misinformation and fraudulent user profiles. This paper reviews\ncommon news feed algorithms as well as methods for fake news detection, and we\ndiscuss how news feed algorithms could be misused to promote falsified content,\naffect news diversity, or impact credibility. We review how news feed\nalgorithms and recommender engines can enable confirmation bias to isolate\nusers to certain news sources and affecting the perception of reality. As a\npotential solution for increasing user awareness of how content is selected or\nsorted, we argue for the use of interpretable and explainable news feed\nalgorithms. We discuss how improved user awareness and system transparency\ncould mitigate unwanted outcomes of echo chambers and bubble filters in social\nmedia.", "doi": "", "date": "2018-11-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.12349v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1187369804, "title": "Attention Based Neural Architecture for Rumor Detection with Author\n  Context Awareness", "abstract": "The prevalence of social media has made information sharing possible across\nthe globe. The downside, unfortunately, is the wide spread of misinformation.\nMethods applied in most previous rumor classifiers give an equal weight, or\nattention, to words in the microblog, and do not take the context beyond\nmicroblog contents into account; therefore, the accuracy becomes plateaued. In\nthis research, we propose an ensemble neural architecture to detect rumor on\nTwitter. The architecture incorporates word attention and context from the\nauthor to enhance the classification performance. In particular, the word-level\nattention mechanism enables the architecture to put more emphasis on important\nwords when constructing the text representation. To derive further context,\nmicroblog posts composed by individual authors are exploited since they can\nreflect style and characteristics in spreading information, which are\nsignificant cues to help classify whether the shared content is rumor or\nlegitimate news. The experiment on the real-world Twitter dataset collected\nfrom two well-known rumor tracking websites demonstrates promising results.", "doi": "", "date": "2019-09-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.01458v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4113065981, "title": "Health Wars and Beyond: The Rapidly Expanding and Efficient Network\n  Insurgency Interlinking Local and Global Online Crowds of Distrust", "abstract": "We present preliminary results on the online war surrounding distrust of\nexpertise in medical science -- specifically, the issue of vaccinations. While\ndistrust and misinformation in politics can damage democratic elections, in the\nmedical context it may also endanger lives through missed vaccinations and DIY\ncancer cures. We find that this online health war has evolved into a highly\nefficient network insurgency with direct inter-crowd links across countries,\ncontinents and cultures. The online anti-vax crowds (referred to as Red) now\nappear better positioned to groom new recruits (Green) than those supporting\nestablished expertise (Blue). We also present preliminary results from a\nmathematically-grounded, crowd-based analysis of the war's evolution, which\noffers an explanation for how Red seems to be turning the tide on Blue.", "doi": "", "date": "2019-10-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.02103v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4230876869, "title": "Megaprojects and Risk: An Anatomy of Ambition", "abstract": "Back cover text: Megaprojects and Risk provides the first detailed\nexamination of the phenomenon of megaprojects. It is a fascinating account of\nhow the promoters of multibillion-dollar megaprojects systematically and\nself-servingly misinform parliaments, the public and the media in order to get\nprojects approved and built. It shows, in unusual depth, how the formula for\napproval is an unhealthy cocktail of underestimated costs, overestimated\nrevenues, undervalued environmental impacts and overvalued economic development\neffects. This results in projects that are extremely risky, but where the risk\nis concealed from MPs, taxpayers and investors. The authors not only explore\nthe problems but also suggest practical solutions drawing on theory and hard,\nscientific evidence from the several hundred projects in twenty nations that\nillustrate the book. Accessibly written, it will be essential reading in its\nfield for students, scholars, planners, economists, auditors, politicians,\njournalists and interested citizens.", "doi": "", "date": "2013-03-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1303.7404v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1925571345, "title": "Measuring Online Social Bubbles", "abstract": "Social media have quickly become a prevalent channel to access information,\nspread ideas, and influence opinions. However, it has been suggested that\nsocial and algorithmic filtering may cause exposure to less diverse points of\nview, and even foster polarization and misinformation. Here we explore and\nvalidate this hypothesis quantitatively for the first time, at the collective\nand individual levels, by mining three massive datasets of web traffic, search\nlogs, and Twitter posts. Our analysis shows that collectively, people access\ninformation from a significantly narrower spectrum of sources through social\nmedia and email, compared to search. The significance of this finding for\nindividual exposure is revealed by investigating the relationship between the\ndiversity of information sources experienced by users at the collective and\nindividual level. There is a strong correlation between collective and\nindividual diversity, supporting the notion that when we use social media we\nfind ourselves inside \"social bubbles\". Our results could lead to a deeper\nunderstanding of how technology biases our exposure to new information.", "doi": "", "date": "2015-02-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1502.07162v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1672832682, "title": "Personality Traits and Echo Chambers on Facebook", "abstract": "In online social networks, users tend to select information that adhere to\ntheir system of beliefs and to form polarized groups of like minded people.\nPolarization as well as its effects on online social interactions have been\nextensively investigated. Still, the relation between group formation and\npersonality traits remains unclear. A better understanding of the cognitive and\npsychological determinants of online social dynamics might help to design more\nefficient communication strategies and to challenge the digital misinformation\nthreat. In this work, we focus on users commenting posts published by US\nFacebook pages supporting scientific and conspiracy-like narratives, and we\nclassify the personality traits of those users according to their online\nbehavior. We show that different and conflicting communities are populated by\nusers showing similar psychological profiles, and that the dominant personality\nmodel is the same in both scientific and conspiracy echo chambers. Moreover, we\nobserve that the permanence within echo chambers slightly shapes users'\npsychological profiles. Our results suggest that the presence of specific\npersonality traits in individuals lead to their considerable involvement in\nsupporting narratives inside virtual echo chambers.", "doi": "", "date": "2016-06-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1606.04721v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2632908918, "title": "Evaluating Quality of Chatbots and Intelligent Conversational Agents", "abstract": "Chatbots are one class of intelligent, conversational software agents\nactivated by natural language input (which can be in the form of text, voice,\nor both). They provide conversational output in response, and if commanded, can\nsometimes also execute tasks. Although chatbot technologies have existed since\nthe 1960s and have influenced user interface development in games since the\nearly 1980s, chatbots are now easier to train and implement. This is due to\nplentiful open source code, widely available development platforms, and\nimplementation options via Software as a Service (SaaS). In addition to\nenhancing customer experiences and supporting learning, chatbots can also be\nused to engineer social harm - that is, to spread rumors and misinformation, or\nattack people for posting their thoughts and opinions online. This paper\npresents a literature review of quality issues and attributes as they relate to\nthe contemporary issue of chatbot development and implementation. Finally,\nquality assessment approaches are reviewed, and a quality assessment method\nbased on these attributes and the Analytic Hierarchy Process (AHP) is proposed\nand examined.", "doi": "", "date": "2017-04-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1704.04579v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3484960718, "title": "People on Drugs: Credibility of User Statements in Health Communities", "abstract": "Online health communities are a valuable source of information for patients\nand physicians. However, such user-generated resources are often plagued by\ninaccuracies and misinformation. In this work we propose a method for\nautomatically establishing the credibility of user-generated medical statements\nand the trustworthiness of their authors by exploiting linguistic cues and\ndistant supervision from expert sources. To this end we introduce a\nprobabilistic graphical model that jointly learns user trustworthiness,\nstatement credibility, and language objectivity. We apply this methodology to\nthe task of extracting rare or unknown side-effects of medical drugs --- this\nbeing one of the problems where large scale non-expert data has the potential\nto complement expert medical knowledge. We show that our method can reliably\nextract side-effects and filter out false statements, while identifying\ntrustworthy users that are likely to contribute valuable medical information.", "doi": "", "date": "2017-05-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1705.02522v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2449759444, "title": "U-Phylogeny: Undirected Provenance Graph Construction in the Wild", "abstract": "Deriving relationships between images and tracing back their history of\nmodifications are at the core of Multimedia Phylogeny solutions, which aim to\ncombat misinformation through doctored visual media. Nonetheless, most recent\nimage phylogeny solutions cannot properly address cases of forged composite\nimages with multiple donors, an area known as multiple parenting phylogeny\n(MPP). This paper presents a preliminary undirected graph construction solution\nfor MPP, without any strict assumptions. The algorithm is underpinned by robust\nimage representative keypoints and different geometric consistency checks among\nmatching regions in both images to provide regions of interest for direct\ncomparison. The paper introduces a novel technique to geometrically filter the\nmost promising matches as well as to aid in the shared region localization\ntask. The strength of the approach is corroborated by experiments with\nreal-world cases, with and without image distractors (unrelated cases).", "doi": "", "date": "2017-05-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1705.11187v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2224898318, "title": "A simple but tough-to-beat baseline for the Fake News Challenge stance\n  detection task", "abstract": "Identifying public misinformation is a complicated and challenging task. An\nimportant part of checking the veracity of a specific claim is to evaluate the\nstance different news sources take towards the assertion. Automatic stance\nevaluation, i.e. stance detection, would arguably facilitate the process of\nfact checking. In this paper, we present our stance detection system which\nclaimed third place in Stage 1 of the Fake News Challenge. Despite our\nstraightforward approach, our system performs at a competitive level with the\ncomplex ensembles of the top two winning teams. We therefore propose our system\nas the 'simple but tough-to-beat baseline' for the Fake News Challenge stance\ndetection task.", "doi": "", "date": "2017-07-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1707.03264v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2064361205, "title": "An Analysis of the Twitter Discussion on the 2016 Austrian Presidential\n  Elections", "abstract": "In this paper, we provide a systematic analysis of the Twitter discussion on\nthe 2016 Austrian presidential elections. In particular, we extracted and\nanalyzed a data-set consisting of 343645 Twitter messages related to the 2016\nAustrian presidential elections. Our analysis combines methods from network\nscience, sentiment analysis, as well as bot detection. Among other things, we\nfound that: a) the winner of the election (Alexander Van der Bellen) was\nconsiderably more popular and influential on Twitter than his opponent, b) the\nTwitter followers of Van der Bellen substantially participated in the spread of\nmisinformation about him, c) there was a clear polarization in terms of the\nsentiments spread by Twitter followers of the two presidential candidates, d)\nthe in-degree and out-degree distributions of the underlying communication\nnetwork are heavy-tailed, and e) compared to other recent events, such as the\n2016 Brexit referendum or the 2016 US presidential elections, only a very small\nnumber of bots participated in the Twitter discussion on the 2016 Austrian\npresidential election.", "doi": "", "date": "2017-07-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1707.09939v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4181112925, "title": "Has the Online Discussion Been Manipulated? Quantifying Online\n  Discussion Authenticity within Online Social Media", "abstract": "Online social media (OSM) has a enormous influence in today's world. Some\nindividuals view OSM as fertile ground for abuse and use it to disseminate\nmisinformation and political propaganda, slander competitors, and spread spam.\nThe crowdturfing industry employs large numbers of bots and human workers to\nmanipulate OSM and misrepresent public opinion. The detection of online\ndiscussion topics manipulated by OSM \\emph{abusers} is an emerging issue\nattracting significant attention. In this paper, we propose an approach for\nquantifying the authenticity of online discussions based on the similarity of\nOSM accounts participating in the discussion to known abusers and legitimate\naccounts. Our method uses several similarity functions for the analysis and\nclassification of OSM accounts. The proposed methods are demonstrated using\nTwitter data collected for this study and previously published \\emph{Arabic\nhoneypot dataset}. The former includes manually labeled accounts and abusers\nwho participated in crowdturfing platforms. Evaluation of the topic's\nauthenticity, derived from account similarity functions, shows that the\nsuggested approach is effective for discriminating between topics that were\nstrongly promoted by abusers and topics that attracted authentic public\ninterest.", "doi": "", "date": "2017-08-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1708.02763v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2804885603, "title": "A Production Oriented Approach for Vandalism Detection in Wikidata - The\n  Buffaloberry Vandalism Detector at WSDM Cup 2017", "abstract": "Wikidata is a free and open knowledge base from the Wikimedia Foundation,\nthat not only acts as a central storage of structured data for other projects\nof the organization, but also for a growing array of information systems,\nincluding search engines. Like Wikipedia, Wikidata's content can be created and\nedited by anyone; which is the main source of its strength, but also allows for\nmalicious users to vandalize it, risking the spreading of misinformation\nthrough all the systems that rely on it as a source of structured facts. Our\ntask at the WSDM Cup 2017 was to come up with a fast and reliable prediction\nsystem that narrows down suspicious edits for human revision. Elaborating on\nprevious works by Heindorf et al. we were able to outperform all other\ncontestants, while incorporating new interesting features, unifying the\nprogramming language used to only Python and refactoring the feature extractor\ninto a simpler and more compact code base.", "doi": "", "date": "2017-12-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1712.06919v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3548974243, "title": "Forex trading and Twitter: Spam, bots, and reputation manipulation", "abstract": "Currency trading (Forex) is the largest world market in terms of volume. We\nanalyze trading and tweeting about the EUR-USD currency pair over a period of\nthree years. First, a large number of tweets were manually labeled, and a\nTwitter stance classification model is constructed. The model then classifies\nall the tweets by the trading stance signal: buy, hold, or sell (EUR vs. USD).\nThe Twitter stance is compared to the actual currency rates by applying the\nevent study methodology, well-known in financial economics. It turns out that\nthere are large differences in Twitter stance distribution and potential\ntrading returns between the four groups of Twitter users: trading robots,\nspammers, trading companies, and individual traders. Additionally, we observe\nattempts of reputation manipulation by post festum removal of tweets with poor\npredictions, and deleting/reposting of identical tweets to increase the\nvisibility without tainting one's Twitter timeline.", "doi": "", "date": "2018-04-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.02233v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3636733741, "title": "Bitcoin Risk Modeling with Blockchain Graphs", "abstract": "A key challenge for Bitcoin cryptocurrency holders, such as startups using\nICOs to raise funding, is managing their FX risk. Specifically, a misinformed\ndecision to convert Bitcoin to fiat currency could, by itself, cost USD\nmillions.\n  In contrast to financial exchanges, Blockchain based crypto-currencies expose\nthe entire transaction history to the public. By processing all transactions,\nwe model the network with a high fidelity graph so that it is possible to\ncharacterize how the flow of information in the network evolves over time. We\ndemonstrate how this data representation permits a new form of microstructure\nmodeling - with the emphasis on the topological network structures to study the\nrole of users, entities and their interactions in formation and dynamics of\ncrypto-currency investment risk. In particular, we identify certain sub-graphs\n('chainlets') that exhibit predictive influence on Bitcoin price and\nvolatility, and characterize the types of chainlets that signify extreme\nlosses.", "doi": "", "date": "2018-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1805.04698v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2735772573, "title": "Trust-based dynamic linear threshold models for non-competitive and\n  competitive influence propagation", "abstract": "What are the key-features that enable an information diffusion model to\nexplain the inherent dynamic, and often competitive, nature of real-world\npropagation phenomena? In this paper we aim to answer this question by\nproposing a novel class of diffusion models, inspired by the classic Linear\nThreshold model, and built around the following aspects: trust/distrust in the\nuser relationships, which is leveraged to model different effects of social\ninfluence on the decisions taken by an individual; changes in adopting one or\nalternative information items; hesitation towards adopting an information item\nover time; latency in the propagation; time horizon for the unfolding of the\ndiffusion process; and multiple cascades of information that might occur\ncompetitively. To the best of our knowledge, the above aspects have never been\nunified into the same LT-based diffusion model. We also define different\nstrategies for the selection of the initial influencers to simulate\nnon-competitive and competitive diffusion scenarios, particularly related to\nthe problem of limitation of misinformation spread. Results on publicly\navailable networks have shown the meaningfulness and uniqueness of our models.", "doi": "", "date": "2018-05-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1805.11303v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 868608580, "title": "TrollSpot: Detecting misbehavior in commenting platforms", "abstract": "Commenting platforms, such as Disqus, have emerged as a major online\ncommunication platform with millions of users and posts. Their popularity has\nalso attracted parasitic and malicious behav- iors, such as trolling and\nspamming. There has been relatively little research on modeling and\nsafeguarding these platforms. As our key contribution, we develop a systematic\napproach to detect malicious users on commenting platforms focusing on having:\n(a) interpretable, and (b) fine-grained classification of malice. Our work has\ntwo key novelties: (a) we propose two classifications methods, with one\nfollowing a two stage approach, which first maps observ- able features to\nbehaviors and then maps these behaviors to user roles, and (b) we use a\ncomprehensive set of 73 features that span four dimensions of information. We\nuse 7 million comments during a 9 month period, and we show that our\nclassification methods can distinguish between benign, and malicious roles\n(spammers, trollers, and fanatics) with a 0.904 AUC. Our work is a solid step\nto- wards ensuring that commenting platforms are a safe and pleasant medium for\nthe exchange of ideas.", "doi": "", "date": "2018-06-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.01997v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2148481434, "title": "Anchored in a Data Storm: How Anchoring Bias Can Affect User Strategy,\n  Confidence, and Decisions in Visual Analytics", "abstract": "Cognitive biases have been shown to lead to faulty decision-making. Recent\nresearch has demonstrated that the effect of cognitive biases, anchoring bias\nin particular, transfers to information visualization and visual analytics.\nHowever, it is still unclear how users of visual interfaces can be anchored and\nthe impact of anchoring on user performance and decision-making process. To\ninvestigate, we performed two rounds of between-subjects, in-laboratory\nexperiments with 94 participants to analyze the effect of visual anchors and\nstrategy cues in decision-making with a visual analytic system that employs\ncoordinated multiple view design. The decision-making task is identifying\nmisinformation from Twitter news accounts. Participants were randomly assigned\none of three treatment groups (including control) in which participant training\nprocesses were modified. Our findings reveal that strategy cues and visual\nanchors (scenario videos) can significantly affect user activity, speed,\nconfidence, and, under certain circumstances, accuracy. We discuss the\nimplications of our experiment results on training users how to use a newly\ndeveloped visual interface. We call for more careful consideration into how\nvisualization designers and researchers train users to avoid unintentionally\nanchoring users and thus affecting the end result.", "doi": "", "date": "2018-06-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.02720v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2635155362, "title": "The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake\n  News", "abstract": "A large body of research work and efforts have been focused on detecting fake\nnews and building online fact-check systems in order to debunk fake news as\nsoon as possible. Despite the existence of these systems, fake news is still\nwildly shared by online users. It indicates that these systems may not be fully\nutilized. After detecting fake news, what is the next step to stop people from\nsharing it? How can we improve the utilization of these fact-check systems? To\nfill this gap, in this paper, we (i) collect and analyze online users called\nguardians, who correct misinformation and fake news in online discussions by\nreferring fact-checking URLs; and (ii) propose a novel fact-checking URL\nrecommendation model to encourage the guardians to engage more in fact-checking\nactivities. We found that the guardians usually took less than one day to reply\nto claims in online conversations and took another day to spread verified\ninformation to hundreds of millions of followers. Our proposed recommendation\nmodel outperformed four state-of-the-art models by 11%~33%. Our source code and\ndataset are available at https://github.com/nguyenvo09/CombatingFakeNews.", "doi": "", "date": "2018-06-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.07516v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1317621754, "title": "Automated Fact Checking: Task formulations, methods and future\n  directions", "abstract": "The recently increased focus on misinformation has stimulated research in\nfact checking, the task of assessing the truthfulness of a claim. Research in\nautomating this task has been conducted in a variety of disciplines including\nnatural language processing, machine learning, knowledge representation,\ndatabases, and journalism. While there has been substantial progress, relevant\npapers and articles have been published in research communities that are often\nunaware of each other and use inconsistent terminology, thus impeding\nunderstanding and further progress. In this paper we survey automated fact\nchecking research stemming from natural language processing and related\ndisciplines, unifying the task formulations and methodologies across papers and\nauthors. Furthermore, we highlight the use of evidence as an important\ndistinguishing factor among them cutting across task formulations and methods.\nWe conclude with proposing avenues for future NLP research on automated fact\nchecking.", "doi": "", "date": "2018-06-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.07687v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3339133581, "title": "Technology, Propaganda, and the Limits of Human Intellect", "abstract": "\"Fake news\" is a recent phenomenon, but misinformation and propaganda are\nnot. Our new communication technologies make it easy for us to be exposed to\nhigh volumes of true, false, irrelevant, and unprovable information. Future AI\nis expected to amplify the problem even more. At the same time, our brains are\nreaching their limits in handling information. How should we respond to\npropaganda? Technology can help, but relying on it alone will not suffice in\nthe long term. We also need ethical policies, laws, regulations, and trusted\nauthorities, including fact-checkers. However, we will not solve the problem\nwithout the active engagement of the educated citizen. Epistemological\neducation, recognition of self biases and protection of our channels of\ncommunication and trusted networks are all needed to overcome the problem and\ncontinue our progress as democratic societies.", "doi": "", "date": "2018-06-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.09541v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1872328091, "title": "Are You Tampering With My Data?", "abstract": "We propose a novel approach towards adversarial attacks on neural networks\n(NN), focusing on tampering the data used for training instead of generating\nattacks on trained models. Our network-agnostic method creates a backdoor\nduring training which can be exploited at test time to force a neural network\nto exhibit abnormal behaviour. We demonstrate on two widely used datasets\n(CIFAR-10 and SVHN) that a universal modification of just one pixel per image\nfor all the images of a class in the training set is enough to corrupt the\ntraining procedure of several state-of-the-art deep neural networks causing the\nnetworks to misclassify any images to which the modification is applied. Our\naim is to bring to the attention of the machine learning community, the\npossibility that even learning-based methods that are personally trained on\npublic datasets can be subject to attacks by a skillful adversary.", "doi": "", "date": "2018-08-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.06809v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1863543999, "title": "When facts fail: Bias, polarisation and truth in social networks", "abstract": "Online social networks provide users with unprecedented opportunities to\nengage with diverse opinions. At the same time, they enable confirmation bias\non large scales by empowering individuals to self-select narratives they want\nto be exposed to. A precise understanding of such tradeoffs is still largely\nmissing. We introduce a social learning model where most participants in a\nnetwork update their beliefs unbiasedly based on new information, while a\nminority of participants reject information that is incongruent with their\npreexisting beliefs. This simple mechanism generates permanent opinion\npolarization and cascade dynamics, and accounts for the aforementioned tradeoff\nbetween confirmation bias and social connectivity through analytic results. We\ninvestigate the model's predictions empirically using US county-level data on\nthe impact of Internet access on the formation of beliefs about global warming.\nWe conclude by discussing policy implications of our model, highlighting the\ndownsides of debunking and suggesting alternative strategies to contrast\nmisinformation.", "doi": "", "date": "2018-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.08524v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 652189244, "title": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning", "abstract": "Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.", "doi": "", "date": "2018-09-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.06416v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 626593131, "title": "Technology-Enabled Disinformation: Summary, Lessons, and Recommendations", "abstract": "Technology is increasingly used -- unintentionally (misinformation) or\nintentionally (disinformation) -- to spread false information at scale, with\npotentially broad-reaching societal effects. For example, technology enables\nincreasingly realistic false images and videos, and hyper-personal targeting\nmeans different people may see different versions of reality. This report is\nthe culmination of a PhD-level special topics course\n(https://courses.cs.washington.edu/courses/cse599b/18au/) in Computer Science &\nEngineering at the University of Washington's Paul G. Allen School in the fall\nof 2018. The goals of this course were to study (1) how technologies and\ntoday's technical platforms enable and support the creation and spread of such\nmis- and disinformation, as well as (2) how technical approaches could be used\nto mitigate these issues. In this report, we summarize the space of\ntechnology-enabled mis- and disinformation based on our investigations, and\nthen surface our lessons and recommendations for technologists, researchers,\nplatform designers, policymakers, and users.", "doi": "", "date": "2018-12-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.09383v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3779274966, "title": "Group based Centrality for Immunization of Complex Networks", "abstract": "Network immunization is an extensively recognized issue in several domains\nlike virtual network security, public health and social media, to deal with the\nproblem of node inoculation so as to minimize the transmission through the\nlinks existed in these networks. We aim to identify top ranked nodes to\nimmunize networks, leading to control the outbreak of epidemics or\nmisinformation. We consider group based centrality and define a heuristic\nobjective criteria to establish the target of key nodes finding in network\nwhich if immunized result in essential network vulnerability. We propose a\ngroup based game theoretic payoff division approach, by employing Shapley value\nto assign the surplus acquired by participating nodes in different groups\nthrough the positional power and functional influence over other nodes. We tag\nthese key nodes as Shapley Value based Information Delimiters (SVID).\nExperiments on empirical data sets and model networks establish the efficacy of\nour proposed approach and acknowledge performance of node inoculation to\ndelimit contagion outbreak.", "doi": "10.1016/j.physa.2018.05.107", "date": "2018-12-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.11535v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4100158350, "title": "Combating Fake News: A Survey on Identification and Mitigation\n  Techniques", "abstract": "The proliferation of fake news on social media has opened up new directions\nof research for timely identification and containment of fake news, and\nmitigation of its widespread impact on public opinion. While much of the\nearlier research was focused on identification of fake news based on its\ncontents or by exploiting users' engagements with the news on social media,\nthere has been a rising interest in proactive intervention strategies to\ncounter the spread of misinformation and its impact on society. In this survey,\nwe describe the modern-day problem of fake news and, in particular, highlight\nthe technical challenges associated with it. We discuss existing methods and\ntechniques applicable to both identification and mitigation, with a focus on\nthe significant advances in each method and their advantages and limitations.\nIn addition, research has often been limited by the quality of existing\ndatasets and their specific application contexts. To alleviate this problem, we\ncomprehensively compile and summarize characteristic features of available\ndatasets. Furthermore, we outline new directions of research to facilitate\nfuture development of effective and interdisciplinary solutions.", "doi": "", "date": "2019-01-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.06437v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2761121369, "title": "The few-get-richer: a surprising consequence of popularity-based\n  rankings", "abstract": "Ranking algorithms play a crucial role in online platforms ranging from\nsearch engines to recommender systems. In this paper, we identify a surprising\nconsequence of popularity-based rankings: the fewer the items reporting a given\nsignal, the higher the share of the overall traffic they collectively attract.\nThis few-get-richer effect emerges in settings where there are few distinct\nclasses of items (e.g., left-leaning news sources versus right-leaning news\nsources), and items are ranked based on their popularity. We demonstrate\nanalytically that the few-get-richer effect emerges when people tend to click\non top-ranked items and have heterogeneous preferences for the classes of\nitems. Using simulations, we analyze how the strength of the effect changes\nwith assumptions about the setting and human behavior. We also test our\npredictions experimentally in an online experiment with human participants. Our\nfindings have important implications to understand the spread of\nmisinformation.", "doi": "", "date": "2019-02-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.02580v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3244149755, "title": "AIRD: Adversarial Learning Framework for Image Repurposing Detection", "abstract": "Image repurposing is a commonly used method for spreading misinformation on\nsocial media and online forums, which involves publishing untampered images\nwith modified metadata to create rumors and further propaganda. While manual\nverification is possible, given vast amounts of verified knowledge available on\nthe internet, the increasing prevalence and ease of this form of semantic\nmanipulation call for the development of robust automatic ways of assessing the\nsemantic integrity of multimedia data. In this paper, we present a novel method\nfor image repurposing detection that is based on the real-world adversarial\ninterplay between a bad actor who repurposes images with counterfeit metadata\nand a watchdog who verifies the semantic consistency between images and their\naccompanying metadata, where both players have access to a reference dataset of\nverified content, which they can use to achieve their goals. The proposed\nmethod exhibits state-of-the-art performance on location-identity,\nsubject-identity and painting-artist verification, showing its efficacy across\na diverse set of scenarios.", "doi": "", "date": "2019-03-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.00788v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3347911179, "title": "Lexical convergence and collective identities on Facebook", "abstract": "Recent studies, targeting Facebook, showed the tendency of users to interact\nwith information adhering to their preferred narrative and to ignore dissenting\ninformation. Primarily driven by confirmation bias, users tend to join\npolarized clusters where they cooperate to reinforce a like-minded system of\nbeliefs, thus facilitating fake news and misinformation cascades. To gain a\ndeeper understanding of these phenomena, in this work we analyze the lexicons\nused by the communities of users emerging on Facebook around verified and\nunverified contents. We show how the lexical approach provides important\ninsights about the kind of information processed by the two communities of\nusers and about their overall sentiment. Furthermore, by focusing on comment\nthreads, we observe a strong positive correlation between the lexical\nconvergence of co-commenters and their number of interactions, which in turns\nsuggests that such a trend could be a proxy for the emergence of collective\nidentities and polarization in opinion dynamics.", "doi": "", "date": "2019-03-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.11452v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 377573506, "title": "Automated Fact Checking in the News Room", "abstract": "Fact checking is an essential task in journalism; its importance has been\nhighlighted due to recently increased concerns and efforts in combating\nmisinformation. In this paper, we present an automated fact-checking platform\nwhich given a claim, it retrieves relevant textual evidence from a document\ncollection, predicts whether each piece of evidence supports or refutes the\nclaim, and returns a final verdict. We describe the architecture of the system\nand the user interface, focusing on the choices made to improve its\nuser-friendliness and transparency. We conduct a user study of the\nfact-checking platform in a journalistic setting: we integrated it with a\ncollection of news articles and provide an evaluation of the platform using\nfeedback from journalists in their workflow. We found that the predictions of\nour platform were correct 58\\% of the time, and 59\\% of the returned evidence\nwas relevant.", "doi": "", "date": "2019-04-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.02037v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 773594793, "title": "Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality", "abstract": "The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media.", "doi": "", "date": "2019-04-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.05386v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1027226197, "title": "Recurrent Convolutional Strategies for Face Manipulation Detection in\n  Videos", "abstract": "The spread of misinformation through synthetically generated yet realistic\nimages and videos has become a significant problem, calling for robust\nmanipulation detection methods. Despite the predominant effort of detecting\nface manipulation in still images, less attention has been paid to the\nidentification of tampered faces in videos by taking advantage of the temporal\ninformation present in the stream. Recurrent convolutional models are a class\nof deep learning models which have proven effective at exploiting the temporal\ninformation from image streams across domains. We thereby distill the best\nstrategy for combining variations in these models along with domain specific\nface preprocessing techniques through extensive experimentation to obtain\nstate-of-the-art performance on publicly available video-based facial\nmanipulation benchmarks. Specifically, we attempt to detect Deepfake, Face2Face\nand FaceSwap tampered faces in video streams. Evaluation is performed on the\nrecently introduced FaceForensics++ dataset, improving the previous\nstate-of-the-art by up to 4.55% in accuracy.", "doi": "", "date": "2019-05-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.00582v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2551409912, "title": "Modeling echo chambers and polarization dynamics in social networks", "abstract": "Echo chambers and opinion polarization recently quantified in several\nsociopolitical contexts and across different social media, raise concerns on\ntheir potential impact on the spread of misinformation and on openness of\ndebates. Despite increasing efforts, the dynamics leading to the emergence of\nthese phenomena stay unclear. We propose a model that introduces the dynamics\nof radicalization, as a reinforcing mechanism driving the evolution to extreme\nopinions from moderate initial conditions. Inspired by empirical findings on\nsocial interaction dynamics, we consider agents characterized by heterogeneous\nactivities and homophily. We show that the transition between a global\nconsensus and emerging radicalized states is mostly governed by social\ninfluence and by the controversialness of the topic discussed. Compared with\nempirical data of polarized debates on Twitter, the model qualitatively\nreproduces the observed relation between users' engagement and opinions, as\nwell as opinion segregation in the interaction network. Our findings shed light\non the mechanisms that may lie at the core of the emergence of echo chambers\nand polarization in social media.", "doi": "10.1103/physrevlett.124.048301", "date": "2019-06-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.12325v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3199413008, "title": "A New Approach to Distributed Hypothesis Testing and Non-Bayesian\n  Learning: Improved Learning Rate and Byzantine-Resilience", "abstract": "We study a setting where a group of agents, each receiving partially\ninformative private signals, seek to collaboratively learn the true underlying\nstate of the world (from a finite set of hypotheses) that generates their joint\nobservation profiles. To solve this problem, we propose a distributed learning\nrule that differs fundamentally from existing approaches, in that it does not\nemploy any form of \"belief-averaging\". Instead, agents update their beliefs\nbased on a min-rule. Under standard assumptions on the observation model and\nthe network structure, we establish that each agent learns the truth\nasymptotically almost surely. As our main contribution, we prove that with\nprobability 1, each false hypothesis is ruled out by every agent exponentially\nfast at a network-independent rate that is strictly larger than existing rates.\nWe then develop a computationally-efficient variant of our learning rule that\nis provably resilient to agents who do not behave as expected (as represented\nby a Byzantine adversary model) and deliberately try to spread misinformation.", "doi": "", "date": "2019-07-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.03588v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2069122015, "title": "Manipulating the Online Marketplace of Ideas", "abstract": "Social media, the modern marketplace of ideas, is vulnerable to manipulation.\nDeceptive inauthentic actors impersonate humans to amplify misinformation and\ninfluence public opinions. Little is known about the large-scale consequences\nof such operations, due to the ethical challenges posed by online experiments\nthat manipulate human behavior. Here we introduce a model of information\nspreading where agents prefer quality information but have limited attention.\nWe evaluate the impact of manipulation strategies aimed at degrading the\noverall quality of the information ecosystem. The model reproduces empirical\npatterns about amplification of low-quality information. We find that\ninfiltrating a critical fraction of the network is more damaging than\ngenerating attention-grabbing content or targeting influentials. We discuss\ncountermeasures suggested by these insights to increase the resilience of\nsocial media users to manipulation, and legal issues arising from regulations\naimed at protecting human speech from suppression by inauthentic actors.", "doi": "", "date": "2019-07-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.06130v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1672571760, "title": "Entropy-Regularized Stochastic Games", "abstract": "In two-player zero-sum stochastic games, where two competing players make\ndecisions under uncertainty, a pair of optimal strategies is traditionally\ndescribed by Nash equilibrium and computed under the assumption that the\nplayers have perfect information about the stochastic transition model of the\nenvironment. However, implementing such strategies may make the players\nvulnerable to unforeseen changes in the environment. In this paper, we\nintroduce entropy-regularized stochastic games where each player aims to\nmaximize the causal entropy of its strategy in addition to its expected payoff.\nThe regularization term balances each player's rationality with its belief\nabout the level of misinformation about the transition model. We consider both\nentropy-regularized $N$-stage and entropy-regularized discounted stochastic\ngames, and establish the existence of a value in both games. Moreover, we prove\nthe sufficiency of Markovian and stationary mixed strategies to attain the\nvalue, respectively, in $N$-stage and discounted games. Finally, we present\nalgorithms, which are based on convex optimization problems, to compute the\noptimal strategies. In a numerical example, we demonstrate the proposed method\non a motion planning scenario and illustrate the effect of the regularization\nterm on the expected payoff.", "doi": "", "date": "2019-07-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.11543v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3687458731, "title": "Hateful People or Hateful Bots? Detection and Characterization of Bots\n  Spreading Religious Hatred in Arabic Social Media", "abstract": "Arabic Twitter space is crawling with bots that fuel political feuds, spread\nmisinformation, and proliferate sectarian rhetoric. While efforts have long\nexisted to analyze and detect English bots, Arabic bot detection and\ncharacterization remains largely understudied. In this work, we contribute new\ninsights into the role of bots in spreading religious hatred on Arabic Twitter\nand introduce a novel regression model that can accurately identify Arabic\nlanguage bots. Our assessment shows that existing tools that are highly\naccurate in detecting English bots don't perform as well on Arabic bots. We\nidentify the possible reasons for this poor performance, perform a thorough\nanalysis of linguistic, content, behavioral and network features, and report on\nthe most informative features that distinguish Arabic bots from humans as well\nas the differences between Arabic and English bots. Our results mark an\nimportant step toward understanding the behavior of malicious bots on Arabic\nTwitter and pave the way for a more effective Arabic bot detection tools.", "doi": "10.1145/3359163", "date": "2019-08-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.00153v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 206598265, "title": "The Myths of Our Time: Fake News", "abstract": "While the purpose of most fake news is misinformation and political\npropaganda, our team sees it as a new type of myth that is created by people in\nthe age of internet identities and artificial intelligence. Seeking insights on\nthe fear and desire hidden underneath these modified or generated stories, we\nuse machine learning methods to generate fake articles and present them in the\nform of an online news blog. This paper aims to share the details of our\npipeline and the techniques used for full generation of fake news, from dataset\ncollection to presentation as a media art project on the internet.", "doi": "", "date": "2019-08-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.01760v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4166411935, "title": "Tensor Factorization with Label Information for Fake News Detection", "abstract": "The buzz over the so-called \"fake news\" has created concerns about a\ndegenerated media environment and led to the need for technological solutions.\nAs the detection of fake news is increasingly considered a technological\nproblem, it has attracted considerable research. Most of these studies\nprimarily focus on utilizing information extracted from textual news content.\nIn contrast, we focus on detecting fake news solely based on structural\ninformation of social networks. We suggest that the underlying network\nconnections of users that share fake news are discriminative enough to support\nthe detection of fake news. Thereupon, we model each post as a network of\nfriendship interactions and represent a collection of posts as a\nmultidimensional tensor. Taking into account the available labeled data, we\npropose a tensor factorization method which associates the class labels of data\nsamples with their latent representations. Specifically, we combine a\nclassification error term with the standard factorization in a unified\noptimization process. Results on real-world datasets demonstrate that our\nproposed method is competitive against state-of-the-art methods by implementing\nan arguably simpler approach.", "doi": "", "date": "2019-08-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.03957v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3030343750, "title": "Credibility-based Fake News Detection", "abstract": "Fake news can significantly misinform people who often rely on online sources\nand social media for their information. Current research on fake news detection\nhas mostly focused on analyzing fake news content and how it propagates on a\nnetwork of users. In this paper, we emphasize the detection of fake news by\nassessing its credibility. By analyzing public fake news data, we show that\ninformation on news sources (and authors) can be a strong indicator of\ncredibility. Our findings suggest that an author's history of association with\nfake news, and the number of authors of a news article, can play a significant\nrole in detecting fake news. Our approach can help improve traditional fake\nnews detection methods, wherein content features are often used to detect fake\nnews.", "doi": "", "date": "2019-11-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.00643v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 285911175, "title": "Celebrating Three Decades of Worldwide Stock Market Manipulation", "abstract": "As the decade turns, we reflect on nearly thirty years of successful\nmanipulation of the world's public equity markets. This reflection highlights a\nfew of the key enabling ingredients and lessons learned along the way. A\nquantitative understanding of market impact and its decay, which we cover\nbriefly, lets you move long-term market prices to your advantage at acceptable\ncost. Hiding your footprints turns out to be less important than moving prices\nin the direction most people want them to move. Widespread (if misplaced) trust\nof market prices -- buttressed by overestimates of the cost of manipulation and\nunderestimates of the benefits to certain market participants -- makes price\nmanipulation a particularly valuable and profitable tool. Of the many recent\nstories heralding the dawn of the present golden age of misinformation, the\nmanipulation leading to the remarkable increase in the market capitalization of\nthe world's publicly traded companies over the past three decades is among the\nbest.", "doi": "", "date": "2019-11-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.01708v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4028607466, "title": "An Unsupervised Domain-Independent Framework for Automated Detection of\n  Persuasion Tactics in Text", "abstract": "With the increasing growth of social media, people have started relying\nheavily on the information shared therein to form opinions and make decisions.\nWhile such a reliance is motivation for a variety of parties to promote\ninformation, it also makes people vulnerable to exploitation by slander,\nmisinformation, terroristic and predatorial advances. In this work, we aim to\nunderstand and detect such attempts at persuasion. Existing works on detecting\npersuasion in text make use of lexical features for detecting persuasive\ntactics, without taking advantage of the possible structures inherent in the\ntactics used. We formulate the task as a multi-class classification problem and\npropose an unsupervised, domain-independent machine learning framework for\ndetecting the type of persuasion used in text, which exploits the inherent\nsentence structure present in the different persuasion tactics. Our work shows\npromising results as compared to existing work.", "doi": "", "date": "2019-12-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.06745v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1539197768, "title": "Four Years in Review: Statistical Practices of Likert Scales in\n  Human-Robot Interaction Studies", "abstract": "As robots become more prevalent, the importance of the field of human-robot\ninteraction (HRI) grows accordingly. As such, we should endeavor to employ the\nbest statistical practices. Likert scales are commonly used metrics in HRI to\nmeasure perceptions and attitudes. Due to misinformation or honest mistakes,\nmost HRI researchers do not adopt best practices when analyzing Likert data. We\nconduct a review of psychometric literature to determine the current standard\nfor Likert scale design and analysis. Next, we conduct a survey of four years\nof the International Conference on Human-Robot Interaction (2016 through 2019)\nand report on incorrect statistical practices and design of Likert scales.\nDuring these years, only 3 of the 110 papers applied proper statistical testing\nto correctly-designed Likert scales. Our analysis suggests there are areas for\nmeaningful improvement in the design and testing of Likert scales. Lastly, we\nprovide recommendations to improve the accuracy of conclusions drawn from\nLikert data.", "doi": "10.1145/3319502.3378178", "date": "2020-01-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.03231v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3807148727, "title": "aiTPR: Attribute Interaction-Tensor Product Representation for Image\n  Caption", "abstract": "Region visual features enhance the generative capability of the machines\nbased on features, however they lack proper interaction attentional perceptions\nand thus ends up with biased or uncorrelated sentences or pieces of\nmisinformation. In this work, we propose Attribute Interaction-Tensor Product\nRepresentation (aiTPR) which is a convenient way of gathering more information\nthrough orthogonal combination and learning the interactions as physical\nentities (tensors) and improving the captions. Compared to previous works,\nwhere features are added up to undefined feature spaces, TPR helps in\nmaintaining sanity in combinations and orthogonality helps in defining familiar\nspaces. We have introduced a new concept layer that defines the objects and\nalso their interactions that can play a crucial role in determination of\ndifferent descriptions. The interaction portions have contributed heavily for\nbetter caption quality and has out-performed different previous works on this\ndomain and MSCOCO dataset. We introduced, for the first time, the notion of\ncombining regional image features and abstracted interaction likelihood\nembedding for image captioning.", "doi": "", "date": "2020-01-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.09545v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2991067817, "title": "A Kernel of Truth: Determining Rumor Veracity on Twitter by Diffusion\n  Pattern Alone", "abstract": "Recent work in the domain of misinformation detection has leveraged rich\nsignals in the text and user identities associated with content on social\nmedia. But text can be strategically manipulated and accounts reopened under\ndifferent aliases, suggesting that these approaches are inherently brittle. In\nthis work, we investigate an alternative modality that is naturally robust: the\npattern in which information propagates. Can the veracity of an unverified\nrumor spreading online be discerned solely on the basis of its pattern of\ndiffusion through the social network?\n  Using graph kernels to extract complex topological information from Twitter\ncascade structures, we train accurate predictive models that are blind to\nlanguage, user identities, and time, demonstrating for the first time that such\n\"sanitized\" diffusion patterns are highly informative of veracity. Our results\nindicate that, with proper aggregation, the collective sharing pattern of the\ncrowd may reveal powerful signals of rumor truth or falsehood, even in the\nearly stages of propagation.", "doi": "10.1145/3366423.3380180", "date": "2020-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.00850v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2513119213, "title": "Limits of Detecting Text Generated by Large-Scale Language Models", "abstract": "Some consider large-scale language models that can generate long and coherent\npieces of text as dangerous, since they may be used in misinformation\ncampaigns. Here we formulate large-scale language model output detection as a\nhypothesis testing problem to classify text as genuine or generated. We show\nthat error exponents for particular language models are bounded in terms of\ntheir perplexity, a standard measure of language generation performance. Under\nthe assumption that human language is stationary and ergodic, the formulation\nis extended from considering specific language models to considering maximum\nlikelihood language models, among the class of k-order Markov approximations;\nerror probabilities are characterized. Some discussion of incorporating\nsemantic side information is also given.", "doi": "", "date": "2020-02-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.03438v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 351420032, "title": "TIES: Temporal Interaction Embeddings For Enhancing Social Media\n  Integrity At Facebook", "abstract": "Since its inception, Facebook has become an integral part of the online\nsocial community. People rely on Facebook to make connections with others and\nbuild communities. As a result, it is paramount to protect the integrity of\nsuch a rapidly growing network in a fast and scalable manner. In this paper, we\npresent our efforts to protect various social media entities at Facebook from\npeople who try to abuse our platform. We present a novel Temporal Interaction\nEmbeddingS (TIES) model that is designed to capture rogue social interactions\nand flag them for further suitable actions. TIES is a supervised, deep\nlearning, production ready model at Facebook-scale networks. Prior works on\nintegrity problems are mostly focused on capturing either only static or\ncertain dynamic features of social entities. In contrast, TIES can capture both\nthese variant behaviors in a unified model owing to the recent strides made in\nthe domains of graph embedding and deep sequential pattern learning. To show\nthe real-world impact of TIES, we present a few applications especially for\npreventing spread of misinformation, fake account detection, and reducing ads\npayment risks in order to enhance the platform's integrity.", "doi": "", "date": "2020-02-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.07917v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2481160427, "title": "An Information Diffusion Approach to Rumor Propagation and\n  Identification on Twitter", "abstract": "With the increasing use of online social networks as a source of news and\ninformation, the propensity for a rumor to disseminate widely and quickly poses\na great concern, especially in disaster situations where users do not have\nenough time to fact-check posts before making the informed decision to react to\na post that appears to be credible. In this study, we explore the propagation\npattern of rumors on Twitter by exploring the dynamics of microscopic-level\nmisinformation spread, based on the latent message and user interaction\nattributes. We perform supervised learning for feature selection and\nprediction. Experimental results with real-world data sets give the models'\nprediction accuracy at about 90\\% for the diffusion of both True and False\ntopics. Our findings confirm that rumor cascades run deeper and that rumor\nmasked as news, and messages that incite fear, will diffuse faster than other\nmessages. We show that the models for True and False message propagation differ\nsignificantly, both in the prediction parameters and in the message features\nthat govern the diffusion. Finally, we show that the diffusion pattern is an\nimportant metric in identifying the credibility of a tweet.", "doi": "", "date": "2020-02-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.11104v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2982967603, "title": "Attacking Neural Text Detectors", "abstract": "Machine learning based language models have recently made significant\nprogress, which introduces a danger to spread misinformation. To combat this\npotential danger, several methods have been proposed for detecting text written\nby these language models. This paper presents two classes of black-box attacks\non these detectors, one which randomly replaces characters with homoglyphs, and\nthe other a simple scheme to purposefully misspell words. The homoglyph and\nmisspelling attacks decrease a popular neural text detector's recall on neural\ntext from 97.44% to 0.26% and 22.68%, respectively. Results also indicate that\nthe attacks are transferable to other neural text detectors.", "doi": "", "date": "2020-02-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.11768v3", "pdf": ""}, "publisher-venue": "the ICLR 2020 workshop \"Towards Trustworthy ML:\\n  Rethinking Security and Privacy for ML.\"", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3209119604, "title": "Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business", "abstract": "In the age of social media, disasters and epidemics usher not only a\ndevastation and affliction in the physical world, but also prompt a deluge of\ninformation, opinions, prognoses and advice to billions of internet users. The\ncoronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World\nHealth Organization warning of a possible \"infodemic\" of fake news. In this\nstudy, we examine the alternative narratives around the coronavirus outbreak\nthrough advertisements promoted on Facebook, the largest social media platform\nin the US. Using the new Facebook Ads Library, we discover advertisers from\npublic health and non-profit sectors, alongside those from news media,\npolitics, and business, incorporating coronavirus into their messaging and\nagenda. We find the virus used in political attacks, donation solicitations,\nbusiness promotion, stock market advice, and animal rights campaigning. Among\nthese, we find several instances of possible misinformation, ranging from\nbioweapons conspiracy theories to unverifiable claims by politicians. As we\nmake the dataset available to the community, we hope the advertising domain\nwill become an important part of quality control for public health\ncommunication and public discourse in general.", "doi": "", "date": "2020-03-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.00923v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1574877969, "title": "Discover Your Social Identity from What You Tweet: a Content Based\n  Approach", "abstract": "An identity denotes the role an individual or a group plays in highly\ndifferentiated contemporary societies. In this paper, our goal is to classify\nTwitter users based on their role identities. We first collect a coarse-grained\npublic figure dataset automatically, then manually label a more fine-grained\nidentity dataset. We propose a hierarchical self-attention neural network for\nTwitter user role identity classification. Our experiments demonstrate that the\nproposed model significantly outperforms multiple baselines. We further propose\na transfer learning scheme that improves our model's performance by a large\nmargin. Such transfer learning also greatly reduces the need for a large amount\nof human labeled data.", "doi": "10.1007/978-3-030-42699-6", "date": "2020-03-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.01797v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1967797583, "title": "The COVID-19 Social Media Infodemic", "abstract": "We address the diffusion of information about the COVID-19 with a massive\ndata analysis on Twitter, Instagram, YouTube, Reddit and Gab. We analyze\nengagement and interest in the COVID-19 topic and provide a differential\nassessment on the evolution of the discourse on a global scale for each\nplatform and their users. We fit information spreading with epidemic models\ncharacterizing the basic reproduction numbers $R_0$ for each social media\nplatform. Moreover, we characterize information spreading from questionable\nsources, finding different volumes of misinformation in each platform. However,\ninformation from both reliable and questionable sources do not present\ndifferent spreading patterns. Finally, we provide platform-dependent numerical\nestimates of rumors' amplification.", "doi": "10.1038/s41598-020-73510-5", "date": "2020-03-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.05004v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3650207470, "title": "Can Celebrities Burst Your Bubble?", "abstract": "Polarization is a growing, global problem. As such, many social media based\nsolutions have been proposed in order to reduce it. In this study, we propose a\nnew solution that recommends topics to celebrities to encourage them to join a\npolarized debate and increase exposure to contrarian content - bursting the\nfilter bubble. Using a state-of-the art model that quantifies the degree of\npolarization, this paper makes a first attempt to empirically answer the\nquestion: Can celebrities burst filter bubbles? We use a case study to analyze\nhow people react when celebrities are involved in a controversial topic and\nconclude with a list possible research directions.", "doi": "", "date": "2020-03-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.06857v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3926579437, "title": "Social Media and Misleading Information in a Democracy: A Mechanism\n  Design Approach", "abstract": "In this paper, we present a resource allocation mechanism for the problem of\nincentivizing filtering among a finite number of strategic social media\nplatforms. We consider the presence of a strategic government and private\nknowledge of how misinformation affects the users of the social media\nplatforms. Our proposed mechanism incentivizes social media platforms to filter\nmisleading information efficiently, and thus indirectly prevents the spread of\nfake news. In particular, we design an economically inspired mechanism that\nstrongly implements all generalized Nash equilibria for efficient filtering of\nmisleading information in the induced game. We show that our mechanism is\nindividually rational, budget balanced, while it has at least one equilibrium.\nFinally, we show that for quasi-concave utilities and constraints, our\nmechanism admits a generalized Nash equilibrium and implements a Pareto\nefficient solution.", "doi": "", "date": "2020-03-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.07192v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2027481310, "title": "Tracking Social Media Discourse About the COVID-19 Pandemic: Development\n  of a Public Coronavirus Twitter Data Set", "abstract": "At the time of this writing, the novel coronavirus (COVID-19) pandemic\noutbreak has already put tremendous strain on many countries' citizens,\nresources and economies around the world. Social distancing measures, travel\nbans, self-quarantines, and business closures are changing the very fabric of\nsocieties worldwide. With people forced out of public spaces, much conversation\nabout these phenomena now occurs online, e.g., on social media platforms like\nTwitter. In this paper, we describe a multilingual coronavirus (COVID-19)\nTwitter dataset that we have been continuously collecting since January 22,\n2020. We are making our dataset available to the research community\n(https://github.com/echen102/COVID-19-TweetIDs). It is our hope that our\ncontribution will enable the study of online conversation dynamics in the\ncontext of a planetary-scale epidemic outbreak of unprecedented proportions and\nimplications. This dataset could also help track scientific coronavirus\nmisinformation and unverified rumors, or enable the understanding of fear and\npanic -- and undoubtedly more. Ultimately, this dataset may contribute towards\nenabling informed solutions and prescribing targeted policy interventions to\nfight this global crisis.", "doi": "10.2196/19273", "date": "2020-03-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.07372v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1259596488, "title": "Understanding the perception of COVID-19 policies by mining a\n  multilanguage Twitter dataset", "abstract": "The objective of this work is to explore popular discourse about the COVID-19\npandemic and policies implemented to manage it. Using Natural Language\nProcessing, Text Mining, and Network Analysis to analyze corpus of tweets that\nrelate to the COVID-19 pandemic, we identify common responses to the pandemic\nand how these responses differ across time. Moreover, insights as to how\ninformation and misinformation were transmitted via Twitter, starting at the\nearly stages of this pandemic, are presented. Finally, this work introduces a\ndataset of tweets collected from all over the world, in multiple languages,\ndating back to January 22nd, when the total cases of reported COVID-19 were\nbelow 600 worldwide. The insights presented in this work could help inform\ndecision makers in the face of future pandemics, and the dataset introduced can\nbe used to acquire valuable knowledge to help mitigate the COVID-19 pandemic.", "doi": "", "date": "2020-03-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.10359v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2101188541, "title": "A first look at COVID-19 information and misinformation sharing on\n  Twitter", "abstract": "Since December 2019, COVID-19 has been spreading rapidly across the world.\nNot surprisingly, conversation about COVID-19 is also increasing. This article\nis a first look at the amount of conversation taking place on social media,\nspecifically Twitter, with respect to COVID-19, the themes of discussion, where\nthe discussion is emerging from, myths shared about the virus, and how much of\nit is connected to other high and low quality information on the Internet\nthrough shared URL links. Our preliminary findings suggest that a meaningful\nspatio-temporal relationship exists between information flow and new cases of\nCOVID-19, and while discussions about myths and links to poor quality\ninformation exist, their presence is less dominant than other crisis specific\nthemes. This research is a first step toward understanding social media\nconversation about COVID-19.", "doi": "", "date": "2020-03-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.13907v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1794433056, "title": "Hate multiverse spreads malicious COVID-19 content online beyond\n  individual platform control", "abstract": "We show that malicious COVID-19 content, including hate speech,\ndisinformation, and misinformation, exploits the multiverse of online hate to\nspread quickly beyond the control of any individual social media platform.\nMachine learning topic analysis shows quantitatively how online hate\ncommunities are weaponizing COVID-19, with topics evolving rapidly and content\nbecoming increasingly coherent. Our mathematical analysis provides a\ngeneralized form of the public health R0 predicting the tipping point for\nmultiverse-wide viral spreading, which suggests new policy options to mitigate\nthe global spread of malicious COVID-19 content without relying on future\ncoordination between all online platforms.", "doi": "", "date": "2020-04-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.00673v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1680115045, "title": "Skepticism and rumor spreading: the role of spatial correlations", "abstract": "Critical thinking and skepticism are fundamental mechanisms that one may use\nto prevent the spreading of rumors, fake-news and misinformation. We consider a\nsimple model in which agents without previous contact with the rumor, being\nskeptically oriented, may convince spreaders to stop their activity or, once\nexposed to the rumor, decide not to propagate it as a consequence, for example,\nof fact-checking. We extend a previous, mean-field analysis of the combined\neffect of these two mechanisms, active and passive skepticism, to include\nspatial correlations. This can be done either analytically, through the pair\napproximation, or simulating an agent-based version on diverse networks. Our\nresults show that while in mean-field there is no coexistence between spreaders\nand susceptibles (although, depending on the parameters, there may be\nbistability depending on the initial conditions), when spatial correlations are\nincluded, because of the protective effect of the isolation provided by removed\nagents, coexistence is possible.", "doi": "10.1103/physreve.101.062418", "date": "2020-04-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.00777v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3568081149, "title": "The Paradox of Information Access: Growing Isolation in the Age of\n  Sharing", "abstract": "Modern online media, such as Twitter, Instagram, and YouTube, enable anyone\nto become an information producer and to offer online content for potentially\nglobal consumption. By increasing the amount of globally accessible real-time\ninformation, today's ubiquitous producers contribute to a world, where an\nindividual consumes vanishingly smaller fractions of all produced content. In\ngeneral, consumers preferentially select information that closely matches their\nindividual views and values. The bias inherent in such selection is further\nmagnified by today's information curation services that maximize user\nengagement (and thus service revenue) by filtering new content in accordance\nwith observed consumer preferences. Consequently, individuals get exposed to\nincreasingly narrower bands of the ideology spectrum. Societies get fragmented\ninto increasingly ideologically isolated enclaves. These enclaves (or\necho-chambers) then become vulnerable to misinformation spread, which in turn\nfurther magnifies polarization and bias. We call this dynamic the paradox of\ninformation access; a growing ideological fragmentation in the age of sharing.\nThis article describes the technical, economic, and socio-cognitive\ncontributors to this paradox, and explores research directions towards its\nmitigation.", "doi": "", "date": "2020-04-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.01967v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2019016676, "title": "Satirical News Detection with Semantic Feature Extraction and\n  Game-theoretic Rough Sets", "abstract": "Satirical news detection is an important yet challenging task to prevent\nspread of misinformation. Many feature based and end-to-end neural nets based\nsatirical news detection systems have been proposed and delivered promising\nresults. Existing approaches explore comprehensive word features from satirical\nnews articles, but lack semantic metrics using word vectors for tweet form\nsatirical news. Moreover, the vagueness of satire and news parody determines\nthat a news tweet can hardly be classified with a binary decision, that is,\nsatirical or legitimate. To address these issues, we collect satirical and\nlegitimate news tweets, and propose a semantic feature based approach. Features\nare extracted by exploring inconsistencies in phrases, entities, and between\nmain and relative clauses. We apply game-theoretic rough set model to detect\nsatirical news, in which probabilistic thresholds are derived by game\nequilibrium and repetition learning mechanism. Experimental results on the\ncollected dataset show the robustness and improvement of the proposed approach\ncompared with Pawlak rough set model and SVM.", "doi": "", "date": "2020-04-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.03788v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3328434507, "title": "Large Arabic Twitter Dataset on COVID-19", "abstract": "The 2019 coronavirus disease (COVID-19), emerged late December 2019 in China,\nis now rapidly spreading across the globe. At the time of writing this paper,\nthe number of global confirmed cases has passed two millions and half with over\n180,000 fatalities. Many countries have enforced strict social distancing\npolicies to contain the spread of the virus. This have changed the daily life\nof tens of millions of people, and urged people to turn their discussions\nonline, e.g., via online social media sites like Twitter. In this work, we\ndescribe the first Arabic tweets dataset on COVID-19 that we have been\ncollecting since January 1st, 2020. The dataset would help researchers and\npolicy makers in studying different societal issues related to the pandemic.\nMany other tasks related to behavioral change, information sharing,\nmisinformation and rumors spreading can also be analyzed.", "doi": "", "date": "2020-04-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.04315v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 295502512, "title": "Automatically Assessing Quality of Online Health Articles", "abstract": "The information ecosystem today is overwhelmed by an unprecedented quantity\nof data on versatile topics are with varied quality. However, the quality of\ninformation disseminated in the field of medicine has been questioned as the\nnegative health consequences of health misinformation can be life-threatening.\nThere is currently no generic automated tool for evaluating the quality of\nonline health information spanned over a broad range. To address this gap, in\nthis paper, we applied a data mining approach to automatically assess the\nquality of online health articles based on 10 quality criteria. We have\nprepared a labeled dataset with 53012 features and applied different feature\nselection methods to identify the best feature subset with which our trained\nclassifier achieved an accuracy of 84%-90% varied over 10 criteria. Our\nsemantic analysis of features shows the underpinning associations between the\nselected features & assessment criteria and further rationalize our assessment\napproach. Our findings will help in identifying high-quality health articles\nand thus aiding users in shaping their opinion to make the right choice while\npicking health-related help from online.", "doi": "", "date": "2020-04-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.05113v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2427042970, "title": "The Creation and Detection of Deepfakes: A Survey", "abstract": "Generative deep learning algorithms have progressed to a point where it is\ndifficult to tell the difference between what is real and what is fake. In\n2018, it was discovered how easy it is to use this technology for unethical and\nmalicious applications, such as the spread of misinformation, impersonation of\npolitical leaders, and the defamation of innocent individuals. Since then,\nthese `deepfakes' have advanced significantly.\n  In this paper, we explore the creation and detection of deepfakes and provide\nan in-depth view of how these architectures work. The purpose of this survey is\nto provide the reader with a deeper understanding of (1) how deepfakes are\ncreated and detected, (2) the current trends and advancements in this domain,\n(3) the shortcomings of the current defense solutions, and (4) the areas which\nrequire further research and attention.", "doi": "10.1145/3425780", "date": "2020-04-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.11138v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1413427073, "title": "A First Instagram Dataset on COVID-19", "abstract": "The novel coronavirus (COVID-19) pandemic outbreak is drastically shaping and\nreshaping many aspects of our life, with a huge impact on our social life. In\nthis era of lockdown policies in most of the major cities around the world, we\nsee a huge increase in people and professional engagement in social media.\nSocial media is playing an important role in news propagation as well as\nkeeping people in contact. At the same time, this source is both a blessing and\na curse as the coronavirus infodemic has become a major concern, and is already\na topic that needs special attention and further research. In this paper, we\nprovide a multilingual coronavirus (COVID-19) Instagram dataset that we have\nbeen continuously collected since March 30, 2020. We are making our dataset\navailable to the research community at Github. We believe that this\ncontribution will help the community to better understand the dynamics behind\nthis phenomenon in Instagram, as one of the major social media. This dataset\ncould also help study the propagation of misinformation related to this\noutbreak.", "doi": "", "date": "2020-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.12226v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 983898920, "title": "DeSePtion: Dual Sequence Prediction and Adversarial Examples for\n  Improved Fact-Checking", "abstract": "The increased focus on misinformation has spurred development of data and\nsystems for detecting the veracity of a claim as well as retrieving\nauthoritative evidence. The Fact Extraction and VERification (FEVER) dataset\nprovides such a resource for evaluating end-to-end fact-checking, requiring\nretrieval of evidence from Wikipedia to validate a veracity prediction. We show\nthat current systems for FEVER are vulnerable to three categories of realistic\nchallenges for fact-checking -- multiple propositions, temporal reasoning, and\nambiguity and lexical variation -- and introduce a resource with these types of\nclaims. Then we present a system designed to be resilient to these \"attacks\"\nusing multiple pointer networks for document selection and jointly modeling a\nsequence of evidence sentences and veracity relation predictions. We find that\nin handling these attacks we obtain state-of-the-art results on FEVER, largely\ndue to improved evidence retrieval.", "doi": "", "date": "2020-04-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.12864v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 961809231, "title": "Prevalence of Low-Credibility Information on Twitter During the COVID-19\n  Outbreak", "abstract": "As the novel coronavirus spreads across the world, concerns regarding the\nspreading of misinformation about it are also growing. Here we estimate the\nprevalence of links to low-credibility information on Twitter during the\noutbreak, and the role of bots in spreading these links. We find that the\ncombined volume of tweets linking to low-credibility information is comparable\nto the volume of New York Times articles and CDC links. Content analysis\nreveals a politicization of the pandemic. The majority of this content spreads\nvia retweets. Social bots are involved in both posting and amplifying\nlow-credibility information, although the majority of volume is generated by\nlikely humans. Some of these accounts appear to amplify low-credibility sources\nin a coordinated fashion.", "doi": "10.36190/2020.16", "date": "2020-04-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.14484v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1634102055, "title": "A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian\n  and Indian Elections", "abstract": "Recently, messaging applications, such as WhatsApp, have been reportedly\nabused by misinformation campaigns, especially in Brazil and India. A notable\nform of abuse in WhatsApp relies on several manipulated images and memes\ncontaining all kinds of fake stories. In this work, we performed an extensive\ndata collection from a large set of WhatsApp publicly accessible groups and\nfact-checking agency websites. This paper opens a novel dataset to the research\ncommunity containing fact-checked fake images shared through WhatsApp for two\ndistinct scenarios known for the spread of fake news on the platform: the 2018\nBrazilian elections and the 2019 Indian elections.", "doi": "", "date": "2020-05-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.02443v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4094484316, "title": "Mega-COV: A Billion-Scale Dataset of 100+ Languages for COVID-19", "abstract": "We describe Mega-COV, a billion-scale dataset from Twitter for studying\nCOVID-19. The dataset is diverse (covers 268 countries), longitudinal (goes as\nback as 2007), multilingual (comes in 100+ languages), and has a significant\nnumber of location-tagged tweets (~169M tweets). We release tweet IDs from the\ndataset. We also develop and release two powerful models, one for identifying\nwhether or not a tweet is related to the pandemic (best F1=97%) and another for\ndetecting misinformation about COVID-19 (best F1=92%). A human annotation study\nreveals the utility of our models on a subset of Mega-COV. Our data and models\ncan be useful for studying a wide host of phenomena related to the pandemic.\nMega-COV and our models are publicly available.", "doi": "", "date": "2020-05-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.06012v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4132530706, "title": "When Wireless Communication Faces COVID-19: Combating the Pandemic and\n  Saving the Economy", "abstract": "The year 2020 is experiencing a global health and economic crisis due to the\nCOVID-19 pandemic. Countries across the world are using digital technologies to\nfight this global crisis. These digital technologies, in one way or another,\nstrongly rely on the availability of wireless communication technologies. In\nthis paper, we present the role of wireless communications in the COVID-19\npandemic from different perspectives. First, we show how these technologies are\nhelping to combat this pandemic, including monitoring of the virus spread,\nenabling healthcare automation, and allowing virtual education and\nconferencing. Also, we show the importance of digital inclusiveness in the\npandemic and possible solutions to connect the unconnected. Next, we discuss\nthe challenges faced by wireless technologies, including privacy, security, and\nmisinformation. Then, we present the importance of wireless communication\ntechnologies in the survival of the global economy, such as automation of\nindustries and supply chain, e-commerce, and supporting occupations that are at\nrisk. Finally, we reveal that how the technologies developed during the\npandemic can be helpful in the post-pandemic era.", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.06637v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 757482122, "title": "Neutral bots probe political bias on social media", "abstract": "Social media platforms attempting to curb abuse and misinformation have been\naccused of political bias. We deploy neutral social bots who start following\ndifferent news sources on Twitter, and track them to probe distinct biases\nemerging from platform mechanisms versus user interactions. We find no strong\nor consistent evidence of political bias in the news feed. Despite this, the\nnews and information to which U.S. Twitter users are exposed depend strongly on\nthe political leaning of their early connections. The interactions of\nconservative accounts are skewed toward the right, whereas liberal accounts are\nexposed to moderate content shifting their experience toward the political\ncenter. Partisan accounts, especially conservative ones, tend to receive more\nfollowers and follow more automated accounts. Conservative accounts also find\nthemselves in denser communities and are exposed to more low-credibility\ncontent.", "doi": "", "date": "2020-05-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.08141v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2609128624, "title": "Challenges in Combating COVID-19 Infodemic -- Data, Tools, and Ethics", "abstract": "While the COVID-19 pandemic continues its global devastation, numerous\naccompanying challenges emerge. One important challenge we face is to\nefficiently and effectively use recently gathered data and find computational\ntools to combat the COVID-19 infodemic, a typical information overloading\nproblem. Novel coronavirus presents many questions without ready answers; its\nuncertainty and our eagerness in search of solutions offer a fertile\nenvironment for infodemic. It is thus necessary to combat the infodemic and\nmake a concerted effort to confront COVID-19 and mitigate its negative impact\nin all walks of life when saving lives and maintaining normal orders during\ntrying times. In this position paper of combating the COVID-19 infodemic, we\nillustrate its need by providing real-world examples of rampant conspiracy\ntheories, misinformation, and various types of scams that take advantage of\nhuman kindness, fear, and ignorance. We present three key challenges in this\nfight against the COVID-19 infodemic where researchers and practitioners\ninstinctively want to contribute and help. We demonstrate that these three\nchallenges can and will be effectively addressed by collective wisdom,\ncrowdsourcing, and collaborative research.", "doi": "", "date": "2020-05-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.13691v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1187277667, "title": "Disinformation and Misinformation on Twitter during the Novel\n  Coronavirus Outbreak", "abstract": "As the novel coronavirus spread globally, a growing public panic was\nexpressed over the internet. We examine the public discussion concerning\nCOVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million\nusers collected between January 29, 2020 and March 4, 2020. We categorize users\nbased on their home countries, social identities, and political orientation. We\nfind that news media, government officials, and individual news reporters\nposted a majority of influential tweets, while the most influential ones are\nstill written by regular users. Tweets mentioning \"fake news\" URLs and\ndisinformation story-lines are also more likely to be spread by regular users.\nUnlike real news and normal tweets, tweets containing URLs pointing to \"fake\nnews\" sites are most likely to be retweeted within the source country and so\nare less likely to spread internationally.", "doi": "", "date": "2020-06-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.04278v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 386622778, "title": "Cultural Convergence: Insights into the behavior of misinformation\n  networks on Twitter", "abstract": "How can the birth and evolution of ideas and communities in a network be\nstudied over time? We use a multimodal pipeline, consisting of network mapping,\ntopic modeling, bridging centrality, and divergence to analyze Twitter data\nsurrounding the COVID-19 pandemic. We use network mapping to detect accounts\ncreating content surrounding COVID-19, then Latent Dirichlet Allocation to\nextract topics, and bridging centrality to identify topical and non-topical\nbridges, before examining the distribution of each topic and bridge over time\nand applying Jensen-Shannon divergence of topic distributions to show\ncommunities that are converging in their topical narratives.", "doi": "", "date": "2020-07-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.03443v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 482586862, "title": "A Survey on Computational Propaganda Detection", "abstract": "Propaganda campaigns aim at influencing people's mindset with the purpose of\nadvancing a specific agenda. They exploit the anonymity of the Internet, the\nmicro-profiling ability of social networks, and the ease of automatically\ncreating and managing coordinated networks of accounts, to reach millions of\nsocial network users with persuasive messages, specifically targeted to topics\neach individual user is sensitive to, and ultimately influencing the outcome on\na targeted issue. In this survey, we review the state of the art on\ncomputational propaganda detection from the perspective of Natural Language\nProcessing and Network Analysis, arguing about the need for combined efforts\nbetween these communities. We further discuss current challenges and future\nresearch directions.", "doi": "", "date": "2020-07-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.08024v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1231286022, "title": "Information disorders on Italian Facebook during COVID-19 infodemic", "abstract": "In this work we carry out an exploratory analysis of online conversations on\nthe Italian Facebook during the recent COVID-19 pandemic. We analyze the\ncirculation of controversial topics associated with the origin of the virus,\nwhich involve popular targets of misinformation, such as migrants and 5G\ntechnology. We collected over 1.5 M posts in Italian language and related to\nCOVID-19, shared by nearly 80k public pages and groups for a period of four\nmonths since January 2020. Overall, we find that potentially harmful content\nshared by unreliable sources is substantially negligible compared to\ntraditional news websites, and that discussions over controversial topics has a\nlimited engagement w.r.t to the pandemic in general. Besides, we highlight a\n\"small-worldness\" effect in the URL sharing diffusion network, indicating that\nusers navigating through a limited set of pages could reach almost the entire\npool of shared content related to the pandemic, thus being easily exposed to\nharmful propaganda as well as to verified information on the virus.", "doi": "10.1016/j.osnem.2021.100124", "date": "2020-07-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.11302v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2023782828, "title": "Machine Learning Explanations to Prevent Overtrust in Fake News\n  Detection", "abstract": "Combating fake news and misinformation propagation is a challenging task in\nthe post-truth era. News feed and search algorithms could potentially lead to\nunintentional large-scale propagation of false and fabricated information with\nusers being exposed to algorithmically selected false content. Our research\ninvestigates the effects of an Explainable AI assistant embedded in news review\nplatforms for combating the propagation of fake news. We design a news\nreviewing and sharing interface, create a dataset of news stories, and train\nfour interpretable fake news detection algorithms to study the effects of\nalgorithmic transparency on end-users. We present evaluation results and\nanalysis from multiple controlled crowdsourced studies. For a deeper\nunderstanding of Explainable AI systems, we discuss interactions between user\nengagement, mental model, trust, and performance measures in the process of\nexplaining. The study results indicate that explanations helped participants to\nbuild appropriate mental models of the intelligent assistants in different\nconditions and adjust their trust accordingly for model limitations.", "doi": "", "date": "2020-07-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.12358v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1731192915, "title": "Analyzing Twitter Users' Behavior Before and After Contact by the\n  Internet Research Agency", "abstract": "Social media platforms have been exploited to conduct election interference\nin recent years. In particular, the Russian-backed Internet Research Agency\n(IRA) has been identified as a key source of misinformation spread on Twitter\nprior to the 2016 U.S. presidential election. The goal of this research is to\nunderstand whether general Twitter users changed their behavior in the year\nfollowing first contact from an IRA account. We compare the before and after\nbehavior of contacted users to determine whether there were differences in\ntheir mean tweet count, the sentiment of their tweets, and the frequency and\nsentiment of tweets mentioning @realDonaldTrump or @HillaryClinton. Our results\nindicate that users overall exhibited statistically significant changes in\nbehavior across most of these metrics, and that those users that engaged with\nthe IRA generally showed greater changes in behavior.", "doi": "10.1145/3449164", "date": "2020-08-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.01273v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 151177811, "title": "Preserving Integrity in Online Social Networks", "abstract": "Online social networks provide a platform for sharing information and free\nexpression. However, these networks are also used for malicious purposes, such\nas distributing misinformation and hate speech, selling illegal drugs, and\ncoordinating sex trafficking or child exploitation. This paper surveys the\nstate of the art in keeping online platforms and their users safe from such\nharm, also known as the problem of preserving integrity. This survey comes from\nthe perspective of having to combat a broad spectrum of integrity violations at\nFacebook. We highlight the techniques that have been proven useful in practice\nand that deserve additional attention from the academic community. Instead of\ndiscussing the many individual violation types, we identify key aspects of the\nsocial-media eco-system, each of which is common to a wide variety violation\ntypes. Furthermore, each of these components represents an area for research\nand development, and the innovations that are found can be applied widely.", "doi": "", "date": "2020-09-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.10311v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2910258474, "title": "Anatomy of a Rumour: Social media and the suicide of Sushant Singh\n  Rajput", "abstract": "The suicide of Indian actor Sushant Singh Rajput in the midst of the COVID-19\nlockdown triggered a media frenzy of prime time coverage that lasted several\nmonths and became a political hot button issue. Using data from Twitter,\nYouTube, and an archive of debunked misinformation stories, we found two\nimportant patterns. First, that retweet rates on Twitter clearly suggest that\ncommentators benefited from talking about the case, which got higher engagement\nthan other topics. Second, that politicians, in particular, were instrumental\nin changing the course of the discourse by referring to the case as 'murder',\nrather than 'suicide'. In conclusion, we consider the effects of Rajput's\noutsider status as a small-town implant in the film industry within the broader\nnarrative of systemic injustice, as well as the gendered aspects of mob justice\nthat have taken aim at his former partner in the months since.", "doi": "", "date": "2020-09-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.11744v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1964735770, "title": "Identifying Automatically Generated Headlines using Transformers", "abstract": "False information spread via the internet and social media influences public\nopinion and user activity, while generative models enable fake content to be\ngenerated faster and more cheaply than had previously been possible. In the not\nso distant future, identifying fake content generated by deep learning models\nwill play a key role in protecting users from misinformation. To this end, a\ndataset containing human and computer-generated headlines was created and a\nuser study indicated that humans were only able to identify the fake headlines\nin 47.8% of the cases. However, the most accurate automatic approach,\ntransformers, achieved an overall accuracy of 85.7%, indicating that content\ngenerated from language models can be filtered out accurately.", "doi": "", "date": "2020-09-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.13375v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4073174151, "title": "AMUSED: An Annotation Framework of Multi-modal Social Media Data", "abstract": "In this paper, we present a semi-automated framework called AMUSED for\ngathering multi-modal annotated data from the multiple social media platforms.\nThe framework is designed to mitigate the issues of collecting and annotating\nsocial media data by cohesively combining machine and human in the data\ncollection process. From a given list of the articles from professional news\nmedia or blog, AMUSED detects links to the social media posts from news\narticles and then downloads contents of the same post from the respective\nsocial media platform to gather details about that specific post. The framework\nis capable of fetching the annotated data from multiple platforms like Twitter,\nYouTube, Reddit. The framework aims to reduce the workload and problems behind\nthe data annotation from the social media platforms. AMUSED can be applied in\nmultiple application domains, as a use case, we have implemented the framework\nfor collecting COVID-19 misinformation data from different social media\nplatforms.", "doi": "", "date": "2020-10-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.00502v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2568778707, "title": "Incorporating Count-Based Features into Pre-Trained Models for Improved\n  Stance Detection", "abstract": "The explosive growth and popularity of Social Media has revolutionised the\nway we communicate and collaborate. Unfortunately, this same ease of accessing\nand sharing information has led to an explosion of misinformation and\npropaganda. Given that stance detection can significantly aid in veracity\nprediction, this work focuses on boosting automated stance detection, a task on\nwhich pre-trained models have been extremely successful on, as on several other\ntasks. This work shows that the task of stance detection can benefit from\nfeature based information, especially on certain under performing classes,\nhowever, integrating such features into pre-trained models using ensembling is\nchallenging. We propose a novel architecture for integrating features with\npre-trained models that address these challenges and test our method on the\nRumourEval 2019 dataset. This method achieves state-of-the-art results with an\nF1-score of 63.94 on the test set.", "doi": "", "date": "2020-10-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.09078v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2663031605, "title": "Disinformation in the Online Information Ecosystem: Detection,\n  Mitigation and Challenges", "abstract": "With the rapid increase in access to internet and the subsequent growth in\nthe population of online social media users, the quality of information posted,\ndisseminated and consumed via these platforms is an issue of growing concern. A\nlarge fraction of the common public turn to social media platforms and in\ngeneral the internet for news and even information regarding highly concerning\nissues such as COVID-19 symptoms. Given that the online information ecosystem\nis extremely noisy, fraught with misinformation and disinformation, and often\ncontaminated by malicious agents spreading propaganda, identifying genuine and\ngood quality information from disinformation is a challenging task for humans.\nIn this regard, there is a significant amount of ongoing research in the\ndirections of disinformation detection and mitigation. In this survey, we\ndiscuss the online disinformation problem, focusing on the recent 'infodemic'\nin the wake of the coronavirus pandemic. We then proceed to discuss the\ninherent challenges in disinformation research, and then elaborate on the\ncomputational and interdisciplinary approaches towards mitigation of\ndisinformation, after a short overview of the various directions explored in\ndetection efforts.", "doi": "", "date": "2020-10-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.09113v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2171714178, "title": "The Manufacture of Partisan Echo Chambers by Follow Train Abuse on\n  Twitter", "abstract": "A growing body of evidence points to critical vulnerabilities of social\nmedia, such as the emergence of partisan echo chambers and the viral spread of\nmisinformation. We show that these vulnerabilities are amplified by abusive\nbehaviors associated with so-called \"follow trains\" on Twitter, in which long\nlists of like-minded accounts are mentioned for others to follow. We present\nthe first systematic analysis of a large U.S. hyper-partisan train network. We\nobserve an artificial inflation of influence: accounts heavily promoted by\nfollow trains profit from a median six-fold increase in daily follower growth.\nThis catalyzes the formation of highly clustered echo chambers, hierarchically\norganized around a dense core of active accounts. Train accounts also engage in\nother behaviors that violate platform policies: we find evidence of activity by\ninauthentic automated accounts and abnormal content deletion, as well as\namplification of toxic content from low-credibility and conspiratorial sources.\nSome train accounts have been active for years, suggesting that platforms need\nto pay greater attention to this kind of abuse.", "doi": "", "date": "2020-10-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.13691v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3179291706, "title": "Collective Movement with Signaling", "abstract": "We consider a population of mobile agents able to make noisy observation of\nthe environment and communicate their observation by production and\ncomprehension of signals. Individuals try to align their movement direction\nwith their neighbors. Besides, they try to collectively find and travel towards\nan environmental direction. We show that, when the fraction of informed\nindividuals is small, by increasing the noise in communication, similarly to\nthe Viscek model, the model shows a discontinuous order-disorder transition\nwith strong finite size effects. In contrast, for large fraction of informed\nindividuals, it is possible to go from the ordered phase to the disordered\nphase without passing any phase transition. The ordered phase is composed of\ntwo phases separated by a discontinuous transition. Informed collective motion,\nin which the population collectively infers the correct environmental\ndirection, occurs for high fraction of informed individuals. When the fraction\nof informed individuals is low, misinformed collective motion, where the\npopulation fails to find the environmental direction becomes stable as well.\nBesides, we show that an amount of noise in the production of signals is more\ndetrimental for the inference capability of the population, and increases the\ndensity fluctuations and the probability of group fragmentation, compared to\nthe same amount of noise in the comprehension.", "doi": "", "date": "2020-10-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.14190v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2073531666, "title": "Artificial Intelligence (AI) in Action: Addressing the COVID-19 Pandemic\n  with Natural Language Processing (NLP)", "abstract": "The COVID-19 pandemic has had a significant impact on society, both because\nof the serious health effects of COVID-19 and because of public health measures\nimplemented to slow its spread. Many of these difficulties are fundamentally\ninformation needs; attempts to address these needs have caused an information\noverload for both researchers and the public. Natural language processing\n(NLP), the branch of artificial intelligence that interprets human language,\ncan be applied to address many of the information needs made urgent by the\nCOVID-19 pandemic. This review surveys approximately 150 NLP studies and more\nthan 50 systems and datasets addressing the COVID-19 pandemic. We detail work\non four core NLP tasks: information retrieval, named entity recognition,\nliterature-based discovery, and question answering. We also describe work that\ndirectly addresses aspects of the pandemic through four additional tasks: topic\nmodeling, sentiment and emotion analysis, caseload forecasting, and\nmisinformation detection. We conclude by discussing observable trends and\nremaining challenges.", "doi": "", "date": "2020-10-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.16413v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3819692787, "title": "A First Look at COVID-19 Messages on WhatsApp in Pakistan", "abstract": "The worldwide spread of COVID-19 has prompted extensive online discussions,\ncreating an `infodemic' on social media platforms such as WhatsApp and Twitter.\nHowever, the information shared on these platforms is prone to be unreliable\nand/or misleading. In this paper, we present the first analysis of COVID-19\ndiscourse on public WhatsApp groups from Pakistan. Building on a large scale\nannotation of thousands of messages containing text and images, we identify the\nmain categories of discussion. We focus on COVID-19 messages and understand the\ndifferent types of images/text messages being propagated. By exploring user\nbehavior related to COVID messages, we inspect how misinformation is spread.\nFinally, by quantifying the flow of information across WhatsApp and Twitter, we\nshow how information spreads across platforms and how WhatsApp acts as a source\nfor much of the information shared on Twitter.", "doi": "", "date": "2020-11-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.09145v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3577948282, "title": "Adversarial Threats to DeepFake Detection: A Practical Perspective", "abstract": "Facially manipulated images and videos or DeepFakes can be used maliciously\nto fuel misinformation or defame individuals. Therefore, detecting DeepFakes is\ncrucial to increase the credibility of social media platforms and other media\nsharing web sites. State-of-the art DeepFake detection techniques rely on\nneural network based classification models which are known to be vulnerable to\nadversarial examples. In this work, we study the vulnerabilities of\nstate-of-the-art DeepFake detection methods from a practical stand point. We\nperform adversarial attacks on DeepFake detectors in a black box setting where\nthe adversary does not have complete knowledge of the classification models. We\nstudy the extent to which adversarial perturbations transfer across different\nmodels and propose techniques to improve the transferability of adversarial\nexamples. We also create more accessible attacks using Universal Adversarial\nPerturbations which pose a very feasible attack scenario since they can be\neasily shared amongst attackers. We perform our evaluations on the winning\nentries of the DeepFake Detection Challenge (DFDC) and demonstrate that they\ncan be easily bypassed in a practical attack scenario by designing transferable\nand accessible adversarial attacks.", "doi": "", "date": "2020-11-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.09957v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1048039381, "title": "CLIMATE-FEVER: A Dataset for Verification of Real-World Climate Claims", "abstract": "We introduce CLIMATE-FEVER, a new publicly available dataset for verification\nof climate change-related claims. By providing a dataset for the research\ncommunity, we aim to facilitate and encourage work on improving algorithms for\nretrieving evidential support for climate-specific claims, addressing the\nunderlying language understanding challenges, and ultimately help alleviate the\nimpact of misinformation on climate change. We adapt the methodology of FEVER\n[1], the largest dataset of artificially designed claims, to real-life claims\ncollected from the Internet. While during this process, we could rely on the\nexpertise of renowned climate scientists, it turned out to be no easy task. We\ndiscuss the surprising, subtle complexity of modeling real-world\nclimate-related claims within the \\textsc{fever} framework, which we believe\nprovides a valuable challenge for general natural language understanding. We\nhope that our work will mark the beginning of a new exciting long-term joint\neffort by the climate science and AI community.", "doi": "", "date": "2020-12-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.00614v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3822545601, "title": "ArCorona: Analyzing Arabic Tweets in the Early Days of Coronavirus\n  (COVID-19) Pandemic", "abstract": "Over the past few months, there were huge numbers of circulating tweets and\ndiscussions about Coronavirus (COVID-19) in the Arab region. It is important\nfor policy makers and many people to identify types of shared tweets to better\nunderstand public behavior, topics of interest, requests from governments,\nsources of tweets, etc. It is also crucial to prevent spreading of rumors and\nmisinformation about the virus or bad cures. To this end, we present the\nlargest manually annotated dataset of Arabic tweets related to COVID-19. We\ndescribe annotation guidelines, analyze our dataset and build effective machine\nlearning and transformer based models for classification.", "doi": "", "date": "2020-12-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.01462v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4142818178, "title": "Fake News Detection in Social Media using Graph Neural Networks and NLP\n  Techniques: A COVID-19 Use-case", "abstract": "The paper presents our solutions for the MediaEval 2020 task namely FakeNews:\nCorona Virus and 5G Conspiracy Multimedia Twitter-Data-Based Analysis. The task\naims to analyze tweets related to COVID-19 and 5G conspiracy theories to detect\nmisinformation spreaders. The task is composed of two sub-tasks namely (i)\ntext-based, and (ii) structure-based fake news detection. For the first task,\nwe propose six different solutions relying on Bag of Words (BoW) and BERT\nembedding. Three of the methods aim at binary classification task by\ndifferentiating in 5G conspiracy and the rest of the COVID-19 related tweets\nwhile the rest of them treat the task as ternary classification problem. In the\nternary classification task, our BoW and BERT based methods obtained an\nF1-score of .606% and .566% on the development set, respectively. On the binary\nclassification, the BoW and BERT based solutions obtained an average F1-score\nof .666% and .693%, respectively. On the other hand, for structure-based fake\nnews detection, we rely on Graph Neural Networks (GNNs) achieving an average\nROC of .95% on the development set.", "doi": "", "date": "2020-11-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.07517v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2397266453, "title": "Recommenders with a mission: assessing diversity in newsrecommendations", "abstract": "News recommenders help users to find relevant online content and have the\npotential to fulfill a crucial role in a democratic society, directing the\nscarce attention of citizens towards the information that is most important to\nthem. Simultaneously, recent concerns about so-called filter bubbles,\nmisinformation and selective exposure are symptomatic of the disruptive\npotential of these digital news recommenders. Recommender systems can make or\nbreak filter bubbles, and as such can be instrumental in creating either a more\nclosed or a more open internet. Current approaches to evaluating recommender\nsystems are often focused on measuring an increase in user clicks and\nshort-term engagement, rather than measuring the user's longer term interest in\ndiverse and important information.\n  This paper aims to bridge the gap between normative notions of diversity,\nrooted in democratic theory, and quantitative metrics necessary for evaluating\nthe recommender system. We propose a set of metrics grounded in social science\ninterpretations of diversity and suggest ways for practical implementations.", "doi": "", "date": "2020-12-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.10185v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1668500551, "title": "g2tmn at Constraint@AAAI2021: Exploiting CT-BERT and Ensembling Learning\n  for COVID-19 Fake News Detection", "abstract": "The COVID-19 pandemic has had a huge impact on various areas of human life.\nHence, the coronavirus pandemic and its consequences are being actively\ndiscussed on social media. However, not all social media posts are truthful.\nMany of them spread fake news that cause panic among readers, misinform people\nand thus exacerbate the effect of the pandemic. In this paper, we present our\nresults at the Constraint@AAAI2021 Shared Task: COVID-19 Fake News Detection in\nEnglish. In particular, we propose our approach using the transformer-based\nensemble of COVID-Twitter-BERT (CT-BERT) models. We describe the models used,\nthe ways of text preprocessing and adding extra data. As a result, our best\nmodel achieved the weighted F1-score of 98.69 on the test set (the first place\nin the leaderboard) of this shared task that attracted 166 submitted teams in\ntotal.", "doi": "10.1007/978-3-030-73696-5_12", "date": "2020-12-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.11967v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1727363081, "title": "Transformer based Automatic COVID-19 Fake News Detection System", "abstract": "Recent rapid technological advancements in online social networks such as\nTwitter have led to a great incline in spreading false information and fake\nnews. Misinformation is especially prevalent in the ongoing coronavirus disease\n(COVID-19) pandemic, leading to individuals accepting bogus and potentially\ndeleterious claims and articles. Quick detection of fake news can reduce the\nspread of panic and confusion among the public. For our analysis in this paper,\nwe report a methodology to analyze the reliability of information shared on\nsocial media pertaining to the COVID-19 pandemic. Our best approach is based on\nan ensemble of three transformer models (BERT, ALBERT, and XLNET) to detecting\nfake news. This model was trained and evaluated in the context of the\nConstraintAI 2021 shared task COVID19 Fake News Detection in English. Our\nsystem obtained 0.9855 f1-score on testset and ranked 5th among 160 teams.", "doi": "", "date": "2021-01-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.00180v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2108355805, "title": "Depolarization of echo chambers by random dynamical nudge", "abstract": "Interactions among individuals in social networks lead to echo chambers where\nthe distribution of opinions follows a bimodal distribution with two peaks at\nthe opposite extremes. In issues with clear answers, such as global warming,\none of the echo chambers reflects an inaccurate judgment, potentially from\nmisinformation. However, in issues without clear answers such as elections, the\nneutral consensus is preferable for promoting discourse. In this letter, we use\nan opinion dynamics model to study the effect of a random dynamical nudge where\nwe present random input to each agent from the other individuals in the\nnetwork. We show that random dynamical nudge disallows the formation of echo\nchambers and leads to a normal distribution of opinions centered around the\nneutral consensus. The random dynamical nudge relies on the collective dynamics\nand it does not require surveillance of every person's opinions. Social media\nnetworks could implement a version of this self-feedback mechanism to prevent\nthe formation of segregated online communities on pressing issues such as\nelections.", "doi": "", "date": "2021-01-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.04079v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1856429802, "title": "Analysis of Moral Judgement on Reddit", "abstract": "Moral outrage has become synonymous with social media in recent years.\nHowever, the preponderance of academic analysis on social media websites has\nfocused on hate speech and misinformation. This paper focuses on analyzing\nmoral judgements rendered on social media by capturing the moral judgements\nthat are passed in the subreddit /r/AmITheAsshole on Reddit. Using the labels\nassociated with each judgement we train a classifier that can take a comment\nand determine whether it judges the user who made the original post to have\npositive or negative moral valence. Then, we use this classifier to investigate\nan assortment of website traits surrounding moral judgements in ten other\nsubreddits, including where negative moral users like to post and their posting\npatterns. Our findings also indicate that posts that are judged in a positive\nmanner will score higher.", "doi": "", "date": "2021-01-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.07664v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 14005896, "title": "Examining Factors Associated with Twitter Account Suspension Following\n  the 2020 U.S. Presidential Election", "abstract": "Online social media enables mass-level, transparent, and democratized\ndiscussion on numerous socio-political issues. Due to such openness, these\nplatforms often endure manipulation and misinformation - leading to negative\nimpacts. To prevent such harmful activities, platform moderators employ\ncountermeasures to safeguard against actors violating their rules. However, the\ncorrelation between publicly outlined policies and employed action is less\nclear to general people. In this work, we examine violations and subsequent\nmoderation related to the 2020 U.S. President Election discussion on Twitter, a\npopular micro-blogging site. We focus on quantifying plausible reasons for the\nsuspension, drawing on Twitter's rules and policies by identifying suspended\nusers (Case) and comparing their activities and properties with (yet)\nnon-suspended (Control) users. Using a dataset of 240M election-related tweets\nmade by 21M unique users, we observe that Suspended users violate Twitter's\nrules at a higher rate (statistically significant) than Control users across\nall the considered aspects - hate speech, offensiveness, spamming, and civic\nintegrity. Moreover, through the lens of Twitter's suspension mechanism, we\nqualitatively examine the targeted topics for manipulation.", "doi": "", "date": "2021-01-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.09575v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 192390092, "title": "A transformer based approach for fighting COVID-19 fake news", "abstract": "The rapid outbreak of COVID-19 has caused humanity to come to a stand-still\nand brought with it a plethora of other problems. COVID-19 is the first\npandemic in history when humanity is the most technologically advanced and\nrelies heavily on social media platforms for connectivity and other benefits.\nUnfortunately, fake news and misinformation regarding this virus is also\navailable to people and causing some massive problems. So, fighting this\ninfodemic has become a significant challenge. We present our solution for the\n\"Constraint@AAAI2021 - COVID19 Fake News Detection in English\" challenge in\nthis work. After extensive experimentation with numerous architectures and\ntechniques, we use eight different transformer-based pre-trained models with\nadditional layers to construct a stacking ensemble classifier and fine-tuned\nthem for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,\n0.979906542 recall, and 0.979907901 f1-score on the test dataset of the\ncompetition.", "doi": "", "date": "2021-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.12027v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 143512992, "title": "A Secure Learning Control Strategy via Dynamic Camouflaging for Unknown\n  Dynamical Systems under Attacks", "abstract": "This paper presents a secure reinforcement learning (RL) based control method\nfor unknown linear time-invariant cyber-physical systems (CPSs) that are\nsubjected to compositional attacks such as eavesdropping and covert attack. We\nconsider the attack scenario where the attacker learns about the dynamic model\nduring the exploration phase of the learning conducted by the designer to learn\na linear quadratic regulator (LQR), and thereafter, use such information to\nconduct a covert attack on the dynamic system, which we refer to as doubly\nlearning-based control and attack (DLCA) framework. We propose a dynamic\ncamouflaging based attack-resilient reinforcement learning (ARRL) algorithm\nwhich can learn the desired optimal controller for the dynamic system, and at\nthe same time, can inject sufficient misinformation in the estimation of system\ndynamics by the attacker. The algorithm is accompanied by theoretical\nguarantees and extensive numerical experiments on a consensus multi-agent\nsystem and on a benchmark power grid model.", "doi": "", "date": "2021-02-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.00573v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1764406168, "title": "A comparative study of Bot Detection techniques methods with an\n  application related to Covid-19 discourse on Twitter", "abstract": "Bot Detection is an essential asset in a period where Online Social\nNetworks(OSN) is a part of our lives. This task becomes more relevant in\ncrises, as the Covid-19 pandemic, where there is an incipient risk of\nproliferation of social bots, producing a possible source of misinformation. In\norder to address this issue, it has been compared different methods to detect\nautomatically social bots on Twitter using Data Selection. The techniques\nutilized to elaborate the bot detection models include the utilization of\nfeatures as the tweets metadata or the Digital Fingerprint of the Twitter\naccounts. In addition, it was analyzed the presence of bots in tweets from\ndifferent periods of the first months of the Covid-19 pandemic, using the bot\ndetection technique which best fits the scope of the task. Moreover, this work\nincludes also analysis over aspects regarding the discourse of bots and humans,\nsuch as sentiment or hashtag utilization.", "doi": "", "date": "2021-02-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.01148v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 527805116, "title": "Hierarchical Multi-head Attentive Network for Evidence-aware Fake News\n  Detection", "abstract": "The widespread of fake news and misinformation in various domains ranging\nfrom politics, economics to public health has posed an urgent need to\nautomatically fact-check information. A recent trend in fake news detection is\nto utilize evidence from external sources. However, existing evidence-aware\nfake news detection methods focused on either only word-level attention or\nevidence-level attention, which may result in suboptimal performance. In this\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\ntextual claims. Our model jointly combines multi-head word-level attention and\nmulti-head document-level attention, which aid explanation in both word-level\nand evidence-level. Experiments on two real-word datasets show that our model\noutperforms seven state-of-the-art baselines. Improvements over baselines are\nfrom 6\\% to 18\\%. Our source code and datasets are released at\n\\texttt{\\url{https://github.com/nguyenvo09/EACL2021}}.", "doi": "", "date": "2021-02-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.02680v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 515533481, "title": "NELA-GT-2020: A Large Multi-Labelled News Dataset for The Study of\n  Misinformation in News Articles", "abstract": "In this paper, we present an updated version of the NELA-GT-2019 dataset,\nentitled NELA-GT-2020. NELA-GT-2020 contains nearly 1.8M news articles from 519\nsources collected between January 1st, 2020 and December 31st, 2020. Just as\nwith NELA-GT-2018 and NELA-GT-2019, these sources come from a wide range of\nmainstream news sources and alternative news sources. Included in the dataset\nare source-level ground truth labels from Media Bias/Fact Check (MBFC) covering\nmultiple dimensions of veracity. Additionally, new in the 2020 dataset are the\nTweets embedded in the collected news articles, adding an extra layer of\ninformation to the data. The NELA-GT-2020 dataset can be found at\nhttps://doi.org/10.7910/DVN/CHMUYZ.", "doi": "", "date": "2021-02-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.04567v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1851452597, "title": "The Sensitivity of Word Embeddings-based Author Detection Models to\n  Semantic-preserving Adversarial Perturbations", "abstract": "Authorship analysis is an important subject in the field of natural language\nprocessing. It allows the detection of the most likely writer of articles,\nnews, books, or messages. This technique has multiple uses in tasks related to\nauthorship attribution, detection of plagiarism, style analysis, sources of\nmisinformation, etc. The focus of this paper is to explore the limitations and\nsensitiveness of established approaches to adversarial manipulations of inputs.\nTo this end, and using those established techniques, we first developed an\nexperimental frame-work for author detection and input perturbations. Next, we\nexperimentally evaluated the performance of the authorship detection model to a\ncollection of semantic-preserving adversarial perturbations of input\nnarratives. Finally, we compare and analyze the effects of different\nperturbation strategies, input and model configurations, and the effects of\nthese on the author detection model.", "doi": "", "date": "2021-02-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.11917v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 471337178, "title": "Images, Emotions, and Credibility: Effect of Emotional Facial Images on\n  Perceptions of News Content Bias and Source Credibility in Social Media", "abstract": "Images are an indispensable part of the news content we consume. Highly\nemotional images from sources of misinformation can greatly influence our\njudgements. We present two studies on the effects of emotional facial images on\nusers' perception of bias in news content and the credibility of sources. In\nstudy 1, we investigate the impact of happy and angry facial images on users'\ndecisions. In study 2, we focus on sources' systematic emotional treatment of\nspecific politicians. Our results show that depending on the political\norientation of the source, the cumulative effect of angry facial emotions\nimpacts users' perceived content bias and source credibility. When sources\nsystematically portray specific politicians as angry, users are more likely to\nfind those sources as less credible and their content as more biased. These\nresults highlight how implicit visual propositions manifested by emotions in\nfacial expressions might have a substantial effect on our trust of news content\nand sources.", "doi": "", "date": "2021-02-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.13167v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2202291566, "title": "A Survey on Stance Detection for Mis- and Disinformation Identification", "abstract": "Detecting attitudes expressed in texts, also known as stance detection, has\nbecome an important task for the detection of false information online, be it\nmisinformation (unintentionally false) or disinformation (intentionally false,\nspread deliberately with malicious intent). Stance detection has been framed in\ndifferent ways, including: (a) as a component of fact-checking, rumour\ndetection, and detecting previously fact-checked claims; or (b) as a task in\nits own right. While there have been prior efforts to contrast stance detection\nwith other related social media tasks such as argumentation mining and\nsentiment analysis, there is no survey examining the relationship between\nstance detection detection and mis- and disinformation detection from a\nholistic viewpoint, which is the focus of this survey. We review and analyse\nexisting work in this area, before discussing lessons learnt and future\nchallenges.", "doi": "", "date": "2021-02-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.00242v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 320828744, "title": "The Rise and Fall of Fake News sites: A Traffic Analysis", "abstract": "Over the past decade, we have witnessed the rise of misinformation on the\nInternet, with online users constantly falling victims of fake news. A\nmultitude of past studies have analyzed fake news diffusion mechanics and\ndetection and mitigation techniques. However, there are still open questions\nabout their operational behavior such as: How old are fake news websites? Do\nthey typically stay online for long periods of time? Do such websites\nsynchronize with each other their up and down time? Do they share similar\ncontent through time? Which third-parties support their operations? How much\nuser traffic do they attract, in comparison to mainstream or real news\nwebsites? In this paper, we perform a first of its kind investigation to answer\nsuch questions regarding the online presence of fake news websites and\ncharacterize their behavior in comparison to real news websites. Based on our\nfindings, we build a content-agnostic ML classifier for automatic detection of\nfake news websites (i.e. accuracy) that are not yet included in manually\ncurated blacklists.", "doi": "", "date": "2021-03-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.09258v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1889884964, "title": "Transfer Learning for Node Regression Applied to Spreading Prediction", "abstract": "Understanding how information propagates in real-life complex networks yields\na better understanding of dynamic processes such as misinformation or epidemic\nspreading. The recently introduced branch of machine learning methods for\nlearning node representations offers many novel applications, one of them being\nthe task of spreading prediction addressed in this paper. We explore the\nutility of the state-of-the-art node representation learners when used to\nassess the effects of spreading from a given node, estimated via extensive\nsimulations. Further, as many real-life networks are topologically similar, we\nsystematically investigate whether the learned models generalize to previously\nunseen networks, showing that in some cases very good model transfer can be\nobtained. This work is one of the first to explore transferability of the\nlearned representations for the task of node regression; we show there exist\npairs of networks with similar structure between which the trained models can\nbe transferred (zero-shot), and demonstrate their competitive performance. To\nour knowledge, this is one of the first attempts to evaluate the utility of\nzero-shot transfer for the task of node regression.", "doi": "", "date": "2021-03-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.00088v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1894105563, "title": "The Burden of Being a Bridge: Understanding the Role of Multilingual\n  Users during the COVID-19 Pandemic", "abstract": "The outbreak of the COVID-19 pandemic triggers infodemic over online social\nnetworks. It is thus important for governments to ensure their official\nmessages outpace misinformation and efficiently reach the public. Some\ncountries and regions that are currently worst affected by the virus including\nEurope, South America and India, encounter an additional difficulty:\nmultilingualism. Understanding the specific role of multilingual users in the\nprocess of information diffusion is critical to adjust their publishing\nstrategies for the governments of such countries and regions. In this paper, we\ninvestigate the role of multilingual users in diffusing information during the\nCOVID-19 pandemic on popular social networks. We collect a large-scale dataset\nof Twitter from a populated multilingual region from the beginning of the\npandemic. With this dataset, we successfully show that multilingual users act\nas bridges in diffusing COVID-19 related information. We further study the\nmental health of multilingual users and show that being the bridges,\nmultilingual users tend to be more negative. This is confirmed by a recent\npsychological study stating that excessive exposure to social media may result\nin a negative mood.", "doi": "", "date": "2021-04-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.04331v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 779338843, "title": "A Few Observations About State-Centric Online Propaganda", "abstract": "This paper presents a few observations about pro-Kremlin propaganda between\n2015 and early 2021 with a dataset from the East Stratcom Task Force (ESTF),\nwhich is affiliated with the European Union (EU) but working independently from\nit. Instead of focusing on misinformation and disinformation, the observations\nare motivated by classical propaganda research and the ongoing transformation\nof media systems. According to the tentative results, (i) the propaganda can be\nassumed to target both domestic and foreign audiences. Of the countries and\nregions discussed, (ii) Russia, Ukraine, the United States, and within Europe,\nGermany, Poland, and the EU have been the most frequently discussed. Also other\nconflict regions such as Syria have often appeared in the propaganda. In terms\nof longitudinal trends, however, (iii) most of these discussions have decreased\nin volume after the digital tsunami in 2016, although the conflict in Ukraine\nseems to have again increased the intensity of pro-Kremlin propaganda. Finally,\n(iv) the themes discussed align with state-centric war propaganda and conflict\nzones, although also post-truth themes frequently appear; from conspiracy\ntheories via COVID-19 to fascism -- anything goes, as is typical to propaganda.", "doi": "", "date": "2021-04-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.04389v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 106412734, "title": "On Representation Learning for Scientific News Articles Using\n  Heterogeneous Knowledge Graphs", "abstract": "In the era of misinformation and information inflation, the credibility\nassessment of the produced news is of the essence. However, fact-checking can\nbe challenging considering the limited references presented in the news. This\nchallenge can be transcended by utilizing the knowledge graph that is related\nto the news articles. In this work, we present a methodology for creating\nscientific news article representations by modeling the directed graph between\nthe scientific news articles and the cited scientific publications. The network\nused for the experiments is comprised of the scientific news articles, their\ntopic, the cited research literature, and their corresponding authors. We\nimplement and present three different approaches: 1) a baseline Relational\nGraph Convolutional Network (R-GCN), 2) a Heterogeneous Graph Neural Network\n(HetGNN) and 3) a Heterogeneous Graph Transformer (HGT). We test these models\nin the downstream task of link prediction on the: a) news article - paper links\nand b) news article - article topic links. The results show promising\napplications of graph neural network approaches in the domains of knowledge\ntracing and scientific news credibility assessment.", "doi": "10.1145/3442442.3451362", "date": "2021-04-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.05866v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3719118346, "title": "NewsCLIPpings: Automatic Generation of Out-of-Context Multimodal Media", "abstract": "The threat of online misinformation is hard to overestimate, with adversaries\nrelying on a range of tools, from cheap fakes to sophisticated deep fakes. We\nare motivated by a threat scenario where an image is being used out of context\nto support a certain narrative expressed in a caption. While some prior\ndatasets for detecting image-text inconsistency can be solved with blind models\ndue to linguistic cues introduced by text manipulation, we propose a dataset\nwhere both image and text are unmanipulated but mismatched. We introduce\nseveral strategies for automatic retrieval of suitable images for the given\ncaptions, capturing cases with related semantics but inconsistent entities as\nwell as matching entities but inconsistent semantic context. Our large-scale\nautomatically generated NewsCLIPpings Dataset requires models to jointly\nanalyze both modalities and to reason about entity mismatch as well as semantic\nmismatch between text and images in news media.", "doi": "", "date": "2021-04-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.05893v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 899884108, "title": "Claim Detection in Biomedical Twitter Posts", "abstract": "Social media contains unfiltered and unique information, which is potentially\nof great value, but, in the case of misinformation, can also do great harm.\nWith regards to biomedical topics, false information can be particularly\ndangerous. Methods of automatic fact-checking and fake news detection address\nthis problem, but have not been applied to the biomedical domain in social\nmedia yet. We aim to fill this research gap and annotate a corpus of 1200\ntweets for implicit and explicit biomedical claims (the latter also with span\nannotations for the claim phrase). With this corpus, which we sample to be\nrelated to COVID-19, measles, cystic fibrosis, and depression, we develop\nbaseline models which detect tweets that contain a claim automatically. Our\nanalyses reveal that biomedical tweets are densely populated with claims (45 %\nin a corpus sampled to contain 1200 tweets focused on the domains mentioned\nabove). Baseline classification experiments with embedding-based classifiers\nand BERT-based transfer learning demonstrate that the detection is challenging,\nhowever, shows acceptable performance for the identification of explicit\nexpressions of claims. Implicit claim tweets are more challenging to detect.", "doi": "", "date": "2021-04-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.11639v2", "pdf": ""}, "publisher-venue": "the BioNLP Workshop at NAACL 2021", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1656152649, "title": "Evaluating Deception Detection Model Robustness To Linguistic Variation", "abstract": "With the increasing use of machine-learning driven algorithmic judgements, it\nis critical to develop models that are robust to evolving or manipulated\ninputs. We propose an extensive analysis of model robustness against linguistic\nvariation in the setting of deceptive news detection, an important task in the\ncontext of misinformation spread online. We consider two prediction tasks and\ncompare three state-of-the-art embeddings to highlight consistent trends in\nmodel performance, high confidence misclassifications, and high impact\nfailures. By measuring the effectiveness of adversarial defense strategies and\nevaluating model susceptibility to adversarial attacks using character- and\nword-perturbed text, we find that character or mixed ensemble models are the\nmost effective defenses and that character perturbation-based attack tactics\nare more successful.", "doi": "", "date": "2021-04-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.11729v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4238334479, "title": "Making GAN-Generated Images Difficult To Spot: A New Attack Against\n  Synthetic Image Detectors", "abstract": "Visually realistic GAN-generated images have recently emerged as an important\nmisinformation threat. Research has shown that these synthetic images contain\nforensic traces that are readily identifiable by forensic detectors.\nUnfortunately, these detectors are built upon neural networks, which are\nvulnerable to recently developed adversarial attacks. In this paper, we propose\na new anti-forensic attack capable of fooling GAN-generated image detectors.\nOur attack uses an adversarially trained generator to synthesize traces that\nthese detectors associate with real images. Furthermore, we propose a technique\nto train our attack so that it can achieve transferability, i.e. it can fool\nunknown CNNs that it was not explicitly trained against. We demonstrate the\nperformance of our attack through an extensive set of experiments, where we\nshow that our attack can fool eight state-of-the-art detection CNNs with\nsynthetic images created using seven different GANs.", "doi": "", "date": "2021-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.12069v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3426106632, "title": "COVID-19 Modeling: A Review", "abstract": "The SARS-CoV-2 virus and COVID-19 disease have posed unprecedented and\noverwhelming demand, challenges and opportunities to domain, model and data\ndriven modeling. This paper provides a comprehensive review of the challenges,\ntasks, methods, progress, gaps and opportunities in relation to modeling\nCOVID-19 problems, data and objectives. It constructs a research landscape of\nCOVID-19 modeling tasks and methods, and further categorizes, summarizes,\ncompares and discusses the related methods and progress of modeling COVID-19\nepidemic transmission processes and dynamics, case identification and tracing,\ninfection diagnosis and medical treatments, non-pharmaceutical interventions\nand their effects, drug and vaccine development, psychological, economic and\nsocial influence and impact, and misinformation, etc. The modeling methods\ninvolve mathematical and statistical models, domain-driven modeling by\nepidemiological compartmental models, medical and biomedical analysis, AI and\ndata science in particular shallow and deep machine learning, simulation\nmodeling, social science methods, and hybrid modeling.", "doi": "", "date": "2021-04-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.12556v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 50718628, "title": "AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance\n  Detection for Fact Checking", "abstract": "With the continuing spread of misinformation and disinformation online, it is\nof increasing importance to develop combating mechanisms at scale in the form\nof automated systems that support multiple languages. One task of interest is\nclaim veracity prediction, which can be addressed using stance detection with\nrespect to relevant documents retrieved online. To this end, we present our new\nArabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from\na diverse set of sources comprising three fact-checking websites and one news\nwebsite. AraStance covers false and true claims from multiple domains (e.g.,\npolitics, sports, health) and several Arab countries, and it is well-balanced\nbetween related and unrelated documents with respect to the claims. We\nbenchmark AraStance, along with two other stance detection datasets, using a\nnumber of BERT-based models. Our best model achieves an accuracy of 85\\% and a\nmacro F1 score of 78\\%, which leaves room for improvement and reflects the\nchallenging nature of AraStance and the task of stance detection in general.", "doi": "", "date": "2021-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13559v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2903490491, "title": "QuTI! Quantifying Text-Image Consistency in Multimodal Documents", "abstract": "The World Wide Web and social media platforms have become popular sources for\nnews and information. Typically, multimodal information, e.g., image and text\nis used to convey information more effectively and to attract attention. While\nin most cases image content is decorative or depicts additional information, it\nhas also been leveraged to spread misinformation and rumors in recent years. In\nthis paper, we present a Web-based demo application that automatically\nquantifies the cross-modal relations of entities (persons, locations, and\nevents) in image and text. The applications are manifold. For example, the\nsystem can help users to explore multimodal articles more efficiently, or can\nassist human assessors and fact-checking efforts in the verification of the\ncredibility of news stories, tweets, or other multimodal documents.", "doi": "", "date": "2021-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13748v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 465365887, "title": "The Evolution of Rumors on a Closed Platform during COVID-19", "abstract": "In this work we looked into a dataset of 114 thousands of suspicious messages\ncollected from the most popular closed messaging platform in Taiwan between\nJanuary and July, 2020. We proposed an hybrid algorithm that could efficiently\ncluster a large number of text messages according their topics and narratives.\nThat is, we obtained groups of messages that are within a limited content\nalterations within each other. By employing the algorithm to the dataset, we\nwere able to look at the content alterations and the temporal dynamics of each\nparticular rumor over time. With qualitative case studies of three COVID-19\nrelated rumors, we have found that key authoritative figures were often\nmisquoted in false information. It was an effective measure to increase the\npopularity of one false information. In addition, fact-check was not effective\nin stopping misinformation from getting attention. In fact, the popularity of\none false information was often more influenced by major societal events and\neffective content alterations.", "doi": "", "date": "2021-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13816v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4090681765, "title": "Deep Insights of Deepfake Technology : A Review", "abstract": "Under the aegis of computer vision and deep learning technology, a new\nemerging techniques has introduced that anyone can make highly realistic but\nfake videos, images even can manipulates the voices. This technology is widely\nknown as Deepfake Technology. Although it seems interesting techniques to make\nfake videos or image of something or some individuals but it could spread as\nmisinformation via internet. Deepfake contents could be dangerous for\nindividuals as well as for our communities, organizations, countries religions\netc. As Deepfake content creation involve a high level expertise with\ncombination of several algorithms of deep learning, it seems almost real and\ngenuine and difficult to differentiate. In this paper, a wide range of articles\nhave been examined to understand Deepfake technology more extensively. We have\nexamined several articles to find some insights such as what is Deepfake, who\nare responsible for this, is there any benefits of Deepfake and what are the\nchallenges of this technology. We have also examined several creation and\ndetection techniques. Our study revealed that although Deepfake is a threat to\nour societies, proper measures and strict regulations could prevent this.", "doi": "", "date": "2021-05-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.00192v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 693966075, "title": "Primary and Secondary Social Media Source Identification", "abstract": "Social networks like Facebook and WhatsApp have enabled users to share images\nwith other users around the world. Along with this has come the rapid spread of\nmisinformation. One step towards verifying the authenticity of an image is\nunderstanding its origin, including it distribution history through social\nmedia. In this paper, we present a method for tracing the posting history of an\nimage across different social networks. To do this, we propose a two-stage\ndeep-learning-based approach, which takes advantage of cascaded fingerprints in\nimages left by social networks during uploading. Our proposed system is not\nreliant upon metadata or similar easily falsifiable information. Through a\nseries of experiments, we show that we are able to outperform existing social\nmedia source identification algorithms. and identify chains of social networks\nup to length two with over over 84% accuracy.", "doi": "", "date": "2021-05-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.02306v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1692936881, "title": "A Synchronized Action Framework for Responsible Detection of\n  Coordination on Social Media", "abstract": "The study of coordinated manipulation of conversations on social media has\nbecome more prevalent as social media's role in amplifying misinformation,\nhate, and polarization has come under scrutiny. We discuss the implications of\nsuccessful coordination detection algorithms based on shifts of power, and\nconsider how responsible coordination detection may be carried out through\nsynchronized action. We then propose a Synchronized Action Framework for\ndetection of automated coordination through construction and analysis of\nmulti-view networks. We validate our framework by examining the Reopen America\nconversation on Twitter, discovering three coordinated campaigns. We further\ninvestigate covert coordination surrounding the protests and find the task to\nbe far more complex than examples seen in prior work, demonstrating the need\nfor our multi-view approach. A cluster of suspicious users is identified and\nthe activity of three members is detailed. These users amplify protest messages\nusing the same hashtags at very similar times, though they all focus on\ndifferent states. Through this analysis, we emphasize both the potential\nusefulness of coordination detection algorithms in investigating amplification,\nand the need for careful and responsible deployment of such tools.", "doi": "", "date": "2021-05-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.07454v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2300808026, "title": "\"Hey Alexa, What do You Know About the COVID-19 Vaccine?\" --\n  (Mis)perceptions of Mass Immunization Among Voice Assistant Users", "abstract": "In this paper, we analyzed the perceived accuracy of COVID-19 vaccine\ninformation spoken back by Amazon Alexa. Unlike social media, Amazon Alexa\ndoesn't apply soft moderation to unverified content, allowing for use of\nthird-party malicious skills to arbitrarily phrase COVID-19 vaccine\ninformation. The results from a 210-participant study suggest that a\nthird-party malicious skill could successful reduce the perceived accuracy\namong the users of information as to who gets the vaccine first, vaccine\ntesting, and the side effects of the vaccine. We also found that the\nvaccine-hesitant participants are drawn to pessimistically rephrased Alexa\nresponses focused on the downsides of the mass immunization. We discuss\nsolutions for soft moderation against misperception-inducing or altogether\nCOVID-19 misinformation malicious third-party skills.", "doi": "", "date": "2021-05-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.07854v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 534316890, "title": "SemEval-2021 Task 6: Detection of Persuasion Techniques in Texts and\n  Images", "abstract": "We describe SemEval-2021 task 6 on Detection of Persuasion Techniques in\nTexts and Images: the data, the annotation guidelines, the evaluation setup,\nthe results, and the participating systems. The task focused on memes and had\nthree subtasks: (i) detecting the techniques in the text, (ii) detecting the\ntext spans where the techniques are used, and (iii) detecting techniques in the\nentire meme, i.e., both in the text and in the image. It was a popular task,\nattracting 71 registrations, and 22 teams that eventually made an official\nsubmission on the test set. The evaluation results for the third subtask\nconfirmed the importance of both modalities, the text and the image. Moreover,\nsome teams reported benefits when not just combining the two modalities, e.g.,\nby using early or late fusion, but rather modeling the interaction between them\nin a joint model.", "doi": "", "date": "2021-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.09284v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3692062525, "title": "SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?", "abstract": "Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges.", "doi": "", "date": "2021-05-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.10671v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3143872029, "title": "Online Hate: Behavioural Dynamics and Relationship with Misinformation", "abstract": "Online debates are often characterised by extreme polarisation and heated\ndiscussions among users. The presence of hate speech online is becoming\nincreasingly problematic, making necessary the development of appropriate\ncountermeasures. In this work, we perform hate speech detection on a corpus of\nmore than one million comments on YouTube videos through a machine learning\nmodel fine-tuned on a large set of hand-annotated data. Our analysis shows that\nthere is no evidence of the presence of \"serial haters\", intended as active\nusers posting exclusively hateful comments. Moreover, coherently with the echo\nchamber hypothesis, we find that users skewed towards one of the two categories\nof video channels (questionable, reliable) are more prone to use inappropriate,\nviolent, or hateful language within their opponents community. Interestingly,\nusers loyal to reliable sources use on average a more toxic language than their\ncounterpart. Finally, we find that the overall toxicity of the discussion\nincreases with its length, measured both in terms of number of comments and\ntime. Our results show that, coherently with Godwin's law, online debates tend\nto degenerate towards increasingly toxic exchanges of views.", "doi": "", "date": "2021-05-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.14005v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3782091404, "title": "Beyond the Spectrum: Detecting Deepfakes via Re-Synthesis", "abstract": "The rapid advances in deep generative models over the past years have led to\nhighly {realistic media, known as deepfakes,} that are commonly\nindistinguishable from real to human eyes. These advances make assessing the\nauthenticity of visual data increasingly difficult and pose a misinformation\nthreat to the trustworthiness of visual content in general. Although recent\nwork has shown strong detection accuracy of such deepfakes, the success largely\nrelies on identifying frequency artifacts in the generated images, which will\nnot yield a sustainable detection approach as generative models continue\nevolving and closing the gap to real images. In order to overcome this issue,\nwe propose a novel fake detection that is designed to re-synthesize testing\nimages and extract visual cues for detection. The re-synthesis procedure is\nflexible, allowing us to incorporate a series of visual tasks - we adopt\nsuper-resolution, denoising and colorization as the re-synthesis. We\ndemonstrate the improved effectiveness, cross-GAN generalization, and\nrobustness against perturbations of our approach in a variety of detection\nscenarios involving multiple generators over CelebA-HQ, FFHQ, and LSUN\ndatasets. Source code is available at\nhttps://github.com/SSAW14/BeyondtheSpectrum.", "doi": "", "date": "2021-05-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.14376v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 891296878, "title": "Detecting Bot-Generated Text by Characterizing Linguistic Accommodation\n  in Human-Bot Interactions", "abstract": "Language generation models' democratization benefits many domains, from\nanswering health-related questions to enhancing education by providing\nAI-driven tutoring services. However, language generation models'\ndemocratization also makes it easier to generate human-like text at-scale for\nnefarious activities, from spreading misinformation to targeting specific\ngroups with hate speech. Thus, it is essential to understand how people\ninteract with bots and develop methods to detect bot-generated text. This paper\nshows that bot-generated text detection methods are more robust across datasets\nand models if we use information about how people respond to it rather than\nusing the bot's text directly. We also analyze linguistic alignment, providing\ninsight into differences between human-human and human-bot conversations.", "doi": "", "date": "2021-06-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.01170v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1969869776, "title": "Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study\n  of the 2019 Indian Election on WhatsApp", "abstract": "There is currently no easy way to fact-check content on WhatsApp and other\nend-to-end encrypted platforms at scale. In this paper, we analyze the\nusefulness of a crowd-sourced \"tipline\" through which users can submit content\n(\"tips\") that they want fact-checked. We compare the tips sent to a WhatsApp\ntipline run during the 2019 Indian national elections with the messages\ncirculating in large, public groups on WhatsApp and other social media\nplatforms during the same period. We find that tiplines are a very useful lens\ninto WhatsApp conversations: a significant fraction of messages and images sent\nto the tipline match with the content being shared on public WhatsApp groups\nand other social media. Our analysis also shows that tiplines cover the most\npopular content well, and a majority of such content is often shared to the\ntipline before appearing in large, public WhatsApp groups. Overall, our\nfindings suggest tiplines can be an effective source for discovering content to\nfact-check.", "doi": "", "date": "2021-06-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.04726v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 635934288, "title": "Mechanisms and Attributes of Echo Chambers in Social Media", "abstract": "Echo chambers may exclude social media users from being exposed to other\nopinions, therefore, can cause rampant negative effects. Among abundant\nevidence are the 2016 and 2020 US presidential elections conspiracy theories\nand polarization, as well as the COVID-19 disinfodemic. To help better detect\necho chambers and mitigate its negative effects, this paper explores the\nmechanisms and attributes of echo chambers in social media. In particular, we\nfirst illustrate four primary mechanisms related to three main factors: human\npsychology, social networks, and automatic systems. We then depict common\nattributes of echo chambers with a focus on the diffusion of misinformation,\nspreading of conspiracy theory, creation of social trends, political\npolarization, and emotional contagion of users. We illustrate each mechanism\nand attribute in a multi-perspective of sociology, psychology, and social\ncomputing with recent case studies. Our analysis suggest an emerging need to\ndetect echo chambers and mitigate their negative effects.", "doi": "", "date": "2021-06-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.05401v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1234448039, "title": "FEVEROUS: Fact Extraction and VERification Over Unstructured and\n  Structured information", "abstract": "Fact verification has attracted a lot of attention in the machine learning\nand natural language processing communities, as it is one of the key methods\nfor detecting misinformation. Existing large-scale benchmarks for this task\nhave focused mostly on textual sources, i.e. unstructured information, and thus\nignored the wealth of information available in structured formats, such as\ntables. In this paper we introduce a novel dataset and benchmark, Fact\nExtraction and VERification Over Unstructured and Structured information\n(FEVEROUS), which consists of 87,026 verified claims. Each claim is annotated\nwith evidence in the form of sentences and/or cells from tables in Wikipedia,\nas well as a label indicating whether this evidence supports, refutes, or does\nnot provide enough information to reach a verdict. Furthermore, we detail our\nefforts to track and minimize the biases present in the dataset and could be\nexploited by models, e.g. being able to predict the label without using\nevidence. Finally, we develop a baseline for verifying claims against text and\ntables which predicts both the correct evidence and verdict for 18% of the\nclaims.", "doi": "", "date": "2021-06-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.05707v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2048351935, "title": "Flipping Stance: Social Influence on Bot's and Non Bot's COVID Vaccine\n  Stance", "abstract": "Social influence characterizes the change of opinions in a complex social\nenvironment, incorporating an individual's past stances and the impact of\ninterpersonal influence through the social network influence. In this work, we\nobserve stance changes towards the coronavirus vaccine on Twitter from April\n2020 to May 2021, where 1\\% of the agents exhibit the stance flipping behavior,\nof which 53.7\\% are identified bots. We then propose a novel social influence\nmodel to characterize the change in stance of agents. This model considers an\nagent's and his neighbor's past tweets and the overall network structure\ntowards a stance score. In our experiments, the model achieves 86\\% accuracy.\nIn our analysis, bot agents require lesser social influence to flip stances and\na larger proportion of bots flip.", "doi": "", "date": "2021-06-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.11076v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3638250496, "title": "A preliminary approach to knowledge integrity risk assessment in\n  Wikipedia projects", "abstract": "Wikipedia is one of the main repositories of free knowledge available today,\nwith a central role in the Web ecosystem. For this reason, it can also be a\nbattleground for actors trying to impose specific points of view or even\nspreading disinformation online. There is a growing need to monitor its\n\"health\" but this is not an easy task. Wikipedia exists in over 300 language\neditions and each project is maintained by a different community, with their\nown strengths, weaknesses and limitations. In this paper, we introduce a\ntaxonomy of knowledge integrity risks across Wikipedia projects and a first set\nof indicators to assess internal risks related to community and content issues,\nas well as external threats such as the geopolitical and media landscape. On\ntop of this taxonomy, we offer a preliminary analysis illustrating how the lack\nof editors' geographical diversity might represent a knowledge integrity risk.\nThese are the first steps of a research project to build a Wikipedia Knowledge\nIntegrity Risk Observatory.", "doi": "", "date": "2021-06-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.15940v1", "pdf": ""}, "publisher-venue": "MIS2", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 840841843, "title": "Tackling COVID-19 Infodemic using Deep Learning", "abstract": "Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia.", "doi": "", "date": "2021-07-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.02012v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1436787940, "title": "Putting words into the system's mouth: A targeted attack on neural\n  machine translation using monolingual data poisoning", "abstract": "Neural machine translation systems are known to be vulnerable to adversarial\ntest inputs, however, as we show in this paper, these systems are also\nvulnerable to training attacks. Specifically, we propose a poisoning attack in\nwhich a malicious adversary inserts a small poisoned sample of monolingual text\ninto the training set of a system trained using back-translation. This sample\nis designed to induce a specific, targeted translation behaviour, such as\npeddling misinformation. We present two methods for crafting poisoned examples,\nand show that only a tiny handful of instances, amounting to only 0.02% of the\ntraining set, is sufficient to enact a successful attack. We outline a defence\nmethod against said attacks, which partly ameliorates the problem. However, we\nstress that this is a blind-spot in modern NMT, demanding immediate attention.", "doi": "", "date": "2021-07-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.05243v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1450306098, "title": "As Easy as 1, 2, 3: Behavioural Testing of NMT Systems for Numerical\n  Translation", "abstract": "Mistranslated numbers have the potential to cause serious effects, such as\nfinancial loss or medical misinformation. In this work we develop comprehensive\nassessments of the robustness of neural machine translation systems to\nnumerical text via behavioural testing. We explore a variety of numerical\ntranslation capabilities a system is expected to exhibit and design effective\ntest examples to expose system underperformance. We find that numerical\nmistranslation is a general issue: major commercial systems and\nstate-of-the-art research models fail on many of our test examples, for high-\nand low-resource languages. Our tests reveal novel errors that have not\npreviously been reported in NMT systems, to the best of our knowledge. Lastly,\nwe discuss strategies to mitigate numerical mistranslation.", "doi": "", "date": "2021-07-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.08357v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 706497914, "title": "Analysis of External Content in the Vaccination Discussion on Twitter", "abstract": "The spread of coronavirus and anti-vaccine conspiracies online hindered\npublic health responses to the pandemic. We examined the content of external\narticles shared on Twitter from February to June 2020 to understand how\nconspiracy theories and fake news competed with legitimate sources of\ninformation. Examining external content--articles, rather than social media\nposts--is a novel methodology that allows for non-social media specific\nanalysis of misinformation, tracking of changing narratives over time, and\ndetermining which types of resources (government, news, scientific, or dubious)\ndominate the pandemic vaccine conversation. We find that distinct narratives\nemerge, those narratives change over time, and lack of government and\nscientific messaging on coronavirus created an information vacuum filled by\nboth traditional news and conspiracy theories.", "doi": "", "date": "2021-07-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.09183v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1192150129, "title": "The False COVID-19 Narratives That Keep Being Debunked: A Spatiotemporal\n  Analysis", "abstract": "The onset of the Coronavirus disease 2019 (COVID-19) pandemic instigated a\nglobal infodemic that has brought unprecedented challenges for society as a\nwhole. During this time, a number of manual fact-checking initiatives have\nemerged to alleviate the spread of dis/mis-information. This study is about\nCOVID-19 debunks published in multiple languages by different fact-checking\norganisations, sometimes as far as several months apart, despite the fact that\nthe claim has already been fact-checked before. The spatiotemporal analysis\nreveals that similar or nearly duplicate false COVID-19 narratives have been\nspreading in multifarious modalities on various social media platforms in\ndifferent countries. We also find that misinformation involving general medical\nadvice has spread across multiple countries and hence has the highest\nproportion of false COVID-19 narratives that keep being debunked. Furthermore,\nas manual fact-checking is an onerous task in itself, therefore debunking\nsimilar claims recurrently is leading to a waste of resources. To this end, we\npropound the idea of the inclusion of multilingual debunk search in the\nfact-checking pipeline.", "doi": "", "date": "2021-07-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.12303v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2286211845, "title": "Exploring the Links between Personality Traits and Suscep;bility to\n  Disinformation", "abstract": "The growth of online Digital/social media has allowed a variety of ideas and\nopinions to coexist. Social Media has appealed users due to the ease of fast\ndissemination of information at low cost and easy access. However, due to the\ngrowth in affordance of Digital platforms, users have become prone to consume\ndisinformation, misinformation, propaganda, and conspiracy theories. In this\npaper, we wish to explore the links between the personality traits given by the\nBig Five Inventory and their susceptibility to disinformation. More\nspeciDically, this study is attributed to capture the short- term as well as\nthe long-term effects of disinformation and its effects on the Dive personality\ntraits. Further, we expect to observe that different personalities traits have\ndifferent shifts in opinion and different increase or decrease of uncertainty\non an issue after consuming the disinformation. Based on the Dindings of this\nstudy, we would like to propose a personalized narrative-based change in\nbehavior for different personality traits.", "doi": "10.1145/3465336.3475121", "date": "2021-08-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.05150v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 362223087, "title": "Narrative Sensemaking: Strategies for Narrative Maps Construction", "abstract": "Narrative sensemaking is a fundamental process to understand sequential\ninformation. Narrative maps are a visual representation framework that can aid\nanalysts in this process. They allow analysts to understand the big picture of\na narrative, uncover new relationships between events, and model connections\nbetween storylines. As a sensemaking tool, narrative maps have applications in\nintelligence analysis, misinformation modeling, and computational journalism.\nIn this work, we seek to understand how analysts construct narrative maps in\norder to improve narrative map representation and extraction methods. We\nperform an experiment with a data set of news articles. Our main contribution\nis an analysis of how analysts construct narrative maps. The insights extracted\nfrom our study can be used to design narrative map visualizations, extraction\nalgorithms, and visual analytics tools to support the sensemaking process.", "doi": "", "date": "2021-08-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.06035v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 803707930, "title": "Informed Crowds Can Effectively Identify Misinformation", "abstract": "Can crowd workers be trusted to judge whether news-like articles circulating\non the Internet are wildly misleading, or does partisanship and inexperience\nget in the way? We assembled pools of both liberal and conservative crowd\nraters and tested three ways of asking them to make judgments about 374\narticles. In a no research condition, they were just asked to view the article\nand then render a judgment. In an individual research condition, they were also\nasked to search for corroborating evidence and provide a link to the best\nevidence they found. In a collective research condition, they were not asked to\nsearch, but instead to look at links collected from workers in the individual\nresearch condition. The individual research condition reduced the partisanship\nof judgments. Moreover, the judgments of a panel of sixteen or more crowd\nworkers were better than that of a panel of three expert journalists, as\nmeasured by alignment with a held out journalist's ratings. Without research,\nthe crowd judgments were better than those of a single journalist, but not as\ngood as the average of two journalists.", "doi": "", "date": "2021-08-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.07898v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2413608975, "title": "Ensuring the Inclusive Use of Natural Language Processing in the Global\n  Response to COVID-19", "abstract": "Natural language processing (NLP) plays a significant role in tools for the\nCOVID-19 pandemic response, from detecting misinformation on social media to\nhelping to provide accurate clinical information or summarizing scientific\nresearch. However, the approaches developed thus far have not benefited all\npopulations, regions or languages equally. We discuss ways in which current and\nfuture NLP approaches can be made more inclusive by covering low-resource\nlanguages, including alternative modalities, leveraging out-of-the-box tools\nand forming meaningful partnerships. We suggest several future directions for\nresearchers interested in maximizing the positive societal impacts of NLP.", "doi": "", "date": "2021-08-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.10791v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 64926461, "title": "Detecting Propaganda on the Sentence Level during the COVID-19 Pandemic", "abstract": "The spread of misinformation, conspiracy, and questionable content and\ninformation manipulation by foreign adversaries on social media has surged\nalong with the COVID-19 pandemic. Such malicious cyber-enabled actions may\ncause increasing social polarization, health crises, and property loss. In this\npaper, using fine-tuned contextualized embedding trained on Reddit, we tackle\nthe detection of the propaganda of such user accounts and their targeted issues\non Twitter during March 2020 when the COVID-19 epidemic became recognized as a\npandemic. Our result shows that the pro-China group appeared to be tweeting 35\nto 115 times more than the neutral group. At the same time, neutral groups were\ntweeting more positive-attitude content and voicing alarm for the COVID-19\nsituation. The pro-China group was also using more call-for-action words on\npolitical issues not necessarily China-related.", "doi": "", "date": "2021-07-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12269v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3908535536, "title": "Predicting the Factuality of Reporting of News Media Using Observations\n  About User Attention in Their YouTube Channels", "abstract": "We propose a novel framework for predicting the factuality of reporting of\nnews media outlets by studying the user attention cycles in their YouTube\nchannels. In particular, we design a rich set of features derived from the\ntemporal evolution of the number of views, likes, dislikes, and comments for a\nvideo, which we then aggregate to the channel level. We develop and release a\ndataset for the task, containing observations of user attention on YouTube\nchannels for 489 news media. Our experiments demonstrate both complementarity\nand sizable improvements over state-of-the-art textual representations.", "doi": "", "date": "2021-08-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12519v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 516016509, "title": "Interpretable Propaganda Detection in News Articles", "abstract": "Online users today are exposed to misleading and propagandistic news articles\nand media posts on a daily basis. To counter thus, a number of approaches have\nbeen designed aiming to achieve a healthier and safer online news and media\nconsumption. Automatic systems are able to support humans in detecting such\ncontent; yet, a major impediment to their broad adoption is that besides being\naccurate, the decisions of such systems need also to be interpretable in order\nto be trusted and widely adopted by users. Since misleading and propagandistic\ncontent influences readers through the use of a number of deception techniques,\nwe propose to detect and to show the use of such techniques as a way to offer\ninterpretability. In particular, we define qualitatively descriptive features\nand we analyze their suitability for detecting deception techniques. We further\nshow that our interpretable features can be easily combined with pre-trained\nlanguage models, yielding state-of-the-art results.", "doi": "", "date": "2021-08-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12802v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2844524300, "title": "BioFors: A Large Biomedical Image Forensics Dataset", "abstract": "Research in media forensics has gained traction to combat the spread of\nmisinformation. However, most of this research has been directed towards\ncontent generated on social media. Biomedical image forensics is a related\nproblem, where manipulation or misuse of images reported in biomedical research\ndocuments is of serious concern. The problem has failed to gain momentum beyond\nan academic discussion due to an absence of benchmark datasets and standardized\ntasks. In this paper we present BioFors -- the first dataset for benchmarking\ncommon biomedical image manipulations. BioFors comprises 47,805 images\nextracted from 1,031 open-source research papers. Images in BioFors are divided\ninto four categories -- Microscopy, Blot/Gel, FACS and Macroscopy. We also\npropose three tasks for forensic analysis -- external duplication detection,\ninternal duplication detection and cut/sharp-transition detection. We benchmark\nBioFors on all tasks with suitable state-of-the-art algorithms. Our results and\nanalysis show that existing algorithms developed on common computer vision\ndatasets are not robust when applied to biomedical images, validating that more\nresearch is required to address the unique challenges of biomedical image\nforensics.", "doi": "", "date": "2021-08-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12961v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 694972715, "title": "Effect of the Born-Infeld Parameter in higher dimensional Hawking\n  radiation", "abstract": "We show in detail that the Hawking temperature calculated from the surface\ngravity is in agreement with the result of exact semi-classical radiation\nspectrum for higher dimensional linear dilaton black holes in various theories.\nWe extend the method derived first by Cl\\'ement-Fabris-Marques for\n4-dimensional linear dilaton black hole solutions to the higher dimensions in\ntheories such as Einstein-Maxwell-Dilaton, Einstein-Yang-Mills-Dilaton and\nEinstein-Yang-Mills-Born-Infeld-Dilaton. Similar to the\nCl\\'ement-Fabris-Marques results, it is proved that whenever an analytic\nsolution is available to the massless scalar wave equation in the background of\nhigher dimensional massive linear dilaton black holes, an exact computation of\nthe radiation spectrum leads to the Hawking temperature T_{H} in the high\nfrequency regime. The significance of the dimensionality on the value of T_{H}\nis shown, explicitly. For a chosen dimension, we demonstrate how higher\ndimensional linear dilaton black holes interpolate between the black hole\nsolutions with Yang-Mills and electromagnetic fields by altering the\nBorn-Infeld parameter in aspect of measurable quantity T_{H}. Finally, we\nexplain the reason of, why massless higher dimensional linear dilaton black\nholes cannot radiate.", "doi": "10.1016/j.physletb.2009.01.024", "date": "2009-02-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/0902.0666v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1088975329, "title": "Clustering Memes in Social Media", "abstract": "The increasing pervasiveness of social media creates new opportunities to\nstudy human social behavior, while challenging our capability to analyze their\nmassive data streams. One of the emerging tasks is to distinguish between\ndifferent kinds of activities, for example engineered misinformation campaigns\nversus spontaneous communication. Such detection problems require a formal\ndefinition of meme, or unit of information that can spread from person to\nperson through the social network. Once a meme is identified, supervised\nlearning methods can be applied to classify different types of communication.\nThe appropriate granularity of a meme, however, is hardly captured from\nexisting entities such as tags and keywords. Here we present a framework for\nthe novel task of detecting memes by clustering messages from large streams of\nsocial data. We evaluate various similarity measures that leverage content,\nmetadata, network features, and their combinations. We also explore the idea of\npre-clustering on the basis of existing entities. A systematic evaluation is\ncarried out using a manually curated dataset as ground truth. Our analysis\nshows that pre-clustering and a combination of heterogeneous features yield the\nbest trade-off between number of clusters and their quality, demonstrating that\na simple combination based on pairwise maximization of similarity is as\neffective as a non-trivial optimization of parameters. Our approach is fully\nautomatic, unsupervised, and scalable for real-time detection of memes in\nstreaming data.", "doi": "10.1145/2492517.2492530", "date": "2013-10-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1310.2665v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3208311617, "title": "Manipulation and abuse on social media", "abstract": "The computer science research community has became increasingly interested in\nthe study of social media due to their pervasiveness in the everyday life of\nmillions of individuals. Methodological questions and technical challenges\nabound as more and more data from social platforms become available for\nanalysis. This data deluge not only yields the unprecedented opportunity to\nunravel questions about online individuals' behavior at scale, but also allows\nto explore the potential perils that the massive adoption of social media\nbrings to our society. These communication channels provide plenty of\nincentives (both economical and social) and opportunities for abuse. As social\nmedia activity became increasingly intertwined with the events in the offline\nworld, individuals and organizations have found ways to exploit these platforms\nto spread misinformation, to attack and smear others, or to deceive and\nmanipulate. During crises, social media have been effectively used for\nemergency response, but fear-mongering actions have also triggered mass\nhysteria and panic. Criminal gangs and terrorist organizations like ISIS adopt\nsocial media for propaganda and recruitment. Synthetic activity and social bots\nhave been used to coordinate orchestrated astroturf campaigns, to manipulate\npolitical elections and the stock market. The lack of effective content\nverification systems on many of these platforms, including Twitter and\nFacebook, rises concerns when younger users become exposed to cyber-bulling,\nharassment, or hate speech, inducing risks like depression and suicide. This\narticle illustrates some of the recent advances facing these issues and\ndiscusses what it remains to be done, including the challenges to address in\nthe future to make social media a more useful and accessible, safer and\nhealthier environment for all users.", "doi": "10.1145/2749279.2749283", "date": "2015-03-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1503.03752v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 64687896, "title": "Visual Themes and Sentiment on Social Networks To Aid First Responders\n  During Crisis Events", "abstract": "Online Social Networks explode with activity whenever a crisis event takes\nplace. Most content generated as part of this activity is a mixture of text and\nimages, and is particularly useful for first responders to identify popular\ntopics of interest and gauge the pulse and sentiment of citizens. While\nmultiple researchers have used text to identify, analyze and measure themes and\npublic sentiment during such events, little work has explored visual themes\nfloating on networks in the form of images, and the sentiment inspired by them.\nGiven the potential of visual content for influencing users' thoughts and\nemotions, we perform a large scale analysis to compare popular themes and\nsentiment across images and textual content posted on Facebook during the\nterror attacks that took place in Paris in 2015. Using state-of-the-art image\nsummarization techniques, we discovered multiple visual themes which were\npopular in images, but were not identifiable through text. We uncovered\ninstances of misinformation and false flag (conspiracy) theories among popular\nimage themes, which were not prominent in user generated textual content, and\ncan be of particular inter- est to first responders. Our analysis also revealed\nthat while textual content posted after the attacks reflected negative\nsentiment, images inspired positive sentiment. To the best of our knowledge,\nthis is the first large scale study of images posted on social networks during\na crisis event.", "doi": "", "date": "2016-10-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1610.07772v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1333326211, "title": "Public discourse and news consumption on online social media: A\n  quantitative, cross-platform analysis of the Italian Referendum", "abstract": "The rising attention to the spreading of fake news and unsubstantiated rumors\non online social media and the pivotal role played by confirmation bias led\nresearchers to investigate different aspects of the phenomenon. Experimental\nevidence showed that confirmatory information gets accepted even if containing\ndeliberately false claims while dissenting information is mainly ignored or\nmight even increase group polarization. It seems reasonable that, to address\nmisinformation problem properly, we have to understand the main determinants\nbehind content consumption and the emergence of narratives on online social\nmedia. In this paper we address such a challenge by focusing on the discussion\naround the Italian Constitutional Referendum by conducting a quantitative,\ncross-platform analysis on both Facebook public pages and Twitter accounts. We\nobserve the spontaneous emergence of well-separated communities on both\nplatforms. Such a segregation is completely spontaneous, since no\ncategorization of contents was performed a priori. By exploring the dynamics\nbehind the discussion, we find that users tend to restrict their attention to a\nspecific set of Facebook pages/Twitter accounts. Finally, taking advantage of\nautomatic topic extraction and sentiment analysis techniques, we are able to\nidentify the most controversial topics inside and across both platforms. We\nmeasure the distance between how a certain topic is presented in the\nposts/tweets and the related emotional response of users. Our results provide\ninteresting insights for the understanding of the evolution of the core\nnarratives behind different echo chambers and for the early detection of\nmassive viral phenomena around false claims.", "doi": "", "date": "2017-02-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1702.06016v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 706777121, "title": "A Comprehensive Low and High-level Feature Analysis for Early Rumor\n  Detection on Twitter", "abstract": "Recent work have done a good job in modeling rumors and detecting them over\nmicroblog streams. However, the performance of their automatic approaches are\nnot relatively high when looking early in the diffusion. A first intuition is\nthat, at early stage, most of the aggregated rumor features (e.g., propagation\nfeatures) are not mature and distinctive enough. The objective of rumor\ndebunking in microblogs, however, are to detect these misinformation as early\nas possible. In this work, we leverage neural models in learning the hidden\nrepresentations of individual rumor-related tweets at the very beginning of a\nrumor. Our extensive experiments show that the resulting signal improves our\nclassification performance over time, significantly within the first 10 hours.\nTo deepen the understanding of these low and high-level features in\ncontributing to the model performance over time, we conduct an extensive study\non a wide range of high impact rumor features for the 48 hours range. The end\nmodel that engages these features are shown to be competitive, reaches over 90%\naccuracy and out-performs strong baselines in our carefully cured dataset.", "doi": "", "date": "2017-11-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.00726v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1880915272, "title": "Fake News Detection in Social Networks via Crowd Signals", "abstract": "Our work considers leveraging crowd signals for detecting fake news and is\nmotivated by tools recently introduced by Facebook that enable users to flag\nfake news. By aggregating users' flags, our goal is to select a small subset of\nnews every day, send them to an expert (e.g., via a third-party fact-checking\norganization), and stop the spread of news identified as fake by an expert. The\nmain objective of our work is to minimize the spread of misinformation by\nstopping the propagation of fake news in the network. It is especially\nchallenging to achieve this objective as it requires detecting fake news with\nhigh-confidence as quickly as possible. We show that in order to leverage\nusers' flags efficiently, it is crucial to learn about users' flagging\naccuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian\ninference for detecting fake news and jointly learns about users' flagging\naccuracy over time. Our algorithm employs posterior sampling to actively trade\noff exploitation (selecting news that maximize the objective value at a given\nepoch) and exploration (selecting news that maximize the value of information\ntowards learning about users' flagging accuracy). We demonstrate the\neffectiveness of our approach via extensive experiments and show the power of\nleveraging community signals for fake news detection.", "doi": "", "date": "2017-11-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.09025v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3483437554, "title": "Emotional Dynamics in the Age of Misinformation", "abstract": "According to the World Economic Forum, the diffusion of unsubstantiated\nrumors on online social media is one of the main threats for our society.\n  The disintermediated paradigm of content production and consumption on online\nsocial media might foster the formation of homophile communities\n(echo-chambers) around specific worldviews. Such a scenario has been shown to\nbe a vivid environment for the diffusion of false claims, in particular with\nrespect to conspiracy theories. Not rarely, viral phenomena trigger naive (and\nfunny) social responses -- e.g., the recent case of Jade Helm 15 where a simple\nmilitary exercise turned out to be perceived as the beginning of the civil war\nin the US. In this work, we address the emotional dynamics of collective\ndebates around distinct kind of news -- i.e., science and conspiracy news --\nand inside and across their respective polarized communities (science and\nconspiracy news).\n  Our findings show that comments on conspiracy posts tend to be more negative\nthan on science posts. However, the more the engagement of users, the more they\ntend to negative commenting (both on science and conspiracy). Finally, zooming\nin at the interaction among polarized communities, we find a general negative\npattern. As the number of comments increases -- i.e., the discussion becomes\nlonger -- the sentiment of the post is more and more negative.", "doi": "10.1371/journal.pone.0138740", "date": "2015-05-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1505.08001v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 250170659, "title": "Bayesian Social Influence in the Online Realm", "abstract": "Our opinions, which things we like or dislike, depend on the opinions of\nthose around us. Nowadays, we are influenced by the opinions of online\nstrangers, expressed in comments and ratings on online platforms. Here, we\nperform novel \"academic A/B testing\" experiments with over 2,500 participants\nto measure the extent of that influence. In our experiments, the participants\nwatch and evaluate videos on mirror proxies of YouTube and Vimeo. We control\nthe comments and ratings that are shown underneath each of these videos. Our\nstudy shows that from 5$\\%$ up to 40$\\%$ of subjects adopt the majority opinion\nof strangers expressed in the comments. Using Bayes' theorem, we derive a\nflexible and interpretable family of models of social influence, in which each\nindividual forms posterior opinions stochastically following a logit model. The\nvariants of our mixture model that maximize Akaike information criterion\nrepresent two sub-populations, i.e., non-influenceable and influenceable\nindividuals. The prior opinions of the non-influenceable individuals are\nstrongly correlated with the external opinions and have low standard error,\nwhereas the prior opinions of influenceable individuals have high standard\nerror and become correlated with the external opinions due to social influence.\nOur findings suggest that opinions are random variables updated via Bayes' rule\nwhose standard deviation is correlated with opinion influenceability. Based on\nthese findings, we discuss how to hinder opinion manipulation and\nmisinformation diffusion in the online realm.", "doi": "", "date": "2015-12-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1512.00770v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2921138684, "title": "Cost Effective Rumor Containment in Social Networks", "abstract": "The spread of rumors through social media and online social networks can not\nonly disrupt the daily lives of citizens but also result in loss of life and\nproperty. A rumor spreads when individuals, who are unable decide the\nauthenticity of the information, mistake the rumor as genuine information and\npass it on to their acquaintances. We propose a solution where a set of\nindividuals (based on their degree) in the social network are trained and\nprovided resources to help them distinguish a rumor from genuine information.\nBy formulating an optimization problem we calculate the optimum set of\nindividuals, who must undergo training, and the quality of training that\nminimizes the expected training cost and ensures an upper bound on the size of\nthe rumor outbreak. Our primary contribution is that although the optimization\nproblem turns out to be non convex, we show that the problem is equivalent to\nsolving a set of linear programs. This result also allows us to solve the\nproblem of minimizing the size of rumor outbreak for a given cost budget. The\noptimum solution displays an interesting pattern which can be implemented as a\nheuristic. These results can prove to be very useful for social planners and\nlaw enforcement agencies for preventing dangerous rumors and misinformation\nepidemics.", "doi": "", "date": "2014-03-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1403.6315v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1373659177, "title": "Investigating Rumor Propagation with TwitterTrails", "abstract": "Social media have become part of modern news reporting, used by journalists\nto spread information and find sources, or as a news source by individuals. The\nquest for prominence and recognition on social media sites like Twitter can\nsometimes eclipse accuracy and lead to the spread of false information. As a\nway to study and react to this trend, we introduce {\\sc TwitterTrails}, an\ninteractive, web-based tool ({\\tt twittertrails.com}) that allows users to\ninvestigate the origin and propagation characteristics of a rumor and its\nrefutation, if any, on Twitter. Visualizations of burst activity, propagation\ntimeline, retweet and co-retweeted networks help its users trace the spread of\na story. Within minutes {\\sc TwitterTrails} will collect relevant tweets and\nautomatically answer several important questions regarding a rumor: its\noriginator, burst characteristics, propagators and main actors according to the\naudience. In addition, it will compute and report the rumor's level of\nvisibility and, as an example of the power of crowdsourcing, the audience's\nskepticism towards it which correlates with the rumor's credibility. We\nenvision {\\sc TwitterTrails} as valuable tool for individual use, but we\nespecially for amateur and professional journalists investigating recent and\nbreaking stories. Further, its expanding collection of investigated rumors can\nbe used to answer questions regarding the amount and success of misinformation\non Twitter.", "doi": "", "date": "2014-11-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1411.3550v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2959210153, "title": "Combining Fact Extraction and Verification with Neural Semantic Matching\n  Networks", "abstract": "The increasing concern with misinformation has stimulated research efforts on\nautomatic fact checking. The recently-released FEVER dataset introduced a\nbenchmark fact-verification task in which a system is asked to verify a claim\nusing evidential sentences from Wikipedia documents. In this paper, we present\na connected system consisting of three homogeneous neural semantic matching\nmodels that conduct document retrieval, sentence selection, and claim\nverification jointly for fact extraction and verification. For evidence\nretrieval (document retrieval and sentence selection), unlike traditional\nvector space IR models in which queries and sources are matched in some\npre-designed term vector space, we develop neural models to perform deep\nsemantic matching from raw textual input, assuming no intermediate term\nrepresentation and no access to structured external knowledge bases. We also\nshow that Pageview frequency can also help improve the performance of evidence\nretrieval results, that later can be matched by using our neural semantic\nmatching network. For claim verification, unlike previous approaches that\nsimply feed upstream retrieved evidence and the claim to a natural language\ninference (NLI) model, we further enhance the NLI model by providing it with\ninternal semantic relatedness scores (hence integrating it with the evidence\nretrieval modules) and ontological WordNet features. Experiments on the FEVER\ndataset indicate that (1) our neural semantic matching method outperforms\npopular TF-IDF and encoder models, by significant margins on all evidence\nretrieval metrics, (2) the additional relatedness score and WordNet features\nimprove the NLI model via better semantic awareness, and (3) by formalizing all\nthree subtasks as a similar semantic matching problem and improving on all\nthree stages, the complete model is able to achieve the state-of-the-art\nresults on the FEVER test set.", "doi": "", "date": "2018-11-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.07039v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4245465761, "title": "Descendant distributions for the impact of mutant contagion on networks", "abstract": "Contagion, broadly construed, refers to anything that can spread infectiously\nfrom peer to peer. Examples include communicable diseases, rumors,\nmisinformation, ideas, innovations, bank failures, and electrical blackouts.\nSometimes, as in the 1918 Spanish flu epidemic, a contagion mutates at some\npoint as it spreads through a network. Here, using a simple\nsusceptible-infected (SI) model of contagion, we explore the downstream impact\nof a single mutation event. Assuming that this mutation occurs at a random node\nin the contact network, we calculate the distribution of the number of\n\"descendants,\" $d$, downstream from the initial \"Patient Zero\" mutant. We find\nthat the tail of the distribution decays as $d^{-2}$ for complete graphs,\nrandom graphs, small-world networks, networks with block-like structure, and\nother infinite-dimensional networks. This prediction agrees with the observed\nstatistics of memes propagating and mutating on Facebook, and is expected to\nhold for other effectively infinite-dimensional networks, such as the global\nhuman contact network. In a wider context, our approach suggests a possible\nstarting point for a mesoscopic theory of contagion. Such a theory would focus\non the paths traced by a spreading contagion, thereby furnishing an\nintermediate level of description between that of individual nodes and the\ntotal infected population. We anticipate that contagion pathways will hold\nvaluable lessons, given their role as the conduits through which single\nmutations, innovations, or failures can sweep through a network as a whole.", "doi": "10.1103/physrevresearch.2.033005", "date": "2019-10-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.00655v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2732850406, "title": "Identifying Nuances in Fake News vs. Satire: Using Semantic and\n  Linguistic Cues", "abstract": "The blurry line between nefarious fake news and protected-speech satire has\nbeen a notorious struggle for social media platforms. Further to the efforts of\nreducing exposure to misinformation on social media, purveyors of fake news\nhave begun to masquerade as satire sites to avoid being demoted. In this work,\nwe address the challenge of automatically classifying fake news versus satire.\nPrevious work have studied whether fake news and satire can be distinguished\nbased on language differences. Contrary to fake news, satire stories are\nusually humorous and carry some political or social message. We hypothesize\nthat these nuances could be identified using semantic and linguistic cues.\nConsequently, we train a machine learning method using semantic representation,\nwith a state-of-the-art contextual language model, and with linguistic features\nbased on textual coherence metrics. Empirical evaluation attests to the merits\nof our approach compared to the language-based baseline and sheds light on the\nnuances between fake news and satire. As avenues for future work, we consider\nstudying additional linguistic features related to the humor aspect, and\nenriching the data with current news events, to help identify a political or\nsocial message.", "doi": "10.18653/v1/d19-5004", "date": "2019-10-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.01160v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2384037954, "title": "SCG: Spotting Coordinated Groups in Social Media", "abstract": "Recent events have led to a burgeoning awareness on the misuse of social\nmedia sites to affect political events, sway public opinion, and confuse the\nvoters. Such serious, hostile mass manipulation has motivated a large body of\nworks on bots/troll detection and fake news detection, which mostly focus on\nclassifying at the user level based on the content generated by the users. In\nthis study, we jointly analyze the connections among the users, as well as the\ncontent generated by them to Spot Coordinated Groups (SCG), sets of users that\nare likely to be organized towards impacting the general discourse. Given their\ntiny size (relative to the whole data), detecting these groups is\ncomputationally hard. Our proposed method detects these tiny-clusters\neffectively and efficiently. We deploy our SCG method to summarize and explain\nthe coordinated groups on Twitter around the 2019 Canadian Federal Elections,\nby analyzing over 60 thousand user accounts with 3.4 million followership\nconnections, and 1.3 million unique hashtags in the content of their tweets.\nThe users in the detected coordinated groups are over 4x more likely to get\nsuspended, whereas the hashtags which characterize their creed are linked to\nmisinformation campaigns.", "doi": "", "date": "2019-10-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.07130v5", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3915918027, "title": "Trend of Narratives in the Age of Misinformation", "abstract": "Social media enabled a direct path from producer to consumer of contents\nchanging the way users get informed, debate, and shape their worldviews. Such a\n{\\em disintermediation} weakened consensus on social relevant issues in favor\nof rumors, mistrust, and fomented conspiracy thinking -- e.g., chem-trails\ninducing global warming, the link between vaccines and autism, or the New World\nOrder conspiracy.\n  In this work, we study through a thorough quantitative analysis how different\nconspiracy topics are consumed in the Italian Facebook. By means of a\nsemi-automatic topic extraction strategy, we show that the most discussed\ncontents semantically refer to four specific categories: {\\em environment},\n{\\em diet}, {\\em health}, and {\\em geopolitics}. We find similar patterns by\ncomparing users activity (likes and comments) on posts belonging to different\nsemantic categories. However, if we focus on the lifetime -- i.e., the distance\nin time between the first and the last comment for each user -- we notice a\nremarkable difference within narratives -- e.g., users polarized on geopolitics\nare more persistent in commenting, whereas the less persistent are those\nfocused on diet related topics. Finally, we model users mobility across various\ntopics finding that the more a user is active, the more he is likely to join\nall topics. Once inside a conspiracy narrative users tend to embrace the\noverall corpus.", "doi": "10.1371/journal.pone.0134641", "date": "2015-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1504.05163v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1990838161, "title": "Determining the Veracity of Rumours on Twitter", "abstract": "While social networks can provide an ideal platform for up-to-date\ninformation from individuals across the world, it has also proved to be a place\nwhere rumours fester and accidental or deliberate misinformation often emerges.\nIn this article, we aim to support the task of making sense from social media\ndata, and specifically, seek to build an autonomous message-classifier that\nfilters relevant and trustworthy information from Twitter. For our work, we\ncollected about 100 million public tweets, including users' past tweets, from\nwhich we identified 72 rumours (41 true, 31 false). We considered over 80\ntrustworthiness measures including the authors' profile and past behaviour, the\nsocial network connections (graphs), and the content of tweets themselves. We\nran modern machine-learning classifiers over those measures to produce\ntrustworthiness scores at various time windows from the outbreak of the rumour.\nSuch time-windows were key as they allowed useful insight into the progression\nof the rumours. From our findings, we identified that our model was\nsignificantly more accurate than similar studies in the literature. We also\nidentified critical attributes of the data that give rise to the\ntrustworthiness scores assigned. Finally we developed a software demonstration\nthat provides a visual user interface to allow the user to examine the\nanalysis.", "doi": "10.1007/978-3-319-47880-7_12", "date": "2016-11-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1611.06314v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 68581505, "title": "Limited individual attention and online virality of low-quality\n  information", "abstract": "Social media are massive marketplaces where ideas and news compete for our\nattention. Previous studies have shown that quality is not a necessary\ncondition for online virality and that knowledge about peer choices can distort\nthe relationship between quality and popularity. However, these results do not\nexplain the viral spread of low-quality information, such as the digital\nmisinformation that threatens our democracy. We investigate quality\ndiscrimination in a stylized model of online social network, where individual\nagents prefer quality information, but have behavioral limitations in managing\na heavy flow of information. We measure the relationship between the quality of\nan idea and its likelihood to become prevalent at the system level. We find\nthat both information overload and limited attention contribute to a\ndegradation in the market's discriminative power. A good tradeoff between\ndiscriminative power and diversity of information is possible according to the\nmodel. However, calibration with empirical data characterizing information load\nand finite attention in real social media reveals a weak correlation between\nquality and popularity of information. In these realistic conditions, the model\npredicts that high-quality information has little advantage over low-quality\ninformation.", "doi": "", "date": "2017-01-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1701.02694v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2065568351, "title": "Some Like it Hoax: Automated Fake News Detection in Social Networks", "abstract": "In recent years, the reliability of information on the Internet has emerged\nas a crucial issue of modern society. Social network sites (SNSs) have\nrevolutionized the way in which information is spread by allowing users to\nfreely share content. As a consequence, SNSs are also increasingly used as\nvectors for the diffusion of misinformation and hoaxes. The amount of\ndisseminated information and the rapidity of its diffusion make it practically\nimpossible to assess reliability in a timely manner, highlighting the need for\nautomatic hoax detection systems.\n  As a contribution towards this objective, we show that Facebook posts can be\nclassified with high accuracy as hoaxes or non-hoaxes on the basis of the users\nwho \"liked\" them. We present two classification techniques, one based on\nlogistic regression, the other on a novel adaptation of boolean crowdsourcing\nalgorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users,\nwe obtain classification accuracies exceeding 99% even when the training set\ncontains less than 1% of the posts. We further show that our techniques are\nrobust: they work even when we restrict our attention to the users who like\nboth hoax and non-hoax posts. These results suggest that mapping the diffusion\npattern of information can be a useful component of automatic hoax detection\nsystems.", "doi": "", "date": "2017-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1704.07506v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3798674009, "title": "Finding Streams in Knowledge Graphs to Support Fact Checking", "abstract": "The volume and velocity of information that gets generated online limits\ncurrent journalistic practices to fact-check claims at the same rate.\nComputational approaches for fact checking may be the key to help mitigate the\nrisks of massive misinformation spread. Such approaches can be designed to not\nonly be scalable and effective at assessing veracity of dubious claims, but\nalso to boost a human fact checker's productivity by surfacing relevant facts\nand patterns to aid their analysis. To this end, we present a novel,\nunsupervised network-flow based approach to determine the truthfulness of a\nstatement of fact expressed in the form of a (subject, predicate, object)\ntriple. We view a knowledge graph of background information about real-world\nentities as a flow network, and knowledge as a fluid, abstract commodity. We\nshow that computational fact checking of such a triple then amounts to finding\na \"knowledge stream\" that emanates from the subject node and flows toward the\nobject node through paths connecting them. Evaluation on a range of real-world\nand hand-crafted datasets of facts related to entertainment, business, sports,\ngeography and more reveals that this network-flow model can be very effective\nin discerning true statements from false ones, outperforming existing\nalgorithms on many test cases. Moreover, the model is expressive in its ability\nto automatically discover several useful path patterns and surface relevant\nfacts that may help a human fact checker corroborate or refute a claim.", "doi": "", "date": "2017-08-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1708.07239v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2227294849, "title": "Automated Crowdturfing Attacks and Defenses in Online Review Systems", "abstract": "Malicious crowdsourcing forums are gaining traction as sources of spreading\nmisinformation online, but are limited by the costs of hiring and managing\nhuman workers. In this paper, we identify a new class of attacks that leverage\ndeep learning language models (Recurrent Neural Networks or RNNs) to automate\nthe generation of fake online reviews for products and services. Not only are\nthese attacks cheap and therefore more scalable, but they can control rate of\ncontent output to eliminate the signature burstiness that makes crowdsourced\ncampaigns easy to detect.\n  Using Yelp reviews as an example platform, we show how a two phased review\ngeneration and customization attack can produce reviews that are\nindistinguishable by state-of-the-art statistical detectors. We conduct a\nsurvey-based user study to show these reviews not only evade human detection,\nbut also score high on \"usefulness\" metrics by users. Finally, we develop novel\nautomated defenses against these attacks, by leveraging the lossy\ntransformation introduced by the RNN training and generation cycle. We consider\ncountermeasures against our mechanisms, show that they produce unattractive\ncost-benefit tradeoffs for attackers, and that they can be further curtailed by\nsimple constraints imposed by online service providers.", "doi": "", "date": "2017-08-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1708.08151v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3156026446, "title": "The Wisdom of Polarized Crowds", "abstract": "As political polarization in the United States continues to rise, the\nquestion of whether polarized individuals can fruitfully cooperate becomes\npressing. Although diversity of individual perspectives typically leads to\nsuperior team performance on complex tasks, strong political perspectives have\nbeen associated with conflict, misinformation and a reluctance to engage with\npeople and perspectives beyond one's echo chamber. It is unclear whether\nself-selected teams of politically diverse individuals will create higher or\nlower quality outcomes. In this paper, we explore the effect of team political\ncomposition on performance through analysis of millions of edits to Wikipedia's\nPolitical, Social Issues, and Science articles. We measure editors' political\nalignments by their contributions to conservative versus liberal articles. A\nsurvey of editors validates that those who primarily edit liberal articles\nidentify more strongly with the Democratic party and those who edit\nconservative ones with the Republican party. Our analysis then reveals that\npolarized teams---those consisting of a balanced set of politically diverse\neditors---create articles of higher quality than politically homogeneous teams.\nThe effect appears most strongly in Wikipedia's Political articles, but is also\nobserved in Social Issues and even Science articles. Analysis of article \"talk\npages\" reveals that politically polarized teams engage in longer, more\nconstructive, competitive, and substantively focused but linguistically diverse\ndebates than political moderates. More intense use of Wikipedia policies by\npolitically diverse teams suggests institutional design principles to help\nunleash the power of politically polarized teams.", "doi": "10.1038/s41562-019-0541-6", "date": "2017-11-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1712.06414v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3488192464, "title": "Sampling the News Producers: A Large News and Feature Data Set for the\n  Study of the Complex Media Landscape", "abstract": "The complexity and diversity of today's media landscape provides many\nchallenges for researchers studying news producers. These producers use many\ndifferent strategies to get their message believed by readers through the\nwriting styles they employ, by repetition across different media sources with\nor without attribution, as well as other mechanisms that are yet to be studied\ndeeply. To better facilitate systematic studies in this area, we present a\nlarge political news data set, containing over 136K news articles, from 92 news\nsources, collected over 7 months of 2017. These news sources are carefully\nchosen to include well-established and mainstream sources, maliciously fake\nsources, satire sources, and hyper-partisan political blogs. In addition to\neach article we compute 130 content-based and social media engagement features\ndrawn from a wide range of literature on political bias, persuasion, and\nmisinformation. With the release of the data set, we also provide the source\ncode for feature computation. In this paper, we discuss the first release of\nthe data set and demonstrate 4 use cases of the data and features: news\ncharacterization, engagement characterization, news attribution and content\ncopying, and discovering news narratives.", "doi": "", "date": "2018-03-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1803.10124v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2160218133, "title": "Semi-supervised Content-based Detection of Misinformation via Tensor\n  Embeddings", "abstract": "Fake news may be intentionally created to promote economic, political and\nsocial interests, and can lead to negative impacts on humans beliefs and\ndecisions. Hence, detection of fake news is an emerging problem that has become\nextremely prevalent during the last few years. Most existing works on this\ntopic focus on manual feature extraction and supervised classification models\nleveraging a large number of labeled (fake or real) articles. In contrast, we\nfocus on content-based detection of fake news articles, while assuming that we\nhave a small amount of labels, made available by manual fact-checkers or\nautomated sources. We argue this is a more realistic setting in the presence of\nmassive amounts of content, most of which cannot be easily factchecked. To that\nend, we represent collections of news articles as multi-dimensional tensors,\nleverage tensor decomposition to derive concise article embeddings that capture\nspatial/contextual information about each news article, and use those\nembeddings to create an article-by-article graph on which we propagate limited\nlabels. Results on three real-world datasets show that our method performs on\npar or better than existing models that are fully supervised, in that we\nachieve better detection accuracy using fewer labels. In particular, our\nproposed method achieves 75.43% of accuracy using only 30% of labels of a\npublic dataset while an SVM-based classifier achieved 67.43%. Furthermore, our\nmethod achieves 70.92% of accuracy in a large dataset using only 2% of labels.", "doi": "", "date": "2018-04-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.09088v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3040241370, "title": "Polarization Rank: A Study on European News Consumption on Facebook", "abstract": "The advent of WWW changed the way we can produce and access information.\nRecent studies showed that users tend to select information that is consistent\nwith their system of beliefs, forming polarized groups of like-minded people\naround shared narratives where dissenting information is ignored. In this\nenvironment, users cooperate to frame and reinforce their shared narrative\nmaking any attempt at debunking inefficient. Such a configuration occurs even\nin the consumption of news online, and considering that 63% of users access\nnews directly form social media, one hypothesis is that more polarization\nallows for further spreading of misinformation. Along this path, we focus on\nthe polarization of users around news outlets on Facebook in different European\ncountries (Italy, France, Spain and Germany). First, we compare the pages'\nposting behavior and the users' interacting patterns across countries and\nobserve different posting, liking and commenting rates. Second, we explore the\ntendency of users to interact with different pages (i.e., selective exposure)\nand the emergence of polarized communities generated around specific pages.\nThen, we introduce a new metric -- i.e., polarization rank -- to measure\npolarization of communities for each country. We find that Italy is the most\npolarized country, followed by France, Germany and lastly Spain. Finally, we\npresent a variation of the Bounded Confidence Model to simulate the emergence\nof these communities by considering the users' engagement and trust on the\nnews. Our findings suggest that trust in information broadcaster plays a\npivotal role against polarization of users online.", "doi": "", "date": "2018-05-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1805.08030v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1856198542, "title": "Sea of Lights: Practical Device-to-Device Security Bootstrapping in the\n  Dark", "abstract": "Practical solutions to bootstrap security in today's information and\ncommunication systems critically depend on centralized services for\nauthentication as well as key and trust management. This is particularly true\nfor mobile users. Identity providers such as Google or Facebook have active\nuser bases of two billion each, and the subscriber number of mobile operators\nexceeds five billion unique users as of early 2018. If these centralized\nservices go completely `dark' due to natural or man made disasters, large scale\nblackouts, or country-wide censorship, the users are left without practical\nsolutions to bootstrap security on their mobile devices. Existing distributed\nsolutions, for instance, the so-called web-of-trust are not sufficiently\nlightweight. Furthermore, they support neither cross-application on mobile\ndevices nor strong protection of key material using hardware security modules.\nWe propose Sea of Lights(SoL), a practical lightweight scheme for bootstrapping\ndevice-to-device security wirelessly, thus, enabling secure distributed\nself-organized networks. It is tailored to operate `in the dark' and provides\nstrong protection of key material as well as an intuitive means to build a\nlightweight web-of-trust. SoL is particularly well suited for local or urban\noperation in scenarios such as the coordination of emergency response, where it\nhelps containing/limiting the spreading of misinformation. As a proof of\nconcept, we implement SoL in the Android platform and hence test its\nfeasibility on real mobile devices. We further evaluate its key performance\naspects using simulation.", "doi": "10.1109/lcn.2018.8638102", "date": "2018-08-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.04671v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1735893205, "title": "Feature Analysis for Assessing the Quality of Wikipedia Articles through\n  Supervised Classification", "abstract": "Nowadays, thanks to Web 2.0 technologies, people have the possibility to\ngenerate and spread contents on different social media in a very easy way. In\nthis context, the evaluation of the quality of the information that is\navailable online is becoming more and more a crucial issue. In fact, a constant\nflow of contents is generated every day by often unknown sources, which are not\ncertified by traditional authoritative entities. This requires the development\nof appropriate methodologies that can evaluate in a systematic way these\ncontents, based on `objective' aspects connected with them. This would help\nindividuals, who nowadays tend to increasingly form their opinions based on\nwhat they read online and on social media, to come into contact with\ninformation that is actually useful and verified. Wikipedia is nowadays one of\nthe biggest online resources on which users rely as a source of information.\nThe amount of collaboratively generated content that is sent to the online\nencyclopedia every day can let to the possible creation of low-quality articles\n(and, consequently, misinformation) if not properly monitored and revised. For\nthis reason, in this paper, the problem of automatically assessing the quality\nof Wikipedia articles is considered. In particular, the focus is on the\nanalysis of hand-crafted features that can be employed by supervised machine\nlearning techniques to perform the classification of Wikipedia articles on\nqualitative bases. With respect to prior literature, a wider set of\ncharacteristics connected to Wikipedia articles are taken into account and\nillustrated in detail. Evaluations are performed by considering a labeled\ndataset provided in a prior work, and different supervised machine learning\nalgorithms, which produced encouraging results with respect to the considered\nfeatures.", "doi": "", "date": "2018-12-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.02655v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 939609288, "title": "Socratrees: Exploring the Design of Argument Technology for Layman Users", "abstract": "Terms like 'misinformation', 'fake news', and 'echo chambers' permeate\ncurrent discussions on the state of the Internet. We believe a lack of\ntechnological support to evaluate, contest, and reason about information\nonline---as opposed to merely disseminating it---lies at the root of these\nproblems. Several argument technologies support such functionality, but have\nseen limited use outside of niche communities. Most research systems\noveremphasize argument analysis and structure, standing in stark contrast with\nthe informal dialectical nature of everyday argumentation. Conversely,\nnon-academic systems overlook important implications for design which can be\nderived from theory. In this paper, we present the design of a system aiming to\nstrike a balance between structured argumentation and ease of use. Socratrees\nis a website for collaborative argumentative discussion targeting layman users,\nbut includes sophisticated community guidelines and novel features inspired by\ninformal logic. During an exploratory study, we evaluate the usefulness of our\nimposed structure on argumentation and investigate how users perceive it.\nContributing to arguments remains a complex task, but most users learned to do\nso effectively with minimal guidance and all recognized that the structure of\nSocratrees may improve online discussion and results in a clearer overview of\narguments.", "doi": "", "date": "2018-12-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.04478v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 569400534, "title": "Trollslayer: Crowdsourcing and Characterization of Abusive Birds in\n  Twitter", "abstract": "As of today, abuse is a pressing issue to participants and administrators of\nOnline Social Networks (OSN). Abuse in Twitter can spawn from arguments\ngenerated for influencing outcomes of a political election, the use of bots to\nautomatically spread misinformation, and generally speaking, activities that\ndeny, disrupt, degrade or deceive other participants and, or the network. Given\nthe difficulty in finding and accessing a large enough sample of abuse ground\ntruth from the Twitter platform, we built and deployed a custom crawler that we\nuse to judiciously collect a new dataset from the Twitter platform with the aim\nof characterizing the nature of abusive users, a.k.a abusive birds, in the\nwild. We provide a comprehensive set of features based on users' attributes, as\nwell as social-graph metadata. The former includes metadata about the account\nitself, while the latter is computed from the social graph among the sender and\nthe receiver of each message. Attribute-based features are useful to\ncharacterize user's accounts in OSN, while graph-based features can reveal the\ndynamics of information dissemination across the network. In particular, we\nderive the Jaccard index as a key feature to reveal the benign or malicious\nnature of directed messages in Twitter. To the best of our knowledge, we are\nthe first to propose such a similarity metric to characterize abuse in Twitter.", "doi": "10.1109/snams.2018.8554898", "date": "2018-12-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.06156v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3955599426, "title": "Stance Classification for Rumour Analysis in Twitter: Exploiting\n  Affective Information and Conversation Structure", "abstract": "Analysing how people react to rumours associated with news in social media is\nan important task to prevent the spreading of misinformation, which is nowadays\nwidely recognized as a dangerous tendency. In social media conversations, users\nshow different stances and attitudes towards rumourous stories. Some users take\na definite stance, supporting or denying the rumour at issue, while others just\ncomment it, or ask for additional evidence related to the veracity of the\nrumour. On this line, a new shared task has been proposed at SemEval-2017 (Task\n8, SubTask A), which is focused on rumour stance classification in English\ntweets. The goal is predicting user stance towards emerging rumours in Twitter,\nin terms of supporting, denying, querying, or commenting the original rumour,\nlooking at the conversation threads originated by the rumour. This paper\ndescribes a new approach to this task, where the use of conversation-based and\naffective-based features, covering different facets of affect, has been\nexplored. Our classification model outperforms the best-performing systems for\nstance classification at SemEval-2017 Task 8, showing the effectiveness of the\nfeature set proposed.", "doi": "", "date": "2019-01-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.01911v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3543653369, "title": "Influence Minimization Under Budget and Matroid Constraints: Extended\n  Version", "abstract": "Recently, online social networks have become major battlegrounds for\npolitical campaigns, viral marketing, and the dissemination of news. As a\nconsequence, ''bad actors'' are increasingly exploiting these platforms,\nbecoming a key challenge for their administrators, businesses and the society\nin general. The spread of fake news is a classical example of the abuse of\nsocial networks by these actors. While some have advocated for stricter\npolicies to control the spread of misinformation in social networks, this often\nhappens in detriment of their democratic and organic structure. In this paper\nwe study how to limit the influence of a target set of users in a network via\nthe removal of a few edges. The idea is to control the diffusion processes\nwhile minimizing the amount of disturbance in the network structure.\n  We formulate the influence limitation problem in a data-driven fashion, by\ntaking into account past propagation traces. Moreover, we consider two types of\nconstraints over the set of edge removals, a budget constraint and also a, more\ngeneral, set of matroid constraints. These problems lead to interesting\nchallenges in terms of algorithm design. For instance, we are able to show that\ninfluence limitation is APX-hard and propose deterministic and probabilistic\napproximation algorithms for the budgeted and matroid version of the problem,\nrespectively. Our experiments show that the proposed solutions outperform the\nbaselines by up to 40%.", "doi": "", "date": "2019-01-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.02156v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1913191459, "title": "Quantifying echo chamber effects in information spreading over political\n  communication networks", "abstract": "Echo chambers in online social networks, in which users prefer to interact\nonly with ideologically-aligned peers, are believed to facilitate\nmisinformation spreading and contribute to radicalize political discourse. In\nthis paper, we gauge the effects of echo chambers in information spreading\nphenomena over political communication networks. Mining 12 million Twitter\nmessages, we reconstruct a network in which users interchange opinions related\nto the impeachment of the former Brazilian President Dilma Rousseff. We define\na continuous {political position} parameter, independent of the network's\nstructure, that allows to quantify the presence of echo chambers in the\nstrongly connected component of the network, reflected in two well-separated\ncommunities of similar sizes with opposite views of the impeachment process. By\nmeans of simple spreading models, we show that the capability of users in\npropagating the content they produce, measured by the associated spreadability,\nstrongly depends on their attitude. Users expressing pro-impeachment sentiments\nare capable to transmit information, on average, to a larger audience than\nusers expressing anti-impeachment sentiments. Furthermore, the users'\nspreadability is correlated to the diversity, in terms of political position,\nof the audience reached. Our method can be exploited to identify the presence\nof echo chambers and their effects across different contexts and shed light\nupon the mechanisms allowing to break echo chambers.", "doi": "10.1140/epjds/s13688-019-0213-9", "date": "2019-01-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.03688v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1243274265, "title": "Message Distortion in Information Cascades", "abstract": "Information diffusion is usually modeled as a process in which immutable\npieces of information propagate over a network. In reality, however, messages\nare not immutable, but may be morphed with every step, potentially entailing\nlarge cumulative distortions. This process may lead to misinformation even in\nthe absence of malevolent actors, and understanding it is crucial for modeling\nand improving online information systems. Here, we perform a controlled,\ncrowdsourced experiment in which we simulate the propagation of information\nfrom medical research papers. Starting from the original abstracts, crowd\nworkers iteratively shorten previously produced summaries to increasingly\nsmaller lengths. We also collect control summaries where the original abstract\nis compressed directly to the final target length. Comparing cascades to\ncontrols allows us to separate the effect of the length constraint from that of\naccumulated distortion. Via careful manual coding, we annotate lexical and\nsemantic units in the medical abstracts and track them along cascades. We find\nthat iterative summarization has a negative impact due to the accumulation of\nerror, but that high-quality intermediate summaries result in less distorted\nmessages than in the control case. Different types of information behave\ndifferently; in particular, the conclusion of a medical abstract (i.e., its key\nmessage) is distorted most. Finally, we compare abstractive with extractive\nsummaries, finding that the latter are less prone to semantic distortion.\nOverall, this work is a first step in studying information cascades without the\nassumption that disseminated content is immutable, with implications on our\nunderstanding of the role of word-of-mouth effects on the misreporting of\nscience.", "doi": "10.1145/3308558.3313531", "date": "2019-02-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.09197v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2792100818, "title": "Less is More: Semi-Supervised Causal Inference for Detecting Pathogenic\n  Users in Social Media", "abstract": "Recent years have witnessed a surge of manipulation of public opinion and\npolitical events by malicious social media actors. These users are referred to\nas \"Pathogenic Social Media (PSM)\" accounts. PSMs are key users in spreading\nmisinformation in social media to viral proportions. These accounts can be\neither controlled by real users or automated bots. Identification of PSMs is\nthus of utmost importance for social media authorities. The burden usually\nfalls to automatic approaches that can identify these accounts and protect\nsocial media reputation. However, lack of sufficient labeled examples for\ndevising and training sophisticated approaches to combat these accounts is\nstill one of the foremost challenges facing social media firms. In contrast,\nunlabeled data is abundant and cheap to obtain thanks to massive user-generated\ndata. In this paper, we propose a semi-supervised causal inference PSM\ndetection framework, SemiPsm, to compensate for the lack of labeled data. In\nparticular, the proposed method leverages unlabeled data in the form of\nmanifold regularization and only relies on cascade information. This is in\ncontrast to the existing approaches that use exhaustive feature engineering\n(e.g., profile information, network structure, etc.). Evidence from empirical\nexperiments on a real-world ISIS-related dataset from Twitter suggests\npromising results of utilizing unlabeled instances for detecting PSMs.", "doi": "", "date": "2019-03-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.01693v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 724805736, "title": "Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking", "abstract": "Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.", "doi": "", "date": "2019-03-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.08404v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1030167565, "title": "Belief places and spaces: Mapping cognitive environments", "abstract": "Beliefs are not facts, but they are factive - they feel like facts. This\nproperty is what can make misinformation dangerous. Being able to deliberately\nnavigate through a landscape of often conflicting factive statements is\ndifficult when there is no way to show the relationships between them without\nincorporating the information in linear, narrative forms. In this paper, we\npresent a mechanism to produce maps of belief places, where populations agree\non salient features of fictional environments, and belief spaces, where\nsubgroups have related but distinct perspectives. Using a model developed using\nagent-based simulation, we show that by observing the repeated behaviors of\nhuman participants in the same social context, it is possible to build maps\nthat show the shared narrative environment overlaid with traces that show\nunique, individual or subgroup perspectives. Our contribution is a\nproof-of-concept system, based on the affordances of fantasy tabletop\nrole-playing games, which support multiple groups interacting with the same\ndungeon in a controlled, online environment. The techniques used in this\nprocess are mathematically straightforward, and should be generalizable to\nauto-generating larger-scale maps of belief spaces from other corpora, such as\ndiscussions on social media.", "doi": "", "date": "2019-07-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.04191v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2715945953, "title": "Automatic Fact-Checking Using Context and Discourse Information", "abstract": "We study the problem of automatic fact-checking, paying special attention to\nthe impact of contextual and discourse information. We address two related\ntasks: (i) detecting check-worthy claims, and (ii) fact-checking claims. We\ndevelop supervised systems based on neural networks, kernel-based support\nvector machines, and combinations thereof, which make use of rich input\nrepresentations in terms of discourse cues and contextual features. For the\ncheck-worthiness estimation task, we focus on political debates, and we model\nthe target claim in the context of the full intervention of a participant and\nthe previous and the following turns in the debate, taking into account\ncontextual meta information. For the fact-checking task, we focus on answer\nverification in a community forum, and we model the veracity of the answer with\nrespect to the entire question--answer thread in which it occurs as well as\nwith respect to other related posts from the entire forum. We develop annotated\ndatasets for both tasks and we run extensive experimental evaluation,\nconfirming that both types of information ---but especially contextual\nfeatures--- play an important role.", "doi": "10.1145/3297722", "date": "2019-08-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.01328v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1133899816, "title": "Homophily on social networks changes evolutionary advantage in\n  competitive information diffusion", "abstract": "Competitive information diffusion on large-scale social networks reveals\nfundamental characteristics of rumor contagions and has profound influence on\npublic opinion formation. There has been growing interest in exploring\ndynamical mechanisms of the competing evolutions recently. Nevertheless, the\nimpacts of population homophily, which determines powerful collective human\nbehaviors, remains unclear. In this paper, we incorporate homophily effects\ninto a modified competitive ignorant-spreader-ignorant (SIS) rumor diffusion\nmodel with generalized population preference. Using microscopic Markov chain\napproach, we first derive the phase diagram of competing diffusion results and\nexamine how competitive information spreads and evolves on social networks. We\nthen explore the detailed effects of homophily, which is modeled by a rewiring\nmechanism. Results show that homophily promotes the formation of divided \"echo\nchambers\" and protects the disadvantaged information from extinction, which\nfurther changes or even reverses the evolutionary advantage, i.e., the\ndifference of final proportions of the competitive information. We highlight\nthe conclusion that the reversals may happen only when the initially\ndisadvantaged information has stronger transmission ability, owning diffusion\nadvantage over the other one. Our framework provides profound insight into\ncompeting dynamics with population homophily, which may pave ways for further\ncontrolling misinformation and guiding public belief systems. Moreover, the\nreversing condition sheds light on designing effective competing strategies in\nmany real scenarios.", "doi": "10.1088/1367-2630/ab623c", "date": "2019-08-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.05992v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2253373602, "title": "FakeSpotter: A Simple yet Robust Baseline for Spotting AI-Synthesized\n  Fake Faces", "abstract": "In recent years, generative adversarial networks (GANs) and its variants have\nachieved unprecedented success in image synthesis. They are widely adopted in\nsynthesizing facial images which brings potential security concerns to humans\nas the fakes spread and fuel the misinformation. However, robust detectors of\nthese AI-synthesized fake faces are still in their infancy and are not ready to\nfully tackle this emerging challenge. In this work, we propose a novel\napproach, named FakeSpotter, based on monitoring neuron behaviors to spot\nAI-synthesized fake faces. The studies on neuron coverage and interactions have\nsuccessfully shown that they can be served as testing criteria for deep\nlearning systems, especially under the settings of being exposed to adversarial\nattacks. Here, we conjecture that monitoring neuron behavior can also serve as\nan asset in detecting fake faces since layer-by-layer neuron activation\npatterns may capture more subtle features that are important for the fake\ndetector. Experimental results on detecting four types of fake faces\nsynthesized with the state-of-the-art GANs and evading four perturbation\nattacks show the effectiveness and robustness of our approach.", "doi": "", "date": "2019-09-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.06122v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3004357316, "title": "SpoC: Spoofing Camera Fingerprints", "abstract": "Thanks to the fast progress in synthetic media generation, creating realistic\nfalse images has become very easy. Such images can be used to wrap \"rich\" fake\nnews with enhanced credibility, spawning a new wave of high-impact, high-risk\nmisinformation campaigns. Therefore, there is a fast-growing interest in\nreliable detectors of manipulated media. The most powerful detectors, to date,\nrely on the subtle traces left by any device on all images acquired by it. In\nparticular, due to proprietary in-camera processes, like demosaicing or\ncompression, each camera model leaves trademark traces that can be exploited\nfor forensic analyses. The absence or distortion of such traces in the target\nimage is a strong hint of manipulation. In this paper, we challenge such\ndetectors to gain better insight into their vulnerabilities. This is an\nimportant study in order to build better forgery detectors able to face\nmalicious attacks. Our proposal consists of a GAN-based approach that injects\ncamera traces into synthetic images. Given a GAN-generated image, we insert the\ntraces of a specific camera model into it and deceive state-of-the-art\ndetectors into believing the image was acquired by that model. Likewise, we\ndeceive independent detectors of synthetic GAN images into believing the image\nis real. Experiments prove the effectiveness of the proposed method in a wide\narray of conditions. Moreover, no prior information on the attacked detectors\nis needed, but only sample images from the target camera.", "doi": "", "date": "2019-11-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.12069v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 363472266, "title": "A Multi-Feature Diffusion Model: Rumor Blocking in Social Networks", "abstract": "Online social networks provide a convenient platform for the spread of\nrumors, which could lead to serious aftermaths such as economic losses and\npublic panic. The classical rumor blocking problem aims to launch a set of\nnodes as a positive cascade to compete with misinformation in order to limit\nthe spread of rumors. However, most of the related researches were based on\none-dimensional diffusion model. In reality, there are more than one feature\nassociated with an object. The user's impression on this object is determined\nnot just by one feature but by his/her overall evaluation on all of these\nfeatures. Thus, the influence spread of this object can be decomposed into the\nspread of multiple features. Based on that, we propose a Multi-Feature\ndiffusion model (MF-model) in this paper, and a novel problem, Multi-Feature\nRumor Blocking (MFRB), is formulated on a multi-layer network structure\naccording to this model. To solve MFRB, we design a creative sampling method,\ncalled Multi-Sampling, which can be applied to a multi-layer network structure.\nInspired by martingale analysis, the Revised-IMM algorithm is proposed, and\nreturns a satisfactory approximate solution to MFRB. Finally, we evaluate our\nproposed algorithm by conducting experiments on real datasets, and show the\neffectiveness and accuracy of the Revised-IMM algorithm and significantly\noutperforms other baseline algorithms.", "doi": "10.1109/tnet.2020.3032893", "date": "2019-12-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.03481v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 52263096, "title": "BERT has a Moral Compass: Improvements of ethical and moral values of\n  machines", "abstract": "Allowing machines to choose whether to kill humans would be devastating for\nworld peace and security. But how do we equip machines with the ability to\nlearn ethical or even moral choices? Jentzsch et al.(2019) showed that applying\nmachine learning to human texts can extract deontological ethical reasoning\nabout \"right\" and \"wrong\" conduct by calculating a moral bias score on a\nsentence level using sentence embeddings. The machine learned that it is\nobjectionable to kill living beings, but it is fine to kill time; It is\nessential to eat, yet one might not eat dirt; it is important to spread\ninformation, yet one should not spread misinformation. However, the evaluated\nmoral bias was restricted to simple actions -- one verb -- and a ranking of\nactions with surrounding context. Recently BERT ---and variants such as RoBERTa\nand SBERT--- has set a new state-of-the-art performance for a wide range of NLP\ntasks. But has BERT also a better moral compass? In this paper, we discuss and\nshow that this is indeed the case. Thus, recent improvements of language\nrepresentations also improve the representation of the underlying ethical and\nmoral values of the machine. We argue that through an advanced semantic\nrepresentation of text, BERT allows one to get better insights of moral and\nethical values implicitly represented in text. This enables the Moral Choice\nMachine (MCM) to extract more accurate imprints of moral choices and ethical\nvalues.", "doi": "", "date": "2019-12-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.05238v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3447416430, "title": "A Novel Approach in Strategic Planning of Power Networks Against\n  Physical Attacks", "abstract": "The reported work points at developing a practical approach for power\ntransmission planners to secure power networks from potential deliberate\nattacks. We study the interaction between a system planner (defender) and a\nrational attacker who threatens the operation of the power grid. In addition to\nthe commonly used hardening strategy for protecting the network, a new sort of\nresource is introduced under the deception concept. Feint and deception are\nacknowledged as effective tools for misleading the attacker in strategic\nplanning. To this end, the defender deception is mathematically formulated by\nreleasing misinformation about his plan in the shared cognition-based model. To\nreduce the risk of damage in case of deception failure, preemptive-goal\nprogramming is utilized to prioritize the hardening strategy for the vital\ncomponents. Furthermore, the value of posturing is introduced which is the\nbenefits that the deception brings to the system. The problems are formulated\nas tri-level mixed-integer linear programming and solved by the\nconstraint-and-column generation method. Comprehensive simulation studies\nperformed on WSCC 9-bus and IEEE 118-bus systems indicate how the defender will\nsave significant cost from protecting his network with posturing rather than\nhardening and the proposed approach is a promising development to ensure the\nsecure operation of power networks.", "doi": "", "date": "2019-12-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.05603v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3000081815, "title": "Subgraph Classification, Clustering and Centrality for a Degree\n  Asymmetric Twitter Based Graph Case Study: Suicidality", "abstract": "We present some initial results from a case study in social media data\nharvesting and visualization utilizing the tools and analytical features of\nNodeXL applied to a degree asymmetric vertex graph set. We consider twitter\ngraphs harvested for topics related to suicidal ideation, suicide attempts,\nself-harm and bullycide. While the twitter-sphere only captures a small and age\nbiased sample of communications it is a readily available public database for a\nwealth of rich topics yielding a large sample set. All these topics gave rise\nto highly asymmetric vertex degree graphs and all shared the same general\ntopological features. We find a strong preference for in degree vertex\ninformation transfer with a 4:25 out degree to in degree vertex ratio with a\npower law distribution. Overall there is a low global clustering coefficient\naverage of 0.038 and a graph clustering density of 0.00034 for\nClauset-Newman-Moore grouping with a maximum geodesic distance of 6.\nEigenvector centrality does not give any large central impact vertices and\nbetweenness centrality shows many bridging vertices indicating a sparse\ncommunity structure. Parts of speech sentiment scores show a strong asymmetry\nof predominant negative scores for almost all word and word pairs with salience\ngreater than one. We used an Hoaxy analysis to check for deliberate\nmisinformation on these topics by a Twitter-Bot.", "doi": "", "date": "2019-12-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.08909v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1392002708, "title": "AutoDiscern: Rating the Quality of Online Health Information with\n  Hierarchical Encoder Attention-based Neural Networks", "abstract": "Patients increasingly turn to search engines and online content before, or in\nplace of, talking with a health professional. Low quality health information,\nwhich is common on the internet, presents risks to the patient in the form of\nmisinformation and a possibly poorer relationship with their physician. To\naddress this, the DISCERN criteria (developed at University of Oxford) are used\nto evaluate the quality of online health information. However, patients are\nunlikely to take the time to apply these criteria to the health websites they\nvisit. We built an automated implementation of the DISCERN instrument (Brief\nversion) using machine learning models. We compared the performance of a\ntraditional model (Random Forest) with that of a hierarchical encoder\nattention-based neural network (HEA) model using two language embeddings, BERT\nand BioBERT. The HEA BERT and BioBERT models achieved average F1-macro scores\nacross all criteria of 0.75 and 0.74, respectively, outperforming the Random\nForest model (average F1-macro = 0.69). Overall, the neural network based\nmodels achieved 81% and 86% average accuracy at 100% and 80% coverage,\nrespectively, compared to 94% manual rating accuracy. The attention mechanism\nimplemented in the HEA architectures not only provided 'model explainability'\nby identifying reasonable supporting sentences for the documents fulfilling the\nBrief DISCERN criteria, but also boosted F1 performance by 0.05 compared to the\nsame architecture without an attention mechanism. Our research suggests that it\nis feasible to automate online health information quality assessment, which is\nan important step towards empowering patients to become informed partners in\nthe healthcare process.", "doi": "", "date": "2019-12-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.12999v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3368024342, "title": "Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements", "abstract": "In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.", "doi": "", "date": "2020-01-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.00623v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3845953863, "title": "The optimal edge for containing the spreading of SIS model", "abstract": "Numerous real-world systems, for instance, the communication platforms and\ntransportation systems, can be abstracted into complex networks. Containing\nspreading dynamics (e.g., epidemic transmission and misinformation propagation)\nin networked systems is a hot topic in multiple fronts. Most of the previous\nstrategies are based on the immunization of nodes. However, sometimes, these\nnode--based strategies can be impractical. For instance, in the train\ntransportation networks, it is dramatic to isolating train stations for flu\nprevention. On the contrary, temporarily suspending some connections between\nstations is more acceptable. Thus, we pay attention to the edge-based\ncontaining strategy. In this study, we develop a theoretical framework to find\nthe optimal edge for containing the spreading of the\nsusceptible-infected-susceptible model on complex networks. In specific, by\nperforming a perturbation method to the discrete-Markovian-chain equations of\nthe SIS model, we derive a formula that approximately provides the decremental\noutbreak size after the deactivation of a certain edge in the network. Then, we\ndetermine the optimal edge by simply choosing the one with the largest\ndecremental outbreak size. Note that our proposed theoretical framework\nincorporates the information of both network structure and spreading dynamics.\nFinally, we test the performance of our method by extensive numerical\nsimulations. Results demonstrate that our strategy always outperforms other\nstrategies based only on structural properties (degree or edge betweenness\ncentrality). The theoretical framework in this study can be extended to other\nspreading models and offers inspirations for further investigations on\nedge-based immunization strategies.", "doi": "10.1088/1742-5468/ab780d", "date": "2020-02-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.06567v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3846400385, "title": "MIDMod-OSN: A Microscopic-level Information Diffusion Model for Online\n  Social Networks", "abstract": "As online social networks continue to be commonly used for the dissemination\nof information to the public, understanding the phenomena that govern\ninformation diffusion is crucial for many security and safety-related\napplications, such as maximizing information spread and misinformation\ncontainment during crises and natural disasters. In this study, we hypothesize\nthat the features that contribute to information diffusion in online social\nnetworks are significantly influenced by the type of event being studied. We\nclassify Twitter events as either informative or trending and then explore the\nnode-to-node influence dynamics associated with information spread. We build a\nmodel based on Bayesian Logistic Regression for learning and prediction and\nRandom Forests for feature selection. Experimental results from real-world data\nsets show that the proposed model outperforms state-of-the-art diffusion\nprediction models, achieving 93% accuracy in informative events and 86% in\ntrending events. We observed that the models for informative and trending\nevents differ significantly, both in the diffusion process and in the user\nfeatures that govern the diffusion. Our findings show that followers play an\nimportant role in the diffusion process and it is possible to use the diffusion\nand OSN behavior of users for predicting the trending character of a message\nwithout having to count the number of reactions.", "doi": "", "date": "2020-02-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.10522v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1836125685, "title": "Measuring Node Contribution to Community Structure with Modularity\n  Vitality", "abstract": "Community-aware centrality is an emerging research area in network science\nconcerned with the importance of nodes in relation to community structure.\nMeasures are a function of a network's structure and a given partition.\nPrevious approaches extend classical centrality measures to account for\ncommunity structure with little connection to community detection theory. In\ncontrast, we propose cluster-quality vitality measures, i.e., modularity\nvitality, a community-aware measure which is well-grounded in both centrality\nand community detection theory. Modularity vitality quantifies positive and\nnegative contributions to community structure, which indicate a node's role as\na community bridge or hub. We derive a computationally efficient method of\ncalculating modularity vitality for all nodes in O(M + NC) time, where C is the\nnumber of communities. We systematically fragment networks by removing central\nnodes, and find that modularity vitality consistently outperforms existing\ncommunity-aware centrality measures. Modularity vitality is over 8 times more\neffective than the next-best method on a million-node infrastructure network.\nThis result does not generalize to social media communication networks, which\nexhibit extreme robustness to all community-aware centrality attacks. This\nrobustness suggests that user-based interventions to mitigate misinformation\ndiffusion will be ineffective. Finally, we demonstrate that modularity vitality\nprovides a new approach to community-deception.", "doi": "10.1109/tnse.2020.3049068", "date": "2020-02-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.00056v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2408576026, "title": "FakeYou! -- A Gamified Approach for Building and Evaluating Resilience\n  Against Fake News", "abstract": "Nowadays fake news are heavily discussed in public and political debates.\nEven though the phenomenon of intended false information is rather old,\nmisinformation reaches a new level with the rise of the internet and\nparticipatory platforms. Due to Facebook and Co., purposeful false information\n- often called fake news - can be easily spread by everyone. Because of a high\ndata volatility and variety in content types (text, images,...) debunking of\nfake news is a complex challenge. This is especially true for automated\napproaches, which are prone to fail validating the veracity of the information.\nThis work focuses on an a gamified approach to strengthen the resilience of\nconsumers towards fake news. The game FakeYou motivates its players to\ncritically analyze headlines regarding their trustworthiness. Further, the game\nfollows a \"learning by doing strategy\": by generating own fake headlines, users\nshould experience the concepts of convincing fake headline formulations. We\nintroduce the game itself, as well as the underlying technical infrastructure.\nA first evaluation study shows, that users tend to use specific stylistic\ndevices to generate fake news. Further, the results indicate, that creating\ngood fakes and identifying correct headlines are challenging and hard to learn.", "doi": "", "date": "2020-03-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.07595v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1832224732, "title": "Perception of emergent epidemic of COVID-2019 / SARS CoV-2 on the Polish\n  Internet", "abstract": "We study the perception of COVID-2019 epidemic in Polish society using\nquantitative analysis of its digital footprints on the Internet (on Twitter,\nGoogle, YouTube, Wikipedia and electronic media represented by Event Registry)\nfrom January 2020 to 12.03.2020 (before and after official introduction to\nPoland on 04.03.2020). To this end we utilize data mining, social network\nanalysis, natural language processing techniques. Each examined internet\nplatform was analyzed for representativeness and composition of the target\ngroup. We identified three temporal major cluster of the interest before\ndisease introduction on the topic COVID-2019: China- and Italy-related peaks on\nall platforms, as well as a peak on social media related to the recent special\nlaw on combating COVID-2019. Besides, there was a peak in interest on the day\nof officially confirmed introduction as well as an exponential increase of\ninterest when the Polish government declared war against disease with a massive\nmitigation program. From sociolingistic perspective, we found that concepts and\nissues of threat, fear and prevention prevailed before introduction. After\nintroduction, practical concepts about disease and epidemic dominate. We have\nfound out that Twitter reflected the structural division of the Polish\npolitical sphere. We were able to identify clear communities of governing\nparty, mainstream oppostition and protestant group and potential sources of\nmisinformation. We have also detected bluring boundaries between comminities\nafter disease introduction.", "doi": "", "date": "2020-03-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.00005v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3654349000, "title": "The Paradox of Information Access: On Modeling Social-Media-Induced\n  Polarization", "abstract": "The paper develops a stochastic model of drift in human beliefs that shows\nthat today's sheer volume of accessible information, combined with consumers'\nconfirmation bias and natural preference to more outlying content, necessarily\nlead to increased polarization. The model explains the paradox of growing\nideological fragmentation in the age of increased sharing. As social media,\nsearch engines, and other real-time information sharing outlets purport to\nfacilitate access to information, a need for content filtering arises due to\nthe ensuing information overload. In general, consumers select information that\nmatches their individual views and values. The bias inherent in such selection\nis echoed by today's information curation services that maximize user\nengagement by filtering new content in accordance with observed consumer\npreferences. Consequently, individuals get exposed to increasingly narrower\nbands of the ideology spectrum, thus fragmenting society into increasingly\nideologically isolated enclaves. We call this dynamic the paradox of\ninformation access. The model also suggests the disproportionate damage\nattainable with a small infusion of well-positioned misinformation. The paper\ndescribes the modeling methodology, and evaluates modeling results for\ndifferent population sizes and parameter settings.", "doi": "", "date": "2020-04-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.01106v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3470568139, "title": "Leveraging Multi-Source Weak Social Supervision for Early Detection of\n  Fake News", "abstract": "Social media has greatly enabled people to participate in online activities\nat an unprecedented rate. However, this unrestricted access also exacerbates\nthe spread of misinformation and fake news online which might cause confusion\nand chaos unless being detected early for its mitigation. Given the rapidly\nevolving nature of news events and the limited amount of annotated data,\nstate-of-the-art systems on fake news detection face challenges due to the lack\nof large numbers of annotated training instances that are hard to come by for\nearly detection. In this work, we exploit multiple weak signals from different\nsources given by user and content engagements (referred to as weak social\nsupervision), and their complementary utilities to detect fake news. We jointly\nleverage the limited amount of clean data along with weak signals from social\nengagements to train deep neural networks in a meta-learning framework to\nestimate the quality of different weak instances. Experiments on realworld\ndatasets demonstrate that the proposed framework outperforms state-of-the-art\nbaselines for early detection of fake news without using any user engagements\nat prediction time.", "doi": "", "date": "2020-04-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.01732v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1845051712, "title": "A large-scale COVID-19 Twitter chatter dataset for open scientific\n  research -- an international collaboration", "abstract": "As the COVID-19 pandemic continues its march around the world, an\nunprecedented amount of open data is being generated for genetics and\nepidemiological research. The unparalleled rate at which many research groups\naround the world are releasing data and publications on the ongoing pandemic is\nallowing other scientists to learn from local experiences and data generated in\nthe front lines of the COVID-19 pandemic. However, there is a need to integrate\nadditional data sources that map and measure the role of social dynamics of\nsuch a unique world-wide event into biomedical, biological, and epidemiological\nanalyses. For this purpose, we present a large-scale curated dataset of over\n152 million tweets, growing daily, related to COVID-19 chatter generated from\nJanuary 1st to April 4th at the time of writing. This open dataset will allow\nresearchers to conduct a number of research projects relating to the emotional\nand mental responses to social distancing measures, the identification of\nsources of misinformation, and the stratified measurement of sentiment towards\nthe pandemic in near real time.", "doi": "10.3390/epidemiologia2030024", "date": "2020-04-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.03688v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2603737629, "title": "Quantifying Latent Moral Foundations in Twitter Narratives: The Case of\n  the Syrian White Helmets Misinformation", "abstract": "For years, many studies employed sentiment analysis to understand the\nreasoning behind people's choices and feelings, their communication styles, and\nthe communities which they belong to. We argue that gaining more in-depth\ninsight into moral dimensions coupled with sentiment analysis can potentially\nprovide superior results. Understanding moral foundations can yield powerful\nresults in terms of perceiving the intended meaning of the text data, as the\nconcept of morality provides additional information on the unobservable\ncharacteristics of information processing and non-conscious cognitive\nprocesses. Therefore, we studied latent moral loadings of Syrian White\nHelmets-related tweets of Twitter users from April 1st, 2018 to April 30th,\n2019. For the operationalization and quantification of moral rhetoric in\ntweets, we use Extended Moral Foundations Dictionary in which five\npsychological dimensions (Harm/Care, Fairness/Reciprocity, In-group/Loyalty,\nAuthority/Respect and Purity/Sanctity) are considered. We show that people tend\nto share more tweets involving the virtue moral rhetoric than the tweets\ninvolving the vice rhetoric. We observe that the pattern of the moral rhetoric\nof tweets among these five dimensions are very similar during different time\nperiods, while the strength of the five dimension is time-variant. Even though\nthere is no significant difference between the use of Fairness/Reciprocity,\nIn-group/Loyalty or Purity/Sanctity rhetoric, the less use of Harm/Care\nrhetoric is significant and remarkable. Besides, the strength of the moral\nrhetoric and the polarization in morality across people are mostly observed in\ntweets involving Harm/Care rhetoric despite the number of tweets involving the\nHarm/Care dimension is low.", "doi": "", "date": "2020-04-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.13142v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 591853144, "title": "Characterizing information leaders in Twitter during COVID-19 crisis", "abstract": "Information is key during a crisis such as the one produced by the current\nCOVID-19 pandemic as it greatly shapes people opinion, behavior and their\npsychology. Infodemic of misinformation is an important secondary crisis\nassociated to the pandemic. Infodemics can amplify the real negative\nconsequences of the pandemic in different dimensions: social, economic and even\nsanitary. For instance, infodemics can lead to hatred between population groups\nthat fragment the society influencing its response or result in negative habits\nthat help the pandemic propagate. On the contrary, reliable and trustful\ninformation along with messages of hope and solidarity can be used to control\nthe pandemic, build safety nets and help promote resilience. We propose the\nfoundation of a framework to characterize leaders in Twitter based on the\nanalysis of the social graph derived from the activity in this social network.\nCentrality metrics are used to characterize the topology of the network and the\nnodes as potential leaders. These metrics are compared with the user popularity\nmetrics managed by Twitter. We then assess the resulting topology of clusters\nof leaders visually. We propose this tool to be the basis for a system to\ndetect and empower users with a positive influence in the collective behavior\nof the network and the propagation of information.", "doi": "", "date": "2020-05-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.07266v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2469577852, "title": "Information Consumption and Social Response in a Segregated Environment:\n  the Case of Gab", "abstract": "Most of the information operations involve users who may foster polarization\nand distrust toward science and mainstream journalism, without these users\nbeing conscious of their role. Gab is well known to be an extremist-friendly\nplatform that performs little control on the posted content. Thus it represents\nan ideal benchmark for studying phenomena potentially related to polarization\nsuch as misinformation spreading. The combination of these factors may lead to\nhate as well as to episodes of harm in the real world. In this work we provide\na characterization of the interaction patterns within Gab around the COVID-19\ntopic. To assess the spreading of different content type, we analyze\nconsumption patterns based on both interaction type and source reliability.\nOverall we find that there are no strong statistical differences in the social\nresponse to questionable and reliable content, both following a power law\ndistribution. However, questionable and reliable sources display structural and\ntopical differences in the use of hashtags. The commenting behaviour of users\nin terms of both lifetime and sentiment reveals that questionable and reliable\nposts are perceived in the same manner. We can conclude that despite evident\ndifferences between questionable and reliable posts Gab users do not perform\nsuch a differentiation thus treating them as a whole. Our results provide\ninsights toward the understanding of coordinated inauthentic behavior and on\nthe early-warning of information operation.", "doi": "", "date": "2020-06-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.02181v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1681987583, "title": "DyHGCN: A Dynamic Heterogeneous Graph Convolutional Network to Learn\n  Users' Dynamic Preferences for Information Diffusion Prediction", "abstract": "Information diffusion prediction is a fundamental task for understanding the\ninformation propagation process. It has wide applications in such as\nmisinformation spreading prediction and malicious account detection. Previous\nworks either concentrate on utilizing the context of a single diffusion\nsequence or using the social network among users for information diffusion\nprediction. However, the diffusion paths of different messages naturally\nconstitute a dynamic diffusion graph. For one thing, previous works cannot\njointly utilize both the social network and diffusion graph for prediction,\nwhich is insufficient to model the complexity of the diffusion process and\nresults in unsatisfactory prediction performance. For another, they cannot\nlearn users' dynamic preferences. Intuitively, users' preferences are changing\nas time goes on and users' personal preference determines whether the user will\nrepost the information. Thus, it is beneficial to consider users' dynamic\npreferences in information diffusion prediction.\n  In this paper, we propose a novel dynamic heterogeneous graph convolutional\nnetwork (DyHGCN) to jointly learn the structural characteristics of the social\ngraph and dynamic diffusion graph. Then, we encode the temporal information\ninto the heterogeneous graph to learn the users' dynamic preferences. Finally,\nwe apply multi-head attention to capture the context-dependency of the current\ndiffusion path to facilitate the information diffusion prediction task.\nExperimental results show that DyHGCN significantly outperforms the\nstate-of-the-art models on three public datasets, which shows the effectiveness\nof the proposed model.", "doi": "", "date": "2020-06-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.05169v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2831918136, "title": "Detection of Novel Social Bots by Ensembles of Specialized Classifiers", "abstract": "Malicious actors create inauthentic social media accounts controlled in part\nby algorithms, known as social bots, to disseminate misinformation and agitate\nonline discussion. While researchers have developed sophisticated methods to\ndetect abuse, novel bots with diverse behaviors evade detection. We show that\ndifferent types of bots are characterized by different behavioral features. As\na result, supervised learning techniques suffer severe performance\ndeterioration when attempting to detect behaviors not observed in the training\ndata. Moreover, tuning these models to recognize novel bots requires retraining\nwith a significant amount of new annotations, which are expensive to obtain. To\naddress these issues, we propose a new supervised learning method that trains\nclassifiers specialized for each class of bots and combines their decisions\nthrough the maximum rule. The ensemble of specialized classifiers (ESC) can\nbetter generalize, leading to an average improvement of 56\\% in F1 score for\nunseen accounts across datasets. Furthermore, novel bot behaviors are learned\nwith fewer labeled examples during retraining. We deployed ESC in the newest\nversion of Botometer, a popular tool to detect social bots in the wild, with a\ncross-validation AUC of 0.99.", "doi": "10.1145/3340531.3412698", "date": "2020-06-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.06867v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3045594679, "title": "Estimation of COVID-19 under-reporting in Brazilian States through SARI", "abstract": "Due to its impact, COVID-19 has been stressing the academy to search for\ncuring, mitigating, or controlling it. However, when it comes to controlling,\nthere are still few studies focused on under-reporting estimates. It is\nbelieved that under-reporting is a relevant factor in determining the actual\nmortality rate and, if not considered, can cause significant misinformation.\nTherefore, the objective of this work is to estimate the under-reporting of\ncases and deaths of COVID-19 in Brazilian states using data from the Infogripe\non notification of Severe Acute Respiratory Infection (SARI). The methodology\nis based on the concepts of inertia and the use of event detection techniques\nto study the time series of hospitalized SARI cases. The estimate of real cases\nof the disease, called novelty, is calculated by comparing the difference in\nSARI cases in 2020 (after COVID-19) with the total expected cases in recent\nyears (2016 to 2019) derived from a seasonal exponential moving average. The\nresults show that under-reporting rates vary significantly between states and\nthat there are no general patterns for states in the same region in Brazil.\n  The published version of this paper is made available at\nhttps://doi.org/10.1007/s00354-021-00125-3.\n  Please cite as: B. Paix\\~ao, L. Baroni, M. Pedroso, R. Salles, L. Escobar, C.\nde Sousa, R. de Freitas Saldanha, J. Soares, R. Coutinho, et al., 2021,\nEstimation of COVID-19 Under-Reporting in the Brazilian States Through SARI,\nNew Generation Computing", "doi": "10.1007/s00354-021-00125-3", "date": "2020-06-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.12759v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3951628092, "title": "Evolving Methods for Evaluating and Disseminating Computing Research", "abstract": "Social and technical trends have significantly changed methods for evaluating\nand disseminating computing research. Traditional venues for reviewing and\npublishing, such as conferences and journals, worked effectively in the past.\nRecently, trends have created new opportunities but also put new pressures on\nthe process of review and dissemination. For example, many conferences have\nseen large increases in the number of submissions. Likewise, dissemination of\nresearch ideas has become dramatically through publication venues such as\narXiv.org and social media networks. While these trends predate COVID-19, the\npandemic could accelerate longer term changes. Based on interviews with leading\nacademics in computing research, our findings include: (1) Trends impacting\ncomputing research are largely positive and have increased the participation,\nscope, accessibility, and speed of the research process. (2) Challenges remain\nin securing the integrity of the process, including addressing ways to scale\nthe review process, avoiding attempts to misinform or confuse the dissemination\nof results, and ensuring fairness and broad participation in the process\nitself. Based on these findings, we recommend: (1) Regularly polling members of\nthe computing research community, including program and general conference\nchairs, journal editors, authors, reviewers, etc., to identify specific\nchallenges they face to better understand these issues. (2) An influential\nbody, such as the Computing Research Association regularly issues a \"State of\nthe Computing Research Enterprise\" report to update the community on trends,\nboth positive and negative, impacting the computing research enterprise. (3) A\ndeeper investigation, specifically to better understand the influence that\nsocial media and preprint archives have on computing research, is conducted.", "doi": "", "date": "2020-07-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.01242v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2130557024, "title": "Artificial Fingerprinting for Generative Models: Rooting Deepfake\n  Attribution in Training Data", "abstract": "Photorealistic image generation has reached a new level of quality due to the\nbreakthroughs of generative adversarial networks (GANs). Yet, the dark side of\nsuch deepfakes, the malicious use of generated media, raises concerns about\nvisual misinformation. While existing research work on deepfake detection\ndemonstrates high accuracy, it is subject to advances in generation techniques\nand adversarial iterations on detection countermeasure techniques. Thus, we\nseek a proactive and sustainable solution on deepfake detection, that is\nagnostic to the evolution of generative models, by introducing artificial\nfingerprints into the models.\n  Our approach is simple and effective. We first embed artificial fingerprints\ninto training data, then validate a surprising discovery on the transferability\nof such fingerprints from training data to generative models, which in turn\nappears in the generated deepfakes. Experiments show that our fingerprinting\nsolution (1) holds for a variety of cutting-edge generative models, (2) leads\nto a negligible side effect on generation quality, (3) stays robust against\nimage-level and model-level perturbations, (4) stays hard to be detected by\nadversaries, and (5) converts deepfake detection and attribution into trivial\ntasks and outperforms the recent state-of-the-art baselines. Our solution\ncloses the responsibility loop between publishing pre-trained generative model\ninventions and their possible misuses, which makes it independent of the\ncurrent arms race.", "doi": "", "date": "2020-07-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.08457v5", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1689059158, "title": "Dark Web Marketplaces and COVID-19: before the vaccine", "abstract": "The COVID-19 pandemic has reshaped the demand for goods and services\nworldwide. The combination of a public health emergency, economic distress, and\nmisinformation-driven panic have pushed customers and vendors towards the\nshadow economy. In particular, dark web marketplaces (DWMs), commercial\nwebsites accessible via free software, have gained significant popularity.\nHere, we analyse 851,199 listings extracted from 30 DWMs between January 1,\n2020 and November 16, 2020. We identify 788 listings directly related to\nCOVID-19 products and monitor the temporal evolution of product categories\nincluding Personal Protective Equipment (PPE), medicines (e.g.,\nhydroxyclorochine), and medical frauds. Finally, we compare trends in their\ntemporal evolution with variations in public attention, as measured by Twitter\nposts and Wikipedia page visits. We reveal how the online shadow economy has\nevolved during the COVID-19 pandemic and highlight the importance of a\ncontinuous monitoring of DWMs, especially now that real vaccines are available\nand in short supply. We anticipate our analysis will be of interest both to\nresearchers and public agencies focused on the protection of public health.", "doi": "10.1140/epjds/s13688-021-00259-w", "date": "2020-08-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.01585v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3587261910, "title": "Behavioral Modeling of Persian Instagram Users to detect Bots", "abstract": "Bots are user accounts in social media which are controlled by computer\nprograms. Similar to many other things, they are used for both good and evil\npurposes. One nefarious use-case for them is to spread misinformation or biased\ndata in the networks. There are many pieces of research being performed based\non social media data and their results validity is extremely threatened by the\nharmful data bots spread. Consequently, effective methods and tools are\nrequired for detecting bots and then removing misleading data spread by the\nbots. In the present research, a method for detecting Instagram bots is\nproposed. There is no data set including samples of Instagram bots and genuine\naccounts, thus the current research has begun with gathering such a data set\nwith respect to generality concerns such that it includes 1,000 data points in\neach group. The main approach is supervised machine learning and classic models\nare preferred compared to deep neural networks. The final model is evaluated\nusing multiple methods starting with 10-fold cross-validation. After that,\nconfidence in classification studies and is followed by feature importance\nanalysis and feature behavior against the target probability computed by the\nmodel. In the end, an experiment is designed to measure the models\neffectiveness in an operational environment. Finally, It is strongly concluded\nthat the model performs very well in all evaluation experiments.", "doi": "", "date": "2020-08-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.03951v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3607503300, "title": "Covid-19 infodemic reveals new tipping point epidemiology and a revised\n  $R$ formula", "abstract": "Many governments have managed to control their COVID-19 outbreak with a\nsimple message: keep the effective '$R$ number' $R<1$ to prevent widespread\ncontagion and flatten the curve. This raises the question whether a similar\npolicy could control dangerous online 'infodemics' of information,\nmisinformation and disinformation. Here we show, using multi-platform data from\nthe COVID-19 infodemic, that its online spreading instead encompasses a\ndifferent dynamical regime where communities and users within and across\nindependent platforms, sporadically form temporary active links on similar\ntimescales to the viral spreading. This allows material that might have died\nout, to evolve and even mutate. This has enabled niche networks that were\nalready successfully spreading hate and anti-vaccination material, to rapidly\nbecome global super-spreaders of narratives featuring fake COVID-19 treatments,\nanti-Asian sentiment and conspiracy theories. We derive new tools that\nincorporate these coupled social-viral dynamics, including an online $R$, to\nhelp prevent infodemic spreading at all scales: from spreading across platforms\n(e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community,\nor topic. By accounting for similar social and viral timescales, the same\nmathematical theory also offers a quantitative description of other\nunconventional infection profiles such as rumors spreading in financial markets\nand colds spreading in schools.", "doi": "", "date": "2020-08-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.08513v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1716504926, "title": "On Attribution of Deepfakes", "abstract": "Progress in generative modelling, especially generative adversarial networks,\nhave made it possible to efficiently synthesize and alter media at scale.\nMalicious individuals now rely on these machine-generated media, or deepfakes,\nto manipulate social discourse. In order to ensure media authenticity, existing\nresearch is focused on deepfake detection. Yet, the adversarial nature of\nframeworks used for generative modeling suggests that progress towards\ndetecting deepfakes will enable more realistic deepfake generation. Therefore,\nit comes at no surprise that developers of generative models are under the\nscrutiny of stakeholders dealing with misinformation campaigns. At the same\ntime, generative models have a lot of positive applications. As such, there is\na clear need to develop tools that ensure the transparent use of generative\nmodeling, while minimizing the harm caused by malicious applications.\n  Our technique optimizes over the source of entropy of each generative model\nto probabilistically attribute a deepfake to one of the models. We evaluate our\nmethod on the seminal example of face synthesis, demonstrating that our\napproach achieves 97.62% attribution accuracy, and is less sensitive to\nperturbations and adversarial examples. We discuss the ethical implications of\nour work, identify where our technique can be used, and highlight that a more\nmeaningful legislative framework is required for a more transparent and ethical\nuse of generative modeling. Finally, we argue that model developers should be\ncapable of claiming plausible deniability and propose a second framework to do\nso -- this allows a model developer to produce evidence that they did not\nproduce media that they are being accused of having produced.", "doi": "", "date": "2020-08-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.09194v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3529360029, "title": "TRUSTD: Combat Fake Content using Blockchain and Collective Signature\n  Technologies", "abstract": "The growing trend of sharing news/contents, through social media platforms\nand the World Wide Web has been seen to impact our perception of the truth,\naltering our views about politics, economics, relationships, needs and wants.\nThis is because of the growing spread of misinformation and disinformation\nintentionally or unintentionally by individuals and organizations. This trend\nhas grave political, social, ethical, and privacy implications for society due\nto 1) the rapid developments in the field of Machine Learning (ML) and Deep\nLearning (DL) algorithms in creating realistic-looking yet fake digital content\n(such as text, images, and videos), 2) the ability to customize the content\nfeeds and to create a polarized so-called \"filter-bubbles\" leveraging the\navailability of the big-data. Therefore, there is an ethical need to combat the\nflow of fake content. This paper attempts to resolve some of the aspects of\nthis combat by presenting a high-level overview of TRUSTD, a blockchain and\ncollective signature-based ecosystem to help content creators in getting their\ncontent backed by the community, and to help users judge on the credibility and\ncorrectness of these contents.", "doi": "10.1109/icbc48266.2020.9169435", "date": "2020-08-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.13632v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 982409129, "title": "Narrative Maps: An Algorithmic Approach to Represent and Extract\n  Information Narratives", "abstract": "Narratives are fundamental to our perception of the world and are pervasive\nin all activities that involve the representation of events in time. Yet,\nmodern online information systems do not incorporate narratives in their\nrepresentation of events occurring over time. This article aims to bridge this\ngap, combining the theory of narrative representations with the data from\nmodern online systems. We make three key contributions: a theory-driven\ncomputational representation of narratives, a novel extraction algorithm to\nobtain these representations from data, and an evaluation of our approach. In\nparticular, given the effectiveness of visual metaphors, we employ a route map\nmetaphor to design a narrative map representation. The narrative map\nrepresentation illustrates the events and stories in the narrative as a series\nof landmarks and routes on the map. Each element of our representation is\nbacked by a corresponding element from formal narrative theory, thus providing\na solid theoretical background to our method. Our approach extracts the\nunderlying graph structure of the narrative map using a novel optimization\ntechnique focused on maximizing coherence while respecting structural and\ncoverage constraints. We showcase the effectiveness of our approach by\nperforming a user evaluation to assess the quality of the representation,\nmetaphor, and visualization. Evaluation results indicate that the Narrative Map\nrepresentation is a powerful method to communicate complex narratives to\nindividuals. Our findings have implications for intelligence analysts,\ncomputational journalists, and misinformation researchers.", "doi": "", "date": "2020-09-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.04508v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2945822081, "title": "Sustained Online Amplification of COVID-19 Elites in the United States", "abstract": "The ongoing, fluid nature of the COVID-19 pandemic requires individuals to\nregularly seek information about best health practices, local community\nspreading, and public health guidelines. In the absence of a unified response\nto the pandemic in the United States and clear, consistent directives from\nfederal and local officials, people have used social media to collectively\ncrowdsource COVID-19 elites, a small set of trusted COVID-19 information\nsources. We take a census of COVID-19 crowdsourced elites in the United States\nwho have received sustained attention on Twitter during the pandemic. Using a\nmixed methods approach with a panel of Twitter users linked to public U.S.\nvoter registration records, we find that journalists, media outlets, and\npolitical accounts have been consistently amplified around COVID-19, while\nepidemiologists, public health officials, and medical professionals make up\nonly a small portion of all COVID-19 elites on Twitter. We show that COVID-19\nelites vary considerably across demographic groups, and that there are notable\nracial, geographic, and political similarities and disparities between various\ngroups and the demographics of their elites. With this variation in mind, we\ndiscuss the potential for using the disproportionate online voice of\ncrowdsourced COVID-19 elites to equitably promote timely public health\ninformation and mitigate rampant misinformation.", "doi": "10.1177/20563051211024957", "date": "2020-09-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.07255v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2251912789, "title": "A Multimodal Memes Classification: A Survey and Open Research Issues", "abstract": "Memes are graphics and text overlapped so that together they present concepts\nthat become dubious if one of them is absent. It is spread mostly on social\nmedia platforms, in the form of jokes, sarcasm, motivating, etc. After the\nsuccess of BERT in Natural Language Processing (NLP), researchers inclined to\nVisual-Linguistic (VL) multimodal problems like memes classification, image\ncaptioning, Visual Question Answering (VQA), and many more. Unfortunately, many\nmemes get uploaded each day on social media platforms that need automatic\ncensoring to curb misinformation and hate. Recently, this issue has attracted\nthe attention of researchers and practitioners. State-of-the-art methods that\nperformed significantly on other VL dataset, tends to fail on memes\nclassification. In this context, this work aims to conduct a comprehensive\nstudy on memes classification, generally on the VL multimodal problems and\ncutting edge solutions. We propose a generalized framework for VL problems. We\ncover the early and next-generation works on VL problems. Finally, we identify\nand articulate several open research issues and challenges. This is the first\nstudy that presents the generalized view of the advanced classification\ntechniques concerning memes classification to the best of our knowledge. We\nbelieve this study presents a clear road-map for the Machine Learning (ML)\nresearch community to implement and enhance memes classification techniques.", "doi": "", "date": "2020-09-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.08395v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1270754625, "title": "Fake News Spreader Detection on Twitter using Character N-Grams.\n  Notebook for PAN at CLEF 2020", "abstract": "The authors of fake news often use facts from verified news sources and mix\nthem with misinformation to create confusion and provoke unrest among the\nreaders. The spread of fake news can thereby have serious implications on our\nsociety. They can sway political elections, push down the stock price or crush\nreputations of corporations or public figures. Several websites have taken on\nthe mission of checking rumors and allegations, but are often not fast enough\nto check the content of all the news being disseminated. Especially social\nmedia websites have offered an easy platform for the fast propagation of\ninformation. Towards limiting fake news from being propagated among social\nmedia users, the task of this year's PAN 2020 challenge lays the focus on the\nfake news spreaders. The aim of the task is to determine whether it is possible\nto discriminate authors that have shared fake news in the past from those that\nhave never done it. In this notebook, we describe our profiling system for the\nfake news detection task on Twitter. For this, we conduct different feature\nextraction techniques and learning experiments from a multilingual perspective,\nnamely English and Spanish. Our final submitted systems use character n-grams\nas features in combination with a linear SVM for English and Logistic\nRegression for the Spanish language. Our submitted models achieve an overall\naccuracy of 73% and 79% on the English and Spanish official test set,\nrespectively. Our experiments show that it is difficult to differentiate\nsolidly fake news spreaders on Twitter from users who share credible\ninformation leaving room for further investigations. Our model ranked 3rd out\nof 72 competitors.", "doi": "", "date": "2020-09-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.13859v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1373382514, "title": "#Election2020: The First Public Twitter Dataset on the 2020 US\n  Presidential Election", "abstract": "The integrity of democratic political discourse is at the core to guarantee\nfree and fair elections. With social media often dictating the tones and trends\nof politics-related discussion, it is of paramount important to be able to\nstudy online chatter, especially in the run up to important voting events, like\nin the case of the upcoming November 3, 2020 U.S. Presidential Election.\nLimited access to social media data is often the first barrier to impede,\nhinder, or slow down progress, and ultimately our understanding of online\npolitical discourse. To mitigate this issue and try to empower the\nComputational Social Science research community, we decided to publicly release\na massive-scale, longitudinal dataset of U.S. politics- and election-related\ntweets. This multilingual dataset that we have been collecting for over one\nyear encompasses hundreds of millions of tweets and tracks all salient U.S.\npolitics trends, actors, and events between 2019 and 2020. It predates and\nspans the whole period of Republican and Democratic primaries, with real-time\ntracking of all presidential contenders of both sides of the isle. After that,\nit focuses on presidential and vice-presidential candidates. Our dataset\nrelease is curated, documented and will be constantly updated on a\nweekly-basis, until the November 3, 2020 election and beyond. We hope that the\nacademic community, computational journalists, and research practitioners alike\nwill all take advantage of our dataset to study relevant scientific and social\nissues, including problems like misinformation, information manipulation,\ninterference, and distortion of online political discourse that have been\nprevalent in the context of recent election events in the United States and\nworldwide.\n  Our dataset is available at:\nhttps://github.com/echen102/us-pres-elections-2020", "doi": "", "date": "2020-10-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.00600v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2673205057, "title": "FaNDS: Fake News Detection System Using Energy Flow", "abstract": "Recently, the term \"fake news\" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.", "doi": "", "date": "2020-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.02097v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 260728227, "title": "Characterizing the roles of bots during the COVID-19 infodemic on\n  Twitter", "abstract": "An infodemic is an emerging phenomenon caused by an overabundance of\ninformation online. This proliferation of information makes it difficult for\nthe public to distinguish trustworthy news and credible information from\nuntrustworthy sites and non-credible sources. The perils of an infodemic\ndebuted with the outbreak of the COVID-19 pandemic and bots (i.e., automated\naccounts controlled by a set of algorithms) that are suspected of spreading the\ninfodemic. Although previous research has revealed that bots played a central\nrole in spreading misinformation during major political events, how bots\nbehaved during the infodemic is unclear. In this paper, we examined the roles\nof bots in the case of the COVID-19 infodemic and the diffusion of non-credible\ninformation such as \"5G\" and \"Bill Gates\" conspiracy theories and content\nrelated to \"Trump\" and \"WHO\" by analyzing retweet networks and retweeted items.\nWe show the segregated topology of their retweet networks, which indicates that\nright-wing self-media accounts and conspiracy theorists may lead to this\nopinion cleavage, while malicious bots might favor amplification of the\ndiffusion of non-credible information. Although the basic influence of\ninformation diffusion could be larger in human users than bots, the effects of\nbots are non-negligible under an infodemic situation.", "doi": "", "date": "2020-11-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.06249v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1656932554, "title": "The COVID19 infodemic. The role and place of academics in science\n  communication", "abstract": "As the COVID19 pandemic has spread across the world, a concurrent pandemic of\ninformation has spread with it. Deemed an infodemic by the World Health\nOrganization, and described as an overabundance of information, some accurate,\nsome not, that occurs during an epidemic, this proliferation of data, research\nand opinions provides both opportunities and challenges for academics.\nAcademics and scientists have a key role to play in the solutions to the\ninfodemic challenge: as educators, influences and communicators, even where\ntheir expertise and experience does not align precisely with the SARS-Cov2\nvirus and its impacts.\n  Successful communication requires a better understanding of how the public\nseeks, understands and processes scientific information, however, in order to\nmaximise the ways in which experts engage with traditional and social media and\nto make sure that such engagement does not add to confusion and misinformation\nalongside efforts to counter or challenge it. This paper will outline the key\nadvantages to be had from greater engagement with COVID19 discussions, the\npopular channels through which such discussions take place and through which\ninformation is disseminated. It also warns against the common pitfalls those\nwho choose to engage might encounter, whilst stressing that the disadvantages\nof doing so are far outweighed by the advantages such engagement offers.", "doi": "", "date": "2020-11-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.08787v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3998758951, "title": "Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking", "abstract": "The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.", "doi": "", "date": "2020-11-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.13253v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3125971039, "title": "Optimizing sensors placement in complex networks for localization of\n  hidden signal source: A review", "abstract": "As the world becomes more and more interconnected, our everyday objects\nbecome part of the Internet of Things, and our lives get more and more mirrored\nin virtual reality, where every piece of~information, including misinformation,\nfake news and malware, can spread very fast practically anonymously. To\nsuppress such uncontrolled spread, efficient computer systems and algorithms\ncapable to~track down such malicious information spread have to be developed.\nCurrently, the most effective methods for source localization are based on\nsensors which provide the times at which they detect the~spread. We investigate\nthe problem of the optimal placement of such sensors in complex networks and\npropose a new graph measure, called Collective Betweenness, which we compare\nagainst four other metrics. Extensive numerical tests are performed on\ndifferent types of complex networks over the wide ranges of densities of\nsensors and stochasticities of signal. In these tests, we discovered clear\ndifference in comparative performance of the investigated optimal placement\nmethods between real or scale-free synthetic networks versus narrow degree\ndistribution networks. The former have a clear region for any given method's\ndominance in contrast to the latter where the performance maps are less\nhomogeneous. We find that while choosing the best method is very network and\nspread dependent, there are two methods that consistently stand out. High\nVariance Observers seem to do very well for spread with low stochasticity\nwhereas Collective Betwenness, introduced in this paper, thrives when the\nspread is highly unpredictable.", "doi": "10.1016/j.future.2020.06.023", "date": "2020-12-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.01876v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2158393113, "title": "TrollHunter2020: Real-Time Detection of Trolling Narratives on Twitter\n  During the 2020 US Elections", "abstract": "This paper presents TrollHunter2020, a real-time detection mechanism we used\nto hunt for trolling narratives on Twitter during the 2020 U.S. elections.\nTrolling narratives form on Twitter as alternative explanations of polarizing\nevents like the 2020 U.S. elections with the goal to conduct information\noperations or provoke emotional response. Detecting trolling narratives thus is\nan imperative step to preserve constructive discourse on Twitter and remove an\ninflux of misinformation. Using existing techniques, this takes time and a\nwealth of data, which, in a rapidly changing election cycle with high stakes,\nmight not be available. To overcome this limitation, we developed\nTrollHunter2020 to hunt for trolls in real-time with several dozens of trending\nTwitter topics and hashtags corresponding to the candidates' debates, the\nelection night, and the election aftermath. TrollHunter2020 collects trending\ndata and utilizes a correspondence analysis to detect meaningful relationships\nbetween the top nouns and verbs used in constructing trolling narratives while\nthey emerge on Twitter. Our results suggest that the TrollHunter2020 indeed\ncaptures the emerging trolling narratives in a very early stage of an unfolding\npolarizing event. We discuss the utility of TrollHunter2020 for early detection\nof information operations or trolling and the implications of its use in\nsupporting a constrictive discourse on the platform around polarizing topics.", "doi": "", "date": "2020-12-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.02606v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2543965949, "title": "Responsible Disclosure of Generative Models Using Scalable\n  Fingerprinting", "abstract": "Over the past six years, deep generative models have achieved a qualitatively\nnew level of performance. Generated data has become difficult, if not\nimpossible, to be distinguished from real data. While there are plenty of use\ncases that benefit from this technology, there are also strong concerns on how\nthis new technology can be misused to spoof sensors, generate deep fakes, and\nenable misinformation at scale. Unfortunately, current deep fake detection\nmethods are not sustainable, as the gap between real and fake continues to\nclose. In contrast, our work enables a responsible disclosure of such\nstate-of-the-art generative models, that allows researchers and companies to\nfingerprint their models, so that the generated samples containing a\nfingerprint can be accurately detected and attributed to a source. Our\ntechnique achieves this by an efficient and scalable ad-hoc generation of a\nlarge population of models with distinct fingerprints. Our recommended\noperation point uses a 128-bit fingerprint which in principle results in more\nthan $10^{36}$ identifiable models. Experiments show that our method fulfills\nkey properties of a fingerprinting mechanism and achieves effectiveness in deep\nfake detection and attribution.", "doi": "", "date": "2020-12-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.08726v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4006462552, "title": "Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study", "abstract": "Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.", "doi": "", "date": "2020-12-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.01142v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2289549426, "title": "What social media told about us in the time of COVID-19: a scoping\n  review", "abstract": "With the onset of COVID-19 pandemic, social media has rapidly become a\ncrucial communication tool for information generation, dissemination, and\nconsumption. In this scoping review, we selected and examined peer-reviewed\nempirical studies relating to COVID-19 and social media during the first\noutbreak starting in November 2019 until May 2020. From an analysis of 81\nstudies, we identified five overarching public health themes concerning the\nrole of online social platforms and COVID-19. These themes focused on: (i)\nsurveying public attitudes, (ii) identifying infodemics, (iii) assessing mental\nhealth, (iv) detecting or predicting COVID-19 cases, (v) analyzing government\nresponses to the pandemic, and (vi) evaluating quality of health information in\nprevention education videos. Furthermore, our review highlights the paucity of\nstudies on the application of machine learning on social media data related to\nCOVID-19 and a lack of studies documenting real-time surveillance developed\nwith social media data on COVID-19. For COVID-19, social media can play a\ncrucial role in disseminating health information as well as tackling infodemics\nand misinformation.", "doi": "10.1016/s2589-7500(20)30315-0", "date": "2021-01-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.01688v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1981337807, "title": "Model Generalization on COVID-19 Fake News Detection", "abstract": "Amid the pandemic COVID-19, the world is facing unprecedented infodemic with\nthe proliferation of both fake and real information. Considering the\nproblematic consequences that the COVID-19 fake-news have brought, the\nscientific community has put effort to tackle it. To contribute to this fight\nagainst the infodemic, we aim to achieve a robust model for the COVID-19\nfake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking\ntwo separate approaches: 1) fine-tuning transformers based language models with\nrobust loss functions and 2) removing harmful training instances through\ninfluence calculation. We further evaluate the robustness of our models by\nevaluating on different COVID-19 misinformation test set (Tweets-19) to\nunderstand model generalization ability. With the first approach, we achieve\n98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on\nthe Tweets-19 highest. On the contrary, by performing influence data cleansing,\nour model with 99% cleansing percentage can achieve 54.33% W-F1 score on\nTweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news\ntest sets, we suggest the importance of model generalization ability in this\ntask to step forward to tackle the COVID-19 fake-news problem in online social\nmedia platforms.", "doi": "", "date": "2021-01-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.03841v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3930471348, "title": "COSMOS: Catching Out-of-Context Misinformation with Self-Supervised\n  Learning", "abstract": "Despite the recent attention to DeepFakes, one of the most prevalent ways to\nmislead audiences on social media is the use of unaltered images in a new but\nfalse context. To address these challenges and support fact-checkers, we\npropose a new method that automatically detects out-of-context image and text\npairs. Our key insight is to leverage the grounding of image with text to\ndistinguish out-of-context scenarios that cannot be disambiguated with language\nalone. We propose a self-supervised training strategy where we only need a set\nof captioned images. At train time, our method learns to selectively align\nindividual objects in an image with textual claims, without explicit\nsupervision. At test time, we check if both captions correspond to the same\nobject(s) in the image but are semantically different, which allows us to make\nfairly accurate out-of-context predictions. Our method achieves 85%\nout-of-context detection accuracy. To facilitate benchmarking of this task, we\ncreate a large-scale dataset of 200K images with 450K textual captions from a\nvariety of news websites, blogs, and social media posts. The dataset and source\ncode is publicly available at\nhttps://shivangi-aneja.github.io/projects/cosmos/.", "doi": "", "date": "2021-01-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.06278v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 689675904, "title": "Social Bots and Social Media Manipulation in 2020: The Year in Review", "abstract": "The year 2020 will be remembered for two events of global significance: the\nCOVID-19 pandemic and 2020 U.S. Presidential Election. In this chapter, we\nsummarize recent studies using large public Twitter data sets on these issues.\nWe have three primary objectives. First, we delineate epistemological and\npractical considerations when combining the traditions of computational\nresearch and social science research. A sensible balance should be struck when\nthe stakes are high between advancing social theory and concrete, timely\nreporting of ongoing events. We additionally comment on the computational\nchallenges of gleaning insight from large amounts of social media data. Second,\nwe characterize the role of social bots in social media manipulation around the\ndiscourse on the COVID-19 pandemic and 2020 U.S. Presidential Election. Third,\nwe compare results from 2020 to prior years to note that, although bot accounts\nstill contribute to the emergence of echo-chambers, there is a transition from\nstate-sponsored campaigns to domestically emergent sources of distortion.\nFurthermore, issues of public health can be confounded by political\norientation, especially from localized communities of actors who spread\nmisinformation. We conclude that automation and social media manipulation pose\nissues to a healthy and democratic discourse, precisely because they distort\nrepresentation of pluralism within the public sphere.", "doi": "", "date": "2021-02-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.08436v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2331573915, "title": "REMOD: Relation Extraction for Modeling Online Discourse", "abstract": "The enormous amount of discourse taking place online poses challenges to the\nfunctioning of a civil and informed public sphere. Efforts to standardize\nonline discourse data, such as ClaimReview, are making available a wealth of\nnew data about potentially inaccurate claims, reviewed by third-party\nfact-checkers. These data could help shed light on the nature of online\ndiscourse, the role of political elites in amplifying it, and its implications\nfor the integrity of the online information ecosystem. Unfortunately, the\nsemi-structured nature of much of this data presents significant challenges\nwhen it comes to modeling and reasoning about online discourse. A key challenge\nis relation extraction, which is the task of determining the semantic\nrelationships between named entities in a claim. Here we develop a novel\nsupervised learning method for relation extraction that combines graph\nembedding techniques with path traversal on semantic dependency graphs. Our\napproach is based on the intuitive observation that knowledge of the entities\nalong the path between the subject and object of a triple (e.g.\nWashington,_D.C.}, and United_States_of_America) provides useful information\nthat can be leveraged for extracting its semantic relation (i.e. capitalOf). As\nan example of a potential application of this technique for modeling online\ndiscourse, we show that our method can be integrated into a pipeline to reason\nabout potential misinformation claims.", "doi": "", "date": "2021-02-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.11105v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2104402058, "title": "A General Method to Find Highly Coordinating Communities in Social Media\n  through Inferred Interaction Links", "abstract": "Political misinformation, astroturfing and organised trolling are online\nmalicious behaviours with significant real-world effects. Many previous\napproaches examining these phenomena have focused on broad campaigns rather\nthan the small groups responsible for instigating or sustaining them. To reveal\nlatent (i.e., hidden) networks of cooperating accounts, we propose a novel\ntemporal window approach that relies on account interactions and metadata\nalone. It detects groups of accounts engaging in various behaviours that, in\nconcert, come to execute different goal-based strategies, a number of which we\ndescribe. The approach relies upon a pipeline that extracts relevant elements\nfrom social media posts, infers connections between accounts based on criteria\nmatching the coordination strategies to build an undirected weighted network of\naccounts, which is then mined for communities exhibiting high levels of\nevidence of coordination using a novel community extraction method. We address\nthe temporal aspect of the data by using a windowing mechanism, which may be\nsuitable for near real-time application. We further highlight consistent\ncoordination with a sliding frame across multiple windows and application of a\ndecay factor. Our approach is compared with other recent similar processing\napproaches and community detection methods and is validated against two\nrelevant datasets with ground truth data, using content, temporal, and network\nanalyses, as well as with the design, training and application of three\none-class classifiers built using the ground truth; its utility is furthermore\ndemonstrated in two case studies of contentious online discussions.", "doi": "", "date": "2021-03-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.03409v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1362191316, "title": "Supporting verification of news articles with automated search for\n  semantically similar articles", "abstract": "Fake information poses one of the major threats for society in the 21st\ncentury. Identifying misinformation has become a key challenge due to the\namount of fake news that is published daily. Yet, no approach is established\nthat addresses the dynamics and versatility of fake news editorials. Instead of\nclassifying content, we propose an evidence retrieval approach to handle fake\nnews. The learning task is formulated as an unsupervised machine learning\nproblem. For validation purpose, we provide the user with a set of news\narticles from reliable news sources supporting the hypothesis of the news\narticle in query and the final decision is left to the user. Technically we\npropose a two-step process: (i) Aggregation-step: With information extracted\nfrom the given text we query for similar content from reliable news sources.\n(ii) Refining-step: We narrow the supporting evidence down by measuring the\nsemantic distance of the text with the collection from step (i). The distance\nis calculated based on Word2Vec and the Word Mover's Distance. In our\nexperiments, only content that is below a certain distance threshold is\nconsidered as supporting evidence. We find that our approach is agnostic to\nconcept drifts, i.e. the machine learning task is independent of the hypotheses\nin a text. This makes it highly adaptable in times where fake news is as\ndiverse as classical news is. Our pipeline offers the possibility for further\nanalysis in the future, such as investigating bias and differences in news\nreporting.", "doi": "", "date": "2021-03-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.15581v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1423153390, "title": "The polarising effect of Review Bomb", "abstract": "This study discusses the Review Bomb, a phenomenon consisting of a massive\nattack by groups of Internet users on a website that displays users' review on\nproducts. It gained attention, especially on websites that aggregate numerical\nratings. Although this phenomenon can be considered an example of online\nmisinformation, it differs from conventional spam review, which happens within\nlarger time spans. In particular, the Bomb occurs suddenly and for a short\ntime, because in this way it leverages the notorious problem of cold-start: if\nreviews are submitted by a lot of fresh new accounts, it makes hard to justify\npreventative measures. The present research work is focused on the case of The\nLast of Us Part II, a video game published by Sony, that was the target of the\nwidest phenomenon of Review Bomb, occurred in June 2020. By performing an\nobservational analysis of a linguistic corpus of English reviews and the\nfeatures of its users, this study confirms that the Bomb was an ideological\nattack aimed at breaking down the rating system of the platform Metacritic.\nEvidence supports that the bombing had the unintended consequence to induce a\nreaction from users, ending into a consistent polarisation of ratings towards\nextreme values. The results not only display the theory of polarity in online\nreviews, but them also provide insights for the research on the problem of\ncold-start detection of spam review. In particular, it illustrates the\nrelevance of detecting users discussing contextual elements instead of the\nproduct and users with anomalous features.", "doi": "", "date": "2021-04-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.01140v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2197294452, "title": "When Can Liquid Democracy Unveil the Truth?", "abstract": "In this paper, we investigate the so-called ODP-problem that has been\nformulated by Caragiannis and Micha [10]. Here, we are in a setting with two\nelection alternatives out of which one is assumed to be correct. In ODP, the\ngoal is to organise the delegations in the social network in order to maximize\nthe probability that the correct alternative, referred to as ground truth, is\nelected. While the problem is known to be computationally hard, we strengthen\nexisting hardness results by providing a novel strong approximation hardness\nresult: For any positive constant $C$, we prove that, unless $P=NP$, there is\nno polynomial-time algorithm for ODP that achieves an approximation guarantee\nof $\\alpha \\ge (\\ln n)^{-C}$, where $n$ is the number of voters. The reduction\ndesigned for this result uses poorly connected social networks in which some\nvoters suffer from misinformation. Interestingly, under some hypothesis on\neither the accuracies of voters or the connectivity of the network, we obtain a\npolynomial-time $1/2$-approximation algorithm. This observation proves formally\nthat the connectivity of the social network is a key feature for the efficiency\nof the liquid democracy paradigm. Lastly, we run extensive simulations and\nobserve that simple algorithms (working either in a centralized or\ndecentralized way) outperform direct democracy on a large class of instances.\nOverall, our contributions yield new insights on the question in which\nsituations liquid democracy can be beneficial.", "doi": "", "date": "2021-04-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.01828v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2095562276, "title": "Multiscale Governance", "abstract": "Future societal systems will be characterized by heterogeneous human\nbehaviors and also collective action. The interaction between local systems and\nglobal systems will be complex. Humandemics will propagate because of the\npathways that connect the different systems and several invariant behaviors and\npatterns that have emerged globally. On the contrary, infodemics of\nmisinformation can be a risk as it has occurred in the COVID-19 pandemic. The\nemerging fragility or robustness of the system will depend on how this complex\nnetwork of systems is governed. Future societal systems will not be only\nmultiscale in terms of the social dimension, but also in the temporality.\nNecessary and proper prevention and response systems based on complexity, ethic\nand multi-scale governance will be required. Real-time response systems are the\nbasis for resilience to be the foundation of robust societies. A top-down\napproach led by Governmental organs for managing humandemics is not sufficient\nand may be only effective if policies are very restrictive and their efficacy\ndepends not only in the measures implemented but also on the dynamics of the\npolicies and the population perception and compliance. This top-down approach\nis even weaker if there is not national and international coordination.\nCoordinating top-down agencies with bottom-up constructs will be the design\nprinciple. Multi-scale governance integrates decision-making processes with\nsignaling, sensing and leadership mechanisms to drive thriving societal systems\nwith real-time sensitivity.", "doi": "", "date": "2021-04-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.02752v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 973089933, "title": "Combining exogenous and endogenous signals with a semi-supervised\n  co-attention network for early detection of COVID-19 fake tweets", "abstract": "Fake tweets are observed to be ever-increasing, demanding immediate\ncountermeasures to combat their spread. During COVID-19, tweets with\nmisinformation should be flagged and neutralized in their early stages to\nmitigate the damages. Most of the existing methods for early detection of fake\nnews assume to have enough propagation information for large labeled tweets --\nwhich may not be an ideal setting for cases like COVID-19 where both aspects\nare largely absent. In this work, we present ENDEMIC, a novel early detection\nmodel which leverages exogenous and endogenous signals related to tweets, while\nlearning on limited labeled data. We first develop a novel dataset, called CTF\nfor early COVID-19 Twitter fake news, with additional behavioral test sets to\nvalidate early detection. We build a heterogeneous graph with\nfollower-followee, user-tweet, and tweet-retweet connections and train a graph\nembedding model to aggregate propagation information. Graph embeddings and\ncontextual features constitute endogenous, while time-relative web-scraped\ninformation constitutes exogenous signals. ENDEMIC is trained in a\nsemi-supervised fashion, overcoming the challenge of limited labeled data. We\npropose a co-attention mechanism to fuse signal representations optimally.\nExperimental results on ECTF, PolitiFact, and GossipCop show that ENDEMIC is\nhighly reliable in detecting early fake tweets, outperforming nine\nstate-of-the-art methods significantly.", "doi": "", "date": "2021-04-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.05321v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3822613519, "title": "The Role of Context in Detecting Previously Fact-Checked Claims", "abstract": "Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.", "doi": "", "date": "2021-04-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.07423v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1302673835, "title": "Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment", "abstract": "The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations.", "doi": "", "date": "2021-05-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.09114v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1885955387, "title": "Pattern Detection in the Activation Space for Identifying Synthesized\n  Content", "abstract": "Generative Adversarial Networks (GANs) have recently achieved unprecedented\nsuccess in photo-realistic image synthesis from low-dimensional random noise.\nThe ability to synthesize high-quality content at a large scale brings\npotential risks as the generated samples may lead to misinformation that can\ncreate severe social, political, health, and business hazards. We propose\nSubsetGAN to identify generated content by detecting a subset of anomalous\nnode-activations in the inner layers of pre-trained neural networks. These\nnodes, as a group, maximize a non-parametric measure of divergence away from\nthe expected distribution of activations created from real data. This enable us\nto identify synthesised images without prior knowledge of their distribution.\nSubsetGAN efficiently scores subsets of nodes and returns the group of nodes\nwithin the pre-trained classifier that contributed to the maximum score. The\nclassifier can be a general fake classifier trained over samples from multiple\nsources or the discriminator network from different GANs. Our approach shows\nconsistently higher detection power than existing detection methods across\nseveral state-of-the-art GANs (PGGAN, StarGAN, and CycleGAN) and over different\nproportions of generated content.", "doi": "", "date": "2021-05-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.12479v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 572981340, "title": "The 2021 Image Similarity Dataset and Challenge", "abstract": "This paper introduces a new benchmark for large-scale image similarity\ndetection. This benchmark is used for the Image Similarity Challenge at\nNeurIPS'21 (ISC2021). The goal is to determine whether a query image is a\nmodified copy of any image in a reference corpus of size 1~million. The\nbenchmark features a variety of image transformations such as automated\ntransformations, hand-crafted image edits and machine-learning based\nmanipulations. This mimics real-life cases appearing in social media, for\nexample for integrity-related problems dealing with misinformation and\nobjectionable content. The strength of the image manipulations, and therefore\nthe difficulty of the benchmark, is calibrated according to the performance of\na set of baseline approaches. Both the query and reference set contain a\nmajority of \"distractor\" images that do not match, which corresponds to a\nreal-life needle-in-haystack setting, and the evaluation metric reflects that.\nWe expect the DISC21 benchmark to promote image copy detection as an important\nand challenging computer vision task and refresh the state of the art.", "doi": "", "date": "2021-06-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.09672v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2439356577, "title": "Characterizing Social Imaginaries and Self-Disclosures of Dissonance in\n  Online Conspiracy Discussion Communities", "abstract": "Online discussion platforms offer a forum to strengthen and propagate belief\nin misinformed conspiracy theories. Yet, they also offer avenues for conspiracy\ntheorists to express their doubts and experiences of cognitive dissonance. Such\nexpressions of dissonance may shed light on who abandons misguided beliefs and\nunder which circumstances. This paper characterizes self-disclosures of\ndissonance about QAnon, a conspiracy theory initiated by a mysterious leader Q\nand popularized by their followers, anons in conspiracy theory subreddits. To\nunderstand what dissonance and disbelief mean within conspiracy communities, we\nfirst characterize their social imaginaries, a broad understanding of how\npeople collectively imagine their social existence. Focusing on 2K posts from\ntwo image boards, 4chan and 8chan, and 1.2 M comments and posts from 12\nsubreddits dedicated to QAnon, we adopt a mixed methods approach to uncover the\nsymbolic language representing the movement, expectations, practices, heroes\nand foes of the QAnon community. We use these social imaginaries to create a\ncomputational framework for distinguishing belief and dissonance from general\ndiscussion about QAnon. Further, analyzing user engagement with QAnon\nconspiracy subreddits, we find that self-disclosures of dissonance correlate\nwith a significant decrease in user contributions and ultimately with their\ndeparture from the community. We contribute a computational framework for\nidentifying dissonance self-disclosures and measuring the changes in user\nengagement surrounding dissonance. Our work can provide insights into designing\ndissonance-based interventions that can potentially dissuade conspiracists from\nonline conspiracy discussion communities.", "doi": "", "date": "2021-07-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.10204v1", "pdf": ""}, "publisher-venue": "CSCW 2021", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 837469164, "title": "NudgeCred: Supporting News Credibility Assessment on Social Media\n  Through Nudges", "abstract": "Struggling to curb misinformation, social media platforms are experimenting\nwith design interventions to enhance consumption of credible news on their\nplatforms. Some of these interventions, such as the use of warning messages,\nare examples of nudges -- a choice-preserving technique to steer behavior.\nDespite their application, we do not know whether nudges could steer people\ninto making conscious news credibility judgments online and if they do, under\nwhat constraints. To answer, we combine nudge techniques with heuristic based\ninformation processing to design NudgeCred -- a browser extension for Twitter.\nNudgeCred directs users' attention to two design cues: authority of a source\nand other users' collective opinion on a report by activating three design\nnudges -- Reliable, Questionable, and Unreliable, each denoting particular\nlevels of credibility for news tweets. In a controlled experiment, we found\nthat NudgeCred significantly helped users (n=430) distinguish news tweets'\ncredibility, unrestricted by three behavioral confounds -- political ideology,\npolitical cynicism, and media skepticism. A five-day field deployment with\ntwelve participants revealed that NudgeCred improved their recognition of news\nitems and attention towards all of our nudges, particularly towards\nQuestionable. Among other considerations, participants proposed that designers\nshould incorporate heuristics that users' would trust. Our work informs\nnudge-based system design approaches for online media.", "doi": "10.1145/3479571", "date": "2021-08-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.01536v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4902818, "title": "Designing Transparency Cues in Online News Platforms to Promote Trust:\n  Journalists' & Consumers' Perspectives", "abstract": "As news organizations embrace transparency practices on their websites to\ndistinguish themselves from those spreading misinformation, HCI designers have\nthe opportunity to help them effectively utilize the ideals of transparency to\nbuild trust. How can we utilize transparency to promote trust in news? We\nexamine this question through a qualitative lens by interviewing journalists\nand news consumers---the two stakeholders in a news system. We designed a\nscenario to demonstrate transparency features using two fundamental news\nattributes that convey the trustworthiness of a news article: source and\nmessage. In the interviews, our news consumers expressed the idea that news\ntransparency could be best shown by providing indicators of objectivity in two\nareas (news selection and framing) and by providing indicators of evidence in\nfour areas (presence of source materials, anonymous sourcing, verification, and\ncorrections upon erroneous reporting). While our journalists agreed with news\nconsumers' suggestions of using evidence indicators, they also suggested\nadditional transparency indicators in areas such as the news reporting process\nand personal/organizational conflicts of interest. Prompted by our scenario,\nparticipants offered new design considerations for building trustworthy news\nplatforms, such as designing for easy comprehension, presenting appropriate\ndetails in news articles (e.g., showing the number and nature of corrections\nmade to an article), and comparing attributes across news organizations to\nhighlight diverging practices. Comparing the responses from our two stakeholder\ngroups reveals conflicting suggestions with trade-offs between them. Our study\nhas implications for HCI designers in building trustworthy news systems.", "doi": "10.1145/3479539", "date": "2021-08-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.02325v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3448313321, "title": "Towards Explainable Fact Checking", "abstract": "The past decade has seen a substantial rise in the amount of mis- and\ndisinformation online, from targeted disinformation campaigns to influence\npolitics, to the unintentional spreading of misinformation about public health.\nThis development has spurred research in the area of automatic fact checking,\nfrom approaches to detect check-worthy claims and determining the stance of\ntweets towards claims, to methods to determine the veracity of claims given\nevidence documents. These automatic methods are often content-based, using\nnatural language processing methods, which in turn utilise deep neural networks\nto learn higher-order features from text in order to make predictions. As deep\nneural networks are black-box models, their inner workings cannot be easily\nexplained. At the same time, it is desirable to explain how they arrive at\ncertain decisions, especially if they are to be used for decision making. While\nthis has been known for some time, the issues this raises have been exacerbated\nby models increasing in size, and by EU legislation requiring models to be used\nfor decision making to provide explanations, and, very recently, by legislation\nrequiring online platforms operating in the EU to provide transparent reporting\non their services. Despite this, current solutions for explainability are still\nlacking in the area of fact checking. This thesis presents my research on\nautomatic fact checking, including claim check-worthiness detection, stance\ndetection and veracity prediction. Its contributions go beyond fact checking,\nwith the thesis proposing more general machine learning solutions for natural\nlanguage processing in the area of learning with limited labelled data.\nFinally, the thesis presents some first solutions for explainable fact\nchecking.", "doi": "", "date": "2021-08-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.10274v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2770072702, "title": "Misleading the Covid-19 vaccination discourse on Twitter: An exploratory\n  study of infodemic around the pandemic", "abstract": "In this work, we collect a moderate-sized representative corpus of tweets\n(200,000 approx.) pertaining Covid-19 vaccination spanning over a period of\nseven months (September 2020 - March 2021). Following a Transfer Learning\napproach, we utilize the pre-trained Transformer-based XLNet model to classify\ntweets as Misleading or Non-Misleading and validate against a random subset of\nresults manually. We build on this to study and contrast the characteristics of\ntweets in the corpus that are misleading in nature against non-misleading ones.\nThis exploratory analysis enables us to design features (such as sentiments,\nhashtags, nouns, pronouns, etc) that can, in turn, be exploited for classifying\ntweets as (Non-)Misleading using various ML models in an explainable manner.\nSpecifically, several ML models are employed for prediction, with up to 90%\naccuracy, and the importance of each feature is explained using SHAP\nExplainable AI (XAI) tool. While the thrust of this work is principally\nexploratory analysis in order to obtain insights on the online discourse on\nCovid-19 vaccination, we conclude the paper by outlining how these insights\nprovide the foundations for a more actionable approach to mitigate\nmisinformation. The curated dataset and code is made available (Github\nrepository) so that the research community at large can reproduce, compare\nagainst, or build upon this work.", "doi": "", "date": "2021-08-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.10735v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 350700909, "title": "Replaying Archived Twitter: When your bird is broken, will it bring you\n  down?", "abstract": "Historians and researchers trust web archives to preserve social media\ncontent that no longer exists on the live web. However, what we see on the live\nweb and how it is replayed in the archive are not always the same. In this\npaper, we document and analyze the problems in archiving Twitter ever since\nTwitter forced the use of its new UI in June 2020. Most web archives were\nunable to archive the new UI, resulting in archived Twitter pages displaying\nTwitter's \"Something went wrong\" error. The challenges in archiving the new UI\nforced web archives to continue using the old UI. To analyze the potential loss\nof information in web archival data due to this change, we used the personal\nTwitter account of the 45th President of the United States, @realDonaldTrump,\nwhich was suspended by Twitter on January 8, 2021. Trump's account was heavily\nlabeled by Twitter for spreading misinformation, however we discovered that\nthere is no evidence in web archives to prove that some of his tweets ever had\na label assigned to them. We also studied the possibility of temporal\nviolations in archived versions of the new UI, which may result in the replay\nof pages that never existed on the live web. Our goal is to educate researchers\nwho may use web archives and caution them when drawing conclusions based on\narchived Twitter pages.", "doi": "", "date": "2021-08-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12092v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 47190842, "title": "Public sentiment analysis and topic modeling regarding COVID-19 vaccines\n  on the Reddit social media platform: A call to action for strengthening\n  vaccine confidence", "abstract": "The COVID-19 pandemic fueled one of the most rapid vaccine developments in\nhistory. However, misinformation spread through online social media often leads\nto negative vaccine sentiment and hesitancy. To investigate COVID-19\nvaccine-related discussion in social media, we conducted a sentiment analysis\nand Latent Dirichlet Allocation topic modeling on textual data collected from\n13 Reddit communities focusing on the COVID-19 vaccine from Dec 1, 2020, to May\n15, 2021. Data were aggregated and analyzed by month to detect changes in any\nsentiment and latent topics. ty analysis suggested these communities expressed\nmore positive sentiment than negative regarding the vaccine-related discussions\nand has remained static over time. Topic modeling revealed community members\nmainly focused on side effects rather than outlandish conspiracy theories.\nCovid-19 vaccine-related content from 13 subreddits show that the sentiments\nexpressed in these communities are overall more positive than negative and have\nnot meaningfully changed since December 2020. Keywords indicating vaccine\nhesitancy were detected throughout the LDA topic modeling. Public sentiment and\ntopic modeling analysis regarding vaccines could facilitate the implementation\nof appropriate messaging, digital interventions, and new policies to promote\nvaccine confidence.", "doi": "10.1016/j.jiph.2021.08.010", "date": "2021-08-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.13293v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1584317800, "title": "Synchronous Counting and Computational Algorithm Design", "abstract": "Consider a complete communication network on $n$ nodes, each of which is a\nstate machine. In synchronous 2-counting, the nodes receive a common clock\npulse and they have to agree on which pulses are \"odd\" and which are \"even\". We\nrequire that the solution is self-stabilising (reaching the correct operation\nfrom any initial state) and it tolerates $f$ Byzantine failures (nodes that\nsend arbitrary misinformation). Prior algorithms are expensive to implement in\nhardware: they require a source of random bits or a large number of states.\n  This work consists of two parts. In the first part, we use computational\ntechniques (often known as synthesis) to construct very compact deterministic\nalgorithms for the first non-trivial case of $f = 1$. While no algorithm exists\nfor $n < 4$, we show that as few as 3 states per node are sufficient for all\nvalues $n \\ge 4$. Moreover, the problem cannot be solved with only 2 states per\nnode for $n = 4$, but there is a 2-state solution for all values $n \\ge 6$.\n  In the second part, we develop and compare two different approaches for\nsynthesising synchronous counting algorithms. Both approaches are based on\ncasting the synthesis problem as a propositional satisfiability (SAT) problem\nand employing modern SAT-solvers. The difference lies in how to solve the SAT\nproblem: either in a direct fashion, or incrementally within a counter-example\nguided abstraction refinement loop. Empirical results suggest that the former\ntechnique is more efficient if we want to synthesise time-optimal algorithms,\nwhile the latter technique discovers non-optimal algorithms more quickly.", "doi": "10.1016/j.jcss.2015.09.002", "date": "2013-04-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1304.5719v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1921263232, "title": "The Partial Entropy Decomposition: Decomposing multivariate entropy and\n  mutual information via pointwise common surprisal", "abstract": "Obtaining meaningful quantitative descriptions of the statistical dependence\nwithin multivariate systems is a difficult open problem. Recently, the Partial\nInformation Decomposition (PID) was proposed to decompose mutual information\n(MI) about a target variable into components which are redundant, unique and\nsynergistic within different subsets of predictor variables. Here, we propose\nto apply the elegant formalism of the PID to multivariate entropy, resulting in\na Partial Entropy Decomposition (PED). We implement the PED with an entropy\nredundancy measure based on pointwise common surprisal; a natural definition\nwhich is closely related to the definition of MI. We show how this approach can\nreveal the dyadic vs triadic generative structure of multivariate systems that\nare indistinguishable with classical Shannon measures. The entropy perspective\nalso shows that misinformation is synergistic entropy and hence that MI itself\nincludes both redundant and synergistic effects. We show the relationships\nbetween the PED and MI in two predictors, and derive two alternative\ninformation decompositions which we illustrate on several example systems. This\nreveals that in entropy terms, univariate predictor MI is not a proper subset\nof the joint MI, and we suggest this previously unrecognised fact explains in\npart why obtaining a consistent PID has proven difficult. The PED also allows\nseparate quantification of mechanistic redundancy (related to the function of\nthe system) versus source redundancy (arising from dependencies between\ninputs); an important distinction which no existing methods can address. The\nnew perspective provided by the PED helps to clarify some of the difficulties\nencountered with the PID approach and the resulting decompositions provide\nuseful tools for practical data analysis across a wide range of application\nareas.", "doi": "", "date": "2017-02-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1702.01591v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 902276377, "title": "CSI: A Hybrid Deep Model for Fake News Detection", "abstract": "The topic of fake news has drawn attention both from the public and the\nacademic communities. Such misinformation has the potential of affecting public\nopinion, providing an opportunity for malicious parties to manipulate the\noutcomes of public events such as elections. Because such high stakes are at\nplay, automatically detecting fake news is an important, yet challenging\nproblem that is not yet well understood. Nevertheless, there are three\ngenerally agreed upon characteristics of fake news: the text of an article, the\nuser response it receives, and the source users promoting it. Existing work has\nlargely focused on tailoring solutions to one particular characteristic which\nhas limited their success and generality. In this work, we propose a model that\ncombines all three characteristics for a more accurate and automated\nprediction. Specifically, we incorporate the behavior of both parties, users\nand articles, and the group behavior of users who propagate fake news.\nMotivated by the three characteristics, we propose a model called CSI which is\ncomposed of three modules: Capture, Score, and Integrate. The first module is\nbased on the response and text; it uses a Recurrent Neural Network to capture\nthe temporal pattern of user activity on a given article. The second module\nlearns the source characteristic based on the behavior of users, and the two\nare integrated with the third module to classify an article as fake or not.\nExperimental analysis on real-world data demonstrates that CSI achieves higher\naccuracy than existing models, and extracts meaningful latent representations\nof both users and articles.", "doi": "10.1145/3132847.3132877", "date": "2017-03-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1703.06959v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3237911400, "title": "\"But since the affairs of men rest still uncertain, let's reason with\n  the worst that may befall\": Probability, risk, and the 2009 L'Aquila\n  Earthquake", "abstract": "This article is a commentary on the verdict of the \"L'Aquila Six\", the group\nof bureaucrats and scientists tried by an Italian court as a result of their\npublic statements in advance of the quake of 2009 Apr. 6 that left the city in\nruins and cause more than 300 deaths. It was not the worst such catastrophic\nevent in recent Italian history, but it was one of -- if not the -- worst\nfailures of risk assessment and preventive action. The six were found guilty\nand condemned by a first level of the justice system to substantial prison\nterms. The outcry provoked by the verdict in the world press and the\ninternational scientific community has fueled the already fiery debate over\nwhether the six should have been tried at all. They have been presented as\nmartyrs to science being treated as scapegoats by a scientifically illiterate\njustice system and inflamed local population for not being able to perform the\nimpossible (predict the event). Petitions of support have been drafted and\nsigned by thousands of working scientists and technical experts in many fields\nexcoriating the court and the country for such an outrage against the\nscientific community, often accompanied by ominous warnings about the chilling\neffect this will have on the availability of expert advice in times of need. My\npurpose in this essay is to explain why this view of the events of the trial is\nmisguided, however well intentioned, and misinformed.", "doi": "", "date": "2012-11-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1211.3175v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3927030398, "title": "Analyzing the Digital Traces of Political Manipulation: The 2016 Russian\n  Interference Twitter Campaign", "abstract": "Until recently, social media was seen to promote democratic discourse on\nsocial and political issues. However, this powerful communication platform has\ncome under scrutiny for allowing hostile actors to exploit online discussions\nin an attempt to manipulate public opinion. A case in point is the ongoing U.S.\nCongress' investigation of Russian interference in the 2016 U.S. election\ncampaign, with Russia accused of using trolls (malicious accounts created to\nmanipulate) and bots to spread misinformation and politically biased\ninformation. In this study, we explore the effects of this manipulation\ncampaign, taking a closer look at users who re-shared the posts produced on\nTwitter by the Russian troll accounts publicly disclosed by U.S. Congress\ninvestigation. We collected a dataset with over 43 million election-related\nposts shared on Twitter between September 16 and October 21, 2016, by about 5.7\nmillion distinct users. This dataset included accounts associated with the\nidentified Russian trolls. We use label propagation to infer the ideology of\nall users based on the news sources they shared. This method enables us to\nclassify a large number of users as liberal or conservative with precision and\nrecall above 90%. Conservatives retweeted Russian trolls about 31 times more\noften than liberals and produced 36x more tweets. Additionally, most retweets\nof troll content originated from two Southern states: Tennessee and Texas.\nUsing state-of-the-art bot detection techniques, we estimated that about 4.9%\nand 6.2% of liberal and conservative users respectively were bots. Text\nanalysis on the content shared by trolls reveals that they had a mostly\nconservative, pro-Trump agenda. Although an ideologically broad swath of\nTwitter users was exposed to Russian Trolls in the period leading up to the\n2016 U.S. Presidential election, it was mainly conservatives who helped amplify\ntheir message.", "doi": "10.1109/asonam.2018.8508646", "date": "2018-02-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1802.04291v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2766363836, "title": "Combining Similarity Features and Deep Representation Learning for\n  Stance Detection in the Context of Checking Fake News", "abstract": "Fake news are nowadays an issue of pressing concern, given their recent rise\nas a potential threat to high-quality journalism and well-informed public\ndiscourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage\nthe development of machine learning-based classification systems for stance\ndetection (i.e., for identifying whether a particular news article agrees,\ndisagrees, discusses, or is unrelated to a particular news headline), thus\nhelping in the detection and analysis of possible instances of fake news. This\narticle presents a new approach to tackle this stance detection problem, based\non the combination of string similarity features with a deep neural\narchitecture that leverages ideas previously advanced in the context of\nlearning efficient text representations, document classification, and natural\nlanguage inference. Specifically, we use bi-directional Recurrent Neural\nNetworks, together with max-pooling over the temporal/sequential dimension and\nneural attention, for representing (i) the headline, (ii) the first two\nsentences of the news article, and (iii) the entire news article. These\nrepresentations are then combined/compared, complemented with similarity\nfeatures inspired on other FNC-1 approaches, and passed to a final layer that\npredicts the stance of the article towards the headline. We also explore the\nuse of external sources of information, specifically large datasets of sentence\npairs originally proposed for training and evaluating natural language\ninference methods, in order to pre-train specific components of the neural\nnetwork architecture (e.g., the RNNs used for encoding sentences). The obtained\nresults attest to the effectiveness of the proposed ideas and show that our\nmodel, particularly when considering pre-training and the combination of neural\nrepresentations together with similarity features, slightly outperforms the\nprevious state-of-the-art.", "doi": "", "date": "2018-11-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.00706v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 330305384, "title": "An Efficient Randomized Algorithm for Rumor Blocking in Online Social\n  Networks", "abstract": "Social networks allow rapid spread of ideas and innovations while the\nnegative information can also propagate widely. When the cascades with\ndifferent opinions reaching the same user, the cascade arriving first is the\nmost likely to be taken by the user. Therefore, once misinformation or rumor is\ndetected, a natural containment method is to introduce a positive cascade\ncompeting against the rumor. Given a budget $k$, the rumor blocking problem\nasks for $k$ seed users to trigger the spread of the positive cascade such that\nthe number of the users who are not influenced by rumor can be maximized. The\nprior works have shown that the rumor blocking problem can be approximated\nwithin a factor of $(1-1/e-\\delta)$ by a classic greedy algorithm combined with\nMonte Carlo simulation with the running time of $O(\\frac{k^3mn\\ln\nn}{\\delta^2})$, where $n$ and $m$ are the number of users and edges,\nrespectively. Unfortunately, the Monte-Carlo-simulation-based methods are\nextremely time consuming and the existing algorithms either trade performance\nguarantees for practical efficiency or vice versa. In this paper, we present a\nrandomized algorithm which runs in $O(\\frac{km\\ln n}{\\delta^2})$ expected time\nand provides a $(1-1/e-\\delta)$-approximation with a high probability. The\nexperimentally results on both the real-world and synthetic social networks\nhave shown that the proposed randomized rumor blocking algorithm is much more\nefficient than the state-of-the-art method and it is able to find the seed\nnodes which are effective in limiting the spread of rumor.", "doi": "", "date": "2017-01-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1701.02368v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1062579524, "title": "Embedding Climate Change Engagement in Astronomy Education and Research", "abstract": "This White Paper is a call to action for astronomers to respond to climate\nchange with a large structural transition within our profession. Many\nastronomers are deeply concerned about climate change and act upon it in their\npersonal and professional lives, and many organizations within astronomy have\nincorporated incremental changes. We need a collective impact model to better\nnetwork and grow our efforts so that we can achieve results that are on the\nscale appropriate to address climate change at the necessary level indicated by\nscientific research; e.g., becoming carbon neutral by 2050. We need to\nimplement strategies within two primary drivers of our field: (1) Education and\nOutreach, and (2) Research Practices and Infrastructure. (1) In the classroom\nand through public talks, astronomers reach a large audience. Astronomy is\nclosely connected to the science of climate change, and it is arguably the most\nimportant topic we include in our curriculum. Due to misinformation and\ndisinformation, climate change communication is different than for other areas\nof science. We therefore need to expand our communication and implement\neffective strategies, for which there is now a considerable body of research.\n(2) On a per-person basis astronomers have an outsized carbon impact. There are\nnumerous ways we can reduce our footprint; e.g., in the design and operation of\ntelescope facilities and in the optimization and reduction of travel.\nFortunately, many of these solutions are win-win scenarios, e.g., increasing\nthe online presence of conferences will reduce the carbon footprint while\nincreasing participation, especially for astronomers working with fewer\nfinancial resources. Astronomers have an obligation to act on climate change in\nevery way possible, and we need to do it now. In this White Paper, we outline a\nplan for collective impact using a Networked Improvement Community (NIC)\napproach.", "doi": "", "date": "2019-07-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.08043v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2324096695, "title": "Evidence of disorientation towards immunization on online social media\n  after contrasting political communication on vaccines. Results from an\n  analysis of Twitter data in Italy", "abstract": "Background. In Italy, in recent years, vaccination coverage for key\nimmunizations as MMR has been declining to worryingly low levels. In 2017, the\nItalian Gov't expanded the number of mandatory immunizations introducing\npenalties to unvaccinated children's families. During the 2018 general\nelections campaign, immunization policy entered the political debate with the\nGov't in charge blaming oppositions for fuelling vaccine scepticism. A new\nGov't established in 2018 temporarily relaxed penalties. Objectives and\nMethods. Using a sentiment analysis on tweets posted in Italian during 2018, we\naimed to: (i) characterize the temporal flow of vaccines communication on\nTwitter (ii) evaluate the polarity of vaccination opinions and usefulness of\nTwitter data to estimate vaccination parameters, and (iii) investigate whether\nthe contrasting announcements at the highest political level might have\noriginated disorientation amongst the Italian public. Results. Vaccine-relevant\ntweeters interactions peaked in response to main political events. Out of\nretained tweets, 70.0% resulted favourable to vaccination, 16.5% unfavourable,\nand 13.6% undecided, respectively. The smoothed time series of polarity\nproportions exhibit frequent large changes in the favourable proportion,\nenhanced by an up and down trend synchronized with the switch between gov't\nsuggesting evidence of disorientation among the public. Conclusion. The\nreported evidence of disorientation documents that critical immunization\ntopics, should never be used for political consensus. This is especially true\ngiven the increasing role of online social media as information source, which\nmight yield to social pressures eventually harmful for vaccine uptake, and is\nworsened by the lack of institutional presence on Twitter, calling for efforts\nto contrast misinformation and the ensuing spread of hesitancy.", "doi": "", "date": "2019-12-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.00846v5", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4011950482, "title": "CovidSens: A Vision on Reliable Social Sensing for COVID-19", "abstract": "With the spiraling pandemic of the Coronavirus Disease 2019 (COVID-19), it\nhas becoming inherently important to disseminate accurate and timely\ninformation about the disease. Due to the ubiquity of Internet connectivity and\nsmart devices, social sensing is emerging as a dynamic AI-driven sensing\nparadigm to extract real-time observations from online users. In this paper, we\npropose CovidSens, a vision of social sensing based risk alert systems to\nspontaneously obtain and analyze social data to infer COVID-19 propagation.\nCovidSens can actively help to keep the general public informed about the\nCOVID-19 spread and identify risk-prone areas. The CovidSens concept is\nmotivated by three observations: 1) people actively share their experience of\nCOVID-19 via online social media, 2) official warning channels and news\nagencies are relatively slower than people reporting on social media, and 3)\nonline users are frequently equipped with powerful mobile devices that can\nperform data processing and analytics. We envision unprecedented opportunities\nto leverage posts generated by ordinary people to build real-time sensing and\nanalytic system for gathering and circulating COVID-19 propagation data.\nSpecifically, the vision of CovidSens attempts to answer the questions: How to\ndistill reliable information on COVID-19 with prevailing rumors and\nmisinformation? How to inform the general public about the state of the spread\ntimely and effectively? How to leverage the computational power on edge devices\nto construct fully integrated edge-based social sensing platforms? In this\nvision paper, we discuss the roles of CovidSens and identify potential\nchallenges in developing reliable social sensing based risk alert systems. We\nenvision that approaches originating from multiple disciplines can be effective\nin addressing the challenges. Finally, we outline a few research directions for\nfuture work in CovidSens.", "doi": "", "date": "2020-04-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.04565v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2849403656, "title": "Did State-sponsored Trolls Shape the 2016 US Presidential Election\n  Discourse? Quantifying Influence on Twitter", "abstract": "It is a widely accepted fact that state-sponsored Twitter accounts operated\nduring the 2016 US presidential election, spreading millions of tweets with\nmisinformation and inflammatory political content. Whether these social media\ncampaigns of the so-called \"troll\" accounts were able to manipulate public\nopinion is still in question. Here, we quantify the influence of troll accounts\non Twitter by analyzing 152.5 million tweets (by 9.9 million users) from that\nperiod. The data contain original tweets from 822 troll accounts identified as\nsuch by Twitter itself. We construct and analyse a very large interaction graph\nof 9.3 million nodes and 169.9 million edges using graph analysis techniques,\nalong with a game-theoretic centrality measure. Then, we quantify the influence\nof all Twitter accounts on the overall information exchange as is defined by\nthe retweet cascades. We provide a global influence ranking of all Twitter\naccounts and we find that one troll account appears in the top-100 and four in\nthe top-1000. This combined with other findings presented in this paper\nconstitute evidence that the driving force of virality and influence in the\nnetwork came from regular users - users who have not been classified as trolls\nby Twitter. On the other hand, we find that on average, troll accounts were\ntens of times more influential than regular users were. Moreover, 23% and 22%\nof regular accounts in the top-100 and top-1000 respectively, have now been\nsuspended by Twitter. This raises questions about their authenticity and\npractices during the 2016 US presidential election.", "doi": "", "date": "2020-06-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.09938v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 887329891, "title": "A First Look at Android Applications in Google Play related to Covid-19", "abstract": "Due to the convenience of access-on-demand to information and business\nsolutions, mobile apps have become an important asset in the digital world. In\nthe context of the Covid-19 pandemic, app developers have joined the response\neffort in various ways by releasing apps that target different user bases\n(e.g., all citizens or journalists), offer different services (e.g., location\ntracking or diagnostic-aid), provide generic or specialized information, etc.\nWhile many apps have raised some concerns by spreading misinformation or even\nmalware, the literature does not yet provide a clear landscape of the different\napps that were developed. In this study, we focus on the Android ecosystem and\ninvestigate Covid-related Android apps. In a best-effort scenario, we attempt\nto systematically identify all relevant apps and study their characteristics\nwith the objective to provide a First taxonomy of Covid-related apps,\nbroadening the relevance beyond the implementation of contact tracing. Overall,\nour study yields a number of empirical insights that contribute to enlarge the\nknowledge on Covid-related apps: (1) Developer communities contributed rapidly\nto the Covid-19, with dedicated apps released as early as January 2020; (2)\nCovid-related apps deliver digital tools to users (e.g., health diaries), serve\nto broadcast information to users (e.g., spread statistics), and collect data\nfrom users (e.g., for tracing); (3) Covid-related apps are less complex than\nstandard apps; (4) they generally do not seem to leak sensitive data; (5) in\nthe majority of cases, Covid-related apps are released by entities with past\nexperience on the market, mostly official government entities or public health\norganizations.", "doi": "", "date": "2020-06-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.11002v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 428588231, "title": "COVID-19 Remote Patient Monitoring: Social Impact of AI", "abstract": "A primary indicator of success in the fight against COVID-19 is avoiding\nstress on critical care infrastructure and services (CCIS). However, CCIS will\nlikely remain stressed until sustained herd immunity is built. There are also\nsecondary considerations for success: mitigating economic damage; curbing the\nspread of misinformation, improving morale, and preserving a sense of control;\nbuilding global trust for diplomacy, trade and travel; and restoring\nreliability and normalcy to day-to-day life, among others. We envision\ntechnology plays a pivotal role. Here, we focus on the effective use of readily\navailable technology to improve the primary and secondary success criteria for\nthe fight against SARS-CoV-2. In a multifaceted technology approach, we start\nwith effective technology use for remote patient monitoring (RPM) of COVID-19\nwith the following objectives:\n  1. Deploy readily available technology for continuous real-time remote\nmonitoring of patient vitals with the help of biosensors on a large scale.\n  2. Effective and safe remote large-scale communitywide care of low-severity\ncases as a buffer against surges in COVID-19 hospitalizations to reduce strain\non critical care services and emergency hospitals.\n  3. Improve the patient, their family, and their community's sense of control\nand morale.\n  4. Propose a clear technology and medical definition of remote patient\nmonitoring for COVID-19 to address an urgent technology need; address\nobfuscated, narrow, and erroneous information and provide examples; and urge\npublishers to be clear and complete in their disclosures.\n  5. Leverage the cloud-based distributed cognitive RPM platform for community\nleaders and decision makers to enable planning and resource management,\npandemic research, damage prevention and containment, and receiving feedback on\nstrategies and executions.", "doi": "", "date": "2020-07-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.12312v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3267039681, "title": "Developing Future Human-Centered Smart Cities: Critical Analysis of\n  Smart City Security, Interpretability, and Ethical Challenges", "abstract": "As we make tremendous advances in machine learning and artificial\nintelligence technosciences, there is a renewed understanding in the AI\ncommunity that we must ensure that humans being are at the center of our\ndeliberations so that we don't end in technology-induced dystopias. As strongly\nargued by Green in his book Smart Enough City, the incorporation of technology\nin city environs does not automatically translate into prosperity, wellbeing,\nurban livability, or social justice. There is a great need to deliberate on the\nfuture of the cities worth living and designing. There are philosophical and\nethical questions involved along with various challenges that relate to the\nsecurity, safety, and interpretability of AI algorithms that will form the\ntechnological bedrock of future cities. Several research institutes on human\ncentered AI have been established at top international universities. Globally\nthere are calls for technology to be made more humane and human-compatible. For\nexample, Stuart Russell has a book called Human Compatible AI. The Center for\nHumane Technology advocates for regulators and technology companies to avoid\nbusiness models and product features that contribute to social problems such as\nextremism, polarization, misinformation, and Internet addiction. In this paper,\nwe analyze and explore key challenges including security, robustness,\ninterpretability, and ethical challenges to a successful deployment of AI or ML\nin human-centric applications, with a particular emphasis on the convergence of\nthese challenges. We provide a detailed review of existing literature on these\nkey challenges and analyze how one of these challenges may lead to others or\nhelp in solving other challenges. The paper also advises on the current\nlimitations, pitfalls, and future directions of research in these domains, and\nhow it can fill the current gaps and lead to better solutions.", "doi": "", "date": "2020-12-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.09110v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2566323483, "title": "Mining Trends of COVID-19 Vaccine Beliefs on Twitter with Lexical\n  Embeddings", "abstract": "Social media plays a pivotal role in disseminating news globally and acts as\na platform for people to express their opinions on various topics. A wide\nvariety of views accompanies COVID-19 vaccination drives across the globe,\noften colored by emotions, which change along with rising cases, approval of\nvaccines, and multiple factors discussed online. This study aims at analyzing\nthe temporal evolution of different Emotion categories: Hesitation, Rage,\nSorrow, Anticipation, Faith, and Contentment with Influencing Factors: Vaccine\nRollout, Misinformation, Health Effects, and Inequities as lexical categories\ncreated from Tweets belonging to five countries with vital vaccine roll-out\nprograms, namely, India, United States of America, Brazil, United Kingdom, and\nAustralia. We extracted a corpus of nearly 1.8 million Twitter posts related to\nCOVID-19 vaccination. Using cosine distance from selected seed words, we\nexpanded the vocabulary of each category and tracked the longitudinal change in\ntheir strength from June 2020 to April 2021. We used community detection\nalgorithms to find modules in positive correlation networks. Our findings\nsuggest that tweets expressing hesitancy towards vaccines contain the highest\nmentions of health-related effects in all countries. Our results indicated that\nthe patterns of hesitancy were variable across geographies and can help us\nlearn targeted interventions. We also observed a significant change in the\nlinear trends of categories like hesitation and contentment before and after\napproval of vaccines. Negative emotions like rage and sorrow gained the highest\nimportance in the alluvial diagram. They formed a significant module with all\nthe influencing factors in April 2021, when India observed the second wave of\nCOVID-19 cases. The relationship between Emotions and Influencing Factors was\nfound to be variable across the countries.", "doi": "", "date": "2021-04-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.01131v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1206782519, "title": "The State of AI Ethics Report (January 2021)", "abstract": "The 3rd edition of the Montreal AI Ethics Institute's The State of AI Ethics\ncaptures the most relevant developments in AI Ethics since October 2020. It\naims to help anyone, from machine learning experts to human rights activists\nand policymakers, quickly digest and understand the field's ever-changing\ndevelopments. Through research and article summaries, as well as expert\ncommentary, this report distills the research and reporting surrounding various\ndomains related to the ethics of AI, including: algorithmic injustice,\ndiscrimination, ethical AI, labor impacts, misinformation, privacy, risk and\nsecurity, social media, and more.\n  In addition, The State of AI Ethics includes exclusive content written by\nworld-class AI Ethics experts from universities, research institutes,\nconsulting firms, and governments. Unique to this report is \"The Abuse and\nMisogynoir Playbook,\" written by Dr. Katlyn Tuner (Research Scientist, Space\nEnabled Research Group, MIT), Dr. Danielle Wood (Assistant Professor, Program\nin Media Arts and Sciences; Assistant Professor, Aeronautics and Astronautics;\nLead, Space Enabled Research Group, MIT) and Dr. Catherine D'Ignazio (Assistant\nProfessor, Urban Science and Planning; Director, Data + Feminism Lab, MIT). The\npiece (and accompanying infographic), is a deep-dive into the historical and\nsystematic silencing, erasure, and revision of Black women's contributions to\nknowledge and scholarship in the United Stations, and globally. Exposing and\ncountering this Playbook has become increasingly important following the firing\nof AI Ethics expert Dr. Timnit Gebru (and several of her supporters) at Google.\n  This report should be used not only as a point of reference and insight on\nthe latest thinking in the field of AI Ethics, but should also be used as a\ntool for introspection as we aim to foster a more nuanced conversation\nregarding the impacts of AI on the world.", "doi": "", "date": "2021-05-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.09059v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3244559317, "title": "Exploring the effect of social media and spatial characteristics during\n  the COVID-19 pandemic in China", "abstract": "The declaration of COVID-19 as a pandemic has largely amplified the spread of\nrelated information on social media, such as Twitter, Facebook, and\nWeChat.Unlike the previous studies which focused on how to detect the\nmisinformation or fake news related toCOVID-19, we investigate how the disease\nand information co-evolve in the population. We focus onCOVID-19and its\ninformation during the period when the disease was widely spread in China,\ni.e., from January 25th to March 24th, 2020. We first explore how the disease\nand information co-evolve via the spatial analysis of the two spreading\nprocesses. We visualize the geo-location of both disease and information at the\nprovince level and find that disease is more geo-localized compared to\ninformation. We find a high correlation between the disease and information\ndata, and also people care about the spread only when it comes to their\nneighborhood. Regard to the content of the information, we find that positive\nmessages are more negatively correlated with the disease compared to negative\nand neutral messages. Additionally, we introduce machine learning algorithms,\ni.e., linear regression and random forest, to further predict the number of\ninfected using different disease spatial related and information-related\ncharacteristics. We obtain that the disease spatial related characteristics of\nnearby cities can help to improve the prediction accuracy. Meanwhile,\ninformation-related characteristics can also help to improve the prediction\nperformance, but with a delay, i.e., the improvement comes from using, for\ninstance, the number of messages 10 days ago, for disease prediction. The\nmethodology proposed in this paper may shed light on new clues of emerging\ninfections", "doi": "", "date": "2021-07-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.03766v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2860190285, "title": "Brexit and bots: characterizing the behaviour of automated accounts on\n  Twitter during the UK election", "abstract": "Online Social Networks represent a novel opportunity for political campaigns,\nrevolutionising the paradigm of political communication. Nevertheless, many\nstudies uncovered the presence of d/misinformation campaigns or of malicious\nactivities by genuine or automated users, putting at severe risk the\ncredibility of online platforms. This phenomenon is particularly evident during\ncrucial political events, as political elections. In the present paper, we\nprovide a comprehensive description of the structure of the networks of\ninteractions among users and bots during the UK elections of 2019. In\nparticular, we focus on the polarised discussion about Brexit on Twitter\nanalysing a data set made of more than 10 million tweets posted for over a\nmonth. We found that the presence of automated accounts fostered the debate\nparticularly in the days before the UK national elections, in which we find a\nsteep increase of bots in the discussion; in the days after the election day,\ntheir incidence returned to values similar to the ones observed few weeks\nbefore the elections. On the other hand, we found that the number of suspended\nusers (i.e. accounts that were removed by the platform for some violation of\nthe Twitter policy) remained constant until the election day, after which it\nreached significantly higher values. Remarkably, after the TV debate between\nBoris Johnson and Jeremy Corbyn, we observed the injection of a large number of\nnovel bots whose behaviour is markedly different from that of pre-existing\nones. Finally, we explored the bots' stance, finding that their activity is\nspread across the whole political spectrum, although in different proportions,\nand we studied the different usage of hashtags by automated accounts and\nsuspended users, thus targeting the formation of common narratives in different\nsides of the debate.", "doi": "", "date": "2021-07-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.14155v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 862149568, "title": "Fighting disaster misinformation in Latin America - the #19S Mexican earthquake case study.", "abstract": "", "doi": "10.1007/s00779-020-01411-5", "date": "2021", "authors": [{"name": "Claudia Flores-Saviaga", "id-internal": "170/4752", "id-external": ""}, {"name": "Saiph Savage", "id-internal": "37/8857", "id-external": ""}], "url": {"full": "URL#79452", "pdf": ""}, "publisher-venue": "Pers. Ubiquitous Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 217016061, "title": "Auditing E-Commerce Platforms for Algorithmically Curated Vaccine Misinformation.", "abstract": "", "doi": "10.1145/3411764.3445250", "date": "2021", "authors": [{"name": "Prerna Juneja", "id-internal": "172/1209", "id-external": ""}, {"name": "Tanushree Mitra", "id-internal": "38/11520", "id-external": ""}], "url": {"full": "URL#135415", "pdf": ""}, "publisher-venue": "CHI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2167843933, "title": "Combating Misinformation in Bangladesh - Roles and Responsibilities as Perceived by Journalists, Fact-checkers, and Users.", "abstract": "", "doi": "10.1145/3415201", "date": "2020", "authors": [{"name": "Md Mahfuzul Haque", "id-internal": "230/3595", "id-external": ""}, {"name": "Mohammad Yousuf", "id-internal": "198/1367", "id-external": ""}, {"name": "Ahmed Shatil Alam", "id-internal": "230/3449", "id-external": ""}, {"name": "Pratyasha Saha", "id-internal": "229/1485", "id-external": ""}, {"name": "Syed Ishtiaque Ahmed", "id-internal": "75/7215", "id-external": ""}, {"name": "Naeemul Hassan", "id-internal": "66/9718", "id-external": ""}], "url": {"full": "URL#359443", "pdf": ""}, "publisher-venue": "Proc. ACM Hum. Comput. Interact.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4108556790, "title": "The Rumour Mill - Making the Spread of Misinformation Explicit and Tangible.", "abstract": "", "doi": "10.1145/3334480.3383159", "date": "2020", "authors": [{"name": "Nanna Inie", "id-internal": "199/2723", "id-external": ""}, {"name": "Jeanette Falk Olesen", "id-internal": "208/8767", "id-external": ""}, {"name": "Leon Derczynski", "id-internal": "66/8157", "id-external": ""}], "url": {"full": "URL#442850", "pdf": ""}, "publisher-venue": "CHI Extended Abstracts", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2153488178, "title": "The COVID-19 Infodemic - Can the Crowd Judge Recent Misinformation Objectively?", "abstract": "", "doi": "10.1145/3340531.3412048", "date": "2020", "authors": [{"name": "Kevin Roitero", "id-internal": "184/4597", "id-external": ""}, {"name": "Michael Soprano", "id-internal": "222/1241", "id-external": ""}, {"name": "Beatrice Portelli", "id-internal": "272/5540", "id-external": ""}, {"name": "Damiano Spina", "id-internal": "74/2824", "id-external": ""}, {"name": "Vincenzo Della Mea", "id-internal": "m/VincenzoDellaMea", "id-external": ""}, {"name": "Giuseppe Serra 0001", "id-internal": "12/1985-1", "id-external": ""}, {"name": "Stefano Mizzaro", "id-internal": "74/4701", "id-external": ""}, {"name": "Gianluca Demartini", "id-internal": "05/3422", "id-external": ""}], "url": {"full": "URL#444932", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1576539711, "title": "#ArsonEmergency and Australia's \"Black Summer\" - Polarisation and Misinformation on Social Media.", "abstract": "", "doi": "10.1007/978-3-030-61841-4_11", "date": "2020", "authors": [{"name": "Derek Weber", "id-internal": "82/481", "id-external": ""}, {"name": "Mehwish Nasim", "id-internal": "91/8376", "id-external": ""}, {"name": "Lucia Falzon", "id-internal": "46/3934", "id-external": ""}, {"name": "Lewis Mitchell", "id-internal": "126/5006", "id-external": ""}], "url": {"full": "URL#540791", "pdf": ""}, "publisher-venue": "MISDOOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2564276600, "title": "Can The Crowd Identify Misinformation Objectively? - The Effects of Judgment Scale and Assessor's Background.", "abstract": "", "doi": "10.1145/3397271.3401112", "date": "2020", "authors": [{"name": "Kevin Roitero", "id-internal": "184/4597", "id-external": ""}, {"name": "Michael Soprano", "id-internal": "222/1241", "id-external": ""}, {"name": "Shaoyang Fan", "id-internal": "265/5912", "id-external": ""}, {"name": "Damiano Spina", "id-internal": "74/2824", "id-external": ""}, {"name": "Stefano Mizzaro", "id-internal": "74/4701", "id-external": ""}, {"name": "Gianluca Demartini", "id-internal": "05/3422", "id-external": ""}], "url": {"full": "URL#560127", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1754771899, "title": "Impact of misinformation in temporal network epidemiology.", "abstract": "", "doi": "10.1017/nws.2018.28", "date": "2019", "authors": [{"name": "Petter Holme", "id-internal": "10/4899", "id-external": ""}, {"name": "Luis E. C. Rocha", "id-internal": "72/7115", "id-external": ""}], "url": {"full": "URL#765103", "pdf": ""}, "publisher-venue": "Netw. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4149303388, "title": "Hoaxy - A Platform for Tracking Online Misinformation.", "abstract": "", "doi": "10.1145/2872518.2890098", "date": "2016", "authors": [{"name": "Chengcheng Shao", "id-internal": "150/7597", "id-external": ""}, {"name": "Giovanni Luca Ciampaglia", "id-internal": "07/8400", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}], "url": {"full": "URL#2032204", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}][{"id": 4166264849, "title": "Rating the disinformation risks of news domains - Global Disinformation Index.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Santhosh Srinivasan", "id-internal": "66/7258", "id-external": ""}, {"name": "Craig Fagan", "id-internal": "277/6054", "id-external": ""}], "url": {"full": "URL#985256", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1937564131, "title": "Mis- and disinformation in a bounded confidence model.", "abstract": "", "doi": "10.1016/j.artint.2020.103415", "date": "2021", "authors": [{"name": "Igor Douven", "id-internal": "90/4384", "id-external": ""}, {"name": "Rainer Hegselmann", "id-internal": "72/2867", "id-external": ""}], "url": {"full": "URL#11428", "pdf": ""}, "publisher-venue": "Artif. Intell.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4019329541, "title": "Effects of Disinformation Using Deepfake - The Protective Effect of Media Literacy Education.", "abstract": "", "doi": "10.1089/cyber.2020.0174", "date": "2021", "authors": [{"name": "Yoori Hwang", "id-internal": "155/9714", "id-external": ""}, {"name": "Ji Youn Ryu", "id-internal": "290/6718", "id-external": ""}, {"name": "Se Hoon Jeong", "id-internal": "22/9162", "id-external": ""}], "url": {"full": "URL#19909", "pdf": ""}, "publisher-venue": "Cyberpsychology Behav. Soc. Netw.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3295449534, "title": "Analyzing the role of media orchestration in conducting disinformation campaigns on blogs.", "abstract": "", "doi": "10.1007/s10588-018-09288-9", "date": "2021", "authors": [{"name": "Kiran Kumar Bandeli", "id-internal": "216/7307", "id-external": ""}, {"name": "Nitin Agarwal", "id-internal": "72/1395", "id-external": ""}], "url": {"full": "URL#23528", "pdf": ""}, "publisher-venue": "Comput. Math. Organ. Theory", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3006872399, "title": "Disinformation - analysis and identification.", "abstract": "", "doi": "10.1007/s10588-021-09336-x", "date": "2021", "authors": [{"name": "Archita Pathak", "id-internal": "245/8637", "id-external": ""}, {"name": "Rohini K. Srihari", "id-internal": "59/6877", "id-external": ""}, {"name": "Nihit Natu", "id-internal": "300/8159", "id-external": ""}], "url": {"full": "URL#23539", "pdf": ""}, "publisher-venue": "Comput. Math. Organ. Theory", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3793201585, "title": "Data and Disinformation.", "abstract": "", "doi": "10.1109/mc.2021.3074261", "date": "2021", "authors": [{"name": "Norita B. Ahmad", "id-internal": "206/9048", "id-external": ""}, {"name": "Nash Milic", "id-internal": "160/5088", "id-external": ""}, {"name": "Mohammed Ibahrine", "id-internal": "92/5000", "id-external": ""}], "url": {"full": "URL#26811", "pdf": ""}, "publisher-venue": "Computer", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1889372553, "title": "Coronavirus as a Rhizome - The Pandemic of Disinformation.", "abstract": "", "doi": "10.4018/ijcwt.2021040104", "date": "2021", "authors": [{"name": "Teija Sederholm", "id-internal": "177/6384", "id-external": ""}, {"name": "Petri J\u00e4\u00e4skel\u00e4inen", "id-internal": "294/0653", "id-external": ""}, {"name": "Aki-Mauri Huhtinen", "id-internal": "20/3745", "id-external": ""}], "url": {"full": "URL#44345", "pdf": ""}, "publisher-venue": "Int. J. Cyber Warf. Terror.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1918606361, "title": "Raising the Flag - Monitoring User Perceived Disinformation on Reddit.", "abstract": "", "doi": "10.3390/info12010004", "date": "2021", "authors": [{"name": "Vlad Achimescu", "id-internal": "284/0321", "id-external": ""}, {"name": "Pavel Dimitrov Chachev", "id-internal": "284/0231", "id-external": ""}], "url": {"full": "URL#50671", "pdf": ""}, "publisher-venue": "Inf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3501225772, "title": "A Data-Driven Framework for Coding the Intent and Extent of Political Tweeting, Disinformation, and Extremism.", "abstract": "", "doi": "10.3390/info12040148", "date": "2021", "authors": {"name": "Mahdi Hashemi 0001", "id-internal": "53/10591", "id-external": ""}, "url": {"full": "URL#50749", "pdf": ""}, "publisher-venue": "Inf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 214442514, "title": "A systematic literature review on disinformation - Toward a unified taxonomical framework.", "abstract": "", "doi": "10.1177/1461444820959296", "date": "2021", "authors": [{"name": "Eleni Kapantai", "id-internal": "291/6923", "id-external": ""}, {"name": "Androniki Christopoulou", "id-internal": "291/6408", "id-external": ""}, {"name": "Christos Berberidis", "id-internal": "13/132", "id-external": ""}, {"name": "Vassilios Peristeras", "id-internal": "24/1347", "id-external": ""}], "url": {"full": "URL#75741", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 948343668, "title": "The disconcerting potential of online disinformation - Persuasive effects of astroturfing comments and three strategies for inoculation against them.", "abstract": "", "doi": "10.1177/1461444820908530", "date": "2021", "authors": [{"name": "Thomas Zerback", "id-internal": "206/3594", "id-external": ""}, {"name": "Florian T\u00f6pfl", "id-internal": "291/6719", "id-external": ""}, {"name": "Maria Kn\u00f6pfle", "id-internal": "291/6820", "id-external": ""}], "url": {"full": "URL#75802", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3897352287, "title": "Special Issue on Disinformation, Hoaxes and Propaganda within Online Social Networks and Media.", "abstract": "", "doi": "10.1016/j.osnem.2021.100132", "date": "2021", "authors": [{"name": "Yelena Mejova", "id-internal": "29/758", "id-external": ""}, {"name": "Marinella Petrocchi", "id-internal": "30/3349", "id-external": ""}, {"name": "Carolina Scarton", "id-internal": "23/8672", "id-external": ""}], "url": {"full": "URL#76846", "pdf": ""}, "publisher-venue": "Online Soc. Networks Media", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4101387882, "title": "Windmills of the Mind - Higher-Order Forms of Disinformation in International Politics.", "abstract": "", "doi": "10.23919/cycon51939.2021.9468292", "date": "2021", "authors": {"name": "James Shires", "id-internal": "288/3813", "id-external": ""}, "url": {"full": "URL#142462", "pdf": ""}, "publisher-venue": "CyCon", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 958685942, "title": "Multilingual Evidence Retrieval and Fact Verification to Combat Global Disinformation - The Power of Polyglotism.", "abstract": "", "doi": "10.1007/978-3-030-72240-1_36", "date": "2021", "authors": {"name": "Denisa A. O. Roberts", "id-internal": "274/6959", "id-external": ""}, "url": {"full": "URL#144633", "pdf": ""}, "publisher-venue": "ECIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2814642269, "title": "Data Challenges in Disinformation Diffusion Analysis.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Paolo Papotti", "id-internal": "p/PaoloPapotti", "id-external": ""}, "url": {"full": "URL#145066", "pdf": ""}, "publisher-venue": "EDBT/ICDT Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2226120064, "title": "Generational Perspectives on EU Documents Tackling Disinformation.", "abstract": "", "doi": "10.1007/978-3-030-78108-8_26", "date": "2021", "authors": [{"name": "Maria Jos\u00e9 Brites", "id-internal": "269/7484", "id-external": ""}, {"name": "In\u00eas Amaral", "id-internal": "182/6304", "id-external": ""}, {"name": "Rita Bas\u00edlio Sim\u00f5es", "id-internal": "297/1195", "id-external": ""}, {"name": "Sofia Jos\u00e9 Santos", "id-internal": "244/9951", "id-external": ""}], "url": {"full": "URL#148732", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1078400366, "title": "The Impact of Online Disinformation on Democracy in Taiwan.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Julian Neylan", "id-internal": "288/6336", "id-external": ""}, "url": {"full": "URL#150674", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3097165695, "title": "Fake or Real? The Novel Approach to Detecting Online Disinformation Based on Multi ML Classifiers.", "abstract": "", "doi": "10.1007/978-3-030-77970-2_2", "date": "2021", "authors": [{"name": "Martyna Tarczewska", "id-internal": "294/7231", "id-external": ""}, {"name": "Anna Marciniak", "id-internal": "291/0388", "id-external": ""}, {"name": "Agata Gielczyk", "id-internal": "226/5062", "id-external": ""}], "url": {"full": "URL#156309", "pdf": ""}, "publisher-venue": "ICCS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3304100350, "title": "An Exploratory Analysis on a Disinformation Dataset.", "abstract": "", "doi": "10.1007/978-3-030-85672-4_11", "date": "2021", "authors": [{"name": "Matheus Marinho", "id-internal": "232/6658", "id-external": ""}, {"name": "Carmelo J. A. Bastos Filho", "id-internal": "72/164", "id-external": ""}, {"name": "Anthony Lins", "id-internal": "117/2937", "id-external": ""}], "url": {"full": "URL#175764", "pdf": ""}, "publisher-venue": "OLA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1969807416, "title": "Simulating Social-Cyber Maneuvers to Deter Disinformation Campaigns.", "abstract": "", "doi": "10.1007/978-3-030-80387-2_15", "date": "2021", "authors": [{"name": "Janice T. Blane", "id-internal": "296/6933", "id-external": ""}, {"name": "J. D. Moffitt", "id-internal": "296/6992", "id-external": ""}, {"name": "Kathleen M. Carley", "id-internal": "72/6492", "id-external": ""}], "url": {"full": "URL#178511", "pdf": ""}, "publisher-venue": "SBP-BRiMS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 21188095, "title": "Interactions with Potential Mis/Disinformation URLs Among U.S. Users on Facebook, 2017-2019.", "abstract": "", "doi": "10.1145/3473604.3474561", "date": "2021", "authors": [{"name": "Aydan Bailey", "id-internal": "300/2339", "id-external": ""}, {"name": "Theo Gregersen", "id-internal": "300/2633", "id-external": ""}, {"name": "Franziska Roesner", "id-internal": "23/2758", "id-external": ""}], "url": {"full": "URL#179449", "pdf": ""}, "publisher-venue": "FOCI@SIGCOMM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1375441815, "title": "A Survey on Stance Detection for Mis- and Disinformation Identification.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Momchil Hardalov", "id-internal": "167/4829", "id-external": ""}, {"name": "Arnav Arora", "id-internal": "274/2742", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}], "url": {"full": "URL#200767", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3288412179, "title": "A Survey on Multimodal Disinformation Detection.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Firoj Alam", "id-internal": "126/2083", "id-external": ""}, {"name": "Stefano Cresci", "id-internal": "150/6331", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}, {"name": "Fabrizio Silvestri", "id-internal": "s/FabrizioSilvestri", "id-external": ""}, {"name": "Dimiter Dimitrov", "id-internal": "289/0075", "id-external": ""}, {"name": "Giovanni Da San Martino", "id-internal": "25/3236", "id-external": ""}, {"name": "Shaden Shaar", "id-internal": "234/1620", "id-external": ""}, {"name": "Hamed Firooz", "id-internal": "248/8104", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}], "url": {"full": "URL#206052", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1808633111, "title": "Strategically-Motivated Advanced Persistent Threat - Definition, Process, Tactics and a Disinformation Model of Counterattack.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Atif Ahmad", "id-internal": "09/6570", "id-external": ""}, {"name": "Jeb Webb", "id-internal": "147/4482", "id-external": ""}, {"name": "Kevin C. Desouza", "id-internal": "89/2133", "id-external": ""}, {"name": "James Boorman", "id-internal": "250/3212", "id-external": ""}], "url": {"full": "URL#207127", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2130565786, "title": "Helping People Deal With Disinformation - A Socio-Technical Perspective.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Hendrik Heuer", "id-internal": "117/6741", "id-external": ""}, "url": {"full": "URL#210030", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4051831914, "title": "Tactical Reframing of Online Disinformation Campaigns Against The Istanbul Convention.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Tugrulcan Elmas", "id-internal": "251/2973", "id-external": ""}, {"name": "Rebekah Overdorf", "id-internal": "62/10989", "id-external": ""}, {"name": "Karl Aberer", "id-internal": "a/KarlAberer", "id-external": ""}], "url": {"full": "URL#220431", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1556943881, "title": "Assessing disinformation through the dynamics of supply and demand in the news ecosystem.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Pietro Gravino", "id-internal": "65/11449", "id-external": ""}, {"name": "Giulio Prevedello", "id-internal": "293/9637", "id-external": ""}, {"name": "Martina Galletti", "id-internal": "293/9479", "id-external": ""}, {"name": "Vittorio Loreto", "id-internal": "09/3744", "id-external": ""}], "url": {"full": "URL#221298", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 682646324, "title": "Disinformation, Stochastic Harm, and Costly Filtering - A Principal-Agent Analysis of Regulating Social Media Platforms.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Shehroze Khan", "id-internal": "224/5997", "id-external": ""}, {"name": "James R. Wright", "id-internal": "35/8399", "id-external": ""}], "url": {"full": "URL#226019", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 433074412, "title": "A Comparative Study of Online Disinformation and Offline Protests.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Jukka Ruohonen", "id-internal": "166/5041", "id-external": ""}, "url": {"full": "URL#226559", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 949848738, "title": "The Impact of Disinformation on a Controversial Debate on Social Media.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Salvatore Vilella", "id-internal": "244/2480", "id-external": ""}, {"name": "Alfonso Semeraro", "id-internal": "276/9707", "id-external": ""}, {"name": "Daniela Paolotti", "id-internal": "167/3215", "id-external": ""}, {"name": "Giancarlo Ruffo", "id-internal": "05/4635", "id-external": ""}], "url": {"full": "URL#228721", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3562400454, "title": "Characterizing Online Engagement with Disinformation and Conspiracies in the 2020 U.S. Presidential Election.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Karishma Sharma", "id-internal": "222/7902", "id-external": ""}, {"name": "Emilio Ferrara", "id-internal": "38/8773", "id-external": ""}, {"name": "Yan Liu 0002", "id-internal": "l/YanLiu2", "id-external": ""}], "url": {"full": "URL#232377", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 494807878, "title": "Deriving Disinformation Insights from Geolocalized Twitter Callouts.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "David Tuxworth", "id-internal": "299/1633", "id-external": ""}, {"name": "Dimosthenis Antypas", "id-internal": "299/1573", "id-external": ""}, {"name": "Luis Espinosa Anke", "id-internal": "140/3490", "id-external": ""}, {"name": "Jos\u00e9 Camacho-Collados", "id-internal": "165/0790", "id-external": ""}, {"name": "Alun D. Preece", "id-internal": "p/AlunDPreece", "id-external": ""}, {"name": "David Rogers", "id-internal": "24/6521", "id-external": ""}], "url": {"full": "URL#236180", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 870509886, "title": "Exploring the Links between Personality Traits and Suscep;bility to Disinformation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Dipto Barman", "id-internal": "234/1883", "id-external": ""}, {"name": "Owen Conlan", "id-internal": "70/1905", "id-external": ""}], "url": {"full": "URL#237076", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 499634193, "title": "Technological Approaches to Detecting Online Disinformation and Manipulation.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Ales Hor\u00e1k", "id-internal": "90/1370", "id-external": ""}, {"name": "V\u00edt Baisa", "id-internal": "43/8420", "id-external": ""}, {"name": "Ondrej Herman", "id-internal": "212/5997", "id-external": ""}], "url": {"full": "URL#239753", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 385084509, "title": "Quantitative Characterization and Identification of the Company-Related Disinformation Channel Among Media.", "abstract": "", "doi": "10.1109/access.2020.2971727", "date": "2020", "authors": [{"name": "Yong-tian Yu", "id-internal": "256/2233", "id-external": ""}, {"name": "Guang Yu", "id-internal": "97/6934", "id-external": ""}, {"name": "Tong Li", "id-internal": "29/3826", "id-external": ""}, {"name": "Qingli Man", "id-internal": "259/0154", "id-external": ""}, {"name": "Qiuping Chen", "id-internal": "157/2446", "id-external": ""}], "url": {"full": "URL#261098", "pdf": ""}, "publisher-venue": "IEEE Access", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2740291879, "title": "Digital Disinformation About COVID-19 and the Third-Person Effect - Examining the Channel Differences and Negative Emotional Outcomes.", "abstract": "", "doi": "10.1089/cyber.2020.0363", "date": "2020", "authors": [{"name": "Piper Liping Liu", "id-internal": "199/9106", "id-external": ""}, {"name": "Lei Vincent Huang", "id-internal": "199/9190", "id-external": ""}], "url": {"full": "URL#276065", "pdf": ""}, "publisher-venue": "Cyberpsychology Behav. Soc. Netw.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1725118720, "title": "Platform values and democratic elections - How can the law regulate digital disinformation?", "abstract": "", "doi": "10.1016/j.clsr.2019.105373", "date": "2020", "authors": [{"name": "Christopher T. Marsden", "id-internal": "131/8239", "id-external": ""}, {"name": "Trisha Meyer", "id-internal": "273/5824", "id-external": ""}, {"name": "Ian Brown", "id-internal": "68/1515", "id-external": ""}], "url": {"full": "URL#280126", "pdf": ""}, "publisher-venue": "Comput. Law Secur. Rev.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3944433519, "title": "A multi-layer approach to disinformation detection in US and Italian news spreading on Twitter.", "abstract": "", "doi": "10.1140/epjds/s13688-020-00253-8", "date": "2020", "authors": [{"name": "Francesco Pierri 0002", "id-internal": "80/8064-2", "id-external": ""}, {"name": "Carlo Piccardi", "id-internal": "20/3994", "id-external": ""}, {"name": "Stefano Ceri", "id-internal": "c/StefanoCeri", "id-external": ""}], "url": {"full": "URL#297308", "pdf": ""}, "publisher-venue": "EPJ Data Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3728295402, "title": "The Social Media, Politics of Disinformation in Established Hegemonies, and the Role of Technological Innovations in 21st Century Elections - The Road Map to US 2020 Presidential Elections.", "abstract": "", "doi": "10.4018/ijegr.2020070104", "date": "2020", "authors": [{"name": "Ikedinachi Ayodele Power Wogu", "id-internal": "222/5258", "id-external": ""}, {"name": "Sharon Nanyongo N. Njie", "id-internal": "264/2894", "id-external": ""}, {"name": "Jesse Oluwafemi Katende", "id-internal": "282/2731", "id-external": ""}, {"name": "George Uzoma Ukagba", "id-internal": "282/2760", "id-external": ""}, {"name": "Morris Oziegbe Edogiawerie", "id-internal": "282/2393", "id-external": ""}, {"name": "Sanjay Misra", "id-internal": "86/20", "id-external": ""}], "url": {"full": "URL#312442", "pdf": ""}, "publisher-venue": "Int. J. Electron. Gov. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3272654410, "title": "Deep strategic mediatization - Organizational leaders' knowledge and usage of social bots in an era of disinformation.", "abstract": "", "doi": "10.1016/j.ijinfomgt.2019.102042", "date": "2020", "authors": [{"name": "M. Wiesenberg", "id-internal": "260/7787", "id-external": ""}, {"name": "Ralph Tench", "id-internal": "260/7873", "id-external": ""}], "url": {"full": "URL#315621", "pdf": ""}, "publisher-venue": "Int. J. Inf. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4267275296, "title": "Characterizing Disinformation Risk to Open Data in the Post-Truth Era.", "abstract": "", "doi": "10.1145/3328747", "date": "2020", "authors": [{"name": "Adrienne Colborne", "id-internal": "213/1041", "id-external": ""}, {"name": "Michael Smit", "id-internal": "19/86", "id-external": ""}], "url": {"full": "URL#334946", "pdf": ""}, "publisher-venue": "ACM J. Data Inf. Qual.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2675294231, "title": "The impact of personality in recognizing disinformation.", "abstract": "", "doi": "10.1108/oir-04-2019-0115", "date": "2020", "authors": [{"name": "Colleen Wolverton", "id-internal": "257/8727", "id-external": ""}, {"name": "David Stevens", "id-internal": "51/6836", "id-external": ""}], "url": {"full": "URL#358359", "pdf": ""}, "publisher-venue": "Online Inf. Rev.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 756799302, "title": "Defending a series system with individual protection, overarching protection, and disinformation.", "abstract": "", "doi": "10.1016/j.ress.2020.107131", "date": "2020", "authors": [{"name": "Chen Lin", "id-internal": "37/3102", "id-external": ""}, {"name": "Hui Xiao", "id-internal": "85/4207", "id-external": ""}, {"name": "Gang Kou", "id-internal": "84/5885", "id-external": ""}, {"name": "Rui Peng 0001", "id-internal": "41/6543-1", "id-external": ""}], "url": {"full": "URL#370532", "pdf": ""}, "publisher-venue": "Reliab. Eng. Syst. Saf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2878672444, "title": "Defending a parallel system against a strategic attacker with redundancy, protection and disinformation.", "abstract": "", "doi": "10.1016/j.ress.2019.106651", "date": "2020", "authors": [{"name": "Rui Peng 0001", "id-internal": "41/6543-1", "id-external": ""}, {"name": "Hui Xiao", "id-internal": "85/4207", "id-external": ""}, {"name": "Jianjun Guo", "id-internal": "63/5989", "id-external": ""}, {"name": "Chen Lin", "id-internal": "37/3102", "id-external": ""}], "url": {"full": "URL#370597", "pdf": ""}, "publisher-venue": "Reliab. Eng. Syst. Saf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1876432953, "title": "Combating disinformation in a social media age.", "abstract": "", "doi": "10.1002/widm.1385", "date": "2020", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Amrita Bhattacharjee", "id-internal": "251/2495", "id-external": ""}, {"name": "Faisal Alatawi", "id-internal": "270/1587", "id-external": ""}, {"name": "Tahora H. Nazer", "id-internal": "190/5215", "id-external": ""}, {"name": "Kaize Ding", "id-internal": "234/6878", "id-external": ""}, {"name": "Mansooreh Karami", "id-internal": "243/0884", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#416919", "pdf": ""}, "publisher-venue": "Wiley Interdiscip. Rev. Data Min. Knowl. Discov.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3917431623, "title": "Disinformation Detection using Passive Aggressive Algorithms.", "abstract": "", "doi": "10.1145/3374135.3385324", "date": "2020", "authors": [{"name": "Songqiao Yu", "id-internal": "266/2794", "id-external": ""}, {"name": "Dan Lo 0001", "id-internal": "65/6293", "id-external": ""}], "url": {"full": "URL#419188", "pdf": ""}, "publisher-venue": "ACM Southeast Regional Conference", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 612100256, "title": "Disinformation in Social Media - Role of Dark Triad Personality Traits and Self Regulation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Sarbottam Bhagat", "id-internal": "228/2183", "id-external": ""}, {"name": "Dan J. Kim 0001", "id-internal": "99/3852", "id-external": ""}, {"name": "James L. Parrish", "id-internal": "200/1569", "id-external": ""}], "url": {"full": "URL#429478", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3888021033, "title": "Modeling Disinformation and the Effort to Counter It - A Cautionary Tale of When the Treatment Can Be Worse Than the Disease.", "abstract": "", "doi": "10.5555/3398761.3399046", "date": "2020", "authors": [{"name": "Amirarsalan Rajabi", "id-internal": "262/3725", "id-external": ""}, {"name": "Chathika Gunaratne", "id-internal": "140/0892", "id-external": ""}, {"name": "Alexander V. Mantzaris", "id-internal": "48/7269", "id-external": ""}, {"name": "Ivan Garibay", "id-internal": "27/6705", "id-external": ""}], "url": {"full": "URL#432998", "pdf": ""}, "publisher-venue": "AAMAS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 645020008, "title": "Toward A Multilingual and Multimodal Data Repository for COVID-19 Disinformation.", "abstract": "", "doi": "10.1109/bigdata50022.2020.9378472", "date": "2020", "authors": [{"name": "Yichuan Li", "id-internal": "216/7478", "id-external": ""}, {"name": "Bohan Jiang", "id-internal": "240/6257", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#435631", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2016650384, "title": "On the Detection of Disinformation Campaign Activity with Network Analysis.", "abstract": "", "doi": "10.1145/3411495.3421363", "date": "2020", "authors": [{"name": "Luis Vargas", "id-internal": "68/5101", "id-external": ""}, {"name": "Patrick Emami", "id-internal": "153/7716", "id-external": ""}, {"name": "Patrick Traynor", "id-internal": "14/3295", "id-external": ""}], "url": {"full": "URL#440572", "pdf": ""}, "publisher-venue": "CCSW@CCS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2935847361, "title": "Profiling Spreaders of Disinformation on Twitter - IKMLab and Softbank Submission.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Timothy Niven", "id-internal": "218/6540", "id-external": ""}, {"name": "Hung-Yu Kao", "id-internal": "64/5833", "id-external": ""}, {"name": "Hsin-Yang Wang", "id-internal": "196/3775", "id-external": ""}], "url": {"full": "URL#446216", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3201254940, "title": "Car\u00eancia de Mulheres na Computa\u00e7\u00e3o - Um Estudo sobre a Rela\u00e7\u00e3o entre Incentivo x Desinforma\u00e7\u00e3o (Lack of Women in Computing - A Study on the Relationship between Incentive x Disinformation).", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Samira Santos Da Silva", "id-internal": "152/8623", "id-external": ""}, {"name": "Sincler Peixoto de Meireles", "id-internal": "277/2576", "id-external": ""}], "url": {"full": "URL#446371", "pdf": ""}, "publisher-venue": "LAWCC@CLEI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 703394080, "title": "A Consideration of the Case Study of Disinformation and Its Legal Problems.", "abstract": "", "doi": "10.1007/978-3-030-62803-1_21", "date": "2020", "authors": {"name": "Tomoko Nagasako", "id-internal": "278/4972", "id-external": ""}, "url": {"full": "URL#476999", "pdf": ""}, "publisher-venue": "HCC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3057927493, "title": "Characterizing Social Bots Spreading Financial Disinformation.", "abstract": "", "doi": "10.1007/978-3-030-49570-1_26", "date": "2020", "authors": [{"name": "Serena Tardelli", "id-internal": "218/5964", "id-external": ""}, {"name": "Marco Avvenuti", "id-internal": "86/3252", "id-external": ""}, {"name": "Maurizio Tesconi", "id-internal": "53/3857", "id-external": ""}, {"name": "Stefano Cresci", "id-internal": "150/6331", "id-external": ""}], "url": {"full": "URL#478807", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2711959639, "title": "An Exploration of Disinformation as a Cybersecurity Threat.", "abstract": "", "doi": "10.1109/icict50521.2020.00076", "date": "2020", "authors": {"name": "Kevin Matthe Caramancion", "id-internal": "265/2538", "id-external": ""}, "url": {"full": "URL#495313", "pdf": ""}, "publisher-venue": "ICICT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1811260599, "title": "Disinformation as a strategic weapon - Roles of societal polarization, government's cybersecurity capability, and the rule of law.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Jithesh Arayankalam", "id-internal": "242/6322", "id-external": ""}, "url": {"full": "URL#496562", "pdf": ""}, "publisher-venue": "ICIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 156939191, "title": "Hyperpartisanship, Disinformation and Political Conversations on Twitter - The Brazilian Presidential Election of 2018.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Raquel Recuero", "id-internal": "90/10690", "id-external": ""}, {"name": "Felipe Bonow Soares", "id-internal": "232/1190", "id-external": ""}, {"name": "Anatoliy A. Gruzd", "id-internal": "98/552", "id-external": ""}], "url": {"full": "URL#510076", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1662772115, "title": "Artificial Intelligence Against Disinformation - The FANDANGO Practical Case (short paper).", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Francesco Saverio Nucci", "id-internal": "26/3044", "id-external": ""}, {"name": "Silvia Boi", "id-internal": "281/2670", "id-external": ""}, {"name": "Massimo Magaldi", "id-internal": "82/6469", "id-external": ""}], "url": {"full": "URL#511958", "pdf": ""}, "publisher-venue": "IFDaD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3259881369, "title": "ReSCo-CC - Unsupervised Identification of Key Disinformation Sentences.", "abstract": "", "doi": "10.1145/3428757.3429107", "date": "2020", "authors": [{"name": "Soumya Suvra Ghosal", "id-internal": "233/8190", "id-external": ""}, {"name": "Deepak P 0001", "id-internal": "33/1882", "id-external": ""}, {"name": "Anna Jurek-Loughrey", "id-internal": "45/8120", "id-external": ""}], "url": {"full": "URL#515148", "pdf": ""}, "publisher-venue": "iiWAS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3157306574, "title": "The Four-Stages Strategies on Social Media to Cope with \"Infodemic\" and Repair Public Trust - Covid-19 Disinformation and Effectiveness of Government Intervention in China.", "abstract": "", "doi": "10.1109/isi49825.2020.9280518", "date": "2020", "authors": [{"name": "Yonghan Zhu", "id-internal": "255/8639", "id-external": ""}, {"name": "Yuqiao Jiang", "id-internal": "216/5368", "id-external": ""}], "url": {"full": "URL#525699", "pdf": ""}, "publisher-venue": "ISI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 674351301, "title": "Corpus Development for Studying Online Disinformation Campaign - A Narrative + Stance Approach.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Mack Blackburn", "id-internal": "266/1054", "id-external": ""}, {"name": "Ning Yu", "id-internal": "24/3024", "id-external": ""}, {"name": "John Berrie", "id-internal": "170/8358", "id-external": ""}, {"name": "Brian Gordon", "id-internal": "08/4166", "id-external": ""}, {"name": "David Longfellow", "id-internal": "266/0512", "id-external": ""}, {"name": "William Tirrell", "id-internal": "266/0837", "id-external": ""}, {"name": "Mark Williams", "id-internal": "04/304", "id-external": ""}], "url": {"full": "URL#535536", "pdf": ""}, "publisher-venue": "STOC@LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2413609195, "title": "Is this hotel review truthful or deceptive? A platform for disinformation detection through computational stylometry.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Antonio Pascucci", "id-internal": "231/8127", "id-external": ""}, {"name": "Raffaele Manna", "id-internal": "231/9227", "id-external": ""}, {"name": "Ciro Caterino", "id-internal": "224/9857", "id-external": ""}, {"name": "Vincenzo Masucci", "id-internal": "06/5867", "id-external": ""}, {"name": "Johanna Monti", "id-internal": "33/9656", "id-external": ""}], "url": {"full": "URL#536138", "pdf": ""}, "publisher-venue": "STOC@LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3690879044, "title": "You Said It? How Mis- and Disinformation Tweets Surrounding the Corona-5G-Conspiracy Communicate Through Implying.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Lynn de Rijk", "id-internal": "295/2605", "id-external": ""}, "url": {"full": "URL#537434", "pdf": ""}, "publisher-venue": "MediaEval", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2372120669, "title": "Combating Disinformation - Effects of Timing and Correction Format on Factual Knowledge and Personal Beliefs.", "abstract": "", "doi": "10.1007/978-3-030-61841-4_16", "date": "2020", "authors": [{"name": "Leonie Schaewitz", "id-internal": "276/8910", "id-external": ""}, {"name": "Nicole C. Kr\u00e4mer", "id-internal": "66/5127", "id-external": ""}], "url": {"full": "URL#540788", "pdf": ""}, "publisher-venue": "MISDOOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2327627064, "title": "On Countering Disinformation with Caution - Effective Inoculation Strategies and Others that Backfire into Community Hyper-Polarization.", "abstract": "", "doi": "10.1007/978-3-030-61255-9_13", "date": "2020", "authors": [{"name": "Amirarsalan Rajabi", "id-internal": "262/3725", "id-external": ""}, {"name": "Chathika Gunaratne", "id-internal": "140/0892", "id-external": ""}, {"name": "Alexander V. Mantzaris", "id-internal": "48/7269", "id-external": ""}, {"name": "Ivan Garibay", "id-internal": "27/6705", "id-external": ""}], "url": {"full": "URL#555798", "pdf": ""}, "publisher-venue": "SBP-BRiMS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2822740173, "title": "Homophily and Transitivity in Bot Disinformation Networks.", "abstract": "", "doi": "10.1109/snams52053.2020.9336579", "date": "2020", "authors": [{"name": "Evan M. Williams", "id-internal": "285/1550", "id-external": ""}, {"name": "Valerie Novak", "id-internal": "185/7648", "id-external": ""}, {"name": "Dylan Blackwell", "id-internal": "285/1485", "id-external": ""}, {"name": "Paul Platzman", "id-internal": "285/1556", "id-external": ""}, {"name": "Ian McCulloh", "id-internal": "91/872", "id-external": ""}, {"name": "Nolan Edward Phillips", "id-internal": "285/1559", "id-external": ""}], "url": {"full": "URL#563312", "pdf": ""}, "publisher-venue": "SNAMS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2856177370, "title": "Identifying Disinformation Websites Using Infrastructure Features.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Austin Hounsel", "id-internal": "222/1799", "id-external": ""}, {"name": "Jordan Holland", "id-internal": "207/6570", "id-external": ""}, {"name": "Ben Kaiser", "id-internal": "162/0178", "id-external": ""}, {"name": "Kevin Borgolte", "id-internal": "136/8461", "id-external": ""}, {"name": "Nick Feamster", "id-internal": "87/840", "id-external": ""}, {"name": "Jonathan R. Mayer", "id-internal": "116/8542", "id-external": ""}], "url": {"full": "URL#569738", "pdf": ""}, "publisher-venue": "FOCI @ USENIX Security Symposium", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2737330172, "title": "The 2020 Election - Remote Voting, Disinformation, and Audit.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Avi Rubin", "id-internal": "233/0351", "id-external": ""}, "url": {"full": "URL#569796", "pdf": ""}, "publisher-venue": "USENIX Security Symposium", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 525974813, "title": "Designing Effective Network Visualization Representations of Disinformation Operations - Improving DisInfoVis.", "abstract": "", "doi": "10.2312/eurp.20201118", "date": "2020", "authors": [{"name": "Alexandra Melania Pavliuc", "id-internal": "267/6749", "id-external": ""}, {"name": "Jason Dykes", "id-internal": "34/5069", "id-external": ""}], "url": {"full": "URL#570639", "pdf": ""}, "publisher-venue": "EuroVis", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2533171003, "title": "The Diffusion of Mainstream and Disinformation News on Twitter - The Case of Italy and France.", "abstract": "", "doi": "10.1145/3366424.3385776", "date": "2020", "authors": {"name": "Francesco Pierri 0002", "id-internal": "80/8064-2", "id-external": ""}, "url": {"full": "URL#577179", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3405085730, "title": "Disinformation from the Inside - Combining Machine Learning and Journalism to Investigate Sockpuppet Campaigns.", "abstract": "", "doi": "10.1145/3366424.3385777", "date": "2020", "authors": [{"name": "Christopher Schwartz", "id-internal": "41/2161", "id-external": ""}, {"name": "Rebekah Overdorf", "id-internal": "62/10989", "id-external": ""}], "url": {"full": "URL#577213", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3823009401, "title": "Designing Social Machines for Tackling Online Disinformation.", "abstract": "", "doi": "10.1145/3366424.3385770", "date": "2020", "authors": [{"name": "Antonia Wild", "id-internal": "264/2898", "id-external": ""}, {"name": "Andrei Ciortea", "id-internal": "17/11537", "id-external": ""}, {"name": "Simon Mayer", "id-internal": "16/9863", "id-external": ""}], "url": {"full": "URL#577293", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3187099730, "title": "Disinformation in Open Online Media - First Multidisciplinary International Symposium, MISDOOM 2019, Hamburg, Germany, February 27 - March 1, 2019, Revised Selected Papers", "abstract": "", "doi": "10.1007/978-3-030-39627-5", "date": "2020", "authors": [{"name": "Christian Grimme", "id-internal": "94/3183", "id-external": ""}, {"name": "Mike Preuss", "id-internal": "p/MikePreuss", "id-external": ""}, {"name": "Frank W. Takes", "id-internal": "32/10440", "id-external": ""}, {"name": "Annie Waldherr", "id-internal": "138/0310", "id-external": ""}], "url": {"full": "URL#580867", "pdf": ""}, "publisher-venue": ["MISDOOM", "Lecture Notes in Computer Science"], "type": "Editorship", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 609671776, "title": "Disinformation in Open Online Media - Second Multidisciplinary International Symposium, MISDOOM 2020, Leiden, The Netherlands, October 26-27, 2020, Proceedings", "abstract": "", "doi": "10.1007/978-3-030-61841-4", "date": "2020", "authors": [{"name": "Max van Duijn", "id-internal": "245/6386", "id-external": ""}, {"name": "Mike Preuss", "id-internal": "p/MikePreuss", "id-external": ""}, {"name": "Viktoria Spaiser", "id-internal": "45/10193", "id-external": ""}, {"name": "Frank W. Takes", "id-internal": "32/10440", "id-external": ""}, {"name": "Suzan Verberne", "id-internal": "86/5095", "id-external": ""}], "url": {"full": "URL#580868", "pdf": ""}, "publisher-venue": ["MISDOOM", "Lecture Notes in Computer Science"], "type": "Editorship", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4420480, "title": "HoaxItaly - a collection of Italian disinformation and fact-checking stories shared on Twitter in 2019.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Francesco Pierri 0002", "id-internal": "80/8064-2", "id-external": ""}, {"name": "Alessandro Artoni", "id-internal": "245/2583", "id-external": ""}, {"name": "Stefano Ceri", "id-internal": "c/StefanoCeri", "id-external": ""}], "url": {"full": "URL#586266", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2651676943, "title": "A multi-layer approach to disinformation detection on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Francesco Pierri 0002", "id-internal": "80/8064-2", "id-external": ""}, {"name": "Carlo Piccardi", "id-internal": "20/3994", "id-external": ""}, {"name": "Stefano Ceri", "id-internal": "c/StefanoCeri", "id-external": ""}], "url": {"full": "URL#591808", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 672748848, "title": "Unveiling Coordinated Groups Behind White Helmets Disinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Diogo Pacheco", "id-internal": "241/7654", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}], "url": {"full": "URL#592477", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2303426700, "title": "Traffic networks are vulnerable to disinformation attacks.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Marcin Waniek", "id-internal": "151/3595", "id-external": ""}, {"name": "Gururaghav Raman 0001", "id-internal": "234/6847", "id-external": ""}, {"name": "Bedoor K. AlShebli", "id-internal": "38/4424", "id-external": ""}, {"name": "Jimmy Chih-Hsien Peng", "id-internal": "145/6556", "id-external": ""}, {"name": "Talal Rahwan", "id-internal": "57/4885", "id-external": ""}], "url": {"full": "URL#593403", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3472669419, "title": "Supporting Early and Scalable Discovery of Disinformation Websites.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Austin Hounsel", "id-internal": "222/1799", "id-external": ""}, {"name": "Jordan Holland", "id-internal": "207/6570", "id-external": ""}, {"name": "Ben Kaiser", "id-internal": "162/0178", "id-external": ""}, {"name": "Kevin Borgolte", "id-internal": "136/8461", "id-external": ""}, {"name": "Nick Feamster", "id-internal": "87/840", "id-external": ""}, {"name": "Jonathan R. Mayer", "id-internal": "116/8542", "id-external": ""}], "url": {"full": "URL#594908", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 171760009, "title": "Resistance of communities against disinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Amirarsalan Rajabi", "id-internal": "262/3725", "id-external": ""}, {"name": "Seyyedmilad Talebzadehhosseini", "id-internal": "253/8940", "id-external": ""}, {"name": "Ivan Garibay", "id-internal": "27/6705", "id-external": ""}], "url": {"full": "URL#597637", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1993720268, "title": "Automatic Detection of Influential Actors in Disinformation Networks.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Steven Thomas Smith", "id-internal": "120/7245", "id-external": ""}, {"name": "Edward K. Kao", "id-internal": "67/9054", "id-external": ""}, {"name": "Erika D. Mackin", "id-internal": "162/0170", "id-external": ""}, {"name": "Danelle C. Shah", "id-internal": "74/9968", "id-external": ""}, {"name": "Olga Simek", "id-internal": "137/3712", "id-external": ""}, {"name": "Donald B. Rubin", "id-internal": "58/44", "id-external": ""}], "url": {"full": "URL#607758", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 899658563, "title": "On the Detection of Disinformation Campaign Activity with Network Analysis.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Luis Vargas", "id-internal": "68/5101", "id-external": ""}, {"name": "Patrick Emami", "id-internal": "153/7716", "id-external": ""}, {"name": "Patrick Traynor", "id-internal": "14/3295", "id-external": ""}], "url": {"full": "URL#608727", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3551727408, "title": "Classification Aware Neural Topic Model and its Application on a New COVID-19 Disinformation Corpus.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Xingyi Song", "id-internal": "185/5566", "id-external": ""}, {"name": "Johann Petrak", "id-internal": "37/5468", "id-external": ""}, {"name": "Ye Jiang", "id-internal": "97/6238", "id-external": ""}, {"name": "Iknoor Singh", "id-internal": "243/5708", "id-external": ""}, {"name": "Diana Maynard", "id-internal": "69/4767", "id-external": ""}, {"name": "Kalina Bontcheva", "id-internal": "b/KalinaBontcheva", "id-external": ""}], "url": {"full": "URL#610424", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1937882258, "title": "Combating Disinformation in a Social Media Age.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Amrita Bhattacharjee", "id-internal": "251/2495", "id-external": ""}, {"name": "Faisal Alatawi", "id-internal": "270/1587", "id-external": ""}, {"name": "Tahora H. Nazer", "id-internal": "190/5215", "id-external": ""}, {"name": "Kaize Ding", "id-internal": "234/6878", "id-external": ""}, {"name": "Mansooreh Karami", "id-internal": "243/0884", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#619235", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2347738364, "title": "Adapting Security Warnings to Counter Online Disinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Ben Kaiser", "id-internal": "162/0178", "id-external": ""}, {"name": "Jerry Wei", "id-internal": "266/7921", "id-external": ""}, {"name": "Elena Lucherini", "id-internal": "236/2164", "id-external": ""}, {"name": "Kevin Lee", "id-internal": "44/765", "id-external": ""}, {"name": "J. Nathan Matias", "id-internal": "13/3509", "id-external": ""}, {"name": "Jonathan R. Mayer", "id-internal": "116/8542", "id-external": ""}], "url": {"full": "URL#627013", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1417282594, "title": "Identifying Coordinated Accounts in Disinformation Campaigns.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Karishma Sharma", "id-internal": "222/7902", "id-external": ""}, {"name": "Emilio Ferrara", "id-internal": "38/8773", "id-external": ""}, {"name": "Yan Liu 0002", "id-internal": "l/YanLiu2", "id-external": ""}], "url": {"full": "URL#627212", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3050477275, "title": "Disinformation in the Online Information Ecosystem - Detection, Mitigation and Challenges.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Amrita Bhattacharjee", "id-internal": "251/2495", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Min Gao 0001", "id-internal": "45/1016-1", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#637774", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4164881243, "title": "ReSCo-CC - Unsupervised Identification of Key Disinformation Sentences.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Soumya Suvra Ghosal", "id-internal": "233/8190", "id-external": ""}, {"name": "Deepak P 0001", "id-internal": "33/1882", "id-external": ""}, {"name": "Anna Jurek-Loughrey", "id-internal": "45/8120", "id-external": ""}], "url": {"full": "URL#638528", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2194808164, "title": "MM-COVID - A Multilingual and Multimodal Data Repository for Combating COVID-19 Disinformation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Yichuan Li", "id-internal": "216/7478", "id-external": ""}, {"name": "Bohan Jiang", "id-internal": "240/6257", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#642855", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3732859415, "title": "FakeSafe - Human Level Data Protection by Disinformation Mapping using Cycle-consistent Adversarial Network.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Dianbo Liu", "id-internal": "203/9126", "id-external": ""}, {"name": "He Zhu", "id-internal": "59/2802", "id-external": ""}], "url": {"full": "URL#645840", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2029088554, "title": "An Agenda for Disinformation Research.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Nadya Bliss", "id-internal": "174/2183", "id-external": ""}, {"name": "Elizabeth Bradley", "id-internal": "80/2069", "id-external": ""}, {"name": "Joshua Garland", "id-internal": "43/10316", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}, {"name": "Scott W. Ruston", "id-internal": "189/1495", "id-external": ""}, {"name": "Kate Starbird", "id-internal": "84/7848", "id-external": ""}, {"name": "Chris Wiggins", "id-internal": "39/2310", "id-external": ""}], "url": {"full": "URL#650869", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 551183453, "title": "Multilingual Evidence Retrieval and Fact Verification to Combat Global Disinformation - The Power of Polyglotism.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Denisa A. O. Roberts", "id-internal": "274/6959", "id-external": ""}, "url": {"full": "URL#651010", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3857215954, "title": "Cognitive and affective responses to political disinformation in Facebook.", "abstract": "", "doi": "10.1016/j.chb.2019.07.026", "date": "2019", "authors": {"name": "Arash Barfar", "id-internal": "45/9567", "id-external": ""}, "url": {"full": "URL#690804", "pdf": ""}, "publisher-venue": "Comput. Hum. Behav.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3108555101, "title": "Strategically-motivated advanced persistent threat - Definition, process, tactics and a disinformation model of counterattack.", "abstract": "", "doi": "10.1016/j.cose.2019.07.001", "date": "2019", "authors": [{"name": "Atif Ahmad", "id-internal": "09/6570", "id-external": ""}, {"name": "Jeb Webb", "id-internal": "147/4482", "id-external": ""}, {"name": "Kevin C. Desouza", "id-internal": "89/2133", "id-external": ""}, {"name": "James Boorman", "id-internal": "250/3212", "id-external": ""}], "url": {"full": "URL#697512", "pdf": ""}, "publisher-venue": "Comput. Secur.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1096473129, "title": "Theorizing the Journalism Model of Disinformation and Hate Speech Propagation in a Nigerian Democratic Context.", "abstract": "", "doi": "10.4018/ijep.2019070105", "date": "2019", "authors": {"name": "Adamkolo Mohammed Ibrahim", "id-internal": "223/7967", "id-external": ""}, "url": {"full": "URL#723274", "pdf": ""}, "publisher-venue": "Int. J. E Politics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1371559371, "title": "Disinformation as Collaborative Work - Surfacing the Participatory Nature of Strategic Information Operations.", "abstract": "", "doi": "10.1145/3359229", "date": "2019", "authors": [{"name": "Kate Starbird", "id-internal": "84/7848", "id-external": ""}, {"name": "Ahmer Arif", "id-internal": "176/4136", "id-external": ""}, {"name": "Tom Wilson 0003", "id-internal": "221/6338", "id-external": ""}], "url": {"full": "URL#768424", "pdf": ""}, "publisher-venue": "Proc. ACM Hum. Comput. Interact.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3560090920, "title": "Beyond Fact-Checking - Network Analysis Tools for Monitoring Disinformation in Social Media.", "abstract": "", "doi": "10.1007/978-3-030-36687-2_36", "date": "2019", "authors": [{"name": "Stefano Guarino", "id-internal": "14/2001", "id-external": ""}, {"name": "Noemi Trino", "id-internal": "253/8867", "id-external": ""}, {"name": "Alessandro Chessa", "id-internal": "00/7499", "id-external": ""}, {"name": "Gianni Riotta", "id-internal": "149/2730", "id-external": ""}], "url": {"full": "URL#852525", "pdf": ""}, "publisher-venue": "COMPLEX NETWORKS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1019855489, "title": "Characterization of Disinformation Networks Using Graph Embeddings and Opinion Mining.", "abstract": "", "doi": "10.1109/eisic49498.2019.9108876", "date": "2019", "authors": [{"name": "Olga Simek", "id-internal": "137/3712", "id-external": ""}, {"name": "Alyssa C. Mensch", "id-internal": "229/7585", "id-external": ""}, {"name": "Lin Li 0005", "id-internal": "73/2252-5", "id-external": ""}, {"name": "Charlie K. Dagli", "id-internal": "92/4451", "id-external": ""}], "url": {"full": "URL#865720", "pdf": ""}, "publisher-venue": "EISIC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 464401775, "title": "Online Disinformation and the Psychological Bases of Prejudice and Political Conservatism.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Argha Ray", "id-internal": "172/7157", "id-external": ""}, {"name": "Joey F. George", "id-internal": "83/4347", "id-external": ""}], "url": {"full": "URL#883740", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2958819103, "title": "The Future of Online Advertising - Thoughts on Emerging Issues in Privacy, Information Bubbles, and Disinformation.", "abstract": "", "doi": "10.1109/istas48451.2019.8937870", "date": "2019", "authors": [{"name": "Brendan Kitts", "id-internal": "96/2817", "id-external": ""}, {"name": "Nathan McCoy", "id-internal": "260/8988", "id-external": ""}, {"name": "Mark van den Berg", "id-internal": "53/7853", "id-external": ""}], "url": {"full": "URL#939596", "pdf": ""}, "publisher-venue": "ISTAS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1549215590, "title": "How Facebook and Google Accidentally Created a Perfect Ecosystem for Targeted Disinformation.", "abstract": "", "doi": "10.1007/978-3-030-39627-5_11", "date": "2019", "authors": {"name": "Christian St\u00f6cker", "id-internal": "35/8827", "id-external": ""}, "url": {"full": "URL#952871", "pdf": ""}, "publisher-venue": "MISDOOM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2594703271, "title": "Tribalism, Political Polarisation and Disinformation.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Samantha North", "id-internal": "245/4112", "id-external": ""}, {"name": "Lukasz Piwek", "id-internal": "170/4677", "id-external": ""}, {"name": "Adam N. Joinson", "id-internal": "95/6679", "id-external": ""}], "url": {"full": "URL#975805", "pdf": ""}, "publisher-venue": "NewsIR@SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1325591231, "title": "Disinformation - Detect to Disrupt.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Craig Corcoran", "id-internal": "65/8366", "id-external": ""}, {"name": "Renee DiResta", "id-internal": "277/6545", "id-external": ""}, {"name": "David Morar", "id-internal": "201/3293", "id-external": ""}, {"name": "Numa Dhamani", "id-internal": "234/8672", "id-external": ""}, {"name": "David Sullivan", "id-internal": "164/4744", "id-external": ""}, {"name": "Jeffrey L. Gleason", "id-internal": "234/8589", "id-external": ""}, {"name": "Paul Azunre", "id-internal": "198/3557", "id-external": ""}, {"name": "Steve Kramer", "id-internal": "164/2951", "id-external": ""}, {"name": "Becky Ruppel", "id-internal": "277/5819", "id-external": ""}], "url": {"full": "URL#985242", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4217199871, "title": "Combatting Disinformation via Interactive Evidence Detection.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Chris Stahlhut", "id-internal": "59/10154", "id-external": ""}, "url": {"full": "URL#985257", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3524668339, "title": "The Spread of Disinformation on the Web - An Examination of Memes on Social Networking.", "abstract": "", "doi": "10.1109/smartworld-uic-atc-scalcom-iop-sci.2019.00256", "date": "2019", "authors": [{"name": "Marc J. Dupuis", "id-internal": "177/4467", "id-external": ""}, {"name": "Andrew Williams 0006", "id-internal": "263/1345", "id-external": ""}], "url": {"full": "URL#985917", "pdf": ""}, "publisher-venue": "SmartWorld/SCALCOM/UIC/ATC/CBDCom/IOP/SCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3451376116, "title": "Agent Based Simulation of Bot Disinformation Maneuvers in Twitter.", "abstract": "", "doi": "10.1109/wsc40007.2019.9004942", "date": "2019", "authors": [{"name": "David M. Beskow", "id-internal": "222/3992", "id-external": ""}, {"name": "Kathleen M. Carley", "id-internal": "72/6492", "id-external": ""}], "url": {"full": "URL#994669", "pdf": ""}, "publisher-venue": "WSC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2475577283, "title": "Institutional Counter-disinformation Strategies in a Networked Democracy.", "abstract": "", "doi": "10.1145/3308560.3316740", "date": "2019", "authors": {"name": "Jonathan Stray", "id-internal": "153/7731", "id-external": ""}, "url": {"full": "URL#995668", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3278327451, "title": "Disinformation Warfare - Understanding State-Sponsored Trolls on Twitter and Their Influence on the Web.", "abstract": "", "doi": "10.1145/3308560.3316495", "date": "2019", "authors": [{"name": "Savvas Zannettou", "id-internal": "184/5969", "id-external": ""}, {"name": "Tristan Caulfield", "id-internal": "146/6116", "id-external": ""}, {"name": "Emiliano De Cristofaro", "id-internal": "36/6225", "id-external": ""}, {"name": "Michael Sirivianos", "id-internal": "92/5463", "id-external": ""}, {"name": "Gianluca Stringhini", "id-internal": "86/8823", "id-external": ""}, {"name": "Jeremy Blackburn", "id-internal": "12/8780", "id-external": ""}], "url": {"full": "URL#995796", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4134961792, "title": "Topology comparison of Twitter diffusion networks reliably reveals disinformation news.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Francesco Pierri 0002", "id-internal": "80/8064-2", "id-external": ""}, {"name": "Carlo Piccardi", "id-internal": "20/3994", "id-external": ""}, {"name": "Stefano Ceri", "id-internal": "c/StefanoCeri", "id-external": ""}], "url": {"full": "URL#1019092", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1728899551, "title": "Using Deep Networks and Transfer Learning to Address Disinformation.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Numa Dhamani", "id-internal": "234/8672", "id-external": ""}, {"name": "Paul Azunre", "id-internal": "198/3557", "id-external": ""}, {"name": "Jeffrey L. Gleason", "id-internal": "234/8589", "id-external": ""}, {"name": "Craig Corcoran", "id-internal": "65/8366", "id-external": ""}, {"name": "Garrett Honke", "id-internal": "176/1762", "id-external": ""}, {"name": "Steve Kramer", "id-internal": "164/2951", "id-external": ""}, {"name": "Jonathon Morgan", "id-internal": "218/5301", "id-external": ""}], "url": {"full": "URL#1021615", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2812555948, "title": "Investigating Italian disinformation spreading on Twitter in the context of 2019 European elections.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Francesco Pierri 0002", "id-internal": "80/8064-2", "id-external": ""}, {"name": "Alessandro Artoni", "id-internal": "245/2583", "id-external": ""}, {"name": "Stefano Ceri", "id-internal": "c/StefanoCeri", "id-external": ""}], "url": {"full": "URL#1030763", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1505086378, "title": "How weaponizing disinformation can bring down a city's power grid.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Gururaghav Raman 0001", "id-internal": "234/6847", "id-external": ""}, {"name": "Bedoor K. AlShebli", "id-internal": "38/4424", "id-external": ""}, {"name": "Marcin Waniek", "id-internal": "151/3595", "id-external": ""}, {"name": "Talal Rahwan", "id-internal": "57/4885", "id-external": ""}, {"name": "Jimmy Chih-Hsien Peng", "id-internal": "145/6556", "id-external": ""}], "url": {"full": "URL#1033528", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 627527342, "title": "Multilingual Multimodal Digital Deception Detection and Disinformation Spread across Social Platforms.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Maria Glenski", "id-internal": "164/6043", "id-external": ""}, {"name": "Ellyn Ayton", "id-internal": "207/7452", "id-external": ""}, {"name": "Josh Mendoza", "id-internal": "248/8977", "id-external": ""}, {"name": "Svitlana Volkova", "id-internal": "19/8609", "id-external": ""}], "url": {"full": "URL#1039007", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2016961125, "title": "Disinformation Detection - A review of linguistic feature selection and classification models in news veracity assessments.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Jillian Tompkins", "id-internal": "251/9078", "id-external": ""}, "url": {"full": "URL#1046426", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4186018659, "title": "Online Disinformation and the Role of Wikipedia.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Diego S\u00e1ez-Trumper", "id-internal": "66/9962", "id-external": ""}, "url": {"full": "URL#1046643", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1864577424, "title": "Disinformation, dystopia and post-reality in social media - A semiotic-cognitive perspective.", "abstract": "", "doi": "10.3233/efi-180209", "date": "2018", "authors": [{"name": "Rebeka F. Guarda", "id-internal": "232/0017", "id-external": ""}, {"name": "Marcia P. Ohlson", "id-internal": "231/9718", "id-external": ""}, {"name": "Anderson V. Romanini", "id-internal": "231/9827", "id-external": ""}], "url": {"full": "URL#1098783", "pdf": ""}, "publisher-venue": "Educ. Inf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2815834000, "title": "A simulated cyberattack on Twitter - Assessing partisan vulnerability to spear phishing and disinformation ahead of the 2018 U.S. midterm elections.", "abstract": "", "doi": "", "date": "2018", "authors": {"name": "Michael Bossetta", "id-internal": "228/7853", "id-external": ""}, "url": {"full": "URL#1105734", "pdf": ""}, "publisher-venue": "First Monday", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2497829995, "title": "Russian information troops, disinformation, and democracy.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Volodymyr Lysenko", "id-internal": "27/8819", "id-external": ""}, {"name": "Catherine Brooks", "id-internal": "220/0841", "id-external": ""}], "url": {"full": "URL#1105772", "pdf": ""}, "publisher-venue": "First Monday", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1421769138, "title": "Analyzing Disinformation and Crowd Manipulation Tactics on YouTube.", "abstract": "", "doi": "10.1109/asonam.2018.8508766", "date": "2018", "authors": [{"name": "Muhammad Nihal Hussain", "id-internal": "201/8170", "id-external": ""}, {"name": "Serpil Tokdemir", "id-internal": "126/6317", "id-external": ""}, {"name": "Nitin Agarwal", "id-internal": "72/1395", "id-external": ""}, {"name": "Samer Al-khateeb", "id-internal": "151/7865", "id-external": ""}], "url": {"full": "URL#1217701", "pdf": ""}, "publisher-venue": "ASONAM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1266646372, "title": "Real World Examples Suggest a Path to Automated Mitigation of Disinformation.", "abstract": "", "doi": "10.1109/bigdata.2018.8622153", "date": "2018", "authors": [{"name": "Brian Isle", "id-internal": "234/2852", "id-external": ""}, {"name": "Tyler Smith", "id-internal": "52/3487", "id-external": ""}], "url": {"full": "URL#1221421", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2956430366, "title": "Leveraging Archival Theory to Develop A Taxonomy of Online Disinformation.", "abstract": "", "doi": "10.1109/bigdata.2018.8622391", "date": "2018", "authors": [{"name": "Victoria L. Lemieux", "id-internal": "161/6123", "id-external": ""}, {"name": "Tyler D. Smith", "id-internal": "234/3001", "id-external": ""}], "url": {"full": "URL#1221515", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2099994469, "title": "Designing to Support Reflection on Values & Practices to Address Online Disinformation.", "abstract": "", "doi": "10.1145/3272973.3272974", "date": "2018", "authors": {"name": "Ahmer Arif", "id-internal": "176/4136", "id-external": ""}, "url": {"full": "URL#1237858", "pdf": ""}, "publisher-venue": "CSCW Companion", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3156069304, "title": "Disinformation.", "abstract": "", "doi": "10.1007/978-1-4939-7131-2_100286", "date": "2018", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "URL#1379868", "pdf": ""}, "publisher-venue": "Encyclopedia of Social Network Analysis and Mining. 2nd Ed.", "type": "Reference Works", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 685219240, "title": "Disinformation Warfare - Understanding State-Sponsored Trolls on Twitter and Their Influence on the Web.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Savvas Zannettou", "id-internal": "184/5969", "id-external": ""}, {"name": "Tristan Caulfield", "id-internal": "146/6116", "id-external": ""}, {"name": "Emiliano De Cristofaro", "id-internal": "36/6225", "id-external": ""}, {"name": "Michael Sirivianos", "id-internal": "92/5463", "id-external": ""}, {"name": "Gianluca Stringhini", "id-internal": "86/8823", "id-external": ""}, {"name": "Jeremy Blackburn", "id-internal": "12/8780", "id-external": ""}], "url": {"full": "URL#1383678", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2566467929, "title": "Junk News on Military Affairs and National Security - Social Media Disinformation Campaigns Against US Military Personnel and Veterans.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "John D. Gallacher", "id-internal": "215/3664", "id-external": ""}, {"name": "Vlad Barash", "id-internal": "58/4213", "id-external": ""}, {"name": "Philip N. Howard", "id-internal": "58/7535", "id-external": ""}, {"name": "John Kelly", "id-internal": "73/5081", "id-external": ""}], "url": {"full": "URL#1384972", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 483127701, "title": "A Simulated Cyberattack on Twitter - Assessing Partisan Vulnerability to Spear Phishing and Disinformation ahead of the 2018 U.S. Midterm Elections.", "abstract": "", "doi": "", "date": "2018", "authors": {"name": "Michael Bossetta", "id-internal": "228/7853", "id-external": ""}, "url": {"full": "URL#1416826", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1612085365, "title": "Technology-Enabled Disinformation - Summary, Lessons, and Recommendations.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "John Akers", "id-internal": "232/3284", "id-external": ""}, {"name": "Gagan Bansal", "id-internal": "147/2058", "id-external": ""}, {"name": "Gabriel Cadamuro", "id-internal": "203/1637", "id-external": ""}, {"name": "Christine Chen", "id-internal": "86/9924", "id-external": ""}, {"name": "Quanze Chen", "id-internal": "153/6765", "id-external": ""}, {"name": "Lucy Lin", "id-internal": "232/3355", "id-external": ""}, {"name": "Phoebe Mulcaire", "id-internal": "220/5308", "id-external": ""}, {"name": "Rajalakshmi Nandakumar", "id-internal": "118/3387", "id-external": ""}, {"name": "Matthew Rockett", "id-internal": "232/3050", "id-external": ""}, {"name": "Lucy Simko", "id-internal": "31/9612", "id-external": ""}, {"name": "John Toman", "id-internal": "129/2319", "id-external": ""}, {"name": "Tongshuang Wu", "id-internal": "179/3791", "id-external": ""}, {"name": "Eric Zeng", "id-internal": "202/7659", "id-external": ""}, {"name": "Bill Zorn", "id-internal": "232/3136", "id-external": ""}, {"name": "Franziska Roesner", "id-internal": "23/2758", "id-external": ""}], "url": {"full": "URL#1421736", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4037684763, "title": "Disinformation and social bot operations in the run up to the 2017 French presidential election.", "abstract": "", "doi": "", "date": "2017", "authors": {"name": "Emilio Ferrara", "id-internal": "38/8773", "id-external": ""}, "url": {"full": "URL#1463977", "pdf": ""}, "publisher-venue": "First Monday", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3361591441, "title": "Russian Active Measures and September 11, 2001 - Nostradamus Themed Disinformation?", "abstract": "", "doi": "10.4018/ijcwt.2017010103", "date": "2017", "authors": {"name": "Michael Bennett Hotchkiss", "id-internal": "198/3656", "id-external": ""}, "url": {"full": "URL#1474084", "pdf": ""}, "publisher-venue": "Int. J. Cyber Warf. Terror.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1589052211, "title": "Bots Trending Now - Disinformation and Calculated Manipulation of the Masses [Editorial].", "abstract": "", "doi": "10.1109/mts.2017.2697067", "date": "2017", "authors": {"name": "Katina Michael", "id-internal": "75/1359", "id-external": ""}, "url": {"full": "URL#1534311", "pdf": ""}, "publisher-venue": "IEEE Technol. Soc. Mag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2291197697, "title": "Disinformation and Social Bot Operations in the Run Up to the 2017 French Presidential Election.", "abstract": "", "doi": "", "date": "2017", "authors": {"name": "Emilio Ferrara", "id-internal": "38/8773", "id-external": ""}, "url": {"full": "URL#1728671", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 579915645, "title": "Disinformation in Multimedia Annotation - Misleading Metadata Detection on YouTube.", "abstract": "", "doi": "10.1145/2983563.2983569", "date": "2016", "authors": [{"name": "Payal Bajaj", "id-internal": "175/5244", "id-external": ""}, {"name": "Mridul Kavidayal", "id-internal": "215/3320", "id-external": ""}, {"name": "Priyanshu Srivastava", "id-internal": "215/3317", "id-external": ""}, {"name": "Md Nadeem Akhtar", "id-internal": "215/3314", "id-external": ""}, {"name": "Ponnurangam Kumaraguru", "id-internal": "97/5147", "id-external": ""}], "url": {"full": "URL#1990702", "pdf": ""}, "publisher-venue": "iV&L-MM@MM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2791093233, "title": "Disinformation on the Web - Impact, Characteristics, and Detection of Wikipedia Hoaxes.", "abstract": "", "doi": "10.1145/2872427.2883085", "date": "2016", "authors": [{"name": "Srijan Kumar", "id-internal": "131/9628", "id-external": ""}, {"name": "Robert West 0001", "id-internal": "20/7441-1", "id-external": ""}, {"name": "Jure Leskovec", "id-internal": "l/JureLeskovec", "id-external": ""}], "url": {"full": "URL#2032083", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 686505249, "title": "What Is Disinformation?", "abstract": "", "doi": "10.1353/lib.2015.0014", "date": "2015", "authors": {"name": "Don Fallis", "id-internal": "42/320", "id-external": ""}, "url": {"full": "URL#2136084", "pdf": ""}, "publisher-venue": "Libr. Trends", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 206364696, "title": "Detecting Rumor and Disinformation by Web Mining.", "abstract": "", "doi": "", "date": "2015", "authors": {"name": "Boris A. Galitsky", "id-internal": "137/3611", "id-external": ""}, "url": {"full": "URL#2180351", "pdf": ""}, "publisher-venue": "AAAI Spring Symposia", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1753239594, "title": "From Patches to Honey-Patches - Lightweight Attacker Misdirection, Deception, and Disinformation.", "abstract": "", "doi": "10.1145/2660267.2660329", "date": "2014", "authors": [{"name": "Frederico Araujo", "id-internal": "126/9907", "id-external": ""}, {"name": "Kevin W. Hamlen", "id-internal": "60/1400", "id-external": ""}, {"name": "Sebastian Biedermann", "id-internal": "50/10366", "id-external": ""}, {"name": "Stefan Katzenbeisser 0001", "id-internal": "66/3585-1", "id-external": ""}], "url": {"full": "URL#2489360", "pdf": ""}, "publisher-venue": "CCS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3242754875, "title": "Time Critical Disinformation Influence Minimization in Online Social Networks.", "abstract": "", "doi": "10.1109/jisic.2014.20", "date": "2014", "authors": [{"name": "Chuan Luo", "id-internal": "98/10657", "id-external": ""}, {"name": "Kainan Cui", "id-internal": "91/9838", "id-external": ""}, {"name": "Xiaolong Zheng 0001", "id-internal": "98/3341-1", "id-external": ""}, {"name": "Daniel Dajun Zeng", "id-internal": "z/DanielDajunZeng", "id-external": ""}], "url": {"full": "URL#2567925", "pdf": ""}, "publisher-venue": "JISIC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2459031632, "title": "Disinformation techniques for entity resolution.", "abstract": "", "doi": "10.1145/2505515.2505636", "date": "2013", "authors": [{"name": "Steven Euijong Whang", "id-internal": "w/StevenEuijongWhang", "id-external": ""}, {"name": "Hector Garcia-Molina", "id-internal": "g/HGarciaMolina", "id-external": ""}], "url": {"full": "URL#2776481", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1135556415, "title": "Disinformation - A Taxonomy.", "abstract": "", "doi": "10.1109/msp.2010.141", "date": "2011", "authors": [{"name": "James Alexander", "id-internal": "47/2222", "id-external": ""}, {"name": "Jonathan M. Smith", "id-internal": "s/JonathanMSmith", "id-external": ""}], "url": {"full": "URL#3216231", "pdf": ""}, "publisher-venue": "IEEE Secur. Priv.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2820791899, "title": "Notes from the underground city of disinformation - A conceptual investigation.", "abstract": "", "doi": "10.1002/meet.2011.14504801133", "date": "2011", "authors": [{"name": "Natascha Karlova", "id-internal": "36/10874", "id-external": ""}, {"name": "Jin Ha Lee 0001", "id-internal": "l/JinHaLee", "id-external": ""}], "url": {"full": "URL#3285462", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 147157535, "title": "Disinformation Methods of Financial Crime via Email.", "abstract": "", "doi": "", "date": "2006", "authors": [{"name": "Panagiotis Petratos", "id-internal": "23/5254", "id-external": ""}, {"name": "Sofia Gleni", "id-internal": "27/3023", "id-external": ""}], "url": {"full": "URL#4393198", "pdf": ""}, "publisher-venue": "ICIQ", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1474037707, "title": "Disinformation - The Use of False Information.", "abstract": "", "doi": "10.1023/b:mind.0000021683.28604.5b", "date": "2004", "authors": {"name": "James H. Fetzer", "id-internal": "00/2097", "id-external": ""}, "url": {"full": "URL#4624754", "pdf": ""}, "publisher-venue": "Minds Mach.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2514982698, "title": "Disinformation Theory.", "abstract": "", "doi": "10.1145/236156.765657", "date": "1996", "authors": {"name": "Peter G. Neumann", "id-internal": "n/PeterGNeumann", "id-external": ""}, "url": {"full": "URL#5284194", "pdf": ""}, "publisher-venue": "Commun. ACM", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3204863503, "title": "Identifying Disinformation Websites Using Infrastructure Features", "abstract": "Platforms have struggled to keep pace with the spread of disinformation.\nCurrent responses like user reports, manual analysis, and third-party fact\nchecking are slow and difficult to scale, and as a result, disinformation can\nspread unchecked for some time after being created. Automation is essential for\nenabling platforms to respond rapidly to disinformation. In this work, we\nexplore a new direction for automated detection of disinformation websites:\ninfrastructure features. Our hypothesis is that while disinformation websites\nmay be perceptually similar to authentic news websites, there may also be\nsignificant non-perceptual differences in the domain registrations, TLS/SSL\ncertificates, and web hosting configurations. Infrastructure features are\nparticularly valuable for detecting disinformation websites because they are\navailable before content goes live and reaches readers, enabling early\ndetection. We demonstrate the feasibility of our approach on a large corpus of\nlabeled website snapshots. We also present results from a preliminary real-time\ndeployment, successfully discovering disinformation websites while highlighting\nunexplored challenges for automated disinformation detection.", "doi": "", "date": "2020-02-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.07684v5", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1998847407, "title": "Classification Aware Neural Topic Model and its Application on a New\n  COVID-19 Disinformation Corpus", "abstract": "The explosion of disinformation accompanying the COVID-19 pandemic has\noverloaded fact-checkers and media worldwide, and brought a new major challenge\nto government responses worldwide. Not only is disinformation creating\nconfusion about medical science amongst citizens, but it is also amplifying\ndistrust in policy makers and governments. To help tackle this, we developed\ncomputational methods to categorise COVID-19 disinformation. The COVID-19\ndisinformation categories could be used for a) focusing fact-checking efforts\non the most damaging kinds of COVID-19 disinformation; b) guiding policy makers\nwho are trying to deliver effective public health messages and counter\neffectively COVID-19 disinformation. This paper presents: 1) a corpus\ncontaining what is currently the largest available set of manually annotated\nCOVID-19 disinformation categories; 2) a classification-aware neural topic\nmodel (CANTM) designed for COVID-19 disinformation category classification and\ntopic discovery; 3) an extensive analysis of COVID-19 disinformation categories\nwith respect to time, volume, false type, media type and origin source.", "doi": "10.1371/journal.pone.0247086", "date": "2020-06-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.03354v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2637523398, "title": "Combating Disinformation in a Social Media Age", "abstract": "The creation, dissemination, and consumption of disinformation and fabricated\ncontent on social media is a growing concern, especially with the ease of\naccess to such sources, and the lack of awareness of the existence of such\nfalse information. In this paper, we present an overview of the techniques\nexplored to date for the combating of disinformation with various forms. We\nintroduce different forms of disinformation, discuss factors related to the\nspread of disinformation, elaborate on the inherent challenges in detecting\ndisinformation, and show some approaches to mitigating disinformation via\neducation, research, and collaboration. Looking ahead, we present some\npromising future research directions on disinformation.", "doi": "", "date": "2020-07-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.07388v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3243076547, "title": "Efficiency through disinformation", "abstract": "We study the impact of disinformation on a model of resource allocation with\nindependent selfish agents: clients send requests to one of two servers,\ndepending on which one is perceived as offering shorter waiting times. Delays\nin the information about the servers' state leads to oscillations in load.\nServers can give false information about their state (global disinformation) or\nrefuse service to individual clients (local disinformation). We discuss the\ntradeoff between positive effects of disinformation (attenuation of\noscillations) and negative effects (increased fluctuations and reduced\nadaptability) for different parameter values.", "doi": "", "date": "2003-12-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/cond-mat/0312266v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 325820923, "title": "Helping People Deal With Disinformation -- A Socio-Technical Perspective", "abstract": "At the latest since the advent of the Internet, disinformation and conspiracy\ntheories have become ubiquitous. Recent examples like QAnon and Pizzagate prove\nthat false information can lead to real violence. In this motivation statement\nfor the Workshop on Human Aspects of Misinformation at CHI 2021, I explain my\nresearch agenda focused on 1. why people believe in disinformation, 2. how\npeople can be best supported in recognizing disinformation, and 3. what the\npotentials and risks of different tools designed to fight disinformation are.", "doi": "", "date": "2021-04-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.04311v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1829725278, "title": "Online Disinformation and the Role of Wikipedia", "abstract": "The aim of this study is to find key areas of research that can be useful to\nfight against disinformation on Wikipedia. To address this problem we perform a\nliterature review trying to answer three main questions: (i) What is\ndisinformation? (ii) What are the most popular mechanisms to spread online\ndisinformation? and (iii) Which are the mechanisms that are currently being\nused to fight against disinformation?. In all these three questions we take\nfirst a general approach, considering studies from different areas such as\njournalism and communications, sociology, philosophy, information and political\nsciences. And comparing those studies with the current situation on the\nWikipedia ecosystem. We conclude that in order to keep Wikipedia as free as\npossible from disinformation, it is necessary to help patrollers to early\ndetect disinformation and assess the credibility of external sources. More\nresearch is needed to develop tools that use state-of-the-art machine learning\ntechniques to detect potentially dangerous content, empowering patrollers to\ndeal with attacks that are becoming more complex and sophisticated.", "doi": "", "date": "2019-10-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.12596v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2663031605, "title": "Disinformation in the Online Information Ecosystem: Detection,\n  Mitigation and Challenges", "abstract": "With the rapid increase in access to internet and the subsequent growth in\nthe population of online social media users, the quality of information posted,\ndisseminated and consumed via these platforms is an issue of growing concern. A\nlarge fraction of the common public turn to social media platforms and in\ngeneral the internet for news and even information regarding highly concerning\nissues such as COVID-19 symptoms. Given that the online information ecosystem\nis extremely noisy, fraught with misinformation and disinformation, and often\ncontaminated by malicious agents spreading propaganda, identifying genuine and\ngood quality information from disinformation is a challenging task for humans.\nIn this regard, there is a significant amount of ongoing research in the\ndirections of disinformation detection and mitigation. In this survey, we\ndiscuss the online disinformation problem, focusing on the recent 'infodemic'\nin the wake of the coronavirus pandemic. We then proceed to discuss the\ninherent challenges in disinformation research, and then elaborate on the\ncomputational and interdisciplinary approaches towards mitigation of\ndisinformation, after a short overview of the various directions explored in\ndetection efforts.", "doi": "", "date": "2020-10-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.09113v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3368024342, "title": "Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements", "abstract": "In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.", "doi": "", "date": "2020-01-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.00623v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 484692235, "title": "On the Detection of Disinformation Campaign Activity with Network\n  Analysis", "abstract": "Online manipulation of information has become more prevalent in recent years\nas state-sponsored disinformation campaigns seek to influence and polarize\npolitical topics through massive coordinated efforts. In the process, these\nefforts leave behind artifacts, which researchers have leveraged to analyze the\ntactics employed by disinformation campaigns after they are taken down.\nCoordination network analysis has proven helpful for learning about how\ndisinformation campaigns operate; however, the usefulness of these forensic\ntools as a detection mechanism is still an open question. In this paper, we\nexplore the use of coordination network analysis to generate features for\ndistinguishing the activity of a disinformation campaign from legitimate\nTwitter activity. Doing so would provide more evidence to human analysts as\nthey consider takedowns. We create a time series of daily coordination networks\nfor both Twitter disinformation campaigns and legitimate Twitter communities,\nand train a binary classifier based on statistical features extracted from\nthese networks. Our results show that the classifier can predict future\ncoordinated activity of known disinformation campaigns with high accuracy (F1 =\n0.98). On the more challenging task of out-of-distribution activity\nclassification, the performance drops yet is still promising (F1 = 0.71),\nmainly due to an increase in the false positive rate. By doing this analysis,\nwe show that while coordination patterns could be useful for providing evidence\nof disinformation activity, further investigation is needed to improve upon\nthis method before deployment at scale.", "doi": "", "date": "2020-05-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.13466v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1903879577, "title": "Adapting Security Warnings to Counter Online Disinformation", "abstract": "Disinformation is proliferating on the internet, and platforms are responding\nby attaching warnings to content. There is little evidence, however, that these\nwarnings help users identify or avoid disinformation. In this work, we adapt\nmethods and results from the information security warning literature in order\nto design and evaluate effective disinformation warnings. In an initial\nlaboratory study, we used a simulated search task to examine contextual and\ninterstitial disinformation warning designs. We found that users routinely\nignore contextual warnings, but users notice interstitial warnings -- and\nrespond by seeking information from alternative sources. We then conducted a\nfollow-on crowdworker study with eight interstitial warning designs. We\nconfirmed a significant impact on user information-seeking behavior, and we\nfound that a warning's design could effectively inform users or convey a risk\nof harm. We also found, however, that neither user comprehension nor fear of\nharm moderated behavioral effects. Our work provides evidence that\ndisinformation warnings can -- when designed well -- help users identify and\navoid disinformation. We show a path forward for designing effective warnings,\nand we contribute repeatable methods for evaluating behavioral effects. We also\nsurface a possible dilemma: disinformation warnings might be able to inform\nusers and guide behavior, but the behavioral effects might result from user\nexperience friction, not informed decision making.", "doi": "", "date": "2020-08-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.10772v6", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4258606190, "title": "ReSCo-CC: Unsupervised Identification of Key Disinformation Sentences", "abstract": "Disinformation is often presented in long textual articles, especially when\nit relates to domains such as health, often seen in relation to COVID-19. These\narticles are typically observed to have a number of trustworthy sentences among\nwhich core disinformation sentences are scattered. In this paper, we propose a\nnovel unsupervised task of identifying sentences containing key disinformation\nwithin a document that is known to be untrustworthy. We design a three-phase\nstatistical NLP solution for the task which starts with embedding sentences\nwithin a bespoke feature space designed for the task. Sentences represented\nusing those features are then clustered, following which the key sentences are\nidentified through proximity scoring. We also curate a new dataset with\nsentence level disinformation scorings to aid evaluation for this task; the\ndataset is being made publicly available to facilitate further research. Based\non a comprehensive empirical evaluation against techniques from related tasks\nsuch as claim detection and summarization, as well as against simplified\nvariants of our proposed approach, we illustrate that our method is able to\nidentify core disinformation effectively.", "doi": "", "date": "2020-10-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.10836v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1931478296, "title": "How to Deal with Fake News: Visualizing Disinformation", "abstract": "The current public sense of anxiety in dealing with disinformation as\nmanifested by so-called fake news is acutely displayed by the reaction to\nrecent events prompted by a belief in conspiracies among certain groups. A\nmodel to deal with disinformation is proposed; it is based on a demonstration\nof the analogous behavior of disinformation to that of wave phenomena. Two\ncriteria form the basis to combat the deleterious effects of disinformation:\nthe use of a refractive medium based on skepticism as the default mode, and\npolarization as a filter mechanism to analyze its merits based on evidence.\nCritical thinking is enhanced since the first one tackles the pernicious effect\nof the confirmation bias, and the second the tendency towards attribution, both\nof which undermine our efforts to think and act rationally. The benefits of\nsuch a strategy include an epistemic reformulation of disinformation as an\nindependently existing phenomenon, that removes its negative connotations when\nperceived as being possessed by groups or individuals.", "doi": "", "date": "2021-01-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.09251v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1392881059, "title": "A Comparative Study of Online Disinformation and Offline Protests", "abstract": "In early 2021 the United States Capitol in Washington was stormed during a\nriot and violent attack. Although the storming was merely an instance in a long\nsequence of events, it provided a testimony for many observers who had claimed\nthat online actions, including the propagation of disinformation, have offline\nconsequences. Soon after, a number of papers have been published about the\nrelation between online disinformation and offline violence, among other\nrelated relations. Hitherto, the effects upon political protests have been\nunexplored. This paper thus evaluates such effects with a time series\ncross-sectional sample of 125 countries in a period between 2000 and 2019. The\nresults are mixed. Based on Bayesian multi-level regression modeling, (i) there\nindeed is an effect between online disinformation and offline protests, but the\neffect is partially meditated by political polarization. The results are\nclearer in a sample of countries belonging to the European Economic Area. With\nthis sample, (ii) offline protest counts increase from online disinformation\ndisseminated by domestic governments, political parties, and politicians as\nwell as by foreign governments. Furthermore, (iii) Internet shutdowns and\ngovernmental monitoring of social media tend to decrease the counts. With these\nresults, the paper contributes to the blossoming disinformation research by\nmodeling the impact of disinformation upon offline phenomenon. The contribution\nis important due to the various policy measures planned or already enacted.", "doi": "", "date": "2021-06-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.11000v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2911072355, "title": "The Value of Misinformation and Disinformation", "abstract": "Information is a critical dimension in warfare. Inaccurate information such\nas misinformation or disinformation further complicates military operations. In\nthis paper, we examine the value of misinformation and disinformation to a\nmilitary leader who through investment in people, programs and technology is\nable to affect the accuracy of information communicated between other actors.\nWe model the problem as a partially observable stochastic game with three\nagents, a leader and two followers. We determine the value to the leader of\nmisinformation or disinformation being communicated between two (i) adversarial\nfollowers and (ii) allied followers. We demonstrate that only under certain\nconditions, the prevalent intuition that the leader would benefit from less\n(more) accurate communication between adversarial (allied) followers is valid.\nWe analyzed why the intuition may fail and show a holistic paradigm taking into\naccount both the reward structures and policies of agents is necessary in order\nto correctly determine the value of misinformation and disinformation. Our\nresearch identifies efficient targeted investments to affect the accuracy of\ninformation communicated between followers to the leader's advantage.", "doi": "", "date": "2019-01-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.01464v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 200339615, "title": "Investigating Italian disinformation spreading on Twitter in the context\n  of 2019 European elections", "abstract": "We investigate the presence (and the influence) of disinformation spreading\non online social networks in Italy, in the5-month period preceding the 2019\nEuropean Parliament elections. To this aim we collected a large-scale dataset\noftweets associated to thousands of news articles published on Italian\ndisinformation websites. In the observation period,a few outlets accounted for\nmost of the deceptive information circulating on Twitter, which focused on\ncontroversialand polarizing topics of debate such as immigration, national\nsafety and (Italian) nationalism. We found evidence ofconnections between\ndifferent disinformation outlets across Europe, U.S. and Russia, which often\nlinked to each otherand featured similar, even translated, articles in the\nperiod before the elections. Overall, the spread of disinformation onTwitter\nwas confined in a limited community, strongly (and explicitly) related to the\nItalian conservative and far-rightpolitical environment, who had a limited\nimpact on online discussions on the up-coming elections.", "doi": "10.1371/journal.pone.0227821", "date": "2019-07-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.08170v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2433885526, "title": "How weaponizing disinformation can bring down a city's power grid", "abstract": "Social technologies have made it possible to propagate disinformation and\nmanipulate the masses at an unprecedented scale. This is particularly alarming\nfrom a security perspective, as humans have proven to be the weakest link when\nprotecting critical infrastructure in general, and the power grid in\nparticular. Here, we consider an attack in which an adversary attempts to\nmanipulate the behavior of energy consumers by sending fake discount\nnotifications encouraging them to shift their consumption into the peak-demand\nperiod. We conduct surveys to assess the propensity of people to follow-through\non such notifications and forward them to their friends. This allows us to\nmodel how the disinformation propagates through social networks. Finally, using\nGreater London as a case study, we show that disinformation can indeed be used\nto orchestrate an attack wherein unwitting consumers synchronize their\nenergy-usage patterns, resulting in blackouts on a city-scale. These findings\ndemonstrate that in an era when disinformation can be weaponized, system\nvulnerabilities arise not only from the hardware and software of critical\ninfrastructure, but also from the behavior of the consumers.", "doi": "10.1371/journal.pone.0236517", "date": "2019-08-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.02589v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4082819305, "title": "Deriving Disinformation Insights from Geolocalized Twitter Callouts", "abstract": "This paper demonstrates a two-stage method for deriving insights from social\nmedia data relating to disinformation by applying a combination of geospatial\nclassification and embedding-based language modelling across multiple\nlanguages. In particular, the analysis in centered on Twitter and\ndisinformation for three European languages: English, French and Spanish.\nFirstly, Twitter data is classified into European and non-European sets using\nBERT. Secondly, Word2vec is applied to the classified texts resulting in\nEurocentric, non-Eurocentric and global representations of the data for the\nthree target languages. This comparative analysis demonstrates not only the\nefficacy of the classification method but also highlights geographic, temporal\nand linguistic differences in the disinformation-related media. Thus, the\ncontributions of the work are threefold: (i) a novel language-independent\ntransformer-based geolocation method; (ii) an analytical approach that exploits\nlexical specificity and word embeddings to interrogate user-generated content;\nand (iii) a dataset of 36 million disinformation related tweets in English,\nFrench and Spanish.", "doi": "", "date": "2021-08-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.03067v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3371612135, "title": "Technological Approaches to Detecting Online Disinformation and\n  Manipulation", "abstract": "The move of propaganda and disinformation to the online environment is\npossible thanks to the fact that within the last decade, digital information\nchannels radically increased in popularity as a news source. The main advantage\nof such media lies in the speed of information creation and dissemination.\nThis, on the other hand, inevitably adds pressure, accelerating editorial work,\nfact-checking, and the scrutiny of source credibility. In this chapter, an\noverview of computer-supported approaches to detecting disinformation and\nmanipulative techniques based on several criteria is presented. We concentrate\non the technical aspects of automatic methods which support fact-checking,\ntopic identification, text style analysis, or message filtering on social media\nchannels. Most of the techniques employ artificial intelligence and machine\nlearning with feature extraction combining available information resources. The\nfollowing text firstly specifies the tasks related to computer detection of\nmanipulation and disinformation spreading. The second section presents concrete\nmethods of solving the tasks of the analysis, and the third sections enlists\ncurrent verification and benchmarking datasets published and used in this area\nfor evaluation and comparison.", "doi": "10.1007/978-3-030-58624-9", "date": "2021-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.11669v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2326095633, "title": "Weighted Accuracy Algorithmic Approach In Counteracting Fake News And\n  Disinformation", "abstract": "As the world is becoming more dependent on the internet for information\nexchange, some overzealous journalists, hackers, bloggers, individuals and\norganizations tend to abuse the gift of free information environment by\npolluting it with fake news, disinformation and pretentious content for their\nown agenda. Hence, there is the need to address the issue of fake news and\ndisinformation with utmost seriousness. This paper proposes a methodology for\nfake news detection and reporting through a constraint mechanism that utilizes\nthe combined weighted accuracies of four machine learning algorithms.", "doi": "10.2478/ers-2021-0007", "date": "2020-07-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.01535v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 698653637, "title": "Multilingual Evidence Retrieval and Fact Verification to Combat Global\n  Disinformation: The Power of Polyglotism", "abstract": "This article investigates multilingual evidence retrieval and fact\nverification as a step to combat global disinformation, a first effort of this\nkind, to the best of our knowledge. The goal is building multilingual systems\nthat retrieve in evidence-rich languages to verify claims in evidence-poor\nlanguages that are more commonly targeted by disinformation. To this end, our\nEnmBERT fact verification system shows evidence of transfer learning ability\nand 400 example mixed English-Romanian dataset is made available for\ncross-lingual transfer learning evaluation.", "doi": "", "date": "2020-12-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.08919v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 235588216, "title": "A Survey on Multimodal Disinformation Detection", "abstract": "Recent years have witnessed the proliferation of fake news, propaganda,\nmisinformation, and disinformation online. While initially this was mostly\nabout textual content, over time images and videos gained popularity, as they\nare much easier to consume, attract much more attention, and spread further\nthan simple text. As a result, researchers started targeting different\nmodalities and combinations thereof. As different modalities are studied in\ndifferent research communities, with insufficient interaction, here we offer a\nsurvey that explores the state-of-the-art on multimodal disinformation\ndetection covering various combinations of modalities: text, images, audio,\nvideo, network structure, and temporal information. Moreover, while some\nstudies focused on factuality, others investigated how harmful the content is.\nWhile these two components in the definition of disinformation -- (i)\nfactuality and (ii) harmfulness, are equally important, they are typically\nstudied in isolation. Thus, we argue for the need to tackle disinformation\ndetection by taking into account multiple modalities as well as both factuality\nand harmfulness, in the same framework. Finally, we discuss current challenges\nand future research directions.", "doi": "", "date": "2021-03-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.12541v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4228354606, "title": "Taking a Stance on Fake News: Towards Automatic Disinformation\n  Assessment via Deep Bidirectional Transformer Language Models for Stance\n  Detection", "abstract": "The exponential rise of social media and digital news in the past decade has\nhad the unfortunate consequence of escalating what the United Nations has\ncalled a global topic of concern: the growing prevalence of disinformation.\nGiven the complexity and time-consuming nature of combating disinformation\nthrough human assessment, one is motivated to explore harnessing AI solutions\nto automatically assess news articles for the presence of disinformation. A\nvaluable first step towards automatic identification of disinformation is\nstance detection, where given a claim and a news article, the aim is to predict\nif the article agrees, disagrees, takes no position, or is unrelated to the\nclaim. Existing approaches in literature have largely relied on hand-engineered\nfeatures or shallow learned representations (e.g., word embeddings) to encode\nthe claim-article pairs, which can limit the level of representational\nexpressiveness needed to tackle the high complexity of disinformation\nidentification. In this work, we explore the notion of harnessing large-scale\ndeep bidirectional transformer language models for encoding claim-article pairs\nin an effort to construct state-of-the-art stance detection geared for\nidentifying disinformation. Taking advantage of bidirectional cross-attention\nbetween claim-article pairs via pair encoding with self-attention, we construct\na large-scale language model for stance detection by performing transfer\nlearning on a RoBERTa deep bidirectional transformer language model, and were\nable to achieve state-of-the-art performance (weighted accuracy of 90.01%) on\nthe Fake News Challenge Stage 1 (FNC-I) benchmark. These promising results\nserve as motivation for harnessing such large-scale language models as powerful\nbuilding blocks for creating effective AI solutions to combat disinformation.", "doi": "", "date": "2019-11-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.11951v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 521828829, "title": "Resistance of communities against disinformation", "abstract": "The spread of disinformation is considered a big threat to societies and has\nrecently received unprecedented attention. In this paper we propose an\nagent-based model to simulate dissemination of a conspiracy in a population.\nThe model is able to compare the resistance of different network structures\nagainst the activity of conspirators. Results show that connectedness of\nnetwork structure and centrality of conspirators are of crucial importance in\npreventing conspiracies from becoming widespread.", "doi": "", "date": "2020-03-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.00379v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2940031529, "title": "Disinformation Detection: A review of linguistic feature selection and\n  classification models in news veracity assessments", "abstract": "Over the past couple of years, the topic of \"fake news\" and its influence\nover people's opinions has become a growing cause for concern. Although the\nspread of disinformation on the Internet is not a new phenomenon, the\nwidespread use of social media has exacerbated its effects, providing more\nchannels for dissemination and the potential to \"go viral.\" Nowhere was this\nmore evident than during the 2016 United States Presidential Election. Although\nthe current of disinformation spread via trolls, bots, and hyperpartisan media\noutlets likely reinforced existing biases rather than sway undecided voters,\nthe effects of this deluge of disinformation are by no means trivial. The\nconsequences range in severity from an overall distrust in news media, to an\nill-informed citizenry, and in extreme cases, provocation of violent action. It\nis clear that human ability to discern lies from truth is flawed at best. As\nsuch, greater attention has been given towards applying machine learning\napproaches to detect deliberately deceptive news articles. This paper looks at\nthe work that has already been done in this area.", "doi": "", "date": "2019-10-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.12073v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 626593131, "title": "Technology-Enabled Disinformation: Summary, Lessons, and Recommendations", "abstract": "Technology is increasingly used -- unintentionally (misinformation) or\nintentionally (disinformation) -- to spread false information at scale, with\npotentially broad-reaching societal effects. For example, technology enables\nincreasingly realistic false images and videos, and hyper-personal targeting\nmeans different people may see different versions of reality. This report is\nthe culmination of a PhD-level special topics course\n(https://courses.cs.washington.edu/courses/cse599b/18au/) in Computer Science &\nEngineering at the University of Washington's Paul G. Allen School in the fall\nof 2018. The goals of this course were to study (1) how technologies and\ntoday's technical platforms enable and support the creation and spread of such\nmis- and disinformation, as well as (2) how technical approaches could be used\nto mitigate these issues. In this report, we summarize the space of\ntechnology-enabled mis- and disinformation based on our investigations, and\nthen surface our lessons and recommendations for technologists, researchers,\nplatform designers, policymakers, and users.", "doi": "", "date": "2018-12-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.09383v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1465144227, "title": "Using Deep Networks and Transfer Learning to Address Disinformation", "abstract": "We apply an ensemble pipeline composed of a character-level convolutional\nneural network (CNN) and a long short-term memory (LSTM) as a general tool for\naddressing a range of disinformation problems. We also demonstrate the ability\nto use this architecture to transfer knowledge from labeled data in one domain\nto related (supervised and unsupervised) tasks. Character-level neural networks\nand transfer learning are particularly valuable tools in the disinformation\nspace because of the messy nature of social media, lack of labeled data, and\nthe multi-channel tactics of influence campaigns. We demonstrate their\neffectiveness in several tasks relevant for detecting disinformation: spam\nemails, review bombing, political sentiment, and conversation clustering.", "doi": "", "date": "2019-05-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.10412v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1186126654, "title": "Tactical Reframing of Online Disinformation Campaigns Against The\n  Istanbul Convention", "abstract": "In March 2021, Turkey withdrew from The Istanbul Convention, a human-rights\ntreaty that addresses violence against women, citing issues with the\nconvention's implicit recognition of sexual and gender minorities. In this\nwork, we trace disinformation campaigns related to the Istanbul Convention and\nits associated Turkish law that circulate on divorced men's rights Facebook\ngroups. We find that these groups adjusted the narrative and focus of the\ncampaigns to appeal to a larger audience, which we refer to as \"tactical\nreframing.\" Initially, the men organized in a grass-roots manner to campaign\nagainst the Turkish law that was passed to codify the convention, focusing on\none-sided custody of children and indefinite alimony. Later, they reframed\ntheir campaign and began attacking the Istanbul Convention, highlighting its\nacknowledgment of homosexuality. This case study highlights how disinformation\ncampaigns can be used to weaponize homophobia in order to limit the rights of\nwomen. To the best of our knowledge, this is the first case study that analyzes\na narrative reframing in the context of a disinformation campaign on social\nmedia.", "doi": "10.36190/2021.42", "date": "2021-05-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.13398v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2104145086, "title": "Disinformation and Social Bot Operations in the Run Up to the 2017\n  French Presidential Election", "abstract": "Recent accounts from researchers, journalists, as well as federal\ninvestigators, reached a unanimous conclusion: social media are systematically\nexploited to manipulate and alter public opinion. Some disinformation campaigns\nhave been coordinated by means of bots, social media accounts controlled by\ncomputer scripts that try to disguise themselves as legitimate human users. In\nthis study, we describe one such operation occurred in the run up to the 2017\nFrench presidential election. We collected a massive Twitter dataset of nearly\n17 million posts occurred between April 27 and May 7, 2017 (Election Day). We\nthen set to study the MacronLeaks disinformation campaign: By leveraging a mix\nof machine learning and cognitive behavioral modeling techniques, we separated\nhumans from bots, and then studied the activities of the two groups taken\nindependently, as well as their interplay. We provide a characterization of\nboth the bots and the users who engaged with them and oppose it to those users\nwho didn't. Prior interests of disinformation adopters pinpoint to the reasons\nof the scarce success of this campaign: the users who engaged with MacronLeaks\nare mostly foreigners with a preexisting interest in alt-right topics and\nalternative news media, rather than French users with diverse political views.\nConcluding, anomalous account usage patterns suggest the possible existence of\na black-market for reusable political disinformation bots.", "doi": "10.5210/fm.v22i8.8005", "date": "2017-07-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1707.00086v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2184956968, "title": "A multi-layer approach to disinformation detection on Twitter", "abstract": "We tackle the problem of classifying news articles pertaining to\ndisinformation vs mainstream news by solely inspecting their diffusion\nmechanisms on Twitter. Our technique is inherently simple compared to existing\ntext-based approaches, as it allows to by-pass the multiple levels of\ncomplexity which are found in news content (e.g. grammar, syntax, style). We\nemploy a multi-layer representation of Twitter diffusion networks, and we\ncompute for each layer a set of global network features which quantify\ndifferent aspects of the sharing process. Experimental results with two\nlarge-scale datasets, corresponding to diffusion cascades of news shared\nrespectively in the United States and Italy, show that a simple Logistic\nRegression model is able to classify disinformation vs mainstream networks with\nhigh accuracy (AUROC up to 94%), also when considering the political bias of\ndifferent sources in the classification task. We also highlight differences in\nthe sharing patterns of the two news domains which appear to be\ncountry-independent. We believe that our network-based approach provides useful\ninsights which pave the way to the future development of a system to detect\nmisleading and harmful information spreading on social media.", "doi": "", "date": "2020-02-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.12612v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3445855661, "title": "Assessing disinformation through the dynamics of supply and demand in\n  the news ecosystem", "abstract": "Social dialogue, the foundation of our democracies, is currently threatened\nby disinformation and partisanship, with their disrupting role on individual\nand collective awareness and detrimental effects on decision-making processes.\nDespite a great deal of attention to the news sphere itself, little is known\nabout the subtle interplay between the offer and the demand for information.\nStill, a broader perspective on the news ecosystem, including both the\nproducers and the consumers of information, is needed to build new tools to\nassess the health of the infosphere. Here, we combine in the same framework\nnews supply, as mirrored by a fairly complete Italian news database - partially\nannotated for fake news, and news demand, as captured through the Google Trends\ndata for Italy. Our investigation focuses on the temporal and semantic\ninterplay of news, fake news, and searches in several domains, including the\nvirus SARS-CoV-2 pandemic. Two main results emerge. First, disinformation is\nextremely reactive to people's interests and tends to thrive, especially when\nthere is a mismatch between what people are interested in and what news outlets\nprovide. Second, a suitably defined index can assess the level of\ndisinformation only based on the available volumes of news and searches.\nAlthough our results mainly concern the Coronavirus subject, we provide hints\nthat the same findings can have more general applications. We contend these\nresults can be a powerful asset in informing campaigns against disinformation\nand providing news outlets and institutions with potentially relevant\nstrategies.", "doi": "", "date": "2021-05-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.15172v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1598392052, "title": "Multilingual Multimodal Digital Deception Detection and Disinformation\n  Spread across Social Platforms", "abstract": "Our main contribution in this work is novel results of multilingual models\nthat go beyond typical applications of rumor or misinformation detection in\nEnglish social news content to identify fine-grained classes of digital\ndeception across multiple languages (e.g. Russian, Spanish, etc.). In addition,\nwe present models for multimodal deception detection from images and text and\ndiscuss the limitations of image only and text only models. Finally, we\nelaborate on the ongoing work on measuring deceptive content (in particular\ndisinformation) spread across social platforms.", "doi": "", "date": "2019-09-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.05838v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3783667607, "title": "HoaxItaly: a collection of Italian disinformation and fact-checking\n  stories shared on Twitter in 2019", "abstract": "We released over 1 million tweets shared during 2019 and containing links to\nthousands of news articles published on two classes of Italian outlets: (1)\ndisinformation websites, i.e. outlets which have been repeatedly flagged by\njournalists and fact-checkers for producing low-credibility content such as\nfalse news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)\nfact-checking websites which notably debunk and verify online news and claims.\nThe dataset, which includes also title and body for approximately 37k news\narticles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.", "doi": "", "date": "2020-01-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.10926v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2100870460, "title": "Propagation from Deceptive News Sources: Who Shares, How Much, How\n  Evenly, and How Quickly?", "abstract": "As people rely on social media as their primary sources of news, the spread\nof misinformation has become a significant concern. In this large-scale study\nof news in social media we analyze eleven million posts and investigate\npropagation behavior of users that directly interact with news accounts\nidentified as spreading trusted versus malicious content. Unlike previous work,\nwhich looks at specific rumors, topics, or events, we consider all content\npropagated by various news sources. Moreover, we analyze and contrast\npopulation versus sub-population behaviour (by demographics) when spreading\nmisinformation, and distinguish between two types of propagation, i.e., direct\nretweets and mentions. Our evaluation examines how evenly, how many, how\nquickly, and which users propagate content from various types of news sources\non Twitter.\n  Our analysis has identified several key differences in propagation behavior\nfrom trusted versus suspicious news sources. These include high inequity in the\ndiffusion rate based on the source of disinformation, with a small group of\nhighly active users responsible for the majority of disinformation spread\noverall and within each demographic. Analysis by demographics showed that users\nwith lower annual income and education share more from disinformation sources\ncompared to their counterparts. News content is shared significantly more\nquickly from trusted, conspiracy, and disinformation sources compared to\nclickbait and propaganda. Older users propagate news from trusted sources more\nquickly than younger users, but they share from suspicious sources after longer\ndelays. Finally, users who interact with clickbait and conspiracy sources are\nlikely to share from propaganda accounts, but not the other way around.", "doi": "10.1109/tcss.2018.2881071", "date": "2018-12-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.03533v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4182943922, "title": "Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News", "abstract": "Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 \"infodemic\", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n\"fake news\" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.05854v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2629019894, "title": "An Agenda for Disinformation Research", "abstract": "In the 21st Century information environment, adversarial actors use\ndisinformation to manipulate public opinion. The distribution of false,\nmisleading, or inaccurate information with the intent to deceive is an\nexistential threat to the United States--distortion of information erodes trust\nin the socio-political institutions that are the fundamental fabric of\ndemocracy: legitimate news sources, scientists, experts, and even fellow\ncitizens. As a result, it becomes difficult for society to come together within\na shared reality; the common ground needed to function effectively as an\neconomy and a nation. Computing and communication technologies have facilitated\nthe exchange of information at unprecedented speeds and scales. This has had\ncountless benefits to society and the economy, but it has also played a\nfundamental role in the rising volume, variety, and velocity of disinformation.\nTechnological advances have created new opportunities for manipulation,\ninfluence, and deceit. They have effectively lowered the barriers to reaching\nlarge audiences, diminishing the role of traditional mass media along with the\neditorial oversight they provided. The digitization of information exchange,\nhowever, also makes the practices of disinformation detectable, the networks of\ninfluence discernable, and suspicious content characterizable. New tools and\napproaches must be developed to leverage these affordances to understand and\naddress this growing challenge.", "doi": "", "date": "2020-12-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.08572v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2679227212, "title": "A Simulated Cyberattack on Twitter: Assessing Partisan Vulnerability to\n  Spear Phishing and Disinformation ahead of the 2018 U.S. Midterm Elections", "abstract": "State-sponsored \"bad actors\" increasingly weaponize social media platforms to\nlaunch cyberattacks and disinformation campaigns during elections. Social media\ncompanies, due to their rapid growth and scale, struggle to prevent the\nweaponization of their platforms. This study conducts an automated spear\nphishing and disinformation campaign on Twitter ahead of the 2018 United States\nMidterm Elections. A fake news bot account - the @DCNewsReport - was created\nand programmed to automatically send customized tweets with a \"breaking news\"\nlink to 138 Twitter users, before being restricted by Twitter.\n  Overall, one in five users clicked the link, which could have potentially led\nto the downloading of ransomware or the theft of private information. However,\nthe link in this experiment was non-malicious and redirected users to a Google\nForms survey. In predicting users' likelihood to click the link on Twitter, no\nstatistically significant differences were observed between right-wing and\nleft-wing partisans, or between Web users and mobile users. The findings signal\nthat politically expressive Americans on Twitter, regardless of their party\npreferences or the devices they use to access the platform, are at risk of\nbeing spear phishing on social media.", "doi": "10.5210/fm.v23i12.9540", "date": "2018-11-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.05900v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 773594793, "title": "Fake News, Disinformation, and Deepfakes: Leveraging Distributed Ledger\n  Technologies and Blockchain to Combat Digital Deception and Counterfeit\n  Reality", "abstract": "The rise of ubiquitous deepfakes, misinformation, disinformation, propaganda\nand post-truth, often referred to as fake news, raises concerns over the role\nof Internet and social media in modern democratic societies. Due to its rapid\nand widespread diffusion, digital deception has not only an individual or\nsocietal cost (e.g., to hamper the integrity of elections), but it can lead to\nsignificant economic losses (e.g., to affect stock market performance) or to\nrisks to national security. Blockchain and other Distributed Ledger\nTechnologies (DLTs) guarantee the provenance, authenticity and traceability of\ndata by providing a transparent, immutable and verifiable record of\ntransactions while creating a peer-to-peer secure platform for storing and\nexchanging information. This overview aims to explore the potential of DLTs and\nblockchain to combat digital deception, reviewing initiatives that are\ncurrently under development and identifying their main current challenges.\nMoreover, some recommendations are enumerated to guide future researchers on\nissues that will have to be tackled to face fake news, disinformation and\ndeepfakes, as an integral part of strengthening the resilience against\ncyber-threats on today's online media.", "doi": "", "date": "2019-04-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.05386v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 946481960, "title": "The Alt-Right and Global Information Warfare", "abstract": "The Alt-Right is a neo-fascist white supremacist movement that is involved in\nviolent extremism and shows signs of engagement in extensive disinformation\ncampaigns. Using social media data mining, this study develops a deeper\nunderstanding of such targeted disinformation campaigns and the ways they\nspread. It also adds to the available literature on the endogenous and\nexogenous influences within the US far right, as well as motivating factors\nthat drive disinformation campaigns, such as geopolitical strategy. This study\nis to be taken as a preliminary analysis to indicate future methods and\nfollow-on research that will help develop an integrated approach to\nunderstanding the strategies and associations of the modern fascist movement.", "doi": "10.1109/bigdata.2018.8622270", "date": "2019-05-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.02712v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3567145081, "title": "Traffic networks are vulnerable to disinformation attacks", "abstract": "Disinformation continues to attract attention due to its increasing threat to\nsociety. Nevertheless, a disinformation-based attack on critical infrastructure\nhas never been studied to date. Here, we consider traffic networks and focus on\nfake information that manipulates drivers' decisions to create congestion. We\nstudy the optimization problem faced by the adversary when choosing which\nstreets to target to maximize disruption. We prove that finding an optimal\nsolution is computationally intractable, implying that the adversary has no\nchoice but to settle for suboptimal heuristics. We analyze one such heuristic,\nand compare the cases when targets are spread across the city of Chicago vs.\nconcentrated in its business district. Surprisingly, the latter results in more\nfar-reaching disruption, with its impact felt as far as 2 kilometers from the\nclosest target. Our findings demonstrate that vulnerabilities in critical\ninfrastructure may arise not only from hardware and software, but also from\nbehavioral manipulation.", "doi": "", "date": "2020-03-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.03723v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 353856657, "title": "Understanding the Use of Fauxtography on Social Media", "abstract": "Despite the influence that image-based communication has on online discourse,\nthe role played by images in disinformation is still not well understood. In\nthis paper, we present the first large-scale study of fauxtography, analyzing\nthe use of manipulated or misleading images in news discussion on online\ncommunities. First, we develop a computational pipeline geared to detect\nfauxtography, and identify over 61k instances of fauxtography discussed on\nTwitter, 4chan, and Reddit. Then, we study how posting fauxtography affects\nengagement of posts on social media, finding that posts containing it receive\nmore interactions in the form of re-shares, likes, and comments. Finally, we\nshow that fauxtography images are often turned into memes by Web communities.\nOur findings show that effective mitigation against disinformation need to take\nimages into account, and highlight a number of challenges in dealing with\nimage-based disinformation.", "doi": "", "date": "2020-09-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.11792v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2202291566, "title": "A Survey on Stance Detection for Mis- and Disinformation Identification", "abstract": "Detecting attitudes expressed in texts, also known as stance detection, has\nbecome an important task for the detection of false information online, be it\nmisinformation (unintentionally false) or disinformation (intentionally false,\nspread deliberately with malicious intent). Stance detection has been framed in\ndifferent ways, including: (a) as a component of fact-checking, rumour\ndetection, and detecting previously fact-checked claims; or (b) as a task in\nits own right. While there have been prior efforts to contrast stance detection\nwith other related social media tasks such as argumentation mining and\nsentiment analysis, there is no survey examining the relationship between\nstance detection detection and mis- and disinformation detection from a\nholistic viewpoint, which is the focus of this survey. We review and analyse\nexisting work in this area, before discussing lessons learnt and future\nchallenges.", "doi": "", "date": "2021-02-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.00242v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 100082397, "title": "Strategically-Motivated Advanced Persistent Threat: Definition, Process,\n  Tactics and a Disinformation Model of Counterattack", "abstract": "Advanced persistent threat (APT) is widely acknowledged to be the most\nsophisticated and potent class of security threat. APT refers to knowledgeable\nhuman attackers that are organized, highly sophisticated and motivated to\nachieve their objectives against a targeted organization(s) over a prolonged\nperiod. Strategically-motivated APTs or S-APTs are distinct in that they draw\ntheir objectives from the broader strategic agenda of third parties such as\ncriminal syndicates, nation-states, and rival corporations. In this paper we\nreview the use of the term - Advanced Persistent Threat - and present a formal\ndefinition. We then draw on military science, the science of organized\nconflict, for a theoretical basis to develop a rigorous and holistic model of\nthe stages of an APT operation which we subsequently use to explain how S-APTs\nexecute their strategically motivated operations using tactics, techniques and\nprocedures. Finally, we present a general disinformation model, derived from\nsituation awareness theory, and explain how disinformation can be used to\nattack the situation awareness and decision making of not only S-APT operators,\nbut also the entities that back them.", "doi": "", "date": "2021-03-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.15005v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2796847584, "title": "The Impact of Disinformation on a Controversial Debate on Social Media", "abstract": "In this work we study how pervasive is the presence of disinformation in the\nItalian debate around immigration on Twitter and the role of automated accounts\nin the diffusion of such content. By characterising the Twitter users with an\n\\textit{Untrustworthiness} score, that tells us how frequently they engage with\ndisinformation content, we are able to see that such bad information\nconsumption habits are not equally distributed across the users; adopting a\nnetwork analysis approach, we can identify communities characterised by a very\nhigh presence of users that frequently share content from unreliable news\nsources. Within this context, social bots tend to inject in the network more\nmalicious content, that often remains confined in a limited number of clusters;\ninstead, they target reliable content in order to diversify their reach. The\nevidence we gather suggests that, at least in this particular case study, there\nis a strong interplay between social bots and users engaging with unreliable\ncontent, influencing the diffusion of the latter across the network.", "doi": "", "date": "2021-06-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.15968v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 882715155, "title": "Characterizing Online Engagement with Disinformation and Conspiracies in\n  the 2020 U.S. Presidential Election", "abstract": "Identifying and characterizing disinformation in political discourse on\nsocial media is critical to ensure the integrity of elections and democratic\nprocesses around the world. Persistent manipulation of social media has\nresulted in increased concerns regarding the 2020 U.S. Presidential Election,\ndue to its potential to influence individual opinions and social dynamics. In\nthis work, we focus on the identification of distorted facts, in the form of\nunreliable and conspiratorial narratives in election-related tweets, to\ncharacterize discourse manipulation prior to the election. We apply a detection\nmodel to separate factual from unreliable (or conspiratorial) claims analyzing\na dataset of 242 million election-related tweets. The identified claims are\nused to investigate targeted topics of disinformation, and conspiracy groups,\nmost notably the far-right QAnon conspiracy group. Further, we characterize\naccount engagements with unreliable and conspiracy tweets, and with the QAnon\nconspiracy group, by political leaning and tweet types. Finally, using a\nregression discontinuity design, we investigate whether Twitter's actions to\ncurb QAnon activity on the platform were effective, and how QAnon accounts\nadapt to Twitter's restrictions.", "doi": "", "date": "2021-07-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.08319v1", "pdf": ""}, "publisher-venue": "ICWSM", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1358368017, "title": "Like Article, Like Audience: Enforcing Multimodal Correlations for\n  Disinformation Detection", "abstract": "User-generated content (e.g., tweets and profile descriptions) and shared\ncontent between users (e.g., news articles) reflect a user's online identity.\nThis paper investigates whether correlations between user-generated and\nuser-shared content can be leveraged for detecting disinformation in online\nnews articles. We develop a multimodal learning algorithm for disinformation\ndetection. The latent representations of news articles and user-generated\ncontent allow that during training the model is guided by the profile of users\nwho prefer content similar to the news article that is evaluated, and this\neffect is reinforced if that content is shared among different users. By only\nleveraging user information during model optimization, the model does not rely\non user profiling when predicting an article's veracity. The algorithm is\nsuccessfully applied to three widely used neural classifiers, and results are\nobtained on different datasets. Visualization techniques show that the proposed\nmodel learns feature representations of unseen news articles that better\ndiscriminate between fake and real news texts.", "doi": "", "date": "2021-08-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.13892v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 800414109, "title": "Coordinating Narratives and the Capitol Riots on Parler", "abstract": "Coordinated disinformation campaigns are used to influence social media\nusers, potentially leading to offline violence. In this study, we introduce a\ngeneral methodology to uncover coordinated messaging through analysis of user\nparleys on Parler. The proposed method constructs a user-to-user coordination\nnetwork graph induced by a user-to-text graph and a text-to-text similarity\ngraph. The text-to-text graph is constructed based on the textual similarity of\nParler posts. We study three influential groups of users in the 6 January 2020\nCapitol riots and detect networks of coordinated user clusters that are all\nposting similar textual content in support of different disinformation\nnarratives related to the U.S. 2020 elections.", "doi": "", "date": "2021-09-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2109.00945v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1133819203, "title": "Disinformation, Stochastic Harm, and Costly Filtering: A Principal-Agent\n  Analysis of Regulating Social Media Platforms", "abstract": "The spread of disinformation on social media platforms such as Facebook is\nharmful to society. This harm can take the form of a gradual degradation of\npublic discourse; but it can also take the form of sudden dramatic events such\nas the recent insurrection on Capitol Hill. The platforms themselves are in the\nbest position to prevent the spread of disinformation, as they have the best\naccess to relevant data and the expertise to use it. However, filtering\ndisinformation is costly, not only for implementing filtering algorithms or\nemploying manual filtering effort, but also because removing such highly viral\ncontent impacts user growth and thus potential advertising revenue. Since the\ncosts of harmful content are borne by other entities, the platform will\ntherefore have no incentive to filter at a socially-optimal level. This problem\nis similar to the problem of environmental regulation, in which the costs of\nadverse events are not directly borne by a firm, the mitigation effort of a\nfirm is not observable, and the causal link between a harmful consequence and a\nspecific failure is difficult to prove. In the environmental regulation domain,\none solution to this issue is to perform costly monitoring to ensure that the\nfirm takes adequate precautions according a specified rule. However,\nclassifying disinformation is performative, and thus a fixed rule becomes less\neffective over time. Encoding our domain as a Markov decision process, we\ndemonstrate that no penalty based on a static rule, no matter how large, can\nincentivize adequate filtering by the platform. Penalties based on an adaptive\nrule can incentivize optimal effort, but counterintuitively, only if the\nregulator sufficiently overreacts to harmful events by requiring a\ngreater-than-optimal level of filtering.", "doi": "", "date": "2021-06-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.09847v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3873516380, "title": "Characterizing networks of propaganda on Twitter: a case study", "abstract": "The daily exposure of social media users to propaganda and disinformation\ncampaigns has reinvigorated the need to investigate the local and global\npatterns of diffusion of different (mis)information content on social media.\nEcho chambers and influencers are often deemed responsible of both the\npolarization of users in online social networks and the success of propaganda\nand disinformation campaigns. This article adopts a data-driven approach to\ninvestigate the structuration of communities and propaganda networks on Twitter\nin order to assess the correctness of these imputations. In particular, the\nwork aims at characterizing networks of propaganda extracted from a Twitter\ndataset by combining the information gained by three different classification\napproaches, focused respectively on (i) using Tweets content to infer the\n\"polarization\" of users around a specific topic, (ii) identifying users having\nan active role in the diffusion of different propaganda and disinformation\nitems, and (iii) analyzing social ties to identify topological clusters and\nusers playing a \"central\" role in the network. The work identifies highly\npartisan community structures along political alignments; furthermore,\ncentrality metrics proved to be very informative to detect the most active\nusers in the network and to distinguish users playing different roles; finally,\npolarization and clustering structure of the retweet graphs provided useful\ninsights about relevant properties of users exposure, interactions, and\nparticipation to different propaganda items.", "doi": "10.1007/s41109-020-00286-y", "date": "2020-05-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.10004v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4006462552, "title": "Advanced Machine Learning Techniques for Fake News (Online\n  Disinformation) Detection: A Systematic Mapping Study", "abstract": "Fake news has now grown into a big problem for societies and also a major\nchallenge for people fighting disinformation. This phenomenon plagues\ndemocratic elections, reputations of individual persons or organizations, and\nhas negatively impacted citizens, (e.g., during the COVID-19 pandemic in the US\nor Brazil). Hence, developing effective tools to fight this phenomenon by\nemploying advanced Machine Learning (ML) methods poses a significant challenge.\nThe following paper displays the present body of knowledge on the application\nof such intelligent tools in the fight against disinformation. It starts by\nshowing the historical perspective and the current role of fake news in the\ninformation war. Proposed solutions based solely on the work of experts are\nanalysed and the most important directions of the application of intelligent\nsystems in the detection of misinformation sources are pointed out.\nAdditionally, the paper presents some useful resources (mainly datasets useful\nwhen assessing ML solutions for fake news detection) and provides a short\noverview of the most important R&D projects related to this subject. The main\npurpose of this work is to analyse the current state of knowledge in detecting\nfake news; on the one hand to show possible solutions, and on the other hand to\nidentify the main challenges and methodological gaps to motivate future\nresearch.", "doi": "", "date": "2020-12-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.01142v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3681306308, "title": "The disinformation problem for black holes (conference version)", "abstract": "Basic properties of black holes are explained in terms of trapping horizons.\nIt is shown that matter and information will escape from an evaporating black\nhole. A general scenario is outlined whereby a black hole evaporates completely\nwithout singularity, event horizon or loss of energy or information.", "doi": "", "date": "2005-04-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/gr-qc/0504037v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1649912166, "title": "The disinformation problem for black holes (pop version)", "abstract": "The supposed information paradox for black holes is based on the fundamental\nmisunderstanding that black holes are usefully defined by event horizons.\nUnderstood in terms of locally defined trapping horizons, the paradox\ndisappears: information will escape from an evaporating black hole. According\nto classical properties of trapping horizons, a general scenario is outlined\nwhereby a black hole evaporates completely without singularity, event horizon\nor loss of energy or information.", "doi": "", "date": "2005-04-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/gr-qc/0504038v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1129210658, "title": "Differences between Health Related News Articles from Reliable and\n  Unreliable Media", "abstract": "In this study, we examine a collection of health-related news articles\npublished by reliable and unreliable media outlets. Our analysis shows that\nthere are structural, topical, and semantic differences in the way reliable and\nunreliable media outlets conduct health journalism. We argue that the findings\nfrom this study will be useful for combating health disinformation problem.", "doi": "", "date": "2018-11-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.01852v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 940458288, "title": "Mapping (Dis-)Information Flow about the MH17 Plane Crash", "abstract": "Digital media enables not only fast sharing of information, but also\ndisinformation. One prominent case of an event leading to circulation of\ndisinformation on social media is the MH17 plane crash. Studies analysing the\nspread of information about this event on Twitter have focused on small,\nmanually annotated datasets, or used proxys for data annotation. In this work,\nwe examine to what extent text classifiers can be used to label data for\nsubsequent content analysis, in particular we focus on predicting pro-Russian\nand pro-Ukrainian Twitter content related to the MH17 plane crash. Even though\nwe find that a neural classifier improves over a hashtag based baseline,\nlabeling pro-Russian and pro-Ukrainian content with high precision remains a\nchallenging problem. We provide an error analysis underlining the difficulty of\nthe task and identify factors that might help improve classification in future\nwork. Finally, we show how the classifier can facilitate the annotation task\nfor human annotators.", "doi": "", "date": "2019-10-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.01363v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 644335054, "title": "\"Life never matters in the DEMOCRATS MIND\": Examining Strategies of\n  Retweeted Social Bots During a Mass Shooting Event", "abstract": "This exploratory study examines the strategies of social bots on Twitter that\nwere retweeted following a mass shooting event. Using a case study method to\nframe our work, we collected over seven million tweets during a one-month\nperiod following a mass shooting in Parkland, Florida. From this dataset, we\nselected retweets of content generated by over 400 social bot accounts to\ndetermine what strategies these bots were using and the effectiveness of these\nstrategies as indicated by the number of retweets. We employed qualitative and\nquantitative methods to capture both macro- and micro-level perspectives. Our\nfindings suggest that bots engage in more diverse strategies than solely waging\ndisinformation campaigns, including baiting and sharing information. Further,\nwe found that while bots amplify conversation about mass shootings, humans were\nprimarily responsible for disseminating bot-generated content. These findings\nadd depth to the current understanding of bot strategies and their\neffectiveness. Understanding these strategies can inform efforts to combat\ndubious information as well as more insidious disinformation campaigns.", "doi": "", "date": "2018-08-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.09325v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 609556415, "title": "Modelling election dynamics and the impact of disinformation", "abstract": "Complex dynamical systems driven by the unravelling of information can be\nmodelled effectively by treating the underlying flow of information as the\nmodel input. Complicated dynamical behaviour of the system is then derived as\nan output. Such an information-based approach is in sharp contrast to the\nconventional mathematical modelling of information-driven systems whereby one\nattempts to come up with essentially {\\it ad hoc} models for the outputs. Here,\ndynamics of electoral competition is modelled by the specification of the flow\nof information relevant to election. The seemingly random evolution of the\nelection poll statistics are then derived as model outputs, which in turn are\nused to study election prediction, impact of disinformation, and the optimal\nstrategy for information management in an election campaign.", "doi": "10.1007/s41884-019-00021-2", "date": "2019-04-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.12614v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1904703343, "title": "Determining Individual Origin Similarity (DInOS): Binary Classification\n  of Authors Using Stylometric Features", "abstract": "Author similarity and detection is an integral first step in detecting\nstate-led disinformation campaigns in an automated fashion. Current detection\ntechniques require an analyst or subject matter expert to hand-curate accounts.\nStylometric features have a rich history in identifying authorship of unknown\ndocuments, but little exploration has been done to compare authors to one\nanother. We have adapted a select handful of stylometric features for use in\nauthor similarity metrics, and show their >0.96 F-1 performance on a curated\nauthor classification task, across both traditional machine learning and deep\nlearning models. These features should contribute to the expanding field of\nauthor similarity research, and expedite the process of detecting and\nmitigating large-scale social media disinformation campaigns.", "doi": "", "date": "2019-12-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.03750v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2750273305, "title": "Proppy: A System to Unmask Propaganda in Online News", "abstract": "We present proppy, the first publicly available real-world, real-time\npropaganda detection system for online news, which aims at raising awareness,\nthus potentially limiting the impact of propaganda and helping fight\ndisinformation. The system constantly monitors a number of news sources,\ndeduplicates and clusters the news into events, and organizes the articles\nabout an event on the basis of the likelihood that they contain propagandistic\ncontent. The system is trained on known propaganda sources using a variety of\nstylistic features. The evaluation results on a standard dataset show\nstate-of-the-art results for propaganda detection.", "doi": "", "date": "2019-12-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.06810v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1882878235, "title": "A Dip Into a Deep Well: Online Political Advertisements, Valence, and\n  European Electoral Campaigning", "abstract": "Online political advertisements have become an important element in electoral\ncampaigning throughout the world. At the same time, concepts such as\ndisinformation and manipulation have emerged as a global concern. Although\nthese concepts are distinct from online political ads and data-driven electoral\ncampaigning, they tend to share a similar trait related to valence, the\nintrinsic attractiveness or averseness of a message. Given this background, the\npaper examines online political ads by using a dataset collected from Google's\ntransparency reports. The examination is framed to the mid-2019 situation in\nEurope, including the European Parliament elections in particular. According to\nthe results based on sentiment analysis of the textual ads displayed via\nGoogle's advertisement machinery, (i) most of the political ads have expressed\npositive sentiments, although these vary greatly between (ii) European\ncountries as well as across (iii) European political parties. In addition to\nthese results, the paper contributes to the timely discussion about data-driven\nelectoral campaigning and its relation to politics and democracy.", "doi": "10.1007/978-3-030-61841-4_3", "date": "2020-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.10622v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1187277667, "title": "Disinformation and Misinformation on Twitter during the Novel\n  Coronavirus Outbreak", "abstract": "As the novel coronavirus spread globally, a growing public panic was\nexpressed over the internet. We examine the public discussion concerning\nCOVID-19 on Twitter. We use a dataset of 67 million tweets from 12 million\nusers collected between January 29, 2020 and March 4, 2020. We categorize users\nbased on their home countries, social identities, and political orientation. We\nfind that news media, government officials, and individual news reporters\nposted a majority of influential tweets, while the most influential ones are\nstill written by regular users. Tweets mentioning \"fake news\" URLs and\ndisinformation story-lines are also more likely to be spread by regular users.\nUnlike real news and normal tweets, tweets containing URLs pointing to \"fake\nnews\" sites are most likely to be retweeted within the source country and so\nare less likely to spread internationally.", "doi": "", "date": "2020-06-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.04278v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2327494900, "title": "COVID-19 Misinformation and Disinformation on Social Networks -- The\n  Limits of Veritistic Countermeasures", "abstract": "The COVID-19 pandemic has been the subject of a vast amount of\nmisinformation, particularly in digital information environments, and major\nsocial media platforms recently publicized some of the countermeasures they are\nadopting. This presents an opportunity to examine the nature of the\nmisinformation and disinformation being produced, and the theoretical and\ntechnological paradigm used to counter it. I argue that this approach is based\non a conception of misinformation as epistemic pollution that can only justify\na limited and potentially inadequate response , and that some of the measures\nundertaken in practice outrun this. In fact, social networks manage ecological\nand architectural conditions that influence discourse on their platforms in\nways that should motivate reconsideration of the justifications that ground\nepistemic interventions to combat misinformation, and the types of intervention\nthat they warrant. The editorial role of platforms should not be framed solely\nas the management of epistemic pollution, but instead as managing the epistemic\nenvironment in which narratives and social epistemic processes take place.\nThere is an element of inevitable epistemic paternalism involved in this, and\nexploration of the independent constraints on its justifiability can help\ndetermine proper limits of its exercise in practice.", "doi": "", "date": "2020-08-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.00784v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 208239091, "title": "How Fake News Affect Trust in the Output of a Machine Learning System\n  for News Curation", "abstract": "People are increasingly consuming news curated by machine learning (ML)\nsystems. Motivated by studies on algorithmic bias, this paper explores which\nrecommendations of an algorithmic news curation system users trust and how this\ntrust is affected by untrustworthy news stories like fake news. In a study with\n82 vocational school students with a background in IT, we found that users are\nable to provide trust ratings that distinguish trustworthy recommendations of\nquality news stories from untrustworthy recommendations. However, a single\nuntrustworthy news story combined with four trustworthy news stories is rated\nsimilarly as five trustworthy news stories. The results could be a first\nindication that untrustworthy news stories benefit from appearing in a\ntrustworthy context. The results also show the limitations of users' abilities\nto rate the recommendations of a news curation system. We discuss the\nimplications of this for the user experience of interactive machine learning\nsystems.", "doi": "", "date": "2020-08-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.01988v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2086619452, "title": "Can We Spot the \"Fake News\" Before It Was Even Written?", "abstract": "Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n\"fake news.\" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.", "doi": "", "date": "2020-08-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.04374v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1020213400, "title": "FakeSafe: Human Level Data Protection by Disinformation Mapping using\n  Cycle-consistent Adversarial Network", "abstract": "The concept of disinformation is to use fake messages to confuse people in\norder to protect the real information. This strategy can be adapted into data\nscience to protect valuable private and sensitive data. Huge amount of private\ndata are being generated from personal devices such as smart phone and wearable\nin recent years. Being able to utilize these personal data will bring big\nopportunities to design personalized products, conduct precision healthcare and\nmany other tasks that were impossible in the past. However, due to privacy,\nsafety and regulation reasons, it is often difficult to transfer or store data\nin its original form while keeping them safe. Building a secure data transfer\nand storage infrastructure to preserving privacy is costly in most cases and\nthere is always a concern of data security due to human errors. In this study,\nwe propose a method, named FakeSafe, to provide human level data protection\nusing generative adversarial network with cycle consistency and conducted\nexperiments using both benchmark and real world data sets to illustrate\npotential applications of FakeSafe.", "doi": "", "date": "2020-11-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.11278v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 50718628, "title": "AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance\n  Detection for Fact Checking", "abstract": "With the continuing spread of misinformation and disinformation online, it is\nof increasing importance to develop combating mechanisms at scale in the form\nof automated systems that support multiple languages. One task of interest is\nclaim veracity prediction, which can be addressed using stance detection with\nrespect to relevant documents retrieved online. To this end, we present our new\nArabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from\na diverse set of sources comprising three fact-checking websites and one news\nwebsite. AraStance covers false and true claims from multiple domains (e.g.,\npolitics, sports, health) and several Arab countries, and it is well-balanced\nbetween related and unrelated documents with respect to the claims. We\nbenchmark AraStance, along with two other stance detection datasets, using a\nnumber of BERT-based models. Our best model achieves an accuracy of 85\\% and a\nmacro F1 score of 78\\%, which leaves room for improvement and reflects the\nchallenging nature of AraStance and the task of stance detection in general.", "doi": "", "date": "2021-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13559v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3066885166, "title": "Lumen: A Machine Learning Framework to Expose Influence Cues in Text", "abstract": "Phishing and disinformation are popular social engineering attacks with\nattackers invariably applying influence cues in texts to make them more\nappealing to users. We introduce Lumen, a learning-based framework that exposes\ninfluence cues in text: (i) persuasion, (ii) framing, (iii) emotion, (iv)\nobjectivity/subjectivity, (v) guilt/blame, and (vi) use of emphasis. Lumen was\ntrained with a newly developed dataset of 3K texts comprised of disinformation,\nphishing, hyperpartisan news, and mainstream news. Evaluation of Lumen in\ncomparison to other learning models showed that Lumen and LSTM presented the\nbest F1-micro score, but Lumen yielded better interpretability. Our results\nhighlight the promise of ML to expose influence cues in text, towards the goal\nof application in automatic labeling tools to improve the accuracy of\nhuman-based detection and reduce the likelihood of users falling for deceptive\nonline content.", "doi": "", "date": "2021-07-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.10655v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1025762333, "title": "Is it Fake? News Disinformation Detection on South African News Websites", "abstract": "Disinformation through fake news is an ongoing problem in our society and has\nbecome easily spread through social media. The most cost and time effective way\nto filter these large amounts of data is to use a combination of human and\ntechnical interventions to identify it. From a technical perspective, Natural\nLanguage Processing (NLP) is widely used in detecting fake news. Social media\ncompanies use NLP techniques to identify the fake news and warn their users,\nbut fake news may still slip through undetected. It is especially a problem in\nmore localised contexts (outside the United States of America). How do we\nadjust fake news detection systems to work better for local contexts such as in\nSouth Africa. In this work we investigate fake news detection on South African\nwebsites. We curate a dataset of South African fake news and then train\ndetection models. We contrast this with using widely available fake news\ndatasets (from mostly USA website). We also explore making the datasets more\ndiverse by combining them and observe the differences in behaviour in writing\nbetween nations' fake news using interpretable machine learning.", "doi": "", "date": "2021-08-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.02941v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 799083333, "title": "Fine-Tuned Neural Models for Propaganda Detection at the Sentence and\n  Fragment levels", "abstract": "This paper presents the CUNLP submission for the NLP4IF 2019 shared-task on\nFineGrained Propaganda Detection. Our system finished 5th out of 26 teams on\nthe sentence-level classification task and 5th out of 11 teams on the\nfragment-level classification task based on our scores on the blind test set.\nWe present our models, a discussion of our ablation studies and experiments,\nand an analysis of our performance on all eighteen propaganda techniques\npresent in the corpus of the shared task.", "doi": "10.18653/v1/d19-5013", "date": "2019-10-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.09702v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1118755165, "title": "The Impact of Cyber Security Threats on the 2020 US Elections", "abstract": "This paper will investigate the literature surrounding cyber security threats\nin the 2020 US Elections. It begins with a brief overview of cyber security and\nthe current state of cyber security regarding elections. In the main body of\nthe paper, the focus will be on the literature review of three main areas:\nvoter suppression, voter fraud, and disinformation, considering their impacts\non the outcome of the election and on the voting public. Having evaluated\nsources on each this paper concludes by summarising the areas which have had\nthe greatest impact on the 2020 US elections.", "doi": "", "date": "2020-12-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.08968v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1856992348, "title": "The Limited Reach of Fake News on Twitter during 2019 European Elections", "abstract": "The advent of social media changed the way we consume content favoring a\ndisintermediated access and production. This scenario has been matter of\ncritical discussion about its impact on society. Magnified in the case of Arab\nSpring or heavily criticized in the Brexit and 2016 U.S. elections. In this\nwork we explore information consumption on Twitter during the last European\nelectoral campaign by analyzing the interaction patterns of official news\nsources, fake news sources, politicians, people from the showbiz and many\nothers. We extensively explore interactions among different classes of accounts\nin the months preceding the last European elections, held between 23rd and 26th\nof May, 2019. We collected almost 400,000 tweets posted by 863 accounts having\ndifferent roles in the public society. Through a thorough quantitative analysis\nwe investigate the information flow among them, also exploiting geolocalized\ninformation. Accounts show the tendency to confine their interaction within the\nsame class and the debate rarely crosses national borders. Moreover, we do not\nfind any evidence of an organized network of accounts aimed at spreading\ndisinformation. Instead, disinformation outlets are largely ignored by the\nother actors and hence play a peripheral role in online political discussions.", "doi": "10.1371/journal.pone.0234689", "date": "2019-11-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.12039v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1229093304, "title": "Exploring the Role of Visual Content in Fake News Detection", "abstract": "The increasing popularity of social media promotes the proliferation of fake\nnews, which has caused significant negative societal effects. Therefore, fake\nnews detection on social media has recently become an emerging research area of\ngreat concern. With the development of multimedia technology, fake news\nattempts to utilize multimedia content with images or videos to attract and\nmislead consumers for rapid dissemination, which makes visual content an\nimportant part of fake news. Despite the importance of visual content, our\nunderstanding of the role of visual content in fake news detection is still\nlimited. This chapter presents a comprehensive review of the visual content in\nfake news, including the basic concepts, effective visual features,\nrepresentative detection methods and challenging issues of multimedia fake news\ndetection. This chapter can help readers to understand the role of visual\ncontent in fake news detection, and effectively utilize visual content to\nassist in detecting multimedia fake news.", "doi": "10.1007/978-3-030-42699-6", "date": "2020-03-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.05096v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2575820799, "title": "#ArsonEmergency and Australia's \"Black Summer\": Polarisation and\n  misinformation on social media", "abstract": "During the summer of 2019-20, while Australia suffered unprecedented\nbushfires across the country, false narratives regarding arson and limited\nbackburning spread quickly on Twitter, particularly using the hashtag\n#ArsonEmergency. Misinformation and bot- and troll-like behaviour were detected\nand reported by social media researchers and the news soon reached mainstream\nmedia. This paper examines the communication and behaviour of two polarised\nonline communities before and after news of the misinformation became public\nknowledge. Specifically, the Supporter community actively engaged with others\nto spread the hashtag, using a variety of news sources pushing the arson\nnarrative, while the Opposer community engaged less, retweeted more, and\nfocused its use of URLs to link to mainstream sources, debunking the narratives\nand exposing the anomalous behaviour. This influenced the content of the\nbroader discussion. Bot analysis revealed the active accounts were\npredominantly human, but behavioural and content analysis suggests Supporters\nengaged in trolling, though both communities used aggressive language.", "doi": "10.1007/978-3-030-61841-4_11", "date": "2020-04-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.00742v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1180303048, "title": "Fighting the COVID-19 Infodemic: Modeling the Perspective of\n  Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the\n  Society", "abstract": "With the emergence of the COVID-19 pandemic, the political and the medical\naspects of disinformation merged as the problem got elevated to a whole new\nlevel to become the first global infodemic. Fighting this infodemic is ranked\nsecond in the list of the most important focus areas of the World Health\nOrganization, with dangers ranging from promoting fake cures, rumors, and\nconspiracy theories to spreading xenophobia and panic. Addressing the issue\nrequires solving a number of challenging problems such as identifying messages\ncontaining claims, determining their check-worthiness and factuality, and their\npotential to do harm as well as the nature of that harm, to mention just a few.\nThus, here we design, annotate, and release to the research community a new\ndataset for fine-grained disinformation analysis that (i)focuses on COVID-19,\n(ii) combines the perspectives and the interests of journalists, fact-checkers,\nsocial media platforms, policy makers, and society as a whole, and (iii) covers\nboth English and Arabic. Finally, we show strong evaluation results using\nstate-of-the-art Transformers, thus confirming the practical utility of the\nannotation schema and of the dataset.", "doi": "", "date": "2020-04-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.00033v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1077276239, "title": "Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms", "abstract": "With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.", "doi": "", "date": "2020-07-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.07996v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 493443995, "title": "Detecting Cross-Modal Inconsistency to Defend Against Neural Fake News", "abstract": "Large-scale dissemination of disinformation online intended to mislead or\ndeceive the general population is a major societal problem. Rapid progression\nin image, video, and natural language generative models has only exacerbated\nthis situation and intensified our need for an effective defense mechanism.\nWhile existing approaches have been proposed to defend against neural fake\nnews, they are generally constrained to the very limited setting where articles\nonly have text and metadata such as the title and authors. In this paper, we\nintroduce the more realistic and challenging task of defending against\nmachine-generated news that also includes images and captions. To identify the\npossible weaknesses that adversaries can exploit, we create a NeuralNews\ndataset composed of 4 different types of generated articles as well as conduct\na series of human user study experiments based on this dataset. In addition to\nthe valuable insights gleaned from our user study experiments, we provide a\nrelatively effective approach based on detecting visual-semantic\ninconsistencies, which will serve as an effective first line of defense and a\nuseful reference for future work in defending against machine-generated\ndisinformation.", "doi": "", "date": "2020-09-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.07698v5", "pdf": ""}, "publisher-venue": "EMNLP 2020", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2730503010, "title": "Characterizing and Comparing COVID-19 Misinformation Across Languages,\n  Countries and Platforms", "abstract": "Misinformation/disinformation about COVID-19 has been rampant on social media\naround the world. In this study, we investigate COVID-19 misinformation/\ndisinformation on social media in multiple languages - Farsi (Persian),\nChinese, and English, about multiple countries - Iran, China, and the United\nStates (US), and on multiple platforms such as Twitter, Facebook, Instagram,\nWeibo, and WhatsApp. Misinformation, especially about a global pandemic, is a\nglobal problem yet it is common for studies of COVID-19 misinformation on\nsocial media to focus on a single language, like English, a single country,\nlike the US, or a single platform, like Twitter. We utilized opportunistic\nsampling to compile 200 specific items of viral and yet debunked misinformation\nacross these languages, countries and platforms emerged between January 1 and\nAugust 31. We then categorized this collection based both on the topics of the\nmisinformation and the underlying roots of that misinformation. Our\nmulti-cultural and multilingual team observed that the nature of COVID-19\nmisinformation on social media varied in substantial ways across different\nlanguages/countries depending on the cultures, beliefs/religions, popularity of\nsocial media, types of platforms, freedom of speech and the power of people\nversus governments. We observe that politics is at the root of most of the\ncollected misinformation across all three languages in this dataset. We further\nobserve the different impact of government restrictions on platforms and\nplatform restrictions on content in Iran, China, and the US and their impact on\na key question of our age: how do we control misinformation without silencing\nthe voices we need to hold governments accountable?", "doi": "", "date": "2020-10-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.06455v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 250185027, "title": "Challenges and Opportunities in Rapid Epidemic Information Propagation\n  with Live Knowledge Aggregation from Social Media", "abstract": "A rapidly evolving situation such as the COVID-19 pandemic is a significant\nchallenge for AI/ML models because of its unpredictability. %The most reliable\nindicator of the pandemic spreading has been the number of test positive cases.\nHowever, the tests are both incomplete (due to untested asymptomatic cases) and\nlate (due the lag from the initial contact event, worsening symptoms, and test\nresults). Social media can complement physical test data due to faster and\nhigher coverage, but they present a different challenge: significant amounts of\nnoise, misinformation and disinformation. We believe that social media can\nbecome good indicators of pandemic, provided two conditions are met. The first\n(True Novelty) is the capture of new, previously unknown, information from\nunpredictably evolving situations. The second (Fact vs. Fiction) is the\ndistinction of verifiable facts from misinformation and disinformation. Social\nmedia information that satisfy those two conditions are called live knowledge.\nWe apply evidence-based knowledge acquisition (EBKA) approach to collect,\nfilter, and update live knowledge through the integration of social media\nsources with authoritative sources. Although limited in quantity, the reliable\ntraining data from authoritative sources enable the filtering of misinformation\nas well as capturing truly new information. We describe the EDNA/LITMUS tools\nthat implement EBKA, integrating social media such as Twitter and Facebook with\nauthoritative sources such as WHO and CDC, creating and updating live knowledge\non the COVID-19 pandemic.", "doi": "", "date": "2020-11-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.05416v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3603342703, "title": "Edited Media Understanding: Reasoning About Implications of Manipulated\n  Images", "abstract": "Multimodal disinformation, from `deepfakes' to simple edits that deceive, is\nan important societal problem. Yet at the same time, the vast majority of media\nedits are harmless -- such as a filtered vacation photo. The difference between\nthis example, and harmful edits that spread disinformation, is one of intent.\nRecognizing and describing this intent is a major challenge for today's AI\nsystems.\n  We present the task of Edited Media Understanding, requiring models to answer\nopen-ended questions that capture the intent and implications of an image edit.\nWe introduce a dataset for our task, EMU, with 48k question-answer pairs\nwritten in rich natural language. We evaluate a wide variety of\nvision-and-language models for our task, and introduce a new model PELICAN,\nwhich builds upon recent progress in pretrained multimodal representations. Our\nmodel obtains promising results on our dataset, with humans rating its answers\nas accurate 40.35% of the time. At the same time, there is still much work to\nbe done -- humans prefer human-annotated captions 93.56% of the time -- and we\nprovide analysis that highlights areas for further progress.", "doi": "", "date": "2020-12-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.04726v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3822613519, "title": "The Role of Context in Detecting Previously Fact-Checked Claims", "abstract": "Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.", "doi": "", "date": "2021-04-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.07423v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3448313321, "title": "Towards Explainable Fact Checking", "abstract": "The past decade has seen a substantial rise in the amount of mis- and\ndisinformation online, from targeted disinformation campaigns to influence\npolitics, to the unintentional spreading of misinformation about public health.\nThis development has spurred research in the area of automatic fact checking,\nfrom approaches to detect check-worthy claims and determining the stance of\ntweets towards claims, to methods to determine the veracity of claims given\nevidence documents. These automatic methods are often content-based, using\nnatural language processing methods, which in turn utilise deep neural networks\nto learn higher-order features from text in order to make predictions. As deep\nneural networks are black-box models, their inner workings cannot be easily\nexplained. At the same time, it is desirable to explain how they arrive at\ncertain decisions, especially if they are to be used for decision making. While\nthis has been known for some time, the issues this raises have been exacerbated\nby models increasing in size, and by EU legislation requiring models to be used\nfor decision making to provide explanations, and, very recently, by legislation\nrequiring online platforms operating in the EU to provide transparent reporting\non their services. Despite this, current solutions for explainability are still\nlacking in the area of fact checking. This thesis presents my research on\nautomatic fact checking, including claim check-worthiness detection, stance\ndetection and veracity prediction. Its contributions go beyond fact checking,\nwith the thesis proposing more general machine learning solutions for natural\nlanguage processing in the area of learning with limited labelled data.\nFinally, the thesis presents some first solutions for explainable fact\nchecking.", "doi": "", "date": "2021-08-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.10274v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1047843740, "title": "Disinformation Warfare: Understanding State-Sponsored Trolls on Twitter\n  and Their Influence on the Web", "abstract": "Over the past couple of years, anecdotal evidence has emerged linking\ncoordinated campaigns by state-sponsored actors with efforts to manipulate\npublic opinion on the Web, often around major political events, through\ndedicated accounts, or \"trolls.\" Although they are often involved in spreading\ndisinformation on social media, there is little understanding of how these\ntrolls operate, what type of content they disseminate, and most importantly\ntheir influence on the information ecosystem.\n  In this paper, we shed light on these questions by analyzing 27K tweets\nposted by 1K Twitter users identified as having ties with Russia's Internet\nResearch Agency and thus likely state-sponsored trolls. We compare their\nbehavior to a random set of Twitter users, finding interesting differences in\nterms of the content they disseminate, the evolution of their account, as well\nas their general behavior and use of Twitter. Then, using Hawkes Processes, we\nquantify the influence that trolls had on the dissemination of news on social\nplatforms like Twitter, Reddit, and 4chan. Overall, our findings indicate that\nRussian trolls managed to stay active for long periods of time and to reach a\nsubstantial number of Twitter users with their tweets. When looking at their\nability of spreading news content and making it viral, however, we find that\ntheir effect on social platforms was minor, with the significant exception of\nnews published by the Russian state-sponsored news outlet RT (Russia Today).", "doi": "", "date": "2018-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1801.09288v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1769063860, "title": "Russian trolls speaking Russian: Regional Twitter operations and MH17", "abstract": "The role of social media in promoting media pluralism was initially viewed as\nwholly positive. However, some governments are allegedly manipulating social\nmedia by hiring online commentators (also known as trolls) to spread propaganda\nand disinformation. In particular, an alleged system of professional trolls\noperating both domestically and internationally exists in Russia. In 2018,\nTwitter released data on accounts identified as Russian trolls, starting a wave\nof research. However, while foreign-targeted English language operations of\nthese trolls have received significant attention, no research has analyzed\ntheir Russian language domestic and regional-targeted activities. We address\nthis gap by characterizing the Russian-language operations of Russian trolls.\nWe first perform a descriptive analysis, and then focus in on the trolls'\noperation related to the crash of Malaysia Airlines flight MH17.\n  Among other things, we find that Russian-language trolls have run 163 hashtag\ncampaigns (where hashtag use grows abruptly within a month). The main political\nsentiments of such campaigns were praising Russia and Putin (29%), criticizing\nUkraine (26%), and criticizing the United States and Obama (9%). Further,\ntrolls actively reshared information with 76% of tweets being retweets or\ncontaining a URL. Additionally, we observe periodic temporal patterns of\ntweeting suggesting that trolls use automation tools. Further, we find that\ntrolls' information campaign on the MH17 crash was the largest in terms of\ntweet count. However, around 68% of tweets posted with MH17 hashtags were\nlikely used simply for hashtag amplification. With these tweets excluded, about\n49% of the tweets suggested to varying levels that Ukraine was responsible for\nthe crash, and only 13% contained disinformation and propaganda presented as\nnews. Interestingly, trolls promoted inconsistent alternative theories for the\ncrash.", "doi": "10.1145/3394231.3397898", "date": "2020-05-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.06558v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2496482502, "title": "Junk News on Military Affairs and National Security: Social Media\n  Disinformation Campaigns Against US Military Personnel and Veterans", "abstract": "Social media provides political news and information for both active duty\nmilitary personnel and veterans. We analyze the subgroups of Twitter and\nFacebook users who spend time consuming junk news from websites that target US\nmilitary personnel and veterans with conspiracy theories, misinformation, and\nother forms of junk news about military affairs and national security issues.\n(1) Over Twitter we find that there are significant and persistent interactions\nbetween current and former military personnel and a broad network of extremist,\nRussia-focused, and international conspiracy subgroups. (2) Over Facebook, we\nfind significant and persistent interactions between public pages for military\nand veterans and subgroups dedicated to political conspiracy, and both sides of\nthe political spectrum. (3) Over Facebook, the users who are most interested in\nconspiracy theories and the political right seem to be distributing the most\njunk news, whereas users who are either in the military or are veterans are\namong the most sophisticated news consumers, and share very little junk news\nthrough the network.", "doi": "", "date": "2018-02-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1802.03572v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 812375695, "title": "Sorry: Ambient Tactical Deception Via Malware-Based Social Engineering", "abstract": "In this paper we argue, drawing from the perspectives of cybersecurity and\nsocial psychology, that Internet-based manipulation of an individual or group\nreality using ambient tactical deception is possible using only software and\nchanging words in a web browser. We call this attack Ambient Tactical Deception\n(ATD). Ambient, in artificial intelligence, describes software that is\n\"unobtrusive,\" and completely integrated into a user's life. Tactical deception\nis an information warfare term for the use of deception on an opposing force.\nWe suggest that an ATD attack could change the sentiment of text in a web\nbrowser. This could alter the victim's perception of reality by providing\ndisinformation. Within the limit of online communication, even a pause in\nreplying to a text can affect how people perceive each other. The outcomes of\nan ATD attack could include alienation, upsetting a victim, and influencing\ntheir feelings about an election, a spouse, or a corporation.", "doi": "", "date": "2018-10-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1810.11063v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 342079092, "title": "Quantifying Biases in Online Information Exposure", "abstract": "Our consumption of online information is mediated by filtering, ranking, and\nrecommendation algorithms that introduce unintentional biases as they attempt\nto deliver relevant and engaging content. It has been suggested that our\nreliance on online technologies such as search engines and social media may\nlimit exposure to diverse points of view and make us vulnerable to manipulation\nby disinformation. In this paper, we mine a massive dataset of Web traffic to\nquantify two kinds of bias: (i) homogeneity bias, which is the tendency to\nconsume content from a narrow set of information sources, and (ii) popularity\nbias, which is the selective exposure to content from top sites. Our analysis\nreveals different bias levels across several widely used Web platforms. Search\nexposes users to a diverse set of sources, while social media traffic tends to\nexhibit high popularity and homogeneity bias. When we focus our analysis on\ntraffic to news sites, we find higher levels of popularity bias, with smaller\ndifferences across applications. Overall, our results quantify the extent to\nwhich our choices of online systems confine us inside \"social bubbles.\"", "doi": "10.1002/asi.24121", "date": "2018-07-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1807.06958v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3722193216, "title": "From Senseless Swarms to Smart Mobs: Tuning Networks for Prosocial\n  Behaviour", "abstract": "Social media have been seen to accelerate the spread of negative content such\nas disinformation and hate speech, often unleashing reckless herd mentality\nwithin networks, further aggravated by malicious entities using bots for\namplification. So far, the response to this emerging global crisis has centred\naround social media platform companies making reactive moves that appear to\nhave greater symbolic value than practical utility. These include taking down\npatently objectionable content or manually deactivating the accounts of bad\nactors, while leaving vast troves of negative content to circulate and\nperpetuate within social networks. Governments worldwide have thus sought to\nintervene using regulatory tools, with countries such as France, Germany and\nSingapore introducing laws to compel technology companies to take down or\ncorrect erroneous and harmful content. However, the relentless pace of\ntechnological progress enfeebles regulatory measures that seem fated for\nobsolescence.", "doi": "", "date": "2019-10-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.01303v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1399364541, "title": "Predicting the Leading Political Ideology of YouTube Channels Using\n  Acoustic, Textual, and Metadata Information", "abstract": "We address the problem of predicting the leading political ideology, i.e.,\nleft-center-right bias, for YouTube channels of news media. Previous work on\nthe problem has focused exclusively on text and on analysis of the language\nused, topics discussed, sentiment, and the like. In contrast, here we study\nvideos, which yields an interesting multimodal setup. Starting with gold\nannotations about the leading political ideology of major world news media from\nMedia Bias/Fact Check, we searched on YouTube to find their corresponding\nchannels, and we downloaded a recent sample of videos from each channel. We\ncrawled more than 1,000 YouTube hours along with the corresponding subtitles\nand metadata, thus producing a new multimodal dataset. We further developed a\nmultimodal deep-learning architecture for the task. Our analysis shows that the\nuse of acoustic signal helped to improve bias detection by more than 6%\nabsolute over using text and metadata only. We release the dataset to the\nresearch community, hoping to help advance the field of multi-modal political\nbias detection.", "doi": "", "date": "2019-10-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.08948v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2205795310, "title": "Findings of the NLP4IF-2019 Shared Task on Fine-Grained Propaganda\n  Detection", "abstract": "We present the shared task on Fine-Grained Propaganda Detection, which was\norganized as part of the NLP4IF workshop at EMNLP-IJCNLP 2019. There were two\nsubtasks. FLC is a fragment-level task that asks for the identification of\npropagandist text fragments in a news article and also for the prediction of\nthe specific propaganda technique used in each such fragment (18-way\nclassification task). SLC is a sentence-level binary classification task asking\nto detect the sentences that contain propaganda. A total of 12 teams submitted\nsystems for the FLC task, 25 teams did so for the SLC task, and 14 teams\neventually submitted a system description paper. For both subtasks, most\nsystems managed to beat the baseline by a sizable margin. The leaderboard and\nthe data from the competition are available at\nhttp://propaganda.qcri.org/nlp4if-shared-task/.", "doi": "", "date": "2019-10-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.09982v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1491447155, "title": "Detecting GAN-generated Imagery using Color Cues", "abstract": "Image forensics is an increasingly relevant problem, as it can potentially\naddress online disinformation campaigns and mitigate problematic aspects of\nsocial media. Of particular interest, given its recent successes, is the\ndetection of imagery produced by Generative Adversarial Networks (GANs), e.g.\n`deepfakes'. Leveraging large training sets and extensive computing resources,\nrecent work has shown that GANs can be trained to generate synthetic imagery\nwhich is (in some ways) indistinguishable from real imagery. We analyze the\nstructure of the generating network of a popular GAN implementation, and show\nthat the network's treatment of color is markedly different from a real camera\nin two ways. We further show that these two cues can be used to distinguish\nGAN-generated imagery from camera imagery, demonstrating effective\ndiscrimination between GAN imagery and real camera images used to train the\nGAN.", "doi": "", "date": "2018-12-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.08247v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2719518042, "title": "Using Blockchain to Rein in The New Post-Truth World and Check The\n  Spread of Fake News", "abstract": "In recent years, `fake news' has become a global issue that raises\nunprecedented challenges for human society and democracy. This problem has\narisen due to the emergence of various concomitant phenomena such as (1) the\ndigitization of human life and the ease of disseminating news through social\nnetworking applications (such as Facebook and WhatsApp); (2) the availability\nof `big data' that allows customization of news feeds and the creation of\npolarized so-called `filter-bubbles'; and (3) the rapid progress made by\ngenerative machine learning (ML) and deep learning (DL) algorithms in creating\nrealistic-looking yet fake digital content (such as text, images, and videos).\nThere is a crucial need to combat the rampant rise of fake news and\ndisinformation. In this paper, we propose a high-level overview of a\nblockchain-based framework for fake news prevention and highlight the various\ndesign issues and consideration of such a blockchain-based framework for\ntackling fake news.", "doi": "", "date": "2019-03-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.11899v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3617690783, "title": "An End-to-End Framework to Identify Pathogenic Social Media Accounts on\n  Twitter", "abstract": "Pathogenic Social Media (PSM) accounts such as terrorist supporter accounts\nand fake news writers have the capability of spreading disinformation to viral\nproportions. Early detection of PSM accounts is crucial as they are likely to\nbe key users to make malicious information \"viral\". In this paper, we adopt the\ncausal inference framework along with graph-based metrics in order to\ndistinguish PSMs from normal users within a short time of their activities. We\npropose both supervised and semi-supervised approaches without taking the\nnetwork information and content into account. Results on a real-world dataset\nfrom Twitter accentuates the advantage of our proposed frameworks. We show our\napproach achieves 0.28 improvement in F1 score over existing approaches with\nthe precision of 0.90 and F1 score of 0.63.", "doi": "", "date": "2019-05-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.01553v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 906688158, "title": "Anti-Latinx Computational Propaganda in the United States", "abstract": "Given that the Latino community is the second largest ethnic group in the US,\nan understanding of how Latinos are discussed and targeted on social media\nduring US elections is crucial. This paper explores these questions through a\ndata analysis on Reddit, one of the most prominent and popular social media\nplatforms for political discussion. We collected Reddit posts mentioning\nLatinos and the US midterm elections from September 24, 2017 to September 24,\n2018. We analyzed people's posting patterns over time, and the digital traces\nof the individuals posting the majority of content and the most popular\ncontent. Our research highlights data voids that existed in online discussions\nsurrounding Latinos prior to the US midterm elections. We observe a lack of\nneutral actors engaging Latinos in political topics. It appears that it is the\nmore extremist voices (i.e. individuals operating within subreddits who\nidentify themselves as political trolls) who are creating the most political\ncontent about Latinos. We conclude our report with a discussion of the possible\ndangers of data voids (especially with regard to their ties to mis- and\ndisinformation) and recommendations to increase the involvement of the Latino\ncommunity in future US elections.", "doi": "", "date": "2019-06-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.10736v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2335640016, "title": "Deception Strategies and Threats for Online Discussions", "abstract": "Communication plays a major role in social systems. Effective communications,\nwhich requires transmission of the messages between individuals without\ndisruptions or noise, can be a powerful tool to deliver intended impact.\nLanguage and style of the content can be leveraged to deceive and manipulate\nrecipients. These deception and persuasion strategies can be applied to exert\npower and amass capital in politics and business. In this work, we provide a\nmodest review of how such deception and persuasion strategies were applied to\ndifferent communication channels over the years. We provide examples of\ncampaigns that has occurred in different periods over the last 100 years,\ntogether with their corresponding dissemination mediums. In the Internet age,\nwe enjoy access to the vast amount of information and the ability to\ncommunicate without borders. However, malicious actors work toward abusing\nonline systems to disseminate disinformation, disrupt communication, and\nmanipulate people by the means of automated tools, such as social bots. It is\nimportant to study the old practices of persuasion to be able to investigate\nmodern practices and tools. Here we provide a discussion of current threats\nagainst society while drawing parallels with the historical practices and the\nrecent research efforts on systems of detection and prevention.", "doi": "10.5210/fm.v22i5.7883", "date": "2019-06-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.11371v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1845854794, "title": "Understanding BERT performance in propaganda analysis", "abstract": "In this paper, we describe our system used in the shared task for\nfine-grained propaganda analysis at sentence level. Despite the challenging\nnature of the task, our pretrained BERT model (team YMJA) fine tuned on the\ntraining dataset provided by the shared task scored 0.62 F1 on the test set and\nranked third among 25 teams who participated in the contest. We present a set\nof illustrative experiments to better understand the performance of our BERT\nmodel on this shared task. Further, we explore beyond the given dataset for\nfalse-positive cases that likely to be produced by our system. We show that\ndespite the high performance on the given testset, our system may have the\ntendency of classifying opinion pieces as propaganda and cannot distinguish\nquotations of propaganda speech from actual usage of propaganda techniques.", "doi": "10.18653/v1/d19-5019", "date": "2019-11-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.04525v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 767577524, "title": "Exploiting Human Social Cognition for the Detection of Fake and\n  Fraudulent Faces via Memory Networks", "abstract": "Advances in computer vision have brought us to the point where we have the\nability to synthesise realistic fake content. Such approaches are seen as a\nsource of disinformation and mistrust, and pose serious concerns to governments\naround the world. Convolutional Neural Networks (CNNs) demonstrate encouraging\nresults when detecting fake images that arise from the specific type of\nmanipulation they are trained on. However, this success has not transitioned to\nunseen manipulation types, resulting in a significant gap in the\nline-of-defense. We propose a Hierarchical Memory Network (HMN) architecture,\nwhich is able to successfully detect faked faces by utilising knowledge stored\nin neural memories as well as visual cues to reason about the perceived face\nand anticipate its future semantic embeddings. This renders a generalisable\nface tampering detection framework. Experimental results demonstrate the\nproposed approach achieves superior performance for fake and fraudulent face\ndetection compared to the state-of-the-art.", "doi": "", "date": "2019-11-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.07844v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3292608628, "title": "The Pushshift Telegram Dataset", "abstract": "Messaging platforms, especially those with a mobile focus, have become\nincreasingly ubiquitous in society. These mobile messaging platforms can have\ndeceivingly large user bases, and in addition to being a way for people to stay\nin touch, are often used to organize social movements, as well as a place for\nextremists and other ne'er-do-well to congregate. In this paper, we present a\ndataset from one such mobile messaging platform: Telegram. Our dataset is made\nup of over 27.8K channels and 317M messages from 2.2M unique users. To the best\nof our knowledge, our dataset comprises the largest and most complete of its\nkind. In addition to the raw data, we also provide the source code used to\ncollect it, allowing researchers to run their own data collection instance. We\nbelieve the Pushshift Telegram dataset can help researchers from a variety of\ndisciplines interested in studying online social movements, protests, political\nextremism, and disinformation.", "doi": "", "date": "2020-01-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.08438v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3270586594, "title": "Untrue.News: A New Search Engine For Fake Stories", "abstract": "In this paper, we demonstrate Untrue News, a new search engine for fake\nstories. Untrue News is easy to use and offers useful features such as: a) a\nmulti-language option combining fake stories from different countries and\nlanguages around the same subject or person; b) an user privacy protector,\navoiding the filter bubble by employing a bias-free ranking scheme; and c) a\ncollaborative platform that fosters the development of new tools for fighting\ndisinformation. Untrue News relies on Elasticsearch, a new scalable analytic\nsearch engine based on the Lucene library that provides near real-time results.\nWe demonstrate two key scenarios: the first related to a politician - looking\nhow the categories are shown for different types of fake stories - and a second\nrelated to a refugee - showing the multilingual tool. A prototype of Untrue\nNews is accessible via http://untrue.news", "doi": "", "date": "2020-02-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.06585v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3512102621, "title": "Adversarial Deepfakes: Evaluating Vulnerability of Deepfake Detectors to\n  Adversarial Examples", "abstract": "Recent advances in video manipulation techniques have made the generation of\nfake videos more accessible than ever before. Manipulated videos can fuel\ndisinformation and reduce trust in media. Therefore detection of fake videos\nhas garnered immense interest in academia and industry. Recently developed\nDeepfake detection methods rely on deep neural networks (DNNs) to distinguish\nAI-generated fake videos from real videos. In this work, we demonstrate that it\nis possible to bypass such detectors by adversarially modifying fake videos\nsynthesized using existing Deepfake generation methods. We further demonstrate\nthat our adversarial perturbations are robust to image and video compression\ncodecs, making them a real-world threat. We present pipelines in both white-box\nand black-box attack scenarios that can fool DNN based Deepfake detectors into\nclassifying fake videos as real.", "doi": "", "date": "2020-02-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.12749v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1574877969, "title": "Discover Your Social Identity from What You Tweet: a Content Based\n  Approach", "abstract": "An identity denotes the role an individual or a group plays in highly\ndifferentiated contemporary societies. In this paper, our goal is to classify\nTwitter users based on their role identities. We first collect a coarse-grained\npublic figure dataset automatically, then manually label a more fine-grained\nidentity dataset. We propose a hierarchical self-attention neural network for\nTwitter user role identity classification. Our experiments demonstrate that the\nproposed model significantly outperforms multiple baselines. We further propose\na transfer learning scheme that improves our model's performance by a large\nmargin. Such transfer learning also greatly reduces the need for a large amount\nof human labeled data.", "doi": "10.1007/978-3-030-42699-6", "date": "2020-03-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.01797v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3388776645, "title": "A Longitudinal Analysis of YouTube's Promotion of Conspiracy Videos", "abstract": "Conspiracy theories have flourished on social media, raising concerns that\nsuch content is fueling the spread of disinformation, supporting extremist\nideologies, and in some cases, leading to violence. Under increased scrutiny\nand pressure from legislators and the public, YouTube announced efforts to\nchange their recommendation algorithms so that the most egregious conspiracy\nvideos are demoted and demonetized. To verify this claim, we have developed a\nclassifier for automatically determining if a video is conspiratorial (e.g.,\nthe moon landing was faked, the pyramids of Giza were built by aliens, end of\nthe world prophecies, etc.). We coupled this classifier with an emulation of\nYouTube's watch-next algorithm on more than a thousand popular informational\nchannels to obtain a year-long picture of the videos actively promoted by\nYouTube. We also obtained trends of the so-called filter-bubble effect for\nconspiracy theories.", "doi": "", "date": "2020-03-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.03318v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1794433056, "title": "Hate multiverse spreads malicious COVID-19 content online beyond\n  individual platform control", "abstract": "We show that malicious COVID-19 content, including hate speech,\ndisinformation, and misinformation, exploits the multiverse of online hate to\nspread quickly beyond the control of any individual social media platform.\nMachine learning topic analysis shows quantitatively how online hate\ncommunities are weaponizing COVID-19, with topics evolving rapidly and content\nbecoming increasingly coherent. Our mathematical analysis provides a\ngeneralized form of the public health R0 predicting the tipping point for\nmultiverse-wide viral spreading, which suggests new policy options to mitigate\nthe global spread of malicious COVID-19 content without relying on future\ncoordination between all online platforms.", "doi": "", "date": "2020-04-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.00673v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1236175480, "title": "Probabilistic Model of Narratives Over Topical Trends in Social Media: A\n  Discrete Time Model", "abstract": "Online social media platforms are turning into the prime source of news and\nnarratives about worldwide events. However,a systematic summarization-based\nnarrative extraction that can facilitate communicating the main underlying\nevents is lacking. To address this issue, we propose a novel event-based\nnarrative summary extraction framework. Our proposed framework is designed as a\nprobabilistic topic model, with categorical time distribution, followed by\nextractive text summarization. Our topic model identifies topics' recurrence\nover time with a varying time resolution. This framework not only captures the\ntopic distributions from the data, but also approximates the user activity\nfluctuations over time. Furthermore, we define significance-dispersity\ntrade-off (SDT) as a comparison measure to identify the topic with the highest\nlifetime attractiveness in a timestamped corpus. We evaluate our model on a\nlarge corpus of Twitter data, including more than one million tweets in the\ndomain of the disinformation campaigns conducted against the White Helmets of\nSyria. Our results indicate that the proposed framework is effective in\nidentifying topical trends, as well as extracting narrative summaries from text\ncorpus with timestamped data.", "doi": "10.1145/3372923.3404790", "date": "2020-04-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.06793v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1242241084, "title": "In-store epidemic behavior: scale development and validation", "abstract": "Epidemics of infectious diseases have accompanied humans for a long time and,\ndepending on the scale, cause various undesirable social and economic\nconsequences. During the ongoing COVID-19 pandemic, governments of many\ncountries impose restrictions to inhibit spreading of infection. Isolation and\nlimiting interpersonal contacts are particularly recommended actions. Adhering\nto the rule of isolation may involve restrictions in freedom during daily\nactivities, such as shopping. The aim of the study was to develop a scale of\nin-store pandemic behavior. The whole process involved 3 stages: qualitative\ninquiry, scale purification and scale validation, which were based on 3\nstudies: 1 qualitative (20 in-depth interviews) 2 two quantitative (373 and 584\nrespondents, respectively), and allowed to identify 8 factors. Following, a\ntheoretical model was created to investigate the impact of in-store infection\nthreat on identified variables. All identified factors significantly correlated\nwith the in-store infection threat which reiterates the importance of providing\ninformation revealing the true scale of the pandemic and not leaving space for\nindividuals to create subjective probability judgments. The developed scale can\nhelp counteract disinformation and assess consumer behavior compliance and\nunderstanding of the official recommendations imposed by governments, enabling\nmore efficient educational efforts.", "doi": "", "date": "2020-05-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.02764v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3260825919, "title": "Cognitive Analysis of Security Threats on Social Networking Services:\n  Slovakia in need of stronger action", "abstract": "This short paper examines some of the ongoing research at the UMB Data and\nSociety Lab hosted at the Faculty of Political Science and International\nRelations at Matej Bel University. It begins with an introduction on the\nnecessity of security threat identification on social networking services\n(SNSs), done by states. The paper follows with a general overview of selected\nprojects of the Lab in this field, and afterwards it introduces a use case\nstudy focused on the announcement of the UK snap general election 2017. The\nmain aim of this paper is to demonstrate some of the possibilities of social\nnetworking services analysis in the field of international relations, with an\nemphasis on disinformation and the necessity of identifying novel digital\nactors in Slovakia. We also outline an easy custom system tasked to collect\nsocial media data, and afterwards process it using various cognitive analytic\nmethods.", "doi": "", "date": "2020-05-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.08618v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 482586862, "title": "A Survey on Computational Propaganda Detection", "abstract": "Propaganda campaigns aim at influencing people's mindset with the purpose of\nadvancing a specific agenda. They exploit the anonymity of the Internet, the\nmicro-profiling ability of social networks, and the ease of automatically\ncreating and managing coordinated networks of accounts, to reach millions of\nsocial network users with persuasive messages, specifically targeted to topics\neach individual user is sensitive to, and ultimately influencing the outcome on\na targeted issue. In this survey, we review the state of the art on\ncomputational propaganda detection from the perspective of Natural Language\nProcessing and Network Analysis, arguing about the need for combined efforts\nbetween these communities. We further discuss current challenges and future\nresearch directions.", "doi": "", "date": "2020-07-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.08024v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1769981389, "title": "aschern at SemEval-2020 Task 11: It Takes Three to Tango: RoBERTa, CRF,\n  and Transfer Learning", "abstract": "We describe our system for SemEval-2020 Task 11 on Detection of Propaganda\nTechniques in News Articles. We developed ensemble models using RoBERTa-based\nneural architectures, additional CRF layers, transfer learning between the two\nsubtasks, and advanced post-processing to handle the multi-label nature of the\ntask, the consistency between nested spans, repetitions, and labels from\nsimilar spans in training. We achieved sizable improvements over baseline\nfine-tuned RoBERTa models, and the official evaluation ranked our system 3rd\n(almost tied with the 2nd) out of 36 teams on the span identification subtask\nwith an F1 score of 0.491, and 2nd (almost tied with the 1st) out of 31 teams\non the technique classification subtask with an F1 score of 0.62.", "doi": "", "date": "2020-08-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.02837v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 903954629, "title": "Coordinated Behavior on Social Media in 2019 UK General Election", "abstract": "Coordinated online behaviors are an essential part of information and\ninfluence operations, as they allow a more effective disinformation's spread.\nMost studies on coordinated behaviors involved manual investigations, and the\nfew existing computational approaches make bold assumptions or oversimplify the\nproblem to make it tractable. Here, we propose a new network-based framework\nfor uncovering and studying coordinated behaviors on social media. Our research\nextends existing systems and goes beyond limiting binary classifications of\ncoordinated and uncoordinated behaviors. It allows to expose different\ncoordination patterns and to estimate the degree of coordination that\ncharacterizes diverse communities. We apply our framework to a dataset\ncollected during the 2019 UK General Election, detecting and characterizing\ncoordinated communities that participated in the electoral debate. Our work\nconveys both theoretical and practical implications and provides more nuanced\nand fine-grained results for studying online information manipulation.", "doi": "", "date": "2020-08-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.08370v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1620735892, "title": "Social Cybersecurity Chapter 13: Casestudy with COVID-19 Pandemic", "abstract": "The purpose of this case study is to leverage the concepts and tools\npresented in the preceding chapters and apply them in a real world social\ncybersecurity context. With the COVID-19 pandemic emerging as a defining event\nof the 21st Century and a magnet for disinformation maneuver, we have selected\nthe pandemic and its related social media conversation to focus our efforts on.\nThis chapter therefore applies the tools of information operation maneuver, bot\ndetection and characterization, meme detection and characterization, and\ninformation mapping to the COVID-19 related conversation on Twitter. This\nchapter uses these tools to analyze a stream containing 206 million tweets from\n27 million unique users from 15 March 2020 to 30 April 2020. Our results shed\nlight on elaborate information operations that leverage the full breadth of the\nBEND maneuvers and use bots for important shaping operations.", "doi": "", "date": "2020-08-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.10102v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1501327143, "title": "The Radicalization Risks of GPT-3 and Advanced Neural Language Models", "abstract": "In this paper, we expand on our previous research of the potential for abuse\nof generative language models by assessing GPT-3. Experimenting with prompts\nrepresentative of different types of extremist narrative, structures of social\ninteraction, and radical ideologies, we find that GPT-3 demonstrates\nsignificant improvement over its predecessor, GPT-2, in generating extremist\ntexts. We also show GPT-3's strength in generating text that accurately\nemulates interactive, informational, and influential content that could be\nutilized for radicalizing individuals into violent far-right extremist\nideologies and behaviors. While OpenAI's preventative measures are strong, the\npossibility of unregulated copycat technology represents significant risk for\nlarge-scale online radicalization and recruitment; thus, in the absence of\nsafeguards, successful and efficient weaponization that requires little\nexperimentation is likely. AI stakeholders, the policymaking community, and\ngovernments should begin investing as soon as possible in building social\nnorms, public policy, and educational initiatives to preempt an influx of\nmachine-generated disinformation and propaganda. Mitigation will require\neffective policy and partnerships across industry, government, and civil\nsociety.", "doi": "", "date": "2020-09-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.06807v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 484778703, "title": "Helping Users Tackle Algorithmic Threats on Social Media: A Multimedia\n  Research Agenda", "abstract": "Participation on social media platforms has many benefits but also poses\nsubstantial threats. Users often face an unintended loss of privacy, are\nbombarded with mis-/disinformation, or are trapped in filter bubbles due to\nover-personalized content. These threats are further exacerbated by the rise of\nhidden AI-driven algorithms working behind the scenes to shape users' thoughts,\nattitudes, and behavior. We investigate how multimedia researchers can help\ntackle these problems to level the playing field for social media users. We\nperform a comprehensive survey of algorithmic threats on social media and use\nit as a lens to set a challenging but important research agenda for effective\nand real-time user nudging. We further implement a conceptual prototype and\nevaluate it with experts to supplement our research agenda. This paper calls\nfor solutions that combat the algorithmic threats on social media by utilizing\nmachine learning and multimedia content analysis techniques but in a\ntransparent manner and for the benefit of the users.", "doi": "", "date": "2020-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.07632v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1070311293, "title": "A Multi-Modal Method for Satire Detection using Textual and Visual Cues", "abstract": "Satire is a form of humorous critique, but it is sometimes misinterpreted by\nreaders as legitimate news, which can lead to harmful consequences. We observe\nthat the images used in satirical news articles often contain absurd or\nridiculous content and that image manipulation is used to create fictional\nscenarios. While previous work have studied text-based methods, in this work we\npropose a multi-modal approach based on state-of-the-art visiolinguistic model\nViLBERT. To this end, we create a new dataset consisting of images and\nheadlines of regular and satirical news for the task of satire detection. We\nfine-tune ViLBERT on the dataset and train a convolutional neural network that\nuses an image forensics technique. Evaluation on the dataset shows that our\nproposed multi-modal approach outperforms image-only, text-only, and simple\nfusion baselines.", "doi": "", "date": "2020-10-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.06671v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2378022230, "title": "MM-COVID: A Multilingual and Multimodal Data Repository for Combating\n  COVID-19 Disinformation", "abstract": "The COVID-19 epidemic is considered as the global health crisis of the whole\nsociety and the greatest challenge mankind faced since World War Two.\nUnfortunately, the fake news about COVID-19 is spreading as fast as the virus\nitself. The incorrect health measurements, anxiety, and hate speeches will have\nbad consequences on people's physical health, as well as their mental health in\nthe whole world. To help better combat the COVID-19 fake news, we propose a new\nfake news detection dataset MM-COVID(Multilingual and Multidimensional COVID-19\nFake News Data Repository). This dataset provides the multilingual fake news\nand the relevant social context. We collect 3981 pieces of fake news content\nand 7192 trustworthy information from English, Spanish, Portuguese, Hindi,\nFrench and Italian, 6 different languages. We present a detailed and\nexploratory analysis of MM-COVID from different perspectives and demonstrate\nthe utility of MM-COVID in several potential applications of COVID-19 fake news\nstudy on multilingual and social media.", "doi": "", "date": "2020-11-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.04088v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1271240967, "title": "Detecting Social Media Manipulation in Low-Resource Languages", "abstract": "Social media have been deliberately used for malicious purposes, including\npolitical manipulation and disinformation. Most research focuses on\nhigh-resource languages. However, malicious actors share content across\ncountries and languages, including low-resource ones. Here, we investigate\nwhether and to what extent malicious actors can be detected in low-resource\nlanguage settings. We discovered that a high number of accounts posting in\nTagalog were suspended as part of Twitter's crackdown on interference\noperations after the 2016 US Presidential election. By combining text embedding\nand transfer learning, our framework can detect, with promising accuracy,\nmalicious users posting in Tagalog without any prior knowledge or training on\nmalicious content in that language. We first learn an embedding model for each\nlanguage, namely a high-resource language (English) and a low-resource one\n(Tagalog), independently. Then, we learn a mapping between the two latent\nspaces to transfer the detection model. We demonstrate that the proposed\napproach significantly outperforms state-of-the-art models, including BERT, and\nyields marked advantages in settings with very limited training data-the norm\nwhen dealing with detecting malicious activity in online platforms.", "doi": "", "date": "2020-11-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.05367v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3742174547, "title": "Fact-Enhanced Synthetic News Generation", "abstract": "The advanced text generation methods have witnessed great success in text\nsummarization, language translation, and synthetic news generation. However,\nthese techniques can be abused to generate disinformation and fake news. To\nbetter understand the potential threats of synthetic news, we develop a new\ngeneration method FactGen to generate high-quality news content. The existing\ntext generation methods either afford limited supplementary information or lose\nconsistency between the input and output which makes the synthetic news less\ntrustworthy. To address these issues, FactGen retrieves external facts to\nenrich the output and reconstructs the input claim from the generated content\nto improve the consistency among the input and the output. Experiment results\non real-world datasets show that the generated news contents of FactGen are\nconsistent and contain rich facts. We also discuss the possible defending\nmethod to identify these synthetic news pieces if FactGen is used to generate\nsynthetic news.", "doi": "", "date": "2020-12-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.04778v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2219479422, "title": "Deepfakes and the 2020 US elections: what (did not) happen", "abstract": "Alarmed by the volume of disinformation that was assumed to have taken place\nduring the 2016 US elections, scholars, politics and journalists predicted the\nworst when the first deepfakes began to emerge in 2018. After all, US Elections\n2020 were believed to be the most secure in American history. This paper seeks\nexplanations for an apparent contradiction: we believe that it was precisely\nthe multiplication and conjugation of different types of warnings and fears\nthat created the conditions that prevented malicious political deepfakes from\naffecting the 2020 US elections. From these warnings, we identified four\nfactors (more active role of social networks, new laws, difficulties in\naccessing Artificial Intelligence and better awareness of society). But while\nthis formula has proven to be effective in the case of the United States, 2020,\nit is not correct to assume that it can be repeated in other political\ncontexts.", "doi": "", "date": "2021-01-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.09092v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2428216165, "title": "How does Truth Evolve into Fake News? An Empirical Study of Fake News\n  Evolution", "abstract": "Automatically identifying fake news from the Internet is a challenging\nproblem in deception detection tasks. Online news is modified constantly during\nits propagation, e.g., malicious users distort the original truth and make up\nfake news. However, the continuous evolution process would generate\nunprecedented fake news and cheat the original model. We present the Fake News\nEvolution (FNE) dataset: a new dataset tracking the fake news evolution\nprocess. Our dataset is composed of 950 paired data, each of which consists of\narticles representing the three significant phases of the evolution process,\nwhich are the truth, the fake news, and the evolved fake news. We observe the\nfeatures during the evolution and they are the disinformation techniques, text\nsimilarity, top 10 keywords, classification accuracy, parts of speech, and\nsentiment properties.", "doi": "", "date": "2021-03-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.05944v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2567630133, "title": "Tracking Knowledge Propagation Across Wikipedia Languages", "abstract": "In this paper, we present a dataset of inter-language knowledge propagation\nin Wikipedia. Covering the entire 309 language editions and 33M articles, the\ndataset aims to track the full propagation history of Wikipedia concepts, and\nallow follow up research on building predictive models of them. For this\npurpose, we align all the Wikipedia articles in a language-agnostic manner\naccording to the concept they cover, which results in 13M propagation\ninstances. To the best of our knowledge, this dataset is the first to explore\nthe full inter-language propagation at a large scale. Together with the\ndataset, a holistic overview of the propagation and key insights about the\nunderlying structural factors are provided to aid future research. For example,\nwe find that although long cascades are unusual, the propagation tends to\ncontinue further once it reaches more than four language editions. We also find\nthat the size of language editions is associated with the speed of propagation.\nWe believe the dataset not only contributes to the prior literature on\nWikipedia growth but also enables new use cases such as edit recommendation for\naddressing knowledge gaps, detection of disinformation, and cultural\nrelationship analysis.", "doi": "", "date": "2021-03-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.16613v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 779338843, "title": "A Few Observations About State-Centric Online Propaganda", "abstract": "This paper presents a few observations about pro-Kremlin propaganda between\n2015 and early 2021 with a dataset from the East Stratcom Task Force (ESTF),\nwhich is affiliated with the European Union (EU) but working independently from\nit. Instead of focusing on misinformation and disinformation, the observations\nare motivated by classical propaganda research and the ongoing transformation\nof media systems. According to the tentative results, (i) the propaganda can be\nassumed to target both domestic and foreign audiences. Of the countries and\nregions discussed, (ii) Russia, Ukraine, the United States, and within Europe,\nGermany, Poland, and the EU have been the most frequently discussed. Also other\nconflict regions such as Syria have often appeared in the propaganda. In terms\nof longitudinal trends, however, (iii) most of these discussions have decreased\nin volume after the digital tsunami in 2016, although the conflict in Ukraine\nseems to have again increased the intensity of pro-Kremlin propaganda. Finally,\n(iv) the themes discussed align with state-centric war propaganda and conflict\nzones, although also post-truth themes frequently appear; from conspiracy\ntheories via COVID-19 to fascism -- anything goes, as is typical to propaganda.", "doi": "", "date": "2021-04-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.04389v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3189568715, "title": "Understanding Transformers for Bot Detection in Twitter", "abstract": "In this paper we shed light on the impact of fine-tuning over social media\ndata in the internal representations of neural language models. We focus on bot\ndetection in Twitter, a key task to mitigate and counteract the automatic\nspreading of disinformation and bias in social media. We investigate the use of\npre-trained language models to tackle the detection of tweets generated by a\nbot or a human account based exclusively on its content. Unlike the general\ntrend in benchmarks like GLUE, where BERT generally outperforms generative\ntransformers like GPT and GPT-2 for most classification tasks on regular text,\nwe observe that fine-tuning generative transformers on a bot detection task\nproduces higher accuracies. We analyze the architectural components of each\ntransformer and study the effect of fine-tuning on their hidden states and\noutput representations. Among our findings, we show that part of the\nsyntactical information and distributional properties captured by BERT during\npre-training is lost upon fine-tuning while the generative pre-training\napproach manage to preserve these properties.", "doi": "", "date": "2021-04-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.06182v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2019176704, "title": "The Surprising Performance of Simple Baselines for Misinformation\n  Detection", "abstract": "As social media becomes increasingly prominent in our day to day lives, it is\nincreasingly important to detect informative content and prevent the spread of\ndisinformation and unverified rumours. While many sophisticated and successful\nmodels have been proposed in the literature, they are often compared with older\nNLP baselines such as SVMs, CNNs, and LSTMs. In this paper, we examine the\nperformance of a broad set of modern transformer-based language models and show\nthat with basic fine-tuning, these models are competitive with and can even\nsignificantly outperform recently proposed state-of-the-art methods. We present\nour framework as a baseline for creating and evaluating new methods for\nmisinformation detection. We further study a comprehensive set of benchmark\ndatasets, and discuss potential data leakage and the need for careful design of\nthe experiments and understanding of datasets to account for confounding\nvariables. As an extreme case example, we show that classifying only based on\nthe first three digits of tweet ids, which contain information on the date,\ngives state-of-the-art performance on a commonly used benchmark dataset for\nfake news detection --Twitter16. We provide a simple tool to detect this\nproblem and suggest steps to mitigate it in future datasets.", "doi": "", "date": "2021-04-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.06952v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2440449892, "title": "Mutual Hyperlinking Among Misinformation Peddlers", "abstract": "The internet promised to democratize access to knowledge and make the world\nmore open and understanding. The reality of today's internet, however, is far\nfrom this ideal. Misinformation, lies, and conspiracies dominate many social\nmedia platforms. This toxic online world has had real-world implications\nranging from genocide to, election interference, and threats to global public\nhealth. A frustrated public and impatient government regulators are calling for\na more vigorous response to mis- and disinformation campaigns designed to sow\ncivil unrest and inspire violence against individuals, societies, and\ndemocracies. We describe a large-scale, domain-level analysis that reveals\nseemingly coordinated efforts between multiple domains to spread and amplify\nmisinformation. We also describe how the hyperlinks shared by certain Twitter\nusers can be used to surface problematic domains. These analyses can be used by\nsearch engines and social media recommendation algorithms to systematically\ndiscover and demote misinformation peddlers.", "doi": "", "date": "2021-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.11694v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2765957619, "title": "Tracking Peaceful Tractors on Social Media -- XAI-enabled analysis of\n  Red Fort Riots 2021", "abstract": "On 26 January 2021, India witnessed a national embarrassment from the\ndemographic least expected from - farmers. People across the nation watched in\nhorror as a pseudo-patriotic mob of farmers stormed capital Delhi and\nvandalized the national pride- Red Fort. Investigations that followed the event\nrevealed the existence of a social media trail that led to the likes of such an\nevent. Consequently, it became essential and necessary to archive this trail\nfor social media analysis - not only to understand the bread-crumbs that are\ndispersed across the trail but also to visualize the role played by\nmisinformation and fake news in this event. In this paper, we propose the\ntractor2twitter dataset which contains around 0.05 million tweets that were\nposted before, during, and after this event. Also, we benchmark our dataset\nwith an Explainable AI ML model for classification of each tweet into either of\nthe three categories - disinformation, misinformation, and opinion.", "doi": "", "date": "2021-04-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13352v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 534316890, "title": "SemEval-2021 Task 6: Detection of Persuasion Techniques in Texts and\n  Images", "abstract": "We describe SemEval-2021 task 6 on Detection of Persuasion Techniques in\nTexts and Images: the data, the annotation guidelines, the evaluation setup,\nthe results, and the participating systems. The task focused on memes and had\nthree subtasks: (i) detecting the techniques in the text, (ii) detecting the\ntext spans where the techniques are used, and (iii) detecting techniques in the\nentire meme, i.e., both in the text and in the image. It was a popular task,\nattracting 71 registrations, and 22 teams that eventually made an official\nsubmission on the test set. The evaluation results for the third subtask\nconfirmed the importance of both modalities, the text and the image. Moreover,\nsome teams reported benefits when not just combining the two modalities, e.g.,\nby using early or late fusion, but rather modeling the interaction between them\nin a joint model.", "doi": "", "date": "2021-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.09284v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3692062525, "title": "SOK: Fake News Outbreak 2021: Can We Stop the Viral Spread?", "abstract": "Social Networks' omnipresence and ease of use has revolutionized the\ngeneration and distribution of information in today's world. However, easy\naccess to information does not equal an increased level of public knowledge.\nUnlike traditional media channels, social networks also facilitate faster and\nwider spread of disinformation and misinformation. Viral spread of false\ninformation has serious implications on the behaviors, attitudes and beliefs of\nthe public, and ultimately can seriously endanger the democratic processes.\nLimiting false information's negative impact through early detection and\ncontrol of extensive spread presents the main challenge facing researchers\ntoday. In this survey paper, we extensively analyze a wide range of different\nsolutions for the early detection of fake news in the existing literature. More\nprecisely, we examine Machine Learning (ML) models for the identification and\nclassification of fake news, online fake news detection competitions,\nstatistical outputs as well as the advantages and disadvantages of some of the\navailable data sets. Finally, we evaluate the online web browsing tools\navailable for detecting and mitigating fake news and present some open research\nchallenges.", "doi": "", "date": "2021-05-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.10671v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3635545484, "title": "FBAdTracker: An Interactive Data Collection and Analysis Tool for\n  Facebook Advertisements", "abstract": "The growing use of social media has led to drastic changes in our\ndecision-making. Especially, Facebook offers marketing API which promotes\nbusiness to target potential groups who are likely to consume their items.\nHowever, this service can be abused by malicious advertisers who attempt to\ndeceive people by disinformation such as propaganda and divisive opinion. To\ncounter this problem, we introduce a new application named FBAdTracker. The\npurpose of this application is to provide an integrated data collection and\nanalysis system for current research on fact-checking related to Facebook\nadvertisements. Our system is capable of monitoring up-to-date Facebook ads and\nanalyzing ads retrieved from Facebook Ads Library.", "doi": "", "date": "2021-05-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.00142v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 68112257, "title": "Parlermonium: A Data-Driven UX Design Evaluation of the Parler Platform", "abstract": "This paper evaluates Parler, the controversial social media platform, from\ntwo seemingly orthogonal perspectives: UX design perspective and data science.\nUX design researchers explore how users react to the interface/content of their\nsocial media feeds; Data science researchers analyze the misinformation flow in\nthese feeds to detect alternative narratives and state-sponsored disinformation\ncampaigns. We took a critical look into the intersection of these approaches to\nunderstand how Parler's interface itself is conductive to the flow of\nmisinformation and the perception of \"free speech\" among its audience. Parler\ndrew widespread attention leading up to and after the 2020 U.S. elections as\nthe \"alternative\" place for free speech, as a reaction to other mainstream\nsocial media platform which actively engaged in labeling misinformation with\ncontent warnings. Because platforms like Parler are disruptive to the social\nmedia landscape, we believe the evaluation uniquely uncovers the platform's\nconductivity to the spread of misinformation.", "doi": "", "date": "2021-06-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.00163v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3624949011, "title": "Fingerprinting Fine-tuned Language Models in the Wild", "abstract": "There are concerns that the ability of language models (LMs) to generate high\nquality synthetic text can be misused to launch spam, disinformation, or\npropaganda. Therefore, the research community is actively working on developing\napproaches to detect whether a given text is organic or synthetic. While this\nis a useful first step, it is important to be able to further fingerprint the\nauthor LM to attribute its origin. Prior work on fingerprinting LMs is limited\nto attributing synthetic text generated by a handful (usually < 10) of\npre-trained LMs. However, LMs such as GPT2 are commonly fine-tuned in a myriad\nof ways (e.g., on a domain-specific text corpus) before being used to generate\nsynthetic text. It is challenging to fingerprinting fine-tuned LMs because the\nuniverse of fine-tuned LMs is much larger in realistic scenarios. To address\nthis challenge, we study the problem of large-scale fingerprinting of\nfine-tuned LMs in the wild. Using a real-world dataset of synthetic text\ngenerated by 108 different fine-tuned LMs, we conduct comprehensive experiments\nto demonstrate the limitations of existing fingerprinting approaches. Our\nresults show that fine-tuning itself is the most effective in attributing the\nsynthetic text generated by fine-tuned LMs.", "doi": "", "date": "2021-06-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.01703v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2331842199, "title": "Never guess what I heard... Rumor Detection in Finnish News: a Dataset\n  and a Baseline", "abstract": "This study presents a new dataset on rumor detection in Finnish language news\nheadlines. We have evaluated two different LSTM based models and two different\nBERT models, and have found very significant differences in the results. A\nfine-tuned FinBERT reaches the best overall accuracy of 94.3% and rumor label\naccuracy of 96.0% of the time. However, a model fine-tuned on Multilingual BERT\nreaches the best factual label accuracy of 97.2%. Our results suggest that the\nperformance difference is due to a difference in the original training data.\nFurthermore, we find that a regular LSTM model works better than one trained\nwith a pretrained word2vec model. These findings suggest that more work needs\nto be done for pretrained models in Finnish language as they have been trained\non small and biased corpora.", "doi": "", "date": "2021-06-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.03389v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3638250496, "title": "A preliminary approach to knowledge integrity risk assessment in\n  Wikipedia projects", "abstract": "Wikipedia is one of the main repositories of free knowledge available today,\nwith a central role in the Web ecosystem. For this reason, it can also be a\nbattleground for actors trying to impose specific points of view or even\nspreading disinformation online. There is a growing need to monitor its\n\"health\" but this is not an easy task. Wikipedia exists in over 300 language\neditions and each project is maintained by a different community, with their\nown strengths, weaknesses and limitations. In this paper, we introduce a\ntaxonomy of knowledge integrity risks across Wikipedia projects and a first set\nof indicators to assess internal risks related to community and content issues,\nas well as external threats such as the geopolitical and media landscape. On\ntop of this taxonomy, we offer a preliminary analysis illustrating how the lack\nof editors' geographical diversity might represent a knowledge integrity risk.\nThese are the first steps of a research project to build a Wikipedia Knowledge\nIntegrity Risk Observatory.", "doi": "", "date": "2021-06-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.15940v1", "pdf": ""}, "publisher-venue": "MIS2", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2079431519, "title": "Generative Models for Security: Attacks, Defenses, and Opportunities", "abstract": "Generative models learn the distribution of data from a sample dataset and\ncan then generate new data instances. Recent advances in deep learning has\nbrought forth improvements in generative model architectures, and some\nstate-of-the-art models can (in some cases) produce outputs realistic enough to\nfool humans.\n  We survey recent research at the intersection of security and privacy and\ngenerative models. In particular, we discuss the use of generative models in\nadversarial machine learning, in helping automate or enhance existing attacks,\nand as building blocks for defenses in contexts such as intrusion detection,\nbiometrics spoofing, and malware obfuscation. We also describe the use of\ngenerative models in diverse applications such as fairness in machine learning,\nprivacy-preserving data synthesis, and steganography. Finally, we discuss new\nthreats due to generative models: the creation of synthetic media such as\ndeepfakes that can be used for disinformation.", "doi": "", "date": "2021-07-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.10139v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3521892164, "title": "Profiling Fake News Spreaders on Social Media through Psychological and\n  Motivational Factors", "abstract": "The rise of fake news in the past decade has brought with it a host of\nconsequences, from swaying opinions on elections to generating uncertainty\nduring a pandemic. A majority of methods developed to combat disinformation\neither focus on fake news content or malicious actors who generate it. However,\nthe virality of fake news is largely dependent upon the users who propagate it.\nA deeper understanding of these users can contribute to the development of a\nframework for identifying users who are likely to spread fake news. In this\nwork, we study the characteristics and motivational factors of fake news\nspreaders on social media with input from psychological theories and behavioral\nstudies. We then perform a series of experiments to determine if fake news\nspreaders can be found to exhibit different characteristics than other users.\nFurther, we investigate our findings by testing whether the characteristics we\nobserve amongst fake news spreaders in our experiments can be applied to the\ndetection of fake news spreaders in a real social media environment.", "doi": "10.1145/3465336.3475097", "date": "2021-08-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.10942v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3908535536, "title": "Predicting the Factuality of Reporting of News Media Using Observations\n  About User Attention in Their YouTube Channels", "abstract": "We propose a novel framework for predicting the factuality of reporting of\nnews media outlets by studying the user attention cycles in their YouTube\nchannels. In particular, we design a rich set of features derived from the\ntemporal evolution of the number of views, likes, dislikes, and comments for a\nvideo, which we then aggregate to the channel level. We develop and release a\ndataset for the task, containing observations of user attention on YouTube\nchannels for 489 news media. Our experiments demonstrate both complementarity\nand sizable improvements over state-of-the-art textual representations.", "doi": "", "date": "2021-08-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12519v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2505084588, "title": "TAR on Social Media: A Framework for Online Content Moderation", "abstract": "Content moderation (removing or limiting the distribution of posts based on\ntheir contents) is one tool social networks use to fight problems such as\nharassment and disinformation. Manually screening all content is usually\nimpractical given the scale of social media data, and the need for nuanced\nhuman interpretations makes fully automated approaches infeasible. We consider\ncontent moderation from the perspective of technology-assisted review (TAR): a\nhuman-in-the-loop active learning approach developed for high recall retrieval\nproblems in civil litigation and other fields. We show how TAR workflows, and a\nTAR cost model, can be adapted to the content moderation problem. We then\ndemonstrate on two publicly available content moderation data sets that a TAR\nworkflow can reduce moderation costs by 20% to 55% across a variety of\nconditions.", "doi": "", "date": "2021-08-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12752v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 516016509, "title": "Interpretable Propaganda Detection in News Articles", "abstract": "Online users today are exposed to misleading and propagandistic news articles\nand media posts on a daily basis. To counter thus, a number of approaches have\nbeen designed aiming to achieve a healthier and safer online news and media\nconsumption. Automatic systems are able to support humans in detecting such\ncontent; yet, a major impediment to their broad adoption is that besides being\naccurate, the decisions of such systems need also to be interpretable in order\nto be trusted and widely adopted by users. Since misleading and propagandistic\ncontent influences readers through the use of a number of deception techniques,\nwe propose to detect and to show the use of such techniques as a way to offer\ninterpretability. In particular, we define qualitatively descriptive features\nand we analyze their suitability for detecting deception techniques. We further\nshow that our interpretable features can be easily combined with pre-trained\nlanguage models, yielding state-of-the-art results.", "doi": "", "date": "2021-08-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12802v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1962054596, "title": "WikiCheck: An end-to-end open source Automatic Fact-Checking API based\n  on Wikipedia", "abstract": "With the growth of fake news and disinformation, the NLP community has been\nworking to assist humans in fact-checking. However, most academic research has\nfocused on model accuracy without paying attention to resource efficiency,\nwhich is crucial in real-life scenarios. In this work, we review the\nState-of-the-Art datasets and solutions for Automatic Fact-checking and test\ntheir applicability in production environments. We discover overfitting issues\nin those models, and we propose a data filtering method that improves the\nmodel's performance and generalization. Then, we design an unsupervised\nfine-tuning of the Masked Language models to improve its accuracy working with\nWikipedia. We also propose a novel query enhancing method to improve evidence\ndiscovery using the Wikipedia Search API. Finally, we present a new\nfact-checking system, the \\textit{WikiCheck} API that automatically performs a\nfacts validation process based on the Wikipedia knowledge base. It is\ncomparable to SOTA solutions in terms of accuracy and can be used on low-memory\nCPU instances.", "doi": "", "date": "2021-09-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2109.00835v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3695554350, "title": "Disrupting Terrorist Networks, a dynamic fitness landscape approach", "abstract": "Over a period of approximately five years, Pankaj Ghemawat of Harvard\nBusiness School and Daniel Levinthal of the Wharton School have been working on\na detailed simulation (producing approximately a million fitness landscape\ngraphs) in order to determine optimal patterns of decision-making for\ncorporations. In 2006, we adapted this study, combining it with our own work on\nterrorism to examine what would happen if we inverted Ghemawat and Levinthal's\nfindings and sought to provide disinformation or otherwise interfere with the\ncommunications and decision processes of terrorist organizations in order to\noptimize poor decision making and inefficiencies in organizational\ncoordination, command and control.\n  The bulk of this study was then presented at the 2006 annual meeting of the\nNorth American Association for Computation in the Social and Organizational\nSciences. We present here an updated version of that study, emphasizing the\nrather counter-intuitive finding that \"soft\" targets have almost no value and\nthat unless one can influence key factors, an effort directed at the easy to\nreach elements of terrorist organizations may actually be worse than mounting\nno effort at all. We conclude with the recommendation that some fundamental\nrethinking may be required if the United States is to effectively defend itself\nfrom future terrorist attacks.", "doi": "", "date": "2007-07-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/0707.4036v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2838062180, "title": "Informational parasites in code evolution", "abstract": "In a previous study, we considered an information-theoretic model of code\nevolution. In it, agents obtain information about their (common) environment by\nthe perception of messages of other agents, which is determined by an\ninteraction probability (the structure of the population). For an agent to\nunderstand another agent's messages, the former must either know the identity\nof the latter, or the code producing the messages must be universally\ninterpretable. A universal code, however, introduces a vulnerability: a\nparasitic entity can take advantage of it. Here, we investigate this problem.\nIn our specific setting, we consider a parasite to be an agent that tries to\ninflict as much damage as possible in the mutual understanding of the\npopulation (i.e. the parasite acts as a disinformation agent). We show that,\nafter introducing a parasite in the population, the former adopts a code such\nthat it captures the information about the environment that is missing in the\npopulation. Such agent would be of great value, but only if the rest of the\npopulation could understand its messages. However, it is of little use here,\nsince the parasite utilises the most common messages in the population to\nexpress different concepts. Now we let the population respond by updating their\ncodes such that, in this arms race, they again maximise their mutual\nunderstanding. As a result, there is a code drift in the population where the\nutilisation of the messages of the parasite is avoided. A consequence of this\nis that the information that the parasite possesses but the agents lack becomes\nunderstandable and readily available.", "doi": "", "date": "2015-05-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1505.00956v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2732850406, "title": "Identifying Nuances in Fake News vs. Satire: Using Semantic and\n  Linguistic Cues", "abstract": "The blurry line between nefarious fake news and protected-speech satire has\nbeen a notorious struggle for social media platforms. Further to the efforts of\nreducing exposure to misinformation on social media, purveyors of fake news\nhave begun to masquerade as satire sites to avoid being demoted. In this work,\nwe address the challenge of automatically classifying fake news versus satire.\nPrevious work have studied whether fake news and satire can be distinguished\nbased on language differences. Contrary to fake news, satire stories are\nusually humorous and carry some political or social message. We hypothesize\nthat these nuances could be identified using semantic and linguistic cues.\nConsequently, we train a machine learning method using semantic representation,\nwith a state-of-the-art contextual language model, and with linguistic features\nbased on textual coherence metrics. Empirical evaluation attests to the merits\nof our approach compared to the language-based baseline and sheds light on the\nnuances between fake news and satire. As avenues for future work, we consider\nstudying additional linguistic features related to the humor aspect, and\nenriching the data with current news events, to help identify a political or\nsocial message.", "doi": "10.18653/v1/d19-5004", "date": "2019-10-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.01160v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2217595533, "title": "Contradiction Detection for Rumorous Claims", "abstract": "The utilization of social media material in journalistic workflows is\nincreasing, demanding automated methods for the identification of mis- and\ndisinformation. Since textual contradiction across social media posts can be a\nsignal of rumorousness, we seek to model how claims in Twitter posts are being\ntextually contradicted. We identify two different contexts in which\ncontradiction emerges: its broader form can be observed across independently\nposted tweets and its more specific form in threaded conversations. We define\nhow the two scenarios differ in terms of central elements of argumentation:\nclaims and conversation structure. We design and evaluate models for the two\nscenarios uniformly as 3-way Recognizing Textual Entailment tasks in order to\nrepresent claims and conversation structure implicitly in a generic inference\nmodel, while previous studies used explicit or no representation of these\nproperties. To address noisy text, our classifiers use simple similarity\nfeatures derived from the string and part-of-speech level. Corpus statistics\nreveal distribution differences for these features in contradictory as opposed\nto non-contradictory tweet relations, and the classifiers yield state of the\nart performance.", "doi": "", "date": "2016-11-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1611.02588v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 613947364, "title": "Influence Estimation on Social Media Networks Using Causal Inference", "abstract": "Estimating influence on social media networks is an important practical and\ntheoretical problem, especially because this new medium is widely exploited as\na platform for disinformation and propaganda. This paper introduces a novel\napproach to influence estimation on social media networks and applies it to the\nreal-world problem of characterizing active influence operations on Twitter\nduring the 2017 French presidential elections. The new influence estimation\napproach attributes impact by accounting for narrative propagation over the\nnetwork using a network causal inference framework applied to data arising from\ngraph sampling and filtering. This causal framework infers the difference in\noutcome as a function of exposure, in contrast to existing approaches that\nattribute impact to activity volume or topological features, which do not\nexplicitly measure nor necessarily indicate actual network influence.\nCram\\'er-Rao estimation bounds are derived for parameter estimation as a step\nin the causal analysis, and used to achieve geometrical insight on the causal\ninference problem. The ability to infer high causal influence is demonstrated\non real-world social media accounts that are later independently confirmed to\nbe either directly affiliated or correlated with foreign influence operations\nusing evidence supplied by the U.S. Congress and journalistic reports.", "doi": "10.1109/ssp.2018.8450823", "date": "2018-04-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.04109v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 342080327, "title": "Who Falls for Online Political Manipulation?", "abstract": "Social media, once hailed as a vehicle for democratization and the promotion\nof positive social change across the globe, are under attack for becoming a\ntool of political manipulation and spread of disinformation. A case in point is\nthe alleged use of trolls by Russia to spread malicious content in Western\nelections. This paper examines the Russian interference campaign in the 2016 US\npresidential election on Twitter. Our aim is twofold: first, we test whether\npredicting users who spread trolls' content is feasible in order to gain\ninsight on how to contain their influence in the future; second, we identify\nfeatures that are most predictive of users who either intentionally or\nunintentionally play a vital role in spreading this malicious content. We\ncollected a dataset with over 43 million elections-related posts shared on\nTwitter between September 16 and November 9, 2016, by about 5.7 million users.\nThis dataset includes accounts associated with the Russian trolls identified by\nthe US Congress. Proposed models are able to very accurately identify users who\nspread the trolls' content (average AUC score of 96%, using 10-fold\nvalidation). We show that political ideology, bot likelihood scores, and some\nactivity-related account meta data are the most predictive features of whether\na user spreads trolls' content or not.", "doi": "", "date": "2018-08-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.03281v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2956893372, "title": "Hawkes Process for Understanding the Influence of Pathogenic Social\n  Media Accounts", "abstract": "Over the past years, political events and public opinion on the Web have been\nallegedly manipulated by accounts dedicated to spreading disinformation and\nperforming malicious activities on social media. These accounts hereafter\nreferred to as \"Pathogenic Social Media (PSM)\" accounts, are often controlled\nby terrorist supporters, water armies or fake news writers and hence can pose\nthreats to social media and general public. Understanding and analyzing PSMs\ncould help social media firms devise sophisticated and automated techniques\nthat could be deployed to stop them from reaching their audience and\nconsequently reduce their threat. In this paper, we leverage the well-known\nstatistical technique \"Hawkes Process\" to quantify the influence of PSM\naccounts on the dissemination of malicious information on social media\nplatforms. Our findings on a real-world ISIS-related dataset from Twitter\nindicate that PSMs are significantly different from regular users in making a\nmessage viral. Specifically, we observed that PSMs do not usually post URLs\nfrom mainstream news sources. Instead, their tweets usually receive large\nimpact on audience, if contained URLs from Facebook and alternative news\noutlets. In contrary, tweets posted by regular users receive nearly equal\nimpression regardless of the posted URLs and their sources. Our findings can\nfurther shed light on understanding and detecting PSM accounts.", "doi": "", "date": "2019-02-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.01970v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3239447305, "title": "Towards a Robust Deep Neural Network in Texts: A Survey", "abstract": "Deep neural networks (DNNs) have achieved remarkable success in various tasks\n(e.g., image classification, speech recognition, and natural language\nprocessing (NLP)). However, researchers have demonstrated that DNN-based models\nare vulnerable to adversarial examples, which cause erroneous predictions by\nadding imperceptible perturbations into legitimate inputs. Recently, studies\nhave revealed adversarial examples in the text domain, which could effectively\nevade various DNN-based text analyzers and further bring the threats of the\nproliferation of disinformation. In this paper, we give a comprehensive survey\non the existing studies of adversarial techniques for generating adversarial\ntexts written by both English and Chinese characters and the corresponding\ndefense methods. More importantly, we hope that our work could inspire future\nstudies to develop more robust DNN-based text analyzers against known and\nunknown adversarial techniques.\n  We classify the existing adversarial techniques for crafting adversarial\ntexts based on the perturbation units, helping to better understand the\ngeneration of adversarial texts and build robust models for defense. In\npresenting the taxonomy of adversarial attacks and defenses in the text domain,\nwe introduce the adversarial techniques from the perspective of different NLP\ntasks. Finally, we discuss the existing challenges of adversarial attacks and\ndefenses in texts and present the future research directions in this emerging\nand challenging field.", "doi": "", "date": "2019-02-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.07285v6", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3950213260, "title": "The evolution of polarization in the legislative branch of government", "abstract": "The polarization of political opinions among members of the U.S. legislative\nchambers measured by their voting records is greater today than it was thirty\nyears ago. Previous research efforts to find causes of such increase have\nsuggested diverse contributors, like growth of online media, echo chamber\neffects, media biases, or disinformation propagation. Yet, we lack theoretic\ntools to understand, quantify, and predict the emergence of high political\npolarization among voters and their legislators. Here, we analyze millions of\nroll-call votes cast in the U.S. Congress over the past six decades. Our\nanalysis reveals the critical change of polarization patterns that started at\nthe end of 1980's. In earlier decades, polarization within each Congress tended\nto decrease with time. In contrast, in the recent decades, the polarization has\nbeen likely to grow within each term. To shed light on the reasons for this\nchange, we introduce here a formal model for competitive dynamics to quantify\nthe evolution of polarization patterns in the legislative branch of the U.S.\ngovernment. Our model represents dynamics of polarization, enabling us to\nsuccessfully predict the direction of polarization changes in 28 out of 30 U.S.\nCongresses elected in the past six decades. From the evolution of polarization\nlevel as measured by the Rice index, our model extracts a hidden parameter -\npolarization utility which determines the convergence point of the polarization\nevolution. The increase in the polarization utility implied by the model\nstrongly correlates with two current trends: growing polarization of voters and\nincreasing influence of election campaign funders. Two largest peaks of the\nmodel's polarization utility correlate with significant political or\nlegislative changes happening at the same time.", "doi": "10.1098/rsif.2019.0010", "date": "2019-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.10317v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3447788486, "title": "Fake News Early Detection: An Interdisciplinary Study", "abstract": "Massive dissemination of fake news and its potential to erode democracy has\nincreased the demand for accurate fake news detection. Recent advancements in\nthis area have proposed novel techniques that aim to detect fake news by\nexploring how it propagates on social networks. Nevertheless, to detect fake\nnews at an early stage, i.e., when it is published on a news outlet but not yet\nspread on social media, one cannot rely on news propagation information as it\ndoes not exist. Hence, there is a strong need to develop approaches that can\ndetect fake news by focusing on news content. In this paper, a theory-driven\nmodel is proposed for fake news detection. The method investigates news content\nat various levels: lexicon-level, syntax-level, semantic-level and\ndiscourse-level. We represent news at each level, relying on well-established\ntheories in social and forensic psychology. Fake news detection is then\nconducted within a supervised machine learning framework. As an\ninterdisciplinary research, our work explores potential fake news patterns,\nenhances the interpretability in fake news feature engineering, and studies the\nrelationships among fake news, deception/disinformation, and clickbaits.\nExperiments conducted on two real-world datasets indicate the proposed method\ncan outperform the state-of-the-art and enable fake news early detection when\nthere is limited content information.", "doi": "", "date": "2019-04-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.11679v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1902717369, "title": "Defending Against Neural Fake News", "abstract": "Recent progress in natural language generation has raised dual-use concerns.\nWhile applications like summarization and translation are positive, the\nunderlying technology also might enable adversaries to generate neural fake\nnews: targeted propaganda that closely mimics the style of real news.\n  Modern computer security relies on careful threat modeling: identifying\npotential threats and vulnerabilities from an adversary's point of view, and\nexploring potential mitigations to these threats. Likewise, developing robust\ndefenses against neural fake news requires us first to carefully investigate\nand characterize the risks of these models. We thus present a model for\ncontrollable text generation called Grover. Given a headline like `Link Found\nBetween Vaccines and Autism,' Grover can generate the rest of the article;\nhumans find these generations to be more trustworthy than human-written\ndisinformation.\n  Developing robust verification techniques against generators like Grover is\ncritical. We find that best current discriminators can classify neural fake\nnews from real, human-written, news with 73% accuracy, assuming access to a\nmoderate level of training data. Counterintuitively, the best defense against\nGrover turns out to be Grover itself, with 92% accuracy, demonstrating the\nimportance of public release of strong generators. We investigate these results\nfurther, showing that exposure bias -- and sampling strategies that alleviate\nits effects -- both leave artifacts that similar discriminators can pick up on.\nWe conclude by discussing ethical issues regarding the technology, and plan to\nrelease Grover publicly, helping pave the way for better detection of neural\nfake news.", "doi": "", "date": "2019-05-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.12616v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2715945953, "title": "Automatic Fact-Checking Using Context and Discourse Information", "abstract": "We study the problem of automatic fact-checking, paying special attention to\nthe impact of contextual and discourse information. We address two related\ntasks: (i) detecting check-worthy claims, and (ii) fact-checking claims. We\ndevelop supervised systems based on neural networks, kernel-based support\nvector machines, and combinations thereof, which make use of rich input\nrepresentations in terms of discourse cues and contextual features. For the\ncheck-worthiness estimation task, we focus on political debates, and we model\nthe target claim in the context of the full intervention of a participant and\nthe previous and the following turns in the debate, taking into account\ncontextual meta information. For the fact-checking task, we focus on answer\nverification in a community forum, and we model the veracity of the answer with\nrespect to the entire question--answer thread in which it occurs as well as\nwith respect to other related posts from the entire forum. We develop annotated\ndatasets for both tasks and we run extensive experimental evaluation,\nconfirming that both types of information ---but especially contextual\nfeatures--- play an important role.", "doi": "10.1145/3297722", "date": "2019-08-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.01328v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2408576026, "title": "FakeYou! -- A Gamified Approach for Building and Evaluating Resilience\n  Against Fake News", "abstract": "Nowadays fake news are heavily discussed in public and political debates.\nEven though the phenomenon of intended false information is rather old,\nmisinformation reaches a new level with the rise of the internet and\nparticipatory platforms. Due to Facebook and Co., purposeful false information\n- often called fake news - can be easily spread by everyone. Because of a high\ndata volatility and variety in content types (text, images,...) debunking of\nfake news is a complex challenge. This is especially true for automated\napproaches, which are prone to fail validating the veracity of the information.\nThis work focuses on an a gamified approach to strengthen the resilience of\nconsumers towards fake news. The game FakeYou motivates its players to\ncritically analyze headlines regarding their trustworthiness. Further, the game\nfollows a \"learning by doing strategy\": by generating own fake headlines, users\nshould experience the concepts of convincing fake headline formulations. We\nintroduce the game itself, as well as the underlying technical infrastructure.\nA first evaluation study shows, that users tend to use specific stylistic\ndevices to generate fake news. Further, the results indicate, that creating\ngood fakes and identifying correct headlines are challenging and hard to learn.", "doi": "", "date": "2020-03-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.07595v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1439420188, "title": "BaitWatcher: A lightweight web interface for the detection of\n  incongruent news headlines", "abstract": "In digital environments where substantial amounts of information are shared\nonline, news headlines play essential roles in the selection and diffusion of\nnews articles. Some news articles attract audience attention by showing\nexaggerated or misleading headlines. This study addresses the \\textit{headline\nincongruity} problem, in which a news headline makes claims that are either\nunrelated or opposite to the contents of the corresponding article. We present\n\\textit{BaitWatcher}, which is a lightweight web interface that guides readers\nin estimating the likelihood of incongruence in news articles before clicking\non the headlines. BaitWatcher utilizes a hierarchical recurrent encoder that\nefficiently learns complex textual representations of a news headline and its\nassociated body text. For training the model, we construct a million scale\ndataset of news articles, which we also release for broader research use. Based\non the results of a focus group interview, we discuss the importance of\ndeveloping an interpretable AI agent for the design of a better interface for\nmitigating the effects of online misinformation.", "doi": "10.1007/978-3-030-42699-6", "date": "2020-03-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.11459v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2909294353, "title": "Characterising User Content on a Multi-lingual Social Network", "abstract": "Social media has been on the vanguard of political information diffusion in\nthe 21st century. Most studies that look into disinformation, political\ninfluence and fake-news focus on mainstream social media platforms. This has\ninevitably made English an important factor in our current understanding of\npolitical activity on social media. As a result, there has only been a limited\nnumber of studies into a large portion of the world, including the largest,\nmultilingual and multi-cultural democracy: India. In this paper we present our\ncharacterisation of a multilingual social network in India called ShareChat. We\ncollect an exhaustive dataset across 72 weeks before and during the Indian\ngeneral elections of 2019, across 14 languages. We investigate the cross\nlingual dynamics by clustering visually similar images together, and exploring\nhow they move across language barriers. We find that Telugu, Malayalam, Tamil\nand Kannada languages tend to be dominant in soliciting political images (often\nreferred to as memes), and posts from Hindi have the largest cross-lingual\ndiffusion across ShareChat (as well as images containing text in English). In\nthe case of images containing text that cross language barriers, we see that\nlanguage translation is used to widen the accessibility. That said, we find\ncases where the same image is associated with very different text (and\ntherefore meanings). This initial characterisation paves the way for more\nadvanced pipelines to understand the dynamics of fake and political content in\na multi-lingual and non-textual setting.", "doi": "", "date": "2020-04-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.11480v1", "pdf": ""}, "publisher-venue": "ICWSM 2020, please cite the ICWSM version", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3054001539, "title": "Out of the Echo Chamber: Detecting Countering Debate Speeches", "abstract": "An educated and informed consumption of media content has become a challenge\nin modern times. With the shift from traditional news outlets to social media\nand similar venues, a major concern is that readers are becoming encapsulated\nin \"echo chambers\" and may fall prey to fake news and disinformation, lacking\neasy access to dissenting views. We suggest a novel task aiming to alleviate\nsome of these concerns -- that of detecting articles that most effectively\ncounter the arguments -- and not just the stance -- made in a given text. We\nstudy this problem in the context of debate speeches. Given such a speech, we\naim to identify, from among a set of speeches on the same topic and with an\nopposing stance, the ones that directly counter it. We provide a large dataset\nof 3,685 such speeches (in English), annotated for this relation, which\nhopefully would be of general interest to the NLP community. We explore several\nalgorithms addressing this task, and while some are successful, all fall short\nof expert human performance, suggesting room for further research. All data\ncollected during this work is freely available for research.", "doi": "", "date": "2020-05-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.01157v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4010846600, "title": "What Was Written vs. Who Read It: News Media Profiling Using Text\n  Analysis and Social Media Context", "abstract": "Predicting the political bias and the factuality of reporting of entire news\noutlets are critical elements of media profiling, which is an understudied but\nan increasingly important research direction. The present level of\nproliferation of fake, biased, and propagandistic content online, has made it\nimpossible to fact-check every single suspicious claim, either manually or\nautomatically. Alternatively, we can profile entire news outlets and look for\nthose that are likely to publish fake or biased content. This approach makes it\npossible to detect likely \"fake news\" the moment they are published, by simply\nchecking the reliability of their source. From a practical perspective,\npolitical bias and factuality of reporting have a linguistic aspect but also a\nsocial context. Here, we study the impact of both, namely (i) what was written\n(i.e., what was published by the target medium, and how it describes itself on\nTwitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium\non Facebook, Twitter, and YouTube). We further study (iii) what was written\nabout the target medium on Wikipedia. The evaluation results show that what was\nwritten matters most, and that putting all information sources together yields\nhuge improvements over the current state-of-the-art.", "doi": "", "date": "2020-05-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.04518v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 166740091, "title": "That is a Known Lie: Detecting Previously Fact-Checked Claims", "abstract": "The recent proliferation of \"fake news\" has triggered a number of responses,\nmost notably the emergence of several manual fact-checking initiatives. As a\nresult and over time, a large number of fact-checked claims have been\naccumulated, which increases the likelihood that a new claim in social media or\na new statement by a politician might have already been fact-checked by some\ntrusted fact-checking organization, as viral claims often come back after a\nwhile in social media, and politicians like to repeat their favorite\nstatements, true or false, over and over again. As manual fact-checking is very\ntime-consuming (and fully automatic fact-checking has credibility issues), it\nis important to try to save this effort and to avoid wasting time on claims\nthat have already been fact-checked. Interestingly, despite the importance of\nthe task, it has been largely ignored by the research community so far. Here,\nwe aim to bridge this gap. In particular, we formulate the task and we discuss\nhow it relates to, but also differs from, previous work. We further create a\nspecialized dataset, which we release to the research community. Finally, we\npresent learning-to-rank experiments that demonstrate sizable improvements over\nstate-of-the-art retrieval and textual similarity approaches.", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.06058v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2518568753, "title": "A curated collection of COVID-19 online datasets", "abstract": "One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data.", "doi": "", "date": "2020-07-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.09703v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3865039930, "title": "Characterizing COVID-19 Misinformation Communities Using a Novel Twitter\n  Dataset", "abstract": "From conspiracy theories to fake cures and fake treatments, COVID-19 has\nbecome a hot-bed for the spread of misinformation online. It is more important\nthan ever to identify methods to debunk and correct false information online.\nIn this paper, we present a methodology and analyses to characterize the two\ncompeting COVID-19 misinformation communities online: (i) misinformed users or\nusers who are actively posting misinformation, and (ii) informed users or users\nwho are actively spreading true information, or calling out misinformation. The\ngoals of this study are two-fold: (i) collecting a diverse set of annotated\nCOVID-19 Twitter dataset that can be used by the research community to conduct\nmeaningful analysis; and (ii) characterizing the two target communities in\nterms of their network structure, linguistic patterns, and their membership in\nother communities. Our analyses show that COVID-19 misinformed communities are\ndenser, and more organized than informed communities, with a possibility of a\nhigh volume of the misinformation being part of disinformation campaigns. Our\nanalyses also suggest that a large majority of misinformed users may be\nanti-vaxxers. Finally, our sociolinguistic analyses suggest that COVID-19\ninformed users tend to use more narratives than misinformed users.", "doi": "", "date": "2020-08-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.00791v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3607503300, "title": "Covid-19 infodemic reveals new tipping point epidemiology and a revised\n  $R$ formula", "abstract": "Many governments have managed to control their COVID-19 outbreak with a\nsimple message: keep the effective '$R$ number' $R<1$ to prevent widespread\ncontagion and flatten the curve. This raises the question whether a similar\npolicy could control dangerous online 'infodemics' of information,\nmisinformation and disinformation. Here we show, using multi-platform data from\nthe COVID-19 infodemic, that its online spreading instead encompasses a\ndifferent dynamical regime where communities and users within and across\nindependent platforms, sporadically form temporary active links on similar\ntimescales to the viral spreading. This allows material that might have died\nout, to evolve and even mutate. This has enabled niche networks that were\nalready successfully spreading hate and anti-vaccination material, to rapidly\nbecome global super-spreaders of narratives featuring fake COVID-19 treatments,\nanti-Asian sentiment and conspiracy theories. We derive new tools that\nincorporate these coupled social-viral dynamics, including an online $R$, to\nhelp prevent infodemic spreading at all scales: from spreading across platforms\n(e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community,\nor topic. By accounting for similar social and viral timescales, the same\nmathematical theory also offers a quantitative description of other\nunconventional infection profiles such as rumors spreading in financial markets\nand colds spreading in schools.", "doi": "", "date": "2020-08-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.08513v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 505798358, "title": "Identifying Coordinated Accounts on Social Media through Hidden\n  Influence and Group Behaviours", "abstract": "Disinformation campaigns on social media, involving coordinated activities\nfrom malicious accounts towards manipulating public opinion, have become\nincreasingly prevalent. Existing approaches to detect coordinated accounts\neither make very strict assumptions about coordinated behaviours, or require\npart of the malicious accounts in the coordinated group to be revealed in order\nto detect the rest. To address these drawbacks, we propose a generative model,\nAMDN-HAGE (Attentive Mixture Density Network with Hidden Account Group\nEstimation) which jointly models account activities and hidden group behaviours\nbased on Temporal Point Processes (TPP) and Gaussian Mixture Model (GMM), to\ncapture inherent characteristics of coordination which is, accounts that\ncoordinate must strongly influence each other's activities, and collectively\nappear anomalous from normal accounts. To address the challenges of optimizing\nthe proposed model, we provide a bilevel optimization algorithm with\ntheoretical guarantee on convergence. We verified the effectiveness of the\nproposed method and training algorithm on real-world social network data\ncollected from Twitter related to coordinated campaigns from Russia's Internet\nResearch Agency targeting the 2016 U.S. Presidential Elections, and to identify\ncoordinated campaigns related to the COVID-19 pandemic. Leveraging the learned\nmodel, we find that the average influence between coordinated account pairs is\nthe highest.On COVID-19, we found coordinated group spreading anti-vaccination,\nanti-masks conspiracies that suggest the pandemic is a hoax and political scam.", "doi": "", "date": "2020-08-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.11308v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3529360029, "title": "TRUSTD: Combat Fake Content using Blockchain and Collective Signature\n  Technologies", "abstract": "The growing trend of sharing news/contents, through social media platforms\nand the World Wide Web has been seen to impact our perception of the truth,\naltering our views about politics, economics, relationships, needs and wants.\nThis is because of the growing spread of misinformation and disinformation\nintentionally or unintentionally by individuals and organizations. This trend\nhas grave political, social, ethical, and privacy implications for society due\nto 1) the rapid developments in the field of Machine Learning (ML) and Deep\nLearning (DL) algorithms in creating realistic-looking yet fake digital content\n(such as text, images, and videos), 2) the ability to customize the content\nfeeds and to create a polarized so-called \"filter-bubbles\" leveraging the\navailability of the big-data. Therefore, there is an ethical need to combat the\nflow of fake content. This paper attempts to resolve some of the aspects of\nthis combat by presenting a high-level overview of TRUSTD, a blockchain and\ncollective signature-based ecosystem to help content creators in getting their\ncontent backed by the community, and to help users judge on the credibility and\ncorrectness of these contents.", "doi": "10.1109/icbc48266.2020.9169435", "date": "2020-08-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.13632v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1852971266, "title": "Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models", "abstract": "While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.", "doi": "", "date": "2020-09-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.02931v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2673205057, "title": "FaNDS: Fake News Detection System Using Energy Flow", "abstract": "Recently, the term \"fake news\" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.", "doi": "", "date": "2020-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.02097v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1953679818, "title": "Young Adult Unemployment Through the Lens of Social Media: Italy as a\n  case study", "abstract": "Youth unemployment rates are still in alerting levels for many countries,\namong which Italy. Direct consequences include poverty, social exclusion, and\ncriminal behaviours, while negative impact on the future employability and wage\ncannot be obscured. In this study, we employ survey data together with social\nmedia data, and in particular likes on Facebook Pages, to analyse personality,\nmoral values, but also cultural elements of the young unemployed population in\nItaly. Our findings show that there are small but significant differences in\npersonality and moral values, with the unemployed males to be less agreeable\nwhile females more open to new experiences. At the same time, unemployed have a\nmore collectivist point of view, valuing more in-group loyalty, authority, and\npurity foundations. Interestingly, topic modelling analysis did not reveal\nmajor differences in interests and cultural elements of the unemployed.\nUtilisation patterns emerged though; the employed seem to use Facebook to\nconnect with local activities, while the unemployed use it mostly as for\nentertainment purposes and as a source of news, making them susceptible to\nmis/disinformation. We believe these findings can help policymakers get a\ndeeper understanding of this population and initiatives that improve both the\nhard and the soft skills of this fragile population.", "doi": "10.1007/978-3-030-60975-7_28", "date": "2020-10-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.04496v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3228249976, "title": "Fake News Detection through Graph Comment Advanced Learning", "abstract": "Disinformation has long been regarded as a severe social problem, where fake\nnews is one of the most representative issues. What is worse, today's highly\ndeveloped social media makes fake news widely spread at incredible speed,\nbringing in substantial harm to various aspects of human life. Yet, the\npopularity of social media also provides opportunities to better detect fake\nnews. Unlike conventional means which merely focus on either content or user\ncomments, effective collaboration of heterogeneous social media information,\nincluding content and context factors of news, users' comments and the\nengagement of social media with users, will hopefully give rise to better\ndetection of fake news.\n  Motivated by the above observations, a novel detection framework, namely\ngraph comment-user advanced learning framework (GCAL) is proposed in this\npaper. User-comment information is crucial but not well studied in fake news\ndetection. Thus, we model user-comment context through network representation\nlearning based on heterogeneous graph neural network. We conduct experiments on\ntwo real-world datasets, which demonstrate that the proposed joint model\noutperforms 8 state-of-the-art baseline methods for fake news detection (at\nleast 4% in Accuracy, 7% in Recall and 5% in F1). Moreover, the proposed method\nis also explainable.", "doi": "", "date": "2020-11-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.01579v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 776382815, "title": "Predicting Misinformation and Engagement in COVID-19 Twitter Discourse\n  in the First Months of the Outbreak", "abstract": "Disinformation entails the purposeful dissemination of falsehoods towards a\ngreater dubious agenda and the chaotic fracturing of a society. The general\npublic has grown aware of the misuse of social media towards these nefarious\nends, where even global public health crises have not been immune to\nmisinformation (deceptive content spread without intended malice). In this\npaper, we examine nearly 505K COVID-19-related tweets from the initial months\nof the pandemic to understand misinformation as a function of bot-behavior and\nengagement. Using a correlation-based feature selection method, we selected the\n11 most relevant feature subsets among over 170 features to distinguish\nmisinformation from facts, and to predict highly engaging misinformation tweets\nabout COVID-19. We achieved an average F-score of at least 72\\% with ten\npopular multi-class classifiers, reinforcing the relevance of the selected\nfeatures. We found that (i) real users tweet both facts and misinformation,\nwhile bots tweet proportionally more misinformation; (ii) misinformation tweets\nwere less engaging than facts; (iii) the textual content of a tweet was the\nmost important to distinguish fact from misinformation while (iv) user account\nmetadata and human-like activity were most important to predict high engagement\nin factual and misinformation tweets; and (v) sentiment features were not\nrelevant.", "doi": "", "date": "2020-12-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.02164v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1548789121, "title": "TrollHunter [Evader]: Automated Detection [Evasion] of Twitter Trolls\n  During the COVID-19 Pandemic", "abstract": "This paper presents TrollHunter, an automated reasoning mechanism we used to\nhunt for trolls on Twitter during the COVID-19 pandemic in 2020. Trolls, poised\nto disrupt the online discourse and spread disinformation, quickly seized the\nabsence of a credible response to COVID-19 and created a COVID-19 infodemic by\npromulgating dubious content on Twitter. To counter the COVID-19 infodemic, the\nTrollHunter leverages a unique linguistic analysis of a multi-dimensional set\nof Twitter content features to detect whether or not a tweet was meant to\ntroll. TrollHunter achieved 98.5% accuracy, 75.4% precision and 69.8% recall\nover a dataset of 1.3 million tweets. Without a final resolution of the\npandemic in sight, it is unlikely that the trolls will go away, although they\nmight be forced to evade automated hunting. To explore the plausibility of this\nstrategy, we developed and tested an adversarial machine learning mechanism\ncalled TrollHunter-Evader. TrollHunter-Evader employs a Test Time Evasion (TTE)\napproach in a combination with a Markov chain-based mechanism to recycle\noriginally trolling tweets. The recycled tweets were able to achieve a\nremarkable 40% decrease in the TrollHunter's ability to correctly identify\ntrolling tweets. Because the COVID-19 infodemic could have a harmful impact on\nthe COVID-19 pandemic, we provide an elaborate discussion about the\nimplications of employing adversarial machine learning to evade Twitter troll\nhunts.", "doi": "", "date": "2020-12-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.02586v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1202117834, "title": "Facebook Ad Engagement in the Russian Active Measures Campaign of 2016", "abstract": "This paper examines 3,517 Facebook ads created by Russia's Internet Research\nAgency (IRA) between June 2015 and August 2017 in its active measures\ndisinformation campaign targeting the 2016 U.S. general election. We aimed to\nunearth the relationship between ad engagement (as measured by ad clicks) and\n41 features related to ads' metadata, sociolinguistic structures, and\nsentiment. Our analysis was three-fold: (i) understand the relationship between\nengagement and features via correlation analysis; (ii) find the most relevant\nfeature subsets to predict engagement via feature selection; and (iii) find the\nsemantic topics that best characterize the dataset via topic modeling. We found\nthat ad expenditure, text size, ad lifetime, and sentiment were the top\nfeatures predicting users' engagement to the ads. Additionally, positive\nsentiment ads were more engaging than negative ads, and sociolinguistic\nfeatures (e.g., use of religion-relevant words) were identified as highly\nimportant in the makeup of an engaging ad. Linear SVM and Logistic Regression\nclassifiers achieved the highest mean F-scores (93.6% for both models),\ndetermining that the optimal feature subset contains 12 and 6 features,\nrespectively. Finally, we corroborate the findings of related works that the\nIRA specifically targeted Americans on divisive ad topics (e.g., LGBT rights,\nAfrican American reparations).", "doi": "", "date": "2020-12-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.11690v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3605409042, "title": "Deepfakes Generation and Detection: State-of-the-art, open challenges,\n  countermeasures, and way forward", "abstract": "Easy access to audio-visual content on social media, combined with the\navailability of modern tools such as Tensorflow or Keras, open-source trained\nmodels, and economical computing infrastructure, and the rapid evolution of\ndeep-learning (DL) methods, especially Generative Adversarial Networks (GAN),\nhave made it possible to generate deepfakes to disseminate disinformation,\nrevenge porn, financial frauds, hoaxes, and to disrupt government functioning.\nThe existing surveys have mainly focused on deepfake video detection only. No\nattempt has been made to review approaches for detection and generation of both\naudio and video deepfakes. This paper provides a comprehensive review and\ndetailed analysis of existing tools and machine learning (ML) based approaches\nfor deepfake generation and the methodologies used to detect such manipulations\nfor the detection and generation of both audio and video deepfakes. For each\ncategory of deepfake, we discuss information related to manipulation\napproaches, current public datasets, and key standards for the performance\nevaluation of deepfake detection techniques along with their results.\nAdditionally, we also discuss open challenges and enumerate future directions\nto guide future researchers on issues that need to be considered to improve the\ndomains of both the deepfake generation and detection. This work is expected to\nassist the readers in understanding the creation and detection mechanisms of\ndeepfake, along with their current limitations and future direction.", "doi": "", "date": "2021-02-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.00484v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1928204902, "title": "Automatically Selecting Striking Images for Social Cards", "abstract": "To allow previewing a web page, social media platforms have developed social\ncards: visualizations consisting of vital information about the underlying\nresource. At a minimum, social cards often include features such as the web\nresource's title, text summary, striking image, and domain name. News and\nscholarly articles on the web are frequently subject to social card creation\nwhen being shared on social media. However, we noticed that not all web\nresources offer sufficient metadata elements to enable appealing social cards.\nFor example, the COVID-19 emergency has made it clear that scholarly articles,\nin particular, are at an aesthetic disadvantage in social media platforms when\ncompared to their often more flashy disinformation rivals. Also, social cards\nare often not generated correctly for archived web resources, including pages\nthat lack or predate standards for specifying striking images. With these\nobservations, we are motivated to quantify the levels of inclusion of required\nmetadata in web resources, its evolution over time for archived resources, and\ncreate and evaluate an algorithm to automatically select a striking image for\nsocial cards. We find that more than 40% of archived news articles sampled from\nthe NEWSROOM dataset and 22% of scholarly articles sampled from the PubMed\nCentral dataset fail to supply striking images. We demonstrate that we can\nautomatically predict the striking image with a Precision@1 of 0.83 for news\narticles from NEWSROOM and 0.78 for scholarly articles from the open access\njournal PLOS ONE.", "doi": "", "date": "2021-03-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.04899v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2315472439, "title": "A Survey on Predicting the Factuality and the Bias of News Media", "abstract": "The present level of proliferation of fake, biased, and propagandistic\ncontent online has made it impossible to fact-check every single suspicious\nclaim or article, either manually or automatically. Thus, many researchers are\nshifting their attention to higher granularity, aiming to profile entire news\noutlets, which makes it possible to detect likely \"fake news\" the moment it is\npublished, by simply checking the reliability of its source. Source factuality\nis also an important element of systems for automatic fact-checking and \"fake\nnews\" detection, as they need to assess the reliability of the evidence they\nretrieve online. Political bias detection, which in the Western political\nlandscape is about predicting left-center-right bias, is an equally important\ntopic, which has experienced a similar shift towards profiling entire news\noutlets. Moreover, there is a clear connection between the two, as highly\nbiased media are less likely to be factual; yet, the two problems have been\naddressed separately. In this survey, we review the state of the art on media\nprofiling for factuality and bias, arguing for the need to model them jointly.\nWe further discuss interesting recent advances in using different information\nsources and modalities, which go beyond the text of the articles the target\nnews outlet has published. Finally, we discuss current challenges and outline\nfuture research directions.", "doi": "", "date": "2021-03-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.12506v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1920045159, "title": "Understanding the Puzzle of Primary Health-care Use: Evidence from India", "abstract": "In India, households' use of primary health-care services presents a puzzle.\nEven though most private health-care providers have no formal medical\nqualifications, a significant fraction of households use fee-charging private\nhealth-care services, which are not covered by insurance. Although the absence\nof public health-care providers could partially explain the high use of the\nprivate sector, this cannot be the only explanation. The private share of\nhealth-care use is even higher in markets where qualified doctors offer free\ncare through public clinics; despite this free service, the majority of\nhealth-care visits are made to providers with no formal medical qualifications.\nThis paper examines the reasons for the existence of this puzzle in India.\nCombining contemporary household-level data with archival records, I examine\nthe aggressive family planning program implemented during the emergency rule in\nthe 1970s and explore whether the coercion, disinformation, and carelessness\ninvolved in implementing the program could partly explain the puzzle.\nExploiting the timing of the emergency rule, state-level variation in the\nnumber of sterilizations, and an instrumental variable approach, I show that\nthe states heavily affected by the sterilization policy have a lower level of\npublic health-care usage today. I demonstrate the mechanism for this practice\nby showing that the states heavily affected by forced sterilizations have a\nlower level of confidence in government hospitals and doctors and a higher\nlevel of confidence in private hospitals and doctors in providing good\ntreatment.", "doi": "", "date": "2021-03-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.13737v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3397888797, "title": "User Preference-aware Fake News Detection", "abstract": "Disinformation and fake news have posed detrimental effects on individuals\nand society in recent years, attracting broad attention to fake news detection.\nThe majority of existing fake news detection algorithms focus on mining news\ncontent and/or the surrounding exogenous context for discovering deceptive\nsignals; while the endogenous preference of a user when he/she decides to\nspread a piece of fake news or not is ignored. The confirmation bias theory has\nindicated that a user is more likely to spread a piece of fake news when it\nconfirms his/her existing beliefs/preferences. Users' historical, social\nengagements such as posts provide rich information about users' preferences\ntoward news and have great potential to advance fake news detection. However,\nthe work on exploring user preference for fake news detection is somewhat\nlimited. Therefore, in this paper, we study the novel problem of exploiting\nuser preference for fake news detection. We propose a new framework, UPFD,\nwhich simultaneously captures various signals from user preferences by joint\ncontent and graph modeling. Experimental results on real-world datasets\ndemonstrate the effectiveness of the proposed framework. We release our code\nand data as a benchmark for GNN-based fake news detection:\nhttps://github.com/safe-graph/GNN-FakeNews.", "doi": "", "date": "2021-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.12259v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1737415682, "title": "Spinning Sequence-to-Sequence Models with Meta-Backdoors", "abstract": "We investigate a new threat to neural sequence-to-sequence (seq2seq) models:\ntraining-time attacks that cause models to \"spin\" their output and support a\ncertain sentiment when the input contains adversary-chosen trigger words. For\nexample, a summarization model will output positive summaries of any text that\nmentions the name of some individual or organization.\n  We introduce the concept of a \"meta-backdoor\" to explain model-spinning\nattacks. These attacks produce models whose output is valid and preserves\ncontext, yet also satisfies a meta-task chosen by the adversary (e.g., positive\nsentiment). Previously studied backdoors in language models simply flip\nsentiment labels or replace words without regard to context. Their outputs are\nincorrect on inputs with the trigger. Meta-backdoors, on the other hand, are\nthe first class of backdoors that can be deployed against seq2seq models to (a)\nintroduce adversary-chosen spin into the output, while (b) maintaining standard\naccuracy metrics.\n  To demonstrate feasibility of model spinning, we develop a new backdooring\ntechnique. It stacks the adversarial meta-task (e.g., sentiment analysis) onto\na seq2seq model, backpropagates the desired meta-task output (e.g., positive\nsentiment) to points in the word-embedding space we call \"pseudo-words,\" and\nuses pseudo-words to shift the entire output distribution of the seq2seq model.\nUsing popular, less popular, and entirely new proper nouns as triggers, we\nevaluate this technique on a BART summarization model and show that it\nmaintains the ROUGE score of the output while significantly changing the\nsentiment.\n  We explain why model spinning can be a dangerous technique in AI-powered\ndisinformation and discuss how to mitigate these attacks.", "doi": "", "date": "2021-07-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.10443v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 76501159, "title": "Uncovering the structure of the French media ecosystem", "abstract": "This study provides a large-scale mapping of the French media space using\ndigital methods to estimate political polarization and to study information\ncircuits. We collect data about the production and circulation of online news\nstories in France over the course of one year, adopting a multi-layer\nperspective on the media ecosystem. We source our data from websites, Twitter\nand Facebook. We also identify a certain number of important structural\nfeatures. A stochastic block model of the hyperlinks structure shows the\nsystematic rejection of counter-informational press in a separate cluster which\nhardly receives any attention from the mainstream media. Counter-informational\nsub-spaces are also peripheral on the consumption side. We measure their\nrespective audiences on Twitter and Facebook and do not observe a large\ndiscrepancy between both social networks, with counter-information space, far\nright and far left media gathering limited audiences. Finally, we also measure\nthe ideological distribution of news stories using Twitter data, which also\nsuggests that the French media landscape is quite balanced. We therefore\nconclude that the French media ecosystem does not suffer from the same level of\npolarization as the US media ecosystem. The comparison with the American\nsituation also allows us to consolidate a result from studies on\ndisinformation: the polarization of the journalistic space and the circulation\nof fake news are phenomena that only become more widespread when dominant and\ninfluential actors in the political or journalistic space spread topics and\ndubious content originally circulating in the fringe of the information space.", "doi": "", "date": "2021-07-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.12073v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1456028799, "title": "The State of AI Ethics Report (Volume 5)", "abstract": "This report from the Montreal AI Ethics Institute covers the most salient\nprogress in research and reporting over the second quarter of 2021 in the field\nof AI ethics with a special emphasis on \"Environment and AI\", \"Creativity and\nAI\", and \"Geopolitics and AI.\" The report also features an exclusive piece\ntitled \"Critical Race Quantum Computer\" that applies ideas from quantum physics\nto explain the complexities of human characteristics and how they can and\nshould shape our interactions with each other. The report also features special\ncontributions on the subject of pedagogy in AI ethics, sociology and AI ethics,\nand organizational challenges to implementing AI ethics in practice. Given\nMAIEI's mission to highlight scholars from around the world working on AI\nethics issues, the report also features two spotlights sharing the work of\nscholars operating in Singapore and Mexico helping to shape policy measures as\nthey relate to the responsible use of technology. The report also has an\nextensive section covering the gamut of issues when it comes to the societal\nimpacts of AI covering areas of bias, privacy, transparency, accountability,\nfairness, interpretability, disinformation, policymaking, law, regulations, and\nmoral philosophy.", "doi": "", "date": "2021-08-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.03929v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2766363836, "title": "Combining Similarity Features and Deep Representation Learning for\n  Stance Detection in the Context of Checking Fake News", "abstract": "Fake news are nowadays an issue of pressing concern, given their recent rise\nas a potential threat to high-quality journalism and well-informed public\ndiscourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage\nthe development of machine learning-based classification systems for stance\ndetection (i.e., for identifying whether a particular news article agrees,\ndisagrees, discusses, or is unrelated to a particular news headline), thus\nhelping in the detection and analysis of possible instances of fake news. This\narticle presents a new approach to tackle this stance detection problem, based\non the combination of string similarity features with a deep neural\narchitecture that leverages ideas previously advanced in the context of\nlearning efficient text representations, document classification, and natural\nlanguage inference. Specifically, we use bi-directional Recurrent Neural\nNetworks, together with max-pooling over the temporal/sequential dimension and\nneural attention, for representing (i) the headline, (ii) the first two\nsentences of the news article, and (iii) the entire news article. These\nrepresentations are then combined/compared, complemented with similarity\nfeatures inspired on other FNC-1 approaches, and passed to a final layer that\npredicts the stance of the article towards the headline. We also explore the\nuse of external sources of information, specifically large datasets of sentence\npairs originally proposed for training and evaluating natural language\ninference methods, in order to pre-train specific components of the neural\nnetwork architecture (e.g., the RNNs used for encoding sentences). The obtained\nresults attest to the effectiveness of the proposed ideas and show that our\nmodel, particularly when considering pre-training and the combination of neural\nrepresentations together with similarity features, slightly outperforms the\nprevious state-of-the-art.", "doi": "", "date": "2018-11-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.00706v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2042028434, "title": "Who Let The Trolls Out? Towards Understanding State-Sponsored Trolls", "abstract": "Recent evidence has emerged linking coordinated campaigns by state-sponsored\nactors to manipulate public opinion on the Web. Campaigns revolving around\nmajor political events are enacted via mission-focused \"trolls.\" While trolls\nare involved in spreading disinformation on social media, there is little\nunderstanding of how they operate, what type of content they disseminate, how\ntheir strategies evolve over time, and how they influence the Web's information\necosystem. In this paper, we begin to address this gap by analyzing 10M posts\nby 5.5K Twitter and Reddit users identified as Russian and Iranian\nstate-sponsored trolls. We compare the behavior of each group of\nstate-sponsored trolls with a focus on how their strategies change over time,\nthe different campaigns they embark on, and differences between the trolls\noperated by Russia and Iran. Among other things, we find: 1) that Russian\ntrolls were pro-Trump while Iranian trolls were anti-Trump; 2) evidence that\ncampaigns undertaken by such actors are influenced by real-world events; and 3)\nthat the behavior of such actors is not consistent over time, hence automated\ndetection is not a straightforward task. Using the Hawkes Processes statistical\nmodel, we quantify the influence these accounts have on pushing URLs on four\nsocial platforms: Twitter, Reddit, 4chan's Politically Incorrect board (/pol/),\nand Gab. In general, Russian trolls were more influential and efficient in\npushing URLs to all the other platforms with the exception of /pol/ where\nIranians were more influential. Finally, we release our data and source code to\nensure the reproducibility of our results and to encourage other researchers to\nwork on understanding other emerging kinds of state-sponsored troll accounts on\nTwitter.", "doi": "", "date": "2018-11-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.03130v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2675394989, "title": "Trust Evaluation Mechanism for User Recruitment in Mobile Crowd-Sensing\n  in the Internet of Things", "abstract": "Mobile Crowd-Sensing (MCS) has appeared as a prospective solution for\nlarge-scale data collection, leveraging built-in sensors and social\napplications in mobile devices that enables a variety of Internet of Things\n(IoT) services. However, the human involvement in MCS results in a high\npossibility for unintentionally contributing corrupted and falsified data or\nintentionally spreading disinformation for malevolent purposes, consequently\nundermining IoT services. Therefore, recruiting trustworthy contributors plays\na crucial role in collecting high-quality data and providing better quality of\nservices while minimizing the vulnerabilities and risks to MCS systems. In this\narticle, a novel trust model called Experience-Reputation (E-R) is proposed for\nevaluating trust relationships between any two mobile device users in a MCS\nplatform. To enable the E-R model, virtual interactions among the users are\nmanipulated by considering an assessment of the quality of contributed data\nfrom such users. Based on these interactions, two indicators of trust called\nExperience and Reputation are calculated accordingly. By incorporating the\nExperience and Reputation trust indicators (TIs), trust relationships between\nthe users are established, evaluated and maintained. Based on these trust\nrelationships, a novel trust-based recruitment scheme is carried out for\nselecting the most trustworthy MCS users to contribute to data sensing tasks.\nIn order to evaluate the performance and effectiveness of the proposed\ntrust-based mechanism as well as the E-R trust model, we deploy several\nrecruitment schemes in a MCS testbed which consists of both normal and\nmalicious users. The results highlight the strength of the trust-based scheme\nas it delivers better quality for MCS services while being able to detect\nmalicious users.", "doi": "10.1109/tifs.2019.2903659", "date": "2019-03-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.01464v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1062579524, "title": "Embedding Climate Change Engagement in Astronomy Education and Research", "abstract": "This White Paper is a call to action for astronomers to respond to climate\nchange with a large structural transition within our profession. Many\nastronomers are deeply concerned about climate change and act upon it in their\npersonal and professional lives, and many organizations within astronomy have\nincorporated incremental changes. We need a collective impact model to better\nnetwork and grow our efforts so that we can achieve results that are on the\nscale appropriate to address climate change at the necessary level indicated by\nscientific research; e.g., becoming carbon neutral by 2050. We need to\nimplement strategies within two primary drivers of our field: (1) Education and\nOutreach, and (2) Research Practices and Infrastructure. (1) In the classroom\nand through public talks, astronomers reach a large audience. Astronomy is\nclosely connected to the science of climate change, and it is arguably the most\nimportant topic we include in our curriculum. Due to misinformation and\ndisinformation, climate change communication is different than for other areas\nof science. We therefore need to expand our communication and implement\neffective strategies, for which there is now a considerable body of research.\n(2) On a per-person basis astronomers have an outsized carbon impact. There are\nnumerous ways we can reduce our footprint; e.g., in the design and operation of\ntelescope facilities and in the optimization and reduction of travel.\nFortunately, many of these solutions are win-win scenarios, e.g., increasing\nthe online presence of conferences will reduce the carbon footprint while\nincreasing participation, especially for astronomers working with fewer\nfinancial resources. Astronomers have an obligation to act on climate change in\nevery way possible, and we need to do it now. In this White Paper, we outline a\nplan for collective impact using a Networked Improvement Community (NIC)\napproach.", "doi": "", "date": "2019-07-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.08043v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2751228307, "title": "Towards Understanding the Information Ecosystem Through the Lens of\n  Multiple Web Communities", "abstract": "The Web consists of numerous Web communities, news sources, and services,\nwhich are often exploited by various entities for the dissemination of false\ninformation. Yet, we lack tools and techniques to effectively track the\npropagation of information across the multiple diverse communities, and to\nmodel the interplay and influence between them. Also, we lack an understanding\nof what the role and impact of emerging communities and services on the Web\nare, and how such communities are exploited by bad actors that spread false and\nweaponized information. In this thesis, we study the information ecosystem on\nthe Web by presenting a typology that includes the various types of false\ninformation, the involved actors and their possible motives. Then, we follow a\ndata-driven cross-platform quantitative approach to analyze billions of posts\nfrom Twitter, Reddit, 4chan's /pol/, and Gab, to shed light on: 1) how news and\nmemes travel from one Web community to another and how we can model and\nquantify the influence between Web communities; 2) characterizing the role of\nemerging Web communities and services on the Web, by studying Gab and two Web\narchiving services, namely the Wayback Machine and archive.is; and 3) how\npopular Web communities are exploited by state-sponsored actors for the purpose\nof spreading disinformation. Our analysis reveal that fringe Web communities\nlike 4chan's /pol/ and The_Donald subreddit have a disproportionate influence\non mainstream communities like Twitter with regard to the dissemination of news\nand memes. We find that Gab acts as the new hub for the alt-right community,\nwhile for Web archiving services we find that they can be misused to penalize\nad revenue from news sources with conflicting ideology. Finally, when studying\nstate-sponsored actors, we find that they were particularly influential in\nspreading news on popular communities like Twitter and Reddit.", "doi": "", "date": "2019-11-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.10517v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3402755139, "title": "Automatically Identifying Political Ads on Facebook: Towards\n  Understanding of Manipulation via User Targeting", "abstract": "The reports of Russian interference in the 2016 United States elections\nbrought into the center of public attention concerns related to the ability of\nforeign actors to increase social discord and take advantage of personal user\ndata for political purposes. It has raised questions regarding the ways and the\nextent to which data can be used to create psychographical profiles to\ndetermine what kind of advertisement would be most effective to persuade a\nparticular person in a particular location for some political event. In this\nwork, we study the political ads dataset collected by ProPublica, an American\nnonprofit newsroom, using a network of volunteers in the period before the 2018\nUS midterm elections. We first describe the main characteristics of the data\nand explore the user attributes including age, region, activity, and more, with\na series of interactive illustrations. Furthermore, an important first step\ntowards understating of political manipulation via user targeting is to\nidentify politically related ads, yet manually checking ads is not feasible due\nto the scale of social media advertising. Consequently, we address the\nchallenge of automatically classifying between political and non-political ads,\ndemonstrating a significant improvement compared to the current text-based\nclassifier used by ProPublica, and study whether the user targeting attributes\nare beneficial for this task. Our evaluation sheds light on questions, such as\nhow user attributes are being used for political ads targeting and which users\nare more prone to be targeted with political ads. Overall, our contribution of\ndata exploration, political ad classification and initial analysis of the\ntargeting attributes, is designed to support future work with the ProPublica\ndataset, and specifically with regard to the understanding of political\nmanipulation via user targeting.", "doi": "", "date": "2020-04-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.09745v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1706681494, "title": "The State of AI Ethics Report (June 2020)", "abstract": "These past few months have been especially challenging, and the deployment of\ntechnology in ways hitherto untested at an unrivalled pace has left the\ninternet and technology watchers aghast. Artificial intelligence has become the\nbyword for technological progress and is being used in everything from helping\nus combat the COVID-19 pandemic to nudging our attention in different\ndirections as we all spend increasingly larger amounts of time online. It has\nnever been more important that we keep a sharp eye out on the development of\nthis field and how it is shaping our society and interactions with each other.\nWith this inaugural edition of the State of AI Ethics we hope to bring forward\nthe most important developments that caught our attention at the Montreal AI\nEthics Institute this past quarter. Our goal is to help you navigate this\never-evolving field swiftly and allow you and your organization to make\ninformed decisions. This pulse-check for the state of discourse, research, and\ndevelopment is geared towards researchers and practitioners alike who are\nmaking decisions on behalf of their organizations in considering the societal\nimpacts of AI-enabled solutions. We cover a wide set of areas in this report\nspanning Agency and Responsibility, Security and Risk, Disinformation, Jobs and\nLabor, the Future of AI Ethics, and more. Our staff has worked tirelessly over\nthe past quarter surfacing signal from the noise so that you are equipped with\nthe right tools and knowledge to confidently tread this complex yet\nconsequential domain.", "doi": "", "date": "2020-06-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.14662v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2665895732, "title": "A Decade of Social Bot Detection", "abstract": "On the morning of November 9th 2016, the world woke up to the shocking\noutcome of the US Presidential elections: Donald Trump was the 45th President\nof the United States of America. An unexpected event that still has tremendous\nconsequences all over the world. Today, we know that a minority of social bots,\nautomated social media accounts mimicking humans, played a central role in\nspreading divisive messages and disinformation, possibly contributing to\nTrump's victory. In the aftermath of the 2016 US elections, the world started\nto realize the gravity of widespread deception in social media. Following\nTrump's exploit, we witnessed to the emergence of a strident dissonance between\nthe multitude of efforts for detecting and removing bots, and the increasing\neffects that these malicious actors seem to have on our societies. This paradox\nopens a burning question: What strategies should we enforce in order to stop\nthis social bot pandemic? In these times, during the run-up to the 2020 US\nelections, the question appears as more crucial than ever. What stroke social,\npolitical and economic analysts after 2016, deception and automation, has been\nhowever a matter of study for computer scientists since at least 2010. In this\nwork, we briefly survey the first decade of research in social bot detection.\nVia a longitudinal analysis, we discuss the main trends of research in the\nfight against bots, the major results that were achieved, and the factors that\nmake this never-ending battle so challenging. Capitalizing on lessons learned\nfrom our extensive analysis, we suggest possible innovations that could give us\nthe upper hand against deception and manipulation. Studying a decade of\nendeavours at social bot detection can also inform strategies for detecting and\nmitigating the effects of other, more recent, forms of online deception, such\nas strategic information operations and political trolls.", "doi": "10.1145/3409116", "date": "2020-06-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.03604v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4139597941, "title": "Decoy Allocation Games on Graphs with Temporal Logic Objectives", "abstract": "We study a class of games, in which the adversary (attacker) is to satisfy a\ncomplex mission specified in linear temporal logic, and the defender is to\nprevent the adversary from achieving its goal. A deceptive defender can\nallocate decoys, in addition to defense actions, to create disinformation for\nthe attacker. Thus, we focus on the problem of jointly synthesizing a decoy\nplacement strategy and a deceptive defense strategy that maximally exploits the\nincomplete information the attacker about the decoy locations. We introduce a\nmodel of hypergames on graphs with temporal logic objectives to capture such\nadversarial interactions with asymmetric information. Using the hypergame\nmodel, we analyze the effectiveness of a given decoy placement, quantified by\nthe set of deceptive winning states where the defender can prevent the attacker\nfrom satisfying the attack objective given its incomplete information about\ndecoy locations. Then, we investigate how to place decoys to maximize the\ndefender's deceptive winning region. Considering the large search space for all\npossible decoy allocation strategies, we incorporate the idea of compositional\nsynthesis from formal methods and show that the objective function in the class\nof decoy allocation problem is monotone and non-decreasing. We derive the\nsufficient conditions under which the objective function for the decoy\nallocation problem is submodular, or supermodular, respectively. We show a\nsub-optimal allocation can be efficiently computed by iteratively composing the\nsolutions of hypergames with a subset of decoys and the solution of a hypergame\ngiven a single decoy. We use a running example to illustrate the proposed\nmethod.", "doi": "", "date": "2020-10-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.01208v1", "pdf": ""}, "publisher-venue": "Conference on Decision\\n  and Game Theory for Security (GameSec) 2020", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1139144424, "title": "The State of AI Ethics Report (October 2020)", "abstract": "The 2nd edition of the Montreal AI Ethics Institute's The State of AI Ethics\ncaptures the most relevant developments in the field of AI Ethics since July\n2020. This report aims to help anyone, from machine learning experts to human\nrights activists and policymakers, quickly digest and understand the\never-changing developments in the field. Through research and article\nsummaries, as well as expert commentary, this report distills the research and\nreporting surrounding various domains related to the ethics of AI, including:\nAI and society, bias and algorithmic justice, disinformation, humans and AI,\nlabor impacts, privacy, risk, and future of AI ethics.\n  In addition, The State of AI Ethics includes exclusive content written by\nworld-class AI Ethics experts from universities, research institutes,\nconsulting firms, and governments. These experts include: Danit Gal (Tech\nAdvisor, United Nations), Amba Kak (Director of Global Policy and Programs,\nNYU's AI Now Institute), Rumman Chowdhury (Global Lead for Responsible AI,\nAccenture), Brent Barron (Director of Strategic Projects and Knowledge\nManagement, CIFAR), Adam Murray (U.S. Diplomat working on tech policy, Chair of\nthe OECD Network on AI), Thomas Kochan (Professor, MIT Sloan School of\nManagement), and Katya Klinova (AI and Economy Program Lead, Partnership on\nAI).\n  This report should be used not only as a point of reference and insight on\nthe latest thinking in the field of AI Ethics, but should also be used as a\ntool for introspection as we aim to foster a more nuanced conversation\nregarding the impacts of AI on the world.", "doi": "", "date": "2020-11-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.02787v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1833834214, "title": "Cognitive Contagion: How to model (and potentially counter) the spread\n  of fake news", "abstract": "Understanding the spread of false or dangerous beliefs - so-called\nmis/disinformation - through a population has never seemed so urgent to many.\nNetwork science researchers have often taken a page from epidemiologists, and\nmodeled the spread of false beliefs as similar to how a disease spreads through\na social network. However, absent from those disease-inspired models is an\ninternal model of an individual's set of current beliefs, where cognitive\nscience has increasingly documented how the interaction between mental models\nand incoming messages seems to be crucially important for their adoption or\nrejection. We introduce a cognitive contagion model that combines a network\nscience approach with an internal cognitive model of the individual agents,\naffecting what they believe, and what they pass on. We show that the model,\neven with a very discrete and simplistic belief function to capture cognitive\ndissonance, both adds expressive power over existing disease-based contagion\nmodels, and qualitatively demonstrates the appropriate belief update phenomena\nat the individual level. Moreover, we situate our cognitive contagion model in\na larger public opinion diffusion model, which attempts to capture the role of\ninstitutions or media sources in belief diffusion - something that is often\nleft out. We conduct an analysis of the POD model with our simple cognitive\ndissonance-sensitive update function across various graph topologies and\ninstitutional messaging patterns. We demonstrate that population-level\naggregate outcomes of the model qualitatively match what has been reported in\nCOVID misinformation public opinion polls. The overall model sets up a\npreliminary framework with which social science misinformation researchers and\ncomputational opinion diffusion modelers can join forces to understand, and\nhopefully learn how to best counter, the spread of misinformation and\n\"alternative facts.\"", "doi": "", "date": "2021-07-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.02828v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1865779534, "title": "Automatic detection of influential actors in disinformation networks.", "abstract": "", "doi": "10.1073/pnas.2011216118", "date": "2021", "authors": [{"name": "Steven Thomas Smith", "id-internal": "120/7245", "id-external": ""}, {"name": "Edward K. Kao", "id-internal": "67/9054", "id-external": ""}, {"name": "Erika D. Mackin", "id-internal": "162/0170", "id-external": ""}, {"name": "Danelle C. Shah", "id-internal": "74/9968", "id-external": ""}, {"name": "Olga Simek", "id-internal": "137/3712", "id-external": ""}, {"name": "Donald B. Rubin", "id-internal": "58/44", "id-external": ""}], "url": {"full": "URL#78336", "pdf": ""}, "publisher-venue": "Proc. Natl. Acad. Sci. USA", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1487606525, "title": "Exploring the Links between Personality Traits and Susceptibility to Disinformation.", "abstract": "", "doi": "10.1145/3465336.3475121", "date": "2021", "authors": [{"name": "Dipto Barman", "id-internal": "234/1883", "id-external": ""}, {"name": "Owen Conlan", "id-internal": "70/1905", "id-external": ""}], "url": {"full": "URL#151523", "pdf": ""}, "publisher-venue": "HT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3707486390, "title": "Unveiling Coordinated Groups Behind White Helmets Disinformation.", "abstract": "", "doi": "10.1145/3366424.3385775", "date": "2020", "authors": [{"name": "Diogo Pacheco", "id-internal": "241/7654", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}], "url": {"full": "URL#577165", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}][{"id": 1453520808, "title": "Memetics of Deception - Spreading Local Meme Hoaxes during COVID-19 1st Year.", "abstract": "", "doi": "10.3390/fi13060152", "date": "2021", "authors": [{"name": "Ra\u00fal Rodr\u00edguez-Ferr\u00e1ndiz", "id-internal": "296/3556", "id-external": ""}, {"name": "Cande S\u00e1nchez-Olmos", "id-internal": "296/3407", "id-external": ""}, {"name": "Tatiana Hidalgo-Mar\u00ed", "id-internal": "227/9697", "id-external": ""}, {"name": "Estela Saquete Bor\u00f3", "id-internal": "s/EstelaSaqueteBoro", "id-external": ""}], "url": {"full": "URL#38387", "pdf": ""}, "publisher-venue": "Future Internet", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2935293266, "title": "The Sokol Hoax - A 25-Year Retrospective.", "abstract": "", "doi": "10.1109/mc.2020.2964894", "date": "2020", "authors": {"name": "Hal Berghel", "id-internal": "b/HalBerghel", "id-external": ""}, "url": {"full": "URL#286041", "pdf": ""}, "publisher-venue": "Computer", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3905947232, "title": "Early Detection of Social Media Hoaxes at Scale.", "abstract": "", "doi": "10.1145/3407194", "date": "2020", "authors": [{"name": "Arkaitz Zubiaga", "id-internal": "34/7374", "id-external": ""}, {"name": "Aiqi Jiang", "id-internal": "230/4077", "id-external": ""}], "url": {"full": "URL#414784", "pdf": ""}, "publisher-venue": "ACM Trans. Web", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3722893773, "title": "A Deep Model on Hoax Detection Using Feed Forward Neural Network and LSTM.", "abstract": "", "doi": "10.14704/web/v17i2/web17058", "date": "2020", "authors": [{"name": "Guntha Venkata Dhanush Kumar", "id-internal": "284/7239", "id-external": ""}, {"name": "Mamatha V. Jadhav", "id-internal": "284/7642", "id-external": ""}, {"name": "Anvesh Tadisetti", "id-internal": "284/7269", "id-external": ""}, {"name": "Kiran", "id-internal": "18/6914", "id-external": ""}], "url": {"full": "URL#416439", "pdf": ""}, "publisher-venue": "Webology", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1104258156, "title": "Social media hoaxes, political ideology, and the role of issue confidence.", "abstract": "", "doi": "10.1016/j.tele.2018.11.001", "date": "2019", "authors": [{"name": "Keonyoung Park", "id-internal": "234/3953", "id-external": ""}, {"name": "Hyejoon Rim", "id-internal": "234/3969", "id-external": ""}], "url": {"full": "URL#800677", "pdf": ""}, "publisher-venue": "Telematics Informatics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2616039519, "title": "Predictive Models for Early Detection of Hoax Spread in Twitter.", "abstract": "", "doi": "10.1109/icdmw.2019.00018", "date": "2019", "authors": [{"name": "Didier Henry", "id-internal": "206/1498", "id-external": ""}, {"name": "Erick Stattner", "id-internal": "20/8138", "id-external": ""}], "url": {"full": "URL#900032", "pdf": ""}, "publisher-venue": "ICDM Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 995129905, "title": "Christopher Marlowe - Hype and Hoax.", "abstract": "", "doi": "10.1093/llc/fqy001", "date": "2018", "authors": {"name": "Hartmut Ilsemann", "id-internal": "38/11114", "id-external": ""}, "url": {"full": "URL#1148164", "pdf": ""}, "publisher-venue": "Digit. Scholarsh. Humanit.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 917243903, "title": "With Few Eyes, All Hoaxes are Deep.", "abstract": "", "doi": "10.1145/3274290", "date": "2018", "authors": [{"name": "Sumit Asthana", "id-internal": "234/4576", "id-external": ""}, {"name": "Aaron Halfaker", "id-internal": "26/2369", "id-external": ""}], "url": {"full": "URL#1158834", "pdf": ""}, "publisher-venue": "Proc. ACM Hum. Comput. Interact.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1768736417, "title": "Image-Based Hoax Detection.", "abstract": "", "doi": "10.1145/3284869.3284903", "date": "2018", "authors": [{"name": "Giulio Angiani", "id-internal": "190/2220", "id-external": ""}, {"name": "Gaudioso Junior Balba", "id-internal": "237/2446", "id-external": ""}, {"name": "Paolo Fornacciari", "id-internal": "164/4696", "id-external": ""}, {"name": "Gianfranco Lombardo", "id-internal": "215/8356", "id-external": ""}, {"name": "Monica Mordonini", "id-internal": "92/1279", "id-external": ""}, {"name": "Michele Tomaiuolo", "id-internal": "87/296", "id-external": ""}], "url": {"full": "URL#1263439", "pdf": ""}, "publisher-venue": "GOODTECHS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3126252172, "title": "Fusion-Based Multimodal Detection of Hoaxes in Social Networks.", "abstract": "", "doi": "10.1109/wi.2018.00-86", "date": "2018", "authors": [{"name": "C\u00e9dric Maigrot", "id-internal": "174/6714", "id-external": ""}, {"name": "Vincent Claveau", "id-internal": "35/6385", "id-external": ""}, {"name": "Ewa Kijak", "id-internal": "09/6343", "id-external": ""}], "url": {"full": "URL#1369449", "pdf": ""}, "publisher-venue": "WI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3430378229, "title": "Learning Class-specific Word Representations for Early Detection of Hoaxes in Social Media.", "abstract": "", "doi": "", "date": "2018", "authors": {"name": "Arkaitz Zubiaga", "id-internal": "34/7374", "id-external": ""}, "url": {"full": "URL#1383224", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4171964849, "title": "Hoaxing statistical features of the Voynich Manuscript.", "abstract": "", "doi": "10.1080/01611194.2016.1206753", "date": "2017", "authors": [{"name": "Gordon Rugg", "id-internal": "23/4034", "id-external": ""}, {"name": "Gavin Taylor", "id-internal": "37/142", "id-external": ""}], "url": {"full": "URL#1452438", "pdf": ""}, "publisher-venue": "Cryptologia", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1998368872, "title": "Cyborg hoaxes - Disability, deception, and critical studies of digital media.", "abstract": "", "doi": "10.1177/1461444816642754", "date": "2017", "authors": {"name": "Elizabeth Ellcessor", "id-internal": "31/9683", "id-external": ""}, "url": {"full": "URL#1513081", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 232310654, "title": "Examination of Classifying Hoaxes over SNS Using Bayesian Network.", "abstract": "", "doi": "10.1109/candar.2017.103", "date": "2017", "authors": [{"name": "Ryutaro Ushigome", "id-internal": "218/3247", "id-external": ""}, {"name": "Takeshi Matsuda", "id-internal": "83/5477", "id-external": ""}, {"name": "Michio Sonoda", "id-internal": "58/10515", "id-external": ""}, {"name": "Jinhui Chao", "id-internal": "63/985", "id-external": ""}], "url": {"full": "URL#1617043", "pdf": ""}, "publisher-venue": "CANDAR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 797460073, "title": "Keynote Speaker II - Biomedical Engineering Research in the Social Network Analysis Era - Stance Classification for Analysis of Hoax Medical News in Social Media.", "abstract": "", "doi": "10.1016/j.procs.2017.10.049", "date": "2017", "authors": [{"name": "Mauridhi Hery Purnomo", "id-internal": "44/1535", "id-external": ""}, {"name": "Surya Sumpeno", "id-internal": "195/6543", "id-external": ""}, {"name": "Esther Irawati Setiawan", "id-internal": "274/8023", "id-external": ""}, {"name": "Diana Purwitasari", "id-internal": "45/3443", "id-external": ""}], "url": {"full": "URL#1625314", "pdf": ""}, "publisher-venue": "ICCSCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2280274421, "title": "Vandals and Hoaxes on the Web.", "abstract": "", "doi": "10.1145/3002137.3002139", "date": "2016", "authors": {"name": "Srijan Kumar", "id-internal": "131/9628", "id-external": ""}, "url": {"full": "URL#1901236", "pdf": ""}, "publisher-venue": "CyberSafety@CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2251273698, "title": "Collective Rumor correction on the Death Hoax.", "abstract": "", "doi": "", "date": "2016", "authors": [{"name": "Alton Y. K. Chua", "id-internal": "00/3451", "id-external": ""}, {"name": "Sin-Mei Cheah", "id-internal": "172/6760", "id-external": ""}, {"name": "Dion Hoe-Lian Goh", "id-internal": "06/4612", "id-external": ""}, {"name": "Ee-Peng Lim", "id-internal": "l/EePengLim", "id-external": ""}], "url": {"full": "URL#1998945", "pdf": ""}, "publisher-venue": "PACIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3942719566, "title": "Email Hoax Detection System Using Levenshtein Distance Method.", "abstract": "", "doi": "10.4304/jcp.9.2.441-446", "date": "2014", "authors": [{"name": "Yoke Yie Chen", "id-internal": "34/7187", "id-external": ""}, {"name": "Suet-Peng Yong", "id-internal": "30/8540", "id-external": ""}, {"name": "Adzlan Ishak", "id-internal": "142/5240", "id-external": ""}], "url": {"full": "URL#2418973", "pdf": ""}, "publisher-venue": "J. Comput.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 791103734, "title": "Xbox 360 Hoaxes, Social Engineering, and Gamertag Exploits.", "abstract": "", "doi": "10.1109/hicss.2013.633", "date": "2013", "authors": [{"name": "Ashley L. Podhradsky", "id-internal": "127/9908", "id-external": ""}, {"name": "Rob D'Ovidio", "id-internal": "56/10683", "id-external": ""}, {"name": "Pat Engebretson", "id-internal": "127/9727", "id-external": ""}, {"name": "Cindy Casey", "id-internal": "53/10686", "id-external": ""}], "url": {"full": "URL#2809516", "pdf": ""}, "publisher-venue": "HICSS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2318044098, "title": "The Masal Bugduv hoax - Football blogging and journalistic authority.", "abstract": "", "doi": "10.1177/1461444811420270", "date": "2012", "authors": [{"name": "Benjamin Burroughs", "id-internal": "115/8871", "id-external": ""}, {"name": "W. Jeffrey Burroughs", "id-internal": "115/8879", "id-external": ""}], "url": {"full": "URL#2994498", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3653051742, "title": "Detecting Hoaxes, Frauds, and Deception in Writing Style Online.", "abstract": "", "doi": "10.1109/sp.2012.34", "date": "2012", "authors": [{"name": "Sadia Afroz", "id-internal": "29/7562", "id-external": ""}, {"name": "Michael Brennan", "id-internal": "10/7564", "id-external": ""}, {"name": "Rachel Greenstadt", "id-internal": "93/655", "id-external": ""}], "url": {"full": "URL#3150461", "pdf": ""}, "publisher-venue": "IEEE Symposium on Security and Privacy", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 673492212, "title": "An Intelligent Automatic Hoax Detection System.", "abstract": "", "doi": "10.1007/978-3-642-04595-0_39", "date": "2009", "authors": [{"name": "Marin Vukovic", "id-internal": "25/2549", "id-external": ""}, {"name": "Kresimir Pripuzic", "id-internal": "94/386", "id-external": ""}, {"name": "Hrvoje Belani", "id-internal": "71/2621", "id-external": ""}], "url": {"full": "URL#3824702", "pdf": ""}, "publisher-venue": "KES", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2182252188, "title": "The Voynich Manuscript - Evidence of the Hoax Hypothesis.", "abstract": "", "doi": "10.1080/01611190601133539", "date": "2007", "authors": {"name": "Andreas Schinner", "id-internal": "14/4093", "id-external": ""}, "url": {"full": "URL#4093499", "pdf": ""}, "publisher-venue": "Cryptologia", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3358368345, "title": "An Elegant Hoax? A Possible Solution to the Voynich Manuscript.", "abstract": "", "doi": "10.1080/0161-110491892755", "date": "2004", "authors": {"name": "Gordon Rugg", "id-internal": "23/4034", "id-external": ""}, "url": {"full": "URL#4604215", "pdf": ""}, "publisher-venue": "Cryptologia", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 39415243, "title": "Reward, persuasion, and the Sokal Hoax - A study in citation identities.", "abstract": "", "doi": "10.1023/b:scie.0000027313.91401.9b", "date": "2004", "authors": {"name": "Howard D. White", "id-internal": "w/HowardDWhite", "id-external": ""}, "url": {"full": "URL#4630792", "pdf": ""}, "publisher-venue": "Scientometrics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1896210874, "title": "Identification and Doing Without It, IV - A Formal Mathematical Analysis for the Feveroles Case, of Mix-Up of Kinds and Ensuing Litigation; and a Formalism for the \"Cardiff Giant\" Double Hoax.", "abstract": "", "doi": "10.1080/01969720302861", "date": "2003", "authors": {"name": "Ephraim Nissan", "id-internal": "69/3457", "id-external": ""}, "url": {"full": "URL#4731698", "pdf": ""}, "publisher-venue": "Cybern. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 143574554, "title": "Clustering Hoax Fire Calls Using Evolutionary Computation Technology.", "abstract": "", "doi": "10.1007/3-540-45034-3_65", "date": "2003", "authors": [{"name": "Lili Yang", "id-internal": "19/6939", "id-external": ""}, {"name": "Michael Gell", "id-internal": "43/1318", "id-external": ""}, {"name": "Christian W. Dawson", "id-internal": "219/8082", "id-external": ""}, {"name": "Martin R. Brown", "id-internal": "06/3888", "id-external": ""}], "url": {"full": "URL#4803635", "pdf": ""}, "publisher-venue": "IEA/AIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3473319945, "title": "Spam, scams, chains, hoaxes and other junk mail.", "abstract": "", "doi": "10.1016/s0167-4048(02)01104-5", "date": "2002", "authors": {"name": "Stephen Hinde", "id-internal": "60/4814", "id-external": ""}, "url": {"full": "URL#4844358", "pdf": ""}, "publisher-venue": "Comput. Secur.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1230736912, "title": "Hoax E-mails and Bonsai Kittens - Are You E-literate in the Docuverse?", "abstract": "", "doi": "", "date": "2002", "authors": {"name": "Angela Lewis", "id-internal": "75/4069", "id-external": ""}, "url": {"full": "URL#4849429", "pdf": ""}, "publisher-venue": "First Monday", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1998963283, "title": "A machine resolution of a four-color hoax.", "abstract": "", "doi": "", "date": "2002", "authors": {"name": "Stan Wagon", "id-internal": "57/3987", "id-external": ""}, "url": {"full": "URL#4881490", "pdf": ""}, "publisher-venue": "CCCG", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2024690471, "title": "The Growing Problem of Virus Hoaxes.", "abstract": "", "doi": "10.1201/1086/43311.9.4.20000910/31368.8", "date": "2000", "authors": {"name": "Ben Rothke", "id-internal": "13/894", "id-external": ""}, "url": {"full": "URL#5030808", "pdf": ""}, "publisher-venue": "Inf. Secur. J. A Glob. Perspect.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 648382416, "title": "The Privacy Hoax.", "abstract": "", "doi": "10.1145/293411.293425", "date": "1999", "authors": {"name": "Brock N. Meeks", "id-internal": "61/4621", "id-external": ""}, "url": {"full": "URL#5096820", "pdf": ""}, "publisher-venue": "Commun. ACM", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3950824678, "title": "Are you prepared for an Internet hoax.", "abstract": "", "doi": "", "date": "1999", "authors": {"name": "Gilbert Held", "id-internal": "73/5294", "id-external": ""}, "url": {"full": "URL#5105048", "pdf": ""}, "publisher-venue": "Int. J. Netw. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1665607692, "title": "1984 - A hoax?", "abstract": "", "doi": "10.1002/asi.4630340112", "date": "1983", "authors": {"name": "Allan Whatley", "id-internal": "162/1777", "id-external": ""}, "url": {"full": "URL#5659686", "pdf": ""}, "publisher-venue": "J. Am. Soc. Inf. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2065568351, "title": "Some Like it Hoax: Automated Fake News Detection in Social Networks", "abstract": "In recent years, the reliability of information on the Internet has emerged\nas a crucial issue of modern society. Social network sites (SNSs) have\nrevolutionized the way in which information is spread by allowing users to\nfreely share content. As a consequence, SNSs are also increasingly used as\nvectors for the diffusion of misinformation and hoaxes. The amount of\ndisseminated information and the rapidity of its diffusion make it practically\nimpossible to assess reliability in a timely manner, highlighting the need for\nautomatic hoax detection systems.\n  As a contribution towards this objective, we show that Facebook posts can be\nclassified with high accuracy as hoaxes or non-hoaxes on the basis of the users\nwho \"liked\" them. We present two classification techniques, one based on\nlogistic regression, the other on a novel adaptation of boolean crowdsourcing\nalgorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users,\nwe obtain classification accuracies exceeding 99% even when the training set\ncontains less than 1% of the posts. We further show that our techniques are\nrobust: they work even when we restrict our attention to the users who like\nboth hoax and non-hoax posts. These results suggest that mapping the diffusion\npattern of information can be a useful component of automatic hoax detection\nsystems.", "doi": "", "date": "2017-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1704.07506v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4170343506, "title": "Early Detection of Social Media Hoaxes at Scale", "abstract": "The unmoderated nature of social media enables the diffusion of hoaxes, which\nin turn jeopardises the credibility of information gathered from social media\nplatforms. Existing research on automated detection of hoaxes has the\nlimitation of using relatively small datasets, owing to the difficulty of\ngetting labelled data. This in turn has limited research exploring early\ndetection of hoaxes as well as exploring other factors such as the effect of\nthe size of the training data or the use of sliding windows. To mitigate this\nproblem, we introduce a semi-automated method that leverages the Wikidata\nknowledge base to build large-scale datasets for veracity classification,\nfocusing on celebrity death reports. This enables us to create a dataset with\n4,007 reports including over 13 million tweets, 15% of which are fake.\nExperiments using class-specific representations of word embeddings show that\nwe can achieve F1 scores nearing 72% within 10 minutes of the first tweet being\nposted when we expand the size of the training data following our\nsemi-automated means. Our dataset represents a realistic scenario with a real\ndistribution of true, commemorative and false stories, which we release for\nfurther use as a benchmark in future research.", "doi": "", "date": "2018-01-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1801.07311v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2655603207, "title": "Network segregation in a model of misinformation and fact checking", "abstract": "Misinformation under the form of rumor, hoaxes, and conspiracy theories\nspreads on social media at alarming rates. One hypothesis is that, since social\nmedia are shaped by homophily, belief in misinformation may be more likely to\nthrive on those social circles that are segregated from the rest of the\nnetwork. One possible antidote is fact checking which, in some cases, is known\nto stop rumors from spreading further. However, fact checking may also backfire\nand reinforce the belief in a hoax. Here we take into account the combination\nof network segregation, finite memory and attention, and fact-checking efforts.\nWe consider a compartmental model of two interacting epidemic processes over a\nnetwork that is segregated between gullible and skeptic users. Extensive\nsimulation and mean-field analysis show that a more segregated network\nfacilitates the spread of a hoax only at low forgetting rates, but has no\neffect when agents forget at faster rates. This finding may inform the\ndevelopment of mitigation techniques and overall inform on the risks of\nuncontrolled misinformation online.", "doi": "10.1007/s42001-018-0018-9", "date": "2016-10-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1610.04170v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3500863983, "title": "Tweet, but Verify: Epistemic Study of Information Verification on\n  Twitter", "abstract": "While Twitter provides an unprecedented opportunity to learn about breaking\nnews and current events as they happen, it often produces skepticism among\nusers as not all the information is accurate but also hoaxes are sometimes\nspread. While avoiding the diffusion of hoaxes is a major concern during\nfast-paced events such as natural disasters, the study of how users trust and\nverify information from tweets in these contexts has received little attention\nso far. We survey users on credibility perceptions regarding witness pictures\nposted on Twitter related to Hurricane Sandy. By examining credibility\nperceptions on features suggested for information verification in the field of\nEpistemology, we evaluate their accuracy in determining whether pictures were\nreal or fake compared to professional evaluations performed by experts. Our\nstudy unveils insight about tweet presentation, as well as features that users\nshould look at when assessing the veracity of tweets in the context of\nfast-paced events. Some of our main findings include that while author details\nnot readily available on Twitter feeds should be emphasized in order to\nfacilitate verification of tweets, showing multiple tweets corroborating a fact\nmisleads users to trusting what actually is a hoax. We contrast some of the\nbehavioral patterns found on tweets with literature in Psychology research.", "doi": "", "date": "2013-12-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1312.5297v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1358113673, "title": "Some lessons for us scientists (too) from the \"Sokal affair\"", "abstract": "In this little non-technical piece, I argue that some of the lessons that can\nbe learnt from the bold action carried out in 1996 by the physicist Alan Sokal\nand typically known as the \"Sokal affair\" not only apply to some sector of the\nhumanities (which was the original target of the hoax), but also (with much\nless intensity, but still) to the hardest sciences.", "doi": "", "date": "2013-11-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1311.5835v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 422656898, "title": "An Emotional Analysis of False Information in Social Media and News\n  Articles", "abstract": "Fake news is risky since it has been created to manipulate the readers'\nopinions and beliefs. In this work, we compared the language of false news to\nthe real one of real news from an emotional perspective, considering a set of\nfalse information types (propaganda, hoax, clickbait, and satire) from social\nmedia and online news articles sources. Our experiments showed that false\ninformation has different emotional patterns in each of its types, and emotions\nplay a key role in deceiving the reader. Based on that, we proposed a LSTM\nneural network model that is emotionally-infused to detect false news.", "doi": "", "date": "2019-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.09951v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3783667607, "title": "HoaxItaly: a collection of Italian disinformation and fact-checking\n  stories shared on Twitter in 2019", "abstract": "We released over 1 million tweets shared during 2019 and containing links to\nthousands of news articles published on two classes of Italian outlets: (1)\ndisinformation websites, i.e. outlets which have been repeatedly flagged by\njournalists and fact-checkers for producing low-credibility content such as\nfalse news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)\nfact-checking websites which notably debunk and verify online news and claims.\nThe dataset, which includes also title and body for approximately 37k news\narticles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.", "doi": "", "date": "2020-01-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.10926v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 503574694, "title": "Experimental demonstration of an isotope-sensitive warhead verification\n  technique using nuclear resonance fluorescence", "abstract": "Future nuclear arms reduction efforts will require technologies to verify\nthat warheads slated for dismantlement are authentic without revealing any\nsensitive weapons design information to international inspectors. Despite\nseveral decades of research, no technology has met these requirements\nsimultaneously. Recent work by Kemp et al. [Kemp RS, Danagoulian A, Macdonald\nRR, Vavrek JR (2016) Proc Natl Acad Sci USA 113:8618--8623] has produced a\nnovel physical cryptographic verification protocol that approaches this treaty\nverification problem by exploiting the isotope-specific nature of nuclear\nresonance fluorescence (NRF) measurements to verify the authenticity of a\nwarhead. To protect sensitive information, the NRF signal from the warhead is\nconvolved with that of an encryption foil that contains key warhead isotopes in\namounts unknown to the inspector. The convolved spectrum from a candidate\nwarhead is statistically compared against that from an authenticated template\nwarhead to determine whether the candidate itself is authentic. Here we report\non recent proof-of-concept warhead verification experiments conducted at the\nMassachusetts Institute of Technology. Using high-purity germanium (HPGe)\ndetectors, we measured NRF spectra from the interrogation of proxy 'genuine'\nand 'hoax' objects by a 2.52 MeV endpoint bremsstrahlung beam. The observed\ndifferences in NRF intensities near 2.2 MeV indicate that the physical\ncryptographic protocol can distinguish between proxy genuine and hoax objects\nwith high confidence in realistic measurement times.", "doi": "10.1073/pnas.1721278115", "date": "2017-12-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1712.02904v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2884521432, "title": "SGG: Spinbot, Grammarly and GloVe based Fake News Detection", "abstract": "Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.", "doi": "", "date": "2020-08-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.06854v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2122709360, "title": "Modeling Rumors: The No Plane Pentagon French Hoax Case", "abstract": "The recent astonishing wide adhesion of french people to the rumor claiming\n`No plane did crash on the Pentagon on September the 11\", is given a generic\nexplanation in terms of a model of minority opinion spreading. Using a majority\nrule reaction-diffusion dynamics, a rumor is shown to invade for sure a social\ngroup provided it fulfills simultaneously two criteria. First it must initiate\nwith a support beyond some critical threshold which however, turns out to be\nalways very low. Then it has to be consistent with some larger collective\nsocial paradigm of the group. Othewise it just dies out. Both conditions were\nsatisfied in the french case with the associated book sold at more than 200 000\ncopies in just a few days. The rumor was stopped by the firm stand of most\nnewspaper editors stating it is nonsense. Such an incredible social dynamics is\nshown to result naturally from an open and free public debate among friends and\ncolleagues. Each one searching for the truth sincerely on a free will basis and\nwithout individual biases. The polarization process appears also to be very\nquick in agreement with reality. It is a very strong anti-democratic reversal\nof opinion although made quite democratically. The model may apply to a large\nrange of rumors.", "doi": "10.1016/s0378-4371(02)01582-0", "date": "2002-11-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/cond-mat/0211571v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 10847017, "title": "Spreading dynamics on small-world networks with connectivity\n  fluctuations and correlations", "abstract": "Infectious diseases and computer malwares spread among humans and computers\nthrough the network of contacts among them. These networks are characterized by\nwide connectivity fluctuations, connectivity correlations and the small-world\nproperty. In a previous work [A. Vazquez, Phys. Rev. Lett. 96, 038702 (2006)] I\nhave shown that the connectivity fluctuations together with the small-world\nproperty lead to a novel spreading law, characterized by an initial power law\ngrowth with an exponent determined by the average node distance on the network.\nHere I extend these results to consider the influence of connectivity\ncorrelations which are generally observed in real networks. I show that\nassortative and disassortative connectivity correlations enhance and diminish,\nrespectively, the range of validity of this spreading law. As a corollary I\nobtain the region of connectivity fluctuations and degree correlations\ncharacterized by the absence of an epidemic threshold. These results are\nrelevant for the spreading of infectious diseases, rumors, and information\namong humans and the spreading of computer viruses, email worms and hoaxes\namong computer users.", "doi": "10.1103/physreve.74.056101", "date": "2006-03-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/q-bio/0603010v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1601591605, "title": "Gauge coupling unification, the GUT scale, and magic fields", "abstract": "We consider field sets that do not form complete SU(5) multiplets, but\nexactly preserve the one-loop MSSM prediction for $\\alpha_3(M_Z)$ independently\nof the value of their mass. Such fields can raise the unification scale in\ndifferent ways, through a delayed convergence of the gauge couplings, a fake\nunified running below the GUT scale, or a postponed unification after a hoax\ncrossing at a lower scale. The $\\alpha_3(M_Z)$ prediction is independent of the\nmass of the new fields, while the GUT scale often is not, which allows to vary\nthe GUT scale. Such \"magic\" fields represent a useful tool in GUT model\nbuilding. For example, they can be used to fix gauge coupling unification in\ncertain two step breakings of the unified group, to suppress large KK\nthresholds in models with extra dimensions, or they can be interpreted as\nmessengers of supersymmetry breaking in GMSB models.", "doi": "10.1016/j.physletb.2009.01.012", "date": "2008-12-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/0812.0342v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3661557000, "title": "Can Social Networks help the progress of Astrophysics and Cosmology? An\n  experiment in the field of Galaxy Kinematics", "abstract": "This paper is crucial part of an experiment aimed to investigate whether\nSocial Networks can be of help for Astrophysics. In the present case, in\nhelping to eliminate the deep-routed wrong misconception of Flat Rotation\nCurves of Spiral Galaxies, more rapidly and efficiently than the traditional\nmethod of publishing peer-reviewed papers and organizing a number of\ninternational conferences. To reach this goal we created the Facebook Group\n\"Rotation Curve are not Flat\" that we filled with all the evidence necessary\nfor an immediate and definite confrontation with the above fallacious legendary\nbelief. In this paper, we solicit the interested Astrophysicist/Cosmologist FB\nusers to join this group. Finally, the paper informs the Astrophysical\nCommunity that a widespread belief is instead an hoax, whose consideration may\nslow down the progress of science and that must be taken care by innovative\nmeans of communicating scientific advances. This test case may anticipate the\nfuture in which Web n.0 will become an effective scientific tool for\nAstrophysics.", "doi": "", "date": "2010-04-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1004.1190v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1804616189, "title": "On the statistical properties of viral misinformation in online social\n  media", "abstract": "The massive diffusion of online social media allows for the rapid and\nuncontrolled spreading of conspiracy theories, hoaxes, unsubstantiated claims,\nand false news. Such an impressive amount of misinformation can influence\npolicy preferences and encourage behaviors strongly divergent from recommended\npractices. In this paper, we study the statistical properties of viral\nmisinformation in online social media. By means of methods belonging to Extreme\nValue Theory, we show that the number of extremely viral posts over time\nfollows a homogeneous Poisson process, and that the interarrival times between\nsuch posts are independent and identically distributed, following an\nexponential distribution. Moreover, we characterize the uncertainty around the\nrate parameter of the Poisson process through Bayesian methods. Finally, we are\nable to derive the predictive posterior probability distribution of the number\nof posts exceeding a certain threshold of shares over a finite interval of\ntime.", "doi": "10.1016/j.physa.2016.11.012", "date": "2016-09-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1609.09435v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3889158462, "title": "The Voynich Manuscript is Written in Natural Language: The Pahlavi\n  Hypothesis", "abstract": "The late medieval Voynich Manuscript (VM) has resisted decryption and was\nconsidered a meaningless hoax or an unsolvable cipher. Here, we provide\nevidence that the VM is written in natural language by establishing a relation\nof the Voynich alphabet and the Iranian Pahlavi script. Many of the Voynich\ncharacters are upside-down versions of their Pahlavi counterparts, which may be\nan effect of different writing directions. Other Voynich letters can be\nexplained as ligatures or departures from Pahlavi with the intent to cope with\nknown problems due to the stupendous ambiguity of Pahlavi text. While a\ntranslation of the VM text is not attempted here, we can confirm the\nVoynich-Pahlavi relation at the character level by the transcription of many\nwords from the VM illustrations and from parts of the main text. Many of the\ntranscribed words can be identified as terms from Zoroastrian cosmology which\nis in line with the use of Pahlavi script in Zoroastrian communities from\nmedieval times.", "doi": "", "date": "2017-09-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1709.01634v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3213696268, "title": "Nuclear Disarmament Verification via Resonant Phenomena", "abstract": "Nuclear disarmament treaties are not sufficient in and of themselves to\nneutralize the existential threat of the nuclear weapons. Technologies are\nnecessary for verifying the authenticity of the nuclear warheads undergoing\ndismantlement before counting them towards a treaty partner's obligation. This\nwork presents a novel concept that leverages isotope-specific nuclear resonance\nphenomena to authenticate a warhead's fissile components by comparing them to a\npreviously authenticated template. All information is encrypted in the physical\ndomain in a manner that amounts to a physical zero-knowledge proof system.\nUsing Monte Carlo simulations, the system is shown to reveal no isotopic or\ngeometric information about the weapon, while readily detecting hoaxing\nattempts. This nuclear technique can dramatically increase the reach and\ntrustworthiness of future nuclear disarmament treaties.", "doi": "10.1038/s41467-018-03680-4", "date": "2017-09-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1709.09736v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2617200188, "title": "Polarization and Fake News: Early Warning of Potential Misinformation\n  Targets", "abstract": "Users polarization and confirmation bias play a key role in misinformation\nspreading on online social media. Our aim is to use this information to\ndetermine in advance potential targets for hoaxes and fake news. In this paper,\nwe introduce a general framework for promptly identifying polarizing content on\nsocial media and, thus, \"predicting\" future fake news topics. We validate the\nperformances of the proposed methodology on a massive Italian Facebook dataset,\nshowing that we are able to identify topics that are susceptible to\nmisinformation with 77% accuracy. Moreover, such information may be embedded as\na new feature in an additional classifier able to recognize fake news with 91%\naccuracy. The novelty of our approach consists in taking into account a series\nof characteristics related to users behavior on online social media, making a\nfirst, important step towards the smoothing of polarization and the mitigation\nof misinformation phenomena.", "doi": "", "date": "2018-02-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1802.01400v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1892167155, "title": "Fake news detection using Deep Learning", "abstract": "The evolution of the information and communication technologies has\ndramatically increased the number of people with access to the Internet, which\nhas changed the way the information is consumed. As a consequence of the above,\nfake news have become one of the major concerns because its potential to\ndestabilize governments, which makes them a potential danger to modern society.\nAn example of this can be found in the US. electoral campaign, where the term\n\"fake news\" gained great notoriety due to the influence of the hoaxes in the\nfinal result of these. In this work the feasibility of applying deep learning\ntechniques to discriminate fake news on the Internet using only their text is\nstudied. In order to accomplish that, three different neural network\narchitectures are proposed, one of them based on BERT, a modern language model\ncreated by Google which achieves state-of-the-art results.", "doi": "", "date": "2019-09-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.03496v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3219510195, "title": "Do Sentence Interactions Matter? Leveraging Sentence Level\n  Representations for Fake News Classification", "abstract": "The rising growth of fake news and misleading information through online\nmedia outlets demands an automatic method for detecting such news articles. Of\nthe few limited works which differentiate between trusted vs other types of\nnews article (satire, propaganda, hoax), none of them model sentence\ninteractions within a document. We observe an interesting pattern in the way\nsentences interact with each other across different kind of news articles. To\ncapture this kind of information for long news articles, we propose a graph\nneural network-based model which does away with the need of feature engineering\nfor fine grained fake news classification. Through experiments, we show that\nour proposed method beats strong neural baselines and achieves state-of-the-art\naccuracy on existing datasets. Moreover, we establish the generalizability of\nour model by evaluating its performance in out-of-domain scenarios. Code is\navailable at https://github.com/MysteryVaibhav/fake_news_semantics", "doi": "", "date": "2019-10-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.12203v1", "pdf": ""}, "publisher-venue": "TextGraphs - EMNLP 2019", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 655566131, "title": "False Information on Web and Social Media: A Survey", "abstract": "False information can be created and spread easily through the web and social\nmedia platforms, resulting in widespread real-world impact. Characterizing how\nfalse information proliferates on social platforms and why it succeeds in\ndeceiving readers are critical to develop efficient detection algorithms and\ntools for early detection. A recent surge of research in this area has aimed to\naddress the key issues using methods based on feature engineering, graph\nmining, and information modeling. Majority of the research has primarily\nfocused on two broad categories of false information: opinion-based (e.g., fake\nreviews), and fact-based (e.g., false news and hoaxes). Therefore, in this\nwork, we present a comprehensive survey spanning diverse aspects of false\ninformation, namely (i) the actors involved in spreading false information,\n(ii) rationale behind successfully deceiving readers, (iii) quantifying the\nimpact of false information, (iv) measuring its characteristics across\ndifferent dimensions, and finally, (iv) algorithms developed to detect false\ninformation. In doing so, we create a unified framework to describe these\nrecent methods and highlight a number of important directions for future\nresearch.", "doi": "", "date": "2018-04-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.08559v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4228587344, "title": "Agent Based Rumor Spreading in a scale-free network", "abstract": "In the last years, the study of rumor spreading on social networks produced a\nlot of interest among the scientific community, expecially due to the role of\nsocial networks in the last political events. The goal of this work is to\nreproduce real-like diffusions of information and misinformation in a\nscale-free network using a multi-agent-based model. The data concerning the\nvirtual spreading are easily obtainable, in particular the diffusion of\ninformation during the announcement for the discovery of the Higgs Boson on\nTwitter was recorded and investigated in detail. We made some assumptions on\nthe micro behavior of our agents and registered the effects in a statistical\nanalysis replying the real data diffusion. Then, we studied an hypotetical\nresponse to a misinformation diffusion adding debunking agents and trying to\nmodel a critic response from the agents using real data from a hoax regarding\nthe Occupy Wall Street movement. After tuning our model to reproduce these\nresults, we measured some network properties and proved the emergence of\nsubstantially separated structures like echochambers, independently from the\nnetwork size scale, i.e. with one hundred, one thousand and ten thousand\nagents.", "doi": "", "date": "2018-05-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1805.05999v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 505798358, "title": "Identifying Coordinated Accounts on Social Media through Hidden\n  Influence and Group Behaviours", "abstract": "Disinformation campaigns on social media, involving coordinated activities\nfrom malicious accounts towards manipulating public opinion, have become\nincreasingly prevalent. Existing approaches to detect coordinated accounts\neither make very strict assumptions about coordinated behaviours, or require\npart of the malicious accounts in the coordinated group to be revealed in order\nto detect the rest. To address these drawbacks, we propose a generative model,\nAMDN-HAGE (Attentive Mixture Density Network with Hidden Account Group\nEstimation) which jointly models account activities and hidden group behaviours\nbased on Temporal Point Processes (TPP) and Gaussian Mixture Model (GMM), to\ncapture inherent characteristics of coordination which is, accounts that\ncoordinate must strongly influence each other's activities, and collectively\nappear anomalous from normal accounts. To address the challenges of optimizing\nthe proposed model, we provide a bilevel optimization algorithm with\ntheoretical guarantee on convergence. We verified the effectiveness of the\nproposed method and training algorithm on real-world social network data\ncollected from Twitter related to coordinated campaigns from Russia's Internet\nResearch Agency targeting the 2016 U.S. Presidential Elections, and to identify\ncoordinated campaigns related to the COVID-19 pandemic. Leveraging the learned\nmodel, we find that the average influence between coordinated account pairs is\nthe highest.On COVID-19, we found coordinated group spreading anti-vaccination,\nanti-masks conspiracies that suggest the pandemic is a hoax and political scam.", "doi": "", "date": "2020-08-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.11308v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2673205057, "title": "FaNDS: Fake News Detection System Using Energy Flow", "abstract": "Recently, the term \"fake news\" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.", "doi": "", "date": "2020-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.02097v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2523937007, "title": "Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised\n  Learning Approach", "abstract": "Online Social Media (OSM) platforms such as Twitter, Facebook are extensively\nexploited by the users of these platforms for spreading the (mis)information to\na large audience effortlessly at a rapid pace. It has been observed that the\nmisinformation can cause panic, fear, and financial loss to society. Thus, it\nis important to detect and control the misinformation in such platforms before\nit spreads to the masses. In this work, we focus on rumors, which is one type\nof misinformation (other types are fake news, hoaxes, etc). One way to control\nthe spread of the rumors is by identifying users who are possibly the rumor\nspreaders, that is, users who are often involved in spreading the rumors. Due\nto the lack of availability of rumor spreaders labeled dataset (which is an\nexpensive task), we use publicly available PHEME dataset, which contains rumor\nand non-rumor tweets information, and then apply a weak supervised learning\napproach to transform the PHEME dataset into rumor spreaders dataset. We\nutilize three types of features, that is, user, text, and ego-network features,\nbefore applying various supervised learning approaches. In particular, to\nexploit the inherent network property in this dataset (user-user reply graph),\nwe explore Graph Convolutional Network (GCN), a type of Graph Neural Network\n(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and\nLSTM. Extensive experiments performed on the rumor spreaders dataset, where we\nachieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the\neffectiveness of our methodology for identifying possible rumor spreaders using\nthe GCN technique.", "doi": "", "date": "2020-10-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.07647v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3605409042, "title": "Deepfakes Generation and Detection: State-of-the-art, open challenges,\n  countermeasures, and way forward", "abstract": "Easy access to audio-visual content on social media, combined with the\navailability of modern tools such as Tensorflow or Keras, open-source trained\nmodels, and economical computing infrastructure, and the rapid evolution of\ndeep-learning (DL) methods, especially Generative Adversarial Networks (GAN),\nhave made it possible to generate deepfakes to disseminate disinformation,\nrevenge porn, financial frauds, hoaxes, and to disrupt government functioning.\nThe existing surveys have mainly focused on deepfake video detection only. No\nattempt has been made to review approaches for detection and generation of both\naudio and video deepfakes. This paper provides a comprehensive review and\ndetailed analysis of existing tools and machine learning (ML) based approaches\nfor deepfake generation and the methodologies used to detect such manipulations\nfor the detection and generation of both audio and video deepfakes. For each\ncategory of deepfake, we discuss information related to manipulation\napproaches, current public datasets, and key standards for the performance\nevaluation of deepfake detection techniques along with their results.\nAdditionally, we also discuss open challenges and enumerate future directions\nto guide future researchers on issues that need to be considered to improve the\ndomains of both the deepfake generation and detection. This work is expected to\nassist the readers in understanding the creation and detection mechanisms of\ndeepfake, along with their current limitations and future direction.", "doi": "", "date": "2021-02-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.00484v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3317822930, "title": "Using an Epidemiological Model to Study the Spread of Misinformation\n  during the Black Lives Matter Movement", "abstract": "The proliferation of social media platforms like Twitter has heightened the\nconsequences of the spread of misinformation. To understand and model the\nspread of misinformation, in this paper, we leveraged the SEIZ (Susceptible,\nExposed, Infected, Skeptics) epidemiological model to describe the underlying\nprocess that delineates the spread of misinformation on Twitter. Compared to\nthe other epidemiological models, this model produces broader results because\nit includes the additional Skeptics (Z) compartment, wherein a user may be\nexposed to an item of misinformation but not engage in any reaction to it, and\nthe additional Exposed (E) compartment, wherein the user may need some time\nbefore deciding to spread a misinformation item. We analyzed misinformation\nregarding the unrest in Washington, D.C. in the month of March 2020 which was\npropagated by the use of the #DCblackout hashtag by different users across the\nU.S. on Twitter. Our analysis shows that misinformation can be modeled using\nthe concept of epidemiology. To the best of our knowledge, this research is the\nfirst to attempt to apply the SEIZ epidemiological model to the spread of a\nspecific item of misinformation, which is a category distinct from that of\nrumor, and a hoax on online social media platforms. Applying a mathematical\nmodel can help to understand the trends and dynamics of the spread of\nmisinformation on Twitter and ultimately help to develop techniques to quickly\nidentify and control it.", "doi": "", "date": "2021-03-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.12191v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1358005379, "title": "Can Evolutionary Computation Help us to Crib the Voynich Manuscript ?", "abstract": "Departing from the postulate that Voynich Manuscript is not a hoax but rather\nencodes authentic contents, our article presents an evolutionary algorithm\nwhich aims to find the most optimal mapping between voynichian glyphs and\ncandidate phonemic values. Core component of the decoding algorithm is a\nprocess of maximization of a fitness function which aims to find most optimal\nset of substitution rules allowing to transcribe the part of the manuscript --\nwhich we call the Calendar -- into lists of feminine names. This leads to sets\nof character subsitution rules which allow us to consistently transcribe dozens\namong three hundred calendar tokens into feminine names: a result far\nsurpassing both ``popular'' as well as \"state of the art\" tentatives to crack\nthe manuscript. What's more, by using name lists stemming from different\nlanguages as potential cribs, our ``adaptive'' method can also be useful in\nidentification of the language in which the manuscript is written.\n  As far as we can currently tell, results of our experiments indicate that the\nCalendar part of the manuscript contains names from baltoslavic, balkanic or\nhebrew language strata. Two further indications are also given: primo, highest\nfitness values were obtained when the crib list contains names with specific\ninfixes at token's penultimate position as is the case, for example, for slavic\n\\textbf{feminine diminutives} (i.e. names ending with -ka and not -a). In the\nmost successful scenario, 240 characters contained in 35 distinct Voynichese\ntokens were successfully transcribed. Secundo, in case of crib stemming from\nHebrew language, whole adaptation process converges to significantly better\nfitness values when transcribing voynichian tokens whose order of individual\ncharacters have been reversed, and when lists feminine and not masculine names\nare used as the crib.", "doi": "", "date": "2021-07-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.05381v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2058597306, "title": "Conspiracy in the Time of Corona: Automatic detection of Covid-19\n  Conspiracy Theories in Social Media and the News", "abstract": "Rumors and conspiracy theories thrive in environments of low confidence and\nlow trust. Consequently, it is not surprising that ones related to the Covid-19\npandemic are proliferating given the lack of any authoritative scientific\nconsensus on the virus, its spread and containment, or on the long term social\nand economic ramifications of the pandemic. Among the stories currently\ncirculating are ones suggesting that the 5G network activates the virus, that\nthe pandemic is a hoax perpetrated by a global cabal, that the virus is a\nbio-weapon released deliberately by the Chinese, or that Bill Gates is using it\nas cover to launch a global surveillance regime. While some may be quick to\ndismiss these stories as having little impact on real-world behavior, recent\nevents including the destruction of property, racially fueled attacks against\nAsian Americans, and demonstrations espousing resistance to public health\norders countermand such conclusions. Inspired by narrative theory, we crawl\nsocial media sites and news reports and, through the application of automated\nmachine-learning methods, discover the underlying narrative frameworks\nsupporting the generation of these stories. We show how the various narrative\nframeworks fueling rumors and conspiracy theories rely on the alignment of\notherwise disparate domains of knowledge, and consider how they attach to the\nbroader reporting on the pandemic. These alignments and attachments, which can\nbe monitored in near real-time, may be useful for identifying areas in the news\nthat are particularly vulnerable to reinterpretation by conspiracy theorists.\nUnderstanding the dynamics of storytelling on social media and the narrative\nframeworks that provide the generative basis for these stories may also be\nhelpful for devising methods to disrupt their spread.", "doi": "", "date": "2020-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.13783v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2034656524, "title": "Cognitive networks identify the content of English and Italian popular\n  posts about COVID-19 vaccines: Anticipation, logistics, conspiracy and loss\n  of trust", "abstract": "Monitoring social discourse about COVID-19 vaccines is key to understanding\nhow large populations perceive vaccination campaigns. We focus on 4765 unique\npopular tweets in English or Italian about COVID-19 vaccines between 12/2020\nand 03/2021. One popular English tweet was liked up to 495,000 times, stressing\nhow popular tweets affected cognitively massive populations. We investigate\nboth text and multimedia in tweets, building a knowledge graph of\nsyntactic/semantic associations in messages including visual features and\nindicating how online users framed social discourse mostly around the logistics\nof vaccine distribution. The English semantic frame of \"vaccine\" was highly\npolarised between trust/anticipation (towards the vaccine as a scientific asset\nsaving lives) and anger/sadness (mentioning critical issues with dose\nadministering). Semantic associations with \"vaccine,\" \"hoax\" and conspiratorial\njargon indicated the persistence of conspiracy theories and vaccines in\nmassively read English posts (absent in Italian messages). The image analysis\nfound that popular tweets with images of people wearing face masks used\nlanguage lacking the trust and joy found in tweets showing people with no\nmasks, indicating a negative affect attributed to face covering in social\ndiscourse. A behavioural analysis revealed a tendency for users to share\ncontent eliciting joy, sadness and disgust and to like less sad messages,\nhighlighting an interplay between emotions and content diffusion beyond\nsentiment. With the AstraZeneca vaccine being suspended in mid March 2021,\n\"Astrazeneca\" was associated with trustful language driven by experts, but\npopular Italian tweets framed \"vaccine\" by crucially replacing earlier levels\nof trust with deep sadness. Our results stress how cognitive networks and\ninnovative multimedia processing open new ways for reconstructing online\nperceptions about vaccines and trust.", "doi": "", "date": "2021-03-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.15909v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}][{"id": 2065568351, "title": "Some Like it Hoax: Automated Fake News Detection in Social Networks", "abstract": "In recent years, the reliability of information on the Internet has emerged\nas a crucial issue of modern society. Social network sites (SNSs) have\nrevolutionized the way in which information is spread by allowing users to\nfreely share content. As a consequence, SNSs are also increasingly used as\nvectors for the diffusion of misinformation and hoaxes. The amount of\ndisseminated information and the rapidity of its diffusion make it practically\nimpossible to assess reliability in a timely manner, highlighting the need for\nautomatic hoax detection systems.\n  As a contribution towards this objective, we show that Facebook posts can be\nclassified with high accuracy as hoaxes or non-hoaxes on the basis of the users\nwho \"liked\" them. We present two classification techniques, one based on\nlogistic regression, the other on a novel adaptation of boolean crowdsourcing\nalgorithms. On a dataset consisting of 15,500 Facebook posts and 909,236 users,\nwe obtain classification accuracies exceeding 99% even when the training set\ncontains less than 1% of the posts. We further show that our techniques are\nrobust: they work even when we restrict our attention to the users who like\nboth hoax and non-hoax posts. These results suggest that mapping the diffusion\npattern of information can be a useful component of automatic hoax detection\nsystems.", "doi": "", "date": "2017-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1704.07506v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4170343506, "title": "Early Detection of Social Media Hoaxes at Scale", "abstract": "The unmoderated nature of social media enables the diffusion of hoaxes, which\nin turn jeopardises the credibility of information gathered from social media\nplatforms. Existing research on automated detection of hoaxes has the\nlimitation of using relatively small datasets, owing to the difficulty of\ngetting labelled data. This in turn has limited research exploring early\ndetection of hoaxes as well as exploring other factors such as the effect of\nthe size of the training data or the use of sliding windows. To mitigate this\nproblem, we introduce a semi-automated method that leverages the Wikidata\nknowledge base to build large-scale datasets for veracity classification,\nfocusing on celebrity death reports. This enables us to create a dataset with\n4,007 reports including over 13 million tweets, 15% of which are fake.\nExperiments using class-specific representations of word embeddings show that\nwe can achieve F1 scores nearing 72% within 10 minutes of the first tweet being\nposted when we expand the size of the training data following our\nsemi-automated means. Our dataset represents a realistic scenario with a real\ndistribution of true, commemorative and false stories, which we release for\nfurther use as a benchmark in future research.", "doi": "", "date": "2018-01-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1801.07311v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2655603207, "title": "Network segregation in a model of misinformation and fact checking", "abstract": "Misinformation under the form of rumor, hoaxes, and conspiracy theories\nspreads on social media at alarming rates. One hypothesis is that, since social\nmedia are shaped by homophily, belief in misinformation may be more likely to\nthrive on those social circles that are segregated from the rest of the\nnetwork. One possible antidote is fact checking which, in some cases, is known\nto stop rumors from spreading further. However, fact checking may also backfire\nand reinforce the belief in a hoax. Here we take into account the combination\nof network segregation, finite memory and attention, and fact-checking efforts.\nWe consider a compartmental model of two interacting epidemic processes over a\nnetwork that is segregated between gullible and skeptic users. Extensive\nsimulation and mean-field analysis show that a more segregated network\nfacilitates the spread of a hoax only at low forgetting rates, but has no\neffect when agents forget at faster rates. This finding may inform the\ndevelopment of mitigation techniques and overall inform on the risks of\nuncontrolled misinformation online.", "doi": "10.1007/s42001-018-0018-9", "date": "2016-10-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1610.04170v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3500863983, "title": "Tweet, but Verify: Epistemic Study of Information Verification on\n  Twitter", "abstract": "While Twitter provides an unprecedented opportunity to learn about breaking\nnews and current events as they happen, it often produces skepticism among\nusers as not all the information is accurate but also hoaxes are sometimes\nspread. While avoiding the diffusion of hoaxes is a major concern during\nfast-paced events such as natural disasters, the study of how users trust and\nverify information from tweets in these contexts has received little attention\nso far. We survey users on credibility perceptions regarding witness pictures\nposted on Twitter related to Hurricane Sandy. By examining credibility\nperceptions on features suggested for information verification in the field of\nEpistemology, we evaluate their accuracy in determining whether pictures were\nreal or fake compared to professional evaluations performed by experts. Our\nstudy unveils insight about tweet presentation, as well as features that users\nshould look at when assessing the veracity of tweets in the context of\nfast-paced events. Some of our main findings include that while author details\nnot readily available on Twitter feeds should be emphasized in order to\nfacilitate verification of tweets, showing multiple tweets corroborating a fact\nmisleads users to trusting what actually is a hoax. We contrast some of the\nbehavioral patterns found on tweets with literature in Psychology research.", "doi": "", "date": "2013-12-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1312.5297v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1358113673, "title": "Some lessons for us scientists (too) from the \"Sokal affair\"", "abstract": "In this little non-technical piece, I argue that some of the lessons that can\nbe learnt from the bold action carried out in 1996 by the physicist Alan Sokal\nand typically known as the \"Sokal affair\" not only apply to some sector of the\nhumanities (which was the original target of the hoax), but also (with much\nless intensity, but still) to the hardest sciences.", "doi": "", "date": "2013-11-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1311.5835v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 422656898, "title": "An Emotional Analysis of False Information in Social Media and News\n  Articles", "abstract": "Fake news is risky since it has been created to manipulate the readers'\nopinions and beliefs. In this work, we compared the language of false news to\nthe real one of real news from an emotional perspective, considering a set of\nfalse information types (propaganda, hoax, clickbait, and satire) from social\nmedia and online news articles sources. Our experiments showed that false\ninformation has different emotional patterns in each of its types, and emotions\nplay a key role in deceiving the reader. Based on that, we proposed a LSTM\nneural network model that is emotionally-infused to detect false news.", "doi": "", "date": "2019-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.09951v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3783667607, "title": "HoaxItaly: a collection of Italian disinformation and fact-checking\n  stories shared on Twitter in 2019", "abstract": "We released over 1 million tweets shared during 2019 and containing links to\nthousands of news articles published on two classes of Italian outlets: (1)\ndisinformation websites, i.e. outlets which have been repeatedly flagged by\njournalists and fact-checkers for producing low-credibility content such as\nfalse news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)\nfact-checking websites which notably debunk and verify online news and claims.\nThe dataset, which includes also title and body for approximately 37k news\narticles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.", "doi": "", "date": "2020-01-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.10926v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 503574694, "title": "Experimental demonstration of an isotope-sensitive warhead verification\n  technique using nuclear resonance fluorescence", "abstract": "Future nuclear arms reduction efforts will require technologies to verify\nthat warheads slated for dismantlement are authentic without revealing any\nsensitive weapons design information to international inspectors. Despite\nseveral decades of research, no technology has met these requirements\nsimultaneously. Recent work by Kemp et al. [Kemp RS, Danagoulian A, Macdonald\nRR, Vavrek JR (2016) Proc Natl Acad Sci USA 113:8618--8623] has produced a\nnovel physical cryptographic verification protocol that approaches this treaty\nverification problem by exploiting the isotope-specific nature of nuclear\nresonance fluorescence (NRF) measurements to verify the authenticity of a\nwarhead. To protect sensitive information, the NRF signal from the warhead is\nconvolved with that of an encryption foil that contains key warhead isotopes in\namounts unknown to the inspector. The convolved spectrum from a candidate\nwarhead is statistically compared against that from an authenticated template\nwarhead to determine whether the candidate itself is authentic. Here we report\non recent proof-of-concept warhead verification experiments conducted at the\nMassachusetts Institute of Technology. Using high-purity germanium (HPGe)\ndetectors, we measured NRF spectra from the interrogation of proxy 'genuine'\nand 'hoax' objects by a 2.52 MeV endpoint bremsstrahlung beam. The observed\ndifferences in NRF intensities near 2.2 MeV indicate that the physical\ncryptographic protocol can distinguish between proxy genuine and hoax objects\nwith high confidence in realistic measurement times.", "doi": "10.1073/pnas.1721278115", "date": "2017-12-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1712.02904v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2884521432, "title": "SGG: Spinbot, Grammarly and GloVe based Fake News Detection", "abstract": "Recently, news consumption using online news portals has increased\nexponentially due to several reasons, such as low cost and easy accessibility.\nHowever, such online platforms inadvertently also become the cause of spreading\nfalse information across the web. They are being misused quite frequently as a\nmedium to disseminate misinformation and hoaxes. Such malpractices call for a\nrobust automatic fake news detection system that can keep us at bay from such\nmisinformation and hoaxes. We propose a robust yet simple fake news detection\nsystem, leveraging the tools for paraphrasing, grammar-checking, and\nword-embedding. In this paper, we try to the potential of these tools in\njointly unearthing the authenticity of a news article. Notably, we leverage\nSpinbot (for paraphrasing), Grammarly (for grammar-checking), and GloVe (for\nword-embedding) tools for this purpose. Using these tools, we were able to\nextract novel features that could yield state-of-the-art results on the Fake\nNews AMT dataset and comparable results on Celebrity datasets when combined\nwith some of the essential features. More importantly, the proposed method is\nfound to be more robust empirically than the existing ones, as revealed in our\ncross-domain analysis and multi-domain analysis.", "doi": "", "date": "2020-08-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.06854v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2122709360, "title": "Modeling Rumors: The No Plane Pentagon French Hoax Case", "abstract": "The recent astonishing wide adhesion of french people to the rumor claiming\n`No plane did crash on the Pentagon on September the 11\", is given a generic\nexplanation in terms of a model of minority opinion spreading. Using a majority\nrule reaction-diffusion dynamics, a rumor is shown to invade for sure a social\ngroup provided it fulfills simultaneously two criteria. First it must initiate\nwith a support beyond some critical threshold which however, turns out to be\nalways very low. Then it has to be consistent with some larger collective\nsocial paradigm of the group. Othewise it just dies out. Both conditions were\nsatisfied in the french case with the associated book sold at more than 200 000\ncopies in just a few days. The rumor was stopped by the firm stand of most\nnewspaper editors stating it is nonsense. Such an incredible social dynamics is\nshown to result naturally from an open and free public debate among friends and\ncolleagues. Each one searching for the truth sincerely on a free will basis and\nwithout individual biases. The polarization process appears also to be very\nquick in agreement with reality. It is a very strong anti-democratic reversal\nof opinion although made quite democratically. The model may apply to a large\nrange of rumors.", "doi": "10.1016/s0378-4371(02)01582-0", "date": "2002-11-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/cond-mat/0211571v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 10847017, "title": "Spreading dynamics on small-world networks with connectivity\n  fluctuations and correlations", "abstract": "Infectious diseases and computer malwares spread among humans and computers\nthrough the network of contacts among them. These networks are characterized by\nwide connectivity fluctuations, connectivity correlations and the small-world\nproperty. In a previous work [A. Vazquez, Phys. Rev. Lett. 96, 038702 (2006)] I\nhave shown that the connectivity fluctuations together with the small-world\nproperty lead to a novel spreading law, characterized by an initial power law\ngrowth with an exponent determined by the average node distance on the network.\nHere I extend these results to consider the influence of connectivity\ncorrelations which are generally observed in real networks. I show that\nassortative and disassortative connectivity correlations enhance and diminish,\nrespectively, the range of validity of this spreading law. As a corollary I\nobtain the region of connectivity fluctuations and degree correlations\ncharacterized by the absence of an epidemic threshold. These results are\nrelevant for the spreading of infectious diseases, rumors, and information\namong humans and the spreading of computer viruses, email worms and hoaxes\namong computer users.", "doi": "10.1103/physreve.74.056101", "date": "2006-03-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/q-bio/0603010v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1601591605, "title": "Gauge coupling unification, the GUT scale, and magic fields", "abstract": "We consider field sets that do not form complete SU(5) multiplets, but\nexactly preserve the one-loop MSSM prediction for $\\alpha_3(M_Z)$ independently\nof the value of their mass. Such fields can raise the unification scale in\ndifferent ways, through a delayed convergence of the gauge couplings, a fake\nunified running below the GUT scale, or a postponed unification after a hoax\ncrossing at a lower scale. The $\\alpha_3(M_Z)$ prediction is independent of the\nmass of the new fields, while the GUT scale often is not, which allows to vary\nthe GUT scale. Such \"magic\" fields represent a useful tool in GUT model\nbuilding. For example, they can be used to fix gauge coupling unification in\ncertain two step breakings of the unified group, to suppress large KK\nthresholds in models with extra dimensions, or they can be interpreted as\nmessengers of supersymmetry breaking in GMSB models.", "doi": "10.1016/j.physletb.2009.01.012", "date": "2008-12-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/0812.0342v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3661557000, "title": "Can Social Networks help the progress of Astrophysics and Cosmology? An\n  experiment in the field of Galaxy Kinematics", "abstract": "This paper is crucial part of an experiment aimed to investigate whether\nSocial Networks can be of help for Astrophysics. In the present case, in\nhelping to eliminate the deep-routed wrong misconception of Flat Rotation\nCurves of Spiral Galaxies, more rapidly and efficiently than the traditional\nmethod of publishing peer-reviewed papers and organizing a number of\ninternational conferences. To reach this goal we created the Facebook Group\n\"Rotation Curve are not Flat\" that we filled with all the evidence necessary\nfor an immediate and definite confrontation with the above fallacious legendary\nbelief. In this paper, we solicit the interested Astrophysicist/Cosmologist FB\nusers to join this group. Finally, the paper informs the Astrophysical\nCommunity that a widespread belief is instead an hoax, whose consideration may\nslow down the progress of science and that must be taken care by innovative\nmeans of communicating scientific advances. This test case may anticipate the\nfuture in which Web n.0 will become an effective scientific tool for\nAstrophysics.", "doi": "", "date": "2010-04-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1004.1190v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1804616189, "title": "On the statistical properties of viral misinformation in online social\n  media", "abstract": "The massive diffusion of online social media allows for the rapid and\nuncontrolled spreading of conspiracy theories, hoaxes, unsubstantiated claims,\nand false news. Such an impressive amount of misinformation can influence\npolicy preferences and encourage behaviors strongly divergent from recommended\npractices. In this paper, we study the statistical properties of viral\nmisinformation in online social media. By means of methods belonging to Extreme\nValue Theory, we show that the number of extremely viral posts over time\nfollows a homogeneous Poisson process, and that the interarrival times between\nsuch posts are independent and identically distributed, following an\nexponential distribution. Moreover, we characterize the uncertainty around the\nrate parameter of the Poisson process through Bayesian methods. Finally, we are\nable to derive the predictive posterior probability distribution of the number\nof posts exceeding a certain threshold of shares over a finite interval of\ntime.", "doi": "10.1016/j.physa.2016.11.012", "date": "2016-09-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1609.09435v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3889158462, "title": "The Voynich Manuscript is Written in Natural Language: The Pahlavi\n  Hypothesis", "abstract": "The late medieval Voynich Manuscript (VM) has resisted decryption and was\nconsidered a meaningless hoax or an unsolvable cipher. Here, we provide\nevidence that the VM is written in natural language by establishing a relation\nof the Voynich alphabet and the Iranian Pahlavi script. Many of the Voynich\ncharacters are upside-down versions of their Pahlavi counterparts, which may be\nan effect of different writing directions. Other Voynich letters can be\nexplained as ligatures or departures from Pahlavi with the intent to cope with\nknown problems due to the stupendous ambiguity of Pahlavi text. While a\ntranslation of the VM text is not attempted here, we can confirm the\nVoynich-Pahlavi relation at the character level by the transcription of many\nwords from the VM illustrations and from parts of the main text. Many of the\ntranscribed words can be identified as terms from Zoroastrian cosmology which\nis in line with the use of Pahlavi script in Zoroastrian communities from\nmedieval times.", "doi": "", "date": "2017-09-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1709.01634v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3213696268, "title": "Nuclear Disarmament Verification via Resonant Phenomena", "abstract": "Nuclear disarmament treaties are not sufficient in and of themselves to\nneutralize the existential threat of the nuclear weapons. Technologies are\nnecessary for verifying the authenticity of the nuclear warheads undergoing\ndismantlement before counting them towards a treaty partner's obligation. This\nwork presents a novel concept that leverages isotope-specific nuclear resonance\nphenomena to authenticate a warhead's fissile components by comparing them to a\npreviously authenticated template. All information is encrypted in the physical\ndomain in a manner that amounts to a physical zero-knowledge proof system.\nUsing Monte Carlo simulations, the system is shown to reveal no isotopic or\ngeometric information about the weapon, while readily detecting hoaxing\nattempts. This nuclear technique can dramatically increase the reach and\ntrustworthiness of future nuclear disarmament treaties.", "doi": "10.1038/s41467-018-03680-4", "date": "2017-09-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1709.09736v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2617200188, "title": "Polarization and Fake News: Early Warning of Potential Misinformation\n  Targets", "abstract": "Users polarization and confirmation bias play a key role in misinformation\nspreading on online social media. Our aim is to use this information to\ndetermine in advance potential targets for hoaxes and fake news. In this paper,\nwe introduce a general framework for promptly identifying polarizing content on\nsocial media and, thus, \"predicting\" future fake news topics. We validate the\nperformances of the proposed methodology on a massive Italian Facebook dataset,\nshowing that we are able to identify topics that are susceptible to\nmisinformation with 77% accuracy. Moreover, such information may be embedded as\na new feature in an additional classifier able to recognize fake news with 91%\naccuracy. The novelty of our approach consists in taking into account a series\nof characteristics related to users behavior on online social media, making a\nfirst, important step towards the smoothing of polarization and the mitigation\nof misinformation phenomena.", "doi": "", "date": "2018-02-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1802.01400v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1892167155, "title": "Fake news detection using Deep Learning", "abstract": "The evolution of the information and communication technologies has\ndramatically increased the number of people with access to the Internet, which\nhas changed the way the information is consumed. As a consequence of the above,\nfake news have become one of the major concerns because its potential to\ndestabilize governments, which makes them a potential danger to modern society.\nAn example of this can be found in the US. electoral campaign, where the term\n\"fake news\" gained great notoriety due to the influence of the hoaxes in the\nfinal result of these. In this work the feasibility of applying deep learning\ntechniques to discriminate fake news on the Internet using only their text is\nstudied. In order to accomplish that, three different neural network\narchitectures are proposed, one of them based on BERT, a modern language model\ncreated by Google which achieves state-of-the-art results.", "doi": "", "date": "2019-09-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.03496v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3219510195, "title": "Do Sentence Interactions Matter? Leveraging Sentence Level\n  Representations for Fake News Classification", "abstract": "The rising growth of fake news and misleading information through online\nmedia outlets demands an automatic method for detecting such news articles. Of\nthe few limited works which differentiate between trusted vs other types of\nnews article (satire, propaganda, hoax), none of them model sentence\ninteractions within a document. We observe an interesting pattern in the way\nsentences interact with each other across different kind of news articles. To\ncapture this kind of information for long news articles, we propose a graph\nneural network-based model which does away with the need of feature engineering\nfor fine grained fake news classification. Through experiments, we show that\nour proposed method beats strong neural baselines and achieves state-of-the-art\naccuracy on existing datasets. Moreover, we establish the generalizability of\nour model by evaluating its performance in out-of-domain scenarios. Code is\navailable at https://github.com/MysteryVaibhav/fake_news_semantics", "doi": "", "date": "2019-10-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.12203v1", "pdf": ""}, "publisher-venue": "TextGraphs - EMNLP 2019", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 655566131, "title": "False Information on Web and Social Media: A Survey", "abstract": "False information can be created and spread easily through the web and social\nmedia platforms, resulting in widespread real-world impact. Characterizing how\nfalse information proliferates on social platforms and why it succeeds in\ndeceiving readers are critical to develop efficient detection algorithms and\ntools for early detection. A recent surge of research in this area has aimed to\naddress the key issues using methods based on feature engineering, graph\nmining, and information modeling. Majority of the research has primarily\nfocused on two broad categories of false information: opinion-based (e.g., fake\nreviews), and fact-based (e.g., false news and hoaxes). Therefore, in this\nwork, we present a comprehensive survey spanning diverse aspects of false\ninformation, namely (i) the actors involved in spreading false information,\n(ii) rationale behind successfully deceiving readers, (iii) quantifying the\nimpact of false information, (iv) measuring its characteristics across\ndifferent dimensions, and finally, (iv) algorithms developed to detect false\ninformation. In doing so, we create a unified framework to describe these\nrecent methods and highlight a number of important directions for future\nresearch.", "doi": "", "date": "2018-04-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.08559v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4228587344, "title": "Agent Based Rumor Spreading in a scale-free network", "abstract": "In the last years, the study of rumor spreading on social networks produced a\nlot of interest among the scientific community, expecially due to the role of\nsocial networks in the last political events. The goal of this work is to\nreproduce real-like diffusions of information and misinformation in a\nscale-free network using a multi-agent-based model. The data concerning the\nvirtual spreading are easily obtainable, in particular the diffusion of\ninformation during the announcement for the discovery of the Higgs Boson on\nTwitter was recorded and investigated in detail. We made some assumptions on\nthe micro behavior of our agents and registered the effects in a statistical\nanalysis replying the real data diffusion. Then, we studied an hypotetical\nresponse to a misinformation diffusion adding debunking agents and trying to\nmodel a critic response from the agents using real data from a hoax regarding\nthe Occupy Wall Street movement. After tuning our model to reproduce these\nresults, we measured some network properties and proved the emergence of\nsubstantially separated structures like echochambers, independently from the\nnetwork size scale, i.e. with one hundred, one thousand and ten thousand\nagents.", "doi": "", "date": "2018-05-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1805.05999v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4147291487, "title": "Hoaxy: A Platform for Tracking Online Misinformation", "abstract": "Massive amounts of misinformation have been observed to spread in\nuncontrolled fashion across social media. Examples include rumors, hoaxes, fake\nnews, and conspiracy theories. At the same time, several journalistic\norganizations devote significant efforts to high-quality fact checking of\nonline claims. The resulting information cascades contain instances of both\naccurate and inaccurate information, unfold over multiple time scales, and\noften reach audiences of considerable size. All these factors pose challenges\nfor the study of the social dynamics of online news sharing. Here we introduce\nHoaxy, a platform for the collection, detection, and analysis of online\nmisinformation and its related fact-checking efforts. We discuss the design of\nthe platform and present a preliminary analysis of a sample of public tweets\ncontaining both fake news and fact checking. We find that, in the aggregate,\nthe sharing of fact-checking content typically lags that of misinformation by\n10--20 hours. Moreover, fake news are dominated by very active users, while\nfact checking is a more grass-roots activity. With the increasing risks\nconnected to massive online misinformation, social news observatories have the\npotential to help researchers, journalists, and the general public understand\nthe dynamics of real and fake news sharing.", "doi": "10.1145/2872518.2890098", "date": "2016-03-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1603.01511v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 505798358, "title": "Identifying Coordinated Accounts on Social Media through Hidden\n  Influence and Group Behaviours", "abstract": "Disinformation campaigns on social media, involving coordinated activities\nfrom malicious accounts towards manipulating public opinion, have become\nincreasingly prevalent. Existing approaches to detect coordinated accounts\neither make very strict assumptions about coordinated behaviours, or require\npart of the malicious accounts in the coordinated group to be revealed in order\nto detect the rest. To address these drawbacks, we propose a generative model,\nAMDN-HAGE (Attentive Mixture Density Network with Hidden Account Group\nEstimation) which jointly models account activities and hidden group behaviours\nbased on Temporal Point Processes (TPP) and Gaussian Mixture Model (GMM), to\ncapture inherent characteristics of coordination which is, accounts that\ncoordinate must strongly influence each other's activities, and collectively\nappear anomalous from normal accounts. To address the challenges of optimizing\nthe proposed model, we provide a bilevel optimization algorithm with\ntheoretical guarantee on convergence. We verified the effectiveness of the\nproposed method and training algorithm on real-world social network data\ncollected from Twitter related to coordinated campaigns from Russia's Internet\nResearch Agency targeting the 2016 U.S. Presidential Elections, and to identify\ncoordinated campaigns related to the COVID-19 pandemic. Leveraging the learned\nmodel, we find that the average influence between coordinated account pairs is\nthe highest.On COVID-19, we found coordinated group spreading anti-vaccination,\nanti-masks conspiracies that suggest the pandemic is a hoax and political scam.", "doi": "", "date": "2020-08-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.11308v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2673205057, "title": "FaNDS: Fake News Detection System Using Energy Flow", "abstract": "Recently, the term \"fake news\" has been broadly and extensively utilized for\ndisinformation, misinformation, hoaxes, propaganda, satire, rumors, click-bait,\nand junk news. It has become a serious problem around the world. We present a\nnew system, FaNDS, that detects fake news efficiently. The system is based on\nseveral concepts used in some previous works but in a different context. There\nare two main concepts: an Inconsistency Graph and Energy Flow. The\nInconsistency Graph contains news items as nodes and inconsistent opinions\nbetween them for edges. Energy Flow assigns each node an initial energy and\nthen some energy is propagated along the edges until the energy distribution on\nall nodes converges. To illustrate FaNDS we use the original data from the Fake\nNews Challenge (FNC-1). First, the data has to be reconstructed in order to\ngenerate the Inconsistency Graph. The graph contains various subgraphs with\nwell-defined shapes that represent different types of connections between the\nnews items. Then the Energy Flow method is applied. The nodes with high energy\nare the candidates for being fake news. In our experiments, all these were\nindeed fake news as we checked each using several reliable web sites. We\ncompared FaNDS to several other fake news detection methods and found it to be\nmore sensitive in discovering fake news items.", "doi": "", "date": "2020-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.02097v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2523937007, "title": "Identifying Possible Rumor Spreaders on Twitter: A Weak Supervised\n  Learning Approach", "abstract": "Online Social Media (OSM) platforms such as Twitter, Facebook are extensively\nexploited by the users of these platforms for spreading the (mis)information to\na large audience effortlessly at a rapid pace. It has been observed that the\nmisinformation can cause panic, fear, and financial loss to society. Thus, it\nis important to detect and control the misinformation in such platforms before\nit spreads to the masses. In this work, we focus on rumors, which is one type\nof misinformation (other types are fake news, hoaxes, etc). One way to control\nthe spread of the rumors is by identifying users who are possibly the rumor\nspreaders, that is, users who are often involved in spreading the rumors. Due\nto the lack of availability of rumor spreaders labeled dataset (which is an\nexpensive task), we use publicly available PHEME dataset, which contains rumor\nand non-rumor tweets information, and then apply a weak supervised learning\napproach to transform the PHEME dataset into rumor spreaders dataset. We\nutilize three types of features, that is, user, text, and ego-network features,\nbefore applying various supervised learning approaches. In particular, to\nexploit the inherent network property in this dataset (user-user reply graph),\nwe explore Graph Convolutional Network (GCN), a type of Graph Neural Network\n(GNN) technique. We compare GCN results with the other approaches: SVM, RF, and\nLSTM. Extensive experiments performed on the rumor spreaders dataset, where we\nachieve up to 0.864 value for F1-Score and 0.720 value for AUC-ROC, shows the\neffectiveness of our methodology for identifying possible rumor spreaders using\nthe GCN technique.", "doi": "", "date": "2020-10-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.07647v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3605409042, "title": "Deepfakes Generation and Detection: State-of-the-art, open challenges,\n  countermeasures, and way forward", "abstract": "Easy access to audio-visual content on social media, combined with the\navailability of modern tools such as Tensorflow or Keras, open-source trained\nmodels, and economical computing infrastructure, and the rapid evolution of\ndeep-learning (DL) methods, especially Generative Adversarial Networks (GAN),\nhave made it possible to generate deepfakes to disseminate disinformation,\nrevenge porn, financial frauds, hoaxes, and to disrupt government functioning.\nThe existing surveys have mainly focused on deepfake video detection only. No\nattempt has been made to review approaches for detection and generation of both\naudio and video deepfakes. This paper provides a comprehensive review and\ndetailed analysis of existing tools and machine learning (ML) based approaches\nfor deepfake generation and the methodologies used to detect such manipulations\nfor the detection and generation of both audio and video deepfakes. For each\ncategory of deepfake, we discuss information related to manipulation\napproaches, current public datasets, and key standards for the performance\nevaluation of deepfake detection techniques along with their results.\nAdditionally, we also discuss open challenges and enumerate future directions\nto guide future researchers on issues that need to be considered to improve the\ndomains of both the deepfake generation and detection. This work is expected to\nassist the readers in understanding the creation and detection mechanisms of\ndeepfake, along with their current limitations and future direction.", "doi": "", "date": "2021-02-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.00484v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3317822930, "title": "Using an Epidemiological Model to Study the Spread of Misinformation\n  during the Black Lives Matter Movement", "abstract": "The proliferation of social media platforms like Twitter has heightened the\nconsequences of the spread of misinformation. To understand and model the\nspread of misinformation, in this paper, we leveraged the SEIZ (Susceptible,\nExposed, Infected, Skeptics) epidemiological model to describe the underlying\nprocess that delineates the spread of misinformation on Twitter. Compared to\nthe other epidemiological models, this model produces broader results because\nit includes the additional Skeptics (Z) compartment, wherein a user may be\nexposed to an item of misinformation but not engage in any reaction to it, and\nthe additional Exposed (E) compartment, wherein the user may need some time\nbefore deciding to spread a misinformation item. We analyzed misinformation\nregarding the unrest in Washington, D.C. in the month of March 2020 which was\npropagated by the use of the #DCblackout hashtag by different users across the\nU.S. on Twitter. Our analysis shows that misinformation can be modeled using\nthe concept of epidemiology. To the best of our knowledge, this research is the\nfirst to attempt to apply the SEIZ epidemiological model to the spread of a\nspecific item of misinformation, which is a category distinct from that of\nrumor, and a hoax on online social media platforms. Applying a mathematical\nmodel can help to understand the trends and dynamics of the spread of\nmisinformation on Twitter and ultimately help to develop techniques to quickly\nidentify and control it.", "doi": "", "date": "2021-03-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.12191v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1358005379, "title": "Can Evolutionary Computation Help us to Crib the Voynich Manuscript ?", "abstract": "Departing from the postulate that Voynich Manuscript is not a hoax but rather\nencodes authentic contents, our article presents an evolutionary algorithm\nwhich aims to find the most optimal mapping between voynichian glyphs and\ncandidate phonemic values. Core component of the decoding algorithm is a\nprocess of maximization of a fitness function which aims to find most optimal\nset of substitution rules allowing to transcribe the part of the manuscript --\nwhich we call the Calendar -- into lists of feminine names. This leads to sets\nof character subsitution rules which allow us to consistently transcribe dozens\namong three hundred calendar tokens into feminine names: a result far\nsurpassing both ``popular'' as well as \"state of the art\" tentatives to crack\nthe manuscript. What's more, by using name lists stemming from different\nlanguages as potential cribs, our ``adaptive'' method can also be useful in\nidentification of the language in which the manuscript is written.\n  As far as we can currently tell, results of our experiments indicate that the\nCalendar part of the manuscript contains names from baltoslavic, balkanic or\nhebrew language strata. Two further indications are also given: primo, highest\nfitness values were obtained when the crib list contains names with specific\ninfixes at token's penultimate position as is the case, for example, for slavic\n\\textbf{feminine diminutives} (i.e. names ending with -ka and not -a). In the\nmost successful scenario, 240 characters contained in 35 distinct Voynichese\ntokens were successfully transcribed. Secundo, in case of crib stemming from\nHebrew language, whole adaptation process converges to significantly better\nfitness values when transcribing voynichian tokens whose order of individual\ncharacters have been reversed, and when lists feminine and not masculine names\nare used as the crib.", "doi": "", "date": "2021-07-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.05381v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2058597306, "title": "Conspiracy in the Time of Corona: Automatic detection of Covid-19\n  Conspiracy Theories in Social Media and the News", "abstract": "Rumors and conspiracy theories thrive in environments of low confidence and\nlow trust. Consequently, it is not surprising that ones related to the Covid-19\npandemic are proliferating given the lack of any authoritative scientific\nconsensus on the virus, its spread and containment, or on the long term social\nand economic ramifications of the pandemic. Among the stories currently\ncirculating are ones suggesting that the 5G network activates the virus, that\nthe pandemic is a hoax perpetrated by a global cabal, that the virus is a\nbio-weapon released deliberately by the Chinese, or that Bill Gates is using it\nas cover to launch a global surveillance regime. While some may be quick to\ndismiss these stories as having little impact on real-world behavior, recent\nevents including the destruction of property, racially fueled attacks against\nAsian Americans, and demonstrations espousing resistance to public health\norders countermand such conclusions. Inspired by narrative theory, we crawl\nsocial media sites and news reports and, through the application of automated\nmachine-learning methods, discover the underlying narrative frameworks\nsupporting the generation of these stories. We show how the various narrative\nframeworks fueling rumors and conspiracy theories rely on the alignment of\notherwise disparate domains of knowledge, and consider how they attach to the\nbroader reporting on the pandemic. These alignments and attachments, which can\nbe monitored in near real-time, may be useful for identifying areas in the news\nthat are particularly vulnerable to reinterpretation by conspiracy theorists.\nUnderstanding the dynamics of storytelling on social media and the narrative\nframeworks that provide the generative basis for these stories may also be\nhelpful for devising methods to disrupt their spread.", "doi": "", "date": "2020-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.13783v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2034656524, "title": "Cognitive networks identify the content of English and Italian popular\n  posts about COVID-19 vaccines: Anticipation, logistics, conspiracy and loss\n  of trust", "abstract": "Monitoring social discourse about COVID-19 vaccines is key to understanding\nhow large populations perceive vaccination campaigns. We focus on 4765 unique\npopular tweets in English or Italian about COVID-19 vaccines between 12/2020\nand 03/2021. One popular English tweet was liked up to 495,000 times, stressing\nhow popular tweets affected cognitively massive populations. We investigate\nboth text and multimedia in tweets, building a knowledge graph of\nsyntactic/semantic associations in messages including visual features and\nindicating how online users framed social discourse mostly around the logistics\nof vaccine distribution. The English semantic frame of \"vaccine\" was highly\npolarised between trust/anticipation (towards the vaccine as a scientific asset\nsaving lives) and anger/sadness (mentioning critical issues with dose\nadministering). Semantic associations with \"vaccine,\" \"hoax\" and conspiratorial\njargon indicated the persistence of conspiracy theories and vaccines in\nmassively read English posts (absent in Italian messages). The image analysis\nfound that popular tweets with images of people wearing face masks used\nlanguage lacking the trust and joy found in tweets showing people with no\nmasks, indicating a negative affect attributed to face covering in social\ndiscourse. A behavioural analysis revealed a tendency for users to share\ncontent eliciting joy, sadness and disgust and to like less sad messages,\nhighlighting an interplay between emotions and content diffusion beyond\nsentiment. With the AstraZeneca vaccine being suspended in mid March 2021,\n\"Astrazeneca\" was associated with trustful language driven by experts, but\npopular Italian tweets framed \"vaccine\" by crucially replacing earlier levels\nof trust with deep sadness. Our results stress how cognitive networks and\ninnovative multimedia processing open new ways for reconstructing online\nperceptions about vaccines and trust.", "doi": "", "date": "2021-03-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.15909v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}][{"id": 3032661722, "title": "FactRank - Developing automated claim detection for Dutch-language fact-checkers.", "abstract": "", "doi": "10.1016/j.osnem.2020.100113", "date": "2021", "authors": [{"name": "Bettina Berendt", "id-internal": "b/BettinaBerendt", "id-external": ""}, {"name": "Peter Burger", "id-internal": "32/3791", "id-external": ""}, {"name": "Rafael Hautekiet", "id-internal": "288/6218", "id-external": ""}, {"name": "Jan Jagers", "id-internal": "288/6306", "id-external": ""}, {"name": "Alexander Pleijter", "id-internal": "234/7821", "id-external": ""}, {"name": "Peter Van Aelst", "id-internal": "196/8545", "id-external": ""}], "url": {"full": "URL#76835", "pdf": ""}, "publisher-venue": "Online Soc. Networks Media", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2751525486, "title": "Automated Fact-Checking for Assisting Human Fact-Checkers.", "abstract": "", "doi": "10.24963/ijcai.2021/619", "date": "2021", "authors": [{"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "David P. A. Corney", "id-internal": "65/1285", "id-external": ""}, {"name": "Maram Hasanain", "id-internal": "151/5519", "id-external": ""}, {"name": "Firoj Alam", "id-internal": "126/2083", "id-external": ""}, {"name": "Tamer Elsayed", "id-internal": "99/5856", "id-external": ""}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o", "id-internal": "40/3383", "id-external": ""}, {"name": "Paolo Papotti", "id-internal": "p/PaoloPapotti", "id-external": ""}, {"name": "Shaden Shaar", "id-internal": "234/1620", "id-external": ""}, {"name": "Giovanni Da San Martino", "id-internal": "25/3236", "id-external": ""}], "url": {"full": "URL#163886", "pdf": ""}, "publisher-venue": "IJCAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1583393118, "title": "Automated Fact-Checking for Assisting Human Fact-Checkers.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "David P. A. Corney", "id-internal": "65/1285", "id-external": ""}, {"name": "Maram Hasanain", "id-internal": "151/5519", "id-external": ""}, {"name": "Firoj Alam", "id-internal": "126/2083", "id-external": ""}, {"name": "Tamer Elsayed", "id-internal": "99/5856", "id-external": ""}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o", "id-internal": "40/3383", "id-external": ""}, {"name": "Paolo Papotti", "id-internal": "p/PaoloPapotti", "id-external": ""}, {"name": "Shaden Shaar", "id-internal": "234/1620", "id-external": ""}, {"name": "Giovanni Da San Martino", "id-internal": "25/3236", "id-external": ""}], "url": {"full": "URL#204013", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2328091791, "title": "Learning from Fact-checkers - Analysis and Generation of Fact-checking Language.", "abstract": "", "doi": "10.1145/3331184.3331248", "date": "2019", "authors": [{"name": "Nguyen Vo", "id-internal": "167/0323", "id-external": ""}, {"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}], "url": {"full": "URL#975869", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3567601747, "title": "A blockchain-based fact-checking registry - Enhancing trust in the fact-checkers.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Walid Al-Saqaf", "id-internal": "277/5974", "id-external": ""}, "url": {"full": "URL#985240", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3453438211, "title": "Learning from Fact-checkers - Analysis and Generation of Fact-checking Language.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Nguyen Vo", "id-internal": "167/0323", "id-external": ""}, {"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}], "url": {"full": "URL#1042786", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2968294947, "title": "Fighting the COVID-19 Infodemic - Modeling the Perspective of Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the Society.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Firoj Alam", "id-internal": "126/2083", "id-external": ""}, {"name": "Shaden Shaar", "id-internal": "234/1620", "id-external": ""}, {"name": "Alex Nikolov", "id-internal": "242/4800", "id-external": ""}, {"name": "Hamdy Mubarak", "id-internal": "146/4030", "id-external": ""}, {"name": "Giovanni Da San Martino", "id-internal": "25/3236", "id-external": ""}, {"name": "Ahmed Abdelali", "id-internal": "48/5636", "id-external": ""}, {"name": "Fahim Dalvi", "id-internal": "194/2537", "id-external": ""}, {"name": "Nadir Durrani", "id-internal": "54/9012", "id-external": ""}, {"name": "Hassan Sajjad", "id-internal": "73/5938", "id-external": ""}, {"name": "Kareem Darwish", "id-internal": "13/5913", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}], "url": {"full": "URL#603461", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1218637610, "title": "Language Models as Fact Checkers?", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Nayeon Lee", "id-internal": "212/6295", "id-external": ""}, {"name": "Belinda Z. Li", "id-internal": "263/9914", "id-external": ""}, {"name": "Sinong Wang", "id-internal": "140/0795", "id-external": ""}, {"name": "Wen-tau Yih", "id-internal": "07/7129", "id-external": ""}, {"name": "Hao Ma", "id-internal": "86/4227", "id-external": ""}, {"name": "Madian Khabsa", "id-internal": "87/11087", "id-external": ""}], "url": {"full": "URL#610764", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1321640166, "title": "Automated Fact-Checking for Assisting Human Fact-Checkers", "abstract": "The reporting and the analysis of current events around the globe has\nexpanded from professional, editor-lead journalism all the way to citizen\njournalism. Nowadays, politicians and other key players enjoy direct access to\ntheir audiences through social media, bypassing the filters of official cables\nor traditional media. However, the multiple advantages of free speech and\ndirect communication are dimmed by the misuse of media to spread inaccurate or\nmisleading claims. These phenomena have led to the modern incarnation of the\nfact-checker -- a professional whose main aim is to examine claims using\navailable evidence and to assess their veracity. As in other text forensics\ntasks, the amount of information available makes the work of the fact-checker\nmore difficult. With this in mind, starting from the perspective of the\nprofessional fact-checker, we survey the available intelligent technologies\nthat can support the human expert in the different steps of her fact-checking\nendeavor. These include identifying claims worth fact-checking, detecting\nrelevant previously fact-checked claims, retrieving relevant evidence to\nfact-check a claim, and actually verifying a claim. In each case, we pay\nattention to the challenges in future work and the potential impact on\nreal-world fact-checking.", "doi": "", "date": "2021-03-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.07769v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3817725814, "title": "Scrutinizer: A Mixed-Initiative Approach to Large-Scale, Data-Driven\n  Claim Verification", "abstract": "Organizations such as the International Energy Agency (IEA) spend significant\namounts of time and money to manually fact check text documents summarizing\ndata. The goal of the Scrutinizer system is to reduce verification overheads by\nsupporting human fact checkers in translating text claims into SQL queries on\nan associated database.\n  Scrutinizer coordinates teams of human fact checkers. It reduces verification\ntime by proposing queries or query fragments to the users. Those proposals are\nbased on claim text classifiers, that gradually improve during the verification\nof a large document. In addition, Scrutinizer uses tentative execution of query\ncandidates to narrow down the set of alternatives. The verification process is\ncontrolled by a cost-based optimizer. It optimizes the interaction with users\nand prioritizes claim verifications. For the latter, it considers expected\nverification overheads as well as the expected claim utility as training\nsamples for the classifiers. We evaluate the Scrutinizer system using\nsimulations and a user study, based on actual claims and data and using\nprofessional fact checkers employed by IEA. Our experiments consistently\ndemonstrate significant savings in verification time, without reducing result\naccuracy.", "doi": "", "date": "2020-03-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.06708v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1367129183, "title": "Language Models as Fact Checkers?", "abstract": "Recent work has suggested that language models (LMs) store both common-sense\nand factual knowledge learned from pre-training data. In this paper, we\nleverage this implicit knowledge to create an effective end-to-end fact checker\nusing a solely a language model, without any external knowledge or explicit\nretrieval components. While previous work on extracting knowledge from LMs have\nfocused on the task of open-domain question answering, to the best of our\nknowledge, this is the first work to examine the use of language models as fact\ncheckers. In a closed-book setting, we show that our zero-shot LM approach\noutperforms a random baseline on the standard FEVER task, and that our\nfine-tuned LM compares favorably with standard baselines. Though we do not\nultimately outperform methods which use explicit knowledge bases, we believe\nour exploration shows that this method is viable and has much room for\nexploration.", "doi": "", "date": "2020-06-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.04102v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2068336266, "title": "Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language", "abstract": "In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.", "doi": "", "date": "2019-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.02202v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 108850251, "title": "Selecting Data to Clean for Fact Checking: Minimizing Uncertainty vs.\n  Maximizing Surprise", "abstract": "We study the optimization problem of selecting numerical quantities to clean\nin order to fact-check claims based on such data. Oftentimes, such claims are\ntechnically correct, but they can still mislead for two reasons. First, data\nmay contain uncertainty and errors. Second, data can be \"fished\" to advance\nparticular positions. In practice, fact-checkers cannot afford to clean all\ndata and must choose to clean what \"matters the most\" to checking a claim. We\nexplore alternative definitions of what \"matters the most\": one is to ascertain\nclaim qualities (by minimizing uncertainty in these measures), while an\nalternative is just to counter the claim (by maximizing the probability of\nfinding a counterargument). We show whether the two objectives align with each\nother, with important implications on when fact-checkers should exercise care\nin selective data cleaning, to avoid potential bias introduced by their desire\nto counter claims. We develop efficient algorithms for solving the various\nvariants of the optimization problem, showing significant improvements over\nnaive solutions. The problem is particularly challenging because the objectives\nin the fact-checking context are complex, non-linear functions over data. We\nobtain results that generalize to a large class of functions, with potential\napplications beyond fact-checking.", "doi": "10.14778/3358701.3358708", "date": "2019-09-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.05380v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4034985354, "title": "Fact Check: Analyzing Financial Events from Multilingual News Sources", "abstract": "The explosion in the sheer magnitude and complexity of financial news data in\nrecent years makes it increasingly challenging for investment analysts to\nextract valuable insights and perform analysis. We propose FactCheck in\nfinance, a web-based news aggregator with deep learning models, to provide\nanalysts with a holistic view of important financial events from multilingual\nnews sources and extract events using an unsupervised clustering method. A web\ninterface is provided to examine the credibility of news articles using a\ntransformer-based fact-checker. The performance of the fact checker is\nevaluated using a dataset related to merger and acquisition (M\\&A) events and\nis shown to outperform several strong baselines.", "doi": "", "date": "2021-06-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.15221v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2444011674, "title": "NoFake at CheckThat! 2021: Fake News Detection Using BERT", "abstract": "Much research has been done for debunking and analysing fake news. Many\nresearchers study fake news detection in the last year, but many are limited to\nsocial media data. Currently, multiples fact-checkers are publishing their\nresults in various formats. Also, multiple fact-checkers use different labels\nfor the fake news, making it difficult to make a generalisable classifier. With\nthe merge classes, the performance of the machine model can be enhanced. This\ndomain categorisation will help group the article, which will help save the\nmanual effort in assigning the claim verification. In this paper, we have\npresented BERT based classification model to predict the domain and\nclassification. We have also used additional data from fact-checked articles.\nWe have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B\nusing the additional training data.", "doi": "", "date": "2021-08-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.05419v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3783667607, "title": "HoaxItaly: a collection of Italian disinformation and fact-checking\n  stories shared on Twitter in 2019", "abstract": "We released over 1 million tweets shared during 2019 and containing links to\nthousands of news articles published on two classes of Italian outlets: (1)\ndisinformation websites, i.e. outlets which have been repeatedly flagged by\njournalists and fact-checkers for producing low-credibility content such as\nfalse news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)\nfact-checking websites which notably debunk and verify online news and claims.\nThe dataset, which includes also title and body for approximately 37k news\narticles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.", "doi": "", "date": "2020-01-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.10926v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4277480656, "title": "Text Similarity Using Word Embeddings to Classify Misinformation", "abstract": "Fake news is a growing problem in the last years, especially during\nelections. It's hard work to identify what is true and what is false among all\nthe user generated content that circulates every day. Technology can help with\nthat work and optimize the fact-checking process. In this work, we address the\nchallenge of finding similar content in order to be able to suggest to a\nfact-checker articles that could have been verified before and thus avoid that\nthe same information is verified more than once. This is especially important\nin collaborative approaches to fact-checking where members of large teams will\nnot know what content others have already fact-checked.", "doi": "", "date": "2020-03-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.06634v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1272546894, "title": "Estimating predictive uncertainty for rumour verification models", "abstract": "The inability to correctly resolve rumours circulating online can have\nharmful real-world consequences. We present a method for incorporating model\nand data uncertainty estimates into natural language processing models for\nautomatic rumour verification. We show that these estimates can be used to\nfilter out model predictions likely to be erroneous, so that these difficult\ninstances can be prioritised by a human fact-checker. We propose two methods\nfor uncertainty-based instance rejection, supervised and unsupervised. We also\nshow how uncertainty estimates can be used to interpret model performance as a\nrumour unfolds.", "doi": "", "date": "2020-05-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.07174v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3798674009, "title": "Finding Streams in Knowledge Graphs to Support Fact Checking", "abstract": "The volume and velocity of information that gets generated online limits\ncurrent journalistic practices to fact-check claims at the same rate.\nComputational approaches for fact checking may be the key to help mitigate the\nrisks of massive misinformation spread. Such approaches can be designed to not\nonly be scalable and effective at assessing veracity of dubious claims, but\nalso to boost a human fact checker's productivity by surfacing relevant facts\nand patterns to aid their analysis. To this end, we present a novel,\nunsupervised network-flow based approach to determine the truthfulness of a\nstatement of fact expressed in the form of a (subject, predicate, object)\ntriple. We view a knowledge graph of background information about real-world\nentities as a flow network, and knowledge as a fluid, abstract commodity. We\nshow that computational fact checking of such a triple then amounts to finding\na \"knowledge stream\" that emanates from the subject node and flows toward the\nobject node through paths connecting them. Evaluation on a range of real-world\nand hand-crafted datasets of facts related to entertainment, business, sports,\ngeography and more reveals that this network-flow model can be very effective\nin discerning true statements from false ones, outperforming existing\nalgorithms on many test cases. Moreover, the model is expressive in its ability\nto automatically discover several useful path patterns and surface relevant\nfacts that may help a human fact checker corroborate or refute a claim.", "doi": "", "date": "2017-08-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1708.07239v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1180303048, "title": "Fighting the COVID-19 Infodemic: Modeling the Perspective of\n  Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the\n  Society", "abstract": "With the emergence of the COVID-19 pandemic, the political and the medical\naspects of disinformation merged as the problem got elevated to a whole new\nlevel to become the first global infodemic. Fighting this infodemic is ranked\nsecond in the list of the most important focus areas of the World Health\nOrganization, with dangers ranging from promoting fake cures, rumors, and\nconspiracy theories to spreading xenophobia and panic. Addressing the issue\nrequires solving a number of challenging problems such as identifying messages\ncontaining claims, determining their check-worthiness and factuality, and their\npotential to do harm as well as the nature of that harm, to mention just a few.\nThus, here we design, annotate, and release to the research community a new\ndataset for fine-grained disinformation analysis that (i)focuses on COVID-19,\n(ii) combines the perspectives and the interests of journalists, fact-checkers,\nsocial media platforms, policy makers, and society as a whole, and (iii) covers\nboth English and Arabic. Finally, we show strong evaluation results using\nstate-of-the-art Transformers, thus confirming the practical utility of the\nannotation schema and of the dataset.", "doi": "", "date": "2020-04-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.00033v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 376754638, "title": "Accenture at CheckThat! 2020: If you say so: Post-hoc fact-checking of\n  claims using transformer-based models", "abstract": "We introduce the strategies used by the Accenture Team for the CLEF2020\nCheckThat! Lab, Task 1, on English and Arabic. This shared task evaluated\nwhether a claim in social media text should be professionally fact checked. To\na journalist, a statement presented as fact, which would be of interest to a\nlarge audience, requires professional fact-checking before dissemination. We\nutilized BERT and RoBERTa models to identify claims in social media text a\nprofessional fact-checker should review, and rank these in priority order for\nthe fact-checker. For the English challenge, we fine-tuned a RoBERTa model and\nadded an extra mean pooling layer and a dropout layer to enhance\ngeneralizability to unseen text. For the Arabic task, we fine-tuned\nArabic-language BERT models and demonstrate the use of back-translation to\namplify the minority class and balance the dataset. The work presented here was\nscored 1st place in the English track, and 1st, 2nd, 3rd, and 4th place in the\nArabic track.", "doi": "", "date": "2020-09-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.02431v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3011474971, "title": "ClaimRank: Detecting Check-Worthy Claims in Arabic and English", "abstract": "We present ClaimRank, an online system for detecting check-worthy claims.\nWhile originally trained on political debates, the system can work for any kind\nof text, e.g., interviews or regular news articles. Its aim is to facilitate\nmanual fact-checking efforts by prioritizing the claims that fact-checkers\nshould consider first. ClaimRank supports both Arabic and English, it is\ntrained on actual annotations from nine reputable fact-checking organizations\n(PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and\nWashington Post), and thus it can mimic the claim selection strategies for each\nand any of them, as well as for the union of them all.", "doi": "", "date": "2018-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.07587v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3339133581, "title": "Technology, Propaganda, and the Limits of Human Intellect", "abstract": "\"Fake news\" is a recent phenomenon, but misinformation and propaganda are\nnot. Our new communication technologies make it easy for us to be exposed to\nhigh volumes of true, false, irrelevant, and unprovable information. Future AI\nis expected to amplify the problem even more. At the same time, our brains are\nreaching their limits in handling information. How should we respond to\npropaganda? Technology can help, but relying on it alone will not suffice in\nthe long term. We also need ethical policies, laws, regulations, and trusted\nauthorities, including fact-checkers. However, we will not solve the problem\nwithout the active engagement of the educated citizen. Epistemological\neducation, recognition of self biases and protection of our channels of\ncommunication and trusted networks are all needed to overcome the problem and\ncontinue our progress as democratic societies.", "doi": "", "date": "2018-06-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.09541v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2717820776, "title": "Too Many Claims to Fact-Check: Prioritizing Political Claims Based on\n  Check-Worthiness", "abstract": "The massive amount of misinformation spreading on the Internet on a daily\nbasis has enormous negative impacts on societies. Therefore, we need automated\nsystems helping fact-checkers in the combat against misinformation. In this\npaper, we propose a model prioritizing the claims based on their\ncheck-worthiness. We use BERT model with additional features including\ndomain-specific controversial topics, word embeddings, and others. In our\nexperiments, we show that our proposed model outperforms all state-of-the-art\nmodels in both test collections of CLEF Check That! Lab in 2018 and 2019. We\nalso conduct a qualitative analysis to shed light-detecting check-worthy\nclaims. We suggest requesting rationales behind judgments are needed to\nunderstand subjective nature of the task and problematic labels.", "doi": "", "date": "2020-04-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.08166v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 759351968, "title": "Checkworthiness in Automatic Claim Detection Models: Definitions and\n  Analysis of Datasets", "abstract": "Public, professional and academic interest in automated fact-checking has\ndrastically increased over the past decade, with many aiming to automate one of\nthe first steps in a fact-check procedure: the selection of so-called\ncheckworthy claims. However, there is little agreement on the definition and\ncharacteristics of checkworthiness among fact-checkers, which is consequently\nreflected in the datasets used for training and testing checkworthy claim\ndetection models. After elaborate analysis of checkworthy claim selection\nprocedures in fact-check organisations and analysis of state-of-the-art claim\ndetection datasets, checkworthiness is defined as the concept of having a\nspatiotemporal and context-dependent worth and need to have the correctness of\nthe objectivity it conveys verified. This is irrespective of the claim's\nperceived veracity judgement by an individual based on prior knowledge and\nbeliefs. Concerning the characteristics of current datasets, it is argued that\nthe data is not only highly imbalanced and noisy, but also too limited in scope\nand language. Furthermore, we believe that the subjective concept of\ncheckworthiness might not be a suitable filter for claim detection.", "doi": "10.1007/978-3-030-61841-4_1", "date": "2020-08-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.08854v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4082178080, "title": "Check Mate: Prioritizing User Generated Multi-Media Content for\n  Fact-Checking", "abstract": "Volume of content and misinformation on social media is rapidly increasing.\nThere is a need for systems that can support fact checkers by prioritizing\ncontent that needs to be fact checked. Prior research on prioritizing content\nfor fact-checking has focused on news media articles, predominantly in English\nlanguage. Increasingly, misinformation is found in user-generated content. In\nthis paper we present a novel dataset that can be used to prioritize\ncheck-worthy posts from multi-media content in Hindi. It is unique in its 1)\nfocus on user generated content, 2) language and 3) accommodation of\nmulti-modality in social media posts. In addition, we also provide metadata for\neach post such as number of shares and likes of the post on ShareChat, a\npopular Indian social media platform, that allows for correlative analysis\naround virality and misinformation. The data is accessible on Zenodo\n(https://zenodo.org/record/4032629) under Creative Commons Attribution License\n(CC BY 4.0).", "doi": "", "date": "2020-10-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.13387v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2017535767, "title": "Generating Fact Checking Briefs", "abstract": "Fact checking at scale is difficult -- while the number of active fact\nchecking websites is growing, it remains too small for the needs of the\ncontemporary media ecosystem. However, despite good intentions, contributions\nfrom volunteers are often error-prone, and thus in practice restricted to claim\ndetection. We investigate how to increase the accuracy and efficiency of fact\nchecking by providing information about the claim before performing the check,\nin the form of natural language briefs. We investigate passage-based briefs,\ncontaining a relevant passage from Wikipedia, entity-centric ones consisting of\nWikipedia pages of mentioned entities, and Question-Answering Briefs, with\nquestions decomposing the claim, and their answers. To produce QABriefs, we\ndevelop QABriefer, a model that generates a set of questions conditioned on the\nclaim, searches the web for evidence, and generates answers. To train its\ncomponents, we introduce QABriefDataset which we collected via crowdsourcing.\nWe show that fact checking with briefs -- in particular QABriefs -- increases\nthe accuracy of crowdworkers by 10% while slightly decreasing the time taken.\nFor volunteer (unpaid) fact checkers, QABriefs slightly increase accuracy and\nreduce the time required by around 20%.", "doi": "", "date": "2020-11-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.05448v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2104350333, "title": "The Strategy Behind Anti-Vaxxers' Reply Behavior on Social Media", "abstract": "Although the online campaigns of anti-vaccine advocates, or anti-vaxxers,\nseverely threaten efforts for herd immunity, their propaganda strategies remain\npoorly understood, as does their reply behavior, which constitutes the most\ndirect form of outreach on social media. Therefore, we empirically analyzed the\nstrategy of anti-vaxxers' reply behavior on Twitter in terms of interaction\nfrequency, content, and targets. Among the results, anti-vaxxers more\nfrequently conducted reply behavior to other clusters, especially to neutral\naccounts, and the content of their replies was significantly toxic and\nemotional. Furthermore, the most-targeted users were so-called \"decent\"\naccounts with large numbers of followers, including accounts related to health\ncare or representing scientists, policymakers, or media figures or outlets. We\ndiscussed and evaluated the effectiveness of these reply strategies, as well as\nthe possible countermeasures to them. Those findings should prove useful for\ndeveloping guidelines for pro-vaxxers and fact-checkers in online communities.", "doi": "", "date": "2021-05-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.10319v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3432556329, "title": "X-FACT: A New Benchmark Dataset for Multilingual Fact Checking", "abstract": "In this work, we introduce X-FACT: the largest publicly available\nmultilingual dataset for factual verification of naturally existing real-world\nclaims. The dataset contains short statements in 25 languages and is labeled\nfor veracity by expert fact-checkers. The dataset includes a multilingual\nevaluation benchmark that measures both out-of-domain generalization, and\nzero-shot capabilities of the multilingual models. Using state-of-the-art\nmultilingual transformer-based models, we develop several automated\nfact-checking models that, along with textual claims, make use of additional\nmetadata and evidence from news stories retrieved using a search engine.\nEmpirically, our best model attains an F-score of around 40%, suggesting that\nour dataset is a challenging benchmark for evaluation of multilingual\nfact-checking models.", "doi": "", "date": "2021-06-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.09248v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2160218133, "title": "Semi-supervised Content-based Detection of Misinformation via Tensor\n  Embeddings", "abstract": "Fake news may be intentionally created to promote economic, political and\nsocial interests, and can lead to negative impacts on humans beliefs and\ndecisions. Hence, detection of fake news is an emerging problem that has become\nextremely prevalent during the last few years. Most existing works on this\ntopic focus on manual feature extraction and supervised classification models\nleveraging a large number of labeled (fake or real) articles. In contrast, we\nfocus on content-based detection of fake news articles, while assuming that we\nhave a small amount of labels, made available by manual fact-checkers or\nautomated sources. We argue this is a more realistic setting in the presence of\nmassive amounts of content, most of which cannot be easily factchecked. To that\nend, we represent collections of news articles as multi-dimensional tensors,\nleverage tensor decomposition to derive concise article embeddings that capture\nspatial/contextual information about each news article, and use those\nembeddings to create an article-by-article graph on which we propagate limited\nlabels. Results on three real-world datasets show that our method performs on\npar or better than existing models that are fully supervised, in that we\nachieve better detection accuracy using fewer labels. In particular, our\nproposed method achieves 75.43% of accuracy using only 30% of labels of a\npublic dataset while an SVM-based classifier achieved 67.43%. Furthermore, our\nmethod achieves 70.92% of accuracy in a large dataset using only 2% of labels.", "doi": "", "date": "2018-04-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.09088v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1507900154, "title": "Limiting the Spread of Fake News on Social Media Platforms by Evaluating\n  Users' Trustworthiness", "abstract": "Today's social media platforms enable to spread both authentic and fake news\nvery quickly. Some approaches have been proposed to automatically detect such\n\"fake\" news based on their content, but it is difficult to agree on universal\ncriteria of authenticity (which can be bypassed by adversaries once known).\nBesides, it is obviously impossible to have each news item checked by a human.\n  In this paper, we a mechanism to limit the spread of fake news which is not\nbased on content. It can be implemented as a plugin on a social media platform.\nThe principle is as follows: a team of fact-checkers reviews a small number of\nnews items (the most popular ones), which enables to have an estimation of each\nuser's inclination to share fake news items. Then, using a Bayesian approach,\nwe estimate the trustworthiness of future news items, and treat accordingly\nthose of them that pass a certain \"untrustworthiness\" threshold.\n  We then evaluate the effectiveness and overhead of this technique on a large\nTwitter graph. We show that having a few thousands users exposed to one given\nnews item enables to reach a very precise estimation of its reliability. We\nthus identify more than 99% of fake news items with no false positives. The\nperformance impact is very small: the induced overhead on the 90th percentile\nlatency is less than 3%, and less than 8% on the throughput of user operations.", "doi": "", "date": "2018-08-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.09922v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3699092025, "title": "How to Write Summaries with Patterns? Learning towards Abstractive\n  Summarization through Prototype Editing", "abstract": "Under special circumstances, summaries should conform to a particular style\nwith patterns, such as court judgments and abstracts in academic papers. To\nthis end, the prototype document-summary pairs can be utilized to generate\nbetter summaries. There are two main challenges in this task: (1) the model\nneeds to incorporate learned patterns from the prototype, but (2) should avoid\ncopying contents other than the patternized words---such as irrelevant\nfacts---into the generated summaries. To tackle these challenges, we design a\nmodel named Prototype Editing based Summary Generator (PESG). PESG first learns\nsummary patterns and prototype facts by analyzing the correlation between a\nprototype document and its summary. Prototype facts are then utilized to help\nextract facts from the input document. Next, an editing generator generates new\nsummary based on the summary pattern or extracted facts. Finally, to address\nthe second challenge, a fact checker is used to estimate mutual information\nbetween the input document and generated summary, providing an additional\nsignal for the generator. Extensive experiments conducted on a large-scale\nreal-world text summarization dataset show that PESG achieves the\nstate-of-the-art performance in terms of both automatic metrics and human\nevaluations.", "doi": "", "date": "2019-09-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.08837v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1998847407, "title": "Classification Aware Neural Topic Model and its Application on a New\n  COVID-19 Disinformation Corpus", "abstract": "The explosion of disinformation accompanying the COVID-19 pandemic has\noverloaded fact-checkers and media worldwide, and brought a new major challenge\nto government responses worldwide. Not only is disinformation creating\nconfusion about medical science amongst citizens, but it is also amplifying\ndistrust in policy makers and governments. To help tackle this, we developed\ncomputational methods to categorise COVID-19 disinformation. The COVID-19\ndisinformation categories could be used for a) focusing fact-checking efforts\non the most damaging kinds of COVID-19 disinformation; b) guiding policy makers\nwho are trying to deliver effective public health messages and counter\neffectively COVID-19 disinformation. This paper presents: 1) a corpus\ncontaining what is currently the largest available set of manually annotated\nCOVID-19 disinformation categories; 2) a classification-aware neural topic\nmodel (CANTM) designed for COVID-19 disinformation category classification and\ntopic discovery; 3) an extensive analysis of COVID-19 disinformation categories\nwith respect to time, volume, false type, media type and origin source.", "doi": "10.1371/journal.pone.0247086", "date": "2020-06-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.03354v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1077276239, "title": "Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms", "abstract": "With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.", "doi": "", "date": "2020-07-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.07996v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3930471348, "title": "COSMOS: Catching Out-of-Context Misinformation with Self-Supervised\n  Learning", "abstract": "Despite the recent attention to DeepFakes, one of the most prevalent ways to\nmislead audiences on social media is the use of unaltered images in a new but\nfalse context. To address these challenges and support fact-checkers, we\npropose a new method that automatically detects out-of-context image and text\npairs. Our key insight is to leverage the grounding of image with text to\ndistinguish out-of-context scenarios that cannot be disambiguated with language\nalone. We propose a self-supervised training strategy where we only need a set\nof captioned images. At train time, our method learns to selectively align\nindividual objects in an image with textual claims, without explicit\nsupervision. At test time, we check if both captions correspond to the same\nobject(s) in the image but are semantically different, which allows us to make\nfairly accurate out-of-context predictions. Our method achieves 85%\nout-of-context detection accuracy. To facilitate benchmarking of this task, we\ncreate a large-scale dataset of 200K images with 450K textual captions from a\nvariety of news websites, blogs, and social media posts. The dataset and source\ncode is publicly available at\nhttps://shivangi-aneja.github.io/projects/cosmos/.", "doi": "", "date": "2021-01-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.06278v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2331573915, "title": "REMOD: Relation Extraction for Modeling Online Discourse", "abstract": "The enormous amount of discourse taking place online poses challenges to the\nfunctioning of a civil and informed public sphere. Efforts to standardize\nonline discourse data, such as ClaimReview, are making available a wealth of\nnew data about potentially inaccurate claims, reviewed by third-party\nfact-checkers. These data could help shed light on the nature of online\ndiscourse, the role of political elites in amplifying it, and its implications\nfor the integrity of the online information ecosystem. Unfortunately, the\nsemi-structured nature of much of this data presents significant challenges\nwhen it comes to modeling and reasoning about online discourse. A key challenge\nis relation extraction, which is the task of determining the semantic\nrelationships between named entities in a claim. Here we develop a novel\nsupervised learning method for relation extraction that combines graph\nembedding techniques with path traversal on semantic dependency graphs. Our\napproach is based on the intuitive observation that knowledge of the entities\nalong the path between the subject and object of a triple (e.g.\nWashington,_D.C.}, and United_States_of_America) provides useful information\nthat can be leveraged for extracting its semantic relation (i.e. capitalOf). As\nan example of a potential application of this technique for modeling online\ndiscourse, we show that our method can be integrated into a pipeline to reason\nabout potential misinformation claims.", "doi": "", "date": "2021-02-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.11105v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 785638926, "title": "FaVIQ: FAct Verification from Information-seeking Questions", "abstract": "Despite significant interest in developing general purpose fact checking\nmodels, it is challenging to construct a large-scale fact verification dataset\nwith realistic claims that would occur in the real world. Existing claims are\neither authored by crowdworkers, thereby introducing subtle biases that are\ndifficult to control for, or manually verified by professional fact checkers,\ncausing them to be expensive and limited in scale. In this paper, we construct\na challenging, realistic, and large-scale fact verification dataset called\nFaVIQ, using information-seeking questions posed by real users who do not know\nhow to answer. The ambiguity in information-seeking questions enables\nautomatically constructing true and false claims that reflect confusions arisen\nfrom users (e.g., the year of the movie being filmed vs. being released). Our\nclaims are verified to be natural, contain little lexical bias, and require a\ncomplete understanding of the evidence for verification. Our experiments show\nthat the state-of-the-art models are far from solving our new task. Moreover,\ntraining on our data helps in professional fact-checking, outperforming models\ntrained on the most widely used dataset FEVER or in-domain data by up to 17%\nabsolute. Altogether, our data will serve as a challenging benchmark for\nnatural language understanding and support future progress in professional fact\nchecking.", "doi": "", "date": "2021-07-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.02153v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2037023389, "title": "Accenture at CheckThat! 2021: Interesting claim identification and\n  ranking with contextually sensitive lexical training data augmentation", "abstract": "This paper discusses the approach used by the Accenture Team for CLEF2021\nCheckThat! Lab, Task 1, to identify whether a claim made in social media would\nbe interesting to a wide audience and should be fact-checked. Twitter training\nand test data were provided in English, Arabic, Spanish, Turkish, and\nBulgarian. Claims were to be classified (check-worthy/not check-worthy) and\nranked in priority order for the fact-checker. Our method used deep neural\nnetwork transformer models with contextually sensitive lexical augmentation\napplied on the supplied training datasets to create additional training\nsamples. This augmentation approach improved the performance for all languages.\nOverall, our architecture and data augmentation pipeline produced the best\nsubmitted system for Arabic, and performance scales according to the quantity\nof provided training data for English, Spanish, Turkish, and Bulgarian. This\npaper investigates the deep neural network architectures for each language as\nwell as the provided data to examine why the approach worked so effectively for\nArabic, and discusses additional data augmentation measures that should could\nbe useful to this problem.", "doi": "", "date": "2021-07-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.05684v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}][{"id": 3303717962, "title": "Factoring Fact-Checks - Structured Information Extraction from Fact-Checking Articles.", "abstract": "", "doi": "10.1145/3366423.3380231", "date": "2020", "authors": [{"name": "Shan Jiang", "id-internal": "04/2910", "id-external": ""}, {"name": "Simon Baumgartner", "id-internal": "218/0228", "id-external": ""}, {"name": "Abe Ittycheriah", "id-internal": "72/3792", "id-external": ""}, {"name": "Cong Yu 0001", "id-internal": "58/3771", "id-external": ""}], "url": {"full": "URL#577051", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2965148069, "title": "X-Fact - A New Benchmark Dataset for Multilingual Fact Checking.", "abstract": "", "doi": "10.18653/v1/2021.acl-short.86", "date": "2021", "authors": [{"name": "Ashim Gupta", "id-internal": "238/6405", "id-external": ""}, {"name": "Vivek Srikumar", "id-internal": "37/44", "id-external": ""}], "url": {"full": "URL#125585", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1632559798, "title": "X-FACT - A New Benchmark Dataset for Multilingual Fact Checking.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Ashim Gupta", "id-internal": "238/6405", "id-external": ""}, {"name": "Vivek Srikumar", "id-internal": "37/44", "id-external": ""}], "url": {"full": "URL#225763", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3622821029, "title": "FactCatch - Incremental Pay-as-You-Go Fact Checking with Minimal User Effort.", "abstract": "", "doi": "10.1145/3397271.3401408", "date": "2020", "authors": [{"name": "Thanh Tam Nguyen", "id-internal": "176/9222", "id-external": ""}, {"name": "Matthias Weidlich", "id-internal": "61/267", "id-external": ""}, {"name": "Hongzhi Yin", "id-internal": "04/10606", "id-external": ""}, {"name": "Bolong Zheng", "id-internal": "152/4895", "id-external": ""}, {"name": "Quang Huy Nguyen", "id-internal": "55/8947", "id-external": ""}, {"name": "Quoc Viet Hung Nguyen", "id-internal": "88/302", "id-external": ""}], "url": {"full": "URL#560101", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 489116316, "title": "Automatic Segmentation and tagging of facts in French for automated fact-checking.", "abstract": "", "doi": "10.1109/bigdata.2018.8622168", "date": "2018", "authors": [{"name": "Edouard Ngor Sarr", "id-internal": "217/8580", "id-external": ""}, {"name": "Ousmane Sall", "id-internal": "57/7283", "id-external": ""}, {"name": "Aminata Maiga", "id-internal": "234/3087", "id-external": ""}, {"name": "Lamine Faty", "id-internal": "234/2898", "id-external": ""}, {"name": "Reine Marie Nd\u00e9la Marone", "id-internal": "231/9301", "id-external": ""}], "url": {"full": "URL#1221706", "pdf": ""}, "publisher-venue": "IEEE BigData", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2108442173, "title": "The Copenhagen Team Participation in the Factuality Task of the Competition of Automatic Identification and Verification of Claims in Political Debates of the CLEF-2018 Fact Checking Lab.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Dongsheng Wang", "id-internal": "21/841", "id-external": ""}, {"name": "Jakob Grue Simonsen", "id-internal": "s/JakobGrueSimonsen", "id-external": ""}, {"name": "Birger Larsen", "id-internal": "34/421", "id-external": ""}, {"name": "Christina Lioma", "id-internal": "16/1917", "id-external": ""}], "url": {"full": "URL#1232899", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3718446214, "title": "Toward Automated Fact-Checking - Detecting Check-worthy Factual Claims by ClaimBuster.", "abstract": "", "doi": "10.1145/3097983.3098131", "date": "2017", "authors": [{"name": "Naeemul Hassan", "id-internal": "66/9718", "id-external": ""}, {"name": "Fatma Arslan", "id-internal": "79/5295", "id-external": ""}, {"name": "Chengkai Li", "id-internal": "14/3692", "id-external": ""}, {"name": "Mark Tremayne", "id-internal": "94/8832", "id-external": ""}], "url": {"full": "URL#1668482", "pdf": ""}, "publisher-venue": "KDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2859746629, "title": "Fact-Checking Reasoning System for Fake Review Detection Using Answer Set Programming.", "abstract": "", "doi": "10.3390/a14070190", "date": "2021", "authors": [{"name": "Nour Jnoub", "id-internal": "219/8263", "id-external": ""}, {"name": "Admir Brankovic", "id-internal": "299/6024", "id-external": ""}, {"name": "Wolfgang Klas", "id-internal": "k/WolfgangKlas", "id-external": ""}], "url": {"full": "URL#12016", "pdf": ""}, "publisher-venue": "Algorithms", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2948692322, "title": "\"The coronavirus is a bioweapon\" - classifying coronavirus stories on fact-checking sites.", "abstract": "", "doi": "10.1007/s10588-021-09329-w", "date": "2021", "authors": [{"name": "Lynnette Hui Xian Ng", "id-internal": "277/0683", "id-external": ""}, {"name": "Kathleen M. Carley", "id-internal": "72/6492", "id-external": ""}], "url": {"full": "URL#23537", "pdf": ""}, "publisher-venue": "Comput. Math. Organ. Theory", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1709821144, "title": "An emerging genre of contemporary fact-checking.", "abstract": "", "doi": "10.1108/jd-05-2020-0083", "date": "2021", "authors": {"name": "Amalia Junestr\u00f6m", "id-internal": "245/0251", "id-external": ""}, "url": {"full": "URL#59496", "pdf": ""}, "publisher-venue": "J. Documentation", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3142609170, "title": "Claim Matching Beyond English to Scale Global Fact-Checking.", "abstract": "", "doi": "10.18653/v1/2021.acl-long.347", "date": "2021", "authors": [{"name": "Ashkan Kazemi", "id-internal": "277/9400", "id-external": ""}, {"name": "Kiran Garimella", "id-internal": "117/4298", "id-external": ""}, {"name": "Devin Gaffney", "id-internal": "133/8424", "id-external": ""}, {"name": "Scott A. Hale", "id-internal": "32/10840", "id-external": ""}], "url": {"full": "URL#125691", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2241876044, "title": "A Multi-Level Attention Model for Evidence-Based Fact Checking.", "abstract": "", "doi": "10.18653/v1/2021.findings-acl.217", "date": "2021", "authors": [{"name": "Canasai Kruengkrai", "id-internal": "16/6986", "id-external": ""}, {"name": "Junichi Yamagishi", "id-internal": "87/3979", "id-external": ""}, {"name": "Xin Wang", "id-internal": "10/5630", "id-external": ""}], "url": {"full": "URL#125721", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3115933481, "title": "Strong and Light Baseline Models for Fact-Checking Joint Inference.", "abstract": "", "doi": "10.18653/v1/2021.findings-acl.426", "date": "2021", "authors": [{"name": "Kateryna Tymoshenko", "id-internal": "94/8176", "id-external": ""}, {"name": "Alessandro Moschitti", "id-internal": "54/2140", "id-external": ""}], "url": {"full": "URL#126176", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3889809184, "title": "Partisan Responses to Fact-Checking in Online News Platforms - Evidence from a Political Rumor about the North Korean Leader.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Taeyoung Kang", "id-internal": "216/3229", "id-external": ""}, {"name": "Jaeung Sim", "id-internal": "211/0841", "id-external": ""}], "url": {"full": "URL#163022", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2515595448, "title": "Check Mate - Prioritizing User Generated Multi-Media Content for Fact-Checking.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Tarunima Prabhakar", "id-internal": "124/9022", "id-external": ""}, {"name": "Anushree Gupta", "id-internal": "277/5413", "id-external": ""}, {"name": "Kruttika Nadig", "id-internal": "277/5285", "id-external": ""}, {"name": "Denny George", "id-internal": "277/4970", "id-external": ""}], "url": {"full": "URL#163043", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3664983490, "title": "Multi-Hop Fact Checking of Political Claims.", "abstract": "", "doi": "10.24963/ijcai.2021/536", "date": "2021", "authors": [{"name": "Wojciech Ostrowski", "id-internal": "229/4701", "id-external": ""}, {"name": "Arnav Arora", "id-internal": "274/2742", "id-external": ""}, {"name": "Pepa Atanasova", "id-internal": "224/2054", "id-external": ""}, {"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}], "url": {"full": "URL#163899", "pdf": ""}, "publisher-venue": "IJCAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3658136358, "title": "How Robust are Fact Checking Systems on Colloquial Claims?", "abstract": "", "doi": "10.18653/v1/2021.naacl-main.121", "date": "2021", "authors": [{"name": "Byeongchang Kim 0002", "id-internal": "32/4011-2", "id-external": ""}, {"name": "Hyunwoo Kim", "id-internal": "71/3655", "id-external": ""}, {"name": "Seokhee Hong", "id-internal": "h/SeokHeeHong", "id-external": ""}, {"name": "Gunhee Kim", "id-internal": "45/115", "id-external": ""}], "url": {"full": "URL#173725", "pdf": ""}, "publisher-venue": "NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 449175410, "title": "Towards Few-shot Fact-Checking via Perplexity.", "abstract": "", "doi": "10.18653/v1/2021.naacl-main.158", "date": "2021", "authors": [{"name": "Nayeon Lee", "id-internal": "212/6295", "id-external": ""}, {"name": "Yejin Bang", "id-internal": "261/2805", "id-external": ""}, {"name": "Andrea Madotto", "id-internal": "174/2905", "id-external": ""}, {"name": "Pascale Fung", "id-internal": "29/4187", "id-external": ""}], "url": {"full": "URL#173740", "pdf": ""}, "publisher-venue": "NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1044915489, "title": "Improving Evidence Retrieval for Automated Explainable Fact-Checking.", "abstract": "", "doi": "10.18653/v1/2021.naacl-demos.10", "date": "2021", "authors": [{"name": "Chris Samarinas", "id-internal": "281/9543", "id-external": ""}, {"name": "Wynne Hsu", "id-internal": "h/WynneHsu", "id-external": ""}, {"name": "Mong-Li Lee", "id-internal": "l/MongLiLee", "id-external": ""}], "url": {"full": "URL#173885", "pdf": ""}, "publisher-venue": "NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2598835179, "title": "FACE-KEG - Fact Checking Explained using KnowledgE Graphs.", "abstract": "", "doi": "10.1145/3437963.3441828", "date": "2021", "authors": [{"name": "Nikhita Vedula", "id-internal": "202/3156", "id-external": ""}, {"name": "Srinivasan Parthasarathy 0001", "id-internal": "p/SParathasarathy", "id-external": ""}], "url": {"full": "URL#187363", "pdf": ""}, "publisher-venue": "WSDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1937592338, "title": "An Experimental Study to Understand User Experience and Perception Bias Occurred by Fact-checking Messages.", "abstract": "", "doi": "10.1145/3442381.3450121", "date": "2021", "authors": [{"name": "Sungkyu Park", "id-internal": "118/8915", "id-external": ""}, {"name": "Jamie Yejean Park", "id-internal": "294/1485", "id-external": ""}, {"name": "Hyojin Chin", "id-internal": "199/2815", "id-external": ""}, {"name": "Jeong-han Kang", "id-internal": "202/9948", "id-external": ""}, {"name": "Meeyoung Cha", "id-internal": "57/4924", "id-external": ""}], "url": {"full": "URL#187697", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4096049111, "title": "Self-Supervised Claim Identification for Automated Fact Checking.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Archita Pathak", "id-internal": "245/8637", "id-external": ""}, {"name": "Mohammad Abuzar Shaikh", "id-internal": "232/1845", "id-external": ""}, {"name": "Rohini K. Srihari", "id-internal": "59/6877", "id-external": ""}], "url": {"full": "URL#195676", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1438449397, "title": "Towards Few-Shot Fact-Checking via Perplexity.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Nayeon Lee", "id-internal": "212/6295", "id-external": ""}, {"name": "Yejin Bang", "id-internal": "261/2805", "id-external": ""}, {"name": "Andrea Madotto", "id-internal": "174/2905", "id-external": ""}, {"name": "Madian Khabsa", "id-internal": "87/11087", "id-external": ""}, {"name": "Pascale Fung", "id-internal": "29/4187", "id-external": ""}], "url": {"full": "URL#204726", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2573914083, "title": "Community-Based Fact-Checking on Twitter's Birdwatch Platform.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Nicolas Pr\u00f6llochs", "id-internal": "160/9792", "id-external": ""}, "url": {"full": "URL#211291", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2807834514, "title": "Extractive and Abstractive Explanations for Fact-Checking and Evaluation of News.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Ashkan Kazemi", "id-internal": "277/9400", "id-external": ""}, {"name": "Zehua Li", "id-internal": "210/6698", "id-external": ""}, {"name": "Ver\u00f3nica P\u00e9rez-Rosas", "id-internal": "53/9684", "id-external": ""}, {"name": "Rada Mihalcea", "id-internal": "m/RadaMihalcea", "id-external": ""}], "url": {"full": "URL#213846", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3296137620, "title": "A Knowledge Enhanced Learning and Semantic Composition Model for Multi-Claim Fact Checking.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Shuai Wang", "id-internal": "42/1503", "id-external": ""}, {"name": "Penghui Wei", "id-internal": "132/1369", "id-external": ""}, {"name": "Jiahao Zhao", "id-internal": "237/8222", "id-external": ""}, {"name": "Wenji Mao", "id-internal": "16/2159", "id-external": ""}], "url": {"full": "URL#213891", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2938866338, "title": "AraStance - A Multi-Country and Multi-Domain Dataset of Arabic Stance Detection for Fact Checking.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Tariq Alhindi", "id-internal": "165/6971", "id-external": ""}, {"name": "Amal Alabdulkarim", "id-internal": "194/8707", "id-external": ""}, {"name": "Ali Alshehri", "id-internal": "210/7018", "id-external": ""}, {"name": "Muhammad Abdul-Mageed", "id-internal": "49/9389", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}], "url": {"full": "URL#214096", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1956592320, "title": "WhatTheWikiFact - Fact-Checking Claims Against Wikipedia.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Anton Chernyavskiy", "id-internal": "272/4246", "id-external": ""}, {"name": "Dmitry Ilvovsky", "id-internal": "270/9528", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}], "url": {"full": "URL#215184", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1148682353, "title": "Claim Matching Beyond English to Scale Global Fact-Checking.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Ashkan Kazemi", "id-internal": "277/9400", "id-external": ""}, {"name": "Kiran Garimella", "id-internal": "117/4298", "id-external": ""}, {"name": "Devin Gaffney", "id-internal": "133/8424", "id-external": ""}, {"name": "Scott A. Hale", "id-internal": "32/10840", "id-external": ""}], "url": {"full": "URL#221718", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3683975025, "title": "A Multi-Level Attention Model for Evidence-Based Fact Checking.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Canasai Kruengkrai", "id-internal": "16/6986", "id-external": ""}, {"name": "Junichi Yamagishi", "id-internal": "87/3979", "id-external": ""}, {"name": "Xin Wang", "id-internal": "10/5630", "id-external": ""}], "url": {"full": "URL#221775", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2116223830, "title": "Towards Explainable Fact Checking.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}, "url": {"full": "URL#239228", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 772340961, "title": "A Survey on Automated Fact-Checking.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Zhijiang Guo", "id-internal": "43/6147", "id-external": ""}, {"name": "Michael Sejr Schlichtkrull", "id-internal": "186/7091", "id-external": ""}, {"name": "Andreas Vlachos 0001", "id-internal": "18/1071-1", "id-external": ""}], "url": {"full": "URL#239851", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1470080815, "title": "A Machine-Learning-Based Pipeline Approach to Automated Fact-Checking.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Andreas Hanselowski", "id-internal": "215/6859", "id-external": ""}, "url": {"full": "URL#242732", "pdf": ""}, "publisher-venue": "", "type": "Books and Theses", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4170523134, "title": "Discipline and promote - Building infrastructure and managing algorithms in a \"structured journalism\" project by professional fact-checking groups.", "abstract": "", "doi": "10.1177/1461444819856916", "date": "2020", "authors": [{"name": "Lucas Graves", "id-internal": "177/6931", "id-external": ""}, {"name": "Cw Anderson", "id-internal": "135/9979", "id-external": ""}], "url": {"full": "URL#357441", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2473203531, "title": "Scrutinizer - Fact Checking Statistical Claims.", "abstract": "", "doi": "10.14778/3415478.3415520", "date": "2020", "authors": [{"name": "Georgios Karagiannis", "id-internal": "83/1616", "id-external": ""}, {"name": "Mohammed Saeed 0002", "id-internal": "09/5035-2", "id-external": ""}, {"name": "Paolo Papotti", "id-internal": "p/PaoloPapotti", "id-external": ""}, {"name": "Immanuel Trummer", "id-internal": "85/9079", "id-external": ""}], "url": {"full": "URL#363247", "pdf": ""}, "publisher-venue": "Proc. VLDB Endow.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1126752084, "title": "Generating Fact Checking Explanations.", "abstract": "", "doi": "10.18653/v1/2020.acl-main.656", "date": "2020", "authors": [{"name": "Pepa Atanasova", "id-internal": "224/2054", "id-external": ""}, {"name": "Jakob Grue Simonsen", "id-internal": "s/JakobGrueSimonsen", "id-external": ""}, {"name": "Christina Lioma", "id-internal": "16/1917", "id-external": ""}, {"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}], "url": {"full": "URL#422796", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 121177407, "title": "DeSePtion - Dual Sequence Prediction and Adversarial Examples for Improved Fact-Checking.", "abstract": "", "doi": "10.18653/v1/2020.acl-main.761", "date": "2020", "authors": [{"name": "Christopher Hidey", "id-internal": "184/3749", "id-external": ""}, {"name": "Tuhin Chakrabarty", "id-internal": "227/2812", "id-external": ""}, {"name": "Tariq Alhindi", "id-internal": "165/6971", "id-external": ""}, {"name": "Siddharth Varia", "id-internal": "224/0055", "id-external": ""}, {"name": "Kriste Krstovski", "id-internal": "05/2269", "id-external": ""}, {"name": "Mona T. Diab", "id-internal": "15/4305", "id-external": ""}, {"name": "Smaranda Muresan", "id-internal": "44/70", "id-external": ""}], "url": {"full": "URL#423029", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1046088780, "title": "LogicalFactChecker - Leveraging Logical Operations for Fact Checking with Graph Module Network.", "abstract": "", "doi": "10.18653/v1/2020.acl-main.539", "date": "2020", "authors": [{"name": "Wanjun Zhong", "id-internal": "227/2128", "id-external": ""}, {"name": "Duyu Tang", "id-internal": "135/6318", "id-external": ""}, {"name": "Zhangyin Feng", "id-internal": "222/7948", "id-external": ""}, {"name": "Nan Duan", "id-internal": "30/8160", "id-external": ""}, {"name": "Ming Zhou 0001", "id-internal": "16/1161-1", "id-external": ""}, {"name": "Ming Gong", "id-internal": "34/4521", "id-external": ""}, {"name": "Linjun Shou", "id-internal": "239/5572", "id-external": ""}, {"name": "Daxin Jiang", "id-internal": "77/5094", "id-external": ""}, {"name": "Jiahai Wang", "id-internal": "00/2989", "id-external": ""}, {"name": "Jian Yin 0001", "id-internal": "95/578-1", "id-external": ""}], "url": {"full": "URL#423631", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2791736050, "title": "Reasoning Over Semantic-Level Graph for Fact Checking.", "abstract": "", "doi": "10.18653/v1/2020.acl-main.549", "date": "2020", "authors": [{"name": "Wanjun Zhong", "id-internal": "227/2128", "id-external": ""}, {"name": "Jingjing Xu", "id-internal": "25/624", "id-external": ""}, {"name": "Duyu Tang", "id-internal": "135/6318", "id-external": ""}, {"name": "Zenan Xu", "id-internal": "204/2481", "id-external": ""}, {"name": "Nan Duan", "id-internal": "30/8160", "id-external": ""}, {"name": "Ming Zhou 0001", "id-internal": "16/1161-1", "id-external": ""}, {"name": "Jiahai Wang", "id-internal": "00/2989", "id-external": ""}, {"name": "Jian Yin 0001", "id-internal": "95/578-1", "id-external": ""}], "url": {"full": "URL#423633", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1161360481, "title": "Generating Fact Checking Summaries for Web Claims.", "abstract": "", "doi": "10.18653/v1/2020.wnut-1.12", "date": "2020", "authors": [{"name": "Rahul Mishra", "id-internal": "66/9553", "id-external": ""}, {"name": "Dhruv Gupta", "id-internal": "184/8485", "id-external": ""}, {"name": "Markus Leippold", "id-internal": "53/9476", "id-external": ""}], "url": {"full": "URL#423724", "pdf": ""}, "publisher-venue": "W-NUT@EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3989335021, "title": "Team Buster.ai at CheckThat! 2020 Insights and Recommendations to Improve Fact-Checking.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Mostafa Bouziane", "id-internal": "277/0559", "id-external": ""}, {"name": "Hugo Perrin", "id-internal": "277/0768", "id-external": ""}, {"name": "Aur\u00e9lien Cluzeau", "id-internal": "277/0681", "id-external": ""}, {"name": "Julien Mardas", "id-internal": "277/0820", "id-external": ""}, {"name": "Amine Sadeq", "id-internal": "277/0734", "id-external": ""}], "url": {"full": "URL#446087", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2027857056, "title": "UAICS at CheckThat! 2020 Fact-checking Claim Prioritization.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Ciprian-Gabriel Cusmuliuc", "id-internal": "245/4434", "id-external": ""}, {"name": "Lucia Georgiana Coca", "id-internal": "245/4184", "id-external": ""}, {"name": "Adrian Iftene", "id-internal": "71/3415", "id-external": ""}], "url": {"full": "URL#446104", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3688510930, "title": "UNIPI-NLE at CheckThat!\u00a02020 - Approaching Fact Checking from a Sentence Similarity Perspective Through the Lens of Transformers.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Lucia C. Passaro", "id-internal": "184/8925", "id-external": ""}, {"name": "Alessandro Bondielli", "id-internal": "191/4078", "id-external": ""}, {"name": "Alessandro Lenci", "id-internal": "02/2701", "id-external": ""}, {"name": "Francesco Marcelloni", "id-internal": "38/2999", "id-external": ""}], "url": {"full": "URL#446226", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 762572131, "title": "Accenture at CheckThat!\u00a02020 - If you say so - Post-hoc fact-checking of Claims using Transformer-based Models.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Evan M. Williams", "id-internal": "285/1550", "id-external": ""}, {"name": "Paul Rodrigues 0001", "id-internal": "24/6308-1", "id-external": ""}, {"name": "Valerie Novak", "id-internal": "185/7648", "id-external": ""}], "url": {"full": "URL#446285", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2022933487, "title": "Unsupervised Fact Checking by Counter-Weighted Positive and Negative Evidential Paths in A Knowledge Graph.", "abstract": "", "doi": "10.18653/v1/2020.coling-main.147", "date": "2020", "authors": [{"name": "Jiseong Kim", "id-internal": "47/8789", "id-external": ""}, {"name": "Key-Sun Choi", "id-internal": "97/6969", "id-external": ""}], "url": {"full": "URL#448930", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1704095519, "title": "Explainable Automated Fact-Checking - A Survey.", "abstract": "", "doi": "10.18653/v1/2020.coling-main.474", "date": "2020", "authors": [{"name": "Neema Kotonya", "id-internal": "218/5785", "id-external": ""}, {"name": "Francesca Toni", "id-internal": "t/FrancescaToni", "id-external": ""}], "url": {"full": "URL#448942", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 676511134, "title": "From Data to the Press - Data Management for Journalism and Fact-Checking.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Ioana Manolescu", "id-internal": "m/IoanaManolescu", "id-external": ""}, "url": {"full": "URL#455840", "pdf": ""}, "publisher-venue": "DATA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4013742922, "title": "Watch 'n' Check - Towards a Social Media Monitoring Tool to Assist Fact-Checking Experts.", "abstract": "", "doi": "10.1109/dsaa49011.2020.00085", "date": "2020", "authors": [{"name": "Assunta Cerone", "id-internal": "279/2019", "id-external": ""}, {"name": "Elham Naghizade", "id-internal": "147/2957", "id-external": ""}, {"name": "Falk Scholer", "id-internal": "98/1631", "id-external": ""}, {"name": "Devi Mallal", "id-internal": "279/2244", "id-external": ""}, {"name": "Russell Skelton", "id-internal": "279/2072", "id-external": ""}, {"name": "Damiano Spina", "id-internal": "74/2824", "id-external": ""}], "url": {"full": "URL#458459", "pdf": ""}, "publisher-venue": "DSAA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1914365831, "title": "Towards IoT-driven Process Event Log Generation for Conformance Checking in Smart Factories.", "abstract": "", "doi": "10.1109/edocw49879.2020.00016", "date": "2020", "authors": [{"name": "Ronny Seiger", "id-internal": "13/10444", "id-external": ""}, {"name": "Francesca Zerbato", "id-internal": "159/9133", "id-external": ""}, {"name": "Andrea Burattin", "id-internal": "81/8569", "id-external": ""}, {"name": "Luciano Garc\u00eda-Ba\u00f1uelos", "id-internal": "19/2137", "id-external": ""}, {"name": "Barbara Weber", "id-internal": "96/2864", "id-external": ""}], "url": {"full": "URL#462975", "pdf": ""}, "publisher-venue": "EDOC Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1773426271, "title": "Generating Fact Checking Briefs.", "abstract": "", "doi": "10.18653/v1/2020.emnlp-main.580", "date": "2020", "authors": [{"name": "Angela Fan", "id-internal": "192/1872", "id-external": ""}, {"name": "Aleksandra Piktus", "id-internal": "241/7090", "id-external": ""}, {"name": "Fabio Petroni", "id-internal": "118/5349", "id-external": ""}, {"name": "Guillaume Wenzek", "id-internal": "169/3295", "id-external": ""}, {"name": "Marzieh Saeidi", "id-internal": "136/9320", "id-external": ""}, {"name": "Andreas Vlachos 0001", "id-internal": "18/1071-1", "id-external": ""}, {"name": "Antoine Bordes", "id-internal": "49/4572", "id-external": ""}, {"name": "Sebastian Riedel 0001", "id-internal": "18/3348-1", "id-external": ""}], "url": {"full": "URL#465690", "pdf": ""}, "publisher-venue": "EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 846468723, "title": "Explainable Automated Fact-Checking for Public Health Claims.", "abstract": "", "doi": "10.18653/v1/2020.emnlp-main.623", "date": "2020", "authors": [{"name": "Neema Kotonya", "id-internal": "218/5785", "id-external": ""}, {"name": "Francesca Toni", "id-internal": "t/FrancescaToni", "id-external": ""}], "url": {"full": "URL#465955", "pdf": ""}, "publisher-venue": "EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2506283154, "title": "AnswerFact - Fact Checking in Product Question Answering.", "abstract": "", "doi": "10.18653/v1/2020.emnlp-main.188", "date": "2020", "authors": [{"name": "Wenxuan Zhang", "id-internal": "85/1177", "id-external": ""}, {"name": "Yang Deng 0002", "id-internal": "115/6282-2", "id-external": ""}, {"name": "Jing Ma", "id-internal": "96/6129", "id-external": ""}, {"name": "Wai Lam", "id-internal": "48/1707", "id-external": ""}], "url": {"full": "URL#466660", "pdf": ""}, "publisher-venue": "EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1942898405, "title": "A Novel Algorithm Checking for the Line Layout in a Factory.", "abstract": "", "doi": "10.1109/gcce50665.2020.9291720", "date": "2020", "authors": [{"name": "Yuki Suzuki", "id-internal": "97/3307", "id-external": ""}, {"name": "Wataru Uemura", "id-internal": "84/7595", "id-external": ""}], "url": {"full": "URL#473924", "pdf": ""}, "publisher-venue": "GCCE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 23914629, "title": "Self-Supervised Claim Identification for Automated Fact Checking.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Archita Pathak", "id-internal": "245/8637", "id-external": ""}, {"name": "Mohammad Abuzar Shaikh", "id-internal": "232/1845", "id-external": ""}, {"name": "Rohini K. Srihari", "id-internal": "59/6877", "id-external": ""}], "url": {"full": "URL#501988", "pdf": ""}, "publisher-venue": "ICON", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2016771187, "title": "Latent Retrieval for Large-Scale Fact-Checking and Question Answering with NLI training.", "abstract": "", "doi": "10.1109/ictai50040.2020.00147", "date": "2020", "authors": [{"name": "Chris Samarinas", "id-internal": "281/9543", "id-external": ""}, {"name": "Wynne Hsu", "id-internal": "h/WynneHsu", "id-external": ""}, {"name": "Mong-Li Lee", "id-internal": "l/MongLiLee", "id-external": ""}], "url": {"full": "URL#508404", "pdf": ""}, "publisher-venue": "ICTAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1910908001, "title": "A KG-based Enhancement Framework for Fact Checking Using Category Information.", "abstract": "", "doi": "10.1109/isi49825.2020.9280520", "date": "2020", "authors": [{"name": "Shuai Wang", "id-internal": "42/1503", "id-external": ""}, {"name": "Lei Wang", "id-internal": "181/2817", "id-external": ""}, {"name": "Wenji Mao", "id-internal": "16/2159", "id-external": ""}], "url": {"full": "URL#525695", "pdf": ""}, "publisher-venue": "ISI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3212195415, "title": "Cracking Tabular Presentation Diversity for Automatic Cross-Checking over Numerical Facts.", "abstract": "", "doi": "10.1145/3394486.3403310", "date": "2020", "authors": [{"name": "Hongwei Li 0002", "id-internal": "39/5544-2", "id-external": ""}, {"name": "Qingping Yang", "id-internal": "20/9644", "id-external": ""}, {"name": "Yixuan Cao", "id-internal": "217/4359", "id-external": ""}, {"name": "Jiaquan Yao", "id-internal": "217/4548", "id-external": ""}, {"name": "Ping Luo 0001", "id-internal": "54/4989-1", "id-external": ""}], "url": {"full": "URL#532857", "pdf": ""}, "publisher-venue": "KDD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 330440286, "title": "Automated Fact-Checking of Claims from Wikipedia.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Aalok Sathe", "id-internal": "266/1129", "id-external": ""}, {"name": "Salar Ather", "id-internal": "266/0747", "id-external": ""}, {"name": "Tuan Manh Le", "id-internal": "266/1059", "id-external": ""}, {"name": "Nathan Perry", "id-internal": "38/8807", "id-external": ""}, {"name": "Joonsuk Park", "id-internal": "50/9717", "id-external": ""}], "url": {"full": "URL#536228", "pdf": ""}, "publisher-venue": "LREC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2021987532, "title": "Fact-Checking for Portuguese - Knowledge Graph and Google Search-Based Methods.", "abstract": "", "doi": "10.1007/978-3-030-41505-1_19", "date": "2020", "authors": [{"name": "Roney Lira de Sales Santos", "id-internal": "189/4600", "id-external": ""}, {"name": "Thiago Alexandre Salgueiro Pardo", "id-internal": "31/4118", "id-external": ""}], "url": {"full": "URL#552300", "pdf": ""}, "publisher-venue": "PROPOR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1587416775, "title": "Fact-checking via Path Embedding and Aggregation.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Giuseppe Pirr\u00f2", "id-internal": "50/96", "id-external": ""}, "url": {"full": "URL#557843", "pdf": ""}, "publisher-venue": "ASLD@ISWC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 782220655, "title": "Factuality Checking in News Headlines with Eye Tracking.", "abstract": "", "doi": "10.1145/3397271.3401221", "date": "2020", "authors": [{"name": "Christian Hansen 0004", "id-internal": "57/2217-4", "id-external": ""}, {"name": "Casper Hansen", "id-internal": "205/2958", "id-external": ""}, {"name": "Jakob Grue Simonsen", "id-internal": "s/JakobGrueSimonsen", "id-external": ""}, {"name": "Birger Larsen", "id-internal": "34/421", "id-external": ""}, {"name": "Stephen Alstrup", "id-internal": "49/4269", "id-external": ""}, {"name": "Christina Lioma", "id-internal": "16/1917", "id-external": ""}], "url": {"full": "URL#559885", "pdf": ""}, "publisher-venue": "SIGIR", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1684396006, "title": "e-FEVER - Explanations and Summaries forAutomated Fact Checking.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Dominik Stammbach", "id-internal": "242/4666", "id-external": ""}, {"name": "Elliott Ash", "id-internal": "271/7737", "id-external": ""}], "url": {"full": "URL#568678", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3345371633, "title": "Comparing Audience Appreciation to Fact-Checking Across Political Communities on Reddit.", "abstract": "", "doi": "10.1145/3394231.3397904", "date": "2020", "authors": [{"name": "Deven Parekh", "id-internal": "161/0423", "id-external": ""}, {"name": "Drew Margolin", "id-internal": "126/1980", "id-external": ""}, {"name": "Derek Ruths", "id-internal": "70/10689", "id-external": ""}], "url": {"full": "URL#574579", "pdf": ""}, "publisher-venue": "WebSci", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3070951438, "title": "Attributed Multi-Relational Attention Network for Fact-checking URL Recommendation.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Di You", "id-internal": "83/8652", "id-external": ""}, {"name": "Nguyen Vo", "id-internal": "167/0323", "id-external": ""}, {"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}, {"name": "Qiang Liu", "id-internal": "61/3234", "id-external": ""}], "url": {"full": "URL#583193", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1319721245, "title": "Debate Dynamics for Human-comprehensible Fact-checking on Knowledge Graphs.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Marcel Hildebrandt", "id-internal": "220/3522", "id-external": ""}, {"name": "Jorge Andres Quintero Serna", "id-internal": "256/1053", "id-external": ""}, {"name": "Yunpu Ma", "id-internal": "199/8143", "id-external": ""}, {"name": "Martin Ringsquandl", "id-internal": "134/3518", "id-external": ""}, {"name": "Mitchell Joblin", "id-internal": "167/0200", "id-external": ""}, {"name": "Volker Tresp", "id-internal": "t/VolkerTresp", "id-external": ""}], "url": {"full": "URL#583596", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3869476739, "title": "Generating Fact Checking Explanations.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Pepa Atanasova", "id-internal": "224/2054", "id-external": ""}, {"name": "Jakob Grue Simonsen", "id-internal": "s/JakobGrueSimonsen", "id-external": ""}, {"name": "Christina Lioma", "id-internal": "16/1917", "id-external": ""}, {"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}], "url": {"full": "URL#599775", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1007082093, "title": "DeSePtion - Dual Sequence Prediction and Adversarial Examples for Improved Fact-Checking.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Christopher Hidey", "id-internal": "184/3749", "id-external": ""}, {"name": "Tuhin Chakrabarty", "id-internal": "227/2812", "id-external": ""}, {"name": "Tariq Alhindi", "id-internal": "165/6971", "id-external": ""}, {"name": "Siddharth Varia", "id-internal": "224/0055", "id-external": ""}, {"name": "Kriste Krstovski", "id-internal": "05/2269", "id-external": ""}, {"name": "Mona T. Diab", "id-internal": "15/4305", "id-external": ""}, {"name": "Smaranda Muresan", "id-internal": "44/70", "id-external": ""}], "url": {"full": "URL#602556", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 522669135, "title": "LogicalFactChecker - Leveraging Logical Operations for Fact Checking with Graph Module Network.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Wanjun Zhong", "id-internal": "227/2128", "id-external": ""}, {"name": "Duyu Tang", "id-internal": "135/6318", "id-external": ""}, {"name": "Zhangyin Feng", "id-internal": "222/7948", "id-external": ""}, {"name": "Nan Duan", "id-internal": "30/8160", "id-external": ""}, {"name": "Ming Zhou 0001", "id-internal": "16/1161-1", "id-external": ""}, {"name": "Ming Gong", "id-internal": "34/4521", "id-external": ""}, {"name": "Linjun Shou", "id-internal": "239/5572", "id-external": ""}, {"name": "Daxin Jiang", "id-internal": "77/5094", "id-external": ""}, {"name": "Jiahai Wang", "id-internal": "00/2989", "id-external": ""}, {"name": "Jian Yin 0001", "id-internal": "95/578-1", "id-external": ""}], "url": {"full": "URL#602878", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3651054122, "title": "Factuality Checking in News Headlines with Eye Tracking.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Christian Hansen 0004", "id-internal": "57/2217-4", "id-external": ""}, {"name": "Casper Hansen", "id-internal": "205/2958", "id-external": ""}, {"name": "Jakob Grue Simonsen", "id-internal": "s/JakobGrueSimonsen", "id-external": ""}, {"name": "Birger Larsen", "id-internal": "34/421", "id-external": ""}, {"name": "Stephen Alstrup", "id-internal": "49/4269", "id-external": ""}, {"name": "Christina Lioma", "id-internal": "16/1917", "id-external": ""}], "url": {"full": "URL#613276", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1995114232, "title": "Accenture at CheckThat! 2020 - If you say so - Post-hoc fact-checking of claims using transformer-based models.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Evan M. Williams", "id-internal": "285/1550", "id-external": ""}, {"name": "Paul Rodrigues 0001", "id-internal": "24/6308-1", "id-external": ""}, {"name": "Valerie Novak", "id-internal": "185/7648", "id-external": ""}], "url": {"full": "URL#629010", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 722195937, "title": "Multi-Hop Fact Checking of Political Claims.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Wojciech Ostrowski", "id-internal": "229/4701", "id-external": ""}, {"name": "Arnav Arora", "id-internal": "274/2742", "id-external": ""}, {"name": "Pepa Atanasova", "id-internal": "224/2054", "id-external": ""}, {"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}], "url": {"full": "URL#630458", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 639031479, "title": "Time-Aware Evidence Ranking for Fact-Checking.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Liesbeth Allein", "id-internal": "256/1719", "id-external": ""}, {"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}, {"name": "Marie-Francine Moens", "id-internal": "m/MarieFrancineMoens", "id-external": ""}], "url": {"full": "URL#630459", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1611924024, "title": "Generating Fact Checking Summaries for Web Claims.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Rahul Mishra", "id-internal": "66/9553", "id-external": ""}, {"name": "Dhruv Gupta", "id-internal": "184/8485", "id-external": ""}, {"name": "Markus Leippold", "id-internal": "53/9476", "id-external": ""}], "url": {"full": "URL#637515", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3185561778, "title": "Explainable Automated Fact-Checking for Public Health Claims.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Neema Kotonya", "id-internal": "218/5785", "id-external": ""}, {"name": "Francesca Toni", "id-internal": "t/FrancescaToni", "id-external": ""}], "url": {"full": "URL#638142", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2234899891, "title": "Fact-Checking at Scale with DimensionRank.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Gregory Coppola", "id-internal": "266/1473", "id-external": ""}, "url": {"full": "URL#638459", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2371609217, "title": "Check Mate - Prioritizing User Generated Multi-Media Content for Fact-Checking.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Anushree Gupta", "id-internal": "277/5413", "id-external": ""}, {"name": "Denny George", "id-internal": "277/4970", "id-external": ""}, {"name": "Kruttika Nadig", "id-internal": "277/5285", "id-external": ""}, {"name": "Tarunima Prabhakar", "id-internal": "124/9022", "id-external": ""}], "url": {"full": "URL#639841", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1122265484, "title": "Explainable Automated Fact-Checking - A Survey.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Neema Kotonya", "id-internal": "218/5785", "id-external": ""}, {"name": "Francesca Toni", "id-internal": "t/FrancescaToni", "id-external": ""}], "url": {"full": "URL#642762", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 89079536, "title": "Generating Fact Checking Briefs.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Angela Fan", "id-internal": "192/1872", "id-external": ""}, {"name": "Aleksandra Piktus", "id-internal": "241/7090", "id-external": ""}, {"name": "Fabio Petroni", "id-internal": "118/5349", "id-external": ""}, {"name": "Guillaume Wenzek", "id-internal": "169/3295", "id-external": ""}, {"name": "Marzieh Saeidi", "id-internal": "136/9320", "id-external": ""}, {"name": "Andreas Vlachos 0001", "id-internal": "18/1071-1", "id-external": ""}, {"name": "Antoine Bordes", "id-internal": "49/4572", "id-external": ""}, {"name": "Sebastian Riedel 0001", "id-internal": "18/3348-1", "id-external": ""}], "url": {"full": "URL#643431", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 560677492, "title": "Fact Checking via Path Embedding and Aggregation.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Giuseppe Pirr\u00f2", "id-internal": "50/96", "id-external": ""}, "url": {"full": "URL#644517", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1781565745, "title": "Checking Fact Worthiness using Sentence Embeddings.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Sidharth Singla", "id-internal": "281/7404", "id-external": ""}, "url": {"full": "URL#651134", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 880753910, "title": "Joint Verification and Reranking for Open Fact Checking Over Tables.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Michael Sejr Schlichtkrull", "id-internal": "186/7091", "id-external": ""}, {"name": "Vladimir Karpukhin", "id-internal": "236/4633", "id-external": ""}, {"name": "Barlas Oguz", "id-internal": "69/9892", "id-external": ""}, {"name": "Mike Lewis", "id-internal": "19/6214", "id-external": ""}, {"name": "Wen-tau Yih", "id-internal": "07/7129", "id-external": ""}, {"name": "Sebastian Riedel 0001", "id-internal": "18/3348-1", "id-external": ""}], "url": {"full": "URL#653318", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 194756411, "title": "Automating the Fact-Checking Task - Challenges and Directions.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Diego Nascimento Esteves da Silva", "id-internal": "252/6620", "id-external": ""}, "url": {"full": "URL#657427", "pdf": ""}, "publisher-venue": "", "type": "Books and Theses", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 793934808, "title": "Vers une v\u00e9rification automatique des affirmations statistiques. (Toward Automatic Fact-Checking of Statistic Claims).", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Tien Duc Cao", "id-internal": "185/4294", "id-external": ""}, "url": {"full": "URL#658191", "pdf": ""}, "publisher-venue": "", "type": "Books and Theses", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4264784819, "title": "Contribution aux m\u00e9canismes d'automatisation du fact-checking pour un journalisme augment\u00e9.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Edouard Ngor Sarr", "id-internal": "217/8580", "id-external": ""}, "url": {"full": "URL#658998", "pdf": ""}, "publisher-venue": "", "type": "Books and Theses", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2325322106, "title": "Fact-checking strategies to limit urban legends spreading in a segregated society.", "abstract": "", "doi": "10.1007/s41109-019-0233-1", "date": "2019", "authors": [{"name": "Marcella Tambuscio", "id-internal": "162/8994", "id-external": ""}, {"name": "Giancarlo Ruffo", "id-internal": "05/4635", "id-external": ""}], "url": {"full": "URL#679498", "pdf": ""}, "publisher-venue": "Appl. Netw. Sci.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 422010092, "title": "Towards an automation of the fact-checking in the journalistic web context.", "abstract": "", "doi": "10.1504/ijbdi.2019.100906", "date": "2019", "authors": [{"name": "Edouard Ngor Sarr", "id-internal": "217/8580", "id-external": ""}, {"name": "Ousmane Sall", "id-internal": "57/7283", "id-external": ""}, {"name": "Aminata Maiga", "id-internal": "234/3087", "id-external": ""}, {"name": "Mouhamadou Saliou Diallo", "id-internal": "117/7929", "id-external": ""}], "url": {"full": "URL#720305", "pdf": ""}, "publisher-venue": "Int. J. Big Data Intell.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1599937277, "title": "Discovering Patterns for Fact Checking in Knowledge Graphs.", "abstract": "", "doi": "10.1145/3286488", "date": "2019", "authors": [{"name": "Peng Lin", "id-internal": "43/5433", "id-external": ""}, {"name": "Qi Song", "id-internal": "82/5132", "id-external": ""}, {"name": "Yinghui Wu", "id-internal": "32/6122", "id-external": ""}, {"name": "Jiaxing Pi", "id-internal": "138/8544", "id-external": ""}], "url": {"full": "URL#744466", "pdf": ""}, "publisher-venue": "ACM J. Data Inf. Qual.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3361173360, "title": "Buckle - Evaluating Fact Checking Algorithms Built on Knowledge Bases.", "abstract": "", "doi": "10.14778/3352063.3352069", "date": "2019", "authors": [{"name": "Viet-Phi Huynh", "id-internal": "218/0760", "id-external": ""}, {"name": "Paolo Papotti", "id-internal": "p/PaoloPapotti", "id-external": ""}], "url": {"full": "URL#772098", "pdf": ""}, "publisher-venue": "Proc. VLDB Endow.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2899152486, "title": "AggChecker - A Fact-Checking System for Text Summaries of Relational Data Sets.", "abstract": "", "doi": "10.14778/3352063.3352104", "date": "2019", "authors": [{"name": "Saehan Jo", "id-internal": "211/2846", "id-external": ""}, {"name": "Immanuel Trummer", "id-internal": "85/9079", "id-external": ""}, {"name": "Weicheng Yu", "id-internal": "218/6701", "id-external": ""}, {"name": "Xuezhi Wang 0002", "id-internal": "70/4090-2", "id-external": ""}, {"name": "Cong Yu 0001", "id-internal": "58/3771", "id-external": ""}, {"name": "Daniel Liu", "id-internal": "174/2261", "id-external": ""}, {"name": "Niyati Mehta", "id-internal": "218/5932", "id-external": ""}], "url": {"full": "URL#772101", "pdf": ""}, "publisher-venue": "Proc. VLDB Endow.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2474150782, "title": "Mining an \"Anti-Knowledge Base\" from Wikipedia Updates with Applications to Fact Checking and Beyond.", "abstract": "", "doi": "10.14778/3372716.3372727", "date": "2019", "authors": [{"name": "Georgios Karagiannis", "id-internal": "83/1616", "id-external": ""}, {"name": "Immanuel Trummer", "id-internal": "85/9079", "id-external": ""}, {"name": "Saehan Jo", "id-internal": "211/2846", "id-external": ""}, {"name": "Shubham Khandelwal", "id-internal": "137/8081", "id-external": ""}, {"name": "Xuezhi Wang 0002", "id-internal": "70/4090-2", "id-external": ""}, {"name": "Cong Yu 0001", "id-internal": "58/3771", "id-external": ""}], "url": {"full": "URL#772108", "pdf": ""}, "publisher-venue": "Proc. VLDB Endow.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3586134912, "title": "User Guidance for Efficient Fact Checking.", "abstract": "", "doi": "10.14778/3324301.3324303", "date": "2019", "authors": [{"name": "Thanh Tam Nguyen", "id-internal": "176/9222", "id-external": ""}, {"name": "Hongzhi Yin", "id-internal": "04/10606", "id-external": ""}, {"name": "Matthias Weidlich", "id-internal": "61/267", "id-external": ""}, {"name": "Bolong Zheng", "id-internal": "152/4895", "id-external": ""}, {"name": "Quoc Viet Hung Nguyen", "id-internal": "88/302", "id-external": ""}, {"name": "Bela Stantic", "id-internal": "74/1636", "id-external": ""}], "url": {"full": "URL#772155", "pdf": ""}, "publisher-venue": "Proc. VLDB Endow.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3879908131, "title": "Selecting Data to Clean for Fact Checking - Minimizing Uncertainty vs. Maximizing Surprise.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Stavros Sintos", "id-internal": "151/3111", "id-external": ""}, {"name": "Pankaj K. Agarwal", "id-internal": "a/PankajKAgarwal", "id-external": ""}, {"name": "Jun Yang 0001", "id-internal": "y/JunYang1", "id-external": ""}], "url": {"full": "URL#772187", "pdf": ""}, "publisher-venue": "Proc. VLDB Endow.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1087031378, "title": "ClaimPortal - Integrated Monitoring, Searching, Checking, and Analytics of Factual Claims on Twitter.", "abstract": "", "doi": "10.18653/v1/p19-3026", "date": "2019", "authors": [{"name": "Sarthak Majithia", "id-internal": "245/9492", "id-external": ""}, {"name": "Fatma Arslan", "id-internal": "79/5295", "id-external": ""}, {"name": "Sumeet Lubal", "id-internal": "245/9433", "id-external": ""}, {"name": "Damian Jimenez", "id-internal": "204/3605", "id-external": ""}, {"name": "Priyank Arora", "id-internal": "245/9464", "id-external": ""}, {"name": "Josue Caraballo", "id-internal": "204/3742", "id-external": ""}, {"name": "Chengkai Li", "id-internal": "14/3692", "id-external": ""}], "url": {"full": "URL#821884", "pdf": ""}, "publisher-venue": "ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 906678166, "title": "Physiological Indicators for User Trust in Machine Learning with Influence Enhanced Fact-Checking.", "abstract": "", "doi": "10.1007/978-3-030-29726-8_7", "date": "2019", "authors": [{"name": "Jianlong Zhou", "id-internal": "03/4147", "id-external": ""}, {"name": "Huaiwen Hu", "id-internal": "239/9253", "id-external": ""}, {"name": "Zhidong Li", "id-internal": "10/6710", "id-external": ""}, {"name": "Kun Yu", "id-internal": "51/4486", "id-external": ""}, {"name": "Fang Chen 0001", "id-internal": "52/488-1", "id-external": ""}], "url": {"full": "URL#844540", "pdf": ""}, "publisher-venue": "CD-MAKE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2477228523, "title": "A Benchmark for Fact Checking Algorithms Built on Knowledge Bases.", "abstract": "", "doi": "10.1145/3357384.3358036", "date": "2019", "authors": [{"name": "Viet-Phi Huynh", "id-internal": "218/0760", "id-external": ""}, {"name": "Paolo Papotti", "id-internal": "p/PaoloPapotti", "id-external": ""}], "url": {"full": "URL#847829", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 610438917, "title": "Attributed Multi-Relational Attention Network for Fact-checking URL Recommendation.", "abstract": "", "doi": "10.1145/3357384.3358006", "date": "2019", "authors": [{"name": "Di You", "id-internal": "83/8652", "id-external": ""}, {"name": "Nguyen Vo", "id-internal": "167/0323", "id-external": ""}, {"name": "Kyumin Lee", "id-internal": "22/8024", "id-external": ""}, {"name": "Qiang Liu", "id-internal": "61/3234", "id-external": ""}], "url": {"full": "URL#848055", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1578117766, "title": "A Richly Annotated Corpus for Different Tasks in Automated Fact-Checking.", "abstract": "", "doi": "10.18653/v1/k19-1046", "date": "2019", "authors": [{"name": "Andreas Hanselowski", "id-internal": "215/6859", "id-external": ""}, {"name": "Christian Stab", "id-internal": "15/8383", "id-external": ""}, {"name": "Claudia Schulz 0001", "id-internal": "125/4725-1", "id-external": ""}, {"name": "Zile Li", "id-internal": "227/3473", "id-external": ""}, {"name": "Iryna Gurevych", "id-internal": "85/6201", "id-external": ""}], "url": {"full": "URL#853356", "pdf": ""}, "publisher-venue": "CoNLL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 424686381, "title": "Towards Fact-Checking through Crowdsourcing.", "abstract": "", "doi": "10.1109/cscwd.2019.8791903", "date": "2019", "authors": [{"name": "Marcos Rodrigues Pinto", "id-internal": "223/7161", "id-external": ""}, {"name": "Yuri Oliveira de Lima", "id-internal": "207/1265", "id-external": ""}, {"name": "Carlos Eduardo Barbosa", "id-internal": "00/2509", "id-external": ""}, {"name": "Jano Moreira de Souza", "id-internal": "m/JMoreiradeSouza", "id-external": ""}], "url": {"full": "URL#855078", "pdf": ""}, "publisher-venue": "CSCWD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 537369755, "title": "MultiFC - A Real-World Multi-Domain Dataset for Evidence-Based Fact Checking of Claims.", "abstract": "", "doi": "10.18653/v1/d19-1475", "date": "2019", "authors": [{"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}, {"name": "Christina Lioma", "id-internal": "16/1917", "id-external": ""}, {"name": "Dongsheng Wang", "id-internal": "21/841", "id-external": ""}, {"name": "Lucas Chaves Lima", "id-internal": "238/0439", "id-external": ""}, {"name": "Casper Hansen", "id-internal": "205/2958", "id-external": ""}, {"name": "Christian Hansen 0004", "id-internal": "57/2217-4", "id-external": ""}, {"name": "Jakob Grue Simonsen", "id-internal": "s/JakobGrueSimonsen", "id-external": ""}], "url": {"full": "URL#867866", "pdf": ""}, "publisher-venue": "EMNLP/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1150578492, "title": "Fact-Checking Meets Fauxtography - Verifying Claims About Images.", "abstract": "", "doi": "10.18653/v1/d19-1216", "date": "2019", "authors": [{"name": "Dimitrina Zlatkova", "id-internal": "220/0888", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Ivan Koychev", "id-internal": "88/2617", "id-external": ""}], "url": {"full": "URL#868629", "pdf": ""}, "publisher-venue": "EMNLP/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3303184169, "title": "Computational fact-checking - state of the art, challenges, and perspectives.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Ioana Manolescu", "id-internal": "m/IoanaManolescu", "id-external": ""}, "url": {"full": "URL#873682", "pdf": ""}, "publisher-venue": "EGC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2132463688, "title": "Analyzing Biases in Perception of Truth in News Stories and Their Implications for Fact Checking.", "abstract": "", "doi": "10.1145/3287560.3287581", "date": "2019", "authors": [{"name": "Mahmoudreza Babaei", "id-internal": "48/10293", "id-external": ""}, {"name": "Abhijnan Chakraborty", "id-internal": "116/1678", "id-external": ""}, {"name": "Juhi Kulshrestha", "id-internal": "73/10042", "id-external": ""}, {"name": "Elissa M. Redmiles", "id-internal": "141/9244", "id-external": ""}, {"name": "Meeyoung Cha", "id-internal": "57/4924", "id-external": ""}, {"name": "Krishna P. Gummadi", "id-internal": "g/PKrishnaGummadi", "id-external": ""}], "url": {"full": "URL#873881", "pdf": ""}, "publisher-venue": "FAT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 808903781, "title": "WhatsApp Monitor - A Fact-Checking System for WhatsApp.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Philipe F. Melo", "id-internal": "210/0839", "id-external": ""}, {"name": "Johnnatan Messias", "id-internal": "139/9735", "id-external": ""}, {"name": "Gustavo Resende", "id-internal": "227/0558", "id-external": ""}, {"name": "Kiran Garimella", "id-internal": "117/4298", "id-external": ""}, {"name": "Jussara M. Almeida", "id-internal": "34/5480", "id-external": ""}, {"name": "Fabr\u00edcio Benevenuto", "id-internal": "90/2878", "id-external": ""}], "url": {"full": "URL#917617", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1407186477, "title": "FAKTA - An Automatic End-to-End Fact Checking System.", "abstract": "", "doi": "10.18653/v1/n19-4014", "date": "2019", "authors": [{"name": "Moin Nadeem", "id-internal": "183/6394", "id-external": ""}, {"name": "Wei Fang", "id-internal": "48/2709", "id-external": ""}, {"name": "Brian Xu", "id-internal": "20/443", "id-external": ""}, {"name": "Mitra Mohtarami", "id-internal": "77/7405", "id-external": ""}, {"name": "James R. Glass", "id-internal": "37/6580", "id-external": ""}], "url": {"full": "URL#956916", "pdf": ""}, "publisher-venue": "NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4118564411, "title": "Machine Learning Approach to Fact-Checking in West Slavic Languages.", "abstract": "", "doi": "10.26615/978-954-452-056-4_113", "date": "2019", "authors": [{"name": "Pavel Prib\u00e1n", "id-internal": "220/0890", "id-external": ""}, {"name": "Tom\u00e1s Hercig", "id-internal": "149/0897", "id-external": ""}, {"name": "Josef Steinberger", "id-internal": "63/5814", "id-external": ""}], "url": {"full": "URL#967268", "pdf": ""}, "publisher-venue": "RANLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1421385296, "title": "CodeForTheChange at SemEval-2019 Task 8 - Skip-Thoughts for Fact Checking in Community Question Answering.", "abstract": "", "doi": "10.18653/v1/s19-2199", "date": "2019", "authors": [{"name": "Adithya Avvaru", "id-internal": "230/7978", "id-external": ""}, {"name": "Anupam Pandey", "id-internal": "242/4739", "id-external": ""}], "url": {"full": "URL#973343", "pdf": ""}, "publisher-venue": "SemEval@NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3454085806, "title": "TueFact at SemEval 2019 Task 8 - Fact checking in community question answering forums - context matters.", "abstract": "", "doi": "10.18653/v1/s19-2206", "date": "2019", "authors": [{"name": "R\u00e9ka Juh\u00e1sz", "id-internal": "242/4822", "id-external": ""}, {"name": "Franziska Barbara Linnenschmidt", "id-internal": "242/4622", "id-external": ""}, {"name": "Teslin Roys", "id-internal": "242/4638", "id-external": ""}], "url": {"full": "URL#973412", "pdf": ""}, "publisher-venue": "SemEval@NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2753600002, "title": "YNU-HPCC at SemEval-2019 Task 8 - Using A LSTM-Attention Model for Fact-Checking in Community Forums.", "abstract": "", "doi": "10.18653/v1/s19-2207", "date": "2019", "authors": [{"name": "Peng Liu", "id-internal": "21/6121", "id-external": ""}, {"name": "Jin Wang 0008", "id-internal": "92/1375-8", "id-external": ""}, {"name": "Xuejie Zhang 0002", "id-internal": "68/3522-2", "id-external": ""}], "url": {"full": "URL#973432", "pdf": ""}, "publisher-venue": "SemEval@NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1190183068, "title": "AUTOHOME-ORCA at SemEval-2019 Task 8 - Application of BERT for Fact-Checking in Community Forums.", "abstract": "", "doi": "10.18653/v1/s19-2150", "date": "2019", "authors": [{"name": "Zhengwei Lv", "id-internal": "242/4779", "id-external": ""}, {"name": "Duoxing Liu", "id-internal": "219/5031", "id-external": ""}, {"name": "Haifeng Sun", "id-internal": "00/11044", "id-external": ""}, {"name": "Xiao Liang", "id-internal": "06/4676", "id-external": ""}, {"name": "Tao Lei", "id-internal": "91/8024", "id-external": ""}, {"name": "Zhizhong Shi", "id-internal": "242/4684", "id-external": ""}, {"name": "Feng Zhu", "id-internal": "71/2791", "id-external": ""}, {"name": "Lei Yang", "id-internal": "50/2484", "id-external": ""}], "url": {"full": "URL#973434", "pdf": ""}, "publisher-venue": "SemEval@NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4063489813, "title": "SemEval-2019 Task 8 - Fact Checking in Community Question Answering Forums.", "abstract": "", "doi": "10.18653/v1/s19-2149", "date": "2019", "authors": [{"name": "Tsvetomila Mihaylova", "id-internal": "184/2078", "id-external": ""}, {"name": "Georgi Karadzhov", "id-internal": "205/1966", "id-external": ""}, {"name": "Pepa Atanasova", "id-internal": "224/2054", "id-external": ""}, {"name": "Ramy Baly", "id-internal": "187/7326", "id-external": ""}, {"name": "Mitra Mohtarami", "id-internal": "77/7405", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}], "url": {"full": "URL#973443", "pdf": ""}, "publisher-venue": "SemEval@NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3150007060, "title": "TMLab SRPOL at SemEval-2019 Task 8 - Fact Checking in Community Question Answering Forums.", "abstract": "", "doi": "10.18653/v1/s19-2205", "date": "2019", "authors": [{"name": "Piotr Niewinski", "id-internal": "242/4806", "id-external": ""}, {"name": "Aleksander Wawer", "id-internal": "62/3540", "id-external": ""}, {"name": "Maria Pszona", "id-internal": "242/4612", "id-external": ""}, {"name": "Maria Janicka", "id-internal": "242/4672", "id-external": ""}], "url": {"full": "URL#973456", "pdf": ""}, "publisher-venue": "SemEval@NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3551470496, "title": "DOMLIN at SemEval-2019 Task 8 - Automated Fact Checking exploiting Ratings in Community Question Answering Forums.", "abstract": "", "doi": "10.18653/v1/s19-2201", "date": "2019", "authors": [{"name": "Dominik Stammbach", "id-internal": "242/4666", "id-external": ""}, {"name": "Stalin Varanasi", "id-internal": "178/5984", "id-external": ""}, {"name": "Guenter Neumann", "id-internal": "94/2519", "id-external": ""}], "url": {"full": "URL#973514", "pdf": ""}, "publisher-venue": "SemEval@NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 951464443, "title": "BLCU_NLP at SemEval-2019 Task 8 - A Contextual Knowledge-enhanced GPT Model for Fact Checking.", "abstract": "", "doi": "10.18653/v1/s19-2198", "date": "2019", "authors": [{"name": "Wanying Xie", "id-internal": "231/7316", "id-external": ""}, {"name": "Mengxi Que", "id-internal": "242/4680", "id-external": ""}, {"name": "Ruoyao Yang", "id-internal": "224/5672", "id-external": ""}, {"name": "Chunhua Liu", "id-internal": "68/4756", "id-external": ""}, {"name": "Dong Yu 0003", "id-internal": "71/4598-3", "id-external": ""}], "url": {"full": "URL#973533", "pdf": ""}, "publisher-venue": "SemEval@NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2051690871, "title": "An Automated Fact Checking System Using Deep Learning Through Word Embedding.", "abstract": "", "doi": "10.1109/ssci44817.2019.9002783", "date": "2019", "authors": [{"name": "Peiyi Wang", "id-internal": "236/6569", "id-external": ""}, {"name": "Lixia Deng", "id-internal": "71/10183", "id-external": ""}, {"name": "Xiujun Wu", "id-internal": "71/9809", "id-external": ""}], "url": {"full": "URL#981636", "pdf": ""}, "publisher-venue": "SSCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 724105454, "title": "Explainable Fact Checking with Probabilistic Answer Set Programming.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Naser Ahmadi", "id-internal": "243/3322", "id-external": ""}, {"name": "Joohyung Lee", "id-internal": "15/4797", "id-external": ""}, {"name": "Paolo Papotti", "id-internal": "p/PaoloPapotti", "id-external": ""}, {"name": "Mohammed Saeed 0002", "id-internal": "09/5035-2", "id-external": ""}], "url": {"full": "URL#985238", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1689502726, "title": "Metafact.io - Expert fact-checking at scale using the scientific method.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Ben McNeil", "id-internal": "277/6449", "id-external": ""}, "url": {"full": "URL#985250", "pdf": ""}, "publisher-venue": "TTO", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 976229823, "title": "Neural Check-Worthiness Ranking with Weak Supervision - Finding Sentences for Fact-Checking.", "abstract": "", "doi": "10.1145/3308560.3316736", "date": "2019", "authors": [{"name": "Casper Hansen", "id-internal": "205/2958", "id-external": ""}, {"name": "Christian Hansen 0004", "id-internal": "57/2217-4", "id-external": ""}, {"name": "Stephen Alstrup", "id-internal": "49/4269", "id-external": ""}, {"name": "Jakob Grue Simonsen", "id-internal": "s/JakobGrueSimonsen", "id-external": ""}, {"name": "Christina Lioma", "id-internal": "16/1917", "id-external": ""}], "url": {"full": "URL#995393", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 295020085, "title": "Examining the Roles of Automation, Crowds and Professionals Towards Sustainable Fact-checking.", "abstract": "", "doi": "10.1145/3308560.3316734", "date": "2019", "authors": [{"name": "Naeemul Hassan", "id-internal": "66/9718", "id-external": ""}, {"name": "Mohammad Yousuf", "id-internal": "198/1367", "id-external": ""}, {"name": "Md Mahfuzul Haque", "id-internal": "230/3595", "id-external": ""}, {"name": "Javier A. Suarez Rivas", "id-internal": "240/9043", "id-external": ""}, {"name": "Md Khadimul Islam", "id-internal": "230/3779", "id-external": ""}], "url": {"full": "URL#995396", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2246711704, "title": "Automated Fact Checking in the News Room.", "abstract": "", "doi": "10.1145/3308558.3314135", "date": "2019", "authors": [{"name": "Sebasti\u00e3o Miranda", "id-internal": "204/1212", "id-external": ""}, {"name": "David Nogueira", "id-internal": "151/8311", "id-external": ""}, {"name": "Afonso Mendes", "id-internal": "18/3562", "id-external": ""}, {"name": "Andreas Vlachos 0001", "id-internal": "18/1071-1", "id-external": ""}, {"name": "Andrew Secker", "id-internal": "97/4613", "id-external": ""}, {"name": "Rebecca Garrett", "id-internal": "239/4082", "id-external": ""}, {"name": "Jeff Mitchell", "id-internal": "28/8160", "id-external": ""}, {"name": "Zita Marinho", "id-internal": "175/1420", "id-external": ""}], "url": {"full": "URL#995557", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 529092921, "title": "Neural Check-Worthiness Ranking with Weak Supervision - Finding Sentences for Fact-Checking.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Casper Hansen", "id-internal": "205/2958", "id-external": ""}, {"name": "Christian Hansen 0004", "id-internal": "57/2217-4", "id-external": ""}, {"name": "Stephen Alstrup", "id-internal": "49/4269", "id-external": ""}, {"name": "Jakob Grue Simonsen", "id-internal": "s/JakobGrueSimonsen", "id-external": ""}, {"name": "Christina Lioma", "id-internal": "16/1917", "id-external": ""}], "url": {"full": "URL#1012119", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2330183967, "title": "Automated Fact Checking in the News Room.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Sebasti\u00e3o Miranda", "id-internal": "204/1212", "id-external": ""}, {"name": "David Nogueira", "id-internal": "151/8311", "id-external": ""}, {"name": "Afonso Mendes", "id-internal": "18/3562", "id-external": ""}, {"name": "Andreas Vlachos 0001", "id-internal": "18/1071-1", "id-external": ""}, {"name": "Andrew Secker", "id-internal": "97/4613", "id-external": ""}, {"name": "Rebecca Garrett", "id-internal": "239/4082", "id-external": ""}, {"name": "Jeff Mitchell", "id-internal": "28/8160", "id-external": ""}, {"name": "Zita Marinho", "id-internal": "175/1420", "id-external": ""}], "url": {"full": "URL#1014087", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1278562491, "title": "TMLab SRPOL at SemEval-2019 Task 8 - Fact Checking in Community Question Answering Forums.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Piotr Niewinski", "id-internal": "242/4806", "id-external": ""}, {"name": "Aleksander Wawer", "id-internal": "62/3540", "id-external": ""}, {"name": "Maria Pszona", "id-internal": "242/4612", "id-external": ""}, {"name": "Maria Janicka", "id-internal": "242/4672", "id-external": ""}], "url": {"full": "URL#1023682", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 137685307, "title": "SemEval-2019 Task 8 - Fact Checking in Community Question Answering Forums.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Tsvetomila Mihaylova", "id-internal": "184/2078", "id-external": ""}, {"name": "Georgi Karadjov", "id-internal": "205/1966", "id-external": ""}, {"name": "Pepa Atanasova", "id-internal": "224/2054", "id-external": ""}, {"name": "Ramy Baly", "id-internal": "187/7326", "id-external": ""}, {"name": "Mitra Mohtarami", "id-internal": "77/7405", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}], "url": {"full": "URL#1023778", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1295682647, "title": "FAKTA - An Automatic End-to-End Fact Checking System.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Moin Nadeem", "id-internal": "183/6394", "id-external": ""}, {"name": "Wei Fang", "id-internal": "48/2709", "id-external": ""}, {"name": "Brian Xu", "id-internal": "20/443", "id-external": ""}, {"name": "Mitra Mohtarami", "id-internal": "77/7405", "id-external": ""}, {"name": "James R. Glass", "id-internal": "37/6580", "id-external": ""}], "url": {"full": "URL#1024747", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 339406281, "title": "Explainable Fact Checking with Probabilistic Answer Set Programming.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Naser Ahmadi", "id-internal": "243/3322", "id-external": ""}, {"name": "Joohyung Lee", "id-internal": "15/4797", "id-external": ""}, {"name": "Paolo Papotti", "id-internal": "p/PaoloPapotti", "id-external": ""}, {"name": "Mohammed Saeed 0002", "id-internal": "09/5035-2", "id-external": ""}], "url": {"full": "URL#1026634", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2547462340, "title": "CobWeb - A Research Prototype for Exploring User Bias in Political Fact-Checking.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Anubrata Das 0001", "id-internal": "166/0983-1", "id-external": ""}, {"name": "Kunjan Mehta", "id-internal": "245/0245", "id-external": ""}, {"name": "Matthew Lease", "id-internal": "29/239", "id-external": ""}], "url": {"full": "URL#1029179", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 103438341, "title": "Automatic Fact-Checking Using Context and Discourse Information.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Pepa Atanasova", "id-internal": "224/2054", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Llu\u00eds M\u00e0rquez", "id-internal": "62/3", "id-external": ""}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o", "id-internal": "40/3383", "id-external": ""}, {"name": "Georgi Karadzhov", "id-internal": "205/1966", "id-external": ""}, {"name": "Tsvetomila Mihaylova", "id-internal": "184/2078", "id-external": ""}, {"name": "Mitra Mohtarami", "id-internal": "77/7405", "id-external": ""}, {"name": "James R. Glass", "id-internal": "37/6580", "id-external": ""}], "url": {"full": "URL#1033088", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3456267134, "title": "Fact-Checking Meets Fauxtography - Verifying Claims About Images.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Dimitrina Zlatkova", "id-internal": "220/0888", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Ivan Koychev", "id-internal": "88/2617", "id-external": ""}], "url": {"full": "URL#1036745", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3276799662, "title": "MultiFC - A Real-World Multi-Domain Dataset for Evidence-Based Fact Checking of Claims.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Isabelle Augenstein", "id-internal": "93/11424", "id-external": ""}, {"name": "Christina Lioma", "id-internal": "16/1917", "id-external": ""}, {"name": "Dongsheng Wang", "id-internal": "21/841", "id-external": ""}, {"name": "Lucas Chaves Lima", "id-internal": "238/0439", "id-external": ""}, {"name": "Casper Hansen", "id-internal": "205/2958", "id-external": ""}, {"name": "Christian Hansen 0004", "id-internal": "57/2217-4", "id-external": ""}, {"name": "Jakob Grue Simonsen", "id-internal": "s/JakobGrueSimonsen", "id-external": ""}], "url": {"full": "URL#1037974", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1153356958, "title": "Reasoning Over Semantic-Level Graph for Fact Checking.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Wanjun Zhong", "id-internal": "227/2128", "id-external": ""}, {"name": "Jingjing Xu", "id-internal": "25/624", "id-external": ""}, {"name": "Duyu Tang", "id-internal": "135/6318", "id-external": ""}, {"name": "Zenan Xu", "id-internal": "204/2481", "id-external": ""}, {"name": "Nan Duan", "id-internal": "30/8160", "id-external": ""}, {"name": "Ming Zhou 0001", "id-internal": "16/1161-1", "id-external": ""}, {"name": "Jiahai Wang", "id-internal": "00/2989", "id-external": ""}, {"name": "Jian Yin 0001", "id-internal": "95/578-1", "id-external": ""}], "url": {"full": "URL#1038208", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 569425311, "title": "Selecting Data to Clean for Fact Checking - Minimizing Uncertainty vs. Maximizing Surprise.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Stavros Sintos", "id-internal": "151/3111", "id-external": ""}, {"name": "Pankaj K. Agarwal", "id-internal": "a/PankajKAgarwal", "id-external": ""}, {"name": "Jun Yang 0001", "id-internal": "y/JunYang1", "id-external": ""}], "url": {"full": "URL#1038826", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4244154714, "title": "Unsupervised Question Answering for Fact-Checking.", "abstract": "", "doi": "", "date": "2019", "authors": {"name": "Mayank Jobanputra", "id-internal": "220/8952", "id-external": ""}, "url": {"full": "URL#1044581", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3687545844, "title": "A Richly Annotated Corpus for Different Tasks in Automated Fact-Checking.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Andreas Hanselowski", "id-internal": "215/6859", "id-external": ""}, {"name": "Christian Stab", "id-internal": "15/8383", "id-external": ""}, {"name": "Claudia Schulz 0001", "id-internal": "125/4725-1", "id-external": ""}, {"name": "Zile Li", "id-internal": "227/3473", "id-external": ""}, {"name": "Iryna Gurevych", "id-internal": "85/6201", "id-external": ""}], "url": {"full": "URL#1047823", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3539500896, "title": "Fact Checking in Knowledge Graphs with Ontological Subgraph Patterns.", "abstract": "", "doi": "10.1007/s41019-018-0082-4", "date": "2018", "authors": [{"name": "Peng Lin", "id-internal": "43/5433", "id-external": ""}, {"name": "Qi Song", "id-internal": "82/5132", "id-external": ""}, {"name": "Yinghui Wu", "id-internal": "32/6122", "id-external": ""}], "url": {"full": "URL#1095928", "pdf": ""}, "publisher-venue": "Data Sci. Eng.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 526731206, "title": "Query Perturbation Analysis - An Adventure of Database Researchers in Fact-Checking.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Jun Yang 0001", "id-internal": "y/JunYang1", "id-external": ""}, {"name": "Pankaj K. Agarwal", "id-internal": "a/PankajKAgarwal", "id-external": ""}, {"name": "Sudeepa Roy", "id-internal": "77/4620", "id-external": ""}, {"name": "Brett Walenz", "id-internal": "98/8877", "id-external": ""}, {"name": "You Wu 0001", "id-internal": "16/8675-1", "id-external": ""}, {"name": "Cong Yu 0001", "id-internal": "58/3771", "id-external": ""}, {"name": "Chengkai Li", "id-internal": "14/3692", "id-external": ""}], "url": {"full": "URL#1096398", "pdf": ""}, "publisher-venue": "IEEE Data Eng. Bull.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1334948408, "title": "Deciding what's true - The rise of political fact-checking in American journalism.", "abstract": "", "doi": "10.1177/1461444818795694", "date": "2018", "authors": {"name": "Rachel E. Moran", "id-internal": "233/4937", "id-external": ""}, "url": {"full": "URL#1157384", "pdf": ""}, "publisher-venue": "New Media Soc.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3481982566, "title": "Computational fact-checking - a content management perspective.", "abstract": "", "doi": "10.14778/3229863.3229880", "date": "2018", "authors": [{"name": "Sylvie Cazalens", "id-internal": "53/6030", "id-external": ""}, {"name": "Julien Leblay", "id-internal": "35/8398", "id-external": ""}, {"name": "Ioana Manolescu", "id-internal": "m/IoanaManolescu", "id-external": ""}, {"name": "Philippe Lamarre", "id-internal": "59/5146", "id-external": ""}, {"name": "Xavier Tannier", "id-internal": "83/4811", "id-external": ""}], "url": {"full": "URL#1162316", "pdf": ""}, "publisher-venue": "Proc. VLDB Endow.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3153279741, "title": "A case study of planning for smart factories - Model checking and Monte Carlo search for the rescue.", "abstract": "", "doi": "10.1007/s10009-018-0498-1", "date": "2018", "authors": [{"name": "Stefan Edelkamp", "id-internal": "98/3919", "id-external": ""}, {"name": "Christoph Greulich", "id-internal": "133/2653", "id-external": ""}], "url": {"full": "URL#1179238", "pdf": ""}, "publisher-venue": "Int. J. Softw. Tools Technol. Transf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2491591660, "title": "Fact Checking in Community Forums.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Tsvetomila Mihaylova", "id-internal": "184/2078", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Llu\u00eds M\u00e0rquez", "id-internal": "62/3", "id-external": ""}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o", "id-internal": "40/3383", "id-external": ""}, {"name": "Mitra Mohtarami", "id-internal": "77/7405", "id-external": ""}, {"name": "Georgi Karadzhov", "id-internal": "205/1966", "id-external": ""}, {"name": "James R. Glass", "id-internal": "37/6580", "id-external": ""}], "url": {"full": "URL#1206396", "pdf": ""}, "publisher-venue": "AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3367859770, "title": "An Interpretable Joint Graphical Model for Fact-Checking From Crowds.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "An T. Nguyen 0001", "id-internal": "181/2304-1", "id-external": ""}, {"name": "Aditya Kharosekar", "id-internal": "218/6982", "id-external": ""}, {"name": "Matthew Lease", "id-internal": "29/239", "id-external": ""}, {"name": "Byron C. Wallace", "id-internal": "00/8247", "id-external": ""}], "url": {"full": "URL#1206429", "pdf": ""}, "publisher-venue": "AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1259930397, "title": "Automated Fact Checking.", "abstract": "", "doi": "", "date": "2018", "authors": {"name": "Andreas Vlachos 0001", "id-internal": "18/1071-1", "id-external": ""}, "url": {"full": "URL#1231667", "pdf": ""}, "publisher-venue": "CIKM Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3078681120, "title": "Re-ranking Web Search Results for Better Fact-Checking - A Preliminary Study.", "abstract": "", "doi": "10.1145/3269206.3269288", "date": "2018", "authors": [{"name": "Khaled Yasser", "id-internal": "168/0236", "id-external": ""}, {"name": "M\u00fccahid Kutlu", "id-internal": "27/7658", "id-external": ""}, {"name": "Tamer Elsayed", "id-internal": "99/5856", "id-external": ""}], "url": {"full": "URL#1231711", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 513311643, "title": "Automated Fact Checking - Task Formulations, Methods and Future Directions.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "James Thorne", "id-internal": "204/1380", "id-external": ""}, {"name": "Andreas Vlachos 0001", "id-internal": "18/1071-1", "id-external": ""}], "url": {"full": "URL#1235456", "pdf": ""}, "publisher-venue": "COLING", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 275149313, "title": "Discovering Graph Patterns for Fact Checking in Knowledge Graphs.", "abstract": "", "doi": "10.1007/978-3-319-91452-7_50", "date": "2018", "authors": [{"name": "Peng Lin", "id-internal": "43/5433", "id-external": ""}, {"name": "Qi Song", "id-internal": "82/5132", "id-external": ""}, {"name": "Jialiang Shen", "id-internal": "179/8961", "id-external": ""}, {"name": "Yinghui Wu", "id-internal": "32/6122", "id-external": ""}], "url": {"full": "URL#1241666", "pdf": ""}, "publisher-venue": "DASFAA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4222624799, "title": "Fact Checking and Information Retrieval.", "abstract": "", "doi": "", "date": "2018", "authors": {"name": "Matthew Lease", "id-internal": "29/239", "id-external": ""}, "url": {"full": "URL#1242818", "pdf": ""}, "publisher-venue": "DESIRES", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 279076171, "title": "Improving Large-Scale Fact-Checking using Decomposable Attention Models and Lexical Tagging.", "abstract": "", "doi": "10.18653/v1/d18-1143", "date": "2018", "authors": [{"name": "Nayeon Lee", "id-internal": "212/6295", "id-external": ""}, {"name": "Chien-Sheng Wu", "id-internal": "180/5537", "id-external": ""}, {"name": "Pascale Fung", "id-internal": "29/4187", "id-external": ""}], "url": {"full": "URL#1251735", "pdf": ""}, "publisher-venue": "EMNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 678116636, "title": "Towards Computational Fact-Checking - Is the information checkable?", "abstract": "", "doi": "10.1109/fuzz-ieee.2018.8491486", "date": "2018", "authors": [{"name": "Hugo Farinha", "id-internal": "228/3057", "id-external": ""}, {"name": "Jo\u00e3o P. Carvalho 0001", "id-internal": "98/4980", "id-external": ""}], "url": {"full": "URL#1259543", "pdf": ""}, "publisher-venue": "FUZZ-IEEE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 70914581, "title": "Extinguishing the Backfire Effect - Using Emotions in Online Social Collaborative Argumentation for Fact Checking.", "abstract": "", "doi": "10.1109/icws.2018.00062", "date": "2018", "authors": [{"name": "Ricky J. Sethi", "id-internal": "69/8616", "id-external": ""}, {"name": "Raghuram Rangaraju", "id-internal": "226/0935", "id-external": ""}], "url": {"full": "URL#1296965", "pdf": ""}, "publisher-venue": "ICWS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2195581315, "title": "Fact Checking from Natural Text with Probabilistic Soft Logic.", "abstract": "", "doi": "10.1007/978-3-030-01768-2_5", "date": "2018", "authors": [{"name": "Nouf Bindris", "id-internal": "227/6041", "id-external": ""}, {"name": "Saatviga Sudhahar", "id-internal": "61/7958", "id-external": ""}, {"name": "Nello Cristianini", "id-internal": "11/4380", "id-external": ""}], "url": {"full": "URL#1297240", "pdf": ""}, "publisher-venue": "IDA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2553669061, "title": "Fact Checking via Evidence Patterns.", "abstract": "", "doi": "10.24963/ijcai.2018/522", "date": "2018", "authors": [{"name": "Valeria Fionda", "id-internal": "43/3753", "id-external": ""}, {"name": "Giuseppe Pirr\u00f2", "id-internal": "50/96", "id-external": ""}], "url": {"full": "URL#1303836", "pdf": ""}, "publisher-venue": "IJCAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1530569526, "title": "Integrating Stance Detection and Fact Checking in a Unified Corpus.", "abstract": "", "doi": "10.18653/v1/n18-2004", "date": "2018", "authors": [{"name": "Ramy Baly", "id-internal": "187/7326", "id-external": ""}, {"name": "Mitra Mohtarami", "id-internal": "77/7405", "id-external": ""}, {"name": "James R. Glass", "id-internal": "37/6580", "id-external": ""}, {"name": "Llu\u00eds M\u00e0rquez", "id-internal": "62/3", "id-external": ""}, {"name": "Alessandro Moschitti", "id-internal": "54/2140", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}], "url": {"full": "URL#1334081", "pdf": ""}, "publisher-venue": "NAACL-HLT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2403874883, "title": "SnVera - A New Algorithm for Automation of Fact-Checking in Web Journalism Context.", "abstract": "", "doi": "10.1109/snams.2018.8554696", "date": "2018", "authors": [{"name": "Edouard Ngor Sarr", "id-internal": "217/8580", "id-external": ""}, {"name": "Ousmane Sall", "id-internal": "57/7283", "id-external": ""}, {"name": "Aminata Diallo", "id-internal": "231/2757", "id-external": ""}], "url": {"full": "URL#1356268", "pdf": ""}, "publisher-venue": "SNAMS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4294100363, "title": "Believe it or not - Designing a Human-AI Partnership for Mixed-Initiative Fact-Checking.", "abstract": "", "doi": "10.1145/3242587.3242666", "date": "2018", "authors": [{"name": "An T. Nguyen 0001", "id-internal": "181/2304-1", "id-external": ""}, {"name": "Aditya Kharosekar", "id-internal": "218/6982", "id-external": ""}, {"name": "Saumyaa Krishnan", "id-internal": "227/7982", "id-external": ""}, {"name": "Siddhesh Krishnan", "id-internal": "227/7997", "id-external": ""}, {"name": "Elizabeth Tate", "id-internal": "227/8011", "id-external": ""}, {"name": "Byron C. Wallace", "id-internal": "00/8247", "id-external": ""}, {"name": "Matthew Lease", "id-internal": "29/239", "id-external": ""}], "url": {"full": "URL#1363728", "pdf": ""}, "publisher-venue": "UIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1192335470, "title": "Truth or Lie - Automatically Fact Checking News.", "abstract": "", "doi": "10.1145/3184558.3186567", "date": "2018", "authors": {"name": "Lucas Azevedo", "id-internal": "215/3319", "id-external": ""}, "url": {"full": "URL#1372757", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4008368262, "title": "A Content Management Perspective on Fact-Checking.", "abstract": "", "doi": "10.1145/3184558.3188727", "date": "2018", "authors": [{"name": "Sylvie Cazalens", "id-internal": "53/6030", "id-external": ""}, {"name": "Philippe Lamarre", "id-internal": "59/5146", "id-external": ""}, {"name": "Julien Leblay", "id-internal": "35/8398", "id-external": ""}, {"name": "Ioana Manolescu", "id-internal": "m/IoanaManolescu", "id-external": ""}, {"name": "Xavier Tannier", "id-internal": "83/4811", "id-external": ""}], "url": {"full": "URL#1372802", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1663109726, "title": "Towards a Benchmark for Fact Checking with Knowledge Bases.", "abstract": "", "doi": "10.1145/3184558.3191616", "date": "2018", "authors": [{"name": "Viet-Phi Huynh", "id-internal": "218/0760", "id-external": ""}, {"name": "Paolo Papotti", "id-internal": "p/PaoloPapotti", "id-external": ""}], "url": {"full": "URL#1372931", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1699236812, "title": "Relevant Document Discovery for Fact-Checking Articles.", "abstract": "", "doi": "10.1145/3184558.3188723", "date": "2018", "authors": [{"name": "Xuezhi Wang 0002", "id-internal": "70/4090-2", "id-external": ""}, {"name": "Cong Yu 0001", "id-internal": "58/3771", "id-external": ""}, {"name": "Simon Baumgartner", "id-internal": "218/0228", "id-external": ""}, {"name": "Flip Korn", "id-internal": "k/FlipKorn", "id-external": ""}], "url": {"full": "URL#1373237", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1630133852, "title": "Fact Checking in Community Forums.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Tsvetomila Mihaylova", "id-internal": "184/2078", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Llu\u00eds M\u00e0rquez", "id-internal": "62/3", "id-external": ""}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o", "id-internal": "40/3383", "id-external": ""}, {"name": "Mitra Mohtarami", "id-internal": "77/7405", "id-external": ""}, {"name": "Georgi Karadzhov", "id-internal": "205/1966", "id-external": ""}, {"name": "James R. Glass", "id-internal": "37/6580", "id-external": ""}], "url": {"full": "URL#1387985", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 456799989, "title": "Integrating Stance Detection and Fact Checking in a Unified Corpus.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Ramy Baly", "id-internal": "187/7326", "id-external": ""}, {"name": "Mitra Mohtarami", "id-internal": "77/7405", "id-external": ""}, {"name": "James R. Glass", "id-internal": "37/6580", "id-external": ""}, {"name": "Llu\u00eds M\u00e0rquez", "id-internal": "62/3", "id-external": ""}, {"name": "Alessandro Moschitti", "id-internal": "54/2140", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}], "url": {"full": "URL#1392798", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3582642030, "title": "Automated Fact Checking - Task formulations, methods and future directions.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "James Thorne", "id-internal": "204/1380", "id-external": ""}, {"name": "Andreas Vlachos 0001", "id-internal": "18/1071-1", "id-external": ""}], "url": {"full": "URL#1400005", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 585877392, "title": "Fact-checking Initiatives in Bangladesh, India, and Nepal - A Study of User Engagement and Challenges.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Md Mahfuzul Haque", "id-internal": "230/3595", "id-external": ""}, {"name": "Mohammad Yousuf", "id-internal": "198/1367", "id-external": ""}, {"name": "Zahedur Arman", "id-internal": "230/3519", "id-external": ""}, {"name": "Md Main Uddin Rony", "id-internal": "198/0599", "id-external": ""}, {"name": "Ahmed Shatil Alam", "id-internal": "230/3449", "id-external": ""}, {"name": "Kazi Mehedi Hasan", "id-internal": "46/11052", "id-external": ""}, {"name": "Md Khadimul Islam", "id-internal": "230/3779", "id-external": ""}, {"name": "Naeemul Hassan", "id-internal": "66/9718", "id-external": ""}], "url": {"full": "URL#1415536", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1036119160, "title": "Uni-DUE Student Team - Tackling fact checking through decomposable attention neural network.", "abstract": "", "doi": "", "date": "2018", "authors": [{"name": "Jan Kowollik", "id-internal": "232/3040", "id-external": ""}, {"name": "Ahmet Aker", "id-internal": "67/7965", "id-external": ""}], "url": {"full": "URL#1422151", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2922437855, "title": "Trust and distrust in online fact-checking services.", "abstract": "", "doi": "10.1145/3122803", "date": "2017", "authors": [{"name": "Petter Bae Brandtz\u00e6g", "id-internal": "95/625", "id-external": ""}, {"name": "Asbj\u00f8rn F\u00f8lstad", "id-internal": "68/1088", "id-external": ""}], "url": {"full": "URL#1441105", "pdf": ""}, "publisher-venue": "Commun. ACM", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3130077822, "title": "ClaimBuster - The First-ever End-to-end Fact-checking System.", "abstract": "", "doi": "10.14778/3137765.3137815", "date": "2017", "authors": [{"name": "Naeemul Hassan", "id-internal": "66/9718", "id-external": ""}, {"name": "Gensheng Zhang", "id-internal": "137/7229", "id-external": ""}, {"name": "Fatma Arslan", "id-internal": "79/5295", "id-external": ""}, {"name": "Josue Caraballo", "id-internal": "204/3742", "id-external": ""}, {"name": "Damian Jimenez", "id-internal": "204/3605", "id-external": ""}, {"name": "Siddhant Gawsane", "id-internal": "204/3590", "id-external": ""}, {"name": "Shohedul Hasan", "id-internal": "204/3637", "id-external": ""}, {"name": "Minumol Joseph", "id-internal": "204/3694", "id-external": ""}, {"name": "Aaditya Kulkarni", "id-internal": "204/3654", "id-external": ""}, {"name": "Anil Kumar Nayak", "id-internal": "204/3728", "id-external": ""}, {"name": "Vikas Sable", "id-internal": "204/3741", "id-external": ""}, {"name": "Chengkai Li", "id-internal": "14/3692", "id-external": ""}, {"name": "Mark Tremayne", "id-internal": "94/8832", "id-external": ""}], "url": {"full": "URL#1517852", "pdf": ""}, "publisher-venue": "Proc. VLDB Endow.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 361084060, "title": "Computational Fact Checking through Query Perturbations.", "abstract": "", "doi": "10.1145/2996453", "date": "2017", "authors": [{"name": "You Wu 0001", "id-internal": "16/8675-1", "id-external": ""}, {"name": "Pankaj K. Agarwal", "id-internal": "a/PankajKAgarwal", "id-external": ""}, {"name": "Chengkai Li", "id-internal": "14/3692", "id-external": ""}, {"name": "Jun Yang 0001", "id-internal": "y/JunYang1", "id-external": ""}, {"name": "Cong Yu 0001", "id-internal": "58/3771", "id-external": ""}], "url": {"full": "URL#1545354", "pdf": ""}, "publisher-venue": "ACM Trans. Database Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2384337408, "title": "A Declarative Approach to Data-Driven Fact Checking.", "abstract": "", "doi": "", "date": "2017", "authors": {"name": "Julien Leblay", "id-internal": "35/8398", "id-external": ""}, "url": {"full": "URL#1555875", "pdf": ""}, "publisher-venue": "AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 46654, "title": "Automation of Fact-Checking - State of the Art, Obstacles and Perspectives.", "abstract": "", "doi": "10.1109/dasc-picom-datacom-cyberscitec.2017.212", "date": "2017", "authors": [{"name": "Edouard Ngor Sarr", "id-internal": "217/8580", "id-external": ""}, {"name": "Ousmane Sall", "id-internal": "57/7283", "id-external": ""}], "url": {"full": "URL#1591302", "pdf": ""}, "publisher-venue": "DASC/PiCom/DataCom/CyberSciTech", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4216243001, "title": "Fact-Checking via Structured Discussions in Virtual Communities.", "abstract": "", "doi": "", "date": "2017", "authors": {"name": "Ricky J. Sethi", "id-internal": "69/8616", "id-external": ""}, "url": {"full": "URL#1615599", "pdf": ""}, "publisher-venue": "HT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3487495486, "title": "Finding Streams in Knowledge Graphs to Support Fact Checking.", "abstract": "", "doi": "10.1109/icdm.2017.105", "date": "2017", "authors": [{"name": "Prashant Shiralkar", "id-internal": "157/8398", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}, {"name": "Giovanni Luca Ciampaglia", "id-internal": "07/8400", "id-external": ""}], "url": {"full": "URL#1627902", "pdf": ""}, "publisher-venue": "ICDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2458026091, "title": "SenFact algorithm - Fact-checking by the confrontation of opinions.", "abstract": "", "doi": "10.1109/fskd.2017.8393118", "date": "2017", "authors": [{"name": "Edouard Ngor Sarr", "id-internal": "217/8580", "id-external": ""}, {"name": "Ousmane Sall", "id-internal": "57/7283", "id-external": ""}, {"name": "Assane Diagne", "id-internal": "221/8810", "id-external": ""}], "url": {"full": "URL#1635988", "pdf": ""}, "publisher-venue": "ICNC-FSKD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3965676566, "title": "Automated Historical Fact-Checking by Passage Retrieval, Word Statistics, and Virtual Question-Answering.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Mio Kobayashi", "id-internal": "30/9749", "id-external": ""}, {"name": "Ai Ishii", "id-internal": "162/8106", "id-external": ""}, {"name": "Chikara Hoshino", "id-internal": "55/11180", "id-external": ""}, {"name": "Hiroshi Miyashita", "id-internal": "08/5383", "id-external": ""}, {"name": "Takuya Matsuzaki", "id-internal": "36/1621", "id-external": ""}], "url": {"full": "URL#1650505", "pdf": ""}, "publisher-venue": "IJCNLP(1)", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 213910138, "title": "The Impact of Facebook's News Fact-Checking on Information Quality (IQ) Shared on Social Media.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Ahmed Abu Halimeh", "id-internal": "122/1569", "id-external": ""}, {"name": "Pardis Pourghomi", "id-internal": "127/1573", "id-external": ""}, {"name": "Fadi Safieddine", "id-internal": "38/6173", "id-external": ""}], "url": {"full": "URL#1655772", "pdf": ""}, "publisher-venue": "ICIQ", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2123633370, "title": "Fully Automated Fact Checking Using External Sources.", "abstract": "", "doi": "10.26615/978-954-452-049-6_046", "date": "2017", "authors": [{"name": "Georgi Karadzhov", "id-internal": "205/1966", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Llu\u00eds M\u00e0rquez", "id-internal": "62/3", "id-external": ""}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o", "id-internal": "40/3383", "id-external": ""}, {"name": "Ivan Koychev", "id-internal": "88/2617", "id-external": ""}], "url": {"full": "URL#1688518", "pdf": ""}, "publisher-venue": "RANLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 223647211, "title": "Finding Streams in Knowledge Graphs to Support Fact Checking.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Prashant Shiralkar", "id-internal": "157/8398", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}, {"name": "Giovanni Luca Ciampaglia", "id-internal": "07/8400", "id-external": ""}], "url": {"full": "URL#1742601", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 131841112, "title": "Fully Automated Fact Checking Using External Sources.", "abstract": "", "doi": "", "date": "2017", "authors": [{"name": "Georgi Karadzhov", "id-internal": "205/1966", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Llu\u00eds M\u00e0rquez", "id-internal": "62/3", "id-external": ""}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o", "id-internal": "40/3383", "id-external": ""}, {"name": "Ivan Koychev", "id-internal": "88/2617", "id-external": ""}], "url": {"full": "URL#1746006", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1578007693, "title": "ContentCheck - Content Management Techniques and Tools for Fact-checking.", "abstract": "", "doi": "", "date": "2017", "authors": {"name": "Ioana Manolescu", "id-internal": "m/IoanaManolescu", "id-external": ""}, "url": {"full": "URL#1754330", "pdf": ""}, "publisher-venue": "ERCIM News", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1377556190, "title": "Symbolic Model Checking for Factored Probabilistic Models.", "abstract": "", "doi": "10.1007/978-3-319-46520-3_28", "date": "2016", "authors": [{"name": "David Deininger", "id-internal": "187/1665", "id-external": ""}, {"name": "Rayna Dimitrova", "id-internal": "69/2960", "id-external": ""}, {"name": "Rupak Majumdar", "id-internal": "71/1981", "id-external": ""}], "url": {"full": "URL#1889049", "pdf": ""}, "publisher-venue": "ATVA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1360801308, "title": "Improving Automated Fact-Checking Through the Semantic Web.", "abstract": "", "doi": "10.1007/978-3-319-38791-8_40", "date": "2016", "authors": {"name": "Alex Carmine Olivieri", "id-internal": "129/2358", "id-external": ""}, "url": {"full": "URL#1959568", "pdf": ""}, "publisher-venue": "ICWE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3519009973, "title": "Fact Checking in Heterogeneous Information Networks.", "abstract": "", "doi": "10.1145/2872518.2889354", "date": "2016", "authors": [{"name": "Baoxu Shi", "id-internal": "132/6140", "id-external": ""}, {"name": "Tim Weninger", "id-internal": "73/2015", "id-external": ""}], "url": {"full": "URL#2032208", "pdf": ""}, "publisher-venue": "WWW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 429523283, "title": "The Genesis and Development of Model Checking - Fact vs. Fiction.", "abstract": "", "doi": "", "date": "2015", "authors": {"name": "Allan Emerson", "id-internal": "173/8887", "id-external": ""}, "url": {"full": "URL#2227567", "pdf": ""}, "publisher-venue": "FMCAD", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1371928010, "title": "Computational fact checking from knowledge networks.", "abstract": "", "doi": "", "date": "2015", "authors": [{"name": "Giovanni Luca Ciampaglia", "id-internal": "07/8400", "id-external": ""}, {"name": "Prashant Shiralkar", "id-internal": "157/8398", "id-external": ""}, {"name": "Luis Mateus Rocha", "id-internal": "r/LuisMateusRocha", "id-external": ""}, {"name": "Johan Bollen", "id-internal": "b/JohanBollen", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}, {"name": "Alessandro Flammini", "id-internal": "78/5715", "id-external": ""}], "url": {"full": "URL#2343594", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2824392819, "title": "Fact Checking in Large Knowledge Graphs - A Discriminative Predicate Path Mining Approach.", "abstract": "", "doi": "", "date": "2015", "authors": [{"name": "Baoxu Shi", "id-internal": "132/6140", "id-external": ""}, {"name": "Tim Weninger", "id-internal": "73/2015", "id-external": ""}], "url": {"full": "URL#2354453", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2128418549, "title": "Toward Computational Fact-Checking.", "abstract": "", "doi": "10.14778/2732286.2732295", "date": "2014", "authors": [{"name": "You Wu 0001", "id-internal": "16/8675-1", "id-external": ""}, {"name": "Pankaj K. Agarwal", "id-internal": "a/PankajKAgarwal", "id-external": ""}, {"name": "Chengkai Li", "id-internal": "14/3692", "id-external": ""}, {"name": "Jun Yang 0001", "id-internal": "y/JunYang1", "id-external": ""}, {"name": "Cong Yu 0001", "id-internal": "58/3771", "id-external": ""}], "url": {"full": "URL#2442219", "pdf": ""}, "publisher-venue": "Proc. VLDB Endow.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 887890231, "title": "Fact Checking - Task definition and dataset construction.", "abstract": "", "doi": "10.3115/v1/w14-2508", "date": "2014", "authors": [{"name": "Andreas Vlachos 0001", "id-internal": "18/1071-1", "id-external": ""}, {"name": "Sebastian Riedel 0001", "id-internal": "18/3348-1", "id-external": ""}], "url": {"full": "URL#2474218", "pdf": ""}, "publisher-venue": "LTCSS@ACL", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2509258871, "title": "Integrating on-demand fact-checking with public dialogue.", "abstract": "", "doi": "10.1145/2531602.2531677", "date": "2014", "authors": [{"name": "Travis Kriplean", "id-internal": "69/989", "id-external": ""}, {"name": "Caitlin Bonnar", "id-internal": "141/3874", "id-external": ""}, {"name": "Alan Borning", "id-internal": "b/AlanBorning", "id-external": ""}, {"name": "Bo Kinney", "id-internal": "141/4083", "id-external": ""}, {"name": "Brian T. Gill", "id-internal": "66/4894", "id-external": ""}], "url": {"full": "URL#2499979", "pdf": ""}, "publisher-venue": "CSCW", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 67760223, "title": "Get Back! You Don't Know Me Like That - The Social Mediation of Fact Checking Interventions in Twitter Conversations.", "abstract": "", "doi": "", "date": "2014", "authors": [{"name": "Aniko Hannak", "id-internal": "83/11516", "id-external": ""}, {"name": "Drew Margolin", "id-internal": "126/1980", "id-external": ""}, {"name": "Brian Keegan", "id-internal": "46/5766", "id-external": ""}, {"name": "Ingmar Weber", "id-internal": "w/IngmarWeber", "id-external": ""}], "url": {"full": "URL#2554065", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1323714410, "title": "Fact checking and analyzing the web.", "abstract": "", "doi": "10.1145/2463676.2463692", "date": "2013", "authors": [{"name": "Fran\u00e7ois Goasdou\u00e9", "id-internal": "92/6981", "id-external": ""}, {"name": "Konstantinos Karanasos", "id-internal": "59/7992", "id-external": ""}, {"name": "Yannis Katsis", "id-internal": "75/4070", "id-external": ""}, {"name": "Julien Leblay", "id-internal": "35/8398", "id-external": ""}, {"name": "Ioana Manolescu", "id-internal": "m/IoanaManolescu", "id-external": ""}, {"name": "Stamatis Zampetakis", "id-internal": "90/8176", "id-external": ""}], "url": {"full": "URL#2883448", "pdf": ""}, "publisher-venue": "SIGMOD Conference", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2737063745, "title": "Web-based statistical fact checking of textual documents.", "abstract": "", "doi": "10.1145/1871985.1872002", "date": "2010", "authors": [{"name": "Amr Magdy 0001", "id-internal": "05/8073-1", "id-external": ""}, {"name": "Nayer M. Wanas", "id-internal": "04/220", "id-external": ""}], "url": {"full": "URL#3536509", "pdf": ""}, "publisher-venue": "SMUC@CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3356427699, "title": "Model Checking Control Communication of a FACTS Device.", "abstract": "", "doi": "10.1109/icppw.2006.54", "date": "2006", "authors": [{"name": "David A. Cape", "id-internal": "62/2865", "id-external": ""}, {"name": "Bruce M. McMillin", "id-internal": "91/2733", "id-external": ""}, {"name": "James K. Townsend", "id-internal": "42/2957", "id-external": ""}], "url": {"full": "URL#4383093", "pdf": ""}, "publisher-venue": "ICPP Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1618556431, "title": "Navigational Checking Using 3D Maps - The Influence of Elevation Angle, Azimuth, and Foreshortening.", "abstract": "", "doi": "10.1518/001872098779480497", "date": "1998", "authors": [{"name": "Brian T. Schreiber", "id-internal": "80/7988", "id-external": ""}, {"name": "Christopher D. Wickens", "id-internal": "89/2440", "id-external": ""}, {"name": "Goetz J. Renner", "id-internal": "74/7987", "id-external": ""}, {"name": "Jeffrey D. Alton", "id-internal": "24/7989", "id-external": ""}, {"name": "Joseph C. Hickox", "id-internal": "35/7989", "id-external": ""}], "url": {"full": "URL#5171640", "pdf": ""}, "publisher-venue": "Hum. Factors", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 814913188, "title": "Checking a Rule Base with Certainty Factor for Incompleteness and Inconsistency.", "abstract": "", "doi": "10.1007/3-540-19402-9_74", "date": "1988", "authors": {"name": "Sangchul Kim", "id-internal": "47/3818", "id-external": ""}, "url": {"full": "URL#5594535", "pdf": ""}, "publisher-venue": "IPMU", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2068336266, "title": "Learning from Fact-checkers: Analysis and Generation of Fact-checking\n  Language", "abstract": "In fighting against fake news, many fact-checking systems comprised of\nhuman-based fact-checking sites (e.g., snopes.com and politifact.com) and\nautomatic detection systems have been developed in recent years. However,\nonline users still keep sharing fake news even when it has been debunked. It\nmeans that early fake news detection may be insufficient and we need another\ncomplementary approach to mitigate the spread of misinformation. In this paper,\nwe introduce a novel application of text generation for combating fake news. In\nparticular, we (1) leverage online users named \\emph{fact-checkers}, who cite\nfact-checking sites as credible evidences to fact-check information in public\ndiscourse; (2) analyze linguistic characteristics of fact-checking tweets; and\n(3) propose and build a deep learning framework to generate responses with\nfact-checking intention to increase the fact-checkers' engagement in\nfact-checking activities. Our analysis reveals that the fact-checkers tend to\nrefute misinformation and use formal language (e.g. few swear words and\nInternet slangs). Our framework successfully generates relevant responses, and\noutperforms competing models by achieving up to 30\\% improvements. Our\nqualitative study also confirms that the superiority of our generated responses\ncompared with responses generated from the existing models.", "doi": "", "date": "2019-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.02202v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 211990329, "title": "Explainable Automated Fact-Checking for Public Health Claims", "abstract": "Fact-checking is the task of verifying the veracity of claims by assessing\ntheir assertions against credible evidence. The vast majority of fact-checking\nstudies focus exclusively on political claims. Very little research explores\nfact-checking for other topics, specifically subject matters for which\nexpertise is required. We present the first study of explainable fact-checking\nfor claims which require specific expertise. For our case study we choose the\nsetting of public health. To support this case study we construct a new dataset\nPUBHEALTH of 11.8K claims accompanied by journalist crafted, gold standard\nexplanations (i.e., judgments) to support the fact-check labels for claims. We\nexplore two tasks: veracity prediction and explanation generation. We also\ndefine and evaluate, with humans and computationally, three coherence\nproperties of explanation quality. Our results indicate that, by training on\nin-domain data, gains can be made in explainable, automated fact-checking for\nclaims which require specific expertise.", "doi": "", "date": "2020-10-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.09926v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2724879214, "title": "Explainable Automated Fact-Checking: A Survey", "abstract": "A number of exciting advances have been made in automated fact-checking\nthanks to increasingly larger datasets and more powerful systems, leading to\nimprovements in the complexity of claims which can be accurately fact-checked.\nHowever, despite these advances, there are still desirable functionalities\nmissing from the fact-checking pipeline. In this survey, we focus on the\nexplanation functionality -- that is fact-checking systems providing reasons\nfor their predictions. We summarize existing methods for explaining the\npredictions of fact-checking systems and we explore trends in this topic.\nFurther, we consider what makes for good explanations in this specific domain\nthrough a comparative analysis of existing fact-checking explanations against\nsome desirable properties. Finally, we propose further research directions for\ngenerating fact-checking explanations, and describe how these may lead to\nimprovements in the research area.", "doi": "", "date": "2020-11-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.03870v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 166740091, "title": "That is a Known Lie: Detecting Previously Fact-Checked Claims", "abstract": "The recent proliferation of \"fake news\" has triggered a number of responses,\nmost notably the emergence of several manual fact-checking initiatives. As a\nresult and over time, a large number of fact-checked claims have been\naccumulated, which increases the likelihood that a new claim in social media or\na new statement by a politician might have already been fact-checked by some\ntrusted fact-checking organization, as viral claims often come back after a\nwhile in social media, and politicians like to repeat their favorite\nstatements, true or false, over and over again. As manual fact-checking is very\ntime-consuming (and fully automatic fact-checking has credibility issues), it\nis important to try to save this effort and to avoid wasting time on claims\nthat have already been fact-checked. Interestingly, despite the importance of\nthe task, it has been largely ignored by the research community so far. Here,\nwe aim to bridge this gap. In particular, we formulate the task and we discuss\nhow it relates to, but also differs from, previous work. We further create a\nspecialized dataset, which we release to the research community. Finally, we\npresent learning-to-rank experiments that demonstrate sizable improvements over\nstate-of-the-art retrieval and textual similarity approaches.", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.06058v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3822613519, "title": "The Role of Context in Detecting Previously Fact-Checked Claims", "abstract": "Recent years have seen the proliferation of disinformation and misinformation\nonline, thanks to the freedom of expression on the Internet and to the rise of\nsocial media. Two solutions were proposed to address the problem: (i) manual\nfact-checking, which is accurate and credible, but slow and non-scalable, and\n(ii) automatic fact-checking, which is fast and scalable, but lacks\nexplainability and credibility. With the accumulation of enough manually\nfact-checked claims, a middle-ground approach has emerged: checking whether a\ngiven claim has previously been fact-checked. This can be made automatically,\nand thus fast, while also offering credibility and explainability, thanks to\nthe human fact-checking and explanations in the associated fact-checking\narticle. This is a relatively new and understudied research direction, and here\nwe focus on claims made in a political debate, where context really matters.\nThus, we study the impact of modeling the context of the claim: both on the\nsource side, i.e., in the debate, as well as on the target side, i.e., in the\nfact-checking explanation document. We do this by modeling the local context,\nthe global context, as well as by means of co-reference resolution, and\nreasoning over the target text using Transformer-XH. The experimental results\nshow that each of these represents a valuable information source, but that\nmodeling the source-side context is more important, and can yield 10+ points of\nabsolute improvement.", "doi": "", "date": "2021-04-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.07423v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2123959733, "title": "Related Fact Checks: a tool for combating fake news", "abstract": "The emergence of \"Fake News\" and misinformation via online news and social\nmedia has spurred an interest in computational tools to combat this phenomenon.\nIn this paper we present a new \"Related Fact Checks\" service, which can help a\nreader critically evaluate an article and make a judgment on its veracity by\nbringing up fact checks that are relevant to the article. We describe the core\ntechnical problems that need to be solved in building a \"Related Fact Checks\"\nservice, and present results from an evaluation of an implementation.", "doi": "", "date": "2017-10-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.00715v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 354168706, "title": "A Survey on Automated Fact-Checking", "abstract": "Fact-checking has become increasingly important due to the speed with which\nboth information and misinformation can spread in the modern media ecosystem.\nTherefore, researchers have been exploring how fact-checking can be automated,\nusing techniques based on natural language processing, machine learning,\nknowledge representation, and databases to automatically predict the veracity\nof claims. In this paper, we survey automated fact-checking stemming from\nnatural language processing, and discuss its connections to related tasks and\ndisciplines. In this process, we present an overview of existing datasets and\nmodels, aiming to unify the various definitions given and identify common\nconcepts. Finally, we highlight challenges for future research.", "doi": "", "date": "2021-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.11896v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1321640166, "title": "Automated Fact-Checking for Assisting Human Fact-Checkers", "abstract": "The reporting and the analysis of current events around the globe has\nexpanded from professional, editor-lead journalism all the way to citizen\njournalism. Nowadays, politicians and other key players enjoy direct access to\ntheir audiences through social media, bypassing the filters of official cables\nor traditional media. However, the multiple advantages of free speech and\ndirect communication are dimmed by the misuse of media to spread inaccurate or\nmisleading claims. These phenomena have led to the modern incarnation of the\nfact-checker -- a professional whose main aim is to examine claims using\navailable evidence and to assess their veracity. As in other text forensics\ntasks, the amount of information available makes the work of the fact-checker\nmore difficult. With this in mind, starting from the perspective of the\nprofessional fact-checker, we survey the available intelligent technologies\nthat can support the human expert in the different steps of her fact-checking\nendeavor. These include identifying claims worth fact-checking, detecting\nrelevant previously fact-checked claims, retrieving relevant evidence to\nfact-check a claim, and actually verifying a claim. In each case, we pay\nattention to the challenges in future work and the potential impact on\nreal-world fact-checking.", "doi": "", "date": "2021-03-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.07769v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1958118904, "title": "Integrating Stance Detection and Fact Checking in a Unified Corpus", "abstract": "A reasonable approach for fact checking a claim involves retrieving\npotentially relevant documents from different sources (e.g., news websites,\nsocial media, etc.), determining the stance of each document with respect to\nthe claim, and finally making a prediction about the claim's factuality by\naggregating the strength of the stances, while taking the reliability of the\nsource into account. Moreover, a fact checking system should be able to explain\nits decision by providing relevant extracts (rationales) from the documents.\nYet, this setup is not directly supported by existing datasets, which treat\nfact checking, document retrieval, source credibility, stance detection and\nrationale extraction as independent tasks. In this paper, we support the\ninterdependencies between these tasks as annotations in the same corpus. We\nimplement this setup on an Arabic fact checking corpus, the first of its kind.", "doi": "", "date": "2018-04-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.08012v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2635155362, "title": "The Rise of Guardians: Fact-checking URL Recommendation to Combat Fake\n  News", "abstract": "A large body of research work and efforts have been focused on detecting fake\nnews and building online fact-check systems in order to debunk fake news as\nsoon as possible. Despite the existence of these systems, fake news is still\nwildly shared by online users. It indicates that these systems may not be fully\nutilized. After detecting fake news, what is the next step to stop people from\nsharing it? How can we improve the utilization of these fact-check systems? To\nfill this gap, in this paper, we (i) collect and analyze online users called\nguardians, who correct misinformation and fake news in online discussions by\nreferring fact-checking URLs; and (ii) propose a novel fact-checking URL\nrecommendation model to encourage the guardians to engage more in fact-checking\nactivities. We found that the guardians usually took less than one day to reply\nto claims in online conversations and took another day to spread verified\ninformation to hundreds of millions of followers. Our proposed recommendation\nmodel outperformed four state-of-the-art models by 11%~33%. Our source code and\ndataset are available at https://github.com/nguyenvo09/CombatingFakeNews.", "doi": "", "date": "2018-06-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.07516v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 220797164, "title": "FakeCovid -- A Multilingual Cross-domain Fact Check News Dataset for\n  COVID-19", "abstract": "In this paper, we present a first multilingual cross-domain dataset of 5182\nfact-checked news articles for COVID-19, collected from 04/01/2020 to\n15/05/2020. We have collected the fact-checked articles from 92 different\nfact-checking websites after obtaining references from Poynter and Snopes. We\nhave manually annotated articles into 11 different categories of the\nfact-checked news according to their content. The dataset is in 40 languages\nfrom 105 countries. We have built a classifier to detect fake news and present\nresults for the automatic fake news detection and its class. Our model achieves\nan F1 score of 0.76 to detect the false class and other fact check articles.\nThe FakeCovid dataset is available at Github.", "doi": "10.36190/2020.14", "date": "2020-06-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.11343v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1507020360, "title": "Where Are the Facts? Searching for Fact-checked Information to Alleviate\n  the Spread of Fake News", "abstract": "Although many fact-checking systems have been developed in academia and\nindustry, fake news is still proliferating on social media. These systems\nmostly focus on fact-checking but usually neglect online users who are the main\ndrivers of the spread of misinformation. How can we use fact-checked\ninformation to improve users' consciousness of fake news to which they are\nexposed? How can we stop users from spreading fake news? To tackle these\nquestions, we propose a novel framework to search for fact-checking articles,\nwhich address the content of an original tweet (that may contain\nmisinformation) posted by online users. The search can directly warn fake news\nposters and online users (e.g. the posters' followers) about misinformation,\ndiscourage them from spreading fake news, and scale up verified content on\nsocial media. Our framework uses both text and images to search for\nfact-checking articles, and achieves promising results on real-world datasets.\nOur code and datasets are released at https://github.com/nguyenvo09/EMNLP2020.", "doi": "", "date": "2020-10-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.03159v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3427649338, "title": "Computational fact checking from knowledge networks", "abstract": "Traditional fact checking by expert journalists cannot keep up with the\nenormous volume of information that is now generated online. Computational fact\nchecking may significantly enhance our ability to evaluate the veracity of\ndubious information. Here we show that the complexities of human fact checking\ncan be approximated quite well by finding the shortest path between concept\nnodes under properly defined semantic proximity metrics on knowledge graphs.\nFramed as a network problem this approach is feasible with efficient\ncomputational techniques. We evaluate this approach by examining tens of\nthousands of claims related to history, entertainment, geography, and\nbiographical information using a public knowledge graph extracted from\nWikipedia. Statements independently known to be true consistently receive\nhigher support via our method than do false ones. These findings represent a\nsignificant step toward scalable computational fact-checking methods that may\none day mitigate the spread of harmful misinformation.", "doi": "10.1371/journal.pone.0128193", "date": "2015-01-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1501.03471v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 790730661, "title": "Fact-Checking Meets Fauxtography: Verifying Claims About Images", "abstract": "The recent explosion of false claims in social media and on the Web in\ngeneral has given rise to a lot of manual fact-checking initiatives.\nUnfortunately, the number of claims that need to be fact-checked is several\norders of magnitude larger than what humans can handle manually. Thus, there\nhas been a lot of research aiming at automating the process. Interestingly,\nprevious work has largely ignored the growing number of claims about images.\nThis is despite the fact that visual imagery is more influential than text and\nnaturally appears alongside fake news. Here we aim at bridging this gap. In\nparticular, we create a new dataset for this problem, and we explore a variety\nof features modeling the claim, the image, and the relationship between the\nclaim and the image. The evaluation results show sizable improvements over the\nbaseline. We release our dataset, hoping to enable further research on\nfact-checking claims about images.", "doi": "", "date": "2019-08-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.11722v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1561896543, "title": "Can WhatsApp Benefit from Debunked Fact-Checked Stories to Reduce\n  Misinformation?", "abstract": "WhatsApp was alleged to be widely used to spread misinformation and\npropaganda during elections in Brazil and India. Due to the private encrypted\nnature of the messages on WhatsApp, it is hard to track the dissemination of\nmisinformation at scale. In this work, using public WhatsApp data, we observe\nthat misinformation has been largely shared on WhatsApp public groups even\nafter they were already fact-checked by popular fact-checking agencies. This\nrepresents a significant portion of misinformation spread in both Brazil and\nIndia in the groups analyzed. We posit that such misinformation content could\nbe prevented if WhatsApp had a means to flag already fact-checked content. To\nthis end, we propose an architecture that could be implemented by WhatsApp to\ncounter such misinformation. Our proposal respects the current end-to-end\nencryption architecture on WhatsApp, thus protecting users' privacy while\nproviding an approach to detect the misinformation that benefits from\nfact-checking efforts.", "doi": "", "date": "2020-06-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.02471v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2393757862, "title": "Fact-Checking at Scale with DimensionRank", "abstract": "The most important problem that has emerged after twenty years of popular\ninternet usage is that of fact-checking at scale. This problem is experienced\nacutely in both of the major internet application platform types, web search\nand social media.\n  We offer a working definition of what a \"platform\" is. We critically\ndeconstruct what we call the \"PolitiFact\" model of fact checking, and show it\nto be inherently inferior for fact-checking at scale to a platform-b ased\nsolution.\n  Our central contribution is to show how to effectively platformize the\nproblem of fact-checking at scale. We show how a two-dimensional rating system,\nwith dimensions agreement and hotness allows us to create information-seeking\nqueries not possible with the on e-dimensional rating system predominating on\nexisting platforms. And, we show that, underlying our user-friendly\nuser-interface, lies a system that allows the creation of formal proofs in the\npropositional calculus.\n  Our algorithm is implemented in our open-source DimensionRank software\npackage available at \"https://thinkdifferentagain.art\".", "doi": "", "date": "2020-10-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.10685v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2017535767, "title": "Generating Fact Checking Briefs", "abstract": "Fact checking at scale is difficult -- while the number of active fact\nchecking websites is growing, it remains too small for the needs of the\ncontemporary media ecosystem. However, despite good intentions, contributions\nfrom volunteers are often error-prone, and thus in practice restricted to claim\ndetection. We investigate how to increase the accuracy and efficiency of fact\nchecking by providing information about the claim before performing the check,\nin the form of natural language briefs. We investigate passage-based briefs,\ncontaining a relevant passage from Wikipedia, entity-centric ones consisting of\nWikipedia pages of mentioned entities, and Question-Answering Briefs, with\nquestions decomposing the claim, and their answers. To produce QABriefs, we\ndevelop QABriefer, a model that generates a set of questions conditioned on the\nclaim, searches the web for evidence, and generates answers. To train its\ncomponents, we introduce QABriefDataset which we collected via crowdsourcing.\nWe show that fact checking with briefs -- in particular QABriefs -- increases\nthe accuracy of crowdworkers by 10% while slightly decreasing the time taken.\nFor volunteer (unpaid) fact checkers, QABriefs slightly increase accuracy and\nreduce the time required by around 20%.", "doi": "", "date": "2020-11-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.05448v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 925020161, "title": "Towards Few-Shot Fact-Checking via Perplexity", "abstract": "Few-shot learning has drawn researchers' attention to overcome the problem of\ndata scarcity. Recently, large pre-trained language models have shown great\nperformance in few-shot learning for various downstream tasks, such as question\nanswering and machine translation. Nevertheless, little exploration has been\nmade to achieve few-shot learning for the fact-checking task. However,\nfact-checking is an important problem, especially when the amount of\ninformation online is growing exponentially every day. In this paper, we\npropose a new way of utilizing the powerful transfer learning ability of a\nlanguage model via a perplexity score. The most notable strength of our\nmethodology lies in its capability in few-shot learning. With only two training\nsamples, our methodology can already outperform the Major Class baseline by\nmore than absolute 10% on the F1-Macro metric across multiple datasets. Through\nexperiments, we empirically verify the plausibility of the rather surprising\nusage of the perplexity score in the context of fact-checking and highlight the\nstrength of our few-shot methodology by comparing it to strong\nfine-tuning-based baseline models. Moreover, we construct and publicly release\ntwo new fact-checking datasets related to COVID-19.", "doi": "", "date": "2021-03-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.09535v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1192150129, "title": "The False COVID-19 Narratives That Keep Being Debunked: A Spatiotemporal\n  Analysis", "abstract": "The onset of the Coronavirus disease 2019 (COVID-19) pandemic instigated a\nglobal infodemic that has brought unprecedented challenges for society as a\nwhole. During this time, a number of manual fact-checking initiatives have\nemerged to alleviate the spread of dis/mis-information. This study is about\nCOVID-19 debunks published in multiple languages by different fact-checking\norganisations, sometimes as far as several months apart, despite the fact that\nthe claim has already been fact-checked before. The spatiotemporal analysis\nreveals that similar or nearly duplicate false COVID-19 narratives have been\nspreading in multifarious modalities on various social media platforms in\ndifferent countries. We also find that misinformation involving general medical\nadvice has spread across multiple countries and hence has the highest\nproportion of false COVID-19 narratives that keep being debunked. Furthermore,\nas manual fact-checking is an onerous task in itself, therefore debunking\nsimilar claims recurrently is leading to a waste of resources. To this end, we\npropound the idea of the inclusion of multilingual debunk search in the\nfact-checking pipeline.", "doi": "", "date": "2021-07-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.12303v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3174802934, "title": "CobWeb: A Research Prototype for Exploring User Bias in Political\n  Fact-Checking", "abstract": "The effect of user bias in fact-checking has not been explored extensively\nfrom a user-experience perspective. We estimate the user bias as a function of\nthe user's perceived reputation of the news sources (e.g., a user with liberal\nbeliefs may tend to trust liberal sources). We build an interface to\ncommunicate the role of estimated user bias in the context of a fact-checking\ntask. We also explore the utility of helping users visualize their detected\nlevel of bias. 80% of the users of our system find that the presence of an\nindicator for user bias is useful in judging the veracity of a political claim.", "doi": "", "date": "2019-07-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.03718v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4277480656, "title": "Text Similarity Using Word Embeddings to Classify Misinformation", "abstract": "Fake news is a growing problem in the last years, especially during\nelections. It's hard work to identify what is true and what is false among all\nthe user generated content that circulates every day. Technology can help with\nthat work and optimize the fact-checking process. In this work, we address the\nchallenge of finding similar content in order to be able to suggest to a\nfact-checker articles that could have been verified before and thus avoid that\nthe same information is verified more than once. This is especially important\nin collaborative approaches to fact-checking where members of large teams will\nnot know what content others have already fact-checked.", "doi": "", "date": "2020-03-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.06634v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 998074582, "title": "Community-Based Fact-Checking on Twitter's Birdwatch Platform", "abstract": "Misinformation undermines the credibility of social media and poses\nsignificant threats to modern societies. As a countermeasure, Twitter has\nrecently introduced \"Birdwatch,\" a community-driven approach to address\nmisinformation on Twitter. On Birdwatch, users can identify tweets they believe\nare misleading, write notes that provide context to the tweet and rate the\nquality of other users' notes. In this work, we empirically analyze how users\ninteract with this new feature. For this purpose, we collect all Birdwatch\nnotes and ratings since the introduction of the feature in early 2021. We then\nmap each Birdwatch note to the fact-checked tweet using Twitter's historical\nAPI. In addition, we use text mining methods to extract content characteristics\nfrom the text explanations in the Birdwatch notes (e.g., sentiment). Our\nempirical analysis yields the following main findings: (i) users more\nfrequently file Birdwatch notes for misleading than not misleading tweets.\nThese misleading tweets are primarily reported because of factual errors, lack\nof important context, or because they contain unverified claims. (ii) Birdwatch\nnotes are more helpful to other users if they link to trustworthy sources and\nif they embed a more positive sentiment. (iii) The helpfulness of Birdwatch\nnotes depends on the social influence of the author of the fact-checked tweet.\nFor influential users with many followers, Birdwatch notes yield a lower level\nof consensus among users and community-created fact checks are more likely to\nbe seen as being incorrect. Altogether, our findings can help social media\nplatforms to formulate guidelines for users on how to write more helpful fact\nchecks. At the same time, our analysis suggests that community-based\nfact-checking faces challenges regarding biased views and polarization among\nthe user base.", "doi": "", "date": "2021-04-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.07175v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4192932918, "title": "A Knowledge Enhanced Learning and Semantic Composition Model for\n  Multi-Claim Fact Checking", "abstract": "To inhibit the spread of rumorous information and its severe consequences,\ntraditional fact checking aims at retrieving relevant evidence to verify the\nveracity of a given claim. Fact checking methods typically use knowledge graphs\n(KGs) as external repositories and develop reasoning mechanism to retrieve\nevidence for verifying the triple claim. However, existing methods only focus\non verifying a single claim. As real-world rumorous information is more complex\nand a textual statement is often composed of multiple clauses (i.e. represented\nas multiple claims instead of a single one), multiclaim fact checking is not\nonly necessary but more important for practical applications. Although previous\nmethods for verifying a single triple can be applied repeatedly to verify\nmultiple triples one by one, they ignore the contextual information implied in\na multi-claim statement and could not learn the rich semantic information in\nthe statement as a whole. In this paper, we propose an end-to-end knowledge\nenhanced learning and verification method for multi-claim fact checking. Our\nmethod consists of two modules, KG-based learning enhancement and multi-claim\nsemantic composition. To fully utilize the contextual information, the KG-based\nlearning enhancement module learns the dynamic context-specific representations\nvia selectively aggregating relevant attributes of entities. To capture the\ncompositional semantics of multiple triples, the multi-claim semantic\ncomposition module constructs the graph structure to model claim-level\ninteractions, and integrates global and salient local semantics with multi-head\nattention. Experimental results on a real-world dataset and two benchmark\ndatasets show the effectiveness of our method for multi-claim fact checking\nover KG.", "doi": "", "date": "2021-04-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13046v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3448313321, "title": "Towards Explainable Fact Checking", "abstract": "The past decade has seen a substantial rise in the amount of mis- and\ndisinformation online, from targeted disinformation campaigns to influence\npolitics, to the unintentional spreading of misinformation about public health.\nThis development has spurred research in the area of automatic fact checking,\nfrom approaches to detect check-worthy claims and determining the stance of\ntweets towards claims, to methods to determine the veracity of claims given\nevidence documents. These automatic methods are often content-based, using\nnatural language processing methods, which in turn utilise deep neural networks\nto learn higher-order features from text in order to make predictions. As deep\nneural networks are black-box models, their inner workings cannot be easily\nexplained. At the same time, it is desirable to explain how they arrive at\ncertain decisions, especially if they are to be used for decision making. While\nthis has been known for some time, the issues this raises have been exacerbated\nby models increasing in size, and by EU legislation requiring models to be used\nfor decision making to provide explanations, and, very recently, by legislation\nrequiring online platforms operating in the EU to provide transparent reporting\non their services. Despite this, current solutions for explainability are still\nlacking in the area of fact checking. This thesis presents my research on\nautomatic fact checking, including claim check-worthiness detection, stance\ndetection and veracity prediction. Its contributions go beyond fact checking,\nwith the thesis proposing more general machine learning solutions for natural\nlanguage processing in the area of learning with limited labelled data.\nFinally, the thesis presents some first solutions for explainable fact\nchecking.", "doi": "", "date": "2021-08-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.10274v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2655603207, "title": "Network segregation in a model of misinformation and fact checking", "abstract": "Misinformation under the form of rumor, hoaxes, and conspiracy theories\nspreads on social media at alarming rates. One hypothesis is that, since social\nmedia are shaped by homophily, belief in misinformation may be more likely to\nthrive on those social circles that are segregated from the rest of the\nnetwork. One possible antidote is fact checking which, in some cases, is known\nto stop rumors from spreading further. However, fact checking may also backfire\nand reinforce the belief in a hoax. Here we take into account the combination\nof network segregation, finite memory and attention, and fact-checking efforts.\nWe consider a compartmental model of two interacting epidemic processes over a\nnetwork that is segregated between gullible and skeptic users. Extensive\nsimulation and mean-field analysis show that a more segregated network\nfacilitates the spread of a hoax only at low forgetting rates, but has no\neffect when agents forget at faster rates. This finding may inform the\ndevelopment of mitigation techniques and overall inform on the risks of\nuncontrolled misinformation online.", "doi": "10.1007/s42001-018-0018-9", "date": "2016-10-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1610.04170v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1317621754, "title": "Automated Fact Checking: Task formulations, methods and future\n  directions", "abstract": "The recently increased focus on misinformation has stimulated research in\nfact checking, the task of assessing the truthfulness of a claim. Research in\nautomating this task has been conducted in a variety of disciplines including\nnatural language processing, machine learning, knowledge representation,\ndatabases, and journalism. While there has been substantial progress, relevant\npapers and articles have been published in research communities that are often\nunaware of each other and use inconsistent terminology, thus impeding\nunderstanding and further progress. In this paper we survey automated fact\nchecking research stemming from natural language processing and related\ndisciplines, unifying the task formulations and methodologies across papers and\nauthors. Furthermore, we highlight the use of evidence as an important\ndistinguishing factor among them cutting across task formulations and methods.\nWe conclude with proposing avenues for future NLP research on automated fact\nchecking.", "doi": "", "date": "2018-06-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.07687v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 377573506, "title": "Automated Fact Checking in the News Room", "abstract": "Fact checking is an essential task in journalism; its importance has been\nhighlighted due to recently increased concerns and efforts in combating\nmisinformation. In this paper, we present an automated fact-checking platform\nwhich given a claim, it retrieves relevant textual evidence from a document\ncollection, predicts whether each piece of evidence supports or refutes the\nclaim, and returns a final verdict. We describe the architecture of the system\nand the user interface, focusing on the choices made to improve its\nuser-friendliness and transparency. We conduct a user study of the\nfact-checking platform in a journalistic setting: we integrated it with a\ncollection of news articles and provide an evaluation of the platform using\nfeedback from journalists in their workflow. We found that the predictions of\nour platform were correct 58\\% of the time, and 59\\% of the returned evidence\nwas relevant.", "doi": "", "date": "2019-04-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.02037v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3191229623, "title": "Explainable Fact Checking with Probabilistic Answer Set Programming", "abstract": "One challenge in fact checking is the ability to improve the transparency of\nthe decision. We present a fact checking method that uses reference information\nin knowledge graphs (KGs) to assess claims and explain its decisions. KGs\ncontain a formal representation of knowledge with semantic descriptions of\nentities and their relationships. We exploit such rich semantics to produce\ninterpretable explanations for the fact checking output. As information in a KG\nis inevitably incomplete, we rely on logical rule discovery and on Web text\nmining to gather the evidence to assess a given claim. Uncertain rules and\nfacts are turned into logical programs and the checking task is modeled as an\ninference problem in a probabilistic extension of answer set programs.\nExperiments show that the probabilistic inference enables the efficient\nlabeling of claims with interpretable explanations, and the quality of the\nresults is higher than state of the art baselines.", "doi": "", "date": "2019-06-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.09198v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 108850251, "title": "Selecting Data to Clean for Fact Checking: Minimizing Uncertainty vs.\n  Maximizing Surprise", "abstract": "We study the optimization problem of selecting numerical quantities to clean\nin order to fact-check claims based on such data. Oftentimes, such claims are\ntechnically correct, but they can still mislead for two reasons. First, data\nmay contain uncertainty and errors. Second, data can be \"fished\" to advance\nparticular positions. In practice, fact-checkers cannot afford to clean all\ndata and must choose to clean what \"matters the most\" to checking a claim. We\nexplore alternative definitions of what \"matters the most\": one is to ascertain\nclaim qualities (by minimizing uncertainty in these measures), while an\nalternative is just to counter the claim (by maximizing the probability of\nfinding a counterargument). We show whether the two objectives align with each\nother, with important implications on when fact-checkers should exercise care\nin selective data cleaning, to avoid potential bias introduced by their desire\nto counter claims. We develop efficient algorithms for solving the various\nvariants of the optimization problem, showing significant improvements over\nnaive solutions. The problem is particularly challenging because the objectives\nin the fact-checking context are complex, non-linear functions over data. We\nobtain results that generalize to a large class of functions, with potential\napplications beyond fact-checking.", "doi": "10.14778/3358701.3358708", "date": "2019-09-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.05380v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2475878305, "title": "A Context-Aware Approach for Detecting Check-Worthy Claims in Political\n  Debates", "abstract": "In the context of investigative journalism, we address the problem of\nautomatically identifying which claims in a given document are most worthy and\nshould be prioritized for fact-checking. Despite its importance, this is a\nrelatively understudied problem. Thus, we create a new dataset of political\ndebates, containing statements that have been fact-checked by nine reputable\nsources, and we train machine learning models to predict which claims should be\nprioritized for fact-checking, i.e., we model the problem as a ranking task.\nUnlike previous work, which has looked primarily at sentences in isolation, in\nthis paper we focus on a rich input representation modeling the context:\nrelationship between the target statement and the larger context of the debate,\ninteraction between the opponents, and reaction by the moderator and by the\npublic. Our experiments show state-of-the-art results, outperforming a strong\nrivaling system by a margin, while also confirming the importance of the\ncontextual information.", "doi": "", "date": "2019-12-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1912.08084v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1529029191, "title": "Attributed Multi-Relational Attention Network for Fact-checking URL\n  Recommendation", "abstract": "To combat fake news, researchers mostly focused on detecting fake news and\njournalists built and maintained fact-checking sites (e.g., Snopes.com and\nPolitifact.com). However, fake news dissemination has been greatly promoted via\nsocial media sites, and these fact-checking sites have not been fully utilized.\nTo overcome these problems and complement existing methods against fake news,\nin this paper we propose a deep-learning based fact-checking URL recommender\nsystem to mitigate impact of fake news in social media sites such as Twitter\nand Facebook. In particular, our proposed framework consists of a\nmulti-relational attentive module and a heterogeneous graph attention network\nto learn complex/semantic relationship between user-URL pairs, user-user pairs,\nand URL-URL pairs. Extensive experiments on a real-world dataset show that our\nproposed framework outperforms eight state-of-the-art recommendation models,\nachieving at least 3~5.3% improvement.", "doi": "", "date": "2020-01-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.02214v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2086619452, "title": "Can We Spot the \"Fake News\" Before It Was Even Written?", "abstract": "Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n\"fake news.\" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.", "doi": "", "date": "2020-08-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.04374v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2067170690, "title": "The Coronavirus is a Bioweapon: Analysing Coronavirus Fact-Checked\n  Stories", "abstract": "The 2020 coronavirus pandemic has heightened the need to flag\ncoronavirus-related misinformation, and fact-checking groups have taken to\nverifying misinformation on the Internet. We explore stories reported by\nfact-checking groups PolitiFact, Poynter and Snopes from January to June 2020,\ncharacterising them into six story clusters before then analyse time-series and\nstory validity trends and the level of agreement across sites. We further break\ndown the story clusters into more granular story types by proposing a unique\nautomated method with a BERT classifier, which can be used to classify diverse\nstory sources, in both fact-checked stories and tweets.", "doi": "", "date": "2021-04-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.01215v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1962054596, "title": "WikiCheck: An end-to-end open source Automatic Fact-Checking API based\n  on Wikipedia", "abstract": "With the growth of fake news and disinformation, the NLP community has been\nworking to assist humans in fact-checking. However, most academic research has\nfocused on model accuracy without paying attention to resource efficiency,\nwhich is crucial in real-life scenarios. In this work, we review the\nState-of-the-Art datasets and solutions for Automatic Fact-checking and test\ntheir applicability in production environments. We discover overfitting issues\nin those models, and we propose a data filtering method that improves the\nmodel's performance and generalization. Then, we design an unsupervised\nfine-tuning of the Masked Language models to improve its accuracy working with\nWikipedia. We also propose a novel query enhancing method to improve evidence\ndiscovery using the Wikipedia Search API. Finally, we present a new\nfact-checking system, the \\textit{WikiCheck} API that automatically performs a\nfacts validation process based on the Wikipedia knowledge base. It is\ncomparable to SOTA solutions in terms of accuracy and can be used on low-memory\nCPU instances.", "doi": "", "date": "2021-09-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2109.00835v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 437533539, "title": "Anatomy of an online misinformation network", "abstract": "Massive amounts of fake news and conspiratorial content have spread over\nsocial media before and after the 2016 US Presidential Elections despite\nintense fact-checking efforts. How do the spread of misinformation and\nfact-checking compete? What are the structural and dynamic characteristics of\nthe core of the misinformation diffusion network, and who are its main\npurveyors? How to reduce the overall amount of misinformation? To explore these\nquestions we built Hoaxy, an open platform that enables large-scale, systematic\nstudies of how misinformation and fact-checking spread and compete on Twitter.\nHoaxy filters public tweets that include links to unverified claims or\nfact-checking articles. We perform k-core decomposition on a diffusion network\nobtained from two million retweets produced by several hundred thousand\naccounts over the six months before the election. As we move from the periphery\nto the core of the network, fact-checking nearly disappears, while social bots\nproliferate. The number of users in the main core reaches equilibrium around\nthe time of the election, with limited churn and increasingly dense\nconnections. We conclude by quantifying how effectively the network can be\ndisrupted by penalizing the most central nodes. These findings provide a first\nlook at the anatomy of a massive online misinformation diffusion network.", "doi": "10.1371/journal.pone.0196087", "date": "2018-01-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1801.06122v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4147291487, "title": "Hoaxy: A Platform for Tracking Online Misinformation", "abstract": "Massive amounts of misinformation have been observed to spread in\nuncontrolled fashion across social media. Examples include rumors, hoaxes, fake\nnews, and conspiracy theories. At the same time, several journalistic\norganizations devote significant efforts to high-quality fact checking of\nonline claims. The resulting information cascades contain instances of both\naccurate and inaccurate information, unfold over multiple time scales, and\noften reach audiences of considerable size. All these factors pose challenges\nfor the study of the social dynamics of online news sharing. Here we introduce\nHoaxy, a platform for the collection, detection, and analysis of online\nmisinformation and its related fact-checking efforts. We discuss the design of\nthe platform and present a preliminary analysis of a sample of public tweets\ncontaining both fake news and fact checking. We find that, in the aggregate,\nthe sharing of fact-checking content typically lags that of misinformation by\n10--20 hours. Moreover, fake news are dominated by very active users, while\nfact checking is a more grass-roots activity. With the increasing risks\nconnected to massive online misinformation, social news observatories have the\npotential to help researchers, journalists, and the general public understand\nthe dynamics of real and fake news sharing.", "doi": "10.1145/2872518.2890098", "date": "2016-03-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1603.01511v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4006939198, "title": "A Richly Annotated Corpus for Different Tasks in Automated Fact-Checking", "abstract": "Automated fact-checking based on machine learning is a promising approach to\nidentify false information distributed on the web. In order to achieve\nsatisfactory performance, machine learning methods require a large corpus with\nreliable annotations for the different tasks in the fact-checking process.\nHaving analyzed existing fact-checking corpora, we found that none of them\nmeets these criteria in full. They are either too small in size, do not provide\ndetailed annotations, or are limited to a single domain. Motivated by this gap,\nwe present a new substantially sized mixed-domain corpus with annotations of\ngood quality for the core fact-checking tasks: document retrieval, evidence\nextraction, stance detection, and claim validation. To aid future corpus\nconstruction, we describe our methodology for corpus creation and annotation,\nand demonstrate that it results in substantial inter-annotator agreement. As\nbaselines for future research, we perform experiments on our corpus with a\nnumber of model architectures that reach high performance in similar problem\nsettings. Finally, to support the development of future models, we provide a\ndetailed error analysis for each of the tasks. Our results show that the\nrealistic, multi-domain setting defined by our data poses new challenges for\nthe existing models, providing opportunities for considerable improvement by\nfuture systems.", "doi": "", "date": "2019-10-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.01214v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2510762461, "title": "Claim Matching Beyond English to Scale Global Fact-Checking", "abstract": "Manual fact-checking does not scale well to serve the needs of the internet.\nThis issue is further compounded in non-English contexts. In this paper, we\ndiscuss claim matching as a possible solution to scale fact-checking. We define\nclaim matching as the task of identifying pairs of textual messages containing\nclaims that can be served with one fact-check. We construct a novel dataset of\nWhatsApp tipline and public group messages alongside fact-checked claims that\nare first annotated for containing \"claim-like statements\" and then matched\nwith potentially similar items and annotated for claim matching. Our dataset\ncontains content in high-resource (English, Hindi) and lower-resource (Bengali,\nMalayalam, Tamil) languages. We train our own embedding model using knowledge\ndistillation and a high-quality \"teacher\" model in order to address the\nimbalance in embedding quality between the low- and high-resource languages in\nour dataset. We provide evaluations on the performance of our solution and\ncompare with baselines and existing state-of-the-art multilingual embedding\nmodels, namely LASER and LaBSE. We demonstrate that our performance exceeds\nLASER and LaBSE in all settings. We release our annotated datasets, codebooks,\nand trained embedding model to allow for further research.", "doi": "", "date": "2021-06-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.00853v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3749142344, "title": "The Role of the Crowd in Countering Misinformation: A Case Study of the\n  COVID-19 Infodemic", "abstract": "Fact checking by professionals is viewed as a vital defense in the fight\nagainst misinformation.While fact checking is important and its impact has been\nsignificant, fact checks could have limited visibility and may not reach the\nintended audience, such as those deeply embedded in polarized communities.\nConcerned citizens (i.e., the crowd), who are users of the platforms where\nmisinformation appears, can play a crucial role in disseminating fact-checking\ninformation and in countering the spread of misinformation. To explore if this\nis the case, we conduct a data-driven study of misinformation on the Twitter\nplatform, focusing on tweets related to the COVID-19 pandemic, analyzing the\nspread of misinformation, professional fact checks, and the crowd response to\npopular misleading claims about COVID-19. In this work, we curate a dataset of\nfalse claims and statements that seek to challenge or refute them. We train a\nclassifier to create a novel dataset of 155,468 COVID-19-related tweets,\ncontaining 33,237 false claims and 33,413 refuting arguments.Our findings show\nthat professional fact-checking tweets have limited volume and reach. In\ncontrast, we observe that the surge in misinformation tweets results in a quick\nresponse and a corresponding increase in tweets that refute such\nmisinformation. More importantly, we find contrasting differences in the way\nthe crowd refutes tweets, some tweets appear to be opinions, while others\ncontain concrete evidence, such as a link to a reputed source. Our work\nprovides insights into how misinformation is organically countered in social\nplatforms by some of their users and the role they play in amplifying\nprofessional fact checks.These insights could lead to development of tools and\nmechanisms that can empower concerned citizens in combating misinformation. The\ncode and data can be found in\nhttp://claws.cc.gatech.edu/covid_counter_misinformation.html.", "doi": "", "date": "2020-11-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.05773v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2287685030, "title": "TMLab SRPOL at SemEval-2019 Task 8: Fact Checking in Community Question\n  Answering Forums", "abstract": "The article describes our submission to SemEval 2019 Task 8 on Fact-Checking\nin Community Forums. The systems under discussion participated in Subtask A:\ndecide whether a question asks for factual information, opinion/advice or is\njust socializing. Our primary submission was ranked as the second one among all\nparticipants in the official evaluation phase. The article presents our primary\nsolution: Deeply Regularized Residual Neural Network (DRR NN) with Universal\nSentence Encoder embeddings. This is followed by a description of two\ncontrastive solutions based on ensemble methods.", "doi": "", "date": "2019-05-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.01515v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 23239651, "title": "FAKTA: An Automatic End-to-End Fact Checking System", "abstract": "We present FAKTA which is a unified framework that integrates various\ncomponents of a fact checking process: document retrieval from media sources\nwith various types of reliability, stance detection of documents with respect\nto given claims, evidence extraction, and linguistic analysis. FAKTA predicts\nthe factuality of given claims and provides evidence at the document and\nsentence level to explain its predictions", "doi": "", "date": "2019-06-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.04164v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3783667607, "title": "HoaxItaly: a collection of Italian disinformation and fact-checking\n  stories shared on Twitter in 2019", "abstract": "We released over 1 million tweets shared during 2019 and containing links to\nthousands of news articles published on two classes of Italian outlets: (1)\ndisinformation websites, i.e. outlets which have been repeatedly flagged by\njournalists and fact-checkers for producing low-credibility content such as\nfalse news, hoaxes, click-bait, misleading and hyper-partisan stories; (2)\nfact-checking websites which notably debunk and verify online news and claims.\nThe dataset, which includes also title and body for approximately 37k news\narticles, is publicly available at https://doi.org/10.7910/DVN/ PGVDHX.", "doi": "", "date": "2020-01-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.10926v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1671282522, "title": "Checking Fact Worthiness using Sentence Embeddings", "abstract": "Checking and confirming factual information in texts and speeches is vital to\ndetermine the veracity and correctness of the factual statements. This work was\npreviously done by journalists and other manual means but it is a\ntime-consuming task. With the advancements in Information Retrieval and NLP,\nresearch in the area of Fact-checking is getting attention for automating it.\nCLEF-2018 and 2019 organised tasks related to Fact-checking and invited\nparticipants. This project focuses on CLEF-2019 Task-1 Check-Worthiness and\nexperiments using the latest Sentence-BERT pre-trained embeddings, topic\nModeling and sentiment score are performed. Evaluation metrics such as MAP,\nMean Reciprocal Rank, Mean R-Precision and Mean Precision@N present the\nimprovement in the results using the techniques.", "doi": "", "date": "2020-12-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.09263v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3854541789, "title": "Self-Supervised Claim Identification for Automated Fact Checking", "abstract": "We propose a novel, attention-based self-supervised approach to identify\n\"claim-worthy\" sentences in a fake news article, an important first step in\nautomated fact-checking. We leverage \"aboutness\" of headline and content using\nattention mechanism for this task. The identified claims can be used for\ndownstream task of claim verification for which we are releasing a benchmark\ndataset of manually selected compelling articles with veracity labels and\nassociated evidence. This work goes beyond stylistic analysis to identifying\ncontent that influences reader belief. Experiments with three datasets show the\nstrength of our model. Data and code available at\nhttps://github.com/architapathak/Self-Supervised-ClaimIdentification", "doi": "", "date": "2021-02-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.02335v1", "pdf": ""}, "publisher-venue": "ICON 2020", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1677678114, "title": "Extractive and Abstractive Explanations for Fact-Checking and Evaluation\n  of News", "abstract": "In this paper, we explore the construction of natural language explanations\nfor news claims, with the goal of assisting fact-checking and news evaluation\napplications. We experiment with two methods: (1) an extractive method based on\nBiased TextRank -- a resource-effective unsupervised graph-based algorithm for\ncontent extraction; and (2) an abstractive method based on the GPT-2 language\nmodel. We perform comparative evaluations on two misinformation datasets in the\npolitical and health news domains, and find that the extractive method shows\nthe most promise.", "doi": "", "date": "2021-04-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.12918v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4250393688, "title": "A Multi-Level Attention Model for Evidence-Based Fact Checking", "abstract": "Evidence-based fact checking aims to verify the truthfulness of a claim\nagainst evidence extracted from textual sources. Learning a representation that\neffectively captures relations between a claim and evidence can be challenging.\nRecent state-of-the-art approaches have developed increasingly sophisticated\nmodels based on graph structures. We present a simple model that can be trained\non sequence structures. Our model enables inter-sentence attentions at\ndifferent levels and can benefit from joint training. Results on a large-scale\ndataset for Fact Extraction and VERification (FEVER) show that our model\noutperforms the graph-based approaches and yields 1.09% and 1.42% improvements\nin label accuracy and FEVER score, respectively, over the best published model.", "doi": "", "date": "2021-06-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.00950v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3798674009, "title": "Finding Streams in Knowledge Graphs to Support Fact Checking", "abstract": "The volume and velocity of information that gets generated online limits\ncurrent journalistic practices to fact-check claims at the same rate.\nComputational approaches for fact checking may be the key to help mitigate the\nrisks of massive misinformation spread. Such approaches can be designed to not\nonly be scalable and effective at assessing veracity of dubious claims, but\nalso to boost a human fact checker's productivity by surfacing relevant facts\nand patterns to aid their analysis. To this end, we present a novel,\nunsupervised network-flow based approach to determine the truthfulness of a\nstatement of fact expressed in the form of a (subject, predicate, object)\ntriple. We view a knowledge graph of background information about real-world\nentities as a flow network, and knowledge as a fluid, abstract commodity. We\nshow that computational fact checking of such a triple then amounts to finding\na \"knowledge stream\" that emanates from the subject node and flows toward the\nobject node through paths connecting them. Evaluation on a range of real-world\nand hand-crafted datasets of facts related to entertainment, business, sports,\ngeography and more reveals that this network-flow model can be very effective\nin discerning true statements from false ones, outperforming existing\nalgorithms on many test cases. Moreover, the model is expressive in its ability\nto automatically discover several useful path patterns and surface relevant\nfacts that may help a human fact checker corroborate or refute a claim.", "doi": "", "date": "2017-08-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1708.07239v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 376754638, "title": "Accenture at CheckThat! 2020: If you say so: Post-hoc fact-checking of\n  claims using transformer-based models", "abstract": "We introduce the strategies used by the Accenture Team for the CLEF2020\nCheckThat! Lab, Task 1, on English and Arabic. This shared task evaluated\nwhether a claim in social media text should be professionally fact checked. To\na journalist, a statement presented as fact, which would be of interest to a\nlarge audience, requires professional fact-checking before dissemination. We\nutilized BERT and RoBERTa models to identify claims in social media text a\nprofessional fact-checker should review, and rank these in priority order for\nthe fact-checker. For the English challenge, we fine-tuned a RoBERTa model and\nadded an extra mean pooling layer and a dropout layer to enhance\ngeneralizability to unseen text. For the Arabic task, we fine-tuned\nArabic-language BERT models and demonstrate the use of back-translation to\namplify the minority class and balance the dataset. The work presented here was\nscored 1st place in the English track, and 1st, 2nd, 3rd, and 4th place in the\nArabic track.", "doi": "", "date": "2020-09-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.02431v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1852971266, "title": "Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models", "abstract": "While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.", "doi": "", "date": "2020-09-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.02931v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2464997893, "title": "Fact-checking Initiatives in Bangladesh, India, and Nepal: A Study of\n  User Engagement and Challenges", "abstract": "Fake news and misinformation spread in developing countries as fast as they\ndo in developed countries with increasing penetration of the internet and\nsocial media. However, fighting misinformation is more difficult in developing\ncountries where resources and necessary technologies are scarce. This study\nprovides an understanding of the challenges various fact-checking initiatives\nface in three South Asian countries--Bangladesh, India, and Nepal. In-depth\ninterviews were conducted with senior editors of six fact-checking initiatives.\nChallenges identified include lack of resources, technologies, and political\npressure. An analysis of Facebook pages of these initiatives shows increasing\nuser engagement with their posts.", "doi": "", "date": "2018-11-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.01806v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4194740806, "title": "Fully Automated Fact Checking Using External Sources", "abstract": "Given the constantly growing proliferation of false claims online in recent\nyears, there has been also a growing research interest in automatically\ndistinguishing false rumors from factually true claims. Here, we propose a\ngeneral-purpose framework for fully-automatic fact checking using external\nsources, tapping the potential of the entire Web as a knowledge source to\nconfirm or reject a claim. Our framework uses a deep neural network with LSTM\ntext encoding to combine semantic kernels with task-specific embeddings that\nencode a claim together with pieces of potentially-relevant text fragments from\nthe Web, taking the source reliability into account. The evaluation results\nshow good performance on two different tasks and datasets: (i) rumor detection\nand (ii) fact checking of the answers to a question in community question\nanswering forums.", "doi": "", "date": "2017-10-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1710.00341v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3011474971, "title": "ClaimRank: Detecting Check-Worthy Claims in Arabic and English", "abstract": "We present ClaimRank, an online system for detecting check-worthy claims.\nWhile originally trained on political debates, the system can work for any kind\nof text, e.g., interviews or regular news articles. Its aim is to facilitate\nmanual fact-checking efforts by prioritizing the claims that fact-checkers\nshould consider first. ClaimRank supports both Arabic and English, it is\ntrained on actual annotations from nine reputable fact-checking organizations\n(PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago Tribune, The Guardian, and\nWashington Post), and thus it can mimic the claim selection strategies for each\nand any of them, as well as for the union of them all.", "doi": "", "date": "2018-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.07587v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 476377564, "title": "SemEval-2019 Task 8: Fact Checking in Community Question Answering\n  Forums", "abstract": "We present SemEval-2019 Task 8 on Fact Checking in Community Question\nAnswering Forums, which features two subtasks. Subtask A is about deciding\nwhether a question asks for factual information vs. an opinion/advice vs. just\nsocializing. Subtask B asks to predict whether an answer to a factual question\nis true, false or not a proper answer. We received 17 official submissions for\nsubtask A and 11 official submissions for Subtask B. For subtask A, all systems\nimproved over the majority class baseline. For Subtask B, all systems were\nbelow a majority class baseline, but several systems were very close to it. The\nleaderboard and the data from the competition can be found at\nhttp://competitions.codalab.org/competitions/20022", "doi": "", "date": "2019-05-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.01727v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2820827416, "title": "It Takes Nine to Smell a Rat: Neural Multi-Task Learning for\n  Check-Worthiness Prediction", "abstract": "We propose a multi-task deep-learning approach for estimating the\ncheck-worthiness of claims in political debates. Given a political debate, such\nas the 2016 US Presidential and Vice-Presidential ones, the task is to predict\nwhich statements in the debate should be prioritized for fact-checking. While\ndifferent fact-checking organizations would naturally make different choices\nwhen analyzing the same debate, we show that it pays to learn from multiple\nsources simultaneously (PolitiFact, FactCheck, ABC, CNN, NPR, NYT, Chicago\nTribune, The Guardian, and Washington Post) in a multi-task learning setup,\neven when a particular source is chosen as a target to imitate. Our evaluation\nshows state-of-the-art results on a standard dataset for the task of\ncheck-worthiness prediction.", "doi": "", "date": "2019-08-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.07912v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3156638161, "title": "Generating Fact Checking Explanations", "abstract": "Most existing work on automated fact checking is concerned with predicting\nthe veracity of claims based on metadata, social network spread, language used\nin claims, and, more recently, evidence supporting or denying claims. A crucial\npiece of the puzzle that is still missing is to understand how to automate the\nmost elaborate part of the process -- generating justifications for verdicts on\nclaims. This paper provides the first study of how these explanations can be\ngenerated automatically based on available claim context, and how this task can\nbe modelled jointly with veracity prediction. Our results indicate that\noptimising both objectives at the same time, rather than training them\nseparately, improves the performance of a fact checking system. The results of\na manual evaluation further suggest that the informativeness, coverage and\noverall quality of the generated explanations are also improved in the\nmulti-task model.", "doi": "", "date": "2020-04-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.05773v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 983898920, "title": "DeSePtion: Dual Sequence Prediction and Adversarial Examples for\n  Improved Fact-Checking", "abstract": "The increased focus on misinformation has spurred development of data and\nsystems for detecting the veracity of a claim as well as retrieving\nauthoritative evidence. The Fact Extraction and VERification (FEVER) dataset\nprovides such a resource for evaluating end-to-end fact-checking, requiring\nretrieval of evidence from Wikipedia to validate a veracity prediction. We show\nthat current systems for FEVER are vulnerable to three categories of realistic\nchallenges for fact-checking -- multiple propositions, temporal reasoning, and\nambiguity and lexical variation -- and introduce a resource with these types of\nclaims. Then we present a system designed to be resilient to these \"attacks\"\nusing multiple pointer networks for document selection and jointly modeling a\nsequence of evidence sentences and veracity relation predictions. We find that\nin handling these attacks we obtain state-of-the-art results on FEVER, largely\ndue to improved evidence retrieval.", "doi": "", "date": "2020-04-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.12864v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1634102055, "title": "A Dataset of Fact-Checked Images Shared on WhatsApp During the Brazilian\n  and Indian Elections", "abstract": "Recently, messaging applications, such as WhatsApp, have been reportedly\nabused by misinformation campaigns, especially in Brazil and India. A notable\nform of abuse in WhatsApp relies on several manipulated images and memes\ncontaining all kinds of fake stories. In this work, we performed an extensive\ndata collection from a large set of WhatsApp publicly accessible groups and\nfact-checking agency websites. This paper opens a novel dataset to the research\ncommunity containing fact-checked fake images shared through WhatsApp for two\ndistinct scenarios known for the spread of fake news on the platform: the 2018\nBrazilian elections and the 2019 Indian elections.", "doi": "", "date": "2020-05-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.02443v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 602647854, "title": "BRENDA: Browser Extension for Fake News Detection", "abstract": "Misinformation such as fake news has drawn a lot of attention in recent\nyears. It has serious consequences on society, politics and economy. This has\nlead to a rise of manually fact-checking websites such as Snopes and\nPolitifact. However, the scale of misinformation limits their ability for\nverification. In this demonstration, we propose BRENDA a browser extension\nwhich can be used to automate the entire process of credibility assessments of\nfalse claims. Behind the scenes BRENDA uses a tested deep neural network\narchitecture to automatically identify fact check worthy claims and classifies\nas well as presents the result along with evidence to the user. Since BRENDA is\na browser extension, it facilities fast automated fact checking for the end\nuser without having to leave the Webpage.", "doi": "10.1145/3397271.3401396", "date": "2020-05-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.13270v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 759351968, "title": "Checkworthiness in Automatic Claim Detection Models: Definitions and\n  Analysis of Datasets", "abstract": "Public, professional and academic interest in automated fact-checking has\ndrastically increased over the past decade, with many aiming to automate one of\nthe first steps in a fact-check procedure: the selection of so-called\ncheckworthy claims. However, there is little agreement on the definition and\ncharacteristics of checkworthiness among fact-checkers, which is consequently\nreflected in the datasets used for training and testing checkworthy claim\ndetection models. After elaborate analysis of checkworthy claim selection\nprocedures in fact-check organisations and analysis of state-of-the-art claim\ndetection datasets, checkworthiness is defined as the concept of having a\nspatiotemporal and context-dependent worth and need to have the correctness of\nthe objectivity it conveys verified. This is irrespective of the claim's\nperceived veracity judgement by an individual based on prior knowledge and\nbeliefs. Concerning the characteristics of current datasets, it is argued that\nthe data is not only highly imbalanced and noisy, but also too limited in scope\nand language. Furthermore, we believe that the subjective concept of\ncheckworthiness might not be a suitable filter for claim detection.", "doi": "10.1007/978-3-030-61841-4_1", "date": "2020-08-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.08854v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3191332844, "title": "Multi-Hop Fact Checking of Political Claims", "abstract": "Recent work has proposed multi-hop models and datasets for studying complex\nnatural language reasoning. One notable task requiring multi-hop reasoning is\nfact checking, where a set of connected evidence pieces leads to the final\nverdict of a claim. However, existing datasets either do not provide\nannotations for gold evidence pages, or the only dataset which does (FEVER)\nmostly consists of claims which can be fact-checked with simple reasoning and\nis constructed artificially. Here, we study more complex claim verification of\nnaturally occurring claims with multiple hops over interconnected evidence\nchunks. We: 1) construct a small annotated dataset, PolitiHop, of evidence\nsentences for claim verification; 2) compare it to existing multi-hop datasets;\nand 3) study how to transfer knowledge from more extensive in- and\nout-of-domain resources to PolitiHop. We find that the task is complex and\nachieve the best performance with an architecture that specifically models\nreasoning over evidence pieces in combination with in-domain transfer learning.", "doi": "", "date": "2020-09-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.06401v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1673406359, "title": "Time-Aware Evidence Ranking for Fact-Checking", "abstract": "Truth can vary over time. Fact-checking decisions on claim veracity should\ntherefore take into account temporal information of both the claim and\nsupporting or refuting evidence. In this work, we investigate the hypothesis\nthat the timestamp of a Web page is crucial to how it should be ranked for a\ngiven claim. We delineate four temporal ranking methods that constrain evidence\nranking differently and simulate hypothesis-specific evidence rankings given\nthe evidence timestamps as gold standard. Evidence ranking in three\nfact-checking models is ultimately optimized using a learning-to-rank loss\nfunction. Our study reveals that time-aware evidence ranking not only surpasses\nrelevance assumptions based purely on semantic similarity or position in a\nsearch results list, but also improves veracity predictions of time-sensitive\nclaims in particular.", "doi": "", "date": "2020-09-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.06402v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2575103845, "title": "Generating Label Cohesive and Well-Formed Adversarial Claims", "abstract": "Adversarial attacks reveal important vulnerabilities and flaws of trained\nmodels. One potent type of attack are universal adversarial triggers, which are\nindividual n-grams that, when appended to instances of a class under attack,\ncan trick a model into predicting a target class. However, for inference tasks\nsuch as fact checking, these triggers often inadvertently invert the meaning of\ninstances they are inserted in. In addition, such attacks produce semantically\nnonsensical inputs, as they simply concatenate triggers to existing samples.\nHere, we investigate how to generate adversarial attacks against fact checking\nsystems that preserve the ground truth meaning and are semantically valid. We\nextend the HotFlip attack algorithm used for universal trigger generation by\njointly minimising the target class loss of a fact checking model and the\nentailment class loss of an auxiliary natural language inference model. We then\ntrain a conditional language model to generate semantically valid statements,\nwhich include the found universal triggers. We find that the generated attacks\nmaintain the directionality and semantic validity of the claim better than\nprevious work.", "doi": "", "date": "2020-09-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.08205v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4082178080, "title": "Check Mate: Prioritizing User Generated Multi-Media Content for\n  Fact-Checking", "abstract": "Volume of content and misinformation on social media is rapidly increasing.\nThere is a need for systems that can support fact checkers by prioritizing\ncontent that needs to be fact checked. Prior research on prioritizing content\nfor fact-checking has focused on news media articles, predominantly in English\nlanguage. Increasingly, misinformation is found in user-generated content. In\nthis paper we present a novel dataset that can be used to prioritize\ncheck-worthy posts from multi-media content in Hindi. It is unique in its 1)\nfocus on user generated content, 2) language and 3) accommodation of\nmulti-modality in social media posts. In addition, we also provide metadata for\neach post such as number of shares and likes of the post on ShareChat, a\npopular Indian social media platform, that allows for correlative analysis\naround virality and misinformation. The data is accessible on Zenodo\n(https://zenodo.org/record/4032629) under Creative Commons Attribution License\n(CC BY 4.0).", "doi": "", "date": "2020-10-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.13387v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1014364118, "title": "Fact Checking via Path Embedding and Aggregation", "abstract": "Knowledge graphs (KGs) are a useful source of background knowledge to\n(dis)prove facts of the form (s, p, o). Finding paths between s and o is the\ncornerstone of several fact-checking approaches. While paths are useful to\n(visually) explain why a given fact is true or false, it is not completely\nclear how to identify paths that are most relevant to a fact, encode them and\nweigh their importance. The goal of this paper is to present the Fact Checking\nvia path Embedding and Aggregation (FEA) system. FEA starts by carefully\ncollecting the paths between s and o that are most semantically related to the\ndomain of p. However, instead of directly working with this subset of all\npaths, it learns vectorized path representations, aggregates them according to\ndifferent strategies, and use them to finally (dis)prove a fact. We conducted a\nlarge set of experiments on a variety of KGs and found that our hybrid solution\nbrings some benefits in terms of performance.", "doi": "", "date": "2020-11-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.08028v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2520965492, "title": "WhatTheWikiFact: Fact-Checking Claims Against Wikipedia", "abstract": "The rise of Internet has made it a major source of information.\nUnfortunately, not all information online is true, and thus a number of\nfact-checking initiatives have been launched, both manual and automatic. Here,\nwe present our contribution in this regard: WhatTheWikiFact, a system for\nautomatic claim verification using Wikipedia. The system predicts the veracity\nof an input claim, and it further shows the evidence it has retrieved as part\nof the verification process. It shows confidence scores and a list of relevant\nWikipedia articles, together with detailed information about each article,\nincluding the phrase used to retrieve it, the most relevant sentences it\ncontains, and their stances with respect to the input claim, with associated\nprobabilities.", "doi": "", "date": "2021-04-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.00826v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1969869776, "title": "Tiplines to Combat Misinformation on Encrypted Platforms: A Case Study\n  of the 2019 Indian Election on WhatsApp", "abstract": "There is currently no easy way to fact-check content on WhatsApp and other\nend-to-end encrypted platforms at scale. In this paper, we analyze the\nusefulness of a crowd-sourced \"tipline\" through which users can submit content\n(\"tips\") that they want fact-checked. We compare the tips sent to a WhatsApp\ntipline run during the 2019 Indian national elections with the messages\ncirculating in large, public groups on WhatsApp and other social media\nplatforms during the same period. We find that tiplines are a very useful lens\ninto WhatsApp conversations: a significant fraction of messages and images sent\nto the tipline match with the content being shared on public WhatsApp groups\nand other social media. Our analysis also shows that tiplines cover the most\npopular content well, and a majority of such content is often shared to the\ntipline before appearing in large, public WhatsApp groups. Overall, our\nfindings suggest tiplines can be an effective source for discovering content to\nfact-check.", "doi": "", "date": "2021-06-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.04726v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3432556329, "title": "X-FACT: A New Benchmark Dataset for Multilingual Fact Checking", "abstract": "In this work, we introduce X-FACT: the largest publicly available\nmultilingual dataset for factual verification of naturally existing real-world\nclaims. The dataset contains short statements in 25 languages and is labeled\nfor veracity by expert fact-checkers. The dataset includes a multilingual\nevaluation benchmark that measures both out-of-domain generalization, and\nzero-shot capabilities of the multilingual models. Using state-of-the-art\nmultilingual transformer-based models, we develop several automated\nfact-checking models that, along with textual claims, make use of additional\nmetadata and evidence from news stories retrieved using a search engine.\nEmpirically, our best model attains an F-score of around 40%, suggesting that\nour dataset is a challenging benchmark for evaluation of multilingual\nfact-checking models.", "doi": "", "date": "2021-06-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.09248v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1170808741, "title": "Combating fake news by empowering fact-checked news spread via\n  topology-based interventions", "abstract": "Rapid information diffusion and large-scaled information cascades can enable\nthe undesired spread of false information. A small-scaled false information\noutbreak may potentially lead to an infodemic. We propose a novel information\ndiffusion and intervention technique to combat the spread of false news. As\nfalse information is often spreading faster in a social network, the proposed\ndiffusion methodology inhibits the spread of false news by proactively\ndiffusing the fact-checked information. Our methodology mainly relies on\ndefining the potential super-spreaders in a social network based on their\ncentrality metrics. We run an extensive set of experiments on different\nnetworks to investigate the impact of centrality metrics on the performance of\nthe proposed diffusion and intervention models. The obtained results\ndemonstrate that empowering the diffusion of fact-checked news combats the\nspread of false news further and deeper in social networks.", "doi": "", "date": "2021-07-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.05016v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4070026767, "title": "Leveraging the Crowd to Detect and Reduce the Spread of Fake News and\n  Misinformation", "abstract": "Online social networking sites are experimenting with the following\ncrowd-powered procedure to reduce the spread of fake news and misinformation:\nwhenever a user is exposed to a story through her feed, she can flag the story\nas misinformation and, if the story receives enough flags, it is sent to a\ntrusted third party for fact checking. If this party identifies the story as\nmisinformation, it is marked as disputed. However, given the uncertain number\nof exposures, the high cost of fact checking, and the trade-off between flags\nand exposures, the above mentioned procedure requires careful reasoning and\nsmart algorithms which, to the best of our knowledge, do not exist to date.\n  In this paper, we first introduce a flexible representation of the above\nprocedure using the framework of marked temporal point processes. Then, we\ndevelop a scalable online algorithm, Curb, to select which stories to send for\nfact checking and when to do so to efficiently reduce the spread of\nmisinformation with provable guarantees. In doing so, we need to solve a novel\nstochastic optimal control problem for stochastic differential equations with\njumps, which is of independent interest. Experiments on two real-world datasets\ngathered from Twitter and Weibo show that our algorithm may be able to\neffectively reduce the spread of fake news and misinformation.", "doi": "", "date": "2017-11-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.09918v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1930880460, "title": "Overview of the CLEF-2018 CheckThat! Lab on Automatic Identification and\n  Verification of Political Claims. Task 1: Check-Worthiness", "abstract": "We present an overview of the CLEF-2018 CheckThat! Lab on Automatic\nIdentification and Verification of Political Claims, with focus on Task 1:\nCheck-Worthiness. The task asks to predict which claims in a political debate\nshould be prioritized for fact-checking. In particular, given a debate or a\npolitical speech, the goal was to produce a ranked list of its sentences based\non their worthiness for fact checking. We offered the task in both English and\nArabic, based on debates from the 2016 US Presidential Campaign, as well as on\nsome speeches during and after the campaign. A total of 30 teams registered to\nparticipate in the Lab and seven teams actually submitted systems for Task~1.\nThe most successful approaches used by the participants relied on recurrent and\nmulti-layer neural networks, as well as on combinations of distributional\nrepresentations, on matchings claims' vocabulary against lexicons, and on\nmeasures of syntactic dependency. The best systems achieved mean average\nprecision of 0.18 and 0.15 on the English and on the Arabic test datasets,\nrespectively. This leaves large room for further improvement, and thus we\nrelease all datasets and the scoring scripts, which should enable further\nresearch in check-worthiness estimation.", "doi": "", "date": "2018-08-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1808.05542v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3203338498, "title": "Citation Needed: A Taxonomy and Algorithmic Assessment of Wikipedia's\n  Verifiability", "abstract": "Wikipedia is playing an increasingly central role on the web,and the policies\nits contributors follow when sourcing and fact-checking content affect million\nof readers. Among these core guiding principles, verifiability policies have a\nparticularly important role. Verifiability requires that information included\nin a Wikipedia article be corroborated against reliable secondary sources.\nBecause of the manual labor needed to curate and fact-check Wikipedia at scale,\nhowever, its contents do not always evenly comply with these policies.\nCitations (i.e. reference to external sources) may not conform to verifiability\nrequirements or may be missing altogether, potentially weakening the\nreliability of specific topic areas of the free encyclopedia. In this paper, we\naim to provide an empirical characterization of the reasons why and how\nWikipedia cites external sources to comply with its own verifiability\nguidelines. First, we construct a taxonomy of reasons why inline citations are\nrequired by collecting labeled data from editors of multiple Wikipedia language\neditions. We then collect a large-scale crowdsourced dataset of Wikipedia\nsentences annotated with categories derived from this taxonomy. Finally, we\ndesign and evaluate algorithmic models to determine if a statement requires a\ncitation, and to predict the citation reason based on our taxonomy. We evaluate\nthe robustness of such models across different classes of Wikipedia articles of\nvarying quality, as well as on an additional dataset of claims annotated for\nfact-checking purposes.", "doi": "", "date": "2019-02-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.11116v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 724805736, "title": "Neural Check-Worthiness Ranking with Weak Supervision: Finding Sentences\n  for Fact-Checking", "abstract": "Automatic fact-checking systems detect misinformation, such as fake news, by\n(i) selecting check-worthy sentences for fact-checking, (ii) gathering related\ninformation to the sentences, and (iii) inferring the factuality of the\nsentences. Most prior research on (i) uses hand-crafted features to select\ncheck-worthy sentences, and does not explicitly account for the recent finding\nthat the top weighted terms in both check-worthy and non-check-worthy sentences\nare actually overlapping [15]. Motivated by this, we present a neural\ncheck-worthiness sentence ranking model that represents each word in a sentence\nby \\textit{both} its embedding (aiming to capture its semantics) and its\nsyntactic dependencies (aiming to capture its role in modifying the semantics\nof other terms in the sentence). Our model is an end-to-end trainable neural\nnetwork for check-worthiness ranking, which is trained on large amounts of\nunlabelled data through weak supervision. Thorough experimental evaluation\nagainst state of the art baselines, with and without weak supervision, shows\nour model to be superior at all times (+13% in MAP and +28% at various\nPrecision cut-offs from the best baseline with statistical significance).\nEmpirical analysis of the use of weak supervision, word embedding pretraining\non domain-specific data, and the use of syntactic dependencies of our model\nreveals that check-worthy sentences contain notably more identical syntactic\ndependencies than non-check-worthy sentences.", "doi": "", "date": "2019-03-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.08404v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2227843256, "title": "Reasoning Over Semantic-Level Graph for Fact Checking", "abstract": "Fact checking is a challenging task because verifying the truthfulness of a\nclaim requires reasoning about multiple retrievable evidence. In this work, we\npresent a method suitable for reasoning about the semantic-level structure of\nevidence. Unlike most previous works, which typically represent evidence\nsentences with either string concatenation or fusing the features of isolated\nevidence sentences, our approach operates on rich semantic structures of\nevidence obtained by semantic role labeling. We propose two mechanisms to\nexploit the structure of evidence while leveraging the advances of pre-trained\nmodels like BERT, GPT or XLNet. Specifically, using XLNet as the backbone, we\nfirst utilize the graph structure to re-define the relative distances of words,\nwith the intuition that semantically related words should have short distances.\nThen, we adopt graph convolutional network and graph attention network to\npropagate and aggregate information from neighboring nodes on the graph. We\nevaluate our system on FEVER, a benchmark dataset for fact checking, and find\nthat rich structural information is helpful and both our graph-based mechanisms\nimprove the accuracy. Our model is the state-of-the-art system in terms of both\nofficial evaluation metrics, namely claim verification accuracy and FEVER\nscore.", "doi": "", "date": "2019-09-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.03745v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 22542311, "title": "CheckThat! at CLEF 2020: Enabling the Automatic Identification and\n  Verification of Claims in Social Media", "abstract": "We describe the third edition of the CheckThat! Lab, which is part of the\n2020 Cross-Language Evaluation Forum (CLEF). CheckThat! proposes four\ncomplementary tasks and a related task from previous lab editions, offered in\nEnglish, Arabic, and Spanish. Task 1 asks to predict which tweets in a Twitter\nstream are worth fact-checking. Task 2 asks to determine whether a claim posted\nin a tweet can be verified using a set of previously fact-checked claims. Task\n3 asks to retrieve text snippets from a given set of Web pages that would be\nuseful for verifying a target tweet's claim. Task 4 asks to predict the\nveracity of a target tweet's claim using a set of Web pages and potentially\nuseful snippets in them. Finally, the lab offers a fifth task that asks to\npredict the check-worthiness of the claims made in English political debates\nand speeches. CheckThat! features a full evaluation framework. The evaluation\nis carried out using mean average precision or precision at rank k for ranking\ntasks, and F1 for classification tasks.", "doi": "", "date": "2020-01-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.08546v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2929734270, "title": "Overview of CheckThat! 2020: Automatic Identification and Verification\n  of Claims in Social Media", "abstract": "We present an overview of the third edition of the CheckThat! Lab at CLEF\n2020. The lab featured five tasks in two different languages: English and\nArabic. The first four tasks compose the full pipeline of claim verification in\nsocial media: Task 1 on check-worthiness estimation, Task 2 on retrieving\npreviously fact-checked claims, Task 3 on evidence retrieval, and Task 4 on\nclaim verification. The lab is completed with Task 5 on check-worthiness\nestimation in political debates and speeches. A total of 67 teams registered to\nparticipate in the lab (up from 47 at CLEF 2019), and 23 of them actually\nsubmitted runs (compared to 14 at CLEF 2019). Most teams used deep neural\nnetworks based on BERT, LSTMs, or CNNs, and achieved sizable improvements over\nthe baselines on all tasks. Here we describe the tasks setup, the evaluation\nresults, and a summary of the approaches used by the participants, and we\ndiscuss some lessons learned. Last but not least, we release to the research\ncommunity all datasets from the lab as well as the evaluation scripts, which\nshould enable further research in the important tasks of check-worthiness\nestimation and automatic claim verification.", "doi": "", "date": "2020-07-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.07997v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 554682666, "title": "Factorization of Fact-Checks for Low Resource Indian Languages", "abstract": "The advancement in technology and accessibility of internet to each\nindividual is revolutionizing the real time information. The liberty to express\nyour thoughts without passing through any credibility check is leading to\ndissemination of fake content in the ecosystem. It can have disastrous effects\non both individuals and society as a whole. The amplification of fake news is\nbecoming rampant in India too. Debunked information often gets republished with\na replacement description, claiming it to depict some different incidence. To\ncurb such fabricated stories, it is necessary to investigate such deduplicates\nand false claims made in public. The majority of studies on automatic\nfact-checking and fake news detection is restricted to English only. But for a\ncountry like India where only 10% of the literate population speak English,\nrole of regional languages in spreading falsity cannot be undermined. In this\npaper, we introduce FactDRIL: the first large scale multilingual Fact-checking\nDataset for Regional Indian Languages. We collect an exhaustive dataset across\n7 months covering 11 low-resource languages. Our propose dataset consists of\n9,058 samples belonging to English, 5,155 samples to Hindi and remaining 8,222\nsamples are distributed across various regional languages, i.e. Bangla,\nMarathi, Malayalam, Telugu, Tamil, Oriya, Assamese, Punjabi, Urdu, Sinhala and\nBurmese. We also present the detailed characterization of three M's\n(multi-lingual, multi-media, multi-domain) in the FactDRIL accompanied with the\ncomplete list of other varied attributes making it a unique dataset to study.\nLastly, we present some potential use cases of the dataset. We expect this\ndataset will be a valuable resource and serve as a starting point to fight\nproliferation of fake news in low resource languages.", "doi": "", "date": "2021-02-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.11276v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2315472439, "title": "A Survey on Predicting the Factuality and the Bias of News Media", "abstract": "The present level of proliferation of fake, biased, and propagandistic\ncontent online has made it impossible to fact-check every single suspicious\nclaim or article, either manually or automatically. Thus, many researchers are\nshifting their attention to higher granularity, aiming to profile entire news\noutlets, which makes it possible to detect likely \"fake news\" the moment it is\npublished, by simply checking the reliability of its source. Source factuality\nis also an important element of systems for automatic fact-checking and \"fake\nnews\" detection, as they need to assess the reliability of the evidence they\nretrieve online. Political bias detection, which in the Western political\nlandscape is about predicting left-center-right bias, is an equally important\ntopic, which has experienced a similar shift towards profiling entire news\noutlets. Moreover, there is a clear connection between the two, as highly\nbiased media are less likely to be factual; yet, the two problems have been\naddressed separately. In this survey, we review the state of the art on media\nprofiling for factuality and bias, arguing for the need to model them jointly.\nWe further discuss interesting recent advances in using different information\nsources and modalities, which go beyond the text of the articles the target\nnews outlet has published. Finally, we discuss current challenges and outline\nfuture research directions.", "doi": "", "date": "2021-03-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.12506v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 785638926, "title": "FaVIQ: FAct Verification from Information-seeking Questions", "abstract": "Despite significant interest in developing general purpose fact checking\nmodels, it is challenging to construct a large-scale fact verification dataset\nwith realistic claims that would occur in the real world. Existing claims are\neither authored by crowdworkers, thereby introducing subtle biases that are\ndifficult to control for, or manually verified by professional fact checkers,\ncausing them to be expensive and limited in scale. In this paper, we construct\na challenging, realistic, and large-scale fact verification dataset called\nFaVIQ, using information-seeking questions posed by real users who do not know\nhow to answer. The ambiguity in information-seeking questions enables\nautomatically constructing true and false claims that reflect confusions arisen\nfrom users (e.g., the year of the movie being filmed vs. being released). Our\nclaims are verified to be natural, contain little lexical bias, and require a\ncomplete understanding of the evidence for verification. Our experiments show\nthat the state-of-the-art models are far from solving our new task. Moreover,\ntraining on our data helps in professional fact-checking, outperforming models\ntrained on the most widely used dataset FEVER or in-domain data by up to 17%\nabsolute. Altogether, our data will serve as a challenging benchmark for\nnatural language understanding and support future progress in professional fact\nchecking.", "doi": "", "date": "2021-07-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.02153v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 343071381, "title": "Predicting Factuality of Reporting and Bias of News Media Sources", "abstract": "We present a study on predicting the factuality of reporting and bias of news\nmedia. While previous work has focused on studying the veracity of claims or\ndocuments, here we are interested in characterizing entire news media. These\nare under-studied but arguably important research problems, both in their own\nright and as a prior for fact-checking systems. We experiment with a large list\nof news websites and with a rich set of features derived from (i) a sample of\narticles from the target news medium, (ii) its Wikipedia page, (iii) its\nTwitter account, (iv) the structure of its URL, and (v) information about the\nWeb traffic it attracts. The experimental results show sizable performance\ngains over the baselines, and confirm the importance of each feature type.", "doi": "", "date": "2018-10-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1810.01765v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2113540298, "title": "Unsupervised Question Answering for Fact-Checking", "abstract": "Recent Deep Learning (DL) models have succeeded in achieving human-level\naccuracy on various natural language tasks such as question-answering, natural\nlanguage inference (NLI), and textual entailment. These tasks not only require\nthe contextual knowledge but also the reasoning abilities to be solved\nefficiently. In this paper, we propose an unsupervised question-answering based\napproach for a similar task, fact-checking. We transform the FEVER dataset into\na Cloze-task by masking named entities provided in the claims. To predict the\nanswer token, we utilize pre-trained Bidirectional Encoder Representations from\nTransformers (BERT). The classifier computes label based on the correctly\nanswered questions and a threshold. Currently, the classifier is able to\nclassify the claims as \"SUPPORTS\" and \"MANUAL_REVIEW\". This approach achieves a\nlabel accuracy of 80.2% on the development set and 80.25% on the test set of\nthe transformed dataset.", "doi": "", "date": "2019-10-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.07154v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4064464143, "title": "Reversible bootstrap percolation: Fake news and fact checking", "abstract": "Bootstrap percolation has been used to describe opinion formation in society\nand other social and natural phenomena. The formal equation of the bootstrap\npercolation may have more than one solution, corresponding to several stable\nfixed points of the corresponding iteration process. We construct a reversible\nbootstrap percolation process, which converges to these extra solutions\ndisplaying a hysteresis typical of discontinuous phase transitions. This\nprocess provides a reasonable model for fake news spreading and the\neffectiveness of fact checking. We show that sometimes it is not sufficient to\ndiscard all the sources of fake news in order to reverse the belief of a\npopulation that formed under the influence of these sources.", "doi": "10.1103/physreve.101.042307", "date": "2019-10-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.09516v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4292765479, "title": "Fact Checking in Community Forums", "abstract": "Community Question Answering (cQA) forums are very popular nowadays, as they\nrepresent effective means for communities around particular topics to share\ninformation. Unfortunately, this information is not always factual. Thus, here\nwe explore a new dimension in the context of cQA, which has been ignored so\nfar: checking the veracity of answers to particular questions in cQA forums. As\nthis is a new problem, we create a specialized dataset for it. We further\npropose a novel multi-faceted model, which captures information from the answer\ncontent (what is said and how), from the author profile (who says it), from the\nrest of the community forum (where it is said), and from external authoritative\nsources of information (external support). Evaluation results show a MAP value\nof 86.54, which is 21 points absolute above the baseline.", "doi": "", "date": "2018-03-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1803.03178v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3551539481, "title": "Fake News Detection via NLP is Vulnerable to Adversarial Attacks", "abstract": "News plays a significant role in shaping people's beliefs and opinions. Fake\nnews has always been a problem, which wasn't exposed to the mass public until\nthe past election cycle for the 45th President of the United States. While\nquite a few detection methods have been proposed to combat fake news since\n2015, they focus mainly on linguistic aspects of an article without any fact\nchecking. In this paper, we argue that these models have the potential to\nmisclassify fact-tampering fake news as well as under-written real news.\nThrough experiments on Fakebox, a state-of-the-art fake news detector, we show\nthat fact tampering attacks can be effective. To address these weaknesses, we\nargue that fact checking should be adopted in conjunction with linguistic\ncharacteristics analysis, so as to truly separate fake news from real news. A\ncrowdsourced knowledge graph is proposed as a straw man solution to collecting\ntimely facts about news events.", "doi": "10.5220/0007566307940800", "date": "2019-01-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1901.09657v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3014337034, "title": "Adversarial Domain Adaptation for Stance Detection", "abstract": "This paper studies the problem of stance detection which aims to predict the\nperspective (or stance) of a given document with respect to a given claim.\nStance detection is a major component of automated fact checking. As annotating\nstances in different domains is a tedious and costly task, automatic methods\nbased on machine learning are viable alternatives. In this paper, we focus on\nadversarial domain adaptation for stance detection where we assume there exists\nsufficient labeled data in the source domain and limited labeled data in the\ntarget domain. Extensive experiments on publicly available datasets show the\neffectiveness of our domain adaption model in transferring knowledge for\naccurate stance detection across domains.", "doi": "", "date": "2019-02-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.02401v1", "pdf": ""}, "publisher-venue": "NIPS-CL-2018, Stance Detection, Fact Checking,\\n  Adversarial Domain Adaptation", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2972435479, "title": "MultiFC: A Real-World Multi-Domain Dataset for Evidence-Based Fact\n  Checking of Claims", "abstract": "We contribute the largest publicly available dataset of naturally occurring\nfactual claims for the purpose of automatic claim verification. It is collected\nfrom 26 fact checking websites in English, paired with textual sources and rich\nmetadata, and labelled for veracity by human expert journalists. We present an\nin-depth analysis of the dataset, highlighting characteristics and challenges.\nFurther, we present results for automatic veracity prediction, both with\nestablished baselines and with a novel method for joint ranking of evidence\npages and predicting veracity that outperforms all baselines. Significant\nperformance increases are achieved by encoding evidence, and by modelling\nmetadata. Our best-performing model achieves a Macro F1 of 49.2%, showing that\nthis is a challenging testbed for claim veracity prediction.", "doi": "", "date": "2019-09-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.03242v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1974050763, "title": "Claim Check-Worthiness Detection as Positive Unlabelled Learning", "abstract": "As the first step of automatic fact checking, claim check-worthiness\ndetection is a critical component of fact checking systems. There are multiple\nlines of research which study this problem: check-worthiness ranking from\npolitical speeches and debates, rumour detection on Twitter, and citation\nneeded detection from Wikipedia. To date, there has been no structured\ncomparison of these various tasks to understand their relatedness, and no\ninvestigation into whether or not a unified approach to all of them is\nachievable. In this work, we illuminate a central challenge in claim\ncheck-worthiness detection underlying all of these tasks, being that they hinge\nupon detecting both how factual a sentence is, as well as how likely a sentence\nis to be believed without verification. As such, annotators only mark those\ninstances they judge to be clear-cut check-worthy. Our best performing method\nis a unified approach which automatically corrects for this using a variant of\npositive unlabelled learning that finds instances which were incorrectly\nlabelled as not check-worthy. In applying this, we out-perform the state of the\nart in two of the three tasks studied for claim check-worthiness detection in\nEnglish.", "doi": "", "date": "2020-03-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.02736v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3834184154, "title": "Generating Fact Checking Summaries for Web Claims", "abstract": "We present SUMO, a neural attention-based approach that learns to establish\nthe correctness of textual claims based on evidence in the form of text\ndocuments (e.g., news articles or Web documents). SUMO further generates an\nextractive summary by presenting a diversified set of sentences from the\ndocuments that explain its decision on the correctness of the textual claim.\nPrior approaches to address the problem of fact checking and evidence\nextraction have relied on simple concatenation of claim and document word\nembeddings as an input to claim driven attention weight computation. This is\ndone so as to extract salient words and sentences from the documents that help\nestablish the correctness of the claim. However, this design of claim-driven\nattention does not capture the contextual information in documents properly. We\nimprove on the prior art by using improved claim and title guided hierarchical\nattention to model effective contextual cues. We show the efficacy of our\napproach on datasets concerning political, healthcare, and environmental\nissues.", "doi": "", "date": "2020-10-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.08570v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 527805116, "title": "Hierarchical Multi-head Attentive Network for Evidence-aware Fake News\n  Detection", "abstract": "The widespread of fake news and misinformation in various domains ranging\nfrom politics, economics to public health has posed an urgent need to\nautomatically fact-check information. A recent trend in fake news detection is\nto utilize evidence from external sources. However, existing evidence-aware\nfake news detection methods focused on either only word-level attention or\nevidence-level attention, which may result in suboptimal performance. In this\npaper, we propose a Hierarchical Multi-head Attentive Network to fact-check\ntextual claims. Our model jointly combines multi-head word-level attention and\nmulti-head document-level attention, which aid explanation in both word-level\nand evidence-level. Experiments on two real-word datasets show that our model\noutperforms seven state-of-the-art baselines. Improvements over baselines are\nfrom 6\\% to 18\\%. Our source code and datasets are released at\n\\texttt{\\url{https://github.com/nguyenvo09/EACL2021}}.", "doi": "", "date": "2021-02-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.02680v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2202291566, "title": "A Survey on Stance Detection for Mis- and Disinformation Identification", "abstract": "Detecting attitudes expressed in texts, also known as stance detection, has\nbecome an important task for the detection of false information online, be it\nmisinformation (unintentionally false) or disinformation (intentionally false,\nspread deliberately with malicious intent). Stance detection has been framed in\ndifferent ways, including: (a) as a component of fact-checking, rumour\ndetection, and detecting previously fact-checked claims; or (b) as a task in\nits own right. While there have been prior efforts to contrast stance detection\nwith other related social media tasks such as argumentation mining and\nsentiment analysis, there is no survey examining the relationship between\nstance detection detection and mis- and disinformation detection from a\nholistic viewpoint, which is the focus of this survey. We review and analyse\nexisting work in this area, before discussing lessons learnt and future\nchallenges.", "doi": "", "date": "2021-02-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.00242v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 50718628, "title": "AraStance: A Multi-Country and Multi-Domain Dataset of Arabic Stance\n  Detection for Fact Checking", "abstract": "With the continuing spread of misinformation and disinformation online, it is\nof increasing importance to develop combating mechanisms at scale in the form\nof automated systems that support multiple languages. One task of interest is\nclaim veracity prediction, which can be addressed using stance detection with\nrespect to relevant documents retrieved online. To this end, we present our new\nArabic Stance Detection dataset (AraStance) of 4,063 claim--article pairs from\na diverse set of sources comprising three fact-checking websites and one news\nwebsite. AraStance covers false and true claims from multiple domains (e.g.,\npolitics, sports, health) and several Arab countries, and it is well-balanced\nbetween related and unrelated documents with respect to the claims. We\nbenchmark AraStance, along with two other stance detection datasets, using a\nnumber of BERT-based models. Our best model achieves an accuracy of 85\\% and a\nmacro F1 score of 78\\%, which leaves room for improvement and reflects the\nchallenging nature of AraStance and the task of stance detection in general.", "doi": "", "date": "2021-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13559v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2674506731, "title": "Automatic Fake News Detection: Are Models Learning to Reason?", "abstract": "Most fact checking models for automatic fake news detection are based on\nreasoning: given a claim with associated evidence, the models aim to estimate\nthe claim veracity based on the supporting or refuting content within the\nevidence. When these models perform well, it is generally assumed to be due to\nthe models having learned to reason over the evidence with regards to the\nclaim. In this paper, we investigate this assumption of reasoning, by exploring\nthe relationship and importance of both claim and evidence. Surprisingly, we\nfind on political fact checking datasets that most often the highest\neffectiveness is obtained by utilizing only the evidence, as the impact of\nincluding the claim is either negligible or harmful to the effectiveness. This\nhighlights an important problem in what constitutes evidence in existing\napproaches for automatic fake news detection.", "doi": "", "date": "2021-05-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.07698v1", "pdf": ""}, "publisher-venue": "ACL 2021", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3261699375, "title": "Rating Facts under Coarse-to-fine Regimes", "abstract": "The rise of manipulating fake news as a political weapon has become a global\nconcern and highlighted the incapability of manually fact checking against\nrapidly produced fake news. Thus, statistical approaches are required if we are\nto address this problem efficiently. The shortage of publicly available\ndatasets is one major bottleneck of automated fact checking. To remedy this, we\ncollected 24K manually rated statements from PolitiFact. The class values\nexhibit a natural order with respect to truthfulness as shown in Table 1. Thus,\nour task represents a twist from standard classification, due to the various\ndegrees of similarity between classes. To investigate this, we defined\ncoarse-to-fine classification regimes, which presents new challenge for\nclassification. To address this, we propose BERT-based models. After training,\nclass similarity is sensible over the multi-class datasets, especially in the\nfine-grained one. Under all the regimes, BERT achieves state of the art, while\nthe additional layers provide insignificant improvement.", "doi": "", "date": "2021-07-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.06051v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3473516306, "title": "Automatic Claim Review for Climate Science via Explanation Generation", "abstract": "There is unison is the scientific community about human induced climate\nchange. Despite this, we see the web awash with claims around climate change\nscepticism, thus driving the need for fact checking them but at the same time\nproviding an explanation and justification for the fact check. Scientists and\nexperts have been trying to address it by providing manually written feedback\nfor these claims. In this paper, we try to aid them by automating generating\nexplanation for a predicted veracity label for a claim by deploying the\napproach used in open domain question answering of a fusion in decoder\naugmented with retrieved supporting passages from an external knowledge. We\nexperiment with different knowledge sources, retrievers, retriever depths and\ndemonstrate that even a small number of high quality manually written\nexplanations can help us in generating good explanations.", "doi": "", "date": "2021-07-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.14740v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3371612135, "title": "Technological Approaches to Detecting Online Disinformation and\n  Manipulation", "abstract": "The move of propaganda and disinformation to the online environment is\npossible thanks to the fact that within the last decade, digital information\nchannels radically increased in popularity as a news source. The main advantage\nof such media lies in the speed of information creation and dissemination.\nThis, on the other hand, inevitably adds pressure, accelerating editorial work,\nfact-checking, and the scrutiny of source credibility. In this chapter, an\noverview of computer-supported approaches to detecting disinformation and\nmanipulative techniques based on several criteria is presented. We concentrate\non the technical aspects of automatic methods which support fact-checking,\ntopic identification, text style analysis, or message filtering on social media\nchannels. Most of the techniques employ artificial intelligence and machine\nlearning with feature extraction combining available information resources. The\nfollowing text firstly specifies the tasks related to computer detection of\nmanipulation and disinformation spreading. The second section presents concrete\nmethods of solving the tasks of the analysis, and the third sections enlists\ncurrent verification and benchmarking datasets published and used in this area\nfor evaluation and comparison.", "doi": "10.1007/978-3-030-58624-9", "date": "2021-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.11669v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2966497446, "title": "Non-integrability of restricted double pendula", "abstract": "We consider two special types of double pendula, with the motion of masses\nrestricted to various surfaces. In order to get quick insight into the dynamics\nof the considered systems the Poincar\\'e cross sections as well as bifurcation\ndiagrams have been used. The numerical computations show that both models are\nchaotic which suggest that they are not integrable. We give an analytic proof\nof this fact checking the properties of the differential Galois group of the\nsystem's variational equations along a particular non-equilibrium solution.", "doi": "10.1016/j.physleta.2015.09.052", "date": "2015-11-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1511.01850v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4095228664, "title": "Numerically Grounded Language Models for Semantic Error Correction", "abstract": "Semantic error detection and correction is an important task for applications\nsuch as fact checking, speech-to-text or grammatical error correction. Current\napproaches generally focus on relatively shallow semantics and do not account\nfor numeric quantities. Our approach uses language models grounded in numbers\nwithin the text. Such groundings are easily achieved for recurrent neural\nlanguage model architectures, which can be further conditioned on incomplete\nbackground knowledge bases. Our evaluation on clinical reports shows that\nnumerical grounding improves perplexity by 33% and F1 for semantic error\ncorrection by 5 points when compared to ungrounded approaches. Conditioning on\na knowledge base yields further improvements.", "doi": "", "date": "2016-08-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1608.04147v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1792751680, "title": "Automatic Stance Detection Using End-to-End Memory Networks", "abstract": "We present a novel end-to-end memory network for stance detection, which\njointly (i) predicts whether a document agrees, disagrees, discusses or is\nunrelated with respect to a given target claim, and also (ii) extracts snippets\nof evidence for that prediction. The network operates at the paragraph level\nand integrates convolutional and recurrent neural networks, as well as a\nsimilarity matrix as part of the overall architecture. The experimental\nevaluation on the Fake News Challenge dataset shows state-of-the-art\nperformance.", "doi": "", "date": "2018-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.07581v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4088009396, "title": "Uni-DUE Student Team: Tackling fact checking through decomposable\n  attention neural network", "abstract": "In this paper we present our system for the FEVER Challenge. The task of this\nchallenge is to verify claims by extracting information from Wikipedia. Our\nsystem has two parts. In the first part it performs a search for candidate\nsentences by treating the claims as query. In the second part it filters out\nnoise from these candidates and uses the remaining ones to decide whether they\nsupport or refute or entail not enough information to verify the claim. We show\nthat this system achieves a FEVER score of 0.3927 on the FEVER shared task\ndevelopment data set which is a 25.5% improvement over the baseline score.", "doi": "", "date": "2018-12-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.10814v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3739828678, "title": "A Benchmark Dataset of Check-worthy Factual Claims", "abstract": "In this paper we present the ClaimBuster dataset of 23,533 statements\nextracted from all U.S. general election presidential debates and annotated by\nhuman coders. The ClaimBuster dataset can be leveraged in building\ncomputational methods to identify claims that are worth fact-checking from the\nmyriad of sources of digital or traditional media. The ClaimBuster dataset is\npublicly available to the research community, and it can be found at\nhttp://doi.org/10.5281/zenodo.3609356.", "doi": "", "date": "2020-04-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.14425v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 686000257, "title": "A Data Set of Internet Claims and Comparison of their Sentiments with\n  Credibility", "abstract": "In this modern era, communication has become faster and easier. This means\nfallacious information can spread as fast as reality. Considering the damage\nthat fake news kindles on the psychology of people and the fact that such news\nproliferates faster than truth, we need to study the phenomenon that helps\nspread fake news. An unbiased data set that depends on reality for rating news\nis necessary to construct predictive models for its classification. This paper\ndescribes the methodology to create such a data set. We collect our data from\nsnopes.com which is a fact-checking organization. Furthermore, we intend to\ncreate this data set not only for classification of the news but also to find\npatterns that reason the intent behind misinformation. We also formally define\nan Internet Claim, its credibility, and the sentiment behind such a claim. We\ntry to realize the relationship between the sentiment of a claim with its\ncredibility. This relationship pours light on the bigger picture behind the\npropagation of misinformation. We pave the way for further research based on\nthe methodology described in this paper to create the data set and usage of\npredictive modeling along with research-based on psychology/mentality of people\nto understand why fake news spreads much faster than reality.", "doi": "", "date": "2019-11-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.10130v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 555570872, "title": "Debate Dynamics for Human-comprehensible Fact-checking on Knowledge\n  Graphs", "abstract": "We propose a novel method for fact-checking on knowledge graphs based on\ndebate dynamics. The underlying idea is to frame the task of triple\nclassification as a debate game between two reinforcement learning agents which\nextract arguments -- paths in the knowledge graph -- with the goal to justify\nthe fact being true (thesis) or the fact being false (antithesis),\nrespectively. Based on these arguments, a binary classifier, referred to as the\njudge, decides whether the fact is true or false. The two agents can be\nconsidered as sparse feature extractors that present interpretable evidence for\neither the thesis or the antithesis. In contrast to black-box methods, the\narguments enable the user to gain an understanding for the decision of the\njudge. Moreover, our method allows for interactive reasoning on knowledge\ngraphs where the users can raise additional arguments or evaluate the debate\ntaking common sense reasoning and external information into account. Such\ninteractive systems can increase the acceptance of various AI applications\nbased on knowledge graphs and can further lead to higher efficiency,\nrobustness, and fairness.", "doi": "", "date": "2020-01-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.03436v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2679908203, "title": "LogicalFactChecker: Leveraging Logical Operations for Fact Checking with\n  Graph Module Network", "abstract": "Verifying the correctness of a textual statement requires not only semantic\nreasoning about the meaning of words, but also symbolic reasoning about logical\noperations like count, superlative, aggregation, etc. In this work, we propose\nLogicalFactChecker, a neural network approach capable of leveraging logical\noperations for fact checking. It achieves the state-of-the-art performance on\nTABFACT, a large-scale, benchmark dataset built for verifying a textual\nstatement with semi-structured tables. This is achieved by a graph module\nnetwork built upon the Transformer-based architecture. With a textual statement\nand a table as the input, LogicalFactChecker automatically derives a program\n(a.k.a. logical form) of the statement in a semantic parsing manner. A\nheterogeneous graph is then constructed to capture not only the structures of\nthe table and the program, but also the connections between inputs with\ndifferent modalities. Such a graph reveals the related contexts of each word in\nthe statement, the table and the program. The graph is used to obtain\ngraph-enhanced contextual representations of words in Transformer-based\narchitecture. After that, a program-driven module network is further introduced\nto exploit the hierarchical structure of the program, where semantic\ncompositionality is dynamically modeled along the program structure with a set\nof function-specific modules. Ablation experiments suggest that both the\nheterogeneous graph and the module network are important to obtain strong\nresults.", "doi": "", "date": "2020-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.13659v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4010846600, "title": "What Was Written vs. Who Read It: News Media Profiling Using Text\n  Analysis and Social Media Context", "abstract": "Predicting the political bias and the factuality of reporting of entire news\noutlets are critical elements of media profiling, which is an understudied but\nan increasingly important research direction. The present level of\nproliferation of fake, biased, and propagandistic content online, has made it\nimpossible to fact-check every single suspicious claim, either manually or\nautomatically. Alternatively, we can profile entire news outlets and look for\nthose that are likely to publish fake or biased content. This approach makes it\npossible to detect likely \"fake news\" the moment they are published, by simply\nchecking the reliability of their source. From a practical perspective,\npolitical bias and factuality of reporting have a linguistic aspect but also a\nsocial context. Here, we study the impact of both, namely (i) what was written\n(i.e., what was published by the target medium, and how it describes itself on\nTwitter) vs. (ii) who read it (i.e., analyzing the readers of the target medium\non Facebook, Twitter, and YouTube). We further study (iii) what was written\nabout the target medium on Wikipedia. The evaluation results show that what was\nwritten matters most, and that putting all information sources together yields\nhuge improvements over the current state-of-the-art.", "doi": "", "date": "2020-05-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.04518v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3868051064, "title": "An Exploratory Study of COVID-19 Misinformation on Twitter", "abstract": "During the COVID-19 pandemic, social media has become a home ground for\nmisinformation. To tackle this infodemic, scientific oversight, as well as a\nbetter understanding by practitioners in crisis management, is needed. We have\nconducted an exploratory study into the propagation, authors and content of\nmisinformation on Twitter around the topic of COVID-19 in order to gain early\ninsights. We have collected all tweets mentioned in the verdicts of\nfact-checked claims related to COVID-19 by over 92 professional fact-checking\norganisations between January and mid-July 2020 and share this corpus with the\ncommunity. This resulted in 1 500 tweets relating to 1 274 false and 276\npartially false claims, respectively. Exploratory analysis of author accounts\nrevealed that the verified twitter handle(including Organisation/celebrity) are\nalso involved in either creating (new tweets) or spreading (retweet) the\nmisinformation. Additionally, we found that false claims propagate faster than\npartially false claims. Compare to a background corpus of COVID-19 tweets,\ntweets with misinformation are more often concerned with discrediting other\ninformation on social media. Authors use less tentative language and appear to\nbe more driven by concerns of potential harm to others. Our results enable us\nto suggest gaps in the current scientific coverage of the topic as well as\npropose actions for authorities and social media users to counter\nmisinformation.", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.05710v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 90644879, "title": "Check_square at CheckThat! 2020: Claim Detection in Social Media via\n  Fusion of Transformer and Syntactic Features", "abstract": "In this digital age of news consumption, a news reader has the ability to\nreact, express and share opinions with others in a highly interactive and fast\nmanner. As a consequence, fake news has made its way into our daily life\nbecause of very limited capacity to verify news on the Internet by large\ncompanies as well as individuals. In this paper, we focus on solving two\nproblems which are part of the fact-checking ecosystem that can help to\nautomate fact-checking of claims in an ever increasing stream of content on\nsocial media. For the first problem, claim check-worthiness prediction, we\nexplore the fusion of syntactic features and deep transformer Bidirectional\nEncoder Representations from Transformers (BERT) embeddings, to classify\ncheck-worthiness of a tweet, i.e. whether it includes a claim or not. We\nconduct a detailed feature analysis and present our best performing models for\nEnglish and Arabic tweets. For the second problem, claim retrieval, we explore\nthe pre-trained embeddings from a Siamese network transformer model\n(sentence-transformers) specifically trained for semantic textual similarity,\nand perform KD-search to retrieve verified claims with respect to a query\ntweet.", "doi": "", "date": "2020-07-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.10534v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4152265165, "title": "Exploiting stance hierarchies for cost-sensitive stance detection of Web\n  documents", "abstract": "Fact checking is an essential challenge when combating fake news. Identifying\ndocuments that agree or disagree with a particular statement (claim) is a core\ntask in this process. In this context, stance detection aims at identifying the\nposition (stance) of a document towards a claim. Most approaches address this\ntask through a 4-class classification model where the class distribution is\nhighly imbalanced. Therefore, they are particularly ineffective in detecting\nthe minority classes (for instance, 'disagree'), even though such instances are\ncrucial for tasks such as fact-checking by providing evidence for detecting\nfalse claims. In this paper, we exploit the hierarchical nature of stance\nclasses, which allows us to propose a modular pipeline of cascading binary\nclassifiers, enabling performance tuning on a per step and class basis. We\nimplement our approach through a combination of neural and traditional\nclassification models that highlight the misclassification costs of minority\nclasses. Evaluation results demonstrate state-of-the-art performance of our\napproach and its ability to significantly improve the classification\nperformance of the important 'disagree' class.", "doi": "10.1007/s10844-021-00642-z", "date": "2020-07-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.15121v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2052838201, "title": "KILT: a Benchmark for Knowledge Intensive Language Tasks", "abstract": "Challenging problems such as open-domain question answering, fact checking,\nslot filling and entity linking require access to large, external knowledge\nsources. While some models do well on individual tasks, developing general\nmodels is difficult as each task might require computationally expensive\nindexing of custom knowledge sources, in addition to dedicated infrastructure.\nTo catalyze research on models that condition on specific information in large\ntextual resources, we present a benchmark for knowledge-intensive language\ntasks (KILT). All tasks in KILT are grounded in the same snapshot of Wikipedia,\nreducing engineering turnaround through the re-use of components, as well as\naccelerating research into task-agnostic memory architectures. We test both\ntask-specific and general baselines, evaluating downstream performance in\naddition to the ability of the models to provide provenance. We find that a\nshared dense vector index coupled with a seq2seq model is a strong baseline,\noutperforming more tailor-made approaches for fact checking, open-domain\nquestion answering and dialogue, and yielding competitive results on entity\nlinking and slot filling, by generating disambiguated text. KILT data and code\nare available at https://github.com/facebookresearch/KILT.", "doi": "", "date": "2020-09-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.02252v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3998758951, "title": "Two Stage Transformer Model for COVID-19 Fake News Detection and Fact\n  Checking", "abstract": "The rapid advancement of technology in online communication via social media\nplatforms has led to a prolific rise in the spread of misinformation and fake\nnews. Fake news is especially rampant in the current COVID-19 pandemic, leading\nto people believing in false and potentially harmful claims and stories.\nDetecting fake news quickly can alleviate the spread of panic, chaos and\npotential health hazards. We developed a two stage automated pipeline for\nCOVID-19 fake news detection using state of the art machine learning models for\nnatural language processing. The first model leverages a novel fact checking\nalgorithm that retrieves the most relevant facts concerning user claims about\nparticular COVID-19 claims. The second model verifies the level of truth in the\nclaim by computing the textual entailment between the claim and the true facts\nretrieved from a manually curated COVID-19 dataset. The dataset is based on a\npublicly available knowledge source consisting of more than 5000 COVID-19 false\nclaims and verified explanations, a subset of which was internally annotated\nand cross-validated to train and evaluate our models. We evaluate a series of\nmodels based on classical text-based features to more contextual Transformer\nbased models and observe that a model pipeline based on BERT and ALBERT for the\ntwo stages respectively yields the best results.", "doi": "", "date": "2020-11-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.13253v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3082450491, "title": "Misinformation, Believability, and Vaccine Acceptance Over 40 Countries:\n  Takeaways From the Initial Phase of The COVID-19 Infodemic", "abstract": "The COVID-19 pandemic has been damaging to the lives of people all around the\nworld. Accompanied by the pandemic is an infodemic, an abundant and\nuncontrolled spreading of potentially harmful misinformation. The infodemic may\nseverely change the pandemic's course by interfering with public health\ninterventions such as wearing masks, social distancing, and vaccination. In\nparticular, the impact of the infodemic on vaccination is critical because it\nholds the key to reverting to pre-pandemic normalcy. This paper presents\nfindings from a global survey on the extent of worldwide exposure to the\nCOVID-19 infodemic, assesses different populations' susceptibility to false\nclaims, and analyzes its association with vaccine acceptance. Based on\nresponses gathered from over 18,400 individuals from 40 countries, we find a\nstrong association between perceived believability of misinformation and\nvaccination hesitancy. Additionally, our study shows that only half of the\nonline users exposed to rumors might have seen the fact-checked information.\nMoreover, depending on the country, between 6% and 37% of individuals\nconsidered these rumors believable. Our survey also shows that poorer regions\nare more susceptible to encountering and believing COVID-19 misinformation. We\ndiscuss implications of our findings on public campaigns that proactively\nspread accurate information to countries that are more susceptible to the\ninfodemic. We also highlight fact-checking platforms' role in better\nidentifying and prioritizing claims that are perceived to be believable and\nhave wide exposure. Our findings give insights into better handling of risk\ncommunication during the initial phase of a future pandemic.", "doi": "", "date": "2021-04-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.10864v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2464109024, "title": "Prevalence and Propagation of Fake News", "abstract": "In recent years, scholars have raised concerns on the effects that unreliable\nnews, or \"fake news,\" has on our political sphere, and our democracy as a\nwhole. For example, the propagation of fake news on social media is widely\nbelieved to have influenced the outcome of national elections, including the\n2016 U.S. Presidential Election, and the 2020 COVID-19 pandemic. What drives\nthe propagation of fake news on an individual level, and which interventions\ncould effectively reduce the propagation rate? Our model disentangles bias from\ntruthfulness of an article and examines the relationship between these two\nparameters and a reader's own beliefs. Using the model, we create policy\nrecommendations for both social media platforms and individual social media\nusers to reduce the spread of untruthful or highly biased news. We recommend\nthat platforms sponsor unbiased truthful news, focus fact-checking efforts on\nmild to moderately biased news, recommend friend suggestions across the\npolitical spectrum, and provide users with reports about the political\nalignment of their feed. We recommend that individual social media users fact\ncheck news that strongly aligns with their political bias and read articles of\nopposing political bias.", "doi": "", "date": "2021-06-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.09586v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4201400514, "title": "TI-CNN: Convolutional Neural Networks for Fake News Detection", "abstract": "With the development of social networks, fake news for various commercial and\npolitical purposes has been appearing in large numbers and gotten widespread in\nthe online world. With deceptive words, people can get infected by the fake\nnews very easily and will share them without any fact-checking. For instance,\nduring the 2016 US president election, various kinds of fake news about the\ncandidates widely spread through both official news media and the online social\nnetworks. These fake news is usually released to either smear the opponents or\nsupport the candidate on their side. The erroneous information in the fake news\nis usually written to motivate the voters' irrational emotion and enthusiasm.\nSuch kinds of fake news sometimes can bring about devastating effects, and an\nimportant goal in improving the credibility of online social networks is to\nidentify the fake news timely. In this paper, we propose to study the fake news\ndetection problem. Automatic fake news identification is extremely hard, since\npure model based fact-checking for news is still an open problem, and few\nexisting models can be applied to solve the problem. With a thorough\ninvestigation of a fake news data, lots of useful explicit features are\nidentified from both the text words and images used in the fake news. Besides\nthe explicit features, there also exist some hidden patterns in the words and\nimages used in fake news, which can be captured with a set of latent features\nextracted via the multiple convolutional layers in our model. A model named as\nTI-CNN (Text and Image information based Convolutinal Neural Network) is\nproposed in this paper. By projecting the explicit and latent features into a\nunified feature space, TI-CNN is trained with both the text and image\ninformation simultaneously. Extensive experiments carried on the real-world\nfake news datasets have demonstrate the effectiveness of TI-CNN.", "doi": "", "date": "2018-06-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.00749v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4033215633, "title": "Understanding the dynamics emerging from infodemics: A call to action\n  for interdisciplinary research", "abstract": "Research on infodemics, i.e., the rapid spread of (mis)information related to\na hazardous event, such as the COVID-19 pandemic, requires the integration of a\nmultiplicity of scientific disciplines. The dynamics emerging from infodemics\nhave the potential to generate complex behavioral patterns. In order to react\nappropriately, it is of ultimate importance for the fields of Business and\nEconomics to understand the dynamics emerging from it. In the short run,\ndynamics might lead to an adaptation in household spending or to a shift in\nbuying behavior towards online providers. In the long run, changes in\ninvestments, consumer behavior, and markets are to be expected. We argue that\nthe dynamics emerge from complex interactions among multiple factors, such as\ninformation and misinformation accessible for individuals and the formation and\nrevision of beliefs. (Mis)information accessible to individuals is, amongst\nothers, affected by algorithms specifically designed to provide personalized\ninformation, while automated fact-checking algorithms can help reduce the\namount of circulating misinformation. The formation and revision of individual\n(and probably false) beliefs and individual fact-checking and interpretation of\ninformation are heavily affected by linguistic patterns inherent to information\nduring pandemics and infodemics and further factors, such as affect, intuition\nand motives. We argue that, in order to get a deep(er) understanding of the\ndynamics emerging from infodemics, the fields of Business and Economics should\nintegrate the perspectives of Computer Science and Information Systems,\n(Computational) Linguistics, and Cognitive Science into the wider context of\neconomic systems (e.g., organizations, markets or industries) and propose a way\nto do so.", "doi": "", "date": "2020-07-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.12226v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 413383628, "title": "Combating Misinformation in Bangladesh: Roles and Responsibilities as\n  Perceived by Journalists, Fact-checkers, and Users", "abstract": "There has been a growing interest within CSCW community in understanding the\ncharacteristics of misinformation propagated through computational media, and\nthe devising techniques to address the associated challenges. However, most\nwork in this area has been concentrated on the cases in the western world\nleaving a major portion of this problem unaddressed that is situated in the\nGlobal South. This paper aims to broaden the scope of this discourse by\nfocusing on this problem in the context of Bangladesh, a country in the Global\nSouth. The spread of misinformation on Facebook in Bangladesh, a country with a\npopulation over 163 million, has resulted in chaos, hate attacks, and killings.\nBy interviewing journalists, fact-checkers, in addition to surveying the\ngeneral public, we analyzed the current state of verifying misinformation in\nBangladesh. Our findings show that most people in the `news audience' want the\nnews media to verify the authenticity of online information that they see\nonline. However, the newspaper journalists say that fact-checking online\ninformation is not a part of their job, and it is also beyond their capacity\ngiven the amount of information being published online everyday. We further\nfind that the voluntary fact-checkers in Bangladesh are not equipped with\nsufficient infrastructural support to fill in this gap. We show how our\nfindings are connected to some of the core concerns of CSCW community around\nsocial media, collaboration, infrastructural politics, and information\ninequality. From our analysis, we also suggest several pathways to increase the\nimpact of fact-checking efforts through collaboration, technology design, and\ninfrastructure development.", "doi": "10.1145/3415201", "date": "2020-07-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.12841v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 502767384, "title": "A Stylometric Inquiry into Hyperpartisan and Fake News", "abstract": "This paper reports on a writing style analysis of hyperpartisan (i.e.,\nextremely one-sided) news in connection to fake news. It presents a large\ncorpus of 1,627 articles that were manually fact-checked by professional\njournalists from BuzzFeed. The articles originated from 9 well-known political\npublishers, 3 each from the mainstream, the hyperpartisan left-wing, and the\nhyperpartisan right-wing. In sum, the corpus contains 299 fake news, 97% of\nwhich originated from hyperpartisan publishers.\n  We propose and demonstrate a new way of assessing style similarity between\ntext categories via Unmasking---a meta-learning approach originally devised for\nauthorship verification---, revealing that the style of left-wing and\nright-wing news have a lot more in common than any of the two have with the\nmainstream. Furthermore, we show that hyperpartisan news can be discriminated\nwell by its style from the mainstream (F1=0.78), as can be satire from both\n(F1=0.81). Unsurprisingly, style-based fake news detection does not live up to\nscratch (F1=0.46). Nevertheless, the former results are important to implement\npre-screening for fake news detectors.", "doi": "", "date": "2017-02-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1702.05638v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 727509252, "title": "Rumor propagation meets skepticism: a parallel with zombies", "abstract": "We propose a model of rumor spreading in which susceptible, but skeptically\noriented individuals may oppose the rumor. Resistance may be implemented either\nby skeptical activists trying to convince spreaders to stop their activity,\nbecoming stiflers or, passively (non-reactive) as a consequence, for example,\nof fact-checking. Interestingly, these two mechanisms, when combined, are\nsimilar to the (assumed) spreading of a fictitious zombie outbreak, where\nsurvivors actively target infected people. We analyse the well-mixed\n(mean-field) description and obtain the conditions for rumors (zombies) to\nspread through the whole population. The results show that when the skepticism\nis strong enough, the model predicts the coexistence of two fixed points (such\nbistability may be related to polarized situations), with the fate of rumors\ndepending on the initial exposure to it.", "doi": "10.1209/0295-5075/124/18007", "date": "2018-10-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1810.03775v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 750529471, "title": "Suspicious News Detection Using Micro Blog Text", "abstract": "We present a new task, suspicious news detection using micro blog text. This\ntask aims to support human experts to detect suspicious news articles to be\nverified, which is costly but a crucial step before verifying the truthfulness\nof the articles. Specifically, in this task, given a set of posts on SNS\nreferring to a news article, the goal is to judge whether the article is to be\nverified or not. For this task, we create a publicly available dataset in\nJapanese and provide benchmark results by using several basic machine learning\ntechniques. Experimental results show that our models can reduce the cost of\nmanual fact-checking process.", "doi": "", "date": "2018-10-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1810.11663v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1157429309, "title": "Detecting Deception in Political Debates Using Acoustic and Textual\n  Features", "abstract": "We present work on deception detection, where, given a spoken claim, we aim\nto predict its factuality. While previous work in the speech community has\nrelied on recordings from staged setups where people were asked to tell the\ntruth or to lie and their statements were recorded, here we use real-world\npolitical debates. Thanks to the efforts of fact-checking organizations, it is\npossible to obtain annotations for statements in the context of a political\ndiscourse as true, half-true, or false. Starting with such data from the\nCLEF-2018 CheckThat! Lab, which was limited to text, we performed alignment to\nthe corresponding videos, thus producing a multimodal dataset. We further\ndeveloped a multimodal deep-learning architecture for the task of deception\ndetection, which yielded sizable improvements over the state of the art for the\nCLEF-2018 Lab task 2. Our experiments show that the use of the acoustic signal\nconsistently helped to improve the performance compared to using textual and\nmetadata features only, based on several different evaluation measures. We\nrelease the new dataset to the research community, hoping to help advance the\noverall field of multimodal deception detection.", "doi": "", "date": "2019-10-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.01990v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1399364541, "title": "Predicting the Leading Political Ideology of YouTube Channels Using\n  Acoustic, Textual, and Metadata Information", "abstract": "We address the problem of predicting the leading political ideology, i.e.,\nleft-center-right bias, for YouTube channels of news media. Previous work on\nthe problem has focused exclusively on text and on analysis of the language\nused, topics discussed, sentiment, and the like. In contrast, here we study\nvideos, which yields an interesting multimodal setup. Starting with gold\nannotations about the leading political ideology of major world news media from\nMedia Bias/Fact Check, we searched on YouTube to find their corresponding\nchannels, and we downloaded a recent sample of videos from each channel. We\ncrawled more than 1,000 YouTube hours along with the corresponding subtitles\nand metadata, thus producing a new multimodal dataset. We further developed a\nmultimodal deep-learning architecture for the task. Our analysis shows that the\nuse of acoustic signal helped to improve bias detection by more than 6%\nabsolute over using text and metadata only. We release the dataset to the\nresearch community, hoping to help advance the field of multi-modal political\nbias detection.", "doi": "", "date": "2019-10-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.08948v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1309371848, "title": "Evaluating the Factual Consistency of Abstractive Text Summarization", "abstract": "Currently used metrics for assessing summarization algorithms do not account\nfor whether summaries are factually consistent with source documents. We\npropose a weakly-supervised, model-based approach for verifying factual\nconsistency and identifying conflicts between source documents and a generated\nsummary. Training data is generated by applying a series of rule-based\ntransformations to the sentences of source documents. The factual consistency\nmodel is then trained jointly for three tasks: 1) identify whether sentences\nremain factually consistent after transformation, 2) extract a span in the\nsource documents to support the consistency prediction, 3) extract a span in\nthe summary sentence that is inconsistent if one exists. Transferring this\nmodel to summaries generated by several state-of-the art models reveals that\nthis highly scalable approach substantially outperforms previous models,\nincluding those trained with strong supervision using standard datasets for\nnatural language inference and fact checking. Additionally, human evaluation\nshows that the auxiliary span extraction tasks provide useful assistance in the\nprocess of verifying factual consistency.", "doi": "", "date": "2019-10-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1910.12840v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2697931280, "title": "ProjE: Embedding Projection for Knowledge Graph Completion", "abstract": "With the large volume of new information created every day, determining the\nvalidity of information in a knowledge graph and filling in its missing parts\nare crucial tasks for many researchers and practitioners. To address this\nchallenge, a number of knowledge graph completion methods have been developed\nusing low-dimensional graph embeddings. Although researchers continue to\nimprove these models using an increasingly complex feature space, we show that\nsimple changes in the architecture of the underlying model can outperform\nstate-of-the-art models without the need for complex feature engineering. In\nthis work, we present a shared variable neural network model called ProjE that\nfills-in missing information in a knowledge graph by learning joint embeddings\nof the knowledge graph's entities and edges, and through subtle, but important,\nchanges to the standard loss function. In doing so, ProjE has a parameter size\nthat is smaller than 11 out of 15 existing methods while performing $37\\%$\nbetter than the current-best method on standard datasets. We also show, via a\nnew fact checking task, that ProjE is capable of accurately determining the\nveracity of many declarative statements.", "doi": "", "date": "2016-11-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1611.05425v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4107886392, "title": "\"Liar, Liar Pants on Fire\": A New Benchmark Dataset for Fake News\n  Detection", "abstract": "Automatic fake news detection is a challenging problem in deception\ndetection, and it has tremendous real-world political and social impacts.\nHowever, statistical approaches to combating fake news has been dramatically\nlimited by the lack of labeled benchmark datasets. In this paper, we present\nliar: a new, publicly available dataset for fake news detection. We collected a\ndecade-long, 12.8K manually labeled short statements in various contexts from\nPolitiFact.com, which provides detailed analysis report and links to source\ndocuments for each case. This dataset can be used for fact-checking research as\nwell. Notably, this new dataset is an order of magnitude larger than previously\nlargest public fake news datasets of similar type. Empirically, we investigate\nautomatic fake news detection based on surface-level linguistic patterns. We\nhave designed a novel, hybrid convolutional neural network to integrate\nmeta-data with text. We show that this hybrid approach can improve a text-only\ndeep learning model.", "doi": "", "date": "2017-05-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1705.00648v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2224898318, "title": "A simple but tough-to-beat baseline for the Fake News Challenge stance\n  detection task", "abstract": "Identifying public misinformation is a complicated and challenging task. An\nimportant part of checking the veracity of a specific claim is to evaluate the\nstance different news sources take towards the assertion. Automatic stance\nevaluation, i.e. stance detection, would arguably facilitate the process of\nfact checking. In this paper, we present our stance detection system which\nclaimed third place in Stage 1 of the Fake News Challenge. Despite our\nstraightforward approach, our system performs at a competitive level with the\ncomplex ensembles of the top two winning teams. We therefore propose our system\nas the 'simple but tough-to-beat baseline' for the Fake News Challenge stance\ndetection task.", "doi": "", "date": "2017-07-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1707.03264v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3736118596, "title": "Using the AIDA Language to Formally Organize Scientific Claims", "abstract": "Scientific communication still mainly relies on natural language written in\nscientific papers, which makes the described knowledge very difficult to access\nwith automatic means. We can therefore only make limited use of formal\nknowledge organization methods to support researchers and other interested\nparties with features such as automatic aggregations, fact checking,\nconsistency checking, question answering, and powerful semantic search.\nExisting approaches to solve this problem by improving the scientific\ncommunication methods have either very restricted coverage, require formal\nlogic skills on the side of the researchers, or depend on unreliable machine\nlearning for the formalization of knowledge. Here, I propose an approach to\nthis problem that is general, intuitive, and flexible. It is based on a unique\nkind of controlled natural language, called AIDA, consisting of English\nsentences that are atomic, independent, declarative, and absolute. Such\nsentences can then serve as nodes in a network of scientific claims linked to\npublications, researchers, and domain elements. I present here some small\nstudies on preliminary applications of this language. The results indicate that\nit is well accepted by users and provides a good basis for the creation of a\nknowledge graph of scientific findings.", "doi": "", "date": "2018-06-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1806.01507v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 652189244, "title": "DeClarE: Debunking Fake News and False Claims using Evidence-Aware Deep\n  Learning", "abstract": "Misinformation such as fake news is one of the big challenges of our society.\nResearch on automated fact-checking has proposed methods based on supervised\nlearning, but these approaches do not consider external evidence apart from\nlabeled training instances. Recent approaches counter this deficit by\nconsidering external sources related to a claim. However, these methods require\nsubstantial feature modeling and rich lexicons. This paper overcomes these\nlimitations of prior work with an end-to-end model for evidence-aware\ncredibility assessment of arbitrary textual claims, without any human\nintervention. It presents a neural network model that judiciously aggregates\nsignals from external evidence articles, the language of these articles and the\ntrustworthiness of their sources. It also derives informative features for\ngenerating user-comprehensible explanations that makes the neural network\npredictions transparent to the end-user. Experiments with four datasets and\nablation studies show the strength of our method.", "doi": "", "date": "2018-09-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.06416v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1373278884, "title": "Adversarial attacks against Fact Extraction and VERification", "abstract": "This paper describes a baseline for the second iteration of the Fact\nExtraction and VERification shared task (FEVER2.0) which explores the\nresilience of systems through adversarial evaluation. We present a collection\nof simple adversarial attacks against systems that participated in the first\nFEVER shared task. FEVER modeled the assessment of truthfulness of written\nclaims as a joint information retrieval and natural language inference task\nusing evidence from Wikipedia. A large number of participants made use of deep\nneural networks in their submissions to the shared task. The extent as to\nwhether such models understand language has been the subject of a number of\nrecent investigations and discussion in literature. In this paper, we present a\nsimple method of generating entailment-preserving and entailment-altering\nperturbations of instances by common patterns within the training data. We find\nthat a number of systems are greatly affected with absolute losses in\nclassification accuracy of up to $29\\%$ on the newly perturbed instances. Using\nthese newly generated instances, we construct a sample submission for the\nFEVER2.0 shared task. Addressing these types of attacks will aid in building\nmore robust fact-checking models, as well as suggest directions to expand the\ndatasets.", "doi": "", "date": "2019-03-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.05543v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3951325966, "title": "Multi-Task Ordinal Regression for Jointly Predicting the Trustworthiness\n  and the Leading Political Ideology of News Media", "abstract": "In the context of fake news, bias, and propaganda, we study two important but\nrelatively under-explored problems: (i) trustworthiness estimation (on a\n3-point scale) and (ii) political ideology detection (left/right bias on a\n7-point scale) of entire news outlets, as opposed to evaluating individual\narticles. In particular, we propose a multi-task ordinal regression framework\nthat models the two problems jointly. This is motivated by the observation that\nhyper-partisanship is often linked to low trustworthiness, e.g., appealing to\nemotions rather than sticking to the facts, while center media tend to be\ngenerally more impartial and trustworthy. We further use several auxiliary\ntasks, modeling centrality, hyperpartisanship, as well as left-vs.-right bias\non a coarse-grained scale. The evaluation results show sizable performance\ngains by the joint models over models that target the problems in isolation.", "doi": "", "date": "2019-04-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1904.00542v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2343131615, "title": "A Topic-Agnostic Approach for Identifying Fake News Pages", "abstract": "Fake news and misinformation have been increasingly used to manipulate\npopular opinion and influence political processes. To better understand fake\nnews, how they are propagated, and how to counter their effect, it is necessary\nto first identify them. Recently, approaches have been proposed to\nautomatically classify articles as fake based on their content. An important\nchallenge for these approaches comes from the dynamic nature of news: as new\npolitical events are covered, topics and discourse constantly change and thus,\na classifier trained using content from articles published at a given time is\nlikely to become ineffective in the future. To address this challenge, we\npropose a topic-agnostic (TAG) classification strategy that uses linguistic and\nweb-markup features to identify fake news pages. We report experimental results\nusing multiple data sets which show that our approach attains high accuracy in\nthe identification of fake news, even as topics evolve over time.", "doi": "10.1145/3308560.3316739", "date": "2019-05-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1905.00957v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3978188041, "title": "YouTube Chatter: Understanding Online Comments Discourse on\n  Misinformative and Political YouTube Videos", "abstract": "We conduct a preliminary analysis of comments on political YouTube content\ncontaining misinformation in comparison to comments on trustworthy or\napolitical videos, labelling the bias and factual ratings of our channels\naccording to Media Bias Fact Check where applicable. One of our most\ninteresting discoveries is that especially-polarized or misinformative\npolitical channels (Left-Bias, Right-Bias, PragerU, Conspiracy-Pseudoscience,\nand Questionable Source) generate 7.5x more comments per view and 10.42x more\nreplies per view than apolitical or Pro-Science channels; in particular,\nConspiracy-Pseudoscience and Questionable Sources generate 8.3x more comments\nper view and 11.0x more replies per view than apolitical and Pro-Science\nchannels. We also compared average thread lengths, average comment lengths, and\nprofanity rates across channels, and present simple machine learning\nclassifiers for predicting the bias category of a video based on these\nstatistics.", "doi": "", "date": "2019-06-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.00435v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 450643252, "title": "Predicting the Topical Stance of Media and Popular Twitter Users", "abstract": "Discovering the stances of media outlets and influential people on current,\ndebatable topics is important for social statisticians and policy makers. Many\nsupervised solutions exist for determining viewpoints, but manually annotating\ntraining data is costly. In this paper, we propose a cascaded method that uses\nunsupervised learning to ascertain the stance of Twitter users with respect to\na polarizing topic by leveraging their retweet behavior; then, it uses\nsupervised learning based on user labels to characterize both the general\npolitical leaning of online media and of popular Twitter users, as well as\ntheir stance with respect to the target polarizing topic. We evaluate the model\nby comparing its predictions to gold labels from the Media Bias/Fact Check\nwebsite, achieving 82.6% accuracy.", "doi": "", "date": "2019-07-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1907.01260v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1643079054, "title": "Detecting Toxicity in News Articles: Application to Bulgarian", "abstract": "Online media aim for reaching ever bigger audience and for attracting ever\nlonger attention span. This competition creates an environment that rewards\nsensational, fake, and toxic news. To help limit their spread and impact, we\npropose and develop a news toxicity detector that can recognize various types\nof toxic content. While previous research primarily focused on English, here we\ntarget Bulgarian. We created a new dataset by crawling a website that for five\nyears has been collecting Bulgarian news articles that were manually\ncategorized into eight toxicity groups. Then we trained a multi-class\nclassifier with nine categories: eight toxic and one non-toxic. We experimented\nwith different representations based on ElMo, BERT, and XLM, as well as with a\nvariety of domain-specific features. Due to the small size of our dataset, we\ncreated a separate model for each feature type, and we ultimately combined\nthese models into a meta-classifier. The evaluation results show an accuracy of\n59.0% and a macro-F1 score of 39.7%, which represent sizable improvements over\nthe majority-class baseline (Acc=30.3%, macro-F1=5.2%).", "doi": "", "date": "2019-08-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1908.09785v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2285146856, "title": "Automatic Fact-guided Sentence Modification", "abstract": "Online encyclopediae like Wikipedia contain large amounts of text that need\nfrequent corrections and updates. The new information may contradict existing\ncontent in encyclopediae. In this paper, we focus on rewriting such dynamically\nchanging articles. This is a challenging constrained generation task, as the\noutput must be consistent with the new information and fit into the rest of the\nexisting document. To this end, we propose a two-step solution: (1) We identify\nand remove the contradicting components in a target text for a given claim,\nusing a neutralizing stance model; (2) We expand the remaining text to be\nconsistent with the given claim, using a novel two-encoder sequence-to-sequence\nmodel with copy attention. Applied to a Wikipedia fact update dataset, our\nmethod successfully generates updated sentences for new claims, achieving the\nhighest SARI score. Furthermore, we demonstrate that generating synthetic data\nthrough such rewritten sentences can successfully augment the FEVER\nfact-checking training dataset, leading to a relative error reduction of 13%.", "doi": "", "date": "2019-09-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.13838v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 315525888, "title": "Optimizing the Factual Correctness of a Summary: A Study of Summarizing\n  Radiology Reports", "abstract": "Neural abstractive summarization models are able to generate summaries which\nhave high overlap with human references. However, existing models are not\noptimized for factual correctness, a critical metric in real-world\napplications. In this work, we develop a general framework where we evaluate\nthe factual correctness of a generated summary by fact-checking it\nautomatically against its reference using an information extraction module. We\nfurther propose a training strategy which optimizes a neural summarization\nmodel with a factual correctness reward via reinforcement learning. We apply\nthe proposed method to the summarization of radiology reports, where factual\ncorrectness is a key requirement. On two separate datasets collected from\nhospitals, we show via both automatic and human evaluation that the proposed\napproach substantially improves the factual correctness and overall quality of\noutputs over a competitive neural summarization system, producing radiology\nsummaries that approach the quality of human-authored ones.", "doi": "", "date": "2019-11-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.02541v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 257173426, "title": "In Search of Credible News", "abstract": "We study the problem of finding fake online news. This is an important\nproblem as news of questionable credibility have recently been proliferating in\nsocial media at an alarming scale. As this is an understudied problem,\nespecially for languages other than English, we first collect and release to\nthe research community three new balanced credible vs. fake news datasets\nderived from four online sources. We then propose a language-independent\napproach for automatically distinguishing credible from fake news, based on a\nrich feature set. In particular, we use linguistic (n-gram),\ncredibility-related (capitalization, punctuation, pronoun use, sentiment\npolarity), and semantic (embeddings and DBPedia data) features. Our experiments\non three different testsets show that our model can distinguish credible from\nfake news with very high accuracy.", "doi": "", "date": "2019-11-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1911.08125v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 220708761, "title": "InChorus: Designing Consistent Multimodal Interactions for Data\n  Visualization on Tablet Devices", "abstract": "While tablet devices are a promising platform for data visualization,\nsupporting consistent interactions across different types of visualizations on\ntablets remains an open challenge. In this paper, we present multimodal\ninteractions that function consistently across different visualizations,\nsupporting common operations during visual data analysis. By considering\nstandard interface elements (e.g., axes, marks) and grounding our design in a\nset of core concepts including operations, parameters, targets, and\ninstruments, we systematically develop interactions applicable to different\nvisualization types. To exemplify how the proposed interactions collectively\nfacilitate data exploration, we employ them in a tablet-based system, InChorus\nthat supports pen, touch, and speech input. Based on a study with 12\nparticipants performing replication and fact-checking tasks with InChorus, we\ndiscuss how participants adapted to using multimodal input and highlight\nconsiderations for future multimodal visualization systems.", "doi": "", "date": "2020-01-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.06423v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3759797048, "title": "The KEEN Universe: An Ecosystem for Knowledge Graph Embeddings with a\n  Focus on Reproducibility and Transferability", "abstract": "There is an emerging trend of embedding knowledge graphs (KGs) in continuous\nvector spaces in order to use those for machine learning tasks. Recently, many\nknowledge graph embedding (KGE) models have been proposed that learn low\ndimensional representations while trying to maintain the structural properties\nof the KGs such as the similarity of nodes depending on their edges to other\nnodes. KGEs can be used to address tasks within KGs such as the prediction of\nnovel links and the disambiguation of entities. They can also be used for\ndownstream tasks like question answering and fact-checking. Overall, these\ntasks are relevant for the semantic web community. Despite their popularity,\nthe reproducibility of KGE experiments and the transferability of proposed KGE\nmodels to research fields outside the machine learning community can be a major\nchallenge. Therefore, we present the KEEN Universe, an ecosystem for knowledge\ngraph embeddings that we have developed with a strong focus on reproducibility\nand transferability. The KEEN Universe currently consists of the Python\npackages PyKEEN (Python KnowlEdge EmbeddiNgs), BioKEEN (Biological KnowlEdge\nEmbeddiNgs), and the KEEN Model Zoo for sharing trained KGE models with the\ncommunity.", "doi": "", "date": "2020-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.10560v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2481160427, "title": "An Information Diffusion Approach to Rumor Propagation and\n  Identification on Twitter", "abstract": "With the increasing use of online social networks as a source of news and\ninformation, the propensity for a rumor to disseminate widely and quickly poses\na great concern, especially in disaster situations where users do not have\nenough time to fact-check posts before making the informed decision to react to\na post that appears to be credible. In this study, we explore the propagation\npattern of rumors on Twitter by exploring the dynamics of microscopic-level\nmisinformation spread, based on the latent message and user interaction\nattributes. We perform supervised learning for feature selection and\nprediction. Experimental results with real-world data sets give the models'\nprediction accuracy at about 90\\% for the diffusion of both True and False\ntopics. Our findings confirm that rumor cascades run deeper and that rumor\nmasked as news, and messages that incite fear, will diffuse faster than other\nmessages. We show that the models for True and False message propagation differ\nsignificantly, both in the prediction parameters and in the message features\nthat govern the diffusion. Finally, we show that the diffusion pattern is an\nimportant metric in identifying the credibility of a tweet.", "doi": "", "date": "2020-02-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2002.11104v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3817725814, "title": "Scrutinizer: A Mixed-Initiative Approach to Large-Scale, Data-Driven\n  Claim Verification", "abstract": "Organizations such as the International Energy Agency (IEA) spend significant\namounts of time and money to manually fact check text documents summarizing\ndata. The goal of the Scrutinizer system is to reduce verification overheads by\nsupporting human fact checkers in translating text claims into SQL queries on\nan associated database.\n  Scrutinizer coordinates teams of human fact checkers. It reduces verification\ntime by proposing queries or query fragments to the users. Those proposals are\nbased on claim text classifiers, that gradually improve during the verification\nof a large document. In addition, Scrutinizer uses tentative execution of query\ncandidates to narrow down the set of alternatives. The verification process is\ncontrolled by a cost-based optimizer. It optimizes the interaction with users\nand prioritizes claim verifications. For the latter, it considers expected\nverification overheads as well as the expected claim utility as training\nsamples for the classifiers. We evaluate the Scrutinizer system using\nsimulations and a user study, based on actual claims and data and using\nprofessional fact checkers employed by IEA. Our experiments consistently\ndemonstrate significant savings in verification time, without reducing result\naccuracy.", "doi": "", "date": "2020-03-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.06708v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3204863503, "title": "Identifying Disinformation Websites Using Infrastructure Features", "abstract": "Platforms have struggled to keep pace with the spread of disinformation.\nCurrent responses like user reports, manual analysis, and third-party fact\nchecking are slow and difficult to scale, and as a result, disinformation can\nspread unchecked for some time after being created. Automation is essential for\nenabling platforms to respond rapidly to disinformation. In this work, we\nexplore a new direction for automated detection of disinformation websites:\ninfrastructure features. Our hypothesis is that while disinformation websites\nmay be perceptually similar to authentic news websites, there may also be\nsignificant non-perceptual differences in the domain registrations, TLS/SSL\ncertificates, and web hosting configurations. Infrastructure features are\nparticularly valuable for detecting disinformation websites because they are\navailable before content goes live and reaches readers, enabling early\ndetection. We demonstrate the feasibility of our approach on a large corpus of\nlabeled website snapshots. We also present results from a preliminary real-time\ndeployment, successfully discovering disinformation websites while highlighting\nunexplored challenges for automated disinformation detection.", "doi": "", "date": "2020-02-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.07684v5", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1680115045, "title": "Skepticism and rumor spreading: the role of spatial correlations", "abstract": "Critical thinking and skepticism are fundamental mechanisms that one may use\nto prevent the spreading of rumors, fake-news and misinformation. We consider a\nsimple model in which agents without previous contact with the rumor, being\nskeptically oriented, may convince spreaders to stop their activity or, once\nexposed to the rumor, decide not to propagate it as a consequence, for example,\nof fact-checking. We extend a previous, mean-field analysis of the combined\neffect of these two mechanisms, active and passive skepticism, to include\nspatial correlations. This can be done either analytically, through the pair\napproximation, or simulating an agent-based version on diverse networks. Our\nresults show that while in mean-field there is no coexistence between spreaders\nand susceptibles (although, depending on the parameters, there may be\nbistability depending on the initial conditions), when spatial correlations are\nincluded, because of the protective effect of the isolation provided by removed\nagents, coexistence is possible.", "doi": "10.1103/physreve.101.062418", "date": "2020-04-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.00777v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1974247915, "title": "Why do People Share Misinformation during the COVID-19 Pandemic?", "abstract": "The World Health Organization have emphasised that misinformation - spreading\nrapidly through social media - poses a serious threat to the COVID-19 response.\nDrawing from theories of health perception and cognitive load, we develop and\ntest a research model hypothesizing why people share unverified COVID-19\ninformation through social media. Our findings suggest a person's trust in\nonline information and perceived information overload are strong predictors of\nunverified information sharing. Furthermore, these factors, along with a\nperson's perceived COVID-19 severity and vulnerability influence cyberchondria.\nFemales were significantly more likely to suffer from cyberchondria, however,\nmales were more likely to share news without fact checking their source. Our\nfindings suggest that to mitigate the spread of COVID-19 misinformation and\ncyberchondria, measures should be taken to enhance a healthy skepticism of\nhealth news while simultaneously guarding against information overload.", "doi": "10.1080/0960085x.2020.1770632", "date": "2020-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.09600v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2627902104, "title": "Analyzing Political Parody in Social Media", "abstract": "Parody is a figurative device used to imitate an entity for comedic or\ncritical purposes and represents a widespread phenomenon in social media\nthrough many popular parody accounts. In this paper, we present the first\ncomputational study of parody. We introduce a new publicly available data set\nof tweets from real politicians and their corresponding parody accounts. We run\na battery of supervised machine learning models for automatically detecting\nparody tweets with an emphasis on robustness by testing on tweets from accounts\nunseen in training, across different genders and across countries. Our results\nshow that political parody tweets can be predicted with an accuracy up to 90%.\nFinally, we identify the markers of parody through a linguistic analysis.\nBeyond research in linguistics and political communication, accurately and\nautomatically detecting parody is important to improving fact checking for\njournalists and analytics such as sentiment analysis through filtering out\nparodical utterances.", "doi": "", "date": "2020-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.13878v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 217409772, "title": "Analysis of misinformation during the COVID-19 outbreak in China:\n  cultural, social and political entanglements", "abstract": "COVID-19 resulted in an infodemic, which could erode public trust, impede\nvirus containment, and outlive the pandemic itself. The evolving and fragmented\nmedia landscape is a key driver of the spread of misinformation. Using\nmisinformation identified by the fact-checking platform by Tencent and posts on\nWeibo, our results showed that the evolution of misinformation follows an\nissue-attention cycle, pertaining to topics such as city lockdown, cures, and\npreventions, and school reopening. Sources of authority weigh in on these\ntopics, but their influence is complicated by peoples' pre-existing beliefs and\ncultural practices. Finally, social media has a complicated relationship with\nestablished or legacy media systems. Sometimes they reinforce each other, but\nin general, social media may have a topic cycle of its own making. Our findings\nshed light on the distinct characteristics of misinformation during the\nCOVID-19 and offer insights into combating misinformation in China and across\nthe world at large.", "doi": "", "date": "2020-05-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.10414v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2157082790, "title": "The role of time scale in the spreading of asymmetrically interacting\n  diseases", "abstract": "Diseases and other contagion phenomena in nature and society can interact\nasymmetrically, such that one can benefit from the other, which in turn impairs\nthe first, in analogy with predator-prey systems. Here, we consider two models\nfor interacting disease-like dynamics with asymmetric interactions and\ndifferent associated time scales. Using rate equations for homogeneously mixed\npopulations, we show that the stationary prevalences and phase diagrams of each\nmodel behave differently with respect to variations of the relative time\nscales. We also characterize in detail the regime where transient oscillations\nare observed, a pattern that is inherent to asymmetrical interactions but often\nignored in the literature. Our results contribute to a better understanding of\ndisease dynamics in particular, and interacting processes in general, and could\nprovide interesting insights for real-world applications, most notably, the\ninterplay between the dynamics of fact-checked and fake news.", "doi": "10.1103/physrevresearch.3.013146", "date": "2020-06-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.02774v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2534458834, "title": "Tackling scalability issues in mining path patterns from knowledge\n  graphs: a preliminary study", "abstract": "Features mined from knowledge graphs are widely used within multiple\nknowledge discovery tasks such as classification or fact-checking. Here, we\nconsider a given set of vertices, called seed vertices, and focus on mining\ntheir associated neighboring vertices, paths, and, more generally, path\npatterns that involve classes of ontologies linked with knowledge graphs. Due\nto the combinatorial nature and the increasing size of real-world knowledge\ngraphs, the task of mining these patterns immediately entails scalability\nissues. In this paper, we address these issues by proposing a pattern mining\napproach that relies on a set of constraints (e.g., support or degree\nthresholds) and the monotonicity property. As our motivation comes from the\nmining of real-world knowledge graphs, we illustrate our approach with PGxLOD,\na biomedical knowledge graph.", "doi": "", "date": "2020-07-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.08821v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3705376194, "title": "Universal Fake News Collection System using Debunking Tweets", "abstract": "Large numbers of people use Social Networking Services (SNS) for easy access\nto various news, but they have more opportunities to obtain and share ``fake\nnews'' carrying false information. Partially to combat fake news, several\nfact-checking sites such as Snopes and PolitiFact have been founded.\nNevertheless, these sites rely on time-consuming and labor-intensive tasks.\nMoreover, their available languages are not extensive. To address these\ndifficulties, we propose a new fake news collection system based on rule-based\n(unsupervised) frameworks that can be extended easily for various languages.\nThe system collects news with high probability of being fake by debunking\ntweets by users and presents event clusters gathering higher attention. Our\nsystem currently functions in two languages: English and Japanese. It shows\nevent clusters, 65\\% of which are actually fake. In future studies, it will be\napplied to other languages and will be published with a large fake news\ndataset.", "doi": "", "date": "2020-07-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.14083v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2344536187, "title": "QMUL-SDS at CheckThat! 2020: Determining COVID-19 Tweet Check-Worthiness\n  Using an Enhanced CT-BERT with Numeric Expressions", "abstract": "This paper describes the participation of the QMUL-SDS team for Task 1 of the\nCLEF 2020 CheckThat! shared task. The purpose of this task is to determine the\ncheck-worthiness of tweets about COVID-19 to identify and prioritise tweets\nthat need fact-checking. The overarching aim is to further support ongoing\nefforts to protect the public from fake news and help people find reliable\ninformation. We describe and analyse the results of our submissions. We show\nthat a CNN using COVID-Twitter-BERT (CT-BERT) enhanced with numeric expressions\ncan effectively boost performance from baseline results. We also show results\nof training data augmentation with rumours on other topics. Our best system\nranked fourth in the task with encouraging outcomes showing potential for\nimproved results in the future.", "doi": "", "date": "2020-08-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.13160v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2264582811, "title": "ArCOV19-Rumors: Arabic COVID-19 Twitter Dataset for Misinformation\n  Detection", "abstract": "In this paper we introduce ArCOV19-Rumors, an Arabic COVID-19 Twitter dataset\nfor misinformation detection composed of tweets containing claims from 27th\nJanuary till the end of April 2020. We collected 138 verified claims, mostly\nfrom popular fact-checking websites, and identified 9.4K relevant tweets to\nthose claims. Tweets were manually-annotated by veracity to support research on\nmisinformation detection, which is one of the major problems faced during a\npandemic. ArCOV19-Rumors supports two levels of misinformation detection over\nTwitter: verifying free-text claims (called claim-level verification) and\nverifying claims expressed in tweets (called tweet-level verification). Our\ndataset covers, in addition to health, claims related to other topical\ncategories that were influenced by COVID-19, namely, social, politics, sports,\nentertainment, and religious. Moreover, we present benchmarking results for\ntweet-level verification on the dataset. We experimented with SOTA models of\nversatile approaches that either exploit content, user profiles features,\ntemporal features and propagation structure of the conversational threads for\ntweet verification.", "doi": "", "date": "2020-10-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.08768v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2146968747, "title": "Encounters with Visual Misinformation and Labels Across Platforms: An\n  Interview and Diary Study to Inform Ecosystem Approaches to Misinformation\n  Interventions", "abstract": "Since 2016, the amount of academic research with the keyword \"misinformation\"\nhas more than doubled [2]. This research often focuses on article headlines\nshown in artificial testing environments, yet misinformation largely spreads\nthrough images and video posts shared in highly-personalized platform contexts.\nA foundation of qualitative research is necessary to begin filling this gap to\nensure platforms' visual misinformation interventions are aligned with users'\nneeds and understanding of information in their personal contexts, across\nplatforms. In two studies, we combined in-depth interviews (n=15) with diary\nand co-design methods (n=23) to investigate how a broad mix of Americans\nexposed to misinformation during COVID-19 understand their visual information\nenvironments, including encounters with interventions such as Facebook\nfact-checking labels. Analysis reveals a deep division in user attitudes about\nplatform labeling interventions for visual information which are perceived by\nmany as overly paternalistic, biased, and punitive. Alongside these findings,\nwe discuss our methods as a model for continued independent qualitative\nresearch on cross-platform user experiences of misinformation that inform\ninterventions.", "doi": "", "date": "2020-11-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.12758v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3280229929, "title": "Evidence-based Factual Error Correction", "abstract": "This paper introduces the task of factual error correction: performing edits\nto a claim so that the generated rewrite is better supported by evidence. This\nextends the well-studied task of fact verification by providing a mechanism to\ncorrect written texts that are refuted or only partially supported by evidence.\nWe demonstrate that it is feasible to train factual error correction systems\nfrom existing fact checking datasets which only contain labeled claims\naccompanied by evidence, but not the correction. We achieve this by employing a\ntwo-stage distant supervision approach that incorporates evidence into masked\nclaims when generating corrections. Our approach, based on the T5 transformer\nand using retrieved evidence, achieved better results than existing work which\nused a pointer copy network and gold evidence, producing accurate factual error\ncorrections for 5x more instances in human evaluation and a .125 increase in\nSARI score. The evaluation is conducted on a dataset of 65,000 instances based\non a recent fact verification shared task and we release it to enable further\nwork on the task.", "doi": "", "date": "2020-12-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.15788v2", "pdf": ""}, "publisher-venue": "ACL2021", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 15053175, "title": "Multi-task Retrieval for Knowledge-Intensive Tasks", "abstract": "Retrieving relevant contexts from a large corpus is a crucial step for tasks\nsuch as open-domain question answering and fact checking. Although neural\nretrieval outperforms traditional methods like tf-idf and BM25, its performance\ndegrades considerably when applied to out-of-domain data.\n  Driven by the question of whether a neural retrieval model can be universal\nand perform robustly on a wide variety of problems, we propose a multi-task\ntrained model. Our approach not only outperforms previous methods in the\nfew-shot setting, but also rivals specialised neural retrievers, even when\nin-domain training data is abundant. With the help of our retriever, we improve\nexisting models for downstream tasks and closely match or improve the state of\nthe art on multiple benchmarks.", "doi": "", "date": "2021-01-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.00117v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 848647816, "title": "Eating Garlic Prevents COVID-19 Infection: Detecting Misinformation on\n  the Arabic Content of Twitter", "abstract": "The rapid growth of social media content during the current pandemic provides\nuseful tools for disseminating information which has also become a root for\nmisinformation. Therefore, there is an urgent need for fact-checking and\neffective techniques for detecting misinformation in social media. In this\nwork, we study the misinformation in the Arabic content of Twitter. We\nconstruct a large Arabic dataset related to COVID-19 misinformation and\ngold-annotate the tweets into two categories: misinformation or not. Then, we\napply eight different traditional and deep machine learning models, with\ndifferent features including word embeddings and word frequency. The word\nembedding models (\\textsc{FastText} and word2vec) exploit more than two million\nArabic tweets related to COVID-19. Experiments show that optimizing the area\nunder the curve (AUC) improves the models' performance and the Extreme Gradient\nBoosting (XGBoost) presents the highest accuracy in detecting COVID-19\nmisinformation online.", "doi": "", "date": "2021-01-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.05626v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2576896097, "title": "TruthBot: An Automated Conversational Tool for Intent Learning, Curated\n  Information Presenting, and Fake News Alerting", "abstract": "We present TruthBot, an all-in-one multilingual conversational chatbot\ndesigned for seeking truth (trustworthy and verified information) on specific\ntopics. It helps users to obtain information specific to certain topics,\nfact-check information, and get recent news. The chatbot learns the intent of a\nquery by training a deep neural network from the data of the previous intents\nand responds appropriately when it classifies the intent in one of the classes\nabove. Each class is implemented as a separate module that uses either its own\ncurated knowledge-base or searches the web to obtain the correct information.\nThe topic of the chatbot is currently set to COVID-19. However, the bot can be\neasily customized to any topic-specific responses. Our experimental results\nshow that each module performs significantly better than its closest\ncompetitor, which is verified both quantitatively and through several\nuser-based surveys in multiple languages. TruthBot has been deployed in June\n2020 and is currently running.", "doi": "", "date": "2021-01-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.00509v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 515533481, "title": "NELA-GT-2020: A Large Multi-Labelled News Dataset for The Study of\n  Misinformation in News Articles", "abstract": "In this paper, we present an updated version of the NELA-GT-2019 dataset,\nentitled NELA-GT-2020. NELA-GT-2020 contains nearly 1.8M news articles from 519\nsources collected between January 1st, 2020 and December 31st, 2020. Just as\nwith NELA-GT-2018 and NELA-GT-2019, these sources come from a wide range of\nmainstream news sources and alternative news sources. Included in the dataset\nare source-level ground truth labels from Media Bias/Fact Check (MBFC) covering\nmultiple dimensions of veracity. Additionally, new in the 2020 dataset are the\nTweets embedded in the collected news articles, adding an extra layer of\ninformation to the data. The NELA-GT-2020 dataset can be found at\nhttps://doi.org/10.7910/DVN/CHMUYZ.", "doi": "", "date": "2021-02-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.04567v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1322113724, "title": "SCARLET: Explainable Attention based Graph Neural Network for Fake News\n  spreader prediction", "abstract": "False information and true information fact checking it, often co-exist in\nsocial networks, each competing to influence people in their spread paths. An\nefficient strategy here to contain false information is to proactively identify\nif nodes in the spread path are likely to endorse false information (i.e.\nfurther spread it) or refutation information (thereby help contain false\ninformation spreading). In this paper, we propose SCARLET (truSt and\nCredibility bAsed gRaph neuraL nEtwork model using aTtention) to predict likely\naction of nodes in the spread path. We aggregate trust and credibility features\nfrom a node's neighborhood using historical behavioral data and network\nstructure and explain how features of a spreader's neighborhood vary. Using\nreal world Twitter datasets, we show that the model is able to predict false\ninformation spreaders with an accuracy of over 87%.", "doi": "", "date": "2021-02-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.04627v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 138365676, "title": "An ontological analysis of misinformation in online social networks", "abstract": "The internet, Online Social Networks (OSNs) and smart phones enable users to\ncreate tremendous amount of information. Users who search for general or\nspecific knowledge may not have these days problems of information scarce but\nmisinformation. Misinformation nowadays can refer to a continuous spectrum\nbetween what can be seen as \"facts\" or \"truth\", if humans agree on the\nexistence of such, to false information that everyone agree that it is false.\nIn this paper, we will look at this spectrum of information/misinformation and\ncompare between some of the major relevant concepts. While few fact-checking\nwebsites exist to evaluate news articles or some of the popular claims people\nexchange, nonetheless this can be seen as a little effort in the mission to tag\nonline information with their \"proper\" category or label.", "doi": "", "date": "2021-02-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.11362v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4209867251, "title": "Get Your Vitamin C! Robust Fact Verification with Contrastive Evidence", "abstract": "Typical fact verification models use retrieved written evidence to verify\nclaims. Evidence sources, however, often change over time as more information\nis gathered and revised. In order to adapt, models must be sensitive to subtle\ndifferences in supporting evidence. We present VitaminC, a benchmark infused\nwith challenging cases that require fact verification models to discern and\nadjust to slight factual changes. We collect over 100,000 Wikipedia revisions\nthat modify an underlying fact, and leverage these revisions, together with\nadditional synthetically constructed ones, to create a total of over 400,000\nclaim-evidence pairs. Unlike previous resources, the examples in VitaminC are\ncontrastive, i.e., they contain evidence pairs that are nearly identical in\nlanguage and content, with the exception that one supports a given claim while\nthe other does not. We show that training using this design increases\nrobustness -- improving accuracy by 10% on adversarial fact verification and 6%\non adversarial natural language inference (NLI). Moreover, the structure of\nVitaminC leads us to define additional tasks for fact-checking resources:\ntagging relevant words in the evidence for verifying the claim, identifying\nfactual revisions, and providing automatic edits via factually consistent text\ngeneration.", "doi": "", "date": "2021-03-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.08541v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 106412734, "title": "On Representation Learning for Scientific News Articles Using\n  Heterogeneous Knowledge Graphs", "abstract": "In the era of misinformation and information inflation, the credibility\nassessment of the produced news is of the essence. However, fact-checking can\nbe challenging considering the limited references presented in the news. This\nchallenge can be transcended by utilizing the knowledge graph that is related\nto the news articles. In this work, we present a methodology for creating\nscientific news article representations by modeling the directed graph between\nthe scientific news articles and the cited scientific publications. The network\nused for the experiments is comprised of the scientific news articles, their\ntopic, the cited research literature, and their corresponding authors. We\nimplement and present three different approaches: 1) a baseline Relational\nGraph Convolutional Network (R-GCN), 2) a Heterogeneous Graph Neural Network\n(HetGNN) and 3) a Heterogeneous Graph Transformer (HGT). We test these models\nin the downstream task of link prediction on the: a) news article - paper links\nand b) news article - article topic links. The results show promising\napplications of graph neural network approaches in the domains of knowledge\ntracing and scientific news credibility assessment.", "doi": "10.1145/3442442.3451362", "date": "2021-04-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.05866v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 363891168, "title": "Misinfo Belief Frames: A Case Study on Covid & Climate News", "abstract": "Prior beliefs of readers impact the way in which they project meaning onto\nnews headlines. These beliefs can influence their perception of news\nreliability, as well as their reaction to news, and their likelihood of\nspreading the misinformation through social networks. However, most prior work\nfocuses on fact-checking veracity of news or stylometry rather than measuring\nimpact of misinformation. We propose Misinfo Belief Frames, a formalism for\nunderstanding how readers perceive the reliability of news and the impact of\nmisinformation. We also introduce the Misinfo Belief Frames (MBF) corpus, a\ndataset of 66k inferences over 23.5k headlines. Misinformation frames use\ncommonsense reasoning to uncover implications of real and fake news headlines\nfocused on global crises: the Covid-19 pandemic and climate change. Our results\nusing large-scale language modeling to predict misinformation frames show that\nmachine-generated inferences can influence readers' trust in news headlines\n(readers' trust in news headlines was affected in 29.3% of cases). This\ndemonstrates the potential effectiveness of using generated frames to counter\nmisinformation.", "doi": "", "date": "2021-04-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.08790v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 899884108, "title": "Claim Detection in Biomedical Twitter Posts", "abstract": "Social media contains unfiltered and unique information, which is potentially\nof great value, but, in the case of misinformation, can also do great harm.\nWith regards to biomedical topics, false information can be particularly\ndangerous. Methods of automatic fact-checking and fake news detection address\nthis problem, but have not been applied to the biomedical domain in social\nmedia yet. We aim to fill this research gap and annotate a corpus of 1200\ntweets for implicit and explicit biomedical claims (the latter also with span\nannotations for the claim phrase). With this corpus, which we sample to be\nrelated to COVID-19, measles, cystic fibrosis, and depression, we develop\nbaseline models which detect tweets that contain a claim automatically. Our\nanalyses reveal that biomedical tweets are densely populated with claims (45 %\nin a corpus sampled to contain 1200 tweets focused on the domains mentioned\nabove). Baseline classification experiments with embedding-based classifiers\nand BERT-based transfer learning demonstrate that the detection is challenging,\nhowever, shows acceptable performance for the identification of explicit\nexpressions of claims. Implicit claim tweets are more challenging to detect.", "doi": "", "date": "2021-04-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.11639v2", "pdf": ""}, "publisher-venue": "the BioNLP Workshop at NAACL 2021", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2903490491, "title": "QuTI! Quantifying Text-Image Consistency in Multimodal Documents", "abstract": "The World Wide Web and social media platforms have become popular sources for\nnews and information. Typically, multimodal information, e.g., image and text\nis used to convey information more effectively and to attract attention. While\nin most cases image content is decorative or depicts additional information, it\nhas also been leveraged to spread misinformation and rumors in recent years. In\nthis paper, we present a Web-based demo application that automatically\nquantifies the cross-modal relations of entities (persons, locations, and\nevents) in image and text. The applications are manifold. For example, the\nsystem can help users to explore multimodal articles more efficiently, or can\nassist human assessors and fact-checking efforts in the verification of the\ncredibility of news stories, tweets, or other multimodal documents.", "doi": "", "date": "2021-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13748v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 465365887, "title": "The Evolution of Rumors on a Closed Platform during COVID-19", "abstract": "In this work we looked into a dataset of 114 thousands of suspicious messages\ncollected from the most popular closed messaging platform in Taiwan between\nJanuary and July, 2020. We proposed an hybrid algorithm that could efficiently\ncluster a large number of text messages according their topics and narratives.\nThat is, we obtained groups of messages that are within a limited content\nalterations within each other. By employing the algorithm to the dataset, we\nwere able to look at the content alterations and the temporal dynamics of each\nparticular rumor over time. With qualitative case studies of three COVID-19\nrelated rumors, we have found that key authoritative figures were often\nmisquoted in false information. It was an effective measure to increase the\npopularity of one false information. In addition, fact-check was not effective\nin stopping misinformation from getting attention. In fact, the popularity of\none false information was often more influenced by major societal events and\neffective content alterations.", "doi": "", "date": "2021-04-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.13816v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4123898066, "title": "AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News and Hate Speech\n  Detection Dataset", "abstract": "Along with the COVID-19 pandemic, an \"infodemic\" of false and misleading\ninformation has emerged and has complicated the COVID-19 response efforts.\nSocial networking sites such as Facebook and Twitter have contributed largely\nto the spread of rumors, conspiracy theories, hate, xenophobia, racism, and\nprejudice. To combat the spread of fake news, researchers around the world have\nand are still making considerable efforts to build and share COVID-19 related\nresearch articles, models, and datasets. This paper releases \"AraCOVID19-MFH\" a\nmanually annotated multi-label Arabic COVID-19 fake news and hate speech\ndetection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10\ndifferent labels. The labels have been designed to consider some aspects\nrelevant to the fact-checking task, such as the tweet's check worthiness,\npositivity/negativity, and factuality. To confirm our annotated dataset's\npractical utility, we used it to train and evaluate several classification\nmodels and reported the obtained results. Though the dataset is mainly designed\nfor fake news detection, it can also be used for hate speech detection,\nopinion/news classification, dialect identification, and many other tasks.", "doi": "", "date": "2021-05-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.03143v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3635545484, "title": "FBAdTracker: An Interactive Data Collection and Analysis Tool for\n  Facebook Advertisements", "abstract": "The growing use of social media has led to drastic changes in our\ndecision-making. Especially, Facebook offers marketing API which promotes\nbusiness to target potential groups who are likely to consume their items.\nHowever, this service can be abused by malicious advertisers who attempt to\ndeceive people by disinformation such as propaganda and divisive opinion. To\ncounter this problem, we introduce a new application named FBAdTracker. The\npurpose of this application is to provide an integrated data collection and\nanalysis system for current research on fact-checking related to Facebook\nadvertisements. Our system is capable of monitoring up-to-date Facebook ads and\nanalyzing ads retrieved from Facebook Ads Library.", "doi": "", "date": "2021-05-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.00142v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3280229929, "title": "Evidence-based Factual Error Correction", "abstract": "This paper introduces the task of factual error correction: performing edits\nto a claim so that the generated rewrite is better supported by evidence. This\nextends the well-studied task of fact verification by providing a mechanism to\ncorrect written texts that are refuted or only partially supported by evidence.\nWe demonstrate that it is feasible to train factual error correction systems\nfrom existing fact checking datasets which only contain labeled claims\naccompanied by evidence, but not the correction. We achieve this by employing a\ntwo-stage distant supervision approach that incorporates evidence into masked\nclaims when generating corrections. Our approach, based on the T5 transformer\nand using retrieved evidence, achieved better results than existing work which\nused a pointer copy network and gold evidence, producing accurate factual error\ncorrections for 5x more instances in human evaluation and a .125 increase in\nSARI score. The evaluation is conducted on a dataset of 65,000 instances based\non a recent fact verification shared task and we release it to enable further\nwork on the task.", "doi": "", "date": "2021-06-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.01072v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 835163275, "title": "Evaluating Entity Disambiguation and the Role of Popularity in\n  Retrieval-Based NLP", "abstract": "Retrieval is a core component for open-domain NLP tasks. In open-domain\ntasks, multiple entities can share a name, making disambiguation an inherent\nyet under-explored problem. We propose an evaluation benchmark for assessing\nthe entity disambiguation capabilities of these retrievers, which we call\nAmbiguous Entity Retrieval (AmbER) sets. We define an AmbER set as a collection\nof entities that share a name along with queries about those entities. By\ncovering the set of entities for polysemous names, AmbER sets act as a\nchallenging test of entity disambiguation. We create AmbER sets for three\npopular open-domain tasks: fact checking, slot filling, and question answering,\nand evaluate a diverse set of retrievers. We find that the retrievers exhibit\npopularity bias, significantly under-performing on rarer entities that share a\nname, e.g., they are twice as likely to retrieve erroneous documents on queries\nfor the less popular entity under the same name. These experiments on AmbER\nsets show their utility as an evaluation tool and highlight the weaknesses of\npopular retrieval systems.", "doi": "", "date": "2021-06-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.06830v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 694244146, "title": "Infodemics on Youtube: Reliability of Content and Echo Chambers on\n  COVID-19", "abstract": "Social media radically changed how information is consumed and reported.\nMoreover, social networks elicited a disintermediated access to an\nunprecedented amount of content. The world health organization (WHO) coined the\nterm infodemics to identify the information overabundance during an epidemic.\nIndeed, the spread of inaccurate and misleading information may alter behaviors\nand complicate crisis management and health responses. This paper addresses\ninformation diffusion during the COVID-19 pandemic period with a massive data\nanalysis on YouTube. First, we analyze more than 2M users' engagement in 13000\nvideos released by 68 different YouTube channels, with different political bias\nand fact-checking indexes. We then investigate the relationship between each\nuser's political preference and her/his consumption of questionable/reliable\ninformation. Our results, quantified using information theory measures, provide\nevidence for the existence of echo chambers across two dimensions represented\nby the political bias and by the trustworthiness of information channels.\nFinally, we observe that the echo chamber structure cannot be reproduced after\nproperly randomizing the users' interaction patterns.", "doi": "", "date": "2021-06-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.08684v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4034985354, "title": "Fact Check: Analyzing Financial Events from Multilingual News Sources", "abstract": "The explosion in the sheer magnitude and complexity of financial news data in\nrecent years makes it increasingly challenging for investment analysts to\nextract valuable insights and perform analysis. We propose FactCheck in\nfinance, a web-based news aggregator with deep learning models, to provide\nanalysts with a holistic view of important financial events from multilingual\nnews sources and extract events using an unsupervised clustering method. A web\ninterface is provided to examine the credibility of news articles using a\ntransformer-based fact-checker. The performance of the fact checker is\nevaluated using a dataset related to merger and acquisition (M\\&A) events and\nis shown to outperform several strong baselines.", "doi": "", "date": "2021-06-29", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.15221v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 840841843, "title": "Tackling COVID-19 Infodemic using Deep Learning", "abstract": "Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia.", "doi": "", "date": "2021-07-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.02012v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1705294604, "title": "Leveraging Commonsense Knowledge on Classifying False News and\n  Determining Checkworthiness of Claims", "abstract": "Widespread and rapid dissemination of false news has made fact-checking an\nindispensable requirement. Given its time-consuming and labor-intensive nature,\nthe task calls for an automated support to meet the demand. In this paper, we\npropose to leverage commonsense knowledge for the tasks of false news\nclassification and check-worthy claim detection. Arguing that commonsense\nknowledge is a factor in human believability, we fine-tune the BERT language\nmodel with a commonsense question answering task and the aforementioned tasks\nin a multi-task learning environment. For predicting fine-grained false news\ntypes, we compare the proposed fine-tuned model's performance with the false\nnews classification models on a public dataset as well as a newly collected\ndataset. We compare the model's performance with the single-task BERT model and\na state-of-the-art check-worthy claim detection tool to evaluate the\ncheck-worthy claim detection. Our experimental analysis demonstrates that\ncommonsense knowledge can improve performance in both tasks.", "doi": "", "date": "2021-08-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.03731v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2444011674, "title": "NoFake at CheckThat! 2021: Fake News Detection Using BERT", "abstract": "Much research has been done for debunking and analysing fake news. Many\nresearchers study fake news detection in the last year, but many are limited to\nsocial media data. Currently, multiples fact-checkers are publishing their\nresults in various formats. Also, multiple fact-checkers use different labels\nfor the fake news, making it difficult to make a generalisable classifier. With\nthe merge classes, the performance of the machine model can be enhanced. This\ndomain categorisation will help group the article, which will help save the\nmanual effort in assigning the claim verification. In this paper, we have\npresented BERT based classification model to predict the domain and\nclassification. We have also used additional data from fact-checked articles.\nWe have achieved a macro F1 score of 83.76 % for Task 3Aand 85.55 % for Task 3B\nusing the additional training data.", "doi": "", "date": "2021-08-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.05419v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1880915272, "title": "Fake News Detection in Social Networks via Crowd Signals", "abstract": "Our work considers leveraging crowd signals for detecting fake news and is\nmotivated by tools recently introduced by Facebook that enable users to flag\nfake news. By aggregating users' flags, our goal is to select a small subset of\nnews every day, send them to an expert (e.g., via a third-party fact-checking\norganization), and stop the spread of news identified as fake by an expert. The\nmain objective of our work is to minimize the spread of misinformation by\nstopping the propagation of fake news in the network. It is especially\nchallenging to achieve this objective as it requires detecting fake news with\nhigh-confidence as quickly as possible. We show that in order to leverage\nusers' flags efficiently, it is crucial to learn about users' flagging\naccuracy. We develop a novel algorithm, DETECTIVE, that performs Bayesian\ninference for detecting fake news and jointly learns about users' flagging\naccuracy over time. Our algorithm employs posterior sampling to actively trade\noff exploitation (selecting news that maximize the objective value at a given\nepoch) and exploration (selecting news that maximize the value of information\ntowards learning about users' flagging accuracy). We demonstrate the\neffectiveness of our approach via extensive experiments and show the power of\nleveraging community signals for fake news detection.", "doi": "", "date": "2017-11-24", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1711.09025v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1237972329, "title": "Image Provenance Analysis at Scale", "abstract": "Prior art has shown it is possible to estimate, through image processing and\ncomputer vision techniques, the types and parameters of transformations that\nhave been applied to the content of individual images to obtain new images.\nGiven a large corpus of images and a query image, an interesting further step\nis to retrieve the set of original images whose content is present in the query\nimage, as well as the detailed sequences of transformations that yield the\nquery image given the original images. This is a problem that recently has\nreceived the name of image provenance analysis. In these times of public media\nmanipulation ( e.g., fake news and meme sharing), obtaining the history of\nimage transformations is relevant for fact checking and authorship\nverification, among many other applications. This article presents an\nend-to-end processing pipeline for image provenance analysis, which works at\nreal-world scale. It employs a cutting-edge image filtering solution that is\ncustom-tailored for the problem at hand, as well as novel techniques for\nobtaining the provenance graph that expresses how the images, as nodes, are\nancestrally connected. A comprehensive set of experiments for each stage of the\npipeline is provided, comparing the proposed solution with state-of-the-art\nresults, employing previously published datasets. In addition, this work\nintroduces a new dataset of real-world provenance cases from the social media\nsite Reddit, along with baseline results.", "doi": "", "date": "2018-01-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1801.06510v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3557215173, "title": "A personal model of trumpery: Deception detection in a real-world\n  high-stakes setting", "abstract": "Language use reveals information about who we are and how we feel1-3. One of\nthe pioneers in text analysis, Walter Weintraub, manually counted which types\nof words people used in medical interviews and showed that the frequency of\nfirst-person singular pronouns (i.e., I, me, my) was a reliable indicator of\ndepression, with depressed people using I more often than people who are not\ndepressed4. Several studies have demonstrated that language use also differs\nbetween truthful and deceptive statements5-7, but not all differences are\nconsistent across people and contexts, making prediction difficult8. Here we\nshow how well linguistic deception detection performs at the individual level\nby developing a model tailored to a single individual: the current US\npresident. Using tweets fact-checked by an independent third party (Washington\nPost), we found substantial linguistic differences between factually correct\nand incorrect tweets and developed a quantitative model based on these\ndifferences. Next, we predicted whether out-of-sample tweets were either\nfactually correct or incorrect and achieved a 73% overall accuracy. Our results\ndemonstrate the power of linguistic analysis in real-world deception research\nwhen applied at the individual level and provide evidence that factually\nincorrect tweets are not random mistakes of the sender.", "doi": "", "date": "2018-11-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.01938v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2959210153, "title": "Combining Fact Extraction and Verification with Neural Semantic Matching\n  Networks", "abstract": "The increasing concern with misinformation has stimulated research efforts on\nautomatic fact checking. The recently-released FEVER dataset introduced a\nbenchmark fact-verification task in which a system is asked to verify a claim\nusing evidential sentences from Wikipedia documents. In this paper, we present\na connected system consisting of three homogeneous neural semantic matching\nmodels that conduct document retrieval, sentence selection, and claim\nverification jointly for fact extraction and verification. For evidence\nretrieval (document retrieval and sentence selection), unlike traditional\nvector space IR models in which queries and sources are matched in some\npre-designed term vector space, we develop neural models to perform deep\nsemantic matching from raw textual input, assuming no intermediate term\nrepresentation and no access to structured external knowledge bases. We also\nshow that Pageview frequency can also help improve the performance of evidence\nretrieval results, that later can be matched by using our neural semantic\nmatching network. For claim verification, unlike previous approaches that\nsimply feed upstream retrieved evidence and the claim to a natural language\ninference (NLI) model, we further enhance the NLI model by providing it with\ninternal semantic relatedness scores (hence integrating it with the evidence\nretrieval modules) and ontological WordNet features. Experiments on the FEVER\ndataset indicate that (1) our neural semantic matching method outperforms\npopular TF-IDF and encoder models, by significant margins on all evidence\nretrieval metrics, (2) the additional relatedness score and WordNet features\nimprove the NLI model via better semantic awareness, and (3) by formalizing all\nthree subtasks as a similar semantic matching problem and improving on all\nthree stages, the complete model is able to achieve the state-of-the-art\nresults on the FEVER test set.", "doi": "", "date": "2018-11-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1811.07039v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1848677359, "title": "It's Always April Fools' Day! On the Difficulty of Social Network\n  Misinformation Classification via Propagation Features", "abstract": "Given the huge impact that Online Social Networks (OSN) had in the way people\nget informed and form their opinion, they became an attractive playground for\nmalicious entities that want to spread misinformation, and leverage their\neffect. In fact, misinformation easily spreads on OSN and is a huge threat for\nmodern society, possibly influencing also the outcome of elections, or even\nputting people's life at risk (e.g., spreading \"anti-vaccines\" misinformation).\nTherefore, it is of paramount importance for our society to have some sort of\n\"validation\" on information spreading through OSN. The need for a wide-scale\nvalidation would greatly benefit from automatic tools.\n  In this paper, we show that it is difficult to carry out an automatic\nclassification of misinformation considering only structural properties of\ncontent propagation cascades. We focus on structural properties, because they\nwould be inherently difficult to be manipulated, with the the aim of\ncircumventing classification systems. To support our claim, we carry out an\nextensive evaluation on Facebook posts belonging to conspiracy theories (as\nrepresentative of misinformation), and scientific news (representative of\nfact-checked content). Our findings show that conspiracy content actually\nreverberates in a way which is hard to distinguish from the one scientific\ncontent does: for the classification mechanisms we investigated, classification\nF1-score never exceeds 0.65 during content propagation stages, and is still\nless than 0.7 even after propagation is complete.", "doi": "", "date": "2017-01-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1701.04221v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3993308270, "title": "Catching Zika Fever: Application of Crowdsourcing and Machine Learning\n  for Tracking Health Misinformation on Twitter", "abstract": "In February 2016, World Health Organization declared the Zika outbreak a\nPublic Health Emergency of International Concern. With developing evidence it\ncan cause birth defects, and the Summer Olympics coming up in the worst\naffected country, Brazil, the virus caught fire on social media. In this work,\nuse Zika as a case study in building a tool for tracking the misinformation\naround health concerns on Twitter. We collect more than 13 million tweets --\nspanning the initial reports in February 2016 and the Summer Olympics --\nregarding the Zika outbreak and track rumors outlined by the World Health\nOrganization and Snopes fact checking website. The tool pipeline, which\nincorporates health professionals, crowdsourcing, and machine learning, allows\nus to capture health-related rumors around the world, as well as clarification\ncampaigns by reputable health organizations. In the case of Zika, we discover\nan extremely bursty behavior of rumor-related topics, and show that, once the\nquestionable topic is detected, it is possible to identify rumor-bearing tweets\nusing automated techniques. Thus, we illustrate insights the proposed tools\nprovide into potentially harmful information on social media, allowing public\nhealth researchers and practitioners to respond with a targeted and timely\naction.", "doi": "", "date": "2017-07-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1707.03778v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3909045775, "title": "Verifying Text Summaries of Relational Data Sets", "abstract": "We present a novel natural language query interface, the AggChecker, aimed at\ntext summaries of relational data sets. The tool focuses on natural language\nclaims that translate into an SQL query and a claimed query result. Similar in\nspirit to a spell checker, the AggChecker marks up text passages that seem to\nbe inconsistent with the actual data. At the heart of the system is a\nprobabilistic model that reasons about the input document in a holistic\nfashion. Based on claim keywords and the document structure, it maps each text\nclaim to a probability distribution over associated query translations. By\nefficiently executing tens to hundreds of thousands of candidate translations\nfor a typical input document, the system maps text claims to correctness\nprobabilities. This process becomes practical via a specialized processing\nbackend, avoiding redundant work via query merging and result caching.\nVerification is an interactive process in which users are shown tentative\nresults, enabling them to take corrective actions if necessary.\n  Our system was tested on a set of 53 public articles containing 392 claims.\nOur test cases include articles from major newspapers, summaries of survey\nresults, and Wikipedia articles. Our tool revealed erroneous claims in roughly\na third of test cases. A detailed user study shows that users using our tool\nare in average six times faster at checking text summaries, compared to generic\nSQL interfaces. In fully automated verification, our tool achieves\nsignificantly higher recall and precision than baselines from the areas of\nnatural language query interfaces and fact-checking.", "doi": "", "date": "2018-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1804.07686v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3270184397, "title": "Belittling the Source: Trustworthiness Indicators to Obfuscate Fake News\n  on the Web", "abstract": "With the growth of the internet, the number of fake-news online has been\nproliferating every year. The consequences of such phenomena are manifold,\nranging from lousy decision-making process to bullying and violence episodes.\nTherefore, fact-checking algorithms became a valuable asset. To this aim, an\nimportant step to detect fake-news is to have access to a credibility score for\na given information source. However, most of the widely used Web indicators\nhave either been shut-down to the public (e.g., Google PageRank) or are not\nfree for use (Alexa Rank). Further existing databases are short-manually\ncurated lists of online sources, which do not scale. Finally, most of the\nresearch on the topic is theoretical-based or explore confidential data in a\nrestricted simulation environment. In this paper we explore current research,\nhighlight the challenges and propose solutions to tackle the problem of\nclassifying websites into a credibility scale. The proposed model automatically\nextracts source reputation cues and computes a credibility factor, providing\nvaluable insights which can help in belittling dubious and confirming trustful\nunknown websites. Experimental results outperform state of the art in the\n2-classes and 5-classes setting.", "doi": "", "date": "2018-09-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1809.00494v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2601928111, "title": "Learning through the Grapevine: The Impact of Noise and the Breadth and\n  Depth of Social Networks", "abstract": "We examine how well people learn when information is noisily relayed from\nperson to person; and we study how communication platforms can improve learning\nwithout censoring or fact-checking messages. We analyze learning as a function\nof social network depth (how many times information is relayed) and breadth\n(the number of relay chains accessed). Noise builds up as depth increases, so\nlearning requires greater breadth. In the presence of mutations (deliberate or\nrandom) and transmission failures of messages, we characterize sharp thresholds\nfor breadths above which receivers learn fully and below which they learn\nnothing. When there is uncertainty about mutation rates, optimizing learning\nrequires either capping depth, or if that is not possible, limiting breadth by\ncapping the number of people to whom someone can forward a message. Limiting\nbreadth cuts the number of messages received but also decreases the fraction\noriginating further from the receiver, and so can increase the signal to noise\nratio. Finally, we extend our model to study learning from message survival:\ne.g., people are more likely to pass messages with one conclusion than another.\nWe find that as depth grows, all learning comes from either the total number of\nmessages received or from the content of received messages, but the learner\ndoes not need to pay attention to both.", "doi": "", "date": "2018-12-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1812.03354v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1113248402, "title": "Human-Misinformation interaction: Understanding the interdisciplinary\n  approach needed to computationally combat false information", "abstract": "The prevalence of new technologies and social media has amplified the effects\nof misinformation on our societies. Thus, it is necessary to create\ncomputational tools to mitigate their effects effectively. This study aims to\nprovide a critical overview of computational approaches concerned with\ncombating misinformation. To this aim, I offer an overview of scholarly\ndefinitions of misinformation. I adopt a framework for studying misinformation\nthat suggests paying attention to the source, content, and consumers as the\nthree main elements involved in the process of misinformation and I provide an\noverview of literature from disciplines of psychology, media studies, and\ncognitive sciences that deal with each of these elements. Using the framework,\nI overview the existing computational methods that deal with 1) misinformation\ndetection and fact-checking using Content 2) Identifying untrustworthy Sources\nand social bots, and 3) Consumer-facing tools and methods aiming to make humans\nresilient to misinformation. I find that the vast majority of works in computer\nscience and information technology is concerned with the crucial tasks of\ndetection and verification of content and sources of misinformation. Moreover,\nI find that computational research focusing on Consumers of Misinformation in\nHuman-Computer Interaction (HCI) and related fields are very sparse and often\ndo not deal with the subtleties of this process. The majority of existing\ninterfaces and systems are less concerned with the usability of the tools\nrather than the robustness and accuracy of the detection methods. Using this\nsurvey, I call for an interdisciplinary approach towards human-misinformation\ninteraction that focuses on building methods and tools that robustly deal with\nsuch complex psychological/social phenomena.", "doi": "", "date": "2019-03-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1903.07136v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3368024342, "title": "Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements", "abstract": "In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.", "doi": "", "date": "2020-01-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.00623v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4055763631, "title": "COVID-19 on Social Media: Analyzing Misinformation in Twitter\n  Conversations", "abstract": "The ongoing Coronavirus (COVID-19) pandemic highlights the\ninter-connectedness of our present-day globalized world. With social distancing\npolicies in place, virtual communication has become an important source of\n(mis)information. As increasing number of people rely on social media platforms\nfor news, identifying misinformation and uncovering the nature of online\ndiscourse around COVID-19 has emerged as a critical task. To this end, we\ncollected streaming data related to COVID-19 using the Twitter API, starting\nMarch 1, 2020. We identified unreliable and misleading contents based on\nfact-checking sources, and examined the narratives promoted in misinformation\ntweets, along with the distribution of engagements with these tweets. In\naddition, we provide examples of the spreading patterns of prominent\nmisinformation tweets. The analysis is presented and updated on a publically\naccessible dashboard (https://usc-melady.github.io/COVID-19-Tweet-Analysis) to\ntrack the nature of online discourse and misinformation about COVID-19 on\nTwitter from March 1 - June 5, 2020. The dashboard provides a daily list of\nidentified misinformation tweets, along with topics, sentiments, and emerging\ntrends in the COVID-19 Twitter discourse. The dashboard is provided to improve\nvisibility into the nature and quality of information shared online, and\nprovide real-time access to insights and information extracted from the\ndataset.", "doi": "", "date": "2020-03-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.12309v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 77078932, "title": "Fact or Fiction: Verifying Scientific Claims", "abstract": "We introduce scientific claim verification, a new task to select abstracts\nfrom the research literature containing evidence that SUPPORTS or REFUTES a\ngiven scientific claim, and to identify rationales justifying each decision. To\nstudy this task, we construct SciFact, a dataset of 1.4K expert-written\nscientific claims paired with evidence-containing abstracts annotated with\nlabels and rationales. We develop baseline models for SciFact, and demonstrate\nthat simple domain adaptation techniques substantially improve performance\ncompared to models trained on Wikipedia or political news. We show that our\nsystem is able to verify claims related to COVID-19 by identifying evidence\nfrom the CORD-19 corpus. Our experiments indicate that SciFact will provide a\nchallenging testbed for the development of new systems designed to retrieve and\nreason over corpora containing specialized domain knowledge. Data and code for\nthis new task are publicly available at https://github.com/allenai/scifact. A\nleaderboard and COVID-19 fact-checking demo are available at\nhttps://scifact.apps.allenai.org.", "doi": "", "date": "2020-04-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.14974v6", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4182943922, "title": "Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News", "abstract": "Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 \"infodemic\", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n\"fake news\" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.05854v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1998847407, "title": "Classification Aware Neural Topic Model and its Application on a New\n  COVID-19 Disinformation Corpus", "abstract": "The explosion of disinformation accompanying the COVID-19 pandemic has\noverloaded fact-checkers and media worldwide, and brought a new major challenge\nto government responses worldwide. Not only is disinformation creating\nconfusion about medical science amongst citizens, but it is also amplifying\ndistrust in policy makers and governments. To help tackle this, we developed\ncomputational methods to categorise COVID-19 disinformation. The COVID-19\ndisinformation categories could be used for a) focusing fact-checking efforts\non the most damaging kinds of COVID-19 disinformation; b) guiding policy makers\nwho are trying to deliver effective public health messages and counter\neffectively COVID-19 disinformation. This paper presents: 1) a corpus\ncontaining what is currently the largest available set of manually annotated\nCOVID-19 disinformation categories; 2) a classification-aware neural topic\nmodel (CANTM) designed for COVID-19 disinformation category classification and\ntopic discovery; 3) an extensive analysis of COVID-19 disinformation categories\nwith respect to time, volume, false type, media type and origin source.", "doi": "10.1371/journal.pone.0247086", "date": "2020-06-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.03354v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 618518392, "title": "A Review on Fact Extraction and Verification", "abstract": "We study the fact checking problem, which aims to identify the veracity of a\ngiven claim. Specifically, we focus on the task of Fact Extraction and\nVERification (FEVER) and its accompanied dataset. The task consists of the\nsubtasks of retrieving the relevant documents (and sentences) from Wikipedia\nand validating whether the information in the documents supports or refutes a\ngiven claim. This task is essential and can be the building block of\napplications such as fake news detection and medical claim verification. In\nthis paper, we aim at a better understanding of the challenges of the task by\npresenting the literature in a structured and comprehensive way. We describe\nthe proposed methods by analyzing the technical perspectives of the different\napproaches and discussing the performance results on the FEVER dataset, which\nis the most well-studied and formally structured dataset on the fact extraction\nand verification task. We also conduct the largest experimental study to date\non identifying beneficial loss functions for the sentence retrieval component.\nOur analysis indicates that sampling negative sentences is important for\nimproving the performance and decreasing the computational complexity. Finally,\nwe describe open issues and future challenges, and we motivate future research\nin the task.", "doi": "", "date": "2020-10-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.03001v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3416800636, "title": "The Forchheim Image Database for Camera Identification in the Wild", "abstract": "Image provenance can represent crucial knowledge in criminal investigation\nand journalistic fact checking. In the last two decades, numerous algorithms\nhave been proposed for obtaining information on the source camera and\ndistribution history of an image. For a fair ranking of these techniques, it is\nimportant to rigorously assess their performance on practically relevant test\ncases. To this end, a number of datasets have been proposed. However, we argue\nthat there is a gap in existing databases: to our knowledge, there is currently\nno dataset that simultaneously satisfies two goals, namely a) to cleanly\nseparate scene content and forensic traces, and b) to support realistic\npost-processing like social media recompression. In this work, we propose the\nForchheim Image Database (FODB) to close this gap. It consists of more than\n23,000 images of 143 scenes by 27 smartphone cameras, and it allows to cleanly\nseparate image content from forensic artifacts. Each image is provided in 6\ndifferent qualities: the original camera-native version, and five copies from\nsocial networks. We demonstrate the usefulness of FODB in an evaluation of\nmethods for camera identification. We report three findings. First, the\nrecently proposed general-purpose EfficientNet remarkably outperforms several\ndedicated forensic CNNs both on clean and compressed images. Second,\nclassifiers obtain a performance boost even on unknown post-processing after\naugmentation by artificial degradations. Third, FODB's clean separation of\nscene content and forensic traces imposes important, rigorous boundary\nconditions for algorithm benchmarking.", "doi": "", "date": "2020-11-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.02241v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3395400065, "title": "ClimaText: A Dataset for Climate Change Topic Detection", "abstract": "Climate change communication in the mass media and other textual sources may\naffect and shape public perception. Extracting climate change information from\nthese sources is an important task, e.g., for filtering content and\ne-discovery, sentiment analysis, automatic summarization, question-answering,\nand fact-checking. However, automating this process is a challenge, as climate\nchange is a complex, fast-moving, and often ambiguous topic with scarce\nresources for popular text-based AI tasks. In this paper, we introduce\n\\textsc{ClimaText}, a dataset for sentence-based climate change topic\ndetection, which we make publicly available. We explore different approaches to\nidentify the climate change topic in various text sources. We find that popular\nkeyword-based models are not adequate for such a complex and evolving task.\nContext-based algorithms like BERT \\cite{devlin2018bert} can detect, in\naddition to many trivial cases, a variety of complex and implicit topic\npatterns. Nevertheless, our analysis reveals a great potential for improvement\nin several directions, such as, e.g., capturing the discussion on indirect\neffects of climate change. Hence, we hope this work can serve as a good\nstarting point for further research on this topic.", "doi": "", "date": "2020-12-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.00483v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4129534803, "title": "Chasm in Hegemony: Explaining and Reproducing Disparities in Homophilous\n  Networks", "abstract": "In networks with a minority and a majority community, it is well-studied that\nminorities are under-represented at the top of the social hierarchy. However,\nresearchers are less clear about the representation of minorities from the\nlower levels of the hierarchy, where other disadvantages or vulnerabilities may\nexist. We offer a more complete picture of social disparities at each social\nlevel with empirical evidence that the minority representation exhibits two\nopposite phases: at the higher rungs of the social ladder, the representation\nof the minority community decreases; but, lower in the ladder, which is more\npopulous, as you ascend, the representation of the minority community improves.\nWe refer to this opposing phenomenon between the upper-level and lower-level as\nthe \\emph{chasm effect}. Previous models of network growth with homophily fail\nto detect and explain the presence of this chasm effect. We analyze the\ninteractions among a few well-observed network-growing mechanisms with a simple\nmodel to reveal the sufficient and necessary conditions for both phases in the\nchasm effect to occur. By generalizing the simple model naturally, we present a\ncomplete bi-affiliation bipartite network-growth model that could successfully\ncapture disparities at all social levels and reproduce real social networks.\nFinally, we illustrate that addressing the chasm effect can create fairer\nsystems with two applications in advertisement and fact-checks, thereby\ndemonstrating the potential impact of the chasm effect on the future research\nof minority-majority disparities and fair algorithms.", "doi": "10.1145/3460083", "date": "2021-02-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.11925v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 50926981, "title": "Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models", "abstract": "Misinformation of COVID-19 is prevalent on social media as the pandemic\nunfolds, and the associated risks are extremely high. Thus, it is critical to\ndetect and combat such misinformation. Recently, deep learning models using\nnatural language processing techniques, such as BERT (Bidirectional Encoder\nRepresentations from Transformers), have achieved great successes in detecting\nmisinformation. In this paper, we proposed an explainable natural language\nprocessing model based on DistilBERT and SHAP (Shapley Additive exPlanations)\nto combat misinformation about COVID-19 due to their efficiency and\neffectiveness. First, we collected a dataset of 984 claims about COVID-19 with\nfact checking. By augmenting the data using back-translation, we doubled the\nsample size of the dataset and the DistilBERT model was able to obtain good\nperformance (accuracy: 0.972; areas under the curve: 0.993) in detecting\nmisinformation about COVID-19. Our model was also tested on a larger dataset\nfor AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good\nperformance (accuracy: 0.938; areas under the curve: 0.985). The performance on\nboth datasets was better than traditional machine learning models. Second, in\norder to boost public trust in model prediction, we employed SHAP to improve\nmodel explainability, which was further evaluated using a between-subjects\nexperiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),\nand text+SHAP explanation+source and evidence (TSESE). The participants were\nsignificantly more likely to trust and share information related to COVID-19 in\nthe TSE and TSESE conditions than in the T condition. Our results provided good\nimplications in detecting misinformation about COVID-19 and improving public\ntrust.", "doi": "", "date": "2021-03-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.00747v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1108208204, "title": "Editing Factual Knowledge in Language Models", "abstract": "The factual knowledge acquired during pretraining and stored in the\nparameters of Language Models (LM) can be useful in downstream tasks (e.g.,\nquestion answering or textual inference). However, some facts can be\nincorrectly induced or become obsolete over time. We present KnowledgeEditor, a\nmethod that can be used to edit this knowledge and, thus, fix 'bugs' or\nunexpected predictions without the need for expensive re-training or\nfine-tuning. Besides being computationally efficient, KnowledgeEditor does not\nrequire any modifications in LM pre-training (e.g., the use of meta-learning).\nIn our approach, we train a hyper-network with constrained optimization to\nmodify a fact without affecting the rest of the knowledge; the trained\nhyper-network is then used to predict the weight update at test time. We show\nKnowledgeEditor's efficacy with two popular architectures and\nknowledge-intensive tasks: i) a BERT model fine-tuned for fact-checking, and\nii) a sequence-to-sequence BART model for question answering. With our method,\nchanging a prediction on the specific wording of a query tends to result in a\nconsistent change in predictions also for its paraphrases. We show that this\ncan be further encouraged by exploiting (e.g., automatically-generated)\nparaphrases during training. Interestingly, our hyper-network can be regarded\nas a 'probe' revealing which components of a model need to be changed to\nmanipulate factual knowledge; our analysis shows that the updates tend to be\nconcentrated on a small subset of components. Code at\nhttps://github.com/nicola-decao/KnowledgeEditor", "doi": "", "date": "2021-04-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.08164v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 808776318, "title": "Hidden Biases in Unreliable News Detection Datasets", "abstract": "Automatic unreliable news detection is a research problem with great\npotential impact. Recently, several papers have shown promising results on\nlarge-scale news datasets with models that only use the article itself without\nresorting to any fact-checking mechanism or retrieving any supporting evidence.\nIn this work, we take a closer look at these datasets. While they all provide\nvaluable resources for future research, we observe a number of problems that\nmay lead to results that do not generalize in more realistic settings.\nSpecifically, we show that selection bias during data collection leads to\nundesired artifacts in the datasets. In addition, while most systems train and\npredict at the level of individual articles, overlapping article sources in the\ntraining and evaluation data can provide a strong confounding factor that\nmodels can exploit. In the presence of this confounding factor, the models can\nachieve good performance by directly memorizing the site-label mapping instead\nof modeling the real task of unreliable news detection. We observed a\nsignificant drop (>10%) in accuracy for all models tested in a clean split with\nno train/test source overlap. Using the observations and experimental results,\nwe provide practical suggestions on how to create more reliable datasets for\nthe unreliable news detection task. We suggest future dataset creation include\na simple model as a difficulty/bias probe and future model development use a\nclean non-overlapping site and date split.", "doi": "", "date": "2021-04-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.10130v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1302673835, "title": "Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment", "abstract": "The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations.", "doi": "", "date": "2021-05-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.09114v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 894886481, "title": "Semantic Representation and Inference for NLP", "abstract": "Semantic representation and inference is essential for Natural Language\nProcessing (NLP). The state of the art for semantic representation and\ninference is deep learning, and particularly Recurrent Neural Networks (RNNs),\nConvolutional Neural Networks (CNNs), and transformer Self-Attention models.\nThis thesis investigates the use of deep learning for novel semantic\nrepresentation and inference, and makes contributions in the following three\nareas: creating training data, improving semantic representations and extending\ninference learning. In terms of creating training data, we contribute the\nlargest publicly available dataset of real-life factual claims for the purpose\nof automatic claim verification (MultiFC), and we present a novel inference\nmodel composed of multi-scale CNNs with different kernel sizes that learn from\nexternal sources to infer fact checking labels. In terms of improving semantic\nrepresentations, we contribute a novel model that captures non-compositional\nsemantic indicators. By definition, the meaning of a non-compositional phrase\ncannot be inferred from the individual meanings of its composing words (e.g.,\nhot dog). Motivated by this, we operationalize the compositionality of a phrase\ncontextually by enriching the phrase representation with external word\nembeddings and knowledge graphs. Finally, in terms of inference learning, we\npropose a series of novel deep learning architectures that improve inference by\nusing syntactic dependencies, by ensembling role guided attention heads,\nincorporating gating layers, and concatenating multiple heads in novel and\neffective ways. This thesis consists of seven publications (five published and\ntwo under review).", "doi": "", "date": "2021-06-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.08117v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1598001025, "title": "MetaDetector: Meta Event Knowledge Transfer for Fake News Detection", "abstract": "The blooming of fake news on social networks has devastating impacts on\nsociety, economy, and public security. Although numerous studies are conducted\nfor the automatic detection of fake news, the majority tend to utilize deep\nneural networks to learn event-specific features for superior detection\nperformance on specific datasets. However, the trained models heavily rely on\nthe training datasets and are infeasible to apply to upcoming events due to the\ndiscrepancy between event distributions. Inspired by domain adaptation\ntheories, we propose an end-to-end adversarial adaptation network, dubbed as\nMetaDetector, to transfer meta knowledge (event-shared features) between\ndifferent events. Specifically, MetaDetector pushes the feature extractor and\nevent discriminator to eliminate event-specific features and preserve required\nevent-shared features by adversarial training. Furthermore, the pseudo-event\ndiscriminator is utilized to evaluate the importance of historical event posts\nto obtain partial shared features that are discriminative for detecting fake\nnews. Under the coordinated optimization among the four submodules,\nMetaDetector accurately transfers the meta-knowledge of historical events to\nthe upcoming event for fact checking. We conduct extensive experiments on two\nlarge-scale datasets collected from Weibo and Twitter. The experimental results\ndemonstrate that MetaDetector outperforms the state-of-the-art methods,\nespecially when the distribution shift between events is significant.\nFurthermore, we find that MetaDetector is able to learn the event-shared\nfeatures, and alleviate the negative transfer caused by the large distribution\nshift between events.", "doi": "", "date": "2021-06-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.11177v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2037023389, "title": "Accenture at CheckThat! 2021: Interesting claim identification and\n  ranking with contextually sensitive lexical training data augmentation", "abstract": "This paper discusses the approach used by the Accenture Team for CLEF2021\nCheckThat! Lab, Task 1, to identify whether a claim made in social media would\nbe interesting to a wide audience and should be fact-checked. Twitter training\nand test data were provided in English, Arabic, Spanish, Turkish, and\nBulgarian. Claims were to be classified (check-worthy/not check-worthy) and\nranked in priority order for the fact-checker. Our method used deep neural\nnetwork transformer models with contextually sensitive lexical augmentation\napplied on the supplied training datasets to create additional training\nsamples. This augmentation approach improved the performance for all languages.\nOverall, our architecture and data augmentation pipeline produced the best\nsubmitted system for Arabic, and performance scales according to the quantity\nof provided training data for English, Spanish, Turkish, and Bulgarian. This\npaper investigates the deep neural network architectures for each language as\nwell as the provided data to examine why the approach worked so effectively for\nArabic, and discusses additional data augmentation measures that should could\nbe useful to this problem.", "doi": "", "date": "2021-07-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.05684v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 897197866, "title": "Checkovid: A COVID-19 misinformation detection system on Twitter using\n  network and content mining perspectives", "abstract": "During the COVID-19 pandemic, social media platforms were ideal for\ncommunicating due to social isolation and quarantine. Also, it was the primary\nsource of misinformation dissemination on a large scale, referred to as the\ninfodemic. Therefore, automatic debunking misinformation is a crucial problem.\nTo tackle this problem, we present two COVID-19 related misinformation datasets\non Twitter and propose a misinformation detection system comprising\nnetwork-based and content-based processes based on machine learning algorithms\nand NLP techniques. In the network-based process, we focus on social\nproperties, network characteristics, and users. On the other hand, we classify\nmisinformation using the content of the tweets directly in the content-based\nprocess, which contains text classification models (paragraph-level and\nsentence-level) and similarity models. The evaluation results on the\nnetwork-based process show the best results for the artificial neural network\nmodel with an F1 score of 88.68%. In the content-based process, our novel\nsimilarity models, which obtained an F1 score of 90.26%, show an improvement in\nthe misinformation classification results compared to the network-based models.\nIn addition, in the text classification models, the best result was achieved\nusing the stacking ensemble-learning model by obtaining an F1 score of 95.18%.\nFurthermore, we test our content-based models on the Constraint@AAAI2021\ndataset, and by getting an F1 score of 94.38%, we improve the baseline results.\nFinally, we develop a fact-checking website called Checkovid that uses each\nprocess to detect misinformative and informative claims in the domain of\nCOVID-19 from different perspectives.", "doi": "", "date": "2021-07-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.09768v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3531339235, "title": "Fake News Detection on Social Media using Geometric Deep Learning", "abstract": "Social media are nowadays one of the main news sources for millions of people\naround the globe due to their low cost, easy access and rapid dissemination.\nThis however comes at the cost of dubious trustworthiness and significant risk\nof exposure to 'fake news', intentionally written to mislead the readers.\nAutomatically detecting fake news poses challenges that defy existing\ncontent-based analysis approaches. One of the main reasons is that often the\ninterpretation of the news requires the knowledge of political or social\ncontext or 'common sense', which current NLP algorithms are still missing.\nRecent studies have shown that fake and real news spread differently on social\nmedia, forming propagation patterns that could be harnessed for the automatic\nfake news detection. Propagation-based approaches have multiple advantages\ncompared to their content-based counterparts, among which is language\nindependence and better resilience to adversarial attacks. In this paper we\nshow a novel automatic fake news detection model based on geometric deep\nlearning. The underlying core algorithms are a generalization of classical CNNs\nto graphs, allowing the fusion of heterogeneous data such as content, user\nprofile and activity, social graph, and news propagation. Our model was trained\nand tested on news stories, verified by professional fact-checking\norganizations, that were spread on Twitter. Our experiments indicate that\nsocial network structure and propagation are important features allowing highly\naccurate (92.7% ROC AUC) fake news detection. Second, we observe that fake news\ncan be reliably detected at an early stage, after just a few hours of\npropagation. Third, we test the aging of our model on training and testing data\nseparated in time. Our results point to the promise of propagation-based\napproaches for fake news detection as an alternative or complementary strategy\nto content-based approaches.", "doi": "", "date": "2019-02-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1902.06673v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2444971646, "title": "Seeing Things from a Different Angle: Discovering Diverse Perspectives\n  about Claims", "abstract": "One key consequence of the information revolution is a significant increase\nand a contamination of our information supply. The practice of fact checking\nwon't suffice to eliminate the biases in text data we observe, as the degree of\nfactuality alone does not determine whether biases exist in the spectrum of\nopinions visible to us. To better understand controversial issues, one needs to\nview them from a diverse yet comprehensive set of perspectives. For example,\nthere are many ways to respond to a claim such as \"animals should have lawful\nrights\", and these responses form a spectrum of perspectives, each with a\nstance relative to this claim and, ideally, with evidence supporting it.\nInherently, this is a natural language understanding task, and we propose to\naddress it as such. Specifically, we propose the task of substantiated\nperspective discovery where, given a claim, a system is expected to discover a\ndiverse set of well-corroborated perspectives that take a stance with respect\nto the claim. Each perspective should be substantiated by evidence paragraphs\nwhich summarize pertinent results and facts. We construct PERSPECTRUM, a\ndataset of claims, perspectives and evidence, making use of online debate\nwebsites to create the initial data collection, and augmenting it using search\nengines in order to expand and diversify our dataset. We use crowd-sourcing to\nfilter out noise and ensure high-quality data. Our dataset contains 1k claims,\naccompanied with pools of 10k and 8k perspective sentences and evidence\nparagraphs, respectively. We provide a thorough analysis of the dataset to\nhighlight key underlying language understanding challenges, and show that human\nbaselines across multiple subtasks far outperform ma-chine baselines built upon\nstate-of-the-art NLP techniques. This poses a challenge and opportunity for the\nNLP community to address.", "doi": "", "date": "2019-06-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1906.03538v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4072799440, "title": "Deep Ensemble Learning for News Stance Detection", "abstract": "Stance detection in fake news is an important component in news veracity\nassessment because this process helps fact-checking by understanding stance to\na central claim from different information sources. The Fake News Challenge\nStage 1 (FNC-1) held in 2017 was setup for this purpose, which involves\nestimating the stance of a news article body relative to a given headline. This\nthesis starts from the error analysis for the three top-performing systems in\nFNC-1. Based on the analysis, a simple but tough-to-beat Multilayer Perceptron\nsystem is chosen as the baseline. Afterwards, three approaches are explored to\nimprove baseline.The first approach explores the possibility of improving the\nprediction accuracy by adding extra keywords features when training a model,\nwhere keywords are converted to an indicator vector and then concatenated to\nthe baseline features. A list of keywords is manually selected based on the\nerror analysis, which may best reflect some characteristics of fake news titles\nand bodies. To make this selection process automatically, three algorithms are\ncreated based on Mutual Information (MI) theory: keywords generator based on MI\nstance class, MI customised class, and Pointwise MI algorithm. The second\napproach is based on word embedding, where word2vec model is introduced and two\ndocument similarities calculation algorithms are implemented: wor2vec cosine\nsimilarity and WMD distance. The third approach is ensemble learning. Different\nmodels are configured together with two continuous outputs combining\nalgorithms. The 10-fold cross validation reveals that the ensemble of three\nneural network models trained from simple bag-of-words features gives the best\nperformance. It is therefore selected to compete in FNC-1. After\nhyperparameters fine tuning, the selected deep ensemble model beats the FNC-1\nwinner team by a remarkable 34.25 marks under FNC-1's evaluation metric.", "doi": "", "date": "2019-09-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1909.12233v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1730281125, "title": "Credulous Users and Fake News: a Real Case Study on the Propagation in\n  Twitter", "abstract": "Recent studies have confirmed a growing trend, especially among youngsters,\nof using Online Social Media as favourite information platform at the expense\nof traditional mass media. Indeed, they can easily reach a wide audience at a\nhigh speed; but exactly because of this they are the preferred medium for\ninfluencing public opinion via so-called fake news. Moreover, there is a\ngeneral agreement that the main vehicle of fakes news are malicious software\nrobots (bots) that automatically interact with human users. In previous work we\nhave considered the problem of tagging human users in Online Social Networks as\ncredulous users. Specifically, we have considered credulous those users with\nrelatively high number of bot friends when compared to total number of their\nsocial friends. We consider this group of users worth of attention because they\nmight have a higher exposure to malicious activities and they may contribute to\nthe spreading of fake information by sharing dubious content. In this work,\nstarting from a dataset of fake news, we investigate the behaviour and the\ndegree of involvement of credulous users in fake news diffusion. The study aims\nto: (i) fight fake news by considering the content diffused by credulous users;\n(ii) highlight the relationship between credulous users and fake news\nspreading; (iii) target fake news detection by focusing on the analysis of\nspecific accounts more exposed to malicious activities of bots. Our first\nresults demonstrate a strong involvement of credulous users in fake news\ndiffusion. This findings are calling for tools that, by performing data\nstreaming on credulous' users actions, enables us to perform targeted\nfact-checking.", "doi": "", "date": "2020-05-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.03550v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2144619053, "title": "Graph Neural Networks with Continual Learning for Fake News Detection\n  from Social Media", "abstract": "Although significant effort has been applied to fact-checking, the prevalence\nof fake news over social media, which has profound impact on justice, public\ntrust and our society, remains a serious problem. In this work, we focus on\npropagation-based fake news detection, as recent studies have demonstrated that\nfake news and real news spread differently online. Specifically, considering\nthe capability of graph neural networks (GNNs) in dealing with non-Euclidean\ndata, we use GNNs to differentiate between the propagation patterns of fake and\nreal news on social media. In particular, we concentrate on two questions: (1)\nWithout relying on any text information, e.g., tweet content, replies and user\ndescriptions, how accurately can GNNs identify fake news? Machine learning\nmodels are known to be vulnerable to adversarial attacks, and avoiding the\ndependence on text-based features can make the model less susceptible to the\nmanipulation of advanced fake news fabricators. (2) How to deal with new,\nunseen data? In other words, how does a GNN trained on a given dataset perform\non a new and potentially vastly different dataset? If it achieves\nunsatisfactory performance, how do we solve the problem without re-training the\nmodel on the entire data from scratch? We study the above questions on two\ndatasets with thousands of labelled news items, and our results show that: (1)\nGNNs can achieve comparable or superior performance without any text\ninformation to state-of-the-art methods. (2) GNNs trained on a given dataset\nmay perform poorly on new, unseen data, and direct incremental training cannot\nsolve the problem---this issue has not been addressed in the previous work that\napplies GNNs for fake news detection. In order to solve the problem, we propose\na method that achieves balanced performance on both existing and new datasets,\nby using techniques from continual learning to train GNNs incrementally.", "doi": "", "date": "2020-07-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.03316v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3915563228, "title": "Flow of online misinformation during the peak of the COVID-19 pandemic\n  in Italy", "abstract": "The COVID-19 pandemic has impacted on every human activity and, because of\nthe urgency of finding the proper responses to such an unprecedented emergency,\nit generated a diffused societal debate. The online version of this discussion\nwas not exempted by the presence of d/misinformation campaigns, but differently\nfrom what already witnessed in other debates, the COVID-19 -- intentional or\nnot -- flow of false information put at severe risk the public health, reducing\nthe effectiveness of governments' countermeasures. In the present manuscript,\nwe study the effective impact of misinformation in the Italian societal debate\non Twitter during the pandemic, focusing on the various discursive communities.\nIn order to extract the discursive communities, we focus on verified users,\ni.e. accounts whose identity is officially certified by Twitter. We thus infer\nthe various discursive communities based on how verified users are perceived by\nstandard ones: if two verified accounts are considered as similar by non\nunverified ones, we link them in the network of certified accounts. We first\nobserve that, beside being a mostly scientific subject, the COVID-19 discussion\nshow a clear division in what results to be different political groups. At this\npoint, by using a commonly available fact-checking software (NewsGuard), we\nassess the reputation of the pieces of news exchanged. We filter the network of\nretweets (i.e. users re-broadcasting the same elementary piece of information,\nor tweet) from random noise and check the presence of messages displaying an\nurl. The impact of misinformation posts reaches the 22.1% in the right and\ncenter-right wing community and its contribution is even stronger in absolute\nnumbers, due to the activity of this group: 96% of all non reputable urls\nshared by political groups come from this community.", "doi": "", "date": "2020-10-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.01913v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3908792315, "title": "Political Bias and Factualness in News Sharing across more than 100,000\n  Online Communities", "abstract": "As civil discourse increasingly takes place online, misinformation and the\npolarization of news shared in online communities have become ever more\nrelevant concerns with real world harms across our society. Studying online\nnews sharing at scale is challenging due to the massive volume of content which\nis shared by millions of users across thousands of communities. Therefore,\nexisting research has largely focused on specific communities or specific\ninterventions, such as bans. However, understanding the prevalence and spread\nof misinformation and polarization more broadly, across thousands of online\ncommunities, is critical for the development of governance strategies,\ninterventions, and community design. Here, we conduct the largest study of news\nsharing on reddit to date, analyzing more than 550 million links spanning 4\nyears. We use non-partisan news source ratings from Media Bias/Fact Check to\nannotate links to news sources with their political bias and factualness. We\nfind that, compared to left-leaning communities, right-leaning communities have\n105% more variance in the political bias of their news sources, and more links\nto relatively-more biased sources, on average. We observe that reddit users'\nvoting and re-sharing behaviors generally decrease the visibility of extremely\nbiased and low factual content, which receives 20% fewer upvotes and 30% fewer\nexposures from crossposts than more neutral or more factual content. This\nsuggests that reddit is more resilient to low factual content than Twitter. We\nshow that extremely biased and low factual content is very concentrated, with\n99% of such content being shared in only 0.5% of communities, giving credence\nto the recent strategy of community-wide bans and quarantines.", "doi": "", "date": "2021-02-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2102.08537v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2272749452, "title": "The Many Dimensions of Truthfulness: Crowdsourcing Misinformation\n  Assessments on a Multidimensional Scale", "abstract": "Recent work has demonstrated the viability of using crowdsourcing as a tool\nfor evaluating the truthfulness of public statements. Under certain conditions\nsuch as: (1) having a balanced set of workers with different backgrounds and\ncognitive abilities; (2) using an adequate set of mechanisms to control the\nquality of the collected data; and (3) using a coarse grained assessment scale,\nthe crowd can provide reliable identification of fake news. However, fake news\nare a subtle matter: statements can be just biased (\"cherrypicked\"), imprecise,\nwrong, etc. and the unidimensional truth scale used in existing work cannot\naccount for such differences. In this paper we propose a multidimensional\nnotion of truthfulness and we ask the crowd workers to assess seven different\ndimensions of truthfulness selected based on existing literature: Correctness,\nNeutrality, Comprehensibility, Precision, Completeness, Speaker's\nTrustworthiness, and Informativeness. We deploy a set of quality control\nmechanisms to ensure that the thousands of assessments collected on 180\npublicly available fact-checked statements distributed over two datasets are of\nadequate quality, including a custom search engine used by the crowd workers to\nfind web pages supporting their truthfulness assessments. A comprehensive\nanalysis of crowdsourced judgments shows that: (1) the crowdsourced assessments\nare reliable when compared to an expert-provided gold standard; (2) the\nproposed dimensions of truthfulness capture independent pieces of information;\n(3) the crowdsourcing task can be easily learned by the workers; and (4) the\nresulting assessments provide a useful basis for a more complete estimation of\nstatement truthfulness.", "doi": "10.1016/j.ipm.2021.102710", "date": "2021-08-03", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.01222v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3399936139, "title": "The Surprising Creativity of Digital Evolution: A Collection of\n  Anecdotes from the Evolutionary Computation and Artificial Life Research\n  Communities", "abstract": "Biological evolution provides a creative fount of complex and subtle\nadaptations, often surprising the scientists who discover them. However,\nbecause evolution is an algorithmic process that transcends the substrate in\nwhich it occurs, evolution's creativity is not limited to nature. Indeed, many\nresearchers in the field of digital evolution have observed their evolving\nalgorithms and organisms subverting their intentions, exposing unrecognized\nbugs in their code, producing unexpected adaptations, or exhibiting outcomes\nuncannily convergent with ones in nature. Such stories routinely reveal\ncreativity by evolution in these digital worlds, but they rarely fit into the\nstandard scientific narrative. Instead they are often treated as mere obstacles\nto be overcome, rather than results that warrant study in their own right. The\nstories themselves are traded among researchers through oral tradition, but\nthat mode of information transmission is inefficient and prone to error and\noutright loss. Moreover, the fact that these stories tend to be shared only\namong practitioners means that many natural scientists do not realize how\ninteresting and lifelike digital organisms are and how natural their evolution\ncan be. To our knowledge, no collection of such anecdotes has been published\nbefore. This paper is the crowd-sourced product of researchers in the fields of\nartificial life and evolutionary computation who have provided first-hand\naccounts of such cases. It thus serves as a written, fact-checked collection of\nscientifically important and even entertaining stories. In doing so we also\npresent here substantial evidence that the existence and importance of\nevolutionary surprises extends beyond the natural world, and may indeed be a\nuniversal property of all complex evolving systems.", "doi": "", "date": "2018-03-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/1803.03453v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2336040595, "title": "Joint Verification and Reranking for Open Fact Checking Over Tables.", "abstract": "", "doi": "10.18653/v1/2021.acl-long.529", "date": "2021", "authors": [{"name": "Michael Sejr Schlichtkrull", "id-internal": "186/7091", "id-external": ""}, {"name": "Vladimir Karpukhin", "id-internal": "236/4633", "id-external": ""}, {"name": "Barlas Oguz", "id-internal": "69/9892", "id-external": ""}, {"name": "Mike Lewis", "id-internal": "19/6214", "id-external": ""}, {"name": "Wen-tau Yih", "id-internal": "07/7129", "id-external": ""}, {"name": "Sebastian Riedel 0001", "id-internal": "18/3348-1", "id-external": ""}], "url": {"full": "URL#126047", "pdf": ""}, "publisher-venue": "ACL/IJCNLP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2408953831, "title": "Automatic Fact-Checking Using Context and Discourse Information.", "abstract": "", "doi": "10.1145/3297722", "date": "2019", "authors": [{"name": "Pepa Atanasova", "id-internal": "224/2054", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, {"name": "Llu\u00eds M\u00e0rquez", "id-internal": "62/3", "id-external": ""}, {"name": "Alberto Barr\u00f3n-Cede\u00f1o", "id-internal": "40/3383", "id-external": ""}, {"name": "Georgi Karadzhov", "id-internal": "205/1966", "id-external": ""}, {"name": "Tsvetomila Mihaylova", "id-internal": "184/2078", "id-external": ""}, {"name": "Mitra Mohtarami", "id-internal": "77/7405", "id-external": ""}, {"name": "James R. Glass", "id-internal": "37/6580", "id-external": ""}], "url": {"full": "URL#744454", "pdf": ""}, "publisher-venue": "ACM J. Data Inf. Qual.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3486136814, "title": "Discriminative predicate path mining for fact checking in knowledge graphs.", "abstract": "", "doi": "10.1016/j.knosys.2016.04.015", "date": "2016", "authors": [{"name": "Baoxu Shi", "id-internal": "132/6140", "id-external": ""}, {"name": "Tim Weninger", "id-internal": "73/2015", "id-external": ""}], "url": {"full": "URL#1830519", "pdf": ""}, "publisher-venue": "Knowl. Based Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1308464343, "title": "Fact-Checking Ziegler's Maximum Entropy Production Principle beyond the Linear Regime and towards Steady States.", "abstract": "", "doi": "10.3390/e15072570", "date": "2013", "authors": {"name": "Matteo Polettini", "id-internal": "132/1649", "id-external": ""}, "url": {"full": "URL#2676301", "pdf": ""}, "publisher-venue": "Entropy", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}][{"id": 1739981783, "title": "Multiplex network reconstruction for the coupled spatial diffusion of infodemic and pandemic of COVID-19.", "abstract": "", "doi": "10.1080/17538947.2021.1888326", "date": "2021", "authors": [{"name": "Xiaoqi Zhang", "id-internal": "60/7678", "id-external": ""}, {"name": "Zi-Ke Zhang", "id-internal": "17/146", "id-external": ""}, {"name": "Wenbo Wang", "id-internal": "132/5158", "id-external": ""}, {"name": "Donglin Hou", "id-internal": "290/7128", "id-external": ""}, {"name": "Jiajing Xu", "id-internal": "10/5731", "id-external": ""}, {"name": "Xinyue Ye", "id-internal": "118/4187", "id-external": ""}, {"name": "Shengwen Li", "id-internal": "73/1167", "id-external": ""}], "url": {"full": "URL#30961", "pdf": ""}, "publisher-venue": "Int. J. Digit. Earth", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1089888134, "title": "Accounting for social media effects to improve the accuracy of infection models - combatting the COVID-19 pandemic and infodemic.", "abstract": "", "doi": "10.1080/0960085x.2021.1890530", "date": "2021", "authors": [{"name": "Sujin Bae", "id-internal": "248/4355", "id-external": ""}, {"name": "Eunyoung (Christine) Sung", "id-internal": "272/8264", "id-external": ""}, {"name": "Ohbyung Kwon", "id-internal": "96/1848", "id-external": ""}], "url": {"full": "URL#33297", "pdf": ""}, "publisher-venue": "Eur. J. Inf. Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 866061984, "title": "Combat COVID-19 infodemic using explainable natural language processing models.", "abstract": "", "doi": "10.1016/j.ipm.2021.102569", "date": "2021", "authors": [{"name": "Jackie Ayoub", "id-internal": "249/1304", "id-external": ""}, {"name": "X. Jessie Yang", "id-internal": "170/3131", "id-external": ""}, {"name": "Feng Zhou 0003", "id-internal": "21/6430-3", "id-external": ""}], "url": {"full": "URL#52759", "pdf": ""}, "publisher-venue": "Inf. Process. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3197436793, "title": "Non-pharmaceutical Interventions and the Infodemic on Twitter - Lessons Learned from Italy during the Covid-19 Pandemic.", "abstract": "", "doi": "10.1007/s10916-021-01726-7", "date": "2021", "authors": [{"name": "Maurizio Massaro", "id-internal": "162/9156", "id-external": ""}, {"name": "Paola Tamburro", "id-internal": "288/3966", "id-external": ""}, {"name": "Matteo La Torre", "id-internal": "288/3894", "id-external": ""}, {"name": "Francesca Dal Mas", "id-internal": "241/6602", "id-external": ""}, {"name": "Ronald Thomas", "id-internal": "288/4311", "id-external": ""}, {"name": "Lorenzo Cobianchi", "id-internal": "288/3994", "id-external": ""}, {"name": "Paul Barach", "id-internal": "160/7804", "id-external": ""}], "url": {"full": "URL#62939", "pdf": ""}, "publisher-venue": "J. Medical Syst.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 345897384, "title": "CovChain - Blockchain-Enabled Identity Preservation and Anti-Infodemics for COVID-19.", "abstract": "", "doi": "10.1109/mnet.011.2000669", "date": "2021", "authors": [{"name": "Pallav Kumar Deb", "id-internal": "271/5337", "id-external": ""}, {"name": "Anandarup Mukherjee", "id-internal": "160/3215", "id-external": ""}, {"name": "Sudip Misra", "id-internal": "36/1023", "id-external": ""}], "url": {"full": "URL#74498", "pdf": ""}, "publisher-venue": "IEEE Netw.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3884805936, "title": "Tackling the Infodemic - Analysis Using Transformer Based Models.", "abstract": "", "doi": "10.1007/978-3-030-73696-5_10", "date": "2021", "authors": [{"name": "Anand Zutshi", "id-internal": "299/5685", "id-external": ""}, {"name": "Aman Raj", "id-internal": "161/0790", "id-external": ""}], "url": {"full": "URL#125049", "pdf": ""}, "publisher-venue": "CONSTRAINT@AAAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2243945329, "title": "Evaluando sitios webs nacionales de salud Latinoamericanos como respuesta a la infodemia en tiempos del COVID-19 / Assessing Latin American National Health Websites as Response to the Infodemic in Times of COVID-19.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "V\u00edctor Boh\u00f3rquez", "id-internal": "73/592", "id-external": ""}, "url": {"full": "URL#130345", "pdf": ""}, "publisher-venue": "AMCIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3779425296, "title": "Distrust in Institutions - Reference and Library Instruction During an Infodemic.", "abstract": "", "doi": "10.1145/3463677.3463749", "date": "2021", "authors": [{"name": "Abby Adams", "id-internal": "247/2914", "id-external": ""}, {"name": "Angela Hackstadt", "id-internal": "294/5979", "id-external": ""}], "url": {"full": "URL#143547", "pdf": ""}, "publisher-venue": "DG.O", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 645457545, "title": "Hate is the New Infodemic - A Topic-aware Modeling of Hate Speech Diffusion on Twitter.", "abstract": "", "doi": "10.1109/icde51399.2021.00050", "date": "2021", "authors": [{"name": "Sarah Masud", "id-internal": "115/9011", "id-external": ""}, {"name": "Subhabrata Dutta", "id-internal": "204/6929", "id-external": ""}, {"name": "Sakshi Makkar", "id-internal": "276/1551", "id-external": ""}, {"name": "Chhavi Jain", "id-internal": "276/0509", "id-external": ""}, {"name": "Vikram Goyal", "id-internal": "70/6404", "id-external": ""}, {"name": "Amitava Das", "id-internal": "75/5002", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}], "url": {"full": "URL#157227", "pdf": ""}, "publisher-venue": "ICDE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1315072055, "title": "Fighting the COVID-19 Infodemic in Social Media - A Holistic Perspective and a Call to Arms.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Firoj Alam", "id-internal": "126/2083", "id-external": ""}, {"name": "Fahim Dalvi", "id-internal": "194/2537", "id-external": ""}, {"name": "Shaden Shaar", "id-internal": "234/1620", "id-external": ""}, {"name": "Nadir Durrani", "id-internal": "54/9012", "id-external": ""}, {"name": "Hamdy Mubarak", "id-internal": "146/4030", "id-external": ""}, {"name": "Alex Nikolov", "id-internal": "242/4800", "id-external": ""}, {"name": "Giovanni Da San Martino", "id-internal": "25/3236", "id-external": ""}, {"name": "Ahmed Abdelali", "id-internal": "48/5636", "id-external": ""}, {"name": "Hassan Sajjad", "id-internal": "73/5938", "id-external": ""}, {"name": "Kareem Darwish", "id-internal": "13/5913", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}], "url": {"full": "URL#162987", "pdf": ""}, "publisher-venue": "ICWSM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4011226011, "title": "Emotional Behavior in the \"Infodemic vs. Panicdemic vs. Pandemic\" modeling COVID-19.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Sergey Bushuyev", "id-internal": "172/8353", "id-external": ""}, {"name": "Igbal Babayev", "id-internal": "291/0788", "id-external": ""}, {"name": "Denis Bushuiev", "id-internal": "260/2006", "id-external": ""}, {"name": "Natalia Bushuyeva", "id-internal": "290/9985", "id-external": ""}, {"name": "Jahid Babayev", "id-internal": "260/1651", "id-external": ""}], "url": {"full": "URL#168893", "pdf": ""}, "publisher-venue": "ITPM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1035382649, "title": "Integrated Infodemic Surveillance System - The Case of COVID-19 in South Korea.", "abstract": "", "doi": "10.3233/shti210342", "date": "2021", "authors": [{"name": "Gil-sung Park", "id-internal": "298/1919", "id-external": ""}, {"name": "Jintae Bae", "id-internal": "298/1541", "id-external": ""}, {"name": "Jong Hun Lee", "id-internal": "165/9735", "id-external": ""}, {"name": "Byung Yeon Yun", "id-internal": "298/1794", "id-external": ""}, {"name": "Byunghwee Lee", "id-internal": "194/2552", "id-external": ""}, {"name": "Eun Kyong Shin", "id-internal": "212/2009", "id-external": ""}], "url": {"full": "URL#172594", "pdf": ""}, "publisher-venue": "MIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2205589722, "title": "WHO Digital Intelligence Analysis for Tracking Narratives and Information Voids in the COVID-19 Infodemic.", "abstract": "", "doi": "10.3233/shti210326", "date": "2021", "authors": [{"name": "Tina D. Purnat", "id-internal": "298/1498", "id-external": ""}, {"name": "Paolo Vacca", "id-internal": "298/1752", "id-external": ""}, {"name": "Stefano Burzo", "id-internal": "298/2403", "id-external": ""}, {"name": "Tim Zecchin", "id-internal": "298/2067", "id-external": ""}, {"name": "Amy Wright", "id-internal": "159/8064", "id-external": ""}, {"name": "Sylvie Briand", "id-internal": "298/1737", "id-external": ""}, {"name": "Tim Nguyen", "id-internal": "75/10853", "id-external": ""}], "url": {"full": "URL#172607", "pdf": ""}, "publisher-venue": "MIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1976931424, "title": "Combat COVID-19 Infodemic Using Explainable Natural Language Processing Models.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Jackie Ayoub", "id-internal": "249/1304", "id-external": ""}, {"name": "X. Jessie Yang", "id-internal": "170/3131", "id-external": ""}, {"name": "Feng Zhou 0003", "id-internal": "21/6430-3", "id-external": ""}], "url": {"full": "URL#200998", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2385462600, "title": "Fighting the COVID-19 Infodemic with a Holistic BERT Ensemble.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Giorgos Tziafas", "id-internal": "288/0129", "id-external": ""}, {"name": "Konstantinos Kogkalidis", "id-internal": "241/9652", "id-external": ""}, {"name": "Tommaso Caselli", "id-internal": "85/7943", "id-external": ""}], "url": {"full": "URL#210672", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1380986687, "title": "Transformers to Fight the COVID-19 Infodemic.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Lasitha Uyangodage", "id-internal": "291/2942", "id-external": ""}, {"name": "Tharindu Ranasinghe", "id-internal": "242/4755", "id-external": ""}, {"name": "Hansi Hettiarachchi", "id-internal": "256/4266", "id-external": ""}], "url": {"full": "URL#213556", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4208448880, "title": "The State of Infodemic on Twitter.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Drishti Jain", "id-internal": "292/7057", "id-external": ""}, {"name": "Tavpritesh Sethi", "id-internal": "205/6969", "id-external": ""}], "url": {"full": "URL#218097", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3157765341, "title": "Infodemics on Youtube - Reliability of Content and Echo Chambers on COVID-19.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Niccol\u00f2 Di Marco", "id-internal": "295/8778", "id-external": ""}, {"name": "Matteo Cinelli", "id-internal": "186/8303", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}], "url": {"full": "URL#225504", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2493526550, "title": "Tackling COVID-19 Infodemic using Deep Learning.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Prathmesh Pathwar", "id-internal": "296/3668", "id-external": ""}, {"name": "Simran Gill", "id-internal": "146/1141", "id-external": ""}], "url": {"full": "URL#229705", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1418113838, "title": "The COVID-19 infodemic does not affect vaccine acceptance.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Carlo Michele Valensise", "id-internal": "255/5946", "id-external": ""}, {"name": "Matteo Cinelli", "id-internal": "186/8303", "id-external": ""}, {"name": "Matthieu Nadini", "id-internal": "178/9444", "id-external": ""}, {"name": "Alessandro Galeazzi", "id-internal": "213/0898", "id-external": ""}, {"name": "Antonio Peruzzi", "id-internal": "231/9066", "id-external": ""}, {"name": "Gabriele Etta", "id-internal": "266/8075", "id-external": ""}, {"name": "Fabiana Zollo", "id-internal": "60/9927", "id-external": ""}, {"name": "Andrea Baronchelli", "id-internal": "63/2029", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}], "url": {"full": "URL#232237", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3085591081, "title": "Misleading the Covid-19 vaccination discourse on Twitter - An exploratory study of infodemic around the pandemic.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Shakshi Sharma", "id-internal": "276/6386", "id-external": ""}, {"name": "Rajesh Sharma", "id-internal": "16/7691", "id-external": ""}, {"name": "Anwitaman Datta", "id-internal": "d/AnwitamanDatta", "id-external": ""}], "url": {"full": "URL#239420", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 322258549, "title": "Who do you trust? The digital destruction of shared situational awareness and the COVID-19 infodemic.", "abstract": "", "doi": "10.1016/j.ijinfomgt.2020.102201", "date": "2020", "authors": {"name": "Deborah Bunker", "id-internal": "02/1327", "id-external": ""}, "url": {"full": "URL#315449", "pdf": ""}, "publisher-venue": "Int. J. Inf. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3386169331, "title": "Managing News Overload (MNO) - The COVID-19 Infodemic.", "abstract": "", "doi": "10.3390/info11080375", "date": "2020", "authors": {"name": "Sameera Tahira Ahmed", "id-internal": "273/3770", "id-external": ""}, "url": {"full": "URL#322894", "pdf": ""}, "publisher-venue": "Inf.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1726819855, "title": "Challenges in Combating COVID-19 Infodemic - Data, Tools, and Ethics.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kaize Ding", "id-internal": "234/6878", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Yichuan Li", "id-internal": "216/7478", "id-external": ""}, {"name": "Amrita Bhattacharjee", "id-internal": "251/2495", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#444660", "pdf": ""}, "publisher-venue": "CIKM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2031712628, "title": "Flattening the Curve of the COVID-19 Infodemic - These Evaluation Campaigns Can Help!", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}, "url": {"full": "URL#470083", "pdf": ""}, "publisher-venue": "EVALITA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1279041179, "title": "Towards Curtailing Infodemic in the Era of COVID-19 - A Contextualized Solution for Ethiopia.", "abstract": "", "doi": "10.1007/978-3-030-60152-2_17", "date": "2020", "authors": [{"name": "Elefelious Getachew Belay", "id-internal": "167/2714", "id-external": ""}, {"name": "Melkamu Beyene", "id-internal": "175/4378", "id-external": ""}, {"name": "Teshome Alemu", "id-internal": "172/1609", "id-external": ""}, {"name": "Amanuel Negash", "id-internal": "275/0064", "id-external": ""}, {"name": "Tibebe Beshah Tesema", "id-internal": "260/1954", "id-external": ""}, {"name": "Aminu Mohammed", "id-internal": "98/6068", "id-external": ""}, {"name": "Mengistu Yilma", "id-internal": "275/0051", "id-external": ""}, {"name": "Berhan Tassew", "id-internal": "275/0079", "id-external": ""}, {"name": "Solomon Mekonnen", "id-internal": "275/0089", "id-external": ""}], "url": {"full": "URL#477155", "pdf": ""}, "publisher-venue": "HCI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2942031851, "title": "Information propagation in an era of Infodemics - The role of language content.", "abstract": "", "doi": "10.1109/snams52053.2020.9336539", "date": "2020", "authors": {"name": "Mona Diab", "id-internal": "249/2627", "id-external": ""}, "url": {"full": "URL#563282", "pdf": ""}, "publisher-venue": "SNAMS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2723147630, "title": "The COVID-19 Social Media Infodemic.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Matteo Cinelli", "id-internal": "186/8303", "id-external": ""}, {"name": "Walter Quattrociocchi", "id-internal": "60/5184", "id-external": ""}, {"name": "Alessandro Galeazzi", "id-internal": "213/0898", "id-external": ""}, {"name": "Carlo Michele Valensise", "id-internal": "255/5946", "id-external": ""}, {"name": "Emanuele Brugnoli", "id-internal": "130/9417", "id-external": ""}, {"name": "Ana Luc\u00eda Schmidt", "id-internal": "213/7548", "id-external": ""}, {"name": "Paola Zola", "id-internal": "240/3455", "id-external": ""}, {"name": "Fabiana Zollo", "id-internal": "60/9927", "id-external": ""}, {"name": "Antonio Scala", "id-internal": "92/9669", "id-external": ""}], "url": {"full": "URL#593910", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2366724214, "title": "Assessing the risks of \"infodemics\" in response to COVID-19 epidemics.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Riccardo Gallotti", "id-internal": "53/10228", "id-external": ""}, {"name": "Francesco Valle", "id-internal": "98/8796", "id-external": ""}, {"name": "Nicola Castaldo", "id-internal": "239/6122", "id-external": ""}, {"name": "Pierluigi Sacco", "id-internal": "262/7407", "id-external": ""}, {"name": "Manlio De Domenico", "id-internal": "120/7524", "id-external": ""}], "url": {"full": "URL#599059", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2215984877, "title": "On the dynamics emerging from pandemics and infodemics.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Stephan Leitner", "id-internal": "144/1349", "id-external": ""}, "url": {"full": "URL#600997", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3410857343, "title": "Psychometric Analysis and Coupling of Emotions Between State Bulletins and Twitter in India during COVID-19 Infodemic.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Baani Leen Kaur Jolly", "id-internal": "242/4766", "id-external": ""}, {"name": "Palash Aggrawal", "id-internal": "254/2885", "id-external": ""}, {"name": "Amogh Gulati", "id-internal": "264/9763", "id-external": ""}, {"name": "Amarjit Singh Sethi", "id-internal": "264/9379", "id-external": ""}, {"name": "Ponnurangam Kumaraguru", "id-internal": "97/5147", "id-external": ""}, {"name": "Tavpritesh Sethi", "id-internal": "205/6969", "id-external": ""}], "url": {"full": "URL#605631", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 742939035, "title": "Critical Impact of Social Networks Infodemic on Defeating Coronavirus COVID-19 Pandemic - Twitter-Based Study and Research Directions.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Azzam Mourad", "id-internal": "34/4038", "id-external": ""}, {"name": "Ali Srour", "id-internal": "265/6198", "id-external": ""}, {"name": "Haidar Harmanani", "id-internal": "47/5155", "id-external": ""}, {"name": "Cathia Jenainatiy", "id-internal": "265/5552", "id-external": ""}, {"name": "Mohamad Arafeh", "id-internal": "255/3008", "id-external": ""}], "url": {"full": "URL#606984", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2578489885, "title": "Challenges in Combating COVID-19 Infodemic - Data, Tools, and Ethics.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kaize Ding", "id-internal": "234/6878", "id-external": ""}, {"name": "Kai Shu", "id-internal": "153/5265", "id-external": ""}, {"name": "Yichuan Li", "id-internal": "216/7478", "id-external": ""}, {"name": "Amrita Bhattacharjee", "id-internal": "251/2495", "id-external": ""}, {"name": "Huan Liu 0001", "id-internal": "92/309-1", "id-external": ""}], "url": {"full": "URL#608797", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 269241153, "title": "Fighting the COVID-19 Infodemic in Social Media - A Holistic Perspective and a Call to Arms.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Firoj Alam", "id-internal": "126/2083", "id-external": ""}, {"name": "Fahim Dalvi", "id-internal": "194/2537", "id-external": ""}, {"name": "Shaden Shaar", "id-internal": "234/1620", "id-external": ""}, {"name": "Nadir Durrani", "id-internal": "54/9012", "id-external": ""}, {"name": "Hamdy Mubarak", "id-internal": "146/4030", "id-external": ""}, {"name": "Alex Nikolov", "id-internal": "242/4800", "id-external": ""}, {"name": "Giovanni Da San Martino", "id-internal": "25/3236", "id-external": ""}, {"name": "Ahmed Abdelali", "id-internal": "48/5636", "id-external": ""}, {"name": "Hassan Sajjad", "id-internal": "73/5938", "id-external": ""}, {"name": "Kareem Darwish", "id-internal": "13/5913", "id-external": ""}, {"name": "Preslav Nakov", "id-internal": "19/1947", "id-external": ""}], "url": {"full": "URL#619468", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1486174827, "title": "The COVID-19 Social Media Infodemic Reflects Uncertainty and State-Sponsored Propaganda.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "David A. Broniatowski", "id-internal": "03/8878", "id-external": ""}, {"name": "Daniel Kerchner", "id-internal": "202/1442", "id-external": ""}, {"name": "Fouzia Farooq", "id-internal": "270/8139", "id-external": ""}, {"name": "Xiaolei Huang", "id-internal": "32/5207", "id-external": ""}, {"name": "Amelia M. Jamison", "id-internal": "212/8940", "id-external": ""}, {"name": "Mark Dredze", "id-internal": "31/5468", "id-external": ""}, {"name": "Sandra Crouse Quinn", "id-internal": "212/8928", "id-external": ""}], "url": {"full": "URL#620226", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2609047891, "title": "Information disorders on Italian Facebook during COVID-19 infodemic.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Alessandro Celestini", "id-internal": "125/2357", "id-external": ""}, {"name": "Marco Di Giovanni", "id-internal": "217/9924", "id-external": ""}, {"name": "Stefano Guarino", "id-internal": "14/2001", "id-external": ""}, {"name": "Francesco Pierri 0002", "id-internal": "80/8064-2", "id-external": ""}], "url": {"full": "URL#620892", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3502982916, "title": "Infodemics - A call to action for interdisciplinary research.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Stephan Leitner", "id-internal": "144/1349", "id-external": ""}, {"name": "Bartosz Gula", "id-internal": "23/6380", "id-external": ""}, {"name": "Dietmar Jannach", "id-internal": "j/DietmarJannach", "id-external": ""}, {"name": "Ulrike Krieg-Holz", "id-internal": "184/8763", "id-external": ""}, {"name": "Friederike Wall", "id-internal": "99/1940", "id-external": ""}], "url": {"full": "URL#621215", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 917352073, "title": "Covid-19 infodemic reveals new tipping point epidemiology and a revised R formula.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Neil F. Johnson 0002", "id-internal": "71/5398-2", "id-external": ""}, {"name": "Nicolas Velasquez", "id-internal": "133/4673", "id-external": ""}, {"name": "O. K. Jha", "id-internal": "272/9146", "id-external": ""}, {"name": "H. Niyazi", "id-internal": "272/8903", "id-external": ""}, {"name": "Rhys Leahy", "id-internal": "266/7929", "id-external": ""}, {"name": "Nicholas Johnson Restrepo", "id-internal": "266/7719", "id-external": ""}, {"name": "Richard F. Sear", "id-internal": "266/8117", "id-external": ""}, {"name": "Pedro D. Manrique", "id-internal": "133/4691", "id-external": ""}, {"name": "Yonatan Lupu", "id-internal": "266/7394", "id-external": ""}, {"name": "P. Devkota", "id-internal": "272/8922", "id-external": ""}, {"name": "S. Wuchty", "id-internal": "272/8686", "id-external": ""}], "url": {"full": "URL#626150", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2941216591, "title": "Hate is the New Infodemic - A Topic-aware Modeling of Hate Speech Diffusion on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Sarah Masud", "id-internal": "115/9011", "id-external": ""}, {"name": "Subhabrata Dutta", "id-internal": "204/6929", "id-external": ""}, {"name": "Sakshi Makkar", "id-internal": "276/1551", "id-external": ""}, {"name": "Chhavi Jain", "id-internal": "276/0509", "id-external": ""}, {"name": "Vikram Goyal", "id-internal": "70/6404", "id-external": ""}, {"name": "Amitava Das", "id-internal": "75/5002", "id-external": ""}, {"name": "Tanmoy Chakraborty 0002", "id-internal": "65/2136-2", "id-external": ""}], "url": {"full": "URL#635610", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 379136058, "title": "A Cross-lingual Natural Language Processing Framework for Infodemic Management.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Ridam Pal", "id-internal": "277/5730", "id-external": ""}, {"name": "Rohan Pandey", "id-internal": "255/8512", "id-external": ""}, {"name": "Vaibhav Gautam", "id-internal": "260/6714", "id-external": ""}, {"name": "Kanav Bhagat", "id-internal": "260/6435", "id-external": ""}, {"name": "Tavpritesh Sethi", "id-internal": "205/6969", "id-external": ""}], "url": {"full": "URL#641042", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 670922317, "title": "Characterizing the roles of bots during the COVID-19 infodemic on Twitter.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Wentao Xu", "id-internal": "33/10700", "id-external": ""}, {"name": "Kazutoshi Sasahara", "id-internal": "27/6619", "id-external": ""}], "url": {"full": "URL#643790", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2305320032, "title": "The COVID19 infodemic. The role and place of academics in science communication.", "abstract": "", "doi": "", "date": "2020", "authors": {"name": "Jennifer Cole", "id-internal": "211/9903", "id-external": ""}, "url": {"full": "URL#644835", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2024296018, "title": "The COVID-19 Infodemic - Twitter versus Facebook.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Kai-Cheng Yang", "id-internal": "25/10485", "id-external": ""}, {"name": "Francesco Pierri 0002", "id-internal": "80/8064-2", "id-external": ""}, {"name": "Pik-Mai Hui", "id-internal": "135/6735", "id-external": ""}, {"name": "David Axelrod", "id-internal": "263/2863", "id-external": ""}, {"name": "Christopher Torres-Lugo", "id-internal": "256/5360", "id-external": ""}, {"name": "John Bryden", "id-internal": "42/4876", "id-external": ""}, {"name": "Filippo Menczer", "id-internal": "79/3056", "id-external": ""}], "url": {"full": "URL#651176", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1451076977, "title": "Conspiracy Machines - The Role of Social Bots during the COVID-19 Infodemic.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Julian Marx", "id-internal": "195/5111", "id-external": ""}, {"name": "Felix Br\u00fcnker", "id-internal": "195/5101", "id-external": ""}, {"name": "Milad Mirbabaie", "id-internal": "155/7706", "id-external": ""}, {"name": "Eric Hochstrate", "id-internal": "281/7410", "id-external": ""}], "url": {"full": "URL#651255", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2609128624, "title": "Challenges in Combating COVID-19 Infodemic -- Data, Tools, and Ethics", "abstract": "While the COVID-19 pandemic continues its global devastation, numerous\naccompanying challenges emerge. One important challenge we face is to\nefficiently and effectively use recently gathered data and find computational\ntools to combat the COVID-19 infodemic, a typical information overloading\nproblem. Novel coronavirus presents many questions without ready answers; its\nuncertainty and our eagerness in search of solutions offer a fertile\nenvironment for infodemic. It is thus necessary to combat the infodemic and\nmake a concerted effort to confront COVID-19 and mitigate its negative impact\nin all walks of life when saving lives and maintaining normal orders during\ntrying times. In this position paper of combating the COVID-19 infodemic, we\nillustrate its need by providing real-world examples of rampant conspiracy\ntheories, misinformation, and various types of scams that take advantage of\nhuman kindness, fear, and ignorance. We present three key challenges in this\nfight against the COVID-19 infodemic where researchers and practitioners\ninstinctively want to contribute and help. We demonstrate that these three\nchallenges can and will be effectively addressed by collective wisdom,\ncrowdsourcing, and collaborative research.", "doi": "", "date": "2020-05-27", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.13691v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 260728227, "title": "Characterizing the roles of bots during the COVID-19 infodemic on\n  Twitter", "abstract": "An infodemic is an emerging phenomenon caused by an overabundance of\ninformation online. This proliferation of information makes it difficult for\nthe public to distinguish trustworthy news and credible information from\nuntrustworthy sites and non-credible sources. The perils of an infodemic\ndebuted with the outbreak of the COVID-19 pandemic and bots (i.e., automated\naccounts controlled by a set of algorithms) that are suspected of spreading the\ninfodemic. Although previous research has revealed that bots played a central\nrole in spreading misinformation during major political events, how bots\nbehaved during the infodemic is unclear. In this paper, we examined the roles\nof bots in the case of the COVID-19 infodemic and the diffusion of non-credible\ninformation such as \"5G\" and \"Bill Gates\" conspiracy theories and content\nrelated to \"Trump\" and \"WHO\" by analyzing retweet networks and retweeted items.\nWe show the segregated topology of their retweet networks, which indicates that\nright-wing self-media accounts and conspiracy theorists may lead to this\nopinion cleavage, while malicious bots might favor amplification of the\ndiffusion of non-credible information. Although the basic influence of\ninformation diffusion could be larger in human users than bots, the effects of\nbots are non-negligible under an infodemic situation.", "doi": "", "date": "2020-11-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.06249v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3082450491, "title": "Misinformation, Believability, and Vaccine Acceptance Over 40 Countries:\n  Takeaways From the Initial Phase of The COVID-19 Infodemic", "abstract": "The COVID-19 pandemic has been damaging to the lives of people all around the\nworld. Accompanied by the pandemic is an infodemic, an abundant and\nuncontrolled spreading of potentially harmful misinformation. The infodemic may\nseverely change the pandemic's course by interfering with public health\ninterventions such as wearing masks, social distancing, and vaccination. In\nparticular, the impact of the infodemic on vaccination is critical because it\nholds the key to reverting to pre-pandemic normalcy. This paper presents\nfindings from a global survey on the extent of worldwide exposure to the\nCOVID-19 infodemic, assesses different populations' susceptibility to false\nclaims, and analyzes its association with vaccine acceptance. Based on\nresponses gathered from over 18,400 individuals from 40 countries, we find a\nstrong association between perceived believability of misinformation and\nvaccination hesitancy. Additionally, our study shows that only half of the\nonline users exposed to rumors might have seen the fact-checked information.\nMoreover, depending on the country, between 6% and 37% of individuals\nconsidered these rumors believable. Our survey also shows that poorer regions\nare more susceptible to encountering and believing COVID-19 misinformation. We\ndiscuss implications of our findings on public campaigns that proactively\nspread accurate information to countries that are more susceptible to the\ninfodemic. We also highlight fact-checking platforms' role in better\nidentifying and prioritizing claims that are perceived to be believable and\nhave wide exposure. Our findings give insights into better handling of risk\ncommunication during the initial phase of a future pandemic.", "doi": "", "date": "2021-04-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.10864v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2243931986, "title": "Fighting the COVID-19 Infodemic with a Holistic BERT Ensemble", "abstract": "This paper describes the TOKOFOU system, an ensemble model for misinformation\ndetection tasks based on six different transformer-based pre-trained encoders,\nimplemented in the context of the COVID-19 Infodemic Shared Task for English.\nWe fine tune each model on each of the task's questions and aggregate their\nprediction scores using a majority voting approach. TOKOFOU obtains an overall\nF1 score of 89.7%, ranking first.", "doi": "", "date": "2021-04-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.05745v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1077276239, "title": "Fighting the COVID-19 Infodemic in Social Media: A Holistic Perspective\n  and a Call to Arms", "abstract": "With the outbreak of the COVID-19 pandemic, people turned to social media to\nread and to share timely information including statistics, warnings, advice,\nand inspirational stories. Unfortunately, alongside all this useful\ninformation, there was also a new blending of medical and political\nmisinformation and disinformation, which gave rise to the first global\ninfodemic. While fighting this infodemic is typically thought of in terms of\nfactuality, the problem is much broader as malicious content includes not only\nfake news, rumors, and conspiracy theories, but also promotion of fake cures,\npanic, racism, xenophobia, and mistrust in the authorities, among others. This\nis a complex problem that needs a holistic approach combining the perspectives\nof journalists, fact-checkers, policymakers, government entities, social media\nplatforms, and society as a whole. Taking them into account we define an\nannotation schema and detailed annotation instructions, which reflect these\nperspectives. We performed initial annotations using this schema, and our\ninitial experiments demonstrated sizable improvements over the baselines. Now,\nwe issue a call to arms to the research community and beyond to join the fight\nby supporting our crowdsourcing annotation efforts.", "doi": "", "date": "2020-07-15", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.07996v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3607503300, "title": "Covid-19 infodemic reveals new tipping point epidemiology and a revised\n  $R$ formula", "abstract": "Many governments have managed to control their COVID-19 outbreak with a\nsimple message: keep the effective '$R$ number' $R<1$ to prevent widespread\ncontagion and flatten the curve. This raises the question whether a similar\npolicy could control dangerous online 'infodemics' of information,\nmisinformation and disinformation. Here we show, using multi-platform data from\nthe COVID-19 infodemic, that its online spreading instead encompasses a\ndifferent dynamical regime where communities and users within and across\nindependent platforms, sporadically form temporary active links on similar\ntimescales to the viral spreading. This allows material that might have died\nout, to evolve and even mutate. This has enabled niche networks that were\nalready successfully spreading hate and anti-vaccination material, to rapidly\nbecome global super-spreaders of narratives featuring fake COVID-19 treatments,\nanti-Asian sentiment and conspiracy theories. We derive new tools that\nincorporate these coupled social-viral dynamics, including an online $R$, to\nhelp prevent infodemic spreading at all scales: from spreading across platforms\n(e.g. Facebook, 4Chan) to spreading within a given subpopulation, or community,\nor topic. By accounting for similar social and viral timescales, the same\nmathematical theory also offers a quantitative description of other\nunconventional infection profiles such as rumors spreading in financial markets\nand colds spreading in schools.", "doi": "", "date": "2020-08-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.08513v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1732949972, "title": "The COVID-19 infodemic does not affect vaccine acceptance", "abstract": "How does information consumption affect behaviour in the context of the\nCOVID-19 pandemic? A popular hypothesis states that the so-called infodemics\nhas substantial impact on orienting individual decisions. A competing\nhypothesis stresses that exposure to vast amounts of even contradictory\ninformation has little effect on personal choices. We analyse the vaccine\ninfodemics on Twitter and Facebook by looking at 146M contents produced by 20M\naccounts between 1 January 2020 and 30 April 2021. We find that vaccine-related\nnews triggered huge interest through social media, affecting attention patterns\nand the modality in which information was spreading. However, we find that such\na tumultuous information landscape translated in only minimal variations in\nvaccine acceptance as measured by Facebook's daily COVID-19 World Symptoms\nSurvey on a sample of 1.6M users. This finding supports the hypothesis that\naltered information consumption patterns are not a reliable predictor of\nbehavioural change. Instead, wider attention on social media seems to resolve\nin polarisation, with the vaccine-prone and the vaccine-hesitant maintaining\ntheir positions.", "doi": "", "date": "2021-07-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.07946v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2195890936, "title": "Psychometric Analysis and Coupling of Emotions Between State Bulletins\n  and Twitter in India during COVID-19 Infodemic", "abstract": "COVID-19 infodemic has been spreading faster than the pandemic itself. The\nmisinformation riding upon the infodemic wave poses a major threat to people's\nhealth and governance systems. Since social media is the largest source of\ninformation, managing the infodemic not only requires mitigating of\nmisinformation but also an early understanding of psychological patterns\nresulting from it. During the COVID-19 crisis, Twitter alone has seen a sharp\n45% increase in the usage of its curated events page, and a 30% increase in its\ndirect messaging usage, since March 6th 2020. In this study, we analyze the\npsychometric impact and coupling of the COVID-19 infodemic with the official\nbulletins related to COVID-19 at the national and state level in India. We look\nat these two sources with a psycho-linguistic lens of emotions and quantified\nthe extent and coupling between the two. We modified path, a deep skip-gram\nbased open-sourced lexicon builder for effective capture of health-related\nemotions. We were then able to capture the time-evolution of health-related\nemotions in social media and official bulletins. An analysis of lead-lag\nrelationships between the time series of extracted emotions from official\nbulletins and social media using Granger's causality showed that state\nbulletins were leading the social media for some emotions such as Medical\nEmergency. Further insights that are potentially relevant for the policymaker\nand the communicators actively engaged in mitigating misinformation are also\ndiscussed. Our paper also introduces CoronaIndiaDataset2, the first social\nmedia based COVID-19 dataset at national and state levels from India with over\n5.6 million national and 2.6 million state-level tweets. Finally, we present\nour findings as COVibes, an interactive web application capturing psychometric\ninsights captured upon the CoronaIndiaDataset, both at a national and state\nlevel.", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.05513v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4033215633, "title": "Understanding the dynamics emerging from infodemics: A call to action\n  for interdisciplinary research", "abstract": "Research on infodemics, i.e., the rapid spread of (mis)information related to\na hazardous event, such as the COVID-19 pandemic, requires the integration of a\nmultiplicity of scientific disciplines. The dynamics emerging from infodemics\nhave the potential to generate complex behavioral patterns. In order to react\nappropriately, it is of ultimate importance for the fields of Business and\nEconomics to understand the dynamics emerging from it. In the short run,\ndynamics might lead to an adaptation in household spending or to a shift in\nbuying behavior towards online providers. In the long run, changes in\ninvestments, consumer behavior, and markets are to be expected. We argue that\nthe dynamics emerge from complex interactions among multiple factors, such as\ninformation and misinformation accessible for individuals and the formation and\nrevision of beliefs. (Mis)information accessible to individuals is, amongst\nothers, affected by algorithms specifically designed to provide personalized\ninformation, while automated fact-checking algorithms can help reduce the\namount of circulating misinformation. The formation and revision of individual\n(and probably false) beliefs and individual fact-checking and interpretation of\ninformation are heavily affected by linguistic patterns inherent to information\nduring pandemics and infodemics and further factors, such as affect, intuition\nand motives. We argue that, in order to get a deep(er) understanding of the\ndynamics emerging from infodemics, the fields of Business and Economics should\nintegrate the perspectives of Computer Science and Information Systems,\n(Computational) Linguistics, and Cognitive Science into the wider context of\neconomic systems (e.g., organizations, markets or industries) and propose a way\nto do so.", "doi": "", "date": "2020-07-23", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.12226v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1180303048, "title": "Fighting the COVID-19 Infodemic: Modeling the Perspective of\n  Journalists, Fact-Checkers, Social Media Platforms, Policy Makers, and the\n  Society", "abstract": "With the emergence of the COVID-19 pandemic, the political and the medical\naspects of disinformation merged as the problem got elevated to a whole new\nlevel to become the first global infodemic. Fighting this infodemic is ranked\nsecond in the list of the most important focus areas of the World Health\nOrganization, with dangers ranging from promoting fake cures, rumors, and\nconspiracy theories to spreading xenophobia and panic. Addressing the issue\nrequires solving a number of challenging problems such as identifying messages\ncontaining claims, determining their check-worthiness and factuality, and their\npotential to do harm as well as the nature of that harm, to mention just a few.\nThus, here we design, annotate, and release to the research community a new\ndataset for fine-grained disinformation analysis that (i)focuses on COVID-19,\n(ii) combines the perspectives and the interests of journalists, fact-checkers,\nsocial media platforms, policy makers, and society as a whole, and (iii) covers\nboth English and Arabic. Finally, we show strong evaluation results using\nstate-of-the-art Transformers, thus confirming the practical utility of the\nannotation schema and of the dataset.", "doi": "", "date": "2020-04-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.00033v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 591853144, "title": "Characterizing information leaders in Twitter during COVID-19 crisis", "abstract": "Information is key during a crisis such as the one produced by the current\nCOVID-19 pandemic as it greatly shapes people opinion, behavior and their\npsychology. Infodemic of misinformation is an important secondary crisis\nassociated to the pandemic. Infodemics can amplify the real negative\nconsequences of the pandemic in different dimensions: social, economic and even\nsanitary. For instance, infodemics can lead to hatred between population groups\nthat fragment the society influencing its response or result in negative habits\nthat help the pandemic propagate. On the contrary, reliable and trustful\ninformation along with messages of hope and solidarity can be used to control\nthe pandemic, build safety nets and help promote resilience. We propose the\nfoundation of a framework to characterize leaders in Twitter based on the\nanalysis of the social graph derived from the activity in this social network.\nCentrality metrics are used to characterize the topology of the network and the\nnodes as potential leaders. These metrics are compared with the user popularity\nmetrics managed by Twitter. We then assess the resulting topology of clusters\nof leaders visually. We propose this tool to be the basis for a system to\ndetect and empower users with a positive influence in the collective behavior\nof the network and the propagation of information.", "doi": "", "date": "2020-05-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.07266v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1656932554, "title": "The COVID19 infodemic. The role and place of academics in science\n  communication", "abstract": "As the COVID19 pandemic has spread across the world, a concurrent pandemic of\ninformation has spread with it. Deemed an infodemic by the World Health\nOrganization, and described as an overabundance of information, some accurate,\nsome not, that occurs during an epidemic, this proliferation of data, research\nand opinions provides both opportunities and challenges for academics.\nAcademics and scientists have a key role to play in the solutions to the\ninfodemic challenge: as educators, influences and communicators, even where\ntheir expertise and experience does not align precisely with the SARS-Cov2\nvirus and its impacts.\n  Successful communication requires a better understanding of how the public\nseeks, understands and processes scientific information, however, in order to\nmaximise the ways in which experts engage with traditional and social media and\nto make sure that such engagement does not add to confusion and misinformation\nalongside efforts to counter or challenge it. This paper will outline the key\nadvantages to be had from greater engagement with COVID19 discussions, the\npopular channels through which such discussions take place and through which\ninformation is disseminated. It also warns against the common pitfalls those\nwho choose to engage might encounter, whilst stressing that the disadvantages\nof doing so are far outweighed by the advantages such engagement offers.", "doi": "", "date": "2020-11-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.08787v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1548789121, "title": "TrollHunter [Evader]: Automated Detection [Evasion] of Twitter Trolls\n  During the COVID-19 Pandemic", "abstract": "This paper presents TrollHunter, an automated reasoning mechanism we used to\nhunt for trolls on Twitter during the COVID-19 pandemic in 2020. Trolls, poised\nto disrupt the online discourse and spread disinformation, quickly seized the\nabsence of a credible response to COVID-19 and created a COVID-19 infodemic by\npromulgating dubious content on Twitter. To counter the COVID-19 infodemic, the\nTrollHunter leverages a unique linguistic analysis of a multi-dimensional set\nof Twitter content features to detect whether or not a tweet was meant to\ntroll. TrollHunter achieved 98.5% accuracy, 75.4% precision and 69.8% recall\nover a dataset of 1.3 million tweets. Without a final resolution of the\npandemic in sight, it is unlikely that the trolls will go away, although they\nmight be forced to evade automated hunting. To explore the plausibility of this\nstrategy, we developed and tested an adversarial machine learning mechanism\ncalled TrollHunter-Evader. TrollHunter-Evader employs a Test Time Evasion (TTE)\napproach in a combination with a Markov chain-based mechanism to recycle\noriginally trolling tweets. The recycled tweets were able to achieve a\nremarkable 40% decrease in the TrollHunter's ability to correctly identify\ntrolling tweets. Because the COVID-19 infodemic could have a harmful impact on\nthe COVID-19 pandemic, we provide an elaborate discussion about the\nimplications of employing adversarial machine learning to evade Twitter troll\nhunts.", "doi": "", "date": "2020-12-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.02586v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 394441329, "title": "The COVID-19 Infodemic: Twitter versus Facebook", "abstract": "The global spread of the novel coronavirus is affected by the spread of\nrelated misinformation -- the so-called COVID-19 Infodemic -- that makes\npopulations more vulnerable to the disease through resistance to mitigation\nefforts. Here we analyze the prevalence and diffusion of links to\nlow-credibility content about the pandemic across two major social media\nplatforms, Twitter and Facebook. We characterize cross-platform similarities\nand differences in popular sources, diffusion patterns, influencers,\ncoordination, and automation. Comparing the two platforms, we find divergence\namong the prevalence of popular low-credibility sources and suspicious videos.\nA minority of accounts and pages exert a strong influence on each platform.\nThese misinformation \"superspreaders\" are often associated with the\nlow-credibility sources and tend to be verified by the platforms. On both\nplatforms, there is evidence of coordinated sharing of Infodemic content. The\novert nature of this manipulation points to the need for societal-level\nsolutions in addition to mitigation strategies within the platforms. However,\nwe highlight limits imposed by inconsistent data-access policies on our\ncapability to study harmful manipulations of information ecosystems.", "doi": "", "date": "2020-12-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.09353v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2525482845, "title": "Experts and authorities receive disproportionate attention on Twitter\n  during the COVID-19 crisis", "abstract": "Timely access to accurate information is crucial during the COVID-19\npandemic. Prompted by key stakeholders' cautioning against an \"infodemic\", we\nstudy information sharing on Twitter from January through May 2020. We observe\nan overall surge in the volume of general as well as COVID-19-related tweets\naround peak lockdown in March/April 2020. With respect to engagement (retweets\nand likes), accounts related to healthcare, science, government and politics\nreceived by far the largest boosts, whereas accounts related to religion and\nsports saw a relative decrease in engagement. While the threat of an\n\"infodemic\" remains, our results show that social media also provide a platform\nfor experts and public authorities to be widely heard during a global crisis.", "doi": "", "date": "2020-08-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.08364v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3550005490, "title": "Towards Combating Pandemic-related Misinformation in Social Media", "abstract": "Conventional preventive measures during pandemic include social distancing\nand lockdown. Such measures in the time of social media brought about a new set\nof challenges - vulnerability to the toxic impact of online misinformation is\nhigh. A case in point is the prevailing COVID-19; as the virus propagates, so\ndoes the associated misinformation and fake news about it leading to infodemic.\nSince the outbreak, there has been a surge of studies investigating various\naspects of the pandemic. Of interest to this chapter include studies centring\non datasets from online social media platforms where the bulk of the public\ndiscourse happen. Consequently, the main goal is to support the fight against\nnegative infodemic by (1) contributing a diverse set of curated relevant\ndatasets (2) recommending relevant areas to study using the datasets (3)\ndiscussion on how relevant datasets, strategies and state-of-the-art IT tools\ncan be leveraged in managing the pandemic.", "doi": "", "date": "2020-11-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.14146v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3211719312, "title": "Conspiracy Machines -- The Role of Social Bots during the COVID-19\n  Infodemic", "abstract": "The omnipresent COVID-19 pandemic gave rise to a parallel spreading of\nmisinformation, also referred to as an Infodemic. Consequently, social media\nhave become targets for the application of social bots, that is, algorithms\nthat mimic human behaviour. Their ability to exert influence on social media\ncan be exploited by amplifying misinformation, rumours, or conspiracy theories\nwhich might be harmful to society and the mastery of the pandemic. By applying\nsocial bot detection and content analysis techniques, this study aims to\ndetermine the extent to which social bots interfere with COVID- 19 discussions\non Twitter. A total of 78 presumptive bots were detected within a sample of\n542,345 users. The analysis revealed that bot-like users who disseminate\nmisinformation, at the same time, intersperse news from renowned sources. The\nfindings of this research provide implications for improved bot detection and\nmanaging potential threats through social bots during ongoing and future\ncrises.", "doi": "", "date": "2020-12-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.09536v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3273676009, "title": "Transformers to Fight the COVID-19 Infodemic", "abstract": "The massive spread of false information on social media has become a global\nrisk especially in a global pandemic situation like COVID-19. False information\ndetection has thus become a surging research topic in recent months.\nNLP4IF-2021 shared task on fighting the COVID-19 infodemic has been organised\nto strengthen the research in false information detection where the\nparticipants are asked to predict seven different binary labels regarding false\ninformation in a tweet. The shared task has been organised in three languages;\nArabic, Bulgarian and English. In this paper, we present our approach to tackle\nthe task objective using transformers. Overall, our approach achieves a 0.707\nmean F1 score in Arabic, 0.578 mean F1 score in Bulgarian and 0.864 mean F1\nscore in English ranking 4th place in all the languages.", "doi": "", "date": "2021-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.12201v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 694244146, "title": "Infodemics on Youtube: Reliability of Content and Echo Chambers on\n  COVID-19", "abstract": "Social media radically changed how information is consumed and reported.\nMoreover, social networks elicited a disintermediated access to an\nunprecedented amount of content. The world health organization (WHO) coined the\nterm infodemics to identify the information overabundance during an epidemic.\nIndeed, the spread of inaccurate and misleading information may alter behaviors\nand complicate crisis management and health responses. This paper addresses\ninformation diffusion during the COVID-19 pandemic period with a massive data\nanalysis on YouTube. First, we analyze more than 2M users' engagement in 13000\nvideos released by 68 different YouTube channels, with different political bias\nand fact-checking indexes. We then investigate the relationship between each\nuser's political preference and her/his consumption of questionable/reliable\ninformation. Our results, quantified using information theory measures, provide\nevidence for the existence of echo chambers across two dimensions represented\nby the political bias and by the trustworthiness of information channels.\nFinally, we observe that the echo chamber structure cannot be reproduced after\nproperly randomizing the users' interaction patterns.", "doi": "", "date": "2021-06-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.08684v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 840841843, "title": "Tackling COVID-19 Infodemic using Deep Learning", "abstract": "Humanity is battling one of the most deleterious virus in modern history, the\nCOVID-19 pandemic, but along with the pandemic there's an infodemic permeating\nthe pupil and society with misinformation which exacerbates the current malady.\nWe try to detect and classify fake news on online media to detect fake\ninformation relating to COVID-19 and coronavirus. The dataset contained fake\nposts, articles and news gathered from fact checking websites like politifact\nwhereas real tweets were taken from verified twitter handles. We incorporated\nmultiple conventional classification techniques like Naive Bayes, KNN, Gradient\nBoost and Random Forest along with Deep learning approaches, specifically CNN,\nRNN, DNN and the ensemble model RMDL. We analyzed these approaches with two\nfeature extraction techniques, TF-IDF and GloVe Word Embeddings which would\nprovide deeper insights into the dataset containing COVID-19 info on online\nmedia.", "doi": "", "date": "2021-07-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.02012v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1395610346, "title": "Twitter and Facebook posts about COVID-19 are less likely to spread\n  false and low-credibility content compared to other health topics", "abstract": "On February 2, 2020, the World Health Organization declared a COVID-19 social\nmedia \"infodemic\", with special attention to misinformation -- frequently\nunderstood as false claims. To understand the infodemic's scope and scale, we\nanalyzed over 500 million posts from Twitter and Facebook about COVID-19 and\nother health topics, between March 8 and May 1, 2020. Following prior work, we\nassumed URL source credibility is a proxy for false content, but we also tested\nthis assumption. Contrary to expectations, we found that messages about\nCOVID-19 were more likely to contain links to more credible sources.\nAdditionally, messages linking to government sources, and to news with\nintermediate credibility, were shared more often, on average, than links to\nnon-credible sources. These results suggest that more ambiguous forms of\nmisinformation about COVID-19 may be more likely to be disseminated through\ncredible sources when compared to other health topics. Furthermore, the\nassumption that credibility is an adequate proxy for false content may\noverestimate the prevalence of false content online: less than 25% of posts\nlinking to the least credible sources contained false content. Our results\nemphasize the importance of distinguishing between explicit falsehoods and more\nambiguous forms of misinformation due to the search for meaning in an\nenvironment of scientific uncertainty.", "doi": "", "date": "2020-07-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.09682v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1852971266, "title": "Team Alex at CLEF CheckThat! 2020: Identifying Check-Worthy Tweets With\n  Transformer Models", "abstract": "While misinformation and disinformation have been thriving in social media\nfor years, with the emergence of the COVID-19 pandemic, the political and the\nhealth misinformation merged, thus elevating the problem to a whole new level\nand giving rise to the first global infodemic. The fight against this infodemic\nhas many aspects, with fact-checking and debunking false and misleading claims\nbeing among the most important ones. Unfortunately, manual fact-checking is\ntime-consuming and automatic fact-checking is resource-intense, which means\nthat we need to pre-filter the input social media posts and to throw out those\nthat do not appear to be check-worthy. With this in mind, here we propose a\nmodel for detecting check-worthy tweets about COVID-19, which combines deep\ncontextualized text representations with modeling the social context of the\ntweet. We further describe a number of additional experiments and comparisons,\nwhich we believe should be useful for future research as they provide some\nindication about what techniques are effective for the task. Our official\nsubmission to the English version of CLEF-2020 CheckThat! Task 1, system\nTeam_Alex, was ranked second with a MAP score of 0.8034, which is almost tied\nwith the wining system, lagging behind by just 0.003 MAP points absolute.", "doi": "", "date": "2020-09-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2009.02931v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3011025938, "title": "Understanding Health Misinformation Transmission: An Interpretable Deep\n  Learning Approach to Manage Infodemics", "abstract": "Health misinformation on social media devastates physical and mental health,\ninvalidates health gains, and potentially costs lives. Understanding how health\nmisinformation is transmitted is an urgent goal for researchers, social media\nplatforms, health sectors, and policymakers to mitigate those ramifications.\nDeep learning methods have been deployed to predict the spread of\nmisinformation. While achieving the state-of-the-art predictive performance,\ndeep learning methods lack the interpretability due to their blackbox nature.\nTo remedy this gap, this study proposes a novel interpretable deep learning\napproach, Generative Adversarial Network based Piecewise Wide and Attention\nDeep Learning (GAN-PiWAD), to predict health misinformation transmission in\nsocial media. Improving upon state-of-the-art interpretable methods, GAN-PiWAD\ncaptures the interactions among multi-modal data, offers unbiased estimation of\nthe total effect of each feature, and models the dynamic total effect of each\nfeature when its value varies. We select features according to social exchange\ntheory and evaluate GAN-PiWAD on 4,445 misinformation videos. The proposed\napproach outperformed strong benchmarks. Interpretation of GAN-PiWAD indicates\nvideo description, negative video content, and channel credibility are key\nfeatures that drive viral transmission of misinformation. This study\ncontributes to IS with a novel interpretable deep learning method that is\ngeneralizable to understand other human decision factors. Our findings provide\ndirect implications for social media platforms and policymakers to design\nproactive interventions to identify misinformation, control transmissions, and\nmanage infodemics.", "doi": "", "date": "2020-12-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.01076v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2289549426, "title": "What social media told about us in the time of COVID-19: a scoping\n  review", "abstract": "With the onset of COVID-19 pandemic, social media has rapidly become a\ncrucial communication tool for information generation, dissemination, and\nconsumption. In this scoping review, we selected and examined peer-reviewed\nempirical studies relating to COVID-19 and social media during the first\noutbreak starting in November 2019 until May 2020. From an analysis of 81\nstudies, we identified five overarching public health themes concerning the\nrole of online social platforms and COVID-19. These themes focused on: (i)\nsurveying public attitudes, (ii) identifying infodemics, (iii) assessing mental\nhealth, (iv) detecting or predicting COVID-19 cases, (v) analyzing government\nresponses to the pandemic, and (vi) evaluating quality of health information in\nprevention education videos. Furthermore, our review highlights the paucity of\nstudies on the application of machine learning on social media data related to\nCOVID-19 and a lack of studies documenting real-time surveillance developed\nwith social media data on COVID-19. For COVID-19, social media can play a\ncrucial role in disseminating health information as well as tackling infodemics\nand misinformation.", "doi": "10.1016/s2589-7500(20)30315-0", "date": "2021-01-05", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.01688v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1981337807, "title": "Model Generalization on COVID-19 Fake News Detection", "abstract": "Amid the pandemic COVID-19, the world is facing unprecedented infodemic with\nthe proliferation of both fake and real information. Considering the\nproblematic consequences that the COVID-19 fake-news have brought, the\nscientific community has put effort to tackle it. To contribute to this fight\nagainst the infodemic, we aim to achieve a robust model for the COVID-19\nfake-news detection task proposed at CONSTRAINT 2021 (FakeNews-19) by taking\ntwo separate approaches: 1) fine-tuning transformers based language models with\nrobust loss functions and 2) removing harmful training instances through\ninfluence calculation. We further evaluate the robustness of our models by\nevaluating on different COVID-19 misinformation test set (Tweets-19) to\nunderstand model generalization ability. With the first approach, we achieve\n98.13% for weighted F1 score (W-F1) for the shared task, whereas 38.18% W-F1 on\nthe Tweets-19 highest. On the contrary, by performing influence data cleansing,\nour model with 99% cleansing percentage can achieve 54.33% W-F1 score on\nTweets-19 with a trade-off. By evaluating our models on two COVID-19 fake-news\ntest sets, we suggest the importance of model generalization ability in this\ntask to step forward to tackle the COVID-19 fake-news problem in online social\nmedia platforms.", "doi": "", "date": "2021-01-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.03841v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3209119604, "title": "Advertisers Jump on Coronavirus Bandwagon: Politics, News, and Business", "abstract": "In the age of social media, disasters and epidemics usher not only a\ndevastation and affliction in the physical world, but also prompt a deluge of\ninformation, opinions, prognoses and advice to billions of internet users. The\ncoronavirus epidemic of 2019-2020, or COVID-19, is no exception, with the World\nHealth Organization warning of a possible \"infodemic\" of fake news. In this\nstudy, we examine the alternative narratives around the coronavirus outbreak\nthrough advertisements promoted on Facebook, the largest social media platform\nin the US. Using the new Facebook Ads Library, we discover advertisers from\npublic health and non-profit sectors, alongside those from news media,\npolitics, and business, incorporating coronavirus into their messaging and\nagenda. We find the virus used in political attacks, donation solicitations,\nbusiness promotion, stock market advice, and animal rights campaigning. Among\nthese, we find several instances of possible misinformation, ranging from\nbioweapons conspiracy theories to unverifiable claims by politicians. As we\nmake the dataset available to the community, we hope the advertising domain\nwill become an important part of quality control for public health\ncommunication and public discourse in general.", "doi": "", "date": "2020-03-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.00923v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1967797583, "title": "The COVID-19 Social Media Infodemic", "abstract": "We address the diffusion of information about the COVID-19 with a massive\ndata analysis on Twitter, Instagram, YouTube, Reddit and Gab. We analyze\nengagement and interest in the COVID-19 topic and provide a differential\nassessment on the evolution of the discourse on a global scale for each\nplatform and their users. We fit information spreading with epidemic models\ncharacterizing the basic reproduction numbers $R_0$ for each social media\nplatform. Moreover, we characterize information spreading from questionable\nsources, finding different volumes of misinformation in each platform. However,\ninformation from both reliable and questionable sources do not present\ndifferent spreading patterns. Finally, we provide platform-dependent numerical\nestimates of rumors' amplification.", "doi": "10.1038/s41598-020-73510-5", "date": "2020-03-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.05004v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1417813737, "title": "Assessing the risks of \"infodemics\" in response to COVID-19 epidemics", "abstract": "Our society is built on a complex web of interdependencies whose effects\nbecome manifest during extraordinary events such as the COVID-19 pandemic, with\nshocks in one system propagating to the others to an exceptional extent. We\nanalyzed more than 100 millions Twitter messages posted worldwide in 64\nlanguages during the epidemic emergency due to SARS-CoV-2 and classified the\nreliability of news diffused. We found that waves of unreliable and low-quality\ninformation anticipate the epidemic ones, exposing entire countries to\nirrational social behavior and serious threats for public health. When the\nepidemics hit the same area, reliable information is quickly inoculated, like\nantibodies, and the system shifts focus towards certified informational\nsources. Contrary to mainstream beliefs, we show that human response to\nfalsehood exhibits early-warning signals that might be mitigated with adequate\ncommunication strategies.", "doi": "10.1038/s41562-020-00994-6", "date": "2020-04-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.03997v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4022670301, "title": "On the dynamics emerging from pandemics and infodemics", "abstract": "This position paper discusses emerging behavioral, social, and economic\ndynamics related to the COVID-19 pandemic and puts particular emphasis on two\nemerging issues: First, delayed effects (or second strikes) of pandemics caused\nby dread risk effects are discussed whereby two factors which might influence\nthe existence of such effects are identified, namely the accessibility of\n(mis-)information and the effects of policy decisions on adaptive behavior.\nSecond, the issue of individual preparedness to hazardous events is discussed.\nAs events such as the COVID-19 pandemic unfolds complex behavioral patterns\nwhich are hard to predict, sophisticated models which account for behavioral,\nsocial, and economic dynamics are required to assess the effectivity and\nefficiency of decision-making.", "doi": "10.1007/s11299-020-00256-y", "date": "2020-04-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.08917v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1413427073, "title": "A First Instagram Dataset on COVID-19", "abstract": "The novel coronavirus (COVID-19) pandemic outbreak is drastically shaping and\nreshaping many aspects of our life, with a huge impact on our social life. In\nthis era of lockdown policies in most of the major cities around the world, we\nsee a huge increase in people and professional engagement in social media.\nSocial media is playing an important role in news propagation as well as\nkeeping people in contact. At the same time, this source is both a blessing and\na curse as the coronavirus infodemic has become a major concern, and is already\na topic that needs special attention and further research. In this paper, we\nprovide a multilingual coronavirus (COVID-19) Instagram dataset that we have\nbeen continuously collected since March 30, 2020. We are making our dataset\navailable to the research community at Github. We believe that this\ncontribution will help the community to better understand the dynamics behind\nthis phenomenon in Instagram, as one of the major social media. This dataset\ncould also help study the propagation of misinformation related to this\noutbreak.", "doi": "", "date": "2020-04-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2004.12226v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 217409772, "title": "Analysis of misinformation during the COVID-19 outbreak in China:\n  cultural, social and political entanglements", "abstract": "COVID-19 resulted in an infodemic, which could erode public trust, impede\nvirus containment, and outlive the pandemic itself. The evolving and fragmented\nmedia landscape is a key driver of the spread of misinformation. Using\nmisinformation identified by the fact-checking platform by Tencent and posts on\nWeibo, our results showed that the evolution of misinformation follows an\nissue-attention cycle, pertaining to topics such as city lockdown, cures, and\npreventions, and school reopening. Sources of authority weigh in on these\ntopics, but their influence is complicated by peoples' pre-existing beliefs and\ncultural practices. Finally, social media has a complicated relationship with\nestablished or legacy media systems. Sometimes they reinforce each other, but\nin general, social media may have a topic cycle of its own making. Our findings\nshed light on the distinct characteristics of misinformation during the\nCOVID-19 and offer insights into combating misinformation in China and across\nthe world at large.", "doi": "", "date": "2020-05-21", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.10414v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2086619452, "title": "Can We Spot the \"Fake News\" Before It Was Even Written?", "abstract": "Given the recent proliferation of disinformation online, there has been also\ngrowing research interest in automatically debunking rumors, false claims, and\n\"fake news.\" A number of fact-checking initiatives have been launched so far,\nboth manual and automatic, but the whole enterprise remains in a state of\ncrisis: by the time a claim is finally fact-checked, it could have reached\nmillions of users, and the harm caused could hardly be undone. An arguably more\npromising direction is to focus on fact-checking entire news outlets, which can\nbe done in advance. Then, we could fact-check the news before it was even\nwritten: by checking how trustworthy the outlets that published it is. We\ndescribe how we do this in the Tanbih news aggregator, which makes readers\naware of what they are reading. In particular, we develop media profiles that\nshow the general factuality of reporting, the degree of propagandistic content,\nhyper-partisanship, leading political ideology, general frame of reporting, and\nstance with respect to various claims and topics.", "doi": "", "date": "2020-08-10", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2008.04374v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2663031605, "title": "Disinformation in the Online Information Ecosystem: Detection,\n  Mitigation and Challenges", "abstract": "With the rapid increase in access to internet and the subsequent growth in\nthe population of online social media users, the quality of information posted,\ndisseminated and consumed via these platforms is an issue of growing concern. A\nlarge fraction of the common public turn to social media platforms and in\ngeneral the internet for news and even information regarding highly concerning\nissues such as COVID-19 symptoms. Given that the online information ecosystem\nis extremely noisy, fraught with misinformation and disinformation, and often\ncontaminated by malicious agents spreading propaganda, identifying genuine and\ngood quality information from disinformation is a challenging task for humans.\nIn this regard, there is a significant amount of ongoing research in the\ndirections of disinformation detection and mitigation. In this survey, we\ndiscuss the online disinformation problem, focusing on the recent 'infodemic'\nin the wake of the coronavirus pandemic. We then proceed to discuss the\ninherent challenges in disinformation research, and then elaborate on the\ncomputational and interdisciplinary approaches towards mitigation of\ndisinformation, after a short overview of the various directions explored in\ndetection efforts.", "doi": "", "date": "2020-10-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.09113v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4252966285, "title": "A Cross-lingual Natural Language Processing Framework for Infodemic\n  Management", "abstract": "The COVID-19 pandemic has put immense pressure on health systems which are\nfurther strained due to the misinformation surrounding it. Under such a\nsituation, providing the right information at the right time is crucial. There\nis a growing demand for the management of information spread using Artificial\nIntelligence. Hence, we have exploited the potential of Natural Language\nProcessing for identifying relevant information that needs to be disseminated\namongst the masses. In this work, we present a novel Cross-lingual Natural\nLanguage Processing framework to provide relevant information by matching daily\nnews with trusted guidelines from the World Health Organization. The proposed\npipeline deploys various techniques of NLP such as summarizers, word\nembeddings, and similarity metrics to provide users with news articles along\nwith a corresponding healthcare guideline. A total of 36 models were evaluated\nand a combination of LexRank based summarizer on Word2Vec embedding with Word\nMover distance metric outperformed all other models. This novel open-source\napproach can be used as a template for proactive dissemination of relevant\nhealthcare information in the midst of misinformation spread associated with\nepidemics.", "doi": "", "date": "2020-10-30", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.16357v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3819692787, "title": "A First Look at COVID-19 Messages on WhatsApp in Pakistan", "abstract": "The worldwide spread of COVID-19 has prompted extensive online discussions,\ncreating an `infodemic' on social media platforms such as WhatsApp and Twitter.\nHowever, the information shared on these platforms is prone to be unreliable\nand/or misleading. In this paper, we present the first analysis of COVID-19\ndiscourse on public WhatsApp groups from Pakistan. Building on a large scale\nannotation of thousands of messages containing text and images, we identify the\nmain categories of discussion. We focus on COVID-19 messages and understand the\ndifferent types of images/text messages being propagated. By exploring user\nbehavior related to COVID messages, we inspect how misinformation is spread.\nFinally, by quantifying the flow of information across WhatsApp and Twitter, we\nshow how information spreads across platforms and how WhatsApp acts as a source\nfor much of the information shared on Twitter.", "doi": "", "date": "2020-11-18", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.09145v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3593293325, "title": "From #Jobsearch to #Mask: Improving COVID-19 Cascade Prediction with\n  Spillover Effects", "abstract": "An information outbreak occurs on social media along with the COVID-19\npandemic and leads to infodemic. Predicting the popularity of online content,\nknown as cascade prediction, allows for not only catching in advance hot\ninformation that deserves attention, but also identifying false information\nthat will widely spread and require quick response to mitigate its impact.\nAmong the various information diffusion patterns leveraged in previous works,\nthe spillover effect of the information exposed to users on their decision to\nparticipate in diffusing certain information is still not studied. In this\npaper, we focus on the diffusion of information related to COVID-19 preventive\nmeasures. Through our collected Twitter dataset, we validated the existence of\nthis spillover effect. Building on the finding, we proposed extensions to three\ncascade prediction methods based on Graph Neural Networks (GNNs). Experiments\nconducted on our dataset demonstrated that the use of the identified spillover\neffect significantly improves the state-of-the-art GNNs methods in predicting\nthe popularity of not only preventive measure messages, but also other COVID-19\nrelated messages.", "doi": "", "date": "2020-12-13", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.07088v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 963554235, "title": "Multistage BiCross encoder for multilingual access to COVID-19 health\n  information", "abstract": "The Coronavirus (COVID-19) pandemic has led to a rapidly growing 'infodemic'\nof health information online. This has motivated the need for accurate semantic\nsearch and retrieval of reliable COVID-19 information across millions of\ndocuments, in multiple languages. To address this challenge, this paper\nproposes a novel high precision and high recall neural Multistage BiCross\nencoder approach. It is a sequential three-stage ranking pipeline which uses\nthe Okapi BM25 retrieval algorithm and transformer-based bi-encoder and\ncross-encoder to effectively rank the documents with respect to the given\nquery. We present experimental results from our participation in the\nMultilingual Information Access (MLIA) shared task on COVID-19 multilingual\nsemantic search. The independently evaluated MLIA results validate our approach\nand demonstrate that it outperforms other state-of-the-art approaches according\nto nearly all evaluation metrics in cases of both monolingual and bilingual\nruns.", "doi": "", "date": "2021-01-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.03013v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 192390092, "title": "A transformer based approach for fighting COVID-19 fake news", "abstract": "The rapid outbreak of COVID-19 has caused humanity to come to a stand-still\nand brought with it a plethora of other problems. COVID-19 is the first\npandemic in history when humanity is the most technologically advanced and\nrelies heavily on social media platforms for connectivity and other benefits.\nUnfortunately, fake news and misinformation regarding this virus is also\navailable to people and causing some massive problems. So, fighting this\ninfodemic has become a significant challenge. We present our solution for the\n\"Constraint@AAAI2021 - COVID19 Fake News Detection in English\" challenge in\nthis work. After extensive experimentation with numerous architectures and\ntechniques, we use eight different transformer-based pre-trained models with\nadditional layers to construct a stacking ensemble classifier and fine-tuned\nthem for our purpose. We achieved 0.979906542 accuracy, 0.979913119 precision,\n0.979906542 recall, and 0.979907901 f1-score on the test dataset of the\ncompetition.", "doi": "", "date": "2021-01-28", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2101.12027v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1894105563, "title": "The Burden of Being a Bridge: Understanding the Role of Multilingual\n  Users during the COVID-19 Pandemic", "abstract": "The outbreak of the COVID-19 pandemic triggers infodemic over online social\nnetworks. It is thus important for governments to ensure their official\nmessages outpace misinformation and efficiently reach the public. Some\ncountries and regions that are currently worst affected by the virus including\nEurope, South America and India, encounter an additional difficulty:\nmultilingualism. Understanding the specific role of multilingual users in the\nprocess of information diffusion is critical to adjust their publishing\nstrategies for the governments of such countries and regions. In this paper, we\ninvestigate the role of multilingual users in diffusing information during the\nCOVID-19 pandemic on popular social networks. We collect a large-scale dataset\nof Twitter from a populated multilingual region from the beginning of the\npandemic. With this dataset, we successfully show that multilingual users act\nas bridges in diffusing COVID-19 related information. We further study the\nmental health of multilingual users and show that being the bridges,\nmultilingual users tend to be more negative. This is confirmed by a recent\npsychological study stating that excessive exposure to social media may result\nin a negative mood.", "doi": "", "date": "2021-04-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.04331v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4123898066, "title": "AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News and Hate Speech\n  Detection Dataset", "abstract": "Along with the COVID-19 pandemic, an \"infodemic\" of false and misleading\ninformation has emerged and has complicated the COVID-19 response efforts.\nSocial networking sites such as Facebook and Twitter have contributed largely\nto the spread of rumors, conspiracy theories, hate, xenophobia, racism, and\nprejudice. To combat the spread of fake news, researchers around the world have\nand are still making considerable efforts to build and share COVID-19 related\nresearch articles, models, and datasets. This paper releases \"AraCOVID19-MFH\" a\nmanually annotated multi-label Arabic COVID-19 fake news and hate speech\ndetection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10\ndifferent labels. The labels have been designed to consider some aspects\nrelevant to the fact-checking task, such as the tweet's check worthiness,\npositivity/negativity, and factuality. To confirm our annotated dataset's\npractical utility, we used it to train and evaluate several classification\nmodels and reported the obtained results. Though the dataset is mainly designed\nfor fake news detection, it can also be used for hate speech detection,\nopinion/news classification, dialect identification, and many other tasks.", "doi": "", "date": "2021-05-07", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.03143v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3396239724, "title": "The State of Infodemic on Twitter", "abstract": "Following the wave of misinterpreted, manipulated and malicious information\ngrowing on the Internet, the misinformation surrounding COVID-19 has become a\nparamount issue. In the context of the current COVID-19 pandemic, social media\nposts and platforms are at risk of rumors and misinformation in the face of the\nserious uncertainty surrounding the virus itself. At the same time, the\nuncertainty and new nature of COVID-19 means that other unconfirmed information\nthat may appear \"rumored\" may be an important indicator of the behavior and\nimpact of this new virus. Twitter, in particular, has taken a center stage in\nthis storm where Covid-19 has been a much talked about subject. We have\npresented an exploratory analysis of the tweets and the users who are involved\nin spreading misinformation and then delved into machine learning models and\nnatural language processing techniques to identify if a tweet contains\nmisinformation.", "doi": "", "date": "2021-05-17", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.07730v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3431246549, "title": "Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study\n  of COVID-19 Infodemic", "abstract": "The spreading COVID-19 misinformation over social media already draws the\nattention of many researchers. According to Google Scholar, about 26000\nCOVID-19 related misinformation studies have been published to date. Most of\nthese studies focusing on 1) detect and/or 2) analysing the characteristics of\nCOVID-19 related misinformation. However, the study of the social behaviours\nrelated to misinformation is often neglected. In this paper, we introduce a\nfine-grained annotated misinformation tweets dataset including social\nbehaviours annotation (e.g. comment or question to the misinformation). The\ndataset not only allows social behaviours analysis but also suitable for both\nevidence-based or non-evidence-based misinformation classification task. In\naddition, we introduce leave claim out validation in our experiments and\ndemonstrate the misinformation classification performance could be\nsignificantly different when applying to real-world unseen misinformation.", "doi": "", "date": "2021-06-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.11702v4", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1170808741, "title": "Combating fake news by empowering fact-checked news spread via\n  topology-based interventions", "abstract": "Rapid information diffusion and large-scaled information cascades can enable\nthe undesired spread of false information. A small-scaled false information\noutbreak may potentially lead to an infodemic. We propose a novel information\ndiffusion and intervention technique to combat the spread of false news. As\nfalse information is often spreading faster in a social network, the proposed\ndiffusion methodology inhibits the spread of false news by proactively\ndiffusing the fact-checked information. Our methodology mainly relies on\ndefining the potential super-spreaders in a social network based on their\ncentrality metrics. We run an extensive set of experiments on different\nnetworks to investigate the impact of centrality metrics on the performance of\nthe proposed diffusion and intervention models. The obtained results\ndemonstrate that empowering the diffusion of fact-checked news combats the\nspread of false news further and deeper in social networks.", "doi": "", "date": "2021-07-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.05016v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2206823614, "title": "DEAP-FAKED: Knowledge Graph based Approach for Fake News Detection", "abstract": "Fake News on social media platforms has attracted a lot of attention in\nrecent times, primarily for events related to politics (2016 US Presidential\nelections), healthcare (infodemic during COVID-19), to name a few. Various\nmethods have been proposed for detecting Fake News. The approaches span from\nexploiting techniques related to network analysis, Natural Language Processing\n(NLP), and the usage of Graph Neural Networks (GNNs). In this work, we propose\nDEAP-FAKED, a knowleDgE grAPh FAKe nEws Detection framework for identifying\nFake News. Our approach is a combination of the NLP -- where we encode the news\ncontent, and the GNN technique -- where we encode the Knowledge Graph (KG). A\nvariety of these encodings provides a complementary advantage to our detector.\nWe evaluate our framework using two publicly available datasets containing\narticles from domains such as politics, business, technology, and healthcare.\nAs part of dataset pre-processing, we also remove the bias, such as the source\nof the articles, which could impact the performance of the models. DEAP-FAKED\nobtains an F1-score of 88% and 78% for the two datasets, which is an\nimprovement of 21%, and 3% respectively, which shows the effectiveness of the\napproach.", "doi": "", "date": "2021-07-04", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.10648v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1192150129, "title": "The False COVID-19 Narratives That Keep Being Debunked: A Spatiotemporal\n  Analysis", "abstract": "The onset of the Coronavirus disease 2019 (COVID-19) pandemic instigated a\nglobal infodemic that has brought unprecedented challenges for society as a\nwhole. During this time, a number of manual fact-checking initiatives have\nemerged to alleviate the spread of dis/mis-information. This study is about\nCOVID-19 debunks published in multiple languages by different fact-checking\norganisations, sometimes as far as several months apart, despite the fact that\nthe claim has already been fact-checked before. The spatiotemporal analysis\nreveals that similar or nearly duplicate false COVID-19 narratives have been\nspreading in multifarious modalities on various social media platforms in\ndifferent countries. We also find that misinformation involving general medical\nadvice has spread across multiple countries and hence has the highest\nproportion of false COVID-19 narratives that keep being debunked. Furthermore,\nas manual fact-checking is an onerous task in itself, therefore debunking\nsimilar claims recurrently is leading to a waste of resources. To this end, we\npropound the idea of the inclusion of multilingual debunk search in the\nfact-checking pipeline.", "doi": "", "date": "2021-07-26", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.12303v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3768800037, "title": "Mapping the Landscape of Artificial Intelligence Applications against\n  COVID-19", "abstract": "COVID-19, the disease caused by the SARS-CoV-2 virus, has been declared a\npandemic by the World Health Organization, which has reported over 18 million\nconfirmed cases as of August 5, 2020. In this review, we present an overview of\nrecent studies using Machine Learning and, more broadly, Artificial\nIntelligence, to tackle many aspects of the COVID-19 crisis. We have identified\napplications that address challenges posed by COVID-19 at different scales,\nincluding: molecular, by identifying new or existing drugs for treatment;\nclinical, by supporting diagnosis and evaluating prognosis based on medical\nimaging and non-invasive measures; and societal, by tracking both the epidemic\nand the accompanying infodemic using multiple data sources. We also review\ndatasets, tools, and resources needed to facilitate Artificial Intelligence\nresearch, and discuss strategic considerations related to the operational\nimplementation of multidisciplinary partnerships and open science. We highlight\nthe need for international cooperation to maximize the potential of AI in this\nand future pandemics.", "doi": "10.1613/jair.1.12162", "date": "2020-03-25", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.11336v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3868051064, "title": "An Exploratory Study of COVID-19 Misinformation on Twitter", "abstract": "During the COVID-19 pandemic, social media has become a home ground for\nmisinformation. To tackle this infodemic, scientific oversight, as well as a\nbetter understanding by practitioners in crisis management, is needed. We have\nconducted an exploratory study into the propagation, authors and content of\nmisinformation on Twitter around the topic of COVID-19 in order to gain early\ninsights. We have collected all tweets mentioned in the verdicts of\nfact-checked claims related to COVID-19 by over 92 professional fact-checking\norganisations between January and mid-July 2020 and share this corpus with the\ncommunity. This resulted in 1 500 tweets relating to 1 274 false and 276\npartially false claims, respectively. Exploratory analysis of author accounts\nrevealed that the verified twitter handle(including Organisation/celebrity) are\nalso involved in either creating (new tweets) or spreading (retweet) the\nmisinformation. Additionally, we found that false claims propagate faster than\npartially false claims. Compare to a background corpus of COVID-19 tweets,\ntweets with misinformation are more often concerned with discrediting other\ninformation on social media. Authors use less tentative language and appear to\nbe more driven by concerns of potential harm to others. Our results enable us\nto suggest gaps in the current scientific coverage of the topic as well as\npropose actions for authorities and social media users to counter\nmisinformation.", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.05710v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4182943922, "title": "Prta: A System to Support the Analysis of Propaganda Techniques in the\n  News", "abstract": "Recent events, such as the 2016 US Presidential Campaign, Brexit and the\nCOVID-19 \"infodemic\", have brought into the spotlight the dangers of online\ndisinformation. There has been a lot of research focusing on fact-checking and\ndisinformation detection. However, little attention has been paid to the\nspecific rhetorical and psychological techniques used to convey propaganda\nmessages. Revealing the use of such techniques can help promote media literacy\nand critical thinking, and eventually contribute to limiting the impact of\n\"fake news\" and disinformation campaigns. Prta (Propaganda Persuasion\nTechniques Analyzer) allows users to explore the articles crawled on a regular\nbasis by highlighting the spans in which propaganda techniques occur and to\ncompare them on the basis of their use of propaganda techniques. The system\nfurther reports statistics about the use of such techniques, overall and over\ntime, or according to filtering criteria specified by the user based on time\ninterval, keywords, and/or political orientation of the media. Moreover, it\nallows users to analyze any text or URL through a dedicated interface or via an\nAPI. The system is available online: https://www.tanbih.org/prta", "doi": "", "date": "2020-05-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2005.05854v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 54841931, "title": "ReCOVery: A Multimodal Repository for COVID-19 News Credibility Research", "abstract": "First identified in Wuhan, China, in December 2019, the outbreak of COVID-19\nhas been declared as a global emergency in January, and a pandemic in March\n2020 by the World Health Organization (WHO). Along with this pandemic, we are\nalso experiencing an \"infodemic\" of information with low credibility such as\nfake news and conspiracies. In this work, we present ReCOVery, a repository\ndesigned and constructed to facilitate research on combating such information\nregarding COVID-19. We first broadly search and investigate ~2,000 news\npublishers, from which 60 are identified with extreme [high or low] levels of\ncredibility. By inheriting the credibility of the media on which they were\npublished, a total of 2,029 news articles on coronavirus, published from\nJanuary to May 2020, are collected in the repository, along with 140,820 tweets\nthat reveal how these news articles have spread on the Twitter social network.\nThe repository provides multimodal information of news articles on coronavirus,\nincluding textual, visual, temporal, and network information. The way that news\ncredibility is obtained allows a trade-off between dataset scalability and\nlabel accuracy. Extensive experiments are conducted to present data statistics\nand distributions, as well as to provide baseline performances for predicting\nnews credibility so that future methods can be compared. Our repository is\navailable at http://coronavirus-fakenews.com.", "doi": "10.1145/3340531.3412880", "date": "2020-06-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2006.05557v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2518568753, "title": "A curated collection of COVID-19 online datasets", "abstract": "One of the defining moments of the year 2020 is the outbreak of Coronavirus\nDisease (Covid-19), a deadly virus affecting the body's respiratory system to\nthe point of needing a breathing aid via ventilators. As of June 21, 2020 there\nare 12,929,306 confirmed cases and 569,738 confirmed deaths across 216\ncountries, areas or territories. The scale of spread and impact of the pandemic\nleft many nations grappling with preventive and curative approaches. The\ninfamous lockdown measure introduced to mitigate the virus spread has altered\nmany aspects of our social routines in which demand for online-based services\nskyrocketed. As the virus propagate, so does misinformation and fake news\naround it via online social media, which seems to favour virality over\nveracity. With a majority of the populace confined to their homes for a long\nperiod, vulnerability to the toxic impact of online misinformation is high. A\ncase in point is the various myths and disinformation associated with the\nCovid-19, which, if left unchecked, could lead to a catastrophic outcome and\nhamper the fight against the virus.\n  While the scientific community is actively engaged in identifying the virus\ntreatment, there is a growing interest in combating the associated harmful\ninfodemic. To this end, researchers have been curating and documenting various\ndatasets about Covid-19. In line with existing studies, we provide an expansive\ncollection of curated datasets to support the fight against the pandemic,\nespecially concerning misinformation. The collection consists of 3 categories\nof Twitter data, information about standard practices from credible sources and\na chronicle of global situation reports. We describe how to retrieve the\nhydrated version of the data and proffer some research problems that could be\naddressed using the data.", "doi": "", "date": "2020-07-19", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2007.09703v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1603573823, "title": "\"Thought I'd Share First\" and Other Conspiracy Theory Tweets from the\n  COVID-19 Infodemic: Exploratory Study", "abstract": "Background: The COVID-19 outbreak has left many people isolated within their\nhomes; these people are turning to social media for news and social connection,\nwhich leaves them vulnerable to believing and sharing misinformation.\nHealth-related misinformation threatens adherence to public health messaging,\nand monitoring its spread on social media is critical to understanding the\nevolution of ideas that have potentially negative public health impacts.\nResults: Analysis using model-labeled data was beneficial for increasing the\nproportion of data matching misinformation indicators. Random forest classifier\nmetrics varied across the four conspiracy theories considered (F1 scores\nbetween 0.347 and 0.857); this performance increased as the given conspiracy\ntheory was more narrowly defined. We showed that misinformation tweets\ndemonstrate more negative sentiment when compared to nonmisinformation tweets\nand that theories evolve over time, incorporating details from unrelated\nconspiracy theories as well as real-world events. Conclusions: Although we\nfocus here on health-related misinformation, this combination of approaches is\nnot specific to public health and is valuable for characterizing misinformation\nin general, which is an important first step in creating targeted messaging to\ncounteract its spread. Initial messaging should aim to preempt generalized\nmisinformation before it becomes widespread, while later messaging will need to\ntarget evolving conspiracy theories and the new facets of each as they become\nincorporated.", "doi": "10.2196/26527", "date": "2020-12-14", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.07729v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2363495486, "title": "Fake news agenda in the era of COVID-19: Identifying trends through\n  fact-checking content", "abstract": "The rise of social media has ignited an unprecedented circulation of false\ninformation in our society. It is even more evident in times of crises, such as\nthe COVID-19 pandemic. Fact-checking efforts have expanded greatly and have\nbeen touted as among the most promising solutions to fake news, especially in\ntimes like these. Several studies have reported the development of\nfact-checking organizations in Western societies, albeit little attention has\nbeen given to the Global South. Here, to fill this gap, we introduce a novel\nMarkov-inspired computational method for identifying topics in tweets. In\ncontrast to other topic modeling approaches, our method clusters topics and\ntheir current evolution in a predefined time window. Through these, we\ncollected data from Twitter accounts of two Brazilian fact-checking outlets and\npresented the topics debunked by these initiatives in fortnights throughout the\npandemic. By comparing these organizations, we could identify similarities and\ndifferences in what was shared by them. Our method resulted in an important\ntechnique to cluster topics in a wide range of scenarios, including an\ninfodemic -- a period overabundance of the same information. In particular, the\ndata clearly revealed a complex intertwining between politics and the health\ncrisis during this period. We conclude by proposing a generic model which, in\nour opinion, is suitable for topic modeling and an agenda for future research.", "doi": "10.1016/j.osnem.2020.100116", "date": "2020-12-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2012.11004v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 50926981, "title": "Combat COVID-19 Infodemic Using Explainable Natural Language Processing\n  Models", "abstract": "Misinformation of COVID-19 is prevalent on social media as the pandemic\nunfolds, and the associated risks are extremely high. Thus, it is critical to\ndetect and combat such misinformation. Recently, deep learning models using\nnatural language processing techniques, such as BERT (Bidirectional Encoder\nRepresentations from Transformers), have achieved great successes in detecting\nmisinformation. In this paper, we proposed an explainable natural language\nprocessing model based on DistilBERT and SHAP (Shapley Additive exPlanations)\nto combat misinformation about COVID-19 due to their efficiency and\neffectiveness. First, we collected a dataset of 984 claims about COVID-19 with\nfact checking. By augmenting the data using back-translation, we doubled the\nsample size of the dataset and the DistilBERT model was able to obtain good\nperformance (accuracy: 0.972; areas under the curve: 0.993) in detecting\nmisinformation about COVID-19. Our model was also tested on a larger dataset\nfor AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good\nperformance (accuracy: 0.938; areas under the curve: 0.985). The performance on\nboth datasets was better than traditional machine learning models. Second, in\norder to boost public trust in model prediction, we employed SHAP to improve\nmodel explainability, which was further evaluated using a between-subjects\nexperiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),\nand text+SHAP explanation+source and evidence (TSESE). The participants were\nsignificantly more likely to trust and share information related to COVID-19 in\nthe TSE and TSESE conditions than in the T condition. Our results provided good\nimplications in detecting misinformation about COVID-19 and improving public\ntrust.", "doi": "", "date": "2021-03-01", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.00747v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2854428532, "title": "Detection of fake news on CoViD-19 on Web Search Engines", "abstract": "In early January 2020, after China reported the first cases of the new\ncoronavirus (SARS-CoV-2) in the city of Wuhan, unreliable and not fully\naccurate information has started spreading faster than the virus itself.\nAlongside this pandemic, people have experienced a parallel infodemic, i.e., an\noverabundance of information, some of which misleading or even harmful, that\nhas widely spread around the globe. Although Social Media are increasingly\nbeing used as information source, Web Search Engines, like Google or Yahoo!,\nstill represent a powerful and trustworthy resource for finding information on\nthe Web. This is due to their capability to capture the largest amount of\ninformation, helping users quickly identify the most relevant, useful, although\nnot always the most reliable, results for their search queries. This study aims\nto detect potential misleading and fake contents by capturing and analysing\ntextual information, which flow through Search Engines. By using a real-world\ndataset associated with recent CoViD-19 pandemic, we first apply re-sampling\ntechniques for class imbalance, then we use existing Machine Learning\nalgorithms for classification of not reliable news. By extracting lexical and\nhost-based features of associated Uniform Resource Locators (URLs) for news\narticles, we show that the proposed methods, so common in phishing and\nmalicious URLs detection, can improve the efficiency and performance of\nclassifiers. Based on these findings, we suggest that the use of both textual\nand URLs features can improve the effectiveness of fake news detection methods.", "doi": "", "date": "2021-03-22", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2103.11804v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2095562276, "title": "Multiscale Governance", "abstract": "Future societal systems will be characterized by heterogeneous human\nbehaviors and also collective action. The interaction between local systems and\nglobal systems will be complex. Humandemics will propagate because of the\npathways that connect the different systems and several invariant behaviors and\npatterns that have emerged globally. On the contrary, infodemics of\nmisinformation can be a risk as it has occurred in the COVID-19 pandemic. The\nemerging fragility or robustness of the system will depend on how this complex\nnetwork of systems is governed. Future societal systems will not be only\nmultiscale in terms of the social dimension, but also in the temporality.\nNecessary and proper prevention and response systems based on complexity, ethic\nand multi-scale governance will be required. Real-time response systems are the\nbasis for resilience to be the foundation of robust societies. A top-down\napproach led by Governmental organs for managing humandemics is not sufficient\nand may be only effective if policies are very restrictive and their efficacy\ndepends not only in the measures implemented but also on the dynamics of the\npolicies and the population perception and compliance. This top-down approach\nis even weaker if there is not national and international coordination.\nCoordinating top-down agencies with bottom-up constructs will be the design\nprinciple. Multi-scale governance integrates decision-making processes with\nsignaling, sensing and leadership mechanisms to drive thriving societal systems\nwith real-time sensitivity.", "doi": "", "date": "2021-04-06", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.02752v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3740168223, "title": "Digital Epidemiology: A review", "abstract": "The epidemiology has recently witnessed great advances based on computational\nmodels. Its scope and impact are getting wider thanks to the new data sources\nfeeding analytical frameworks and models. Besides traditional variables\nconsidered in epidemiology, large-scale social patterns can be now integrated\nin real time with multi-source data bridging the gap between different scales.\nIn a hyper-connected world, models and analysis of interactions and social\nbehaviors are key to understand and stop outbreaks. Big Data along with apps\nare enabling for validating and refining models with real world data at scale,\nas well as new applications and frameworks to map and track diseases in real\ntime or optimize the necessary resources and interventions such as testing and\nvaccination strategies. Digital epidemiology is positioning as a discipline\nnecessary to control epidemics and implement actionable protocols and policies.\nIn this review we address the research areas configuring current digital\nepidemiology: transmission and propagation models and descriptions based on\nhuman networks and contact tracing, mobility analysis and spatio-temporal\npropagation of infectious diseases and the emerging field of infodemics that\ncomprises the study of information and knowledge propagation related to\nepidemics. Digital epidemiology has the potential to create new operational\nmechanisms for prevention and mitigation, monitoring of the evolution of\nepidemics, assessing their impact and evaluating the pharmaceutical and\nnon-pharmaceutical measures to fight the outbreaks.", "doi": "", "date": "2021-04-08", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2104.03611v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3298579215, "title": "Case Study on Detecting COVID-19 Health-Related Misinformation in Social\n  Media", "abstract": "COVID-19 pandemic has generated what public health officials called an\ninfodemic of misinformation. As social distancing and stay-at-home orders came\ninto effect, many turned to social media for socializing. This increase in\nsocial media usage has made it a prime vehicle for the spreading of\nmisinformation. This paper presents a mechanism to detect COVID-19\nhealth-related misinformation in social media following an interdisciplinary\napproach. Leveraging social psychology as a foundation and existing\nmisinformation frameworks, we defined misinformation themes and associated\nkeywords incorporated into the misinformation detection mechanism using applied\nmachine learning techniques. Next, using the Twitter dataset, we explored the\nperformance of the proposed methodology using multiple state-of-the-art machine\nlearning classifiers. Our method shows promising results with at most 78%\naccuracy in classifying health-related misinformation versus true information\nusing uni-gram-based NLP feature generations from tweets and the Decision Tree\nclassifier. We also provide suggestions on alternatives for countering\nmisinformation and ethical consideration for the study.", "doi": "", "date": "2021-06-12", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2106.06811v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 897197866, "title": "Checkovid: A COVID-19 misinformation detection system on Twitter using\n  network and content mining perspectives", "abstract": "During the COVID-19 pandemic, social media platforms were ideal for\ncommunicating due to social isolation and quarantine. Also, it was the primary\nsource of misinformation dissemination on a large scale, referred to as the\ninfodemic. Therefore, automatic debunking misinformation is a crucial problem.\nTo tackle this problem, we present two COVID-19 related misinformation datasets\non Twitter and propose a misinformation detection system comprising\nnetwork-based and content-based processes based on machine learning algorithms\nand NLP techniques. In the network-based process, we focus on social\nproperties, network characteristics, and users. On the other hand, we classify\nmisinformation using the content of the tweets directly in the content-based\nprocess, which contains text classification models (paragraph-level and\nsentence-level) and similarity models. The evaluation results on the\nnetwork-based process show the best results for the artificial neural network\nmodel with an F1 score of 88.68%. In the content-based process, our novel\nsimilarity models, which obtained an F1 score of 90.26%, show an improvement in\nthe misinformation classification results compared to the network-based models.\nIn addition, in the text classification models, the best result was achieved\nusing the stacking ensemble-learning model by obtaining an F1 score of 95.18%.\nFurthermore, we test our content-based models on the Constraint@AAAI2021\ndataset, and by getting an F1 score of 94.38%, we improve the baseline results.\nFinally, we develop a fact-checking website called Checkovid that uses each\nprocess to detect misinformative and informative claims in the domain of\nCOVID-19 from different perspectives.", "doi": "", "date": "2021-07-20", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2107.09768v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2770072702, "title": "Misleading the Covid-19 vaccination discourse on Twitter: An exploratory\n  study of infodemic around the pandemic", "abstract": "In this work, we collect a moderate-sized representative corpus of tweets\n(200,000 approx.) pertaining Covid-19 vaccination spanning over a period of\nseven months (September 2020 - March 2021). Following a Transfer Learning\napproach, we utilize the pre-trained Transformer-based XLNet model to classify\ntweets as Misleading or Non-Misleading and validate against a random subset of\nresults manually. We build on this to study and contrast the characteristics of\ntweets in the corpus that are misleading in nature against non-misleading ones.\nThis exploratory analysis enables us to design features (such as sentiments,\nhashtags, nouns, pronouns, etc) that can, in turn, be exploited for classifying\ntweets as (Non-)Misleading using various ML models in an explainable manner.\nSpecifically, several ML models are employed for prediction, with up to 90%\naccuracy, and the importance of each feature is explained using SHAP\nExplainable AI (XAI) tool. While the thrust of this work is principally\nexploratory analysis in order to obtain insights on the online discourse on\nCovid-19 vaccination, we conclude the paper by outlining how these insights\nprovide the foundations for a more actionable approach to mitigate\nmisinformation. The curated dataset and code is made available (Github\nrepository) so that the research community at large can reproduce, compare\nagainst, or build upon this work.", "doi": "", "date": "2021-08-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.10735v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1044246581, "title": "A Machine Learning Application for Raising WASH Awareness in the Times\n  of COVID-19 Pandemic", "abstract": "Background: The COVID-19 pandemic has uncovered the potential of digital\nmisinformation in shaping the health of nations. The deluge of unverified\ninformation that spreads faster than the epidemic itself is an unprecedented\nphenomenon that has put millions of lives in danger. Mitigating this Infodemic\nrequires strong health messaging systems that are engaging, vernacular,\nscalable, effective and continuously learn the new patterns of misinformation.\n  Objective: We created WashKaro, a multi-pronged intervention for mitigating\nmisinformation through conversational AI, machine translation and natural\nlanguage processing. WashKaro provides the right information matched against\nWHO guidelines through AI, and delivers it in the right format in local\nlanguages.\n  Methods: We theorize (i) an NLP based AI engine that could continuously\nincorporate user feedback to improve relevance of information, (ii) bite sized\naudio in the local language to improve penetrance in a country with skewed\ngender literacy ratios, and (iii) conversational but interactive AI engagement\nwith users towards an increased health awareness in the community. Results: A\ntotal of 5026 people who downloaded the app during the study window, among\nthose 1545 were active users. Our study shows that 3.4 times more females\nengaged with the App in Hindi as compared to males, the relevance of\nAI-filtered news content doubled within 45 days of continuous machine learning,\nand the prudence of integrated AI chatbot Satya increased thus proving the\nusefulness of an mHealth platform to mitigate health misinformation.\n  Conclusion: We conclude that a multi-pronged machine learning application\ndelivering vernacular bite-sized audios and conversational AI is an effective\napproach to mitigate health misinformation.", "doi": "", "date": "2020-03-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2003.07074v3", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3100377796, "title": "Hate is the New Infodemic: A Topic-aware Modeling of Hate Speech\n  Diffusion on Twitter", "abstract": "Online hate speech, particularly over microblogging platforms like Twitter,\nhas emerged as arguably the most severe issue of the past decade. Several\ncountries have reported a steep rise in hate crimes infuriated by malicious\nhate campaigns. While the detection of hate speech is one of the emerging\nresearch areas, the generation and spread of topic-dependent hate in the\ninformation network remain under-explored. In this work, we focus on exploring\nuser behaviour, which triggers the genesis of hate speech on Twitter and how it\ndiffuses via retweets. We crawl a large-scale dataset of tweets, retweets, user\nactivity history, and follower networks, comprising over 161 million tweets\nfrom more than $41$ million unique users. We also collect over 600k\ncontemporary news articles published online. We characterize different signals\nof information that govern these dynamics. Our analyses differentiate the\ndiffusion dynamics in the presence of hate from usual information diffusion.\nThis motivates us to formulate the modelling problem in a topic-aware setting\nwith real-world knowledge. For predicting the initiation of hate speech for any\ngiven hashtag, we propose multiple feature-rich models, with the best\nperforming one achieving a macro F1 score of 0.65. Meanwhile, to predict the\nretweet dynamics on Twitter, we propose RETINA, a novel neural architecture\nthat incorporates exogenous influence using scaled dot-product attention.\nRETINA achieves a macro F1-score of 0.85, outperforming multiple\nstate-of-the-art models. Our analysis reveals the superlative power of RETINA\nto predict the retweet dynamics of hateful content compared to the existing\ndiffusion models.", "doi": "", "date": "2020-10-09", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2010.04377v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3749142344, "title": "The Role of the Crowd in Countering Misinformation: A Case Study of the\n  COVID-19 Infodemic", "abstract": "Fact checking by professionals is viewed as a vital defense in the fight\nagainst misinformation.While fact checking is important and its impact has been\nsignificant, fact checks could have limited visibility and may not reach the\nintended audience, such as those deeply embedded in polarized communities.\nConcerned citizens (i.e., the crowd), who are users of the platforms where\nmisinformation appears, can play a crucial role in disseminating fact-checking\ninformation and in countering the spread of misinformation. To explore if this\nis the case, we conduct a data-driven study of misinformation on the Twitter\nplatform, focusing on tweets related to the COVID-19 pandemic, analyzing the\nspread of misinformation, professional fact checks, and the crowd response to\npopular misleading claims about COVID-19. In this work, we curate a dataset of\nfalse claims and statements that seek to challenge or refute them. We train a\nclassifier to create a novel dataset of 155,468 COVID-19-related tweets,\ncontaining 33,237 false claims and 33,413 refuting arguments.Our findings show\nthat professional fact-checking tweets have limited volume and reach. In\ncontrast, we observe that the surge in misinformation tweets results in a quick\nresponse and a corresponding increase in tweets that refute such\nmisinformation. More importantly, we find contrasting differences in the way\nthe crowd refutes tweets, some tweets appear to be opinions, while others\ncontain concrete evidence, such as a link to a reputed source. Our work\nprovides insights into how misinformation is organically countered in social\nplatforms by some of their users and the role they play in amplifying\nprofessional fact checks.These insights could lead to development of tools and\nmechanisms that can empower concerned citizens in combating misinformation. The\ncode and data can be found in\nhttp://claws.cc.gatech.edu/covid_counter_misinformation.html.", "doi": "", "date": "2020-11-11", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2011.05773v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3145452608, "title": "Information disorders during the COVID-19 infodemic - The case of Italian Facebook.", "abstract": "", "doi": "10.1016/j.osnem.2021.100124", "date": "2021", "authors": [{"name": "Stefano Guarino", "id-internal": "14/2001", "id-external": ""}, {"name": "Francesco Pierri 0002", "id-internal": "80/8064-2", "id-external": ""}, {"name": "Marco Di Giovanni", "id-internal": "217/9924", "id-external": ""}, {"name": "Alessandro Celestini", "id-internal": "125/2357", "id-external": ""}], "url": {"full": "URL#76838", "pdf": ""}, "publisher-venue": "Online Soc. Networks Media", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4059987933, "title": "Critical Impact of Social Networks Infodemic on Defeating Coronavirus COVID-19 Pandemic - Twitter-Based Study and Research Directions.", "abstract": "", "doi": "10.1109/tnsm.2020.3031034", "date": "2020", "authors": [{"name": "Azzam Mourad", "id-internal": "34/4038", "id-external": ""}, {"name": "Ali Srour", "id-internal": "265/6198", "id-external": ""}, {"name": "Haidar M. Harmanani", "id-internal": "47/5155", "id-external": ""}, {"name": "Cathia Jenainatiy", "id-internal": "265/5552", "id-external": ""}, {"name": "Mohamad Arafeh", "id-internal": "255/3008", "id-external": ""}], "url": {"full": "URL#408420", "pdf": ""}, "publisher-venue": "IEEE Trans. Netw. Serv. Manag.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}][{"id": 3172116147, "title": "Patient Information, Consentsand Privacy Protection Scheme for an Information System Dedicated to Pervasive Developmental Disorders.", "abstract": "", "doi": "10.3233/978-1-61499-432-9-755", "date": "2014", "authors": [{"name": "Mohamed Ben Sa\u00efd", "id-internal": "13/2432", "id-external": ""}, {"name": "Laurence Robel", "id-internal": "131/5839", "id-external": ""}, {"name": "Claude Messiaen", "id-internal": "64/7356", "id-external": ""}, {"name": "Yann Craus", "id-internal": "152/2954", "id-external": ""}, {"name": "Jean Philippe Ja\u00efs", "id-internal": "72/3467", "id-external": ""}, {"name": "Bernard Golse", "id-internal": "131/5826", "id-external": ""}, {"name": "Paul Landais", "id-internal": "64/4420", "id-external": ""}], "url": {"full": "URL#2582004", "pdf": ""}, "publisher-venue": "MIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 415563963, "title": "Acoustic and prosodic information for home monitoring of bipolar disorder.", "abstract": "", "doi": "10.1177/1460458220972755", "date": "2021", "authors": [{"name": "Mireia Farr\u00fas", "id-internal": "70/1200", "id-external": ""}, {"name": "Joan Codina-Filb\u00e0", "id-internal": "55/1951", "id-external": ""}, {"name": "Joan Escudero", "id-internal": "283/7055", "id-external": ""}], "url": {"full": "URL#40221", "pdf": ""}, "publisher-venue": "Health Informatics J.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2908163901, "title": "Multimodal Detection of Information Disorder from Social Media.", "abstract": "", "doi": "10.1109/cbmi50038.2021.9461898", "date": "2021", "authors": [{"name": "Matthias Zeppelzauer", "id-internal": "81/4405", "id-external": ""}, {"name": "Djordje Slijepcevic", "id-internal": "203/9182", "id-external": ""}, {"name": "Armin Kirchknopf", "id-internal": "226/2112", "id-external": ""}], "url": {"full": "URL#133596", "pdf": ""}, "publisher-venue": "CBMI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3671557007, "title": "Analogical discovery of disordered perovskite oxides by crystal structure information hidden in unsupervised material fingerprints.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Achintha Ihalage", "id-internal": "211/4390", "id-external": ""}, {"name": "Yang Hao", "id-internal": "54/4089", "id-external": ""}], "url": {"full": "URL#219846", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3326609746, "title": "Multimodal Detection of Information Disorder from Social Media.", "abstract": "", "doi": "", "date": "2021", "authors": [{"name": "Armin Kirchknopf", "id-internal": "226/2112", "id-external": ""}, {"name": "Djordje Slijepcevic", "id-internal": "203/9182", "id-external": ""}, {"name": "Matthias Zeppelzauer", "id-internal": "81/4405", "id-external": ""}], "url": {"full": "URL#221295", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1584474697, "title": "Information Disorders, Moral Values and the Dispute of Narratives.", "abstract": "", "doi": "", "date": "2021", "authors": {"name": "Daniel Schwabe", "id-internal": "s/DanielSchwabe", "id-external": ""}, "url": {"full": "URL#239982", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 42634942, "title": "Digital phenotyping of autism spectrum disorders based on color information - brief review and opinion.", "abstract": "", "doi": "10.1007/s10015-020-00614-6", "date": "2020", "authors": {"name": "Hirokazu Doi", "id-internal": "189/2053", "id-external": ""}, "url": {"full": "URL#265643", "pdf": ""}, "publisher-venue": "Artif. Life Robotics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3657793877, "title": "The impact of data entry structures on perceptions of individuals with chronic mental disorders and physical diseases towards health information sharing.", "abstract": "", "doi": "10.1016/j.ijmedinf.2020.104157", "date": "2020", "authors": [{"name": "Pouyan Esmaeilzadeh", "id-internal": "95/10199", "id-external": ""}, {"name": "Tala Mirzaei", "id-internal": "228/4506", "id-external": ""}, {"name": "Spurthy Dharanikota", "id-internal": "265/4092", "id-external": ""}], "url": {"full": "URL#316530", "pdf": ""}, "publisher-venue": "Int. J. Medical Informatics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3343446512, "title": "A Hybrid Model for Bipolar Disorder Classification from Visual Information.", "abstract": "", "doi": "10.1109/icassp40776.2020.9054648", "date": "2020", "authors": [{"name": "Niloufar Abaei", "id-internal": "270/4769", "id-external": ""}, {"name": "Hussein Al Osman", "id-internal": "69/3639", "id-external": ""}], "url": {"full": "URL#484382", "pdf": ""}, "publisher-venue": "ICASSP", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1409588054, "title": "Classification of Autism Spectrum Disorder Across Age Using Questionnaire and Demographic Information.", "abstract": "", "doi": "10.1007/978-3-030-68790-8_5", "date": "2020", "authors": [{"name": "Sk Rahatul Jannat", "id-internal": "229/1983", "id-external": ""}, {"name": "Shaun J. Canavan", "id-internal": "92/8116", "id-external": ""}], "url": {"full": "URL#503674", "pdf": ""}, "publisher-venue": "ICPR Workshops", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3728082028, "title": "A Two-step Approach in Expert Evaluation of Correctional Information Technologies for Students with Autism Spectrum Disorders.", "abstract": "", "doi": "", "date": "2020", "authors": [{"name": "Tetiana Shestakevych", "id-internal": "227/9896", "id-external": ""}, {"name": "Vasyl Andrunyk", "id-internal": "227/9851", "id-external": ""}], "url": {"full": "URL#510346", "pdf": ""}, "publisher-venue": "IDDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 117149566, "title": "Impaired Capacity to Process Cross-modal Emotional Information between Facial and Auditory Channels in Major Depression Disorders.", "abstract": "", "doi": "10.1145/3451421.3451451", "date": "2020", "authors": [{"name": "Liyuan Li", "id-internal": "14/333", "id-external": ""}, {"name": "Rong Li", "id-internal": "00/3887", "id-external": ""}, {"name": "Fei Shen", "id-internal": "99/6100", "id-external": ""}], "url": {"full": "URL#525721", "pdf": ""}, "publisher-venue": "ISICDM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2567563794, "title": "Assisting Students with Attention Deficit Disorder Through Technology.", "abstract": "", "doi": "10.1007/978-3-319-60013-0_149-1", "date": "2020", "authors": {"name": "Eleni Didaskalou", "id-internal": "294/7766", "id-external": ""}, "url": {"full": "URL#578326", "pdf": ""}, "publisher-venue": "Encyclopedia of Education and Information Technologies", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3843115333, "title": "Assisting people with Autism Spectrum Disorder Through technology.", "abstract": "", "doi": "10.1007/978-3-319-60013-0_146-1", "date": "2020", "authors": {"name": "Nigel Newbutt", "id-internal": "230/7162", "id-external": ""}, "url": {"full": "URL#578399", "pdf": ""}, "publisher-venue": "Encyclopedia of Education and Information Technologies", "type": "Parts in Books or Collections", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3902650486, "title": "A Suggestion of Converting Protein Intrinsic Disorder to Structural Entropy Using Shannon's Information Theory.", "abstract": "", "doi": "10.3390/e21060591", "date": "2019", "authors": [{"name": "Hao-Bo Guo", "id-internal": "186/6451", "id-external": ""}, {"name": "Yue Ma", "id-internal": "08/6794", "id-external": ""}, {"name": "Gerald A. Tuskan", "id-internal": "70/9331", "id-external": ""}, {"name": "Hong Qin", "id-internal": "79/627", "id-external": ""}, {"name": "Xiaohan Yang", "id-internal": "26/8253", "id-external": ""}, {"name": "Hong Guo", "id-internal": "90/6433", "id-external": ""}], "url": {"full": "URL#707095", "pdf": ""}, "publisher-venue": "Entropy", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3025228780, "title": "Entropy and Information within Intrinsically Disordered Protein Regions.", "abstract": "", "doi": "10.3390/e21070662", "date": "2019", "authors": [{"name": "Iva Pritisanac", "id-internal": "246/4398", "id-external": ""}, {"name": "Robert M. Vernon", "id-internal": "246/4557", "id-external": ""}, {"name": "Alan M. Moses", "id-internal": "46/6947", "id-external": ""}, {"name": "Julie D. Forman-Kay", "id-internal": "125/7237", "id-external": ""}], "url": {"full": "URL#707560", "pdf": ""}, "publisher-venue": "Entropy", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1421099068, "title": "Integrating Image and Textual Information in Human-Robot Interactions for Children With Autism Spectrum Disorder.", "abstract": "", "doi": "10.1109/tmm.2018.2865828", "date": "2019", "authors": [{"name": "Xue Yang 0006", "id-internal": "13/1779-6", "id-external": ""}, {"name": "Mei-Ling Shyu", "id-internal": "93/6593", "id-external": ""}, {"name": "Han-Qi Yu", "id-internal": "236/5109", "id-external": ""}, {"name": "Shi-Ming Sun", "id-internal": "236/4778", "id-external": ""}, {"name": "Nian-Sheng Yin", "id-internal": "236/5219", "id-external": ""}, {"name": "Wei Chen", "id-internal": "181/2832", "id-external": ""}], "url": {"full": "URL#808297", "pdf": ""}, "publisher-venue": "IEEE Trans. Multim.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2834707949, "title": "Information Disorder in the GLAM Sector - the Challenges of Crowd Sourced Contributions.", "abstract": "", "doi": "", "date": "2019", "authors": [{"name": "Saima Qutab", "id-internal": "198/4983", "id-external": ""}, {"name": "Michael David Myers", "id-internal": "m/MDMyers", "id-external": ""}, {"name": "Lesley A. Gardner", "id-internal": "125/1151", "id-external": ""}], "url": {"full": "URL#863837", "pdf": ""}, "publisher-venue": "ECIS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3884280703, "title": "An eHealth information technology platform to help the treatment of mental disorders.", "abstract": "", "doi": "10.1177/1460458216669555", "date": "2018", "authors": [{"name": "Alexis Quesada-Arencibia", "id-internal": "84/28", "id-external": ""}, {"name": "Enrique P\u00e9rez-Brito", "id-internal": "184/9892", "id-external": ""}, {"name": "Carmelo R. Garc\u00eda-Rodr\u00edguez", "id-internal": "25/4921", "id-external": ""}, {"name": "Ana P\u00e9rez-Brito", "id-internal": "184/9927", "id-external": ""}], "url": {"full": "URL#1107665", "pdf": ""}, "publisher-venue": "Health Informatics J.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1011599173, "title": "Visual attention toward Socially Rich context information for Autism Spectrum Disorder (ASD) and Normal Developing Children - An Eye Tracking Study.", "abstract": "", "doi": "10.1145/3282353.3282856", "date": "2018", "authors": [{"name": "Emad Bataineh", "id-internal": "43/1082", "id-external": ""}, {"name": "Mohamed Basel Almourad", "id-internal": "80/56", "id-external": ""}, {"name": "Farhi Marir", "id-internal": "95/1864", "id-external": ""}, {"name": "Joana Stocker", "id-internal": "233/1964", "id-external": ""}], "url": {"full": "URL#1333267", "pdf": ""}, "publisher-venue": "MoMM", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3942669297, "title": "Increased decision thresholds enhance information gathering performance in juvenile Obsessive-Compulsive Disorder (OCD).", "abstract": "", "doi": "10.1371/journal.pcbi.1005440", "date": "2017", "authors": [{"name": "Tobias U. Hauser", "id-internal": "138/7995", "id-external": ""}, {"name": "Michael Moutoussis", "id-internal": "26/9817", "id-external": ""}, {"name": "Reto Iannaccone", "id-internal": "138/7618", "id-external": ""}, {"name": "Silvia Brem", "id-internal": "95/8271", "id-external": ""}, {"name": "Susanne Walitza", "id-internal": "138/7989", "id-external": ""}, {"name": "Renate Drechsler", "id-internal": "138/7778", "id-external": ""}, {"name": "Peter Dayan", "id-internal": "22/522", "id-external": ""}, {"name": "Raymond J. Dolan", "id-internal": "87/1572", "id-external": ""}], "url": {"full": "URL#1516006", "pdf": ""}, "publisher-venue": "PLoS Comput. Biol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 888319924, "title": "Protein Disorder Prediction using Information Theory Measures on the Distribution of the Dihedral Torsion Angles from Ramachandran Plots.", "abstract": "", "doi": "10.5220/0006140500430051", "date": "2017", "authors": [{"name": "Jonny A. Uribe", "id-internal": "200/0622", "id-external": ""}, {"name": "Juli\u00e1n D. Arias-Londo\u00f1o", "id-internal": "99/8461", "id-external": ""}, {"name": "Alexandre Perera-Lluna", "id-internal": "53/1787", "id-external": ""}], "url": {"full": "URL#1571709", "pdf": ""}, "publisher-venue": "BIOINFORMATICS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3559437340, "title": "Strengthening Data Confidentiality and Integrity Protection in the Context of a Multi-Centric Information System Dedicated to Autism Spectrum Disorder.", "abstract": "", "doi": "10.3233/978-1-61499-830-3-1133", "date": "2017", "authors": [{"name": "Mohamed Ben Sa\u00efd", "id-internal": "13/2432", "id-external": ""}, {"name": "Laurence Robel", "id-internal": "131/5839", "id-external": ""}, {"name": "Bernard Golse", "id-internal": "131/5826", "id-external": ""}, {"name": "Jean Philippe Ja\u00efs", "id-internal": "72/3467", "id-external": ""}], "url": {"full": "URL#1672767", "pdf": ""}, "publisher-venue": "MedInfo", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 211028988, "title": "Information and Communication Technologies (ICTs) and Autistic Spectrum Disorders (ASD).", "abstract": "", "doi": "", "date": "2016", "authors": [{"name": "Athanasios Drigas", "id-internal": "27/1603", "id-external": ""}, {"name": "Jenny A. Vlachou", "id-internal": "178/7890", "id-external": ""}], "url": {"full": "URL#1794203", "pdf": ""}, "publisher-venue": "Int. J. Recent Contributions Eng. Sci. IT", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2473353657, "title": "Your substance abuse disorder is an open secret! Gleaning sensitive personal information from templates in an EEG-based authentication system.", "abstract": "", "doi": "10.1109/btas.2016.7791210", "date": "2016", "authors": [{"name": "Richard Matovu", "id-internal": "192/4843", "id-external": ""}, {"name": "Abdul Serwadda", "id-internal": "42/8733", "id-external": ""}], "url": {"full": "URL#1894202", "pdf": ""}, "publisher-venue": "BTAS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 358694071, "title": "Improving Single-Modal Neuroimaging Based Diagnosis of Brain Disorders via Boosted Privileged Information Learning Framework.", "abstract": "", "doi": "10.1007/978-3-319-47157-0_12", "date": "2016", "authors": [{"name": "Xiao Zheng", "id-internal": "94/2820", "id-external": ""}, {"name": "Jun Shi 0004", "id-internal": "31/626-4", "id-external": ""}, {"name": "Shihui Ying", "id-internal": "52/2125", "id-external": ""}, {"name": "Qi Zhang 0003", "id-internal": "52/323-3", "id-external": ""}, {"name": "Yan Li 0066", "id-internal": "87/660-66", "id-external": ""}], "url": {"full": "URL#1988792", "pdf": ""}, "publisher-venue": "MLMI@MICCAI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3368768860, "title": "Randomness and disorder of chaotic iterations. Applications in information security field.", "abstract": "", "doi": "", "date": "2016", "authors": [{"name": "Xiaole Fang", "id-internal": "36/10672", "id-external": ""}, {"name": "Christophe Guyeux", "id-internal": "98/722", "id-external": ""}, {"name": "Qianxue Wang", "id-internal": "85/8035", "id-external": ""}, {"name": "Jacques M. Bahi", "id-internal": "58/5562", "id-external": ""}], "url": {"full": "URL#2044870", "pdf": ""}, "publisher-venue": "CoRR", "type": "Informal Publications", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1654578616, "title": "Visual search and task-irrelevant shape information in autism spectrum disorder.", "abstract": "", "doi": "", "date": "2015", "authors": {"name": "Mara Tribull", "id-internal": "264/9181", "id-external": ""}, "url": {"full": "URL#2066835", "pdf": ""}, "publisher-venue": "", "type": "Books and Theses", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1625898833, "title": "A survey of automated information retrieval for genetic disorder from GeneReviews.", "abstract": "", "doi": "", "date": "2015", "authors": [{"name": "Pu Li", "id-internal": "276/0154", "id-external": ""}, {"name": "Qian Zhu", "id-internal": "02/562", "id-external": ""}], "url": {"full": "URL#2187071", "pdf": ""}, "publisher-venue": "AMIA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1476562458, "title": "\"A family like ours\" - Demographic variations in information seeking behavior and community participation among parents of individuals with autism spectrum disorder (ASD).", "abstract": "", "doi": "10.1002/pra2.2015.145052010060", "date": "2015", "authors": [{"name": "Amelia N. Gibson", "id-internal": "55/5517", "id-external": ""}, {"name": "Samantha J. Kaplan", "id-internal": "224/2772", "id-external": ""}], "url": {"full": "URL#2189960", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1336981991, "title": "Information Extraction from Clinical Documents - Towards Disease/Disorder Template Filling.", "abstract": "", "doi": "10.1007/978-3-319-24027-5_41", "date": "2015", "authors": [{"name": "Veera Raghavendra Chikka", "id-internal": "150/5241", "id-external": ""}, {"name": "Nestor Mariyasagayam", "id-internal": "147/9717", "id-external": ""}, {"name": "Yoshiki Niwa", "id-internal": "51/925", "id-external": ""}, {"name": "Kamalakar Karlapalem", "id-internal": "k/KKarlapalem", "id-external": ""}], "url": {"full": "URL#2204495", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3629839455, "title": "More Eating Disorder Patients Than Others Double Check Information Given By Their Doctors.", "abstract": "", "doi": "10.3233/978-1-61499-512-8-981", "date": "2015", "authors": [{"name": "Rolf Wynn", "id-internal": "127/5260", "id-external": ""}, {"name": "Gunn Pettersen", "id-internal": "152/2998", "id-external": ""}, {"name": "Jan Rosenvinge", "id-internal": "152/2716", "id-external": ""}, {"name": "Svein Bergvik", "id-internal": "152/2846", "id-external": ""}, {"name": "Oddgeir Friborg", "id-internal": "152/2843", "id-external": ""}], "url": {"full": "URL#2293036", "pdf": ""}, "publisher-venue": "MIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3262207988, "title": "A Smart Hospital Information System for Mental Disorders.", "abstract": "", "doi": "10.1109/wi-iat.2015.25", "date": "2015", "authors": [{"name": "Youjun Li", "id-internal": "175/5471", "id-external": ""}, {"name": "Zhijiang Wan", "id-internal": "137/8317", "id-external": ""}, {"name": "Jiajin Huang", "id-internal": "79/729", "id-external": ""}, {"name": "Jianhui Chen", "id-internal": "86/6709", "id-external": ""}, {"name": "Zhisheng Huang", "id-internal": "h/ZhishengHuang", "id-external": ""}, {"name": "Ning Zhong 0001", "id-internal": "z/NingZhong", "id-external": ""}], "url": {"full": "URL#2330213", "pdf": ""}, "publisher-venue": "WI-IAT", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2974275485, "title": "Reduced predictable information in brain signals in autism spectrum disorder.", "abstract": "", "doi": "10.3389/fninf.2014.00009", "date": "2014", "authors": [{"name": "Carlos G\u00f3mez", "id-internal": "26/3688", "id-external": ""}, {"name": "Joseph Troy Lizier", "id-internal": "00/6722", "id-external": ""}, {"name": "Michael Schaum", "id-internal": "155/6530", "id-external": ""}, {"name": "Patricia Wollstadt", "id-internal": "140/7247", "id-external": ""}, {"name": "Christine Gr\u00fctzner", "id-internal": "155/6597", "id-external": ""}, {"name": "Peter Uhlhaas", "id-internal": "98/10745", "id-external": ""}, {"name": "Christine M. Freitag", "id-internal": "155/6793", "id-external": ""}, {"name": "Sabine Schlitt", "id-internal": "155/6956", "id-external": ""}, {"name": "Sven B\u00f6lte", "id-internal": "155/7033", "id-external": ""}, {"name": "Roberto Hornero", "id-internal": "12/273", "id-external": ""}, {"name": "Michael Wibral", "id-internal": "54/9393", "id-external": ""}], "url": {"full": "URL#2393640", "pdf": ""}, "publisher-venue": "Frontiers Neuroinformatics", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 747306741, "title": "Is this OCD? - Exploring conditions of information poverty in online support groups dealing with obsessive compulsive disorder.", "abstract": "", "doi": "", "date": "2014", "authors": {"name": "Jenny Bronstein", "id-internal": "87/1978", "id-external": ""}, "url": {"full": "URL#2411602", "pdf": ""}, "publisher-venue": "Inf. Res.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 993218978, "title": "Defining Patients with Depressive Disorder by Using Textual Information.", "abstract": "", "doi": "", "date": "2014", "authors": [{"name": "Tetsuaki Nakamura", "id-internal": "131/8441", "id-external": ""}, {"name": "Kay Kubo", "id-internal": "162/7963", "id-external": ""}, {"name": "Yasuyuki Usuda", "id-internal": "168/7481", "id-external": ""}, {"name": "Eiji Aramaki", "id-internal": "02/2649", "id-external": ""}], "url": {"full": "URL#2473067", "pdf": ""}, "publisher-venue": "AAAI Spring Symposia", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3114299808, "title": "Disease/Disorder Semantic Template Filling - Information Extraction Challenge in the ShARe/CLEF eHealth Evaluation Lab 2014.", "abstract": "", "doi": "", "date": "2014", "authors": [{"name": "Sumithra Velupillai", "id-internal": "82/8032", "id-external": ""}, {"name": "Danielle L. Mowery", "id-internal": "17/10841", "id-external": ""}, {"name": "Lee M. Christensen", "id-internal": "53/1214", "id-external": ""}, {"name": "Noemie Elhadad", "id-internal": "92/6201", "id-external": ""}, {"name": "Sameer Pradhan", "id-internal": "p/SameerPradhan", "id-external": ""}, {"name": "Guergana K. Savova", "id-internal": "73/5451", "id-external": ""}, {"name": "Wendy W. Chapman", "id-internal": "70/2019", "id-external": ""}], "url": {"full": "URL#2479161", "pdf": ""}, "publisher-venue": "AMIA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 827380066, "title": "\"I know what you are going through\" - Answers to informational questions about eating disorders in Yahoo! answers - A qualitative study.", "abstract": "", "doi": "10.1002/meet.14505001057", "date": "2013", "authors": [{"name": "Leanne Bowler", "id-internal": "53/3406", "id-external": ""}, {"name": "Eleanor Mattern", "id-internal": "65/10873", "id-external": ""}, {"name": "Wei Jeng", "id-internal": "97/9167", "id-external": ""}, {"name": "Jung Sun Oh", "id-internal": "83/5590", "id-external": ""}, {"name": "Daqing He", "id-internal": "41/134", "id-external": ""}], "url": {"full": "URL#2763576", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 534167447, "title": "Evaluation of Vector Space Models for Medical Disorders Information Retrieval.", "abstract": "", "doi": "", "date": "2013", "authors": [{"name": "Yaoyun Zhang", "id-internal": "77/8206", "id-external": ""}, {"name": "Trevor Cohen", "id-internal": "10/4030", "id-external": ""}, {"name": "Min Jiang 0007", "id-internal": "35/994-7", "id-external": ""}, {"name": "Buzhou Tang", "id-internal": "00/7437", "id-external": ""}, {"name": "Hua Xu 0001", "id-internal": "31/4114-1", "id-external": ""}], "url": {"full": "URL#2777821", "pdf": ""}, "publisher-venue": "CLEF", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 718790436, "title": "Suprasegmental information modelling for autism disorder spectrum and specific language impairment classification.", "abstract": "", "doi": "", "date": "2013", "authors": [{"name": "David Mart\u00ednez Gonz\u00e1lez", "id-internal": "120/7133", "id-external": ""}, {"name": "Dayana Ribas", "id-internal": "117/3311", "id-external": ""}, {"name": "Eduardo Lleida", "id-internal": "14/4997", "id-external": ""}, {"name": "Alfonso Ortega 0001", "id-internal": "121/1854-1", "id-external": ""}, {"name": "Antonio Miguel", "id-internal": "94/8307", "id-external": ""}], "url": {"full": "URL#2844302", "pdf": ""}, "publisher-venue": "INTERSPEECH", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 859606812, "title": "Do distinct atypical cortical networks process biological motion information in adults with Autism Spectrum Disorders?", "abstract": "", "doi": "10.1016/j.neuroimage.2011.08.033", "date": "2012", "authors": [{"name": "Lawrie S. McKay", "id-internal": "67/10746", "id-external": ""}, {"name": "David R. Simmons", "id-internal": "63/5839", "id-external": ""}, {"name": "Phil McAleer", "id-internal": "03/10744", "id-external": ""}, {"name": "Dominic Marjoram", "id-internal": "86/10743", "id-external": ""}, {"name": "Judith Piggot", "id-internal": "71/8326", "id-external": ""}, {"name": "Frank E. Pollick", "id-internal": "52/930", "id-external": ""}], "url": {"full": "URL#2993657", "pdf": ""}, "publisher-venue": "NeuroImage", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2999321723, "title": "Analysis of government environmental agency web pages for Colony Collapse Disorder information.", "abstract": "", "doi": "10.1002/meet.14504901130", "date": "2012", "authors": [{"name": "Meredith K. Boehm", "id-internal": "224/7237", "id-external": ""}, {"name": "Vandana Singh", "id-internal": "38/3293", "id-external": ""}], "url": {"full": "URL#3033727", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2899614096, "title": "Eating disorder questions in Yahoo! Answers - Information, conversation, or reflection?", "abstract": "", "doi": "10.1002/meet.14504901052", "date": "2012", "authors": [{"name": "Leanne Bowler", "id-internal": "53/3406", "id-external": ""}, {"name": "Jung Sun Oh", "id-internal": "83/5590", "id-external": ""}, {"name": "Daqing He", "id-internal": "41/134", "id-external": ""}, {"name": "Eleanor Mattern", "id-internal": "65/10873", "id-external": ""}, {"name": "Wei Jeng", "id-internal": "97/9167", "id-external": ""}], "url": {"full": "URL#3033728", "pdf": ""}, "publisher-venue": "ASIST", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 4226229956, "title": "TEDIS, Pervasive Developmental Disorder' patients Information System, Preliminary results.", "abstract": "", "doi": "10.3233/978-1-61499-101-4-285", "date": "2012", "authors": [{"name": "Mohamed Ben Sa\u00efd", "id-internal": "13/2432", "id-external": ""}, {"name": "Laurence Robel", "id-internal": "131/5839", "id-external": ""}, {"name": "Marie Pellegrin-Touati", "id-internal": "131/5852", "id-external": ""}, {"name": "Berangere Rousselot-Pailly", "id-internal": "131/5769", "id-external": ""}, {"name": "Bernard Golse", "id-internal": "131/5826", "id-external": ""}, {"name": "Jean Philippe Ja\u00efs", "id-internal": "72/3467", "id-external": ""}, {"name": "Paul Landais", "id-internal": "64/4420", "id-external": ""}], "url": {"full": "URL#3126891", "pdf": ""}, "publisher-venue": "MIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 579328459, "title": "The Role of Information and Computer Technology for Children with Autism Spectrum Disorder and the Facial Expression Wonderland (FEW).", "abstract": "", "doi": "10.4018/jcmam.2011040102", "date": "2011", "authors": [{"name": "Rung-Yu Tseng", "id-internal": "50/9204", "id-external": ""}, {"name": "Ellen Yi-Luen Do", "id-internal": "d/EllenYiLuenDo", "id-external": ""}], "url": {"full": "URL#3221316", "pdf": ""}, "publisher-venue": "Int. J. Comput. Model. Algorithms Medicine", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3007097657, "title": "Implementation and Experimentation of TEDIS - An Information System Dedicated to Patients with Pervasive Developmental Disorders.", "abstract": "", "doi": "10.3233/978-1-60750-806-9-270", "date": "2011", "authors": [{"name": "Mohamed Ben Sa\u00efd", "id-internal": "13/2432", "id-external": ""}, {"name": "Laurence Robel", "id-internal": "131/5839", "id-external": ""}, {"name": "Erwan Vion", "id-internal": "131/6116", "id-external": ""}, {"name": "Antoine El Ghazali", "id-internal": "131/6163", "id-external": ""}, {"name": "Bernard Golse", "id-internal": "131/5826", "id-external": ""}, {"name": "Jean Philippe Ja\u00efs", "id-internal": "72/3467", "id-external": ""}, {"name": "Paul Landais", "id-internal": "64/4420", "id-external": ""}], "url": {"full": "URL#3377717", "pdf": ""}, "publisher-venue": "MIE", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3629076931, "title": "Improved sequence-based prediction of disordered regions with multilayer fusion of multiple information sources.", "abstract": "", "doi": "10.1093/bioinformatics/btq373", "date": "2010", "authors": [{"name": "Marcin J. Mizianty", "id-internal": "75/7573", "id-external": ""}, {"name": "Wojciech Stach", "id-internal": "03/345", "id-external": ""}, {"name": "Ke Chen 0003", "id-internal": "47/6529-3", "id-external": ""}, {"name": "Kanaka Durga Kedarisetti", "id-internal": "97/2916", "id-external": ""}, {"name": "Fatemeh Miri Disfani", "id-internal": "33/452", "id-external": ""}, {"name": "Lukasz A. Kurgan", "id-internal": "37/1871", "id-external": ""}], "url": {"full": "URL#3440535", "pdf": ""}, "publisher-venue": "Bioinform.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2191288460, "title": "Bayesian statistical modelling of human protein interaction network incorporating protein disorder information.", "abstract": "", "doi": "10.1186/1471-2105-11-46", "date": "2010", "authors": [{"name": "Svetlana Bulashevska", "id-internal": "58/6222", "id-external": ""}, {"name": "Alla Bulashevska", "id-internal": "80/7519", "id-external": ""}, {"name": "Roland Eils", "id-internal": "63/1724", "id-external": ""}], "url": {"full": "URL#3441283", "pdf": ""}, "publisher-venue": "BMC Bioinform.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1864570210, "title": "Advanced Information Technology - Support of Improved Personalized Therapy of Speech Disorders.", "abstract": "", "doi": "10.15837/ijccc.2010.5.2224", "date": "2010", "authors": [{"name": "Mirela Danubianu", "id-internal": "35/7661", "id-external": ""}, {"name": "Stefan Gheorghe Pentiuc", "id-internal": "11/3781", "id-external": ""}, {"name": "Ovidiu Andrei Schipor", "id-internal": "97/8848", "id-external": ""}, {"name": "Iolanda Tobolcea", "id-internal": "14/7660", "id-external": ""}], "url": {"full": "URL#3465342", "pdf": ""}, "publisher-venue": "Int. J. Comput. Commun. Control", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1260393467, "title": "POODLE-I - Disordered Region Prediction by Integrating POODLE Series and Structural Information Predictors Based on a Workflow Approach.", "abstract": "", "doi": "10.3233/isb-2010-0426", "date": "2010", "authors": [{"name": "Shuichi Hirose", "id-internal": "12/3482", "id-external": ""}, {"name": "Kana Shimizu", "id-internal": "63/1928", "id-external": ""}, {"name": "Tamotsu Noguchi", "id-internal": "63/2634", "id-external": ""}], "url": {"full": "URL#3474054", "pdf": ""}, "publisher-venue": "Silico Biol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2878301891, "title": "Facial expression wonderland (FEW) - a novel design prototype of information and computer technology (ICT) for children with autism spectrum disorder (ASD).", "abstract": "", "doi": "10.1145/1882992.1883064", "date": "2010", "authors": [{"name": "Rung-Yu Tseng", "id-internal": "50/9204", "id-external": ""}, {"name": "Ellen Yi-Luen Do", "id-internal": "d/EllenYiLuenDo", "id-external": ""}], "url": {"full": "URL#3587345", "pdf": ""}, "publisher-venue": "IHI", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1635683309, "title": "TEDIS - an Information System Dedicated to Patients with Pervasive Developmental Disorders.", "abstract": "", "doi": "10.3233/978-1-60750-588-4-198", "date": "2010", "authors": [{"name": "Mohamed Ben Sa\u00efd", "id-internal": "13/2432", "id-external": ""}, {"name": "Laurence Robel", "id-internal": "131/5839", "id-external": ""}, {"name": "Erwan Vion", "id-internal": "131/6116", "id-external": ""}, {"name": "Bernard Golse", "id-internal": "131/5826", "id-external": ""}, {"name": "Jean Philippe Ja\u00efs", "id-internal": "72/3467", "id-external": ""}, {"name": "Paul Landais", "id-internal": "64/4420", "id-external": ""}], "url": {"full": "URL#3607067", "pdf": ""}, "publisher-venue": "MedInfo", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 855561648, "title": "The use of noise information for detection of temporomandibular disorder.", "abstract": "", "doi": "10.1016/j.bspc.2008.10.001", "date": "2009", "authors": [{"name": "Mansoureh Ghodsi", "id-internal": "94/7918", "id-external": ""}, {"name": "Hossein Hassani", "id-internal": "63/7917", "id-external": ""}, {"name": "Saeid Sanei", "id-internal": "24/856", "id-external": ""}, {"name": "Yulia Hicks", "id-internal": "h/YuliaHicks", "id-external": ""}], "url": {"full": "URL#3666989", "pdf": ""}, "publisher-venue": "Biomed. Signal Process. Control.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2921956832, "title": "Disorderly reasoning in information design.", "abstract": "", "doi": "10.1002/asi.21131", "date": "2009", "authors": {"name": "Peter Hall", "id-internal": "77/5108", "id-external": ""}, "url": {"full": "URL#3699926", "pdf": ""}, "publisher-venue": "J. Assoc. Inf. Sci. Technol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2099625442, "title": "Semantic integration and exploitation of orthology information and genetic disorders.", "abstract": "", "doi": "", "date": "2009", "authors": [{"name": "Jos\u00e9 Antonio Mi\u00f1arro-Gim\u00e9nez", "id-internal": "43/8253", "id-external": ""}, {"name": "Marisa Madrid", "id-internal": "35/8253", "id-external": ""}, {"name": "Jesualdo Tom\u00e1s Fern\u00e1ndez-Breis", "id-internal": "48/4460", "id-external": ""}], "url": {"full": "URL#3849410", "pdf": ""}, "publisher-venue": "SWAT4LS", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 2419273533, "title": "Defining information requirements for physician training and decision support of acid-base disorders in intensive care.", "abstract": "", "doi": "10.1109/icsmc.2007.4414127", "date": "2007", "authors": [{"name": "David T. Bauer", "id-internal": "70/5746", "id-external": ""}, {"name": "Stephanie A. Guerlain", "id-internal": "73/6848", "id-external": ""}], "url": {"full": "URL#4245781", "pdf": ""}, "publisher-venue": "SMC", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 222191398, "title": "Optimizing Long Intrinsic Disorder Predictors with Protein Evolutionary Information.", "abstract": "", "doi": "10.1142/s0219720005000886", "date": "2005", "authors": [{"name": "Kang Peng", "id-internal": "54/4478", "id-external": ""}, {"name": "Slobodan Vucetic", "id-internal": "13/5776", "id-external": ""}, {"name": "Predrag Radivojac", "id-internal": "93/308", "id-external": ""}, {"name": "Celeste J. Brown", "id-internal": "67/1424", "id-external": ""}, {"name": "A. Keith Dunker", "id-internal": "53/20", "id-external": ""}, {"name": "Zoran Obradovic", "id-internal": "92/1944", "id-external": ""}], "url": {"full": "URL#4469089", "pdf": ""}, "publisher-venue": "J. Bioinform. Comput. Biol.", "type": "Journal Articles", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3096449601, "title": "Rare Visible disorders/Diseases as Individually Identifiable Health Information.", "abstract": "", "doi": "", "date": "2005", "authors": [{"name": "Tewodros Eguale", "id-internal": "117/6605", "id-external": ""}, {"name": "Gillian Bartlett", "id-internal": "84/9251", "id-external": ""}, {"name": "Robyn Tamblyn", "id-internal": "07/819", "id-external": ""}], "url": {"full": "URL#4501355", "pdf": ""}, "publisher-venue": "AMIA", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1232298277, "title": "Icon Language-Based Auxiliary Communication System Interface for Language Disorders.", "abstract": "", "doi": "10.1007/11551898_10", "date": "2005", "authors": [{"name": "Kyonam Choo", "id-internal": "33/4359", "id-external": ""}, {"name": "Yoseop Woo", "id-internal": "50/5556", "id-external": ""}, {"name": "Hongki Min", "id-internal": "67/1341", "id-external": ""}, {"name": "JuYeon Jo", "id-internal": "86/4048", "id-external": ""}], "url": {"full": "URL#4563928", "pdf": ""}, "publisher-venue": "Multimedia Information Systems", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1299237479, "title": "An Intelligent Diagnosis System Handling Multiple Disorders.", "abstract": "", "doi": "10.1007/0-387-23152-8_53", "date": "2004", "authors": [{"name": "Wenqi Shi", "id-internal": "16/4475", "id-external": ""}, {"name": "John A. Barnden", "id-internal": "b/JohnABarnden", "id-external": ""}, {"name": "Martin Atzm\u00fcller", "id-internal": "22/4732", "id-external": ""}, {"name": "Joachim Baumeister", "id-internal": "35/5849", "id-external": ""}], "url": {"full": "URL#4684264", "pdf": ""}, "publisher-venue": "Intelligent Information Processing", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 717206399, "title": "Extension of the HEPAR II Model to Multiple-Disorder Diagnosis.", "abstract": "", "doi": "", "date": "2000", "authors": [{"name": "Agnieszka Onisko", "id-internal": "70/6287", "id-external": ""}, {"name": "Marek Druzdezel", "id-internal": "70/5540", "id-external": ""}, {"name": "Hanna Wasyluk", "id-internal": "66/6518", "id-external": ""}], "url": {"full": "URL#5071143", "pdf": ""}, "publisher-venue": "Intelligent Information Systems", "type": "Conference and Workshop Papers", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 1652169653, "title": "Information Disorders, Moral Values and the Dispute of Narratives", "abstract": "In this paper we propose a framework characterizing information disorders as\ndisputes of narratives. Such narratives present claims to readers, who must\ndecide whether to accept the statements in the claims as facts. We point out\nthat this process requires establishing connections to moral values, since it\nhas been shown that human decision making is heavily dependent on them. A\nsimple example illustrating how this could be done is given, related to claims\nabout fraud in the US 2020 Presidential elections.", "doi": "", "date": "2021-08-16", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2108.12262v2", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 115929516, "title": "Multimodal Detection of Information Disorder from Social Media", "abstract": "Social media is accompanied by an increasing proportion of content that\nprovides fake information or misleading content, known as information disorder.\nIn this paper, we study the problem of multimodal fake news detection on a\nlargescale multimodal dataset. We propose a multimodal network architecture\nthat enables different levels and types of information fusion. In addition to\nthe textual and visual content of a posting, we further leverage secondary\ninformation, i.e. user comments and metadata. We fuse information at multiple\nlevels to account for the specific intrinsic structure of the modalities. Our\nresults show that multimodal analysis is highly effective for the task and all\nmodalities contribute positively when fused properly.", "doi": "", "date": "2021-05-31", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2105.15165v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}, {"id": 3368024342, "title": "Mining Disinformation and Fake News: Concepts, Methods, and Recent\n  Advancements", "abstract": "In recent years, disinformation including fake news, has became a global\nphenomenon due to its explosive growth, particularly on social media. The wide\nspread of disinformation and fake news can cause detrimental societal effects.\nDespite the recent progress in detecting disinformation and fake news, it is\nstill non-trivial due to its complexity, diversity, multi-modality, and costs\nof fact-checking or annotation. The goal of this chapter is to pave the way for\nappreciating the challenges and advancements via: (1) introducing the types of\ninformation disorder on social media and examine their differences and\nconnections; (2) describing important and emerging tasks to combat\ndisinformation for characterization, detection and attribution; and (3)\ndiscussing a weak supervision approach to detect disinformation with limited\nlabeled data. We then provide an overview of the chapters in this book that\nrepresent the recent advancements in three related parts: (1) user engagements\nin the dissemination of information disorder; (2) techniques on detecting and\nmitigating disinformation; and (3) trending issues such as ethics, blockchain,\nclickbaits, etc. We hope this book to be a convenient entry point for\nresearchers, practitioners, and students to understand the problems and\nchallenges, learn state-of-the-art solutions for their specific needs, and\nquickly identify new research problems in their domains.", "doi": "", "date": "2020-01-02", "authors": {"name": "", "id-internal": "", "id-external": ""}, "url": {"full": "http://arxiv.org/abs/2001.00623v1", "pdf": ""}, "publisher-venue": "", "type": "", "citations": "", "references": "", "citation-list": [], "reference-list": []}]